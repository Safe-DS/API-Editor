{
    "sklearn.linear_model.Ridge": {
        "solver": {
            "refined_type": {
                "kind": "EnumType",
                "values": [
                    "sparse_cg",
                    "sag",
                    "cholesky",
                    "lsqr",
                    "auto",
                    "svd",
                    "lbfgs",
                    "saga"
                ]
            },
            "docstring": {
                "type": "{'auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg',             'sag', 'saga', 'lbfgs'}, default='auto'",
                "description": "Solver to use in the computational routines:\n\n- 'auto' chooses the solver automatically based on the type of data.\n\n- 'svd' uses a Singular Value Decomposition of X to compute the Ridge\n  coefficients. More stable for singular matrices than 'cholesky'.\n\n- 'cholesky' uses the standard scipy.linalg.solve function to\n  obtain a closed-form solution.\n\n- 'sparse_cg' uses the conjugate gradient solver as found in\n  scipy.sparse.linalg.cg. As an iterative algorithm, this solver is\n  more appropriate than 'cholesky' for large-scale data\n  (possibility to set `tol` and `max_iter`).\n\n- 'lsqr' uses the dedicated regularized least-squares routine\n  scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative\n  procedure.\n\n- 'sag' uses a Stochastic Average Gradient descent, and 'saga' uses\n  its improved, unbiased version named SAGA. Both methods also use an\n  iterative procedure, and are often faster than other solvers when\n  both n_samples and n_features are large. Note that 'sag' and\n  'saga' fast convergence is only guaranteed on features with\n  approximately the same scale. You can preprocess the data with a\n  scaler from sklearn.preprocessing.\n\n- 'lbfgs' uses L-BFGS-B algorithm implemented in\n  `scipy.optimize.minimize`. It can be used only when `positive`\n  is True.\n\nAll last six solvers support both dense and sparse data. However, only\n'sag', 'sparse_cg', and 'lbfgs' support sparse input when `fit_intercept`\nis True.\n\n.. versionadded:: 0.17\n   Stochastic Average Gradient descent solver.\n.. versionadded:: 0.19\n   SAGA solver."
            }
        }
    }
}
