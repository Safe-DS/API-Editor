{
  "class_counts": {
    "sklearn.preprocessing._label.LabelEncoder": 22465,
    "sklearn.preprocessing._data.StandardScaler": 12601,
    "sklearn.linear_model._logistic.LogisticRegression": 10496,
    "sklearn.feature_extraction.text.CountVectorizer": 9360,
    "sklearn.pipeline.Pipeline": 8677,
    "sklearn.feature_extraction.text.TfidfVectorizer": 8594,
    "sklearn.model_selection._split.StratifiedKFold": 8260,
    "sklearn.base.TransformerMixin": 8232,
    "sklearn.linear_model._base.LinearRegression": 5391,
    "sklearn.decomposition._pca.PCA": 5223,
    "sklearn.ensemble._forest.RandomForestClassifier": 5180,
    "sklearn.preprocessing._data.MinMaxScaler": 4836,
    "sklearn.model_selection._split.KFold": 4344,
    "sklearn.neighbors._classification.KNeighborsClassifier": 4013,
    "sklearn.ensemble._forest.RandomForestRegressor": 3941,
    "sklearn.preprocessing._encoders.OneHotEncoder": 3466,
    "sklearn.calibration.CalibratedClassifierCV": 3171,
    "sklearn.base.ClassifierMixin": 2842,
    "sklearn.model_selection._search.GridSearchCV": 2752,
    "sklearn.tree._classes.DecisionTreeClassifier": 2614,
    "sklearn.cluster._kmeans.KMeans": 2288,
    "sklearn.decomposition._truncated_svd.TruncatedSVD": 2226,
    "sklearn.linear_model._ridge.Ridge": 1876,
    "sklearn.base.RegressorMixin": 1801,
    "sklearn.ensemble._gb.GradientBoostingRegressor": 1720,
    "sklearn.impute._base.SimpleImputer": 1692,
    "sklearn.svm._classes.SVC": 1675,
    "sklearn.tree._classes.BaseDecisionTree": 1560,
    "sklearn.tree._classes.DecisionTreeRegressor": 1468,
    "sklearn.feature_selection._base.SelectorMixin": 1432,
    "sklearn.ensemble._gb.GradientBoostingClassifier": 1373,
    "sklearn.preprocessing._label.LabelBinarizer": 1323,
    "sklearn.model_selection._split.GroupKFold": 1305,
    "sklearn.preprocessing._data.PolynomialFeatures": 1136,
    "sklearn.naive_bayes.GaussianNB": 1130,
    "sklearn.manifold._t_sne.TSNE": 1064,
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier": 990,
    "sklearn.preprocessing._data.QuantileTransformer": 976,
    "sklearn.ensemble._voting.VotingClassifier": 957,
    "sklearn.linear_model._coordinate_descent.ElasticNet": 942,
    "sklearn.naive_bayes.MultinomialNB": 909,
    "sklearn.compose._column_transformer.ColumnTransformer": 877,
    "sklearn.linear_model._stochastic_gradient.SGDClassifier": 871,
    "sklearn.feature_selection._variance_threshold.VarianceThreshold": 848,
    "sklearn.linear_model._coordinate_descent.Lasso": 748,
    "sklearn.neighbors._regression.KNeighborsRegressor": 748,
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis": 742,
    "sklearn.preprocessing._data.RobustScaler": 734,
    "sklearn.ensemble._forest.ExtraTreesClassifier": 733,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier": 729,
    "sklearn.svm._classes.LinearSVC": 669,
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer": 667,
    "sklearn.multiclass.OneVsRestClassifier": 631,
    "sklearn.pipeline.FeatureUnion": 586,
    "sklearn.model_selection._search.RandomizedSearchCV": 573,
    "sklearn.decomposition._fastica.FastICA": 513,
    "sklearn.feature_extraction.text.TfidfTransformer": 510,
    "sklearn.svm._classes.SVR": 471,
    "sklearn.preprocessing._encoders.OrdinalEncoder": 462,
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis": 462,
    "sklearn.preprocessing._function_transformer.FunctionTransformer": 462,
    "sklearn.model_selection._split.StratifiedShuffleSplit": 456,
    "sklearn.preprocessing._label.MultiLabelBinarizer": 415,
    "sklearn.linear_model._bayes.BayesianRidge": 390,
    "sklearn.ensemble._weight_boosting.AdaBoostRegressor": 377,
    "sklearn.cluster._kmeans.MiniBatchKMeans": 373,
    "sklearn.feature_selection._univariate_selection.SelectKBest": 367,
    "sklearn.ensemble._forest.ExtraTreesRegressor": 314,
    "sklearn.mixture._gaussian_mixture.GaussianMixture": 296,
    "sklearn.feature_selection._rfe.RFE": 295,
    "sklearn.feature_selection._from_model.SelectFromModel": 291,
    "sklearn.preprocessing._data.Normalizer": 290,
    "sklearn.model_selection._split.ShuffleSplit": 279,
    "sklearn.ensemble._bagging.BaggingClassifier": 270,
    "sklearn.linear_model._logistic.LogisticRegressionCV": 240,
    "sklearn.linear_model._ridge.RidgeClassifier": 239,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor": 239,
    "sklearn.neighbors._unsupervised.NearestNeighbors": 224,
    "sklearn.ensemble._bagging.BaggingRegressor": 217,
    "sklearn.cluster._dbscan.DBSCAN": 210,
    "sklearn.naive_bayes.BernoulliNB": 206,
    "sklearn.model_selection._split.TimeSeriesSplit": 204,
    "sklearn.base.BaseEstimator": 194,
    "sklearn.feature_selection._univariate_selection.SelectPercentile": 169,
    "sklearn.model_selection._split.RepeatedKFold": 166,
    "sklearn.kernel_ridge.KernelRidge": 166,
    "sklearn.preprocessing._data.PowerTransformer": 158,
    "sklearn.random_projection.BaseRandomProjection": 156,
    "sklearn.neighbors._kde.KernelDensity": 151,
    "sklearn.preprocessing._data.Binarizer": 141,
    "sklearn.feature_selection._rfe.RFECV": 141,
    "sklearn.ensemble._stacking.StackingClassifier": 138,
    "sklearn.decomposition._nmf.NMF": 137,
    "sklearn.multioutput.MultiOutputClassifier": 135,
    "sklearn.linear_model._stochastic_gradient.SGDRegressor": 134,
    "sklearn.ensemble._voting.VotingRegressor": 131,
    "sklearn.impute._iterative.IterativeImputer": 130,
    "sklearn.model_selection._split.RepeatedStratifiedKFold": 128,
    "sklearn.dummy.DummyClassifier": 126,
    "sklearn.linear_model._coordinate_descent.LassoCV": 120,
    "sklearn.model_selection._split.GroupShuffleSplit": 118,
    "sklearn.ensemble._stacking.StackingRegressor": 112,
    "sklearn.decomposition._lda.LatentDirichletAllocation": 109,
    "sklearn.ensemble._iforest.IsolationForest": 108,
    "sklearn.svm._classes.NuSVC": 108,
    "sklearn.feature_extraction.text.HashingVectorizer": 104,
    "sklearn.preprocessing._discretization.KBinsDiscretizer": 104,
    "sklearn.dummy.DummyRegressor": 103,
    "sklearn.random_projection.SparseRandomProjection": 103,
    "sklearn.preprocessing._data.MaxAbsScaler": 100,
    "sklearn.random_projection.GaussianRandomProjection": 94,
    "sklearn.cluster._birch.Birch": 91,
    "sklearn.covariance._graph_lasso.GraphicalLasso": 87,
    "sklearn.decomposition._kernel_pca.KernelPCA": 86,
    "sklearn.linear_model._coordinate_descent.ElasticNetCV": 85,
    "sklearn.impute._knn.KNNImputer": 85,
    "sklearn.svm._classes.LinearSVR": 82,
    "sklearn.multioutput.MultiOutputRegressor": 81,
    "sklearn.linear_model._perceptron.Perceptron": 78,
    "sklearn.cluster._agglomerative.AgglomerativeClustering": 74,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier": 70,
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance": 66,
    "sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay": 64,
    "sklearn.covariance._shrunk_covariance.OAS": 61,
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope": 59,
    "sklearn.decomposition._factor_analysis.FactorAnalysis": 56,
    "sklearn.svm._classes.NuSVR": 56,
    "sklearn.linear_model._huber.HuberRegressor": 55,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier": 54,
    "sklearn.compose._target.TransformedTargetRegressor": 52,
    "sklearn.linear_model._ransac.RANSACRegressor": 50,
    "sklearn.linear_model._ridge.RidgeClassifierCV": 47,
    "sklearn.linear_model._least_angle.LassoLarsCV": 44,
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier": 41,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor": 40,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet": 38,
    "sklearn.neighbors._lof.LocalOutlierFactor": 34,
    "sklearn.tree._classes.ExtraTreeClassifier": 32,
    "sklearn.manifold._isomap.Isomap": 29,
    "sklearn.compose._column_transformer.make_column_selector": 28,
    "sklearn.linear_model._theil_sen.TheilSenRegressor": 27,
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor": 26,
    "sklearn.feature_extraction._hash.FeatureHasher": 26,
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture": 26,
    "sklearn.model_selection._search.ParameterGrid": 26,
    "sklearn.covariance._shrunk_covariance.LedoitWolf": 25,
    "sklearn.decomposition._incremental_pca.IncrementalPCA": 25,
    "sklearn.base.ClusterMixin": 24,
    "sklearn.multiclass.OneVsOneClassifier": 23,
    "sklearn.svm._classes.OneClassSVM": 22,
    "sklearn.linear_model._bayes.ARDRegression": 21,
    "sklearn.isotonic.IsotonicRegression": 21,
    "sklearn.base.OutlierMixin": 19,
    "sklearn.ensemble._forest.RandomTreesEmbedding": 18,
    "sklearn.cluster._spectral.SpectralClustering": 18,
    "sklearn.manifold._mds.MDS": 17,
    "sklearn.manifold._spectral_embedding.SpectralEmbedding": 17,
    "sklearn.impute._base.MissingIndicator": 17,
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding": 17,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor": 17,
    "sklearn.model_selection._split.PredefinedSplit": 16,
    "sklearn.decomposition._sparse_pca.SparsePCA": 14,
    "sklearn.gaussian_process.kernels.RBF": 13,
    "sklearn.linear_model._least_angle.LassoLars": 12,
    "sklearn.cluster._mean_shift.MeanShift": 11,
    "sklearn.naive_bayes.CategoricalNB": 11,
    "sklearn.model_selection._split.LeaveOneGroupOut": 10,
    "sklearn.cluster._affinity_propagation.AffinityPropagation": 10,
    "sklearn.linear_model._glm.glm.TweedieRegressor": 10,
    "sklearn.covariance._shrunk_covariance.ShrunkCovariance": 10,
    "sklearn.cross_decomposition._pls.PLSRegression": 9,
    "sklearn.linear_model._least_angle.Lars": 9,
    "sklearn.linear_model._least_angle.LassoLarsIC": 9,
    "sklearn.kernel_approximation.Nystroem": 9,
    "sklearn.feature_extraction.image.PatchExtractor": 8,
    "sklearn.naive_bayes.ComplementNB": 8,
    "sklearn.covariance._robust_covariance.MinCovDet": 8,
    "sklearn.semi_supervised._label_propagation.LabelSpreading": 8,
    "sklearn.multioutput.RegressorChain": 7,
    "sklearn.cluster._optics.OPTICS": 7,
    "sklearn.cluster._agglomerative.FeatureAgglomeration": 7,
    "sklearn.linear_model._omp.OrthogonalMatchingPursuit": 6,
    "sklearn.neighbors._nearest_centroid.NearestCentroid": 6,
    "sklearn.feature_selection._univariate_selection.SelectFpr": 5,
    "sklearn.tree._classes.ExtraTreeRegressor": 5,
    "sklearn.feature_selection._univariate_selection.GenericUnivariateSelect": 5,
    "sklearn.linear_model._omp.OrthogonalMatchingPursuitCV": 5,
    "sklearn.neighbors._classification.RadiusNeighborsClassifier": 5,
    "sklearn.neighbors._regression.RadiusNeighborsRegressor": 5,
    "sklearn.feature_selection._sequential.SequentialFeatureSelector": 4,
    "sklearn.metrics._plot.roc_curve.RocCurveDisplay": 4,
    "sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay": 4,
    "sklearn.neural_network._rbm.BernoulliRBM": 4,
    "sklearn.linear_model._least_angle.LarsCV": 4,
    "sklearn.semi_supervised._label_propagation.LabelPropagation": 3,
    "sklearn.linear_model._glm.glm.GammaRegressor": 3,
    "sklearn.cross_decomposition._pls.PLSSVD": 3,
    "sklearn.kernel_approximation.RBFSampler": 3,
    "sklearn.gaussian_process.kernels.WhiteKernel": 2,
    "sklearn.model_selection._split.BaseCrossValidator": 2,
    "sklearn.gaussian_process.kernels.DotProduct": 2,
    "sklearn.preprocessing._data.KernelCenterer": 2,
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning": 2,
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV": 2,
    "sklearn.gaussian_process.kernels.ConstantKernel": 2,
    "sklearn.gaussian_process.kernels.Matern": 1,
    "sklearn.gaussian_process.kernels.RationalQuadratic": 1,
    "sklearn.linear_model._glm.glm.PoissonRegressor": 1,
    "sklearn.model_selection._split.LeaveOneOut": 1,
    "sklearn.cross_decomposition._pls.CCA": 1,
    "sklearn.feature_selection._univariate_selection.SelectFdr": 1,
    "sklearn.feature_selection._univariate_selection.SelectFwe": 1,
    "sklearn.covariance._graph_lasso.GraphicalLassoCV": 1,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV": 1,
    "sklearn.neighbors._nca.NeighborhoodComponentsAnalysis": 1,
    "sklearn.base.BiclusterMixin": 0,
    "sklearn.base.DensityMixin": 0,
    "sklearn.base.MetaEstimatorMixin": 0,
    "sklearn.base.MultiOutputMixin": 0,
    "sklearn.cluster._bicluster.SpectralBiclustering": 0,
    "sklearn.cluster._bicluster.SpectralCoclustering": 0,
    "sklearn.cross_decomposition._pls.PLSCanonical": 0,
    "sklearn.decomposition._dict_learning.DictionaryLearning": 0,
    "sklearn.decomposition._dict_learning.SparseCoder": 0,
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA": 0,
    "sklearn.ensemble._base.BaseEnsemble": 0,
    "sklearn.exceptions.ChangedBehaviorWarning": 0,
    "sklearn.exceptions.ConvergenceWarning": 0,
    "sklearn.exceptions.DataConversionWarning": 0,
    "sklearn.exceptions.DataDimensionalityWarning": 0,
    "sklearn.exceptions.EfficiencyWarning": 0,
    "sklearn.exceptions.FitFailedWarning": 0,
    "sklearn.exceptions.NonBLASDotWarning": 0,
    "sklearn.exceptions.NotFittedError": 0,
    "sklearn.exceptions.PositiveSpectrumWarning": 0,
    "sklearn.exceptions.SkipTestWarning": 0,
    "sklearn.exceptions.UndefinedMetricWarning": 0,
    "sklearn.gaussian_process.kernels.CompoundKernel": 0,
    "sklearn.gaussian_process.kernels.ExpSineSquared": 0,
    "sklearn.gaussian_process.kernels.Exponentiation": 0,
    "sklearn.gaussian_process.kernels.GenericKernelMixin": 0,
    "sklearn.gaussian_process.kernels.Hyperparameter": 0,
    "sklearn.gaussian_process.kernels.Kernel": 0,
    "sklearn.gaussian_process.kernels.KernelOperator": 0,
    "sklearn.gaussian_process.kernels.NormalizedKernelMixin": 0,
    "sklearn.gaussian_process.kernels.PairwiseKernel": 0,
    "sklearn.gaussian_process.kernels.Product": 0,
    "sklearn.gaussian_process.kernels.StationaryKernelMixin": 0,
    "sklearn.gaussian_process.kernels.Sum": 0,
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay": 0,
    "sklearn.kernel_approximation.AdditiveChi2Sampler": 0,
    "sklearn.kernel_approximation.PolynomialCountSketch": 0,
    "sklearn.kernel_approximation.SkewedChi2Sampler": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskLasso": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV": 0,
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor": 0,
    "sklearn.linear_model._ridge.RidgeCV": 0,
    "sklearn.metrics._plot.det_curve.DetCurveDisplay": 0,
    "sklearn.model_selection._search.ParameterSampler": 0,
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV": 0,
    "sklearn.model_selection._split.LeavePGroupsOut": 0,
    "sklearn.model_selection._split.LeavePOut": 0,
    "sklearn.multiclass.OutputCodeClassifier": 0,
    "sklearn.multioutput.ClassifierChain": 0,
    "sklearn.neighbors._graph.KNeighborsTransformer": 0,
    "sklearn.neighbors._graph.RadiusNeighborsTransformer": 0,
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier": 0,
    "sklearn.utils.Bunch": 0,
    "sklearn.utils.deprecation.deprecated": 0,
    "sklearn.utils.fixes.MaskedArray": 0,
    "sklearn.utils.fixes.loguniform": 0
  },
  "function_counts": {
    "sklearn.model_selection._split.train_test_split": 16829,
    "sklearn.metrics._regression.mean_squared_error": 8462,
    "sklearn.preprocessing._label.LabelEncoder.transform": 8446,
    "sklearn.metrics._ranking.roc_auc_score": 8297,
    "sklearn.base.TransformerMixin.fit_transform": 8232,
    "sklearn.preprocessing._label.LabelEncoder.fit_transform": 7897,
    "sklearn.metrics._classification.accuracy_score": 7130,
    "sklearn.preprocessing._data.StandardScaler.__init__": 6152,
    "sklearn.preprocessing._label.LabelEncoder.fit": 5246,
    "sklearn.ensemble._forest.RandomForestClassifier.__init__": 5180,
    "sklearn.linear_model._logistic.LogisticRegression.__init__": 5129,
    "sklearn.metrics._classification.confusion_matrix": 4460,
    "sklearn.preprocessing._data.StandardScaler.transform": 4369,
    "sklearn.model_selection._split.StratifiedKFold.__init__": 4359,
    "sklearn.model_selection._split.KFold.__init__": 4344,
    "sklearn.metrics._classification.f1_score": 4087,
    "sklearn.metrics._classification.log_loss": 4078,
    "sklearn.ensemble._forest.RandomForestRegressor.__init__": 3941,
    "sklearn.model_selection._split.StratifiedKFold.split": 3901,
    "sklearn.model_selection._validation.cross_val_score": 3801,
    "sklearn.pipeline.Pipeline.__init__": 3706,
    "sklearn.linear_model._logistic.LogisticRegression.fit": 3369,
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__": 3215,
    "sklearn.metrics._classification.classification_report": 3074,
    "sklearn.linear_model._base.LinearRegression.__init__": 2984,
    "sklearn.feature_extraction.text.CountVectorizer.__init__": 2937,
    "sklearn.metrics._regression.mean_absolute_error": 2920,
    "sklearn.base.ClassifierMixin.score": 2842,
    "sklearn.model_selection._search.GridSearchCV.__init__": 2752,
    "sklearn.feature_extraction.text.TfidfVectorizer.transform": 2730,
    "sklearn.decomposition._pca.PCA.__init__": 2653,
    "sklearn.linear_model._base.LinearRegression.fit": 2407,
    "sklearn.feature_extraction.text.CountVectorizer.transform": 2373,
    "sklearn.preprocessing._data.MinMaxScaler.__init__": 2297,
    "sklearn.metrics._regression.r2_score": 2029,
    "sklearn.linear_model._logistic.LogisticRegression.predict_proba": 1995,
    "sklearn.preprocessing._data.StandardScaler.fit": 1837,
    "sklearn.neighbors._classification.KNeighborsClassifier.__init__": 1821,
    "sklearn.feature_extraction.text.CountVectorizer.fit_transform": 1815,
    "sklearn.base.RegressorMixin.score": 1801,
    "sklearn.pipeline.Pipeline.predict": 1796,
    "sklearn.feature_extraction.text.TfidfVectorizer.fit_transform": 1793,
    "sklearn.pipeline.Pipeline.fit": 1780,
    "sklearn.decomposition._pca.PCA.fit_transform": 1719,
    "sklearn.svm._classes.SVC.__init__": 1675,
    "sklearn.preprocessing._data.MinMaxScaler.transform": 1605,
    "sklearn.tree._classes.DecisionTreeClassifier.__init__": 1548,
    "sklearn.tree._classes.BaseDecisionTree.predict": 1547,
    "sklearn.preprocessing._encoders.OneHotEncoder.__init__": 1506,
    "sklearn.feature_extraction.text.CountVectorizer.get_feature_names": 1451,
    "sklearn.metrics._ranking.roc_curve": 1411,
    "sklearn.calibration.CalibratedClassifierCV.predict_proba": 1322,
    "sklearn.linear_model._ridge.Ridge.__init__": 1225,
    "sklearn.metrics._classification.precision_score": 1153,
    "sklearn.impute._base.SimpleImputer.__init__": 1140,
    "sklearn.metrics._classification.recall_score": 1124,
    "sklearn.pipeline.make_pipeline": 1097,
    "sklearn.neighbors._classification.KNeighborsClassifier.fit": 1093,
    "sklearn.metrics._classification.cohen_kappa_score": 1072,
    "sklearn.metrics._regression.mean_squared_log_error": 1052,
    "sklearn.decomposition._truncated_svd.TruncatedSVD.__init__": 996,
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__": 989,
    "sklearn.cluster._kmeans.KMeans.__init__": 928,
    "sklearn.tree._classes.DecisionTreeClassifier.fit": 922,
    "sklearn.metrics._ranking.auc": 918,
    "sklearn.naive_bayes.MultinomialNB.__init__": 909,
    "sklearn.tree._classes.DecisionTreeRegressor.__init__": 896,
    "sklearn.feature_selection._base.SelectorMixin.transform": 895,
    "sklearn.preprocessing._label.LabelEncoder.inverse_transform": 876,
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__": 865,
    "sklearn.feature_extraction.text.TfidfVectorizer.fit": 856,
    "sklearn.decomposition._pca.PCA.fit": 851,
    "sklearn.neighbors._classification.KNeighborsClassifier.predict": 842,
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__": 841,
    "sklearn.utils.shuffle": 821,
    "sklearn.metrics._scorer.make_scorer": 800,
    "sklearn.feature_extraction.text.CountVectorizer.fit": 783,
    "sklearn.calibration.CalibratedClassifierCV.__init__": 782,
    "sklearn.preprocessing._encoders.OneHotEncoder.fit_transform": 765,
    "sklearn.calibration.CalibratedClassifierCV.fit": 753,
    "sklearn.linear_model._coordinate_descent.Lasso.__init__": 748,
    "sklearn.naive_bayes.GaussianNB.__init__": 741,
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__": 733,
    "sklearn.ensemble._gb.GradientBoostingRegressor.predict": 718,
    "sklearn.preprocessing._encoders.OneHotEncoder.transform": 694,
    "sklearn.model_selection._split.GroupKFold.__init__": 689,
    "sklearn.cluster._kmeans.KMeans.fit": 674,
    "sklearn.linear_model._ridge.Ridge.fit": 651,
    "sklearn.model_selection._split.GroupKFold.split": 616,
    "sklearn.feature_selection._variance_threshold.VarianceThreshold.__init__": 605,
    "sklearn.model_selection._search.RandomizedSearchCV.__init__": 573,
    "sklearn.tree._classes.DecisionTreeRegressor.fit": 572,
    "sklearn.preprocessing._data.PolynomialFeatures.__init__": 562,
    "sklearn.manifold._t_sne.TSNE.__init__": 536,
    "sklearn.preprocessing._data.RobustScaler.__init__": 534,
    "sklearn.manifold._t_sne.TSNE.fit_transform": 528,
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.__init__": 527,
    "sklearn.preprocessing._data.MinMaxScaler.fit": 521,
    "sklearn.decomposition._truncated_svd.TruncatedSVD.fit_transform": 518,
    "sklearn.decomposition._truncated_svd.TruncatedSVD.transform": 514,
    "sklearn.preprocessing._label.LabelBinarizer.__init__": 490,
    "sklearn.feature_selection._base.SelectorMixin.get_support": 487,
    "sklearn.linear_model._coordinate_descent.ElasticNet.fit": 475,
    "sklearn.svm._classes.SVR.__init__": 471,
    "sklearn.linear_model._coordinate_descent.ElasticNet.__init__": 467,
    "sklearn.preprocessing._function_transformer.FunctionTransformer.__init__": 456,
    "sklearn.svm._classes.LinearSVC.__init__": 453,
    "sklearn.compose._column_transformer.ColumnTransformer.__init__": 443,
    "sklearn.preprocessing._data.minmax_scale": 433,
    "sklearn.preprocessing._data.normalize": 429,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__": 428,
    "sklearn.preprocessing._data.MinMaxScaler.inverse_transform": 412,
    "sklearn.preprocessing._label.LabelBinarizer.fit_transform": 410,
    "sklearn.pipeline.Pipeline.fit_transform": 410,
    "sklearn.preprocessing._data.QuantileTransformer.transform": 391,
    "sklearn.naive_bayes.GaussianNB.fit": 387,
    "sklearn.impute._base.SimpleImputer.transform": 377,
    "sklearn.cluster._kmeans.KMeans.predict": 369,
    "sklearn.preprocessing._data.QuantileTransformer.__init__": 368,
    "sklearn.feature_selection._univariate_selection.SelectKBest.__init__": 367,
    "sklearn.preprocessing._encoders.OneHotEncoder.fit": 362,
    "sklearn.neighbors._regression.KNeighborsRegressor.__init__": 356,
    "sklearn.feature_extraction.text.TfidfTransformer.__init__": 336,
    "sklearn.preprocessing._encoders.OrdinalEncoder.__init__": 326,
    "sklearn.pipeline.FeatureUnion.__init__": 324,
    "sklearn.preprocessing._data.scale": 314,
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__": 314,
    "sklearn.calibration.CalibratedClassifierCV.predict": 314,
    "sklearn.pipeline.Pipeline.predict_proba": 313,
    "sklearn.ensemble._voting.VotingClassifier.__init__": 304,
    "sklearn.model_selection._validation.cross_validate": 299,
    "sklearn.ensemble._voting.VotingClassifier.predict": 291,
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.__init__": 287,
    "sklearn.multiclass.OneVsRestClassifier.__init__": 280,
    "sklearn.preprocessing._label.LabelBinarizer.transform": 279,
    "sklearn.model_selection._split.ShuffleSplit.__init__": 279,
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.__init__": 276,
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.predict_proba": 274,
    "sklearn.ensemble._gb.GradientBoostingClassifier.predict": 271,
    "sklearn.preprocessing._data.PolynomialFeatures.get_feature_names": 267,
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__": 266,
    "sklearn.ensemble._voting.VotingClassifier.fit": 259,
    "sklearn.neighbors._classification.KNeighborsClassifier.predict_proba": 257,
    "sklearn.utils.class_weight.compute_class_weight": 251,
    "sklearn.cluster._kmeans.KMeans.fit_predict": 251,
    "sklearn.feature_selection._variance_threshold.VarianceThreshold.fit": 243,
    "sklearn.preprocessing._data.StandardScaler.inverse_transform": 241,
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.__init__": 240,
    "sklearn.model_selection._split.StratifiedShuffleSplit.__init__": 240,
    "sklearn.pipeline.Pipeline.score": 236,
    "sklearn.ensemble._weight_boosting.AdaBoostRegressor.__init__": 233,
    "sklearn.base.clone": 231,
    "sklearn.ensemble._gb.GradientBoostingClassifier.predict_proba": 227,
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.fit_transform": 225,
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.fit": 223,
    "sklearn.svm._classes.LinearSVC.fit": 216,
    "sklearn.compose._column_transformer.ColumnTransformer.fit_transform": 216,
    "sklearn.model_selection._split.StratifiedShuffleSplit.split": 216,
    "sklearn.feature_selection._from_model.SelectFromModel.__init__": 215,
    "sklearn.model_selection._validation.cross_val_predict": 214,
    "sklearn.neighbors._regression.KNeighborsRegressor.predict": 212,
    "sklearn.naive_bayes.BernoulliNB.__init__": 206,
    "sklearn.preprocessing._data.PolynomialFeatures.transform": 203,
    "sklearn.tree._export.export_graphviz": 202,
    "sklearn.metrics._ranking.precision_recall_curve": 201,
    "sklearn.preprocessing._data.QuantileTransformer.fit": 200,
    "sklearn.linear_model._bayes.BayesianRidge.__init__": 194,
    "sklearn.decomposition._truncated_svd.TruncatedSVD.fit": 191,
    "sklearn.decomposition._fastica.FastICA.__init__": 190,
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.predict": 189,
    "sklearn.ensemble._bagging.BaggingClassifier.__init__": 186,
    "sklearn.neighbors._regression.KNeighborsRegressor.fit": 180,
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix": 180,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.predict": 179,
    "sklearn.compose._column_transformer.ColumnTransformer.transform": 178,
    "sklearn.utils.resample": 176,
    "sklearn.preprocessing._label.MultiLabelBinarizer.__init__": 175,
    "sklearn.impute._base.SimpleImputer.fit": 175,
    "sklearn.cluster._kmeans.MiniBatchKMeans.predict": 174,
    "sklearn.feature_selection._univariate_selection.SelectPercentile.__init__": 169,
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.fit": 169,
    "sklearn.model_selection._split.RepeatedKFold.__init__": 166,
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.transform": 166,
    "sklearn.decomposition._fastica.FastICA.fit_transform": 163,
    "sklearn.metrics._ranking.average_precision_score": 154,
    "sklearn.random_projection.BaseRandomProjection.transform": 153,
    "sklearn.multiclass.OneVsRestClassifier.predict": 152,
    "sklearn.linear_model._ridge.RidgeClassifier.__init__": 151,
    "sklearn.preprocessing._data.RobustScaler.transform": 149,
    "sklearn.decomposition._fastica.FastICA.transform": 146,
    "sklearn.multiclass.OneVsRestClassifier.fit": 146,
    "sklearn.metrics._classification.matthews_corrcoef": 145,
    "sklearn.tree._classes.DecisionTreeClassifier.predict_proba": 144,
    "sklearn.metrics._classification.fbeta_score": 143,
    "sklearn.preprocessing._label.MultiLabelBinarizer.fit_transform": 142,
    "sklearn.feature_selection._rfe.RFE.__init__": 142,
    "sklearn.ensemble._bagging.BaggingRegressor.__init__": 142,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__": 141,
    "sklearn.metrics.pairwise.cosine_similarity": 134,
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__": 134,
    "sklearn.model_selection._validation.learning_curve": 129,
    "sklearn.preprocessing._data.Normalizer.__init__": 128,
    "sklearn.model_selection._split.RepeatedStratifiedKFold.__init__": 128,
    "sklearn.model_selection._split.TimeSeriesSplit.__init__": 127,
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__": 125,
    "sklearn.preprocessing._encoders.OneHotEncoder.get_feature_names": 123,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.predict_proba": 122,
    "sklearn.preprocessing._label.LabelBinarizer.fit": 121,
    "sklearn.linear_model._bayes.BayesianRidge.predict": 121,
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__": 120,
    "sklearn.feature_extraction.text.TfidfTransformer.transform": 118,
    "sklearn.preprocessing._data.Normalizer.transform": 114,
    "sklearn.neighbors._unsupervised.NearestNeighbors.fit": 114,
    "sklearn.neighbors._unsupervised.NearestNeighbors.__init__": 110,
    "sklearn.base.BaseEstimator.get_params": 108,
    "sklearn.svm._classes.NuSVC.__init__": 108,
    "sklearn.cluster._kmeans.MiniBatchKMeans.__init__": 105,
    "sklearn.feature_selection._rfe.RFE.fit": 104,
    "sklearn.preprocessing._data.PolynomialFeatures.fit": 104,
    "sklearn.random_projection.SparseRandomProjection.__init__": 103,
    "sklearn.cluster._dbscan.DBSCAN.__init__": 103,
    "sklearn.pipeline.FeatureUnion.transform": 99,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.predict": 98,
    "sklearn.kernel_ridge.KernelRidge.__init__": 97,
    "sklearn.linear_model._logistic.LogisticRegressionCV.fit": 96,
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit": 95,
    "sklearn.random_projection.GaussianRandomProjection.__init__": 94,
    "sklearn.utils.validation.indexable": 94,
    "sklearn.cluster._kmeans.MiniBatchKMeans.fit": 92,
    "sklearn.preprocessing._encoders.OrdinalEncoder.transform": 89,
    "sklearn.linear_model._ridge.RidgeClassifier.fit": 88,
    "sklearn.base.BaseEstimator.set_params": 86,
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__": 85,
    "sklearn.pipeline.FeatureUnion.fit_transform": 85,
    "sklearn.multioutput.MultiOutputRegressor.__init__": 81,
    "sklearn.preprocessing._data.Binarizer.__init__": 81,
    "sklearn.metrics._regression.explained_variance_score": 79,
    "sklearn.datasets._samples_generator.make_classification": 79,
    "sklearn.ensemble._weight_boosting.AdaBoostRegressor.fit": 78,
    "sklearn.linear_model._perceptron.Perceptron.__init__": 78,
    "sklearn.model_selection._split.TimeSeriesSplit.split": 77,
    "sklearn.preprocessing._data.PowerTransformer.__init__": 76,
    "sklearn.feature_selection._from_model.SelectFromModel.fit": 76,
    "sklearn.linear_model._bayes.BayesianRidge.fit": 75,
    "sklearn.ensemble._bagging.BaggingRegressor.predict": 75,
    "sklearn.feature_selection._rfe.RFECV.__init__": 73,
    "sklearn.feature_selection._mutual_info.mutual_info_classif": 69,
    "sklearn.multioutput.MultiOutputClassifier.__init__": 68,
    "sklearn.feature_selection._rfe.RFECV.fit": 68,
    "sklearn.ensemble._weight_boosting.AdaBoostRegressor.predict": 66,
    "sklearn.feature_extraction.text.HashingVectorizer.__init__": 66,
    "sklearn.ensemble._stacking.StackingRegressor.__init__": 65,
    "sklearn.decomposition._nmf.NMF.__init__": 65,
    "sklearn.model_selection._split.GroupShuffleSplit.__init__": 64,
    "sklearn.cluster._dbscan.DBSCAN.fit": 64,
    "sklearn.impute._knn.KNNImputer.__init__": 64,
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.__init__": 63,
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__": 62,
    "sklearn.covariance._shrunk_covariance.OAS.fit": 61,
    "sklearn.compose._column_transformer.make_column_transformer": 60,
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict_proba": 60,
    "sklearn.feature_selection._mutual_info.mutual_info_regression": 60,
    "sklearn.utils.validation.check_array": 59,
    "sklearn.metrics._ranking.label_ranking_average_precision_score": 59,
    "sklearn.ensemble._voting.VotingRegressor.__init__": 58,
    "sklearn.metrics._classification.precision_recall_fscore_support": 58,
    "sklearn.metrics._classification.multilabel_confusion_matrix": 57,
    "sklearn.svm._classes.NuSVR.__init__": 56,
    "sklearn.feature_extraction.text.TfidfTransformer.fit": 56,
    "sklearn.preprocessing._discretization.KBinsDiscretizer.__init__": 56,
    "sklearn.preprocessing._data.MaxAbsScaler.__init__": 55,
    "sklearn.impute._iterative.IterativeImputer.__init__": 55,
    "sklearn.model_selection._split.GroupShuffleSplit.split": 54,
    "sklearn.pipeline.make_union": 54,
    "sklearn.svm._classes.LinearSVR.__init__": 54,
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__": 53,
    "sklearn.dummy.DummyRegressor.__init__": 52,
    "sklearn.neighbors._kde.KernelDensity.score_samples": 52,
    "sklearn.ensemble._bagging.BaggingClassifier.predict": 51,
    "sklearn.preprocessing._label.MultiLabelBinarizer.transform": 51,
    "sklearn.utils.validation.check_is_fitted": 50,
    "sklearn.dummy.DummyClassifier.__init__": 50,
    "sklearn.neighbors._kde.KernelDensity.__init__": 50,
    "sklearn.feature_selection._base.SelectorMixin.inverse_transform": 50,
    "sklearn.covariance._graph_lasso.GraphicalLasso.fit": 50,
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.predict_proba": 49,
    "sklearn.multiclass.OneVsRestClassifier.predict_proba": 49,
    "sklearn.preprocessing._data.RobustScaler.fit": 48,
    "sklearn.ensemble._stacking.StackingClassifier.__init__": 48,
    "sklearn.preprocessing._data.Normalizer.fit": 48,
    "sklearn.cluster._birch.Birch.fit": 47,
    "sklearn.neighbors._kde.KernelDensity.fit": 47,
    "sklearn.ensemble._stacking.StackingRegressor.fit": 47,
    "sklearn.pipeline.FeatureUnion.fit": 45,
    "sklearn.ensemble._iforest.IsolationForest.__init__": 44,
    "sklearn.linear_model._least_angle.LassoLarsCV.__init__": 44,
    "sklearn.metrics._plot.roc_curve.plot_roc_curve": 43,
    "sklearn.decomposition._nmf.NMF.fit_transform": 43,
    "sklearn.cluster._dbscan.DBSCAN.fit_predict": 43,
    "sklearn.tree._export.plot_tree": 42,
    "sklearn.preprocessing._label.MultiLabelBinarizer.fit": 42,
    "sklearn.metrics.cluster._unsupervised.silhouette_score": 42,
    "sklearn.pipeline.Pipeline.set_params": 41,
    "sklearn.preprocessing._data.PowerTransformer.fit_transform": 40,
    "sklearn.linear_model._ridge.RidgeClassifierCV.__init__": 40,
    "sklearn.ensemble._stacking.StackingClassifier.fit": 40,
    "sklearn.linear_model._huber.HuberRegressor.__init__": 40,
    "sklearn.cluster._kmeans.KMeans.transform": 40,
    "sklearn.utils.extmath.safe_sparse_dot": 40,
    "sklearn.preprocessing._encoders.OrdinalEncoder.fit": 39,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__": 39,
    "sklearn.ensemble._voting.VotingRegressor.fit": 39,
    "sklearn.kernel_ridge.KernelRidge.predict": 39,
    "sklearn.datasets._base.load_iris": 38,
    "sklearn.utils.validation.check_random_state": 37,
    "sklearn.covariance._graph_lasso.GraphicalLasso.__init__": 37,
    "sklearn.preprocessing._label.label_binarize": 36,
    "sklearn.cluster._agglomerative.AgglomerativeClustering.__init__": 36,
    "sklearn.preprocessing._discretization.KBinsDiscretizer.transform": 36,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__": 35,
    "sklearn.cluster._birch.Birch.__init__": 35,
    "sklearn.impute._iterative.IterativeImputer.fit_transform": 35,
    "sklearn.metrics._classification.hamming_loss": 35,
    "sklearn.feature_selection._univariate_selection.chi2": 35,
    "sklearn.preprocessing._data.MaxAbsScaler.transform": 35,
    "sklearn.metrics.pairwise.linear_kernel": 35,
    "sklearn.decomposition._factor_analysis.FactorAnalysis.__init__": 34,
    "sklearn.ensemble._stacking.StackingClassifier.predict": 34,
    "sklearn.ensemble._voting.VotingRegressor.predict": 34,
    "sklearn.pipeline.Pipeline.get_params": 34,
    "sklearn.preprocessing._data.Binarizer.transform": 33,
    "sklearn.ensemble._bagging.BaggingClassifier.predict_proba": 33,
    "sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay.plot": 32,
    "sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay.__init__": 32,
    "sklearn.metrics.pairwise.euclidean_distances": 32,
    "sklearn.model_selection._validation.validation_curve": 32,
    "sklearn.tree._classes.ExtraTreeClassifier.__init__": 32,
    "sklearn.dummy.DummyClassifier.fit": 31,
    "sklearn.multioutput.MultiOutputClassifier.fit": 31,
    "sklearn.compose._column_transformer.ColumnTransformer.fit": 31,
    "sklearn.kernel_ridge.KernelRidge.fit": 30,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__": 30,
    "sklearn.feature_selection._rfe.RFE.predict": 29,
    "sklearn.decomposition._lda.LatentDirichletAllocation.fit": 29,
    "sklearn.ensemble._iforest.IsolationForest.fit": 28,
    "sklearn.linear_model._ransac.RANSACRegressor.__init__": 28,
    "sklearn.svm._classes.LinearSVR.fit": 28,
    "sklearn.compose._column_transformer.make_column_selector.__init__": 28,
    "sklearn.preprocessing._data.PowerTransformer.transform": 27,
    "sklearn.preprocessing._data.Binarizer.fit": 27,
    "sklearn.ensemble._iforest.IsolationForest.predict": 26,
    "sklearn.linear_model._theil_sen.TheilSenRegressor.__init__": 26,
    "sklearn.metrics._regression.median_absolute_error": 26,
    "sklearn.feature_extraction.text.HashingVectorizer.transform": 26,
    "sklearn.model_selection._search.ParameterGrid.__init__": 26,
    "sklearn.dummy.DummyRegressor.fit": 25,
    "sklearn.dummy.DummyRegressor.predict": 25,
    "sklearn.calibration.calibration_curve": 25,
    "sklearn._config.set_config": 25,
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__": 25,
    "sklearn.pipeline.FeatureUnion.get_feature_names": 25,
    "sklearn.dummy.DummyClassifier.predict": 25,
    "sklearn.inspection._permutation_importance.permutation_importance": 25,
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.__init__": 24,
    "sklearn.cluster._kmeans.KMeans.fit_transform": 24,
    "sklearn.base.ClusterMixin.fit_predict": 24,
    "sklearn.compose._target.TransformedTargetRegressor.__init__": 23,
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.predict": 23,
    "sklearn.impute._iterative.IterativeImputer.transform": 23,
    "sklearn.metrics._classification.balanced_accuracy_score": 23,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.predict_proba": 23,
    "sklearn.preprocessing._label.LabelBinarizer.inverse_transform": 23,
    "sklearn.feature_extraction._hash.FeatureHasher.__init__": 22,
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.get_feature_names": 22,
    "sklearn.metrics._regression.max_error": 22,
    "sklearn.utils.validation.check_X_y": 21,
    "sklearn.decomposition._kernel_pca.KernelPCA.fit_transform": 21,
    "sklearn.metrics.pairwise.pairwise_distances": 21,
    "sklearn.datasets._base.load_boston": 20,
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform": 20,
    "sklearn.cluster._agglomerative.AgglomerativeClustering.fit": 20,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet.__init__": 19,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet.fit": 19,
    "sklearn.linear_model._logistic.LogisticRegressionCV.score": 19,
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.__init__": 19,
    "sklearn.base.OutlierMixin.fit_predict": 19,
    "sklearn.mixture._gaussian_mixture.GaussianMixture.aic": 18,
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups": 18,
    "sklearn.cluster._agglomerative.AgglomerativeClustering.fit_predict": 18,
    "sklearn.utils.multiclass.unique_labels": 17,
    "sklearn.compose._target.TransformedTargetRegressor.predict": 17,
    "sklearn.preprocessing._data.QuantileTransformer.inverse_transform": 17,
    "sklearn.decomposition._nmf.NMF.transform": 17,
    "sklearn.impute._iterative.IterativeImputer.fit": 17,
    "sklearn.utils.multiclass.type_of_target": 17,
    "sklearn.neighbors._lof.LocalOutlierFactor.__init__": 17,
    "sklearn.decomposition._factor_analysis.FactorAnalysis.fit": 16,
    "sklearn.preprocessing._encoders.OneHotEncoder.inverse_transform": 16,
    "sklearn.datasets._svmlight_format_io.dump_svmlight_file": 16,
    "sklearn.dummy.DummyClassifier.score": 16,
    "sklearn.ensemble._stacking.StackingClassifier.predict_proba": 16,
    "sklearn.covariance._shrunk_covariance.LedoitWolf.fit": 16,
    "sklearn.feature_extraction.image.extract_patches_2d": 15,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.fit": 15,
    "sklearn.linear_model._huber.HuberRegressor.fit": 15,
    "sklearn.manifold._isomap.Isomap.__init__": 15,
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.predict": 15,
    "sklearn.impute._knn.KNNImputer.transform": 15,
    "sklearn.model_selection._split.check_cv": 15,
    "sklearn.model_selection._split.PredefinedSplit.__init__": 14,
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.fit": 14,
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.fit": 14,
    "sklearn.datasets._base.load_digits": 14,
    "sklearn.decomposition._lda.LatentDirichletAllocation.transform": 14,
    "sklearn.impute._base.MissingIndicator.__init__": 13,
    "sklearn.feature_selection._univariate_selection.f_regression": 13,
    "sklearn.gaussian_process.kernels.RBF.__init__": 13,
    "sklearn.metrics._classification.jaccard_score": 13,
    "sklearn.multiclass.OneVsOneClassifier.__init__": 13,
    "sklearn.ensemble._gb.GradientBoostingRegressor.staged_predict": 13,
    "sklearn.preprocessing._data.binarize": 12,
    "sklearn.compose._target.TransformedTargetRegressor.fit": 12,
    "sklearn.linear_model._least_angle.LassoLars.__init__": 12,
    "sklearn.linear_model._bayes.ARDRegression.__init__": 12,
    "sklearn.decomposition._nmf.NMF.fit": 12,
    "sklearn.preprocessing._discretization.KBinsDiscretizer.fit": 12,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.predict": 12,
    "sklearn.decomposition._sparse_pca.SparsePCA.__init__": 11,
    "sklearn.manifold._mds.MDS.__init__": 11,
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.__init__": 11,
    "sklearn.metrics._classification.hinge_loss": 11,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__": 11,
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.decision_function": 11,
    "sklearn.linear_model._ransac.RANSACRegressor.predict": 11,
    "sklearn.decomposition._kernel_pca.KernelPCA.transform": 11,
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence": 11,
    "sklearn.base.is_classifier": 11,
    "sklearn.feature_selection._rfe.RFE.predict_proba": 11,
    "sklearn.manifold._spectral_embedding.SpectralEmbedding.__init__": 10,
    "sklearn.feature_selection._univariate_selection.f_classif": 10,
    "sklearn.utils.validation.check_consistent_length": 10,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.predict": 10,
    "sklearn.linear_model._ransac.RANSACRegressor.fit": 10,
    "sklearn.isotonic.IsotonicRegression.__init__": 10,
    "sklearn.linear_model._glm.glm.TweedieRegressor.__init__": 10,
    "sklearn.datasets._samples_generator.make_moons": 10,
    "sklearn.cross_decomposition._pls.PLSRegression.__init__": 9,
    "sklearn.utils.class_weight.compute_sample_weight": 9,
    "sklearn.feature_selection._rfe.RFE.score": 9,
    "sklearn.mixture._gaussian_mixture.GaussianMixture.bic": 9,
    "sklearn.cluster._spectral.SpectralClustering.__init__": 9,
    "sklearn.preprocessing._data.MaxAbsScaler.fit": 9,
    "sklearn.cluster._birch.Birch.predict": 9,
    "sklearn.covariance._shrunk_covariance.LedoitWolf.__init__": 9,
    "sklearn.decomposition._incremental_pca.IncrementalPCA.__init__": 9,
    "sklearn.decomposition._incremental_pca.IncrementalPCA.transform": 9,
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.predict": 9,
    "sklearn.feature_extraction.image.PatchExtractor.__init__": 8,
    "sklearn.preprocessing._data.PowerTransformer.inverse_transform": 8,
    "sklearn.naive_bayes.ComplementNB.__init__": 8,
    "sklearn.preprocessing._data.maxabs_scale": 8,
    "sklearn.metrics._classification.brier_score_loss": 8,
    "sklearn.metrics.cluster._supervised.mutual_info_score": 8,
    "sklearn.svm._classes.OneClassSVM.__init__": 8,
    "sklearn.semi_supervised._label_propagation.LabelSpreading.__init__": 8,
    "sklearn.metrics._classification.zero_one_loss": 8,
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.fit": 8,
    "sklearn.ensemble._iforest.IsolationForest.decision_function": 8,
    "sklearn.preprocessing._data.quantile_transform": 8,
    "sklearn.metrics.pairwise.manhattan_distances": 8,
    "sklearn.preprocessing._encoders.OrdinalEncoder.inverse_transform": 8,
    "sklearn.metrics.cluster._supervised.homogeneity_score": 8,
    "sklearn.metrics.cluster._supervised.completeness_score": 8,
    "sklearn.metrics._plot.precision_recall_curve.plot_precision_recall_curve": 7,
    "sklearn.preprocessing._data.PowerTransformer.fit": 7,
    "sklearn.manifold._spectral_embedding.SpectralEmbedding.fit_transform": 7,
    "sklearn.linear_model._least_angle.Lars.__init__": 7,
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__": 7,
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.__init__": 7,
    "sklearn.multioutput.RegressorChain.fit": 7,
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.fit": 7,
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.predict": 7,
    "sklearn.feature_extraction.text.HashingVectorizer.fit_transform": 7,
    "sklearn.model_selection._split.LeaveOneGroupOut.split": 7,
    "sklearn.svm._classes.OneClassSVM.predict": 7,
    "sklearn.decomposition._fastica.FastICA.fit": 7,
    "sklearn.decomposition._truncated_svd.TruncatedSVD.inverse_transform": 7,
    "sklearn.linear_model._least_angle.LassoLarsIC.__init__": 7,
    "sklearn.ensemble._forest.RandomTreesEmbedding.transform": 7,
    "sklearn.linear_model._ridge.RidgeClassifierCV.fit": 7,
    "sklearn.datasets._base.load_diabetes": 7,
    "sklearn.decomposition._fastica.FastICA.inverse_transform": 7,
    "sklearn.preprocessing._function_transformer.FunctionTransformer.transform": 6,
    "sklearn.manifold._mds.MDS.fit_transform": 6,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.fit": 6,
    "sklearn.tree._classes.BaseDecisionTree.get_n_leaves": 6,
    "sklearn.impute._knn.KNNImputer.fit": 6,
    "sklearn.svm._classes.OneClassSVM.fit": 6,
    "sklearn.tree._export.export_text": 6,
    "sklearn.decomposition._factor_analysis.FactorAnalysis.transform": 6,
    "sklearn.metrics.cluster._supervised.adjusted_rand_score": 6,
    "sklearn.linear_model._bayes.ARDRegression.predict": 6,
    "sklearn.metrics._regression.mean_absolute_percentage_error": 6,
    "sklearn.covariance._shrunk_covariance.ShrunkCovariance.__init__": 6,
    "sklearn.naive_bayes.CategoricalNB.__init__": 6,
    "sklearn.pipeline.Pipeline.decision_function": 6,
    "sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path": 5,
    "sklearn.covariance._robust_covariance.MinCovDet.__init__": 5,
    "sklearn.feature_selection._univariate_selection.SelectFpr.__init__": 5,
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.fit_transform": 5,
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.transform": 5,
    "sklearn.tree._classes.ExtraTreeRegressor.__init__": 5,
    "sklearn.manifold._isomap.Isomap.transform": 5,
    "sklearn.cluster._spectral.SpectralClustering.fit_predict": 5,
    "sklearn.feature_selection._univariate_selection.GenericUnivariateSelect.__init__": 5,
    "sklearn.metrics.cluster._unsupervised.davies_bouldin_score": 5,
    "sklearn.utils.extmath.cartesian": 5,
    "sklearn.cluster._mean_shift.MeanShift.__init__": 5,
    "sklearn.cluster._mean_shift.MeanShift.fit": 5,
    "sklearn.cluster._agglomerative.FeatureAgglomeration.__init__": 5,
    "sklearn.linear_model._omp.OrthogonalMatchingPursuitCV.__init__": 5,
    "sklearn.isotonic.IsotonicRegression.fit": 5,
    "sklearn.linear_model._omp.OrthogonalMatchingPursuit.__init__": 5,
    "sklearn.multiclass.OneVsOneClassifier.fit": 5,
    "sklearn.metrics._scorer.get_scorer": 5,
    "sklearn.naive_bayes.CategoricalNB.fit": 5,
    "sklearn.compose._column_transformer.ColumnTransformer.get_feature_names": 5,
    "sklearn.manifold._isomap.Isomap.fit_transform": 5,
    "sklearn.metrics.pairwise.paired_distances": 5,
    "sklearn.kernel_approximation.Nystroem.__init__": 5,
    "sklearn.preprocessing._label.MultiLabelBinarizer.inverse_transform": 5,
    "sklearn.utils.metaestimators.if_delegate_has_method": 5,
    "sklearn.feature_extraction.text.HashingVectorizer.fit": 5,
    "sklearn.dummy.DummyClassifier.predict_proba": 4,
    "sklearn.datasets._samples_generator.make_blobs": 4,
    "sklearn.cluster._optics.OPTICS.__init__": 4,
    "sklearn.cluster._kmeans.k_means": 4,
    "sklearn.manifold._isomap.Isomap.fit": 4,
    "sklearn.cluster._spectral.SpectralClustering.fit": 4,
    "sklearn.ensemble._forest.RandomTreesEmbedding.fit": 4,
    "sklearn.cluster._affinity_propagation.AffinityPropagation.__init__": 4,
    "sklearn.cluster._affinity_propagation.AffinityPropagation.fit": 4,
    "sklearn.feature_extraction._hash.FeatureHasher.transform": 4,
    "sklearn.multiclass.OneVsOneClassifier.predict": 4,
    "sklearn.neighbors._lof.LocalOutlierFactor.fit": 4,
    "sklearn.datasets._base.load_files": 4,
    "sklearn.decomposition._incremental_pca.IncrementalPCA.partial_fit": 4,
    "sklearn.covariance._shrunk_covariance.ShrunkCovariance.fit": 4,
    "sklearn.kernel_approximation.Nystroem.transform": 4,
    "sklearn.multiclass.OneVsRestClassifier.decision_function": 4,
    "sklearn.neighbors._nearest_centroid.NearestCentroid.__init__": 4,
    "sklearn.datasets._base.load_wine": 4,
    "sklearn.isotonic.IsotonicRegression.transform": 4,
    "sklearn.ensemble._gb.GradientBoostingClassifier.staged_decision_function": 4,
    "sklearn.datasets._samples_generator.make_regression": 3,
    "sklearn.covariance._robust_covariance.MinCovDet.fit": 3,
    "sklearn.utils.validation.column_or_1d": 3,
    "sklearn.cluster._optics.OPTICS.fit": 3,
    "sklearn.linear_model._bayes.ARDRegression.fit": 3,
    "sklearn.cluster._mean_shift.estimate_bandwidth": 3,
    "sklearn.metrics.pairwise.paired_euclidean_distances": 3,
    "sklearn.metrics.cluster._unsupervised.silhouette_samples": 3,
    "sklearn.utils.extmath.density": 3,
    "sklearn.decomposition._incremental_pca.IncrementalPCA.fit": 3,
    "sklearn.linear_model._glm.glm.GammaRegressor.__init__": 3,
    "sklearn.datasets._openml.fetch_openml": 3,
    "sklearn.decomposition._sparse_pca.SparsePCA.transform": 3,
    "sklearn.linear_model._logistic.LogisticRegression.predict_log_proba": 3,
    "sklearn.cross_decomposition._pls.PLSSVD.__init__": 3,
    "sklearn.model_selection._split.LeaveOneGroupOut.get_n_splits": 3,
    "sklearn.preprocessing._data.RobustScaler.inverse_transform": 3,
    "sklearn.neighbors._regression.RadiusNeighborsRegressor.__init__": 3,
    "sklearn.random_projection.BaseRandomProjection.fit": 3,
    "sklearn.metrics.pairwise.pairwise_distances_argmin": 3,
    "sklearn.linear_model._least_angle.LarsCV.fit": 3,
    "sklearn.feature_selection._sequential.SequentialFeatureSelector.fit": 2,
    "sklearn.feature_selection._sequential.SequentialFeatureSelector.__init__": 2,
    "sklearn.ensemble._iforest.IsolationForest.score_samples": 2,
    "sklearn.preprocessing._data.robust_scale": 2,
    "sklearn.neighbors._kde.KernelDensity.sample": 2,
    "sklearn.cluster._kmeans.MiniBatchKMeans.partial_fit": 2,
    "sklearn.datasets._base.load_sample_image": 2,
    "sklearn.gaussian_process.kernels.WhiteKernel.__init__": 2,
    "sklearn.metrics._ranking.ndcg_score": 2,
    "sklearn.tree._classes.BaseDecisionTree.apply": 2,
    "sklearn.metrics.cluster._supervised.v_measure_score": 2,
    "sklearn.compose._column_transformer.ColumnTransformer.set_params": 2,
    "sklearn.metrics._plot.roc_curve.RocCurveDisplay.plot": 2,
    "sklearn.metrics._plot.roc_curve.RocCurveDisplay.__init__": 2,
    "sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay.plot": 2,
    "sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay.__init__": 2,
    "sklearn.naive_bayes.GaussianNB.partial_fit": 2,
    "sklearn.model_selection._split.BaseCrossValidator.split": 2,
    "sklearn.semi_supervised._label_propagation.LabelPropagation.__init__": 2,
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.staged_predict": 2,
    "sklearn.ensemble._gb.GradientBoostingClassifier.staged_predict": 2,
    "sklearn.cluster._agglomerative.FeatureAgglomeration.fit": 2,
    "sklearn.gaussian_process.kernels.DotProduct.__init__": 2,
    "sklearn.neighbors._graph.kneighbors_graph": 2,
    "sklearn.cluster._affinity_propagation.AffinityPropagation.predict": 2,
    "sklearn.impute._base.MissingIndicator.fit": 2,
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.mahalanobis": 2,
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.__init__": 2,
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.predict": 2,
    "sklearn.ensemble._gb.GradientBoostingClassifier.staged_predict_proba": 2,
    "sklearn.ensemble._gb.GradientBoostingClassifier.predict_log_proba": 2,
    "sklearn.kernel_approximation.RBFSampler.__init__": 2,
    "sklearn.isotonic.IsotonicRegression.predict": 2,
    "sklearn.datasets._samples_generator.make_circles": 2,
    "sklearn.manifold._mds.smacof": 2,
    "sklearn.neural_network._rbm.BernoulliRBM.__init__": 2,
    "sklearn.utils.safe_sqr": 2,
    "sklearn.utils.safe_mask": 2,
    "sklearn.preprocessing._data.power_transform": 2,
    "sklearn.cluster._kmeans.KMeans.score": 2,
    "sklearn.datasets._base.load_breast_cancer": 2,
    "sklearn.preprocessing._data.StandardScaler.partial_fit": 2,
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__": 2,
    "sklearn.metrics.pairwise.rbf_kernel": 2,
    "sklearn.metrics.pairwise.polynomial_kernel": 2,
    "sklearn.decomposition._lda.LatentDirichletAllocation.perplexity": 2,
    "sklearn.decomposition._lda.LatentDirichletAllocation.score": 2,
    "sklearn.metrics._regression.mean_tweedie_deviance": 2,
    "sklearn.linear_model._least_angle.LassoLarsIC.fit": 2,
    "sklearn.linear_model._least_angle.Lars.fit": 2,
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__": 2,
    "sklearn.gaussian_process.kernels.ConstantKernel.__init__": 2,
    "sklearn.datasets._svmlight_format_io.load_svmlight_file": 2,
    "sklearn.multioutput.MultiOutputClassifier.score": 2,
    "sklearn.metrics.cluster._supervised.normalized_mutual_info_score": 2,
    "sklearn.dummy.DummyRegressor.score": 1,
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.log_marginal_likelihood": 1,
    "sklearn.covariance._shrunk_covariance.ledoit_wolf": 1,
    "sklearn.svm._classes.OneClassSVM.decision_function": 1,
    "sklearn.cluster._dbscan.dbscan": 1,
    "sklearn.cluster._affinity_propagation.affinity_propagation": 1,
    "sklearn.gaussian_process.kernels.Matern.__init__": 1,
    "sklearn.gaussian_process.kernels.RationalQuadratic.__init__": 1,
    "sklearn.utils.extmath.weighted_mode": 1,
    "sklearn.linear_model._omp.OrthogonalMatchingPursuit.fit": 1,
    "sklearn.impute._base.MissingIndicator.fit_transform": 1,
    "sklearn.impute._base.MissingIndicator.transform": 1,
    "sklearn.compose._column_transformer.ColumnTransformer.get_params": 1,
    "sklearn.linear_model._glm.glm.PoissonRegressor.__init__": 1,
    "sklearn.datasets._samples_generator.make_multilabel_classification": 1,
    "sklearn.model_selection._split.LeaveOneOut.get_n_splits": 1,
    "sklearn.utils.estimator_checks.check_estimator": 1,
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.fit": 1,
    "sklearn.metrics.pairwise.pairwise_distances_argmin_min": 1,
    "sklearn.cross_decomposition._pls.CCA.__init__": 1,
    "sklearn.utils.all_estimators": 1,
    "sklearn.linear_model._theil_sen.TheilSenRegressor.fit": 1,
    "sklearn.linear_model._ransac.RANSACRegressor.score": 1,
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.fit": 1,
    "sklearn.kernel_approximation.RBFSampler.transform": 1,
    "sklearn.metrics.pairwise.cosine_distances": 1,
    "sklearn.inspection._partial_dependence.partial_dependence": 1,
    "sklearn.feature_selection._univariate_selection.SelectFdr.__init__": 1,
    "sklearn.feature_selection._univariate_selection.SelectFwe.__init__": 1,
    "sklearn.decomposition._kernel_pca.KernelPCA.fit": 1,
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.__init__": 1,
    "sklearn.preprocessing._data.KernelCenterer.__init__": 1,
    "sklearn.preprocessing._data.KernelCenterer.transform": 1,
    "sklearn.neighbors._nearest_centroid.NearestCentroid.fit": 1,
    "sklearn.neighbors._nearest_centroid.NearestCentroid.predict": 1,
    "sklearn.model_selection._split.PredefinedSplit.split": 1,
    "sklearn.model_selection._split.PredefinedSplit.get_n_splits": 1,
    "sklearn.neighbors._regression.RadiusNeighborsRegressor.fit": 1,
    "sklearn.neighbors._regression.RadiusNeighborsRegressor.predict": 1,
    "sklearn.feature_extraction.text.CountVectorizer.inverse_transform": 1,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__": 1,
    "sklearn.metrics.pairwise.sigmoid_kernel": 1,
    "sklearn.semi_supervised._label_propagation.LabelPropagation.fit": 1,
    "sklearn.linear_model._least_angle.LarsCV.__init__": 1,
    "sklearn.metrics.pairwise.pairwise_distances_chunked": 1,
    "sklearn.neural_network._rbm.BernoulliRBM.fit": 1,
    "sklearn.neural_network._rbm.BernoulliRBM.score_samples": 1,
    "sklearn.preprocessing._data.MinMaxScaler.partial_fit": 1,
    "sklearn.metrics.pairwise.pairwise_kernels": 1,
    "sklearn.neighbors._nca.NeighborhoodComponentsAnalysis.__init__": 1,
    "sklearn.multiclass.OneVsOneClassifier.decision_function": 1,
    "sklearn.metrics.cluster._supervised.adjusted_mutual_info_score": 1,
    "sklearn.preprocessing._data.MaxAbsScaler.inverse_transform": 1,
    "sklearn.cluster._mean_shift.MeanShift.predict": 1,
    "sklearn.__check_build.raise_build_error": 0,
    "sklearn._build_utils.openmp_helpers.check_openmp_support": 0,
    "sklearn._build_utils.pre_build_helpers.basic_check_build": 0,
    "sklearn._config.config_context": 0,
    "sklearn._config.get_config": 0,
    "sklearn.base.BaseEstimator.__getstate__": 0,
    "sklearn.base.BaseEstimator.__repr__": 0,
    "sklearn.base.BaseEstimator.__setstate__": 0,
    "sklearn.base.BiclusterMixin.biclusters_": 0,
    "sklearn.base.BiclusterMixin.get_indices": 0,
    "sklearn.base.BiclusterMixin.get_shape": 0,
    "sklearn.base.BiclusterMixin.get_submatrix": 0,
    "sklearn.base.DensityMixin.score": 0,
    "sklearn.base.is_outlier_detector": 0,
    "sklearn.base.is_regressor": 0,
    "sklearn.cluster._affinity_propagation.AffinityPropagation.fit_predict": 0,
    "sklearn.cluster._agglomerative.FeatureAgglomeration.fit_predict": 0,
    "sklearn.cluster._agglomerative.linkage_tree": 0,
    "sklearn.cluster._agglomerative.ward_tree": 0,
    "sklearn.cluster._bicluster.SpectralBiclustering.__init__": 0,
    "sklearn.cluster._bicluster.SpectralCoclustering.__init__": 0,
    "sklearn.cluster._birch.Birch.partial_fit": 0,
    "sklearn.cluster._birch.Birch.transform": 0,
    "sklearn.cluster._kmeans.MiniBatchKMeans.counts_": 0,
    "sklearn.cluster._kmeans.MiniBatchKMeans.init_size_": 0,
    "sklearn.cluster._kmeans.MiniBatchKMeans.random_state_": 0,
    "sklearn.cluster._kmeans.kmeans_plusplus": 0,
    "sklearn.cluster._mean_shift.get_bin_seeds": 0,
    "sklearn.cluster._mean_shift.mean_shift": 0,
    "sklearn.cluster._optics.cluster_optics_dbscan": 0,
    "sklearn.cluster._optics.cluster_optics_xi": 0,
    "sklearn.cluster._optics.compute_optics_graph": 0,
    "sklearn.cluster._spectral.spectral_clustering": 0,
    "sklearn.cluster.setup.configuration": 0,
    "sklearn.compose._column_transformer.ColumnTransformer.named_transformers_": 0,
    "sklearn.compose._column_transformer.make_column_selector.__call__": 0,
    "sklearn.compose._target.TransformedTargetRegressor.n_features_in_": 0,
    "sklearn.conftest.pyplot": 0,
    "sklearn.conftest.pytest_collection_modifyitems": 0,
    "sklearn.conftest.pytest_runtest_setup": 0,
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.score": 0,
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.score_samples": 0,
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.error_norm": 0,
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.get_precision": 0,
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.score": 0,
    "sklearn.covariance._empirical_covariance.empirical_covariance": 0,
    "sklearn.covariance._empirical_covariance.log_likelihood": 0,
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.cv_alphas_": 0,
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.fit": 0,
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.grid_scores_": 0,
    "sklearn.covariance._graph_lasso.graphical_lasso": 0,
    "sklearn.covariance._robust_covariance.MinCovDet.correct_covariance": 0,
    "sklearn.covariance._robust_covariance.MinCovDet.reweight_covariance": 0,
    "sklearn.covariance._robust_covariance.fast_mcd": 0,
    "sklearn.covariance._shrunk_covariance.ledoit_wolf_shrinkage": 0,
    "sklearn.covariance._shrunk_covariance.oas": 0,
    "sklearn.covariance._shrunk_covariance.shrunk_covariance": 0,
    "sklearn.cross_decomposition._pls.PLSCanonical.__init__": 0,
    "sklearn.cross_decomposition._pls.PLSSVD.fit": 0,
    "sklearn.cross_decomposition._pls.PLSSVD.fit_transform": 0,
    "sklearn.cross_decomposition._pls.PLSSVD.transform": 0,
    "sklearn.cross_decomposition._pls.PLSSVD.x_mean_": 0,
    "sklearn.cross_decomposition._pls.PLSSVD.x_scores_": 0,
    "sklearn.cross_decomposition._pls.PLSSVD.x_std_": 0,
    "sklearn.cross_decomposition._pls.PLSSVD.y_mean_": 0,
    "sklearn.cross_decomposition._pls.PLSSVD.y_scores_": 0,
    "sklearn.cross_decomposition._pls.PLSSVD.y_std_": 0,
    "sklearn.datasets._base.clear_data_home": 0,
    "sklearn.datasets._base.get_data_home": 0,
    "sklearn.datasets._base.load_linnerud": 0,
    "sklearn.datasets._base.load_sample_images": 0,
    "sklearn.datasets._california_housing.fetch_california_housing": 0,
    "sklearn.datasets._covtype.fetch_covtype": 0,
    "sklearn.datasets._kddcup99.fetch_kddcup99": 0,
    "sklearn.datasets._lfw.fetch_lfw_pairs": 0,
    "sklearn.datasets._lfw.fetch_lfw_people": 0,
    "sklearn.datasets._olivetti_faces.fetch_olivetti_faces": 0,
    "sklearn.datasets._rcv1.fetch_rcv1": 0,
    "sklearn.datasets._samples_generator.make_biclusters": 0,
    "sklearn.datasets._samples_generator.make_checkerboard": 0,
    "sklearn.datasets._samples_generator.make_friedman1": 0,
    "sklearn.datasets._samples_generator.make_friedman2": 0,
    "sklearn.datasets._samples_generator.make_friedman3": 0,
    "sklearn.datasets._samples_generator.make_gaussian_quantiles": 0,
    "sklearn.datasets._samples_generator.make_hastie_10_2": 0,
    "sklearn.datasets._samples_generator.make_low_rank_matrix": 0,
    "sklearn.datasets._samples_generator.make_multilabel_classification.sample_example": 0,
    "sklearn.datasets._samples_generator.make_s_curve": 0,
    "sklearn.datasets._samples_generator.make_sparse_coded_signal": 0,
    "sklearn.datasets._samples_generator.make_sparse_spd_matrix": 0,
    "sklearn.datasets._samples_generator.make_sparse_uncorrelated": 0,
    "sklearn.datasets._samples_generator.make_spd_matrix": 0,
    "sklearn.datasets._samples_generator.make_swiss_roll": 0,
    "sklearn.datasets._species_distributions.fetch_species_distributions": 0,
    "sklearn.datasets._svmlight_format_io.load_svmlight_files": 0,
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups_vectorized": 0,
    "sklearn.datasets.setup.configuration": 0,
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__": 0,
    "sklearn.decomposition._dict_learning.DictionaryLearning.fit": 0,
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.fit": 0,
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.partial_fit": 0,
    "sklearn.decomposition._dict_learning.SparseCoder.__init__": 0,
    "sklearn.decomposition._dict_learning.SparseCoder.components_": 0,
    "sklearn.decomposition._dict_learning.SparseCoder.fit": 0,
    "sklearn.decomposition._dict_learning.SparseCoder.n_components_": 0,
    "sklearn.decomposition._dict_learning.SparseCoder.n_features_in_": 0,
    "sklearn.decomposition._dict_learning.SparseCoder.transform": 0,
    "sklearn.decomposition._dict_learning.dict_learning": 0,
    "sklearn.decomposition._dict_learning.dict_learning_online": 0,
    "sklearn.decomposition._dict_learning.sparse_encode": 0,
    "sklearn.decomposition._factor_analysis.FactorAnalysis.get_covariance": 0,
    "sklearn.decomposition._factor_analysis.FactorAnalysis.get_precision": 0,
    "sklearn.decomposition._factor_analysis.FactorAnalysis.score": 0,
    "sklearn.decomposition._factor_analysis.FactorAnalysis.score_samples": 0,
    "sklearn.decomposition._fastica.fastica": 0,
    "sklearn.decomposition._kernel_pca.KernelPCA.inverse_transform": 0,
    "sklearn.decomposition._lda.LatentDirichletAllocation.partial_fit": 0,
    "sklearn.decomposition._nmf.NMF.inverse_transform": 0,
    "sklearn.decomposition._nmf.non_negative_factorization": 0,
    "sklearn.decomposition._pca.PCA.score": 0,
    "sklearn.decomposition._pca.PCA.score_samples": 0,
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.__init__": 0,
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.fit": 0,
    "sklearn.decomposition._sparse_pca.SparsePCA.fit": 0,
    "sklearn.decomposition.setup.configuration": 0,
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.decision_function": 0,
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict_log_proba": 0,
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.decision_function": 0,
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.predict_log_proba": 0,
    "sklearn.dummy.DummyClassifier.predict_log_proba": 0,
    "sklearn.ensemble._bagging.BaggingClassifier.decision_function": 0,
    "sklearn.ensemble._bagging.BaggingClassifier.predict_log_proba": 0,
    "sklearn.ensemble._base.BaseEnsemble.__getitem__": 0,
    "sklearn.ensemble._base.BaseEnsemble.__init__": 0,
    "sklearn.ensemble._base.BaseEnsemble.__iter__": 0,
    "sklearn.ensemble._base.BaseEnsemble.__len__": 0,
    "sklearn.ensemble._forest.RandomTreesEmbedding.fit_transform": 0,
    "sklearn.ensemble._gb.GradientBoostingClassifier.decision_function": 0,
    "sklearn.ensemble._gb.GradientBoostingRegressor.apply": 0,
    "sklearn.ensemble._gb.GradientBoostingRegressor.n_classes_": 0,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.decision_function": 0,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.staged_decision_function": 0,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.staged_predict": 0,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.staged_predict_proba": 0,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.staged_predict": 0,
    "sklearn.ensemble._stacking.StackingClassifier.decision_function": 0,
    "sklearn.ensemble._stacking.StackingClassifier.transform": 0,
    "sklearn.ensemble._stacking.StackingRegressor.transform": 0,
    "sklearn.ensemble._voting.VotingClassifier.predict_proba": 0,
    "sklearn.ensemble._voting.VotingClassifier.transform": 0,
    "sklearn.ensemble._voting.VotingRegressor.transform": 0,
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.decision_function": 0,
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.predict_log_proba": 0,
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.staged_decision_function": 0,
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.staged_predict_proba": 0,
    "sklearn.ensemble._weight_boosting.AdaBoostRegressor.staged_predict": 0,
    "sklearn.ensemble.setup.configuration": 0,
    "sklearn.externals.conftest.pytest_ignore_collect": 0,
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.inverse_transform": 0,
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.restrict": 0,
    "sklearn.feature_extraction._hash.FeatureHasher.fit": 0,
    "sklearn.feature_extraction.image.PatchExtractor.fit": 0,
    "sklearn.feature_extraction.image.PatchExtractor.transform": 0,
    "sklearn.feature_extraction.image.grid_to_graph": 0,
    "sklearn.feature_extraction.image.img_to_graph": 0,
    "sklearn.feature_extraction.image.reconstruct_from_patches_2d": 0,
    "sklearn.feature_extraction.setup.configuration": 0,
    "sklearn.feature_extraction.text.HashingVectorizer.partial_fit": 0,
    "sklearn.feature_extraction.text.TfidfTransformer.idf_": 0,
    "sklearn.feature_extraction.text.TfidfVectorizer.idf_": 0,
    "sklearn.feature_extraction.text.TfidfVectorizer.norm": 0,
    "sklearn.feature_extraction.text.TfidfVectorizer.smooth_idf": 0,
    "sklearn.feature_extraction.text.TfidfVectorizer.sublinear_tf": 0,
    "sklearn.feature_extraction.text.TfidfVectorizer.use_idf": 0,
    "sklearn.feature_extraction.text.strip_accents_ascii": 0,
    "sklearn.feature_extraction.text.strip_accents_unicode": 0,
    "sklearn.feature_extraction.text.strip_tags": 0,
    "sklearn.feature_selection._from_model.SelectFromModel.n_features_in_": 0,
    "sklearn.feature_selection._from_model.SelectFromModel.partial_fit": 0,
    "sklearn.feature_selection._from_model.SelectFromModel.threshold_": 0,
    "sklearn.feature_selection._rfe.RFE.classes_": 0,
    "sklearn.feature_selection._rfe.RFE.decision_function": 0,
    "sklearn.feature_selection._rfe.RFE.predict_log_proba": 0,
    "sklearn.feature_selection._univariate_selection.f_oneway": 0,
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.kernel_": 0,
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.log_marginal_likelihood": 0,
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.predict_proba": 0,
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.sample_y": 0,
    "sklearn.gaussian_process.kernels.CompoundKernel.__call__": 0,
    "sklearn.gaussian_process.kernels.CompoundKernel.__eq__": 0,
    "sklearn.gaussian_process.kernels.CompoundKernel.__init__": 0,
    "sklearn.gaussian_process.kernels.CompoundKernel.bounds": 0,
    "sklearn.gaussian_process.kernels.CompoundKernel.diag": 0,
    "sklearn.gaussian_process.kernels.CompoundKernel.get_params": 0,
    "sklearn.gaussian_process.kernels.CompoundKernel.is_stationary": 0,
    "sklearn.gaussian_process.kernels.CompoundKernel.requires_vector_input": 0,
    "sklearn.gaussian_process.kernels.CompoundKernel.theta": 0,
    "sklearn.gaussian_process.kernels.ConstantKernel.__call__": 0,
    "sklearn.gaussian_process.kernels.ConstantKernel.__repr__": 0,
    "sklearn.gaussian_process.kernels.ConstantKernel.diag": 0,
    "sklearn.gaussian_process.kernels.ConstantKernel.hyperparameter_constant_value": 0,
    "sklearn.gaussian_process.kernels.DotProduct.__call__": 0,
    "sklearn.gaussian_process.kernels.DotProduct.__repr__": 0,
    "sklearn.gaussian_process.kernels.DotProduct.diag": 0,
    "sklearn.gaussian_process.kernels.DotProduct.hyperparameter_sigma_0": 0,
    "sklearn.gaussian_process.kernels.DotProduct.is_stationary": 0,
    "sklearn.gaussian_process.kernels.ExpSineSquared.__call__": 0,
    "sklearn.gaussian_process.kernels.ExpSineSquared.__init__": 0,
    "sklearn.gaussian_process.kernels.ExpSineSquared.__repr__": 0,
    "sklearn.gaussian_process.kernels.ExpSineSquared.hyperparameter_length_scale": 0,
    "sklearn.gaussian_process.kernels.ExpSineSquared.hyperparameter_periodicity": 0,
    "sklearn.gaussian_process.kernels.Exponentiation.__call__": 0,
    "sklearn.gaussian_process.kernels.Exponentiation.__eq__": 0,
    "sklearn.gaussian_process.kernels.Exponentiation.__init__": 0,
    "sklearn.gaussian_process.kernels.Exponentiation.__repr__": 0,
    "sklearn.gaussian_process.kernels.Exponentiation.bounds": 0,
    "sklearn.gaussian_process.kernels.Exponentiation.diag": 0,
    "sklearn.gaussian_process.kernels.Exponentiation.get_params": 0,
    "sklearn.gaussian_process.kernels.Exponentiation.hyperparameters": 0,
    "sklearn.gaussian_process.kernels.Exponentiation.is_stationary": 0,
    "sklearn.gaussian_process.kernels.Exponentiation.requires_vector_input": 0,
    "sklearn.gaussian_process.kernels.Exponentiation.theta": 0,
    "sklearn.gaussian_process.kernels.GenericKernelMixin.requires_vector_input": 0,
    "sklearn.gaussian_process.kernels.Hyperparameter.__eq__": 0,
    "sklearn.gaussian_process.kernels.Hyperparameter.__new__": 0,
    "sklearn.gaussian_process.kernels.Kernel.__add__": 0,
    "sklearn.gaussian_process.kernels.Kernel.__call__": 0,
    "sklearn.gaussian_process.kernels.Kernel.__eq__": 0,
    "sklearn.gaussian_process.kernels.Kernel.__mul__": 0,
    "sklearn.gaussian_process.kernels.Kernel.__pow__": 0,
    "sklearn.gaussian_process.kernels.Kernel.__radd__": 0,
    "sklearn.gaussian_process.kernels.Kernel.__repr__": 0,
    "sklearn.gaussian_process.kernels.Kernel.__rmul__": 0,
    "sklearn.gaussian_process.kernels.Kernel.bounds": 0,
    "sklearn.gaussian_process.kernels.Kernel.clone_with_theta": 0,
    "sklearn.gaussian_process.kernels.Kernel.diag": 0,
    "sklearn.gaussian_process.kernels.Kernel.get_params": 0,
    "sklearn.gaussian_process.kernels.Kernel.hyperparameters": 0,
    "sklearn.gaussian_process.kernels.Kernel.is_stationary": 0,
    "sklearn.gaussian_process.kernels.Kernel.n_dims": 0,
    "sklearn.gaussian_process.kernels.Kernel.requires_vector_input": 0,
    "sklearn.gaussian_process.kernels.Kernel.set_params": 0,
    "sklearn.gaussian_process.kernels.Kernel.theta": 0,
    "sklearn.gaussian_process.kernels.KernelOperator.__eq__": 0,
    "sklearn.gaussian_process.kernels.KernelOperator.__init__": 0,
    "sklearn.gaussian_process.kernels.KernelOperator.bounds": 0,
    "sklearn.gaussian_process.kernels.KernelOperator.get_params": 0,
    "sklearn.gaussian_process.kernels.KernelOperator.hyperparameters": 0,
    "sklearn.gaussian_process.kernels.KernelOperator.is_stationary": 0,
    "sklearn.gaussian_process.kernels.KernelOperator.requires_vector_input": 0,
    "sklearn.gaussian_process.kernels.KernelOperator.theta": 0,
    "sklearn.gaussian_process.kernels.Matern.__call__": 0,
    "sklearn.gaussian_process.kernels.Matern.__repr__": 0,
    "sklearn.gaussian_process.kernels.NormalizedKernelMixin.diag": 0,
    "sklearn.gaussian_process.kernels.PairwiseKernel.__call__": 0,
    "sklearn.gaussian_process.kernels.PairwiseKernel.__init__": 0,
    "sklearn.gaussian_process.kernels.PairwiseKernel.__repr__": 0,
    "sklearn.gaussian_process.kernels.PairwiseKernel.diag": 0,
    "sklearn.gaussian_process.kernels.PairwiseKernel.hyperparameter_gamma": 0,
    "sklearn.gaussian_process.kernels.PairwiseKernel.is_stationary": 0,
    "sklearn.gaussian_process.kernels.Product.__call__": 0,
    "sklearn.gaussian_process.kernels.Product.__repr__": 0,
    "sklearn.gaussian_process.kernels.Product.diag": 0,
    "sklearn.gaussian_process.kernels.RBF.__call__": 0,
    "sklearn.gaussian_process.kernels.RBF.__repr__": 0,
    "sklearn.gaussian_process.kernels.RBF.anisotropic": 0,
    "sklearn.gaussian_process.kernels.RBF.hyperparameter_length_scale": 0,
    "sklearn.gaussian_process.kernels.RationalQuadratic.__call__": 0,
    "sklearn.gaussian_process.kernels.RationalQuadratic.__repr__": 0,
    "sklearn.gaussian_process.kernels.RationalQuadratic.hyperparameter_alpha": 0,
    "sklearn.gaussian_process.kernels.RationalQuadratic.hyperparameter_length_scale": 0,
    "sklearn.gaussian_process.kernels.StationaryKernelMixin.is_stationary": 0,
    "sklearn.gaussian_process.kernels.Sum.__call__": 0,
    "sklearn.gaussian_process.kernels.Sum.__repr__": 0,
    "sklearn.gaussian_process.kernels.Sum.diag": 0,
    "sklearn.gaussian_process.kernels.WhiteKernel.__call__": 0,
    "sklearn.gaussian_process.kernels.WhiteKernel.__repr__": 0,
    "sklearn.gaussian_process.kernels.WhiteKernel.diag": 0,
    "sklearn.gaussian_process.kernels.WhiteKernel.hyperparameter_noise_level": 0,
    "sklearn.impute._base.SimpleImputer.inverse_transform": 0,
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.__init__": 0,
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.plot": 0,
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.convert_feature": 0,
    "sklearn.inspection.setup.configuration": 0,
    "sklearn.isotonic.IsotonicRegression.__getstate__": 0,
    "sklearn.isotonic.IsotonicRegression.__setstate__": 0,
    "sklearn.isotonic.check_increasing": 0,
    "sklearn.isotonic.isotonic_regression": 0,
    "sklearn.kernel_approximation.AdditiveChi2Sampler.__init__": 0,
    "sklearn.kernel_approximation.AdditiveChi2Sampler.fit": 0,
    "sklearn.kernel_approximation.AdditiveChi2Sampler.transform": 0,
    "sklearn.kernel_approximation.Nystroem.fit": 0,
    "sklearn.kernel_approximation.PolynomialCountSketch.__init__": 0,
    "sklearn.kernel_approximation.PolynomialCountSketch.fit": 0,
    "sklearn.kernel_approximation.PolynomialCountSketch.transform": 0,
    "sklearn.kernel_approximation.RBFSampler.fit": 0,
    "sklearn.kernel_approximation.SkewedChi2Sampler.__init__": 0,
    "sklearn.kernel_approximation.SkewedChi2Sampler.fit": 0,
    "sklearn.kernel_approximation.SkewedChi2Sampler.transform": 0,
    "sklearn.linear_model._coordinate_descent.ElasticNet.sparse_coef_": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskLasso.__init__": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__": 0,
    "sklearn.linear_model._coordinate_descent.enet_path": 0,
    "sklearn.linear_model._coordinate_descent.lasso_path": 0,
    "sklearn.linear_model._glm.glm.GammaRegressor.family": 0,
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.__init__": 0,
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.fit": 0,
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.predict": 0,
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.score": 0,
    "sklearn.linear_model._glm.glm.PoissonRegressor.family": 0,
    "sklearn.linear_model._glm.glm.TweedieRegressor.family": 0,
    "sklearn.linear_model._least_angle.lars_path": 0,
    "sklearn.linear_model._least_angle.lars_path_gram": 0,
    "sklearn.linear_model._omp.OrthogonalMatchingPursuitCV.fit": 0,
    "sklearn.linear_model._omp.orthogonal_mp": 0,
    "sklearn.linear_model._omp.orthogonal_mp_gram": 0,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.partial_fit": 0,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.partial_fit": 0,
    "sklearn.linear_model._ridge.RidgeClassifier.classes_": 0,
    "sklearn.linear_model._ridge.RidgeClassifierCV.classes_": 0,
    "sklearn.linear_model._ridge.ridge_regression": 0,
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.predict_log_proba": 0,
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.predict_proba": 0,
    "sklearn.linear_model.setup.configuration": 0,
    "sklearn.manifold._isomap.Isomap.reconstruction_error": 0,
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.fit": 0,
    "sklearn.manifold._locally_linear.locally_linear_embedding": 0,
    "sklearn.manifold._mds.MDS.fit": 0,
    "sklearn.manifold._spectral_embedding.SpectralEmbedding.fit": 0,
    "sklearn.manifold._spectral_embedding.spectral_embedding": 0,
    "sklearn.manifold._t_sne.TSNE.fit": 0,
    "sklearn.manifold._t_sne.trustworthiness": 0,
    "sklearn.manifold.setup.configuration": 0,
    "sklearn.metrics._plot.det_curve.DetCurveDisplay.__init__": 0,
    "sklearn.metrics._plot.det_curve.DetCurveDisplay.plot": 0,
    "sklearn.metrics._plot.det_curve.plot_det_curve": 0,
    "sklearn.metrics._ranking.coverage_error": 0,
    "sklearn.metrics._ranking.dcg_score": 0,
    "sklearn.metrics._ranking.det_curve": 0,
    "sklearn.metrics._ranking.label_ranking_loss": 0,
    "sklearn.metrics._ranking.top_k_accuracy_score": 0,
    "sklearn.metrics._regression.mean_gamma_deviance": 0,
    "sklearn.metrics._regression.mean_poisson_deviance": 0,
    "sklearn.metrics._scorer.check_scoring": 0,
    "sklearn.metrics.cluster._bicluster.consensus_score": 0,
    "sklearn.metrics.cluster._supervised.contingency_matrix": 0,
    "sklearn.metrics.cluster._supervised.entropy": 0,
    "sklearn.metrics.cluster._supervised.fowlkes_mallows_score": 0,
    "sklearn.metrics.cluster._supervised.homogeneity_completeness_v_measure": 0,
    "sklearn.metrics.cluster._supervised.pair_confusion_matrix": 0,
    "sklearn.metrics.cluster._supervised.rand_score": 0,
    "sklearn.metrics.cluster._unsupervised.calinski_harabasz_score": 0,
    "sklearn.metrics.cluster.setup.configuration": 0,
    "sklearn.metrics.pairwise.additive_chi2_kernel": 0,
    "sklearn.metrics.pairwise.check_paired_arrays": 0,
    "sklearn.metrics.pairwise.check_pairwise_arrays": 0,
    "sklearn.metrics.pairwise.chi2_kernel": 0,
    "sklearn.metrics.pairwise.distance_metrics": 0,
    "sklearn.metrics.pairwise.haversine_distances": 0,
    "sklearn.metrics.pairwise.kernel_metrics": 0,
    "sklearn.metrics.pairwise.laplacian_kernel": 0,
    "sklearn.metrics.pairwise.nan_euclidean_distances": 0,
    "sklearn.metrics.pairwise.paired_cosine_distances": 0,
    "sklearn.metrics.pairwise.paired_manhattan_distances": 0,
    "sklearn.metrics.setup.configuration": 0,
    "sklearn.model_selection._search.ParameterGrid.__getitem__": 0,
    "sklearn.model_selection._search.ParameterGrid.__iter__": 0,
    "sklearn.model_selection._search.ParameterGrid.__len__": 0,
    "sklearn.model_selection._search.ParameterSampler.__init__": 0,
    "sklearn.model_selection._search.ParameterSampler.__iter__": 0,
    "sklearn.model_selection._search.ParameterSampler.__len__": 0,
    "sklearn.model_selection._search.fit_grid_point": 0,
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__": 0,
    "sklearn.model_selection._split.BaseCrossValidator.__repr__": 0,
    "sklearn.model_selection._split.BaseCrossValidator.get_n_splits": 0,
    "sklearn.model_selection._split.LeavePGroupsOut.__init__": 0,
    "sklearn.model_selection._split.LeavePGroupsOut.get_n_splits": 0,
    "sklearn.model_selection._split.LeavePGroupsOut.split": 0,
    "sklearn.model_selection._split.LeavePOut.__init__": 0,
    "sklearn.model_selection._split.LeavePOut.get_n_splits": 0,
    "sklearn.model_selection._validation.permutation_test_score": 0,
    "sklearn.multiclass.OneVsOneClassifier.n_classes_": 0,
    "sklearn.multiclass.OneVsOneClassifier.partial_fit": 0,
    "sklearn.multiclass.OneVsRestClassifier.coef_": 0,
    "sklearn.multiclass.OneVsRestClassifier.intercept_": 0,
    "sklearn.multiclass.OneVsRestClassifier.multilabel_": 0,
    "sklearn.multiclass.OneVsRestClassifier.n_classes_": 0,
    "sklearn.multiclass.OneVsRestClassifier.n_features_in_": 0,
    "sklearn.multiclass.OneVsRestClassifier.partial_fit": 0,
    "sklearn.multiclass.OutputCodeClassifier.__init__": 0,
    "sklearn.multiclass.OutputCodeClassifier.fit": 0,
    "sklearn.multiclass.OutputCodeClassifier.predict": 0,
    "sklearn.multioutput.ClassifierChain.decision_function": 0,
    "sklearn.multioutput.ClassifierChain.fit": 0,
    "sklearn.multioutput.ClassifierChain.predict_proba": 0,
    "sklearn.multioutput.MultiOutputClassifier.predict_proba": 0,
    "sklearn.multioutput.MultiOutputRegressor.partial_fit": 0,
    "sklearn.naive_bayes.CategoricalNB.partial_fit": 0,
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.predict_proba": 0,
    "sklearn.neighbors._graph.KNeighborsTransformer.__init__": 0,
    "sklearn.neighbors._graph.KNeighborsTransformer.fit": 0,
    "sklearn.neighbors._graph.KNeighborsTransformer.fit_transform": 0,
    "sklearn.neighbors._graph.KNeighborsTransformer.transform": 0,
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.__init__": 0,
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.fit": 0,
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.fit_transform": 0,
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.transform": 0,
    "sklearn.neighbors._graph.radius_neighbors_graph": 0,
    "sklearn.neighbors._kde.KernelDensity.score": 0,
    "sklearn.neighbors._lof.LocalOutlierFactor.decision_function": 0,
    "sklearn.neighbors._lof.LocalOutlierFactor.fit_predict": 0,
    "sklearn.neighbors._lof.LocalOutlierFactor.predict": 0,
    "sklearn.neighbors._lof.LocalOutlierFactor.score_samples": 0,
    "sklearn.neighbors._nca.NeighborhoodComponentsAnalysis.fit": 0,
    "sklearn.neighbors._nca.NeighborhoodComponentsAnalysis.transform": 0,
    "sklearn.neighbors.setup.configuration": 0,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.partial_fit": 0,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.predict_log_proba": 0,
    "sklearn.neural_network._rbm.BernoulliRBM.gibbs": 0,
    "sklearn.neural_network._rbm.BernoulliRBM.partial_fit": 0,
    "sklearn.neural_network._rbm.BernoulliRBM.transform": 0,
    "sklearn.pipeline.FeatureUnion.get_params": 0,
    "sklearn.pipeline.FeatureUnion.n_features_in_": 0,
    "sklearn.pipeline.FeatureUnion.set_params": 0,
    "sklearn.pipeline.Pipeline.__getitem__": 0,
    "sklearn.pipeline.Pipeline.__len__": 0,
    "sklearn.pipeline.Pipeline.classes_": 0,
    "sklearn.pipeline.Pipeline.fit_predict": 0,
    "sklearn.pipeline.Pipeline.inverse_transform": 0,
    "sklearn.pipeline.Pipeline.n_features_in_": 0,
    "sklearn.pipeline.Pipeline.named_steps": 0,
    "sklearn.pipeline.Pipeline.predict_log_proba": 0,
    "sklearn.pipeline.Pipeline.score_samples": 0,
    "sklearn.pipeline.Pipeline.transform": 0,
    "sklearn.preprocessing._data.KernelCenterer.fit": 0,
    "sklearn.preprocessing._data.MaxAbsScaler.partial_fit": 0,
    "sklearn.preprocessing._data.PolynomialFeatures.powers_": 0,
    "sklearn.preprocessing._data.add_dummy_feature": 0,
    "sklearn.preprocessing._discretization.KBinsDiscretizer.inverse_transform": 0,
    "sklearn.preprocessing._function_transformer.FunctionTransformer.fit": 0,
    "sklearn.preprocessing._function_transformer.FunctionTransformer.inverse_transform": 0,
    "sklearn.preprocessing.setup.configuration": 0,
    "sklearn.random_projection.BaseRandomProjection.__init__": 0,
    "sklearn.random_projection.johnson_lindenstrauss_min_dim": 0,
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.__init__": 0,
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.decision_function": 0,
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.fit": 0,
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.predict": 0,
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.predict_log_proba": 0,
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.predict_proba": 0,
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.score": 0,
    "sklearn.setup.configuration": 0,
    "sklearn.setup_module": 0,
    "sklearn.svm._bounds.l1_min_c": 0,
    "sklearn.svm._classes.OneClassSVM.probA_": 0,
    "sklearn.svm._classes.OneClassSVM.probB_": 0,
    "sklearn.svm._classes.OneClassSVM.score_samples": 0,
    "sklearn.svm._classes.SVR.probA_": 0,
    "sklearn.svm._classes.SVR.probB_": 0,
    "sklearn.svm.setup.configuration": 0,
    "sklearn.tree._classes.BaseDecisionTree.__init__": 0,
    "sklearn.tree._classes.BaseDecisionTree.decision_path": 0,
    "sklearn.tree._classes.BaseDecisionTree.feature_importances_": 0,
    "sklearn.tree._classes.BaseDecisionTree.fit": 0,
    "sklearn.tree._classes.BaseDecisionTree.get_depth": 0,
    "sklearn.tree._classes.DecisionTreeClassifier.predict_log_proba": 0,
    "sklearn.tree._export.export_text.print_tree_recurse": 0,
    "sklearn.tree.setup.configuration": 0,
    "sklearn.utils.Bunch.__dir__": 0,
    "sklearn.utils.Bunch.__getattr__": 0,
    "sklearn.utils.Bunch.__init__": 0,
    "sklearn.utils.Bunch.__setattr__": 0,
    "sklearn.utils.Bunch.__setstate__": 0,
    "sklearn.utils._estimator_html_repr.estimator_html_repr": 0,
    "sklearn.utils._show_versions.show_versions": 0,
    "sklearn.utils.all_estimators.is_abstract": 0,
    "sklearn.utils.axis0_safe_slice": 0,
    "sklearn.utils.check_matplotlib_support": 0,
    "sklearn.utils.check_pandas_support": 0,
    "sklearn.utils.deprecation.deprecated.__call__": 0,
    "sklearn.utils.deprecation.deprecated.__init__": 0,
    "sklearn.utils.estimator_checks.check_class_weight_balanced_classifiers": 0,
    "sklearn.utils.estimator_checks.check_class_weight_balanced_linear_classifier": 0,
    "sklearn.utils.estimator_checks.check_class_weight_classifiers": 0,
    "sklearn.utils.estimator_checks.check_classifier_data_not_an_array": 0,
    "sklearn.utils.estimator_checks.check_classifier_multioutput": 0,
    "sklearn.utils.estimator_checks.check_classifiers_classes": 0,
    "sklearn.utils.estimator_checks.check_classifiers_multilabel_representation_invariance": 0,
    "sklearn.utils.estimator_checks.check_classifiers_one_label": 0,
    "sklearn.utils.estimator_checks.check_classifiers_predictions": 0,
    "sklearn.utils.estimator_checks.check_classifiers_regression_target": 0,
    "sklearn.utils.estimator_checks.check_classifiers_train": 0,
    "sklearn.utils.estimator_checks.check_clusterer_compute_labels_predict": 0,
    "sklearn.utils.estimator_checks.check_clustering": 0,
    "sklearn.utils.estimator_checks.check_complex_data": 0,
    "sklearn.utils.estimator_checks.check_decision_proba_consistency": 0,
    "sklearn.utils.estimator_checks.check_dict_unchanged": 0,
    "sklearn.utils.estimator_checks.check_dont_overwrite_parameters": 0,
    "sklearn.utils.estimator_checks.check_dtype_object": 0,
    "sklearn.utils.estimator_checks.check_estimator.checks_generator": 0,
    "sklearn.utils.estimator_checks.check_estimator_get_tags_default_keys": 0,
    "sklearn.utils.estimator_checks.check_estimator_sparse_data": 0,
    "sklearn.utils.estimator_checks.check_estimators_data_not_an_array": 0,
    "sklearn.utils.estimator_checks.check_estimators_dtypes": 0,
    "sklearn.utils.estimator_checks.check_estimators_empty_data_messages": 0,
    "sklearn.utils.estimator_checks.check_estimators_fit_returns_self": 0,
    "sklearn.utils.estimator_checks.check_estimators_nan_inf": 0,
    "sklearn.utils.estimator_checks.check_estimators_overwrite_params": 0,
    "sklearn.utils.estimator_checks.check_estimators_partial_fit_n_features": 0,
    "sklearn.utils.estimator_checks.check_estimators_pickle": 0,
    "sklearn.utils.estimator_checks.check_estimators_unfitted": 0,
    "sklearn.utils.estimator_checks.check_fit1d": 0,
    "sklearn.utils.estimator_checks.check_fit2d_1feature": 0,
    "sklearn.utils.estimator_checks.check_fit2d_1sample": 0,
    "sklearn.utils.estimator_checks.check_fit2d_predict1d": 0,
    "sklearn.utils.estimator_checks.check_fit_idempotent": 0,
    "sklearn.utils.estimator_checks.check_fit_non_negative": 0,
    "sklearn.utils.estimator_checks.check_fit_score_takes_y": 0,
    "sklearn.utils.estimator_checks.check_get_params_invariance": 0,
    "sklearn.utils.estimator_checks.check_methods_sample_order_invariance": 0,
    "sklearn.utils.estimator_checks.check_methods_subset_invariance": 0,
    "sklearn.utils.estimator_checks.check_n_features_in": 0,
    "sklearn.utils.estimator_checks.check_n_features_in_after_fitting": 0,
    "sklearn.utils.estimator_checks.check_no_attributes_set_in_init": 0,
    "sklearn.utils.estimator_checks.check_non_transformer_estimators_n_iter": 0,
    "sklearn.utils.estimator_checks.check_nonsquare_error": 0,
    "sklearn.utils.estimator_checks.check_outlier_corruption": 0,
    "sklearn.utils.estimator_checks.check_outliers_fit_predict": 0,
    "sklearn.utils.estimator_checks.check_outliers_train": 0,
    "sklearn.utils.estimator_checks.check_parameters_default_constructible": 0,
    "sklearn.utils.estimator_checks.check_parameters_default_constructible.param_filter": 0,
    "sklearn.utils.estimator_checks.check_pipeline_consistency": 0,
    "sklearn.utils.estimator_checks.check_regressor_data_not_an_array": 0,
    "sklearn.utils.estimator_checks.check_regressor_multioutput": 0,
    "sklearn.utils.estimator_checks.check_regressors_int": 0,
    "sklearn.utils.estimator_checks.check_regressors_no_decision_function": 0,
    "sklearn.utils.estimator_checks.check_regressors_train": 0,
    "sklearn.utils.estimator_checks.check_requires_y_none": 0,
    "sklearn.utils.estimator_checks.check_sample_weights_invariance": 0,
    "sklearn.utils.estimator_checks.check_sample_weights_list": 0,
    "sklearn.utils.estimator_checks.check_sample_weights_not_an_array": 0,
    "sklearn.utils.estimator_checks.check_sample_weights_pandas_series": 0,
    "sklearn.utils.estimator_checks.check_sample_weights_shape": 0,
    "sklearn.utils.estimator_checks.check_set_params": 0,
    "sklearn.utils.estimator_checks.check_sparsify_coefficients": 0,
    "sklearn.utils.estimator_checks.check_supervised_y_2d": 0,
    "sklearn.utils.estimator_checks.check_supervised_y_no_nan": 0,
    "sklearn.utils.estimator_checks.check_transformer_data_not_an_array": 0,
    "sklearn.utils.estimator_checks.check_transformer_general": 0,
    "sklearn.utils.estimator_checks.check_transformer_n_iter": 0,
    "sklearn.utils.estimator_checks.check_transformer_preserve_dtypes": 0,
    "sklearn.utils.estimator_checks.check_transformers_unfitted": 0,
    "sklearn.utils.estimator_checks.parametrize_with_checks": 0,
    "sklearn.utils.estimator_checks.parametrize_with_checks.checks_generator": 0,
    "sklearn.utils.extmath.fast_logdet": 0,
    "sklearn.utils.extmath.log_logistic": 0,
    "sklearn.utils.extmath.make_nonnegative": 0,
    "sklearn.utils.extmath.randomized_range_finder": 0,
    "sklearn.utils.extmath.randomized_svd": 0,
    "sklearn.utils.extmath.row_norms": 0,
    "sklearn.utils.extmath.softmax": 0,
    "sklearn.utils.extmath.squared_norm": 0,
    "sklearn.utils.extmath.stable_cumsum": 0,
    "sklearn.utils.extmath.svd_flip": 0,
    "sklearn.utils.fixes.delayed": 0,
    "sklearn.utils.fixes.delayed.delayed_function": 0,
    "sklearn.utils.gen_batches": 0,
    "sklearn.utils.gen_even_slices": 0,
    "sklearn.utils.get_chunk_n_rows": 0,
    "sklearn.utils.graph.single_source_shortest_path_length": 0,
    "sklearn.utils.indices_to_mask": 0,
    "sklearn.utils.is_scalar_nan": 0,
    "sklearn.utils.multiclass.check_classification_targets": 0,
    "sklearn.utils.multiclass.class_distribution": 0,
    "sklearn.utils.multiclass.is_multilabel": 0,
    "sklearn.utils.setup.configuration": 0,
    "sklearn.utils.sparsefuncs.count_nonzero": 0,
    "sklearn.utils.sparsefuncs.csc_median_axis_0": 0,
    "sklearn.utils.sparsefuncs.incr_mean_variance_axis": 0,
    "sklearn.utils.sparsefuncs.inplace_column_scale": 0,
    "sklearn.utils.sparsefuncs.inplace_csr_column_scale": 0,
    "sklearn.utils.sparsefuncs.inplace_csr_row_scale": 0,
    "sklearn.utils.sparsefuncs.inplace_row_scale": 0,
    "sklearn.utils.sparsefuncs.inplace_swap_column": 0,
    "sklearn.utils.sparsefuncs.inplace_swap_row": 0,
    "sklearn.utils.sparsefuncs.inplace_swap_row_csc": 0,
    "sklearn.utils.sparsefuncs.inplace_swap_row_csr": 0,
    "sklearn.utils.sparsefuncs.mean_variance_axis": 0,
    "sklearn.utils.sparsefuncs.min_max_axis": 0,
    "sklearn.utils.tosequence": 0,
    "sklearn.utils.validation.as_float_array": 0,
    "sklearn.utils.validation.assert_all_finite": 0,
    "sklearn.utils.validation.check_memory": 0,
    "sklearn.utils.validation.check_non_negative": 0,
    "sklearn.utils.validation.check_scalar": 0,
    "sklearn.utils.validation.check_symmetric": 0,
    "sklearn.utils.validation.has_fit_parameter": 0
  },
  "parameter_counts": {
    "sklearn.model_selection._split.train_test_split.test_size": 15002,
    "sklearn.model_selection._split.train_test_split.random_state": 12730,
    "sklearn.metrics._regression.mean_squared_error.y_true": 8461,
    "sklearn.metrics._regression.mean_squared_error.y_pred": 8460,
    "sklearn.preprocessing._label.LabelEncoder.transform.y": 8446,
    "sklearn.metrics._ranking.roc_auc_score.y_true": 8297,
    "sklearn.metrics._ranking.roc_auc_score.y_score": 8297,
    "sklearn.base.TransformerMixin.fit_transform.X": 8232,
    "sklearn.preprocessing._label.LabelEncoder.fit_transform.y": 7897,
    "sklearn.metrics._classification.accuracy_score.y_true": 7130,
    "sklearn.metrics._classification.accuracy_score.y_pred": 7130,
    "sklearn.preprocessing._label.LabelEncoder.fit.y": 5246,
    "sklearn.metrics._classification.confusion_matrix.y_true": 4459,
    "sklearn.metrics._classification.confusion_matrix.y_pred": 4459,
    "sklearn.preprocessing._data.StandardScaler.transform.X": 4369,
    "sklearn.model_selection._split.StratifiedKFold.__init__.n_splits": 4331,
    "sklearn.model_selection._split.KFold.__init__.n_splits": 4325,
    "sklearn.metrics._classification.f1_score.y_true": 4087,
    "sklearn.metrics._classification.f1_score.y_pred": 4087,
    "sklearn.metrics._classification.log_loss.y_true": 4078,
    "sklearn.metrics._classification.log_loss.y_pred": 4078,
    "sklearn.model_selection._split.StratifiedKFold.split.X": 3901,
    "sklearn.model_selection._split.StratifiedKFold.split.y": 3901,
    "sklearn.model_selection._validation.cross_val_score.estimator": 3801,
    "sklearn.model_selection._validation.cross_val_score.X": 3801,
    "sklearn.model_selection._validation.cross_val_score.y": 3801,
    "sklearn.pipeline.Pipeline.__init__.steps": 3706,
    "sklearn.model_selection._validation.cross_val_score.cv": 3619,
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.n_estimators": 3510,
    "sklearn.model_selection._split.StratifiedKFold.__init__.random_state": 3478,
    "sklearn.linear_model._logistic.LogisticRegression.fit.X": 3369,
    "sklearn.linear_model._logistic.LogisticRegression.fit.y": 3369,
    "sklearn.model_selection._split.KFold.__init__.random_state": 3356,
    "sklearn.model_selection._split.KFold.__init__.shuffle": 3335,
    "sklearn.model_selection._split.StratifiedKFold.__init__.shuffle": 3272,
    "sklearn.metrics._classification.classification_report.y_true": 3074,
    "sklearn.metrics._classification.classification_report.y_pred": 3074,
    "sklearn.metrics._regression.mean_absolute_error.y_true": 2920,
    "sklearn.metrics._regression.mean_absolute_error.y_pred": 2920,
    "sklearn.base.ClassifierMixin.score.X": 2842,
    "sklearn.base.ClassifierMixin.score.y": 2841,
    "sklearn.model_selection._search.GridSearchCV.__init__.estimator": 2752,
    "sklearn.model_selection._search.GridSearchCV.__init__.param_grid": 2751,
    "sklearn.feature_extraction.text.TfidfVectorizer.transform.raw_documents": 2730,
    "sklearn.model_selection._validation.cross_val_score.scoring": 2544,
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.n_estimators": 2486,
    "sklearn.linear_model._base.LinearRegression.fit.y": 2407,
    "sklearn.linear_model._base.LinearRegression.fit.X": 2406,
    "sklearn.feature_extraction.text.CountVectorizer.transform.raw_documents": 2373,
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.random_state": 2353,
    "sklearn.decomposition._pca.PCA.__init__.n_components": 2310,
    "sklearn.model_selection._split.train_test_split.stratify": 2281,
    "sklearn.model_selection._search.GridSearchCV.__init__.cv": 2219,
    "sklearn.metrics._classification.f1_score.average": 2080,
    "sklearn.metrics._regression.r2_score.y_true": 2029,
    "sklearn.metrics._regression.r2_score.y_pred": 2029,
    "sklearn.linear_model._logistic.LogisticRegression.predict_proba.X": 1995,
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.ngram_range": 1931,
    "sklearn.preprocessing._data.StandardScaler.fit.X": 1837,
    "sklearn.feature_extraction.text.CountVectorizer.fit_transform.raw_documents": 1815,
    "sklearn.base.RegressorMixin.score.X": 1801,
    "sklearn.base.RegressorMixin.score.y": 1801,
    "sklearn.pipeline.Pipeline.predict.X": 1796,
    "sklearn.feature_extraction.text.TfidfVectorizer.fit_transform.raw_documents": 1793,
    "sklearn.pipeline.Pipeline.fit.X": 1780,
    "sklearn.model_selection._search.GridSearchCV.__init__.scoring": 1761,
    "sklearn.linear_model._logistic.LogisticRegression.__init__.C": 1722,
    "sklearn.decomposition._pca.PCA.fit_transform.X": 1719,
    "sklearn.pipeline.Pipeline.fit.y": 1707,
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.n_jobs": 1659,
    "sklearn.preprocessing._data.MinMaxScaler.transform.X": 1605,
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.n_jobs": 1568,
    "sklearn.tree._classes.BaseDecisionTree.predict.X": 1547,
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.stop_words": 1524,
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.random_state": 1508,
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.max_depth": 1433,
    "sklearn.linear_model._logistic.LogisticRegression.__init__.solver": 1417,
    "sklearn.metrics._ranking.roc_curve.y_true": 1411,
    "sklearn.metrics._ranking.roc_curve.y_score": 1411,
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.max_features": 1389,
    "sklearn.neighbors._classification.KNeighborsClassifier.__init__.n_neighbors": 1344,
    "sklearn.calibration.CalibratedClassifierCV.predict_proba.X": 1322,
    "sklearn.model_selection._search.GridSearchCV.__init__.n_jobs": 1239,
    "sklearn.model_selection._split.train_test_split.shuffle": 1234,
    "sklearn.metrics._classification.precision_score.y_true": 1153,
    "sklearn.metrics._classification.precision_score.y_pred": 1153,
    "sklearn.metrics._classification.recall_score.y_true": 1124,
    "sklearn.metrics._classification.recall_score.y_pred": 1124,
    "sklearn.neighbors._classification.KNeighborsClassifier.fit.X": 1093,
    "sklearn.neighbors._classification.KNeighborsClassifier.fit.y": 1093,
    "sklearn.metrics._classification.cohen_kappa_score.y1": 1072,
    "sklearn.metrics._classification.cohen_kappa_score.y2": 1072,
    "sklearn.metrics._regression.mean_squared_log_error.y_true": 1052,
    "sklearn.metrics._regression.mean_squared_log_error.y_pred": 1052,
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.sublinear_tf": 1042,
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.min_df": 1030,
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.analyzer": 1025,
    "sklearn.model_selection._search.GridSearchCV.__init__.verbose": 1024,
    "sklearn.model_selection._split.train_test_split.train_size": 1024,
    "sklearn.metrics._regression.mean_squared_error.squared": 1018,
    "sklearn.impute._base.SimpleImputer.__init__.strategy": 1002,
    "sklearn.metrics._classification.cohen_kappa_score.weights": 936,
    "sklearn.decomposition._truncated_svd.TruncatedSVD.__init__.n_components": 934,
    "sklearn.tree._classes.DecisionTreeClassifier.fit.X": 922,
    "sklearn.tree._classes.DecisionTreeClassifier.fit.y": 922,
    "sklearn.cluster._kmeans.KMeans.__init__.n_clusters": 918,
    "sklearn.metrics._ranking.auc.x": 918,
    "sklearn.metrics._ranking.auc.y": 918,
    "sklearn.linear_model._logistic.LogisticRegression.__init__.random_state": 897,
    "sklearn.feature_selection._base.SelectorMixin.transform.X": 895,
    "sklearn.preprocessing._label.LabelEncoder.inverse_transform.y": 876,
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.max_depth": 857,
    "sklearn.feature_extraction.text.TfidfVectorizer.fit.raw_documents": 856,
    "sklearn.decomposition._pca.PCA.fit.X": 851,
    "sklearn.neighbors._classification.KNeighborsClassifier.predict.X": 841,
    "sklearn.feature_extraction.text.CountVectorizer.__init__.ngram_range": 815,
    "sklearn.feature_extraction.text.CountVectorizer.__init__.stop_words": 804,
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.strip_accents": 802,
    "sklearn.metrics._scorer.make_scorer.score_func": 800,
    "sklearn.svm._classes.SVC.__init__.kernel": 791,
    "sklearn.feature_extraction.text.CountVectorizer.fit.raw_documents": 783,
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.max_features": 782,
    "sklearn.calibration.CalibratedClassifierCV.__init__.base_estimator": 781,
    "sklearn.linear_model._logistic.LogisticRegression.__init__.max_iter": 767,
    "sklearn.decomposition._pca.PCA.__init__.random_state": 766,
    "sklearn.preprocessing._encoders.OneHotEncoder.fit_transform.X": 765,
    "sklearn.calibration.CalibratedClassifierCV.fit.X": 753,
    "sklearn.calibration.CalibratedClassifierCV.fit.y": 753,
    "sklearn.calibration.CalibratedClassifierCV.__init__.method": 750,
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.token_pattern": 735,
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.min_samples_leaf": 720,
    "sklearn.ensemble._gb.GradientBoostingRegressor.predict.X": 718,
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.criterion": 713,
    "sklearn.feature_extraction.text.CountVectorizer.__init__.min_df": 704,
    "sklearn.preprocessing._encoders.OneHotEncoder.transform.X": 694,
    "sklearn.feature_extraction.text.CountVectorizer.__init__.max_features": 690,
    "sklearn.model_selection._split.GroupKFold.__init__.n_splits": 686,
    "sklearn.metrics._classification.precision_score.average": 680,
    "sklearn.linear_model._ridge.Ridge.__init__.alpha": 675,
    "sklearn.preprocessing._data.MinMaxScaler.__init__.feature_range": 675,
    "sklearn.cluster._kmeans.KMeans.fit.X": 674,
    "sklearn.metrics._classification.recall_score.average": 673,
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.max_features": 660,
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.loss": 657,
    "sklearn.linear_model._logistic.LogisticRegression.__init__.penalty": 653,
    "sklearn.linear_model._ridge.Ridge.fit.X": 651,
    "sklearn.linear_model._ridge.Ridge.fit.y": 651,
    "sklearn.model_selection._split.GroupKFold.split.groups": 616,
    "sklearn.model_selection._split.GroupKFold.split.X": 616,
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.use_idf": 613,
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.smooth_idf": 602,
    "sklearn.model_selection._search.RandomizedSearchCV.__init__.param_distributions": 573,
    "sklearn.model_selection._search.RandomizedSearchCV.__init__.estimator": 573,
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.max_df": 573,
    "sklearn.tree._classes.DecisionTreeRegressor.fit.X": 572,
    "sklearn.tree._classes.DecisionTreeRegressor.fit.y": 572,
    "sklearn.svm._classes.SVC.__init__.C": 569,
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.penalty": 567,
    "sklearn.decomposition._truncated_svd.TruncatedSVD.__init__.random_state": 561,
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.random_state": 560,
    "sklearn.feature_selection._variance_threshold.VarianceThreshold.__init__.threshold": 556,
    "sklearn.metrics._scorer.make_scorer.greater_is_better": 556,
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.alpha": 540,
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.min_samples_leaf": 535,
    "sklearn.preprocessing._data.PolynomialFeatures.__init__.degree": 534,
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.n_estimators": 529,
    "sklearn.manifold._t_sne.TSNE.fit_transform.X": 528,
    "sklearn.preprocessing._encoders.OneHotEncoder.__init__.sparse": 524,
    "sklearn.preprocessing._data.MinMaxScaler.fit.X": 521,
    "sklearn.decomposition._truncated_svd.TruncatedSVD.fit_transform.X": 518,
    "sklearn.decomposition._truncated_svd.TruncatedSVD.transform.X": 514,
    "sklearn.model_selection._search.RandomizedSearchCV.__init__.cv": 512,
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.n_estimators": 502,
    "sklearn.svm._classes.SVC.__init__.probability": 498,
    "sklearn.linear_model._coordinate_descent.ElasticNet.fit.X": 475,
    "sklearn.linear_model._coordinate_descent.ElasticNet.fit.y": 475,
    "sklearn.linear_model._logistic.LogisticRegression.__init__.multi_class": 469,
    "sklearn.cluster._kmeans.KMeans.__init__.random_state": 468,
    "sklearn.linear_model._logistic.LogisticRegression.__init__.class_weight": 461,
    "sklearn.manifold._t_sne.TSNE.__init__.n_components": 458,
    "sklearn.svm._classes.SVC.__init__.gamma": 454,
    "sklearn.preprocessing._function_transformer.FunctionTransformer.__init__.func": 450,
    "sklearn.linear_model._coordinate_descent.Lasso.__init__.alpha": 445,
    "sklearn.compose._column_transformer.ColumnTransformer.__init__.transformers": 443,
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.oob_score": 436,
    "sklearn.tree._classes.DecisionTreeClassifier.__init__.random_state": 436,
    "sklearn.tree._classes.DecisionTreeClassifier.__init__.max_depth": 436,
    "sklearn.preprocessing._data.minmax_scale.X": 433,
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.n_estimators": 429,
    "sklearn.preprocessing._data.normalize.X": 429,
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.min_samples_split": 428,
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.max_depth": 428,
    "sklearn.model_selection._validation.cross_val_score.n_jobs": 424,
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.learning_rate": 421,
    "sklearn.metrics._classification.confusion_matrix.labels": 421,
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.verbose": 415,
    "sklearn.preprocessing._data.MinMaxScaler.inverse_transform.X": 412,
    "sklearn.preprocessing._label.LabelBinarizer.fit_transform.y": 410,
    "sklearn.pipeline.Pipeline.fit_transform.X": 410,
    "sklearn.preprocessing._encoders.OneHotEncoder.__init__.handle_unknown": 396,
    "sklearn.feature_extraction.text.CountVectorizer.__init__.analyzer": 396,
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.random_state": 396,
    "sklearn.model_selection._split.GroupKFold.split.y": 393,
    "sklearn.preprocessing._data.QuantileTransformer.transform.X": 391,
    "sklearn.model_selection._search.RandomizedSearchCV.__init__.n_iter": 390,
    "sklearn.naive_bayes.GaussianNB.fit.X": 387,
    "sklearn.naive_bayes.GaussianNB.fit.y": 387,
    "sklearn.impute._base.SimpleImputer.transform.X": 377,
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.min_samples_split": 369,
    "sklearn.cluster._kmeans.KMeans.predict.X": 369,
    "sklearn.preprocessing._encoders.OneHotEncoder.fit.X": 362,
    "sklearn.model_selection._search.RandomizedSearchCV.__init__.verbose": 360,
    "sklearn.metrics._classification.classification_report.target_names": 358,
    "sklearn.feature_extraction.text.CountVectorizer.__init__.token_pattern": 355,
    "sklearn.utils.shuffle.random_state": 353,
    "sklearn.manifold._t_sne.TSNE.__init__.random_state": 350,
    "sklearn.tree._classes.DecisionTreeRegressor.__init__.random_state": 349,
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.random_state": 349,
    "sklearn.feature_selection._univariate_selection.SelectKBest.__init__.k": 342,
    "sklearn.svm._classes.SVC.__init__.random_state": 340,
    "sklearn.model_selection._search.RandomizedSearchCV.__init__.scoring": 340,
    "sklearn.feature_selection._univariate_selection.SelectKBest.__init__.score_func": 338,
    "sklearn.metrics._classification.log_loss.labels": 334,
    "sklearn.model_selection._search.RandomizedSearchCV.__init__.n_jobs": 333,
    "sklearn.metrics._classification.f1_score.labels": 330,
    "sklearn.pipeline.FeatureUnion.__init__.transformer_list": 324,
    "sklearn.impute._base.SimpleImputer.__init__.missing_values": 319,
    "sklearn.preprocessing._data.QuantileTransformer.__init__.output_distribution": 315,
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.oob_score": 315,
    "sklearn.preprocessing._data.scale.X": 314,
    "sklearn.calibration.CalibratedClassifierCV.predict.X": 314,
    "sklearn.pipeline.Pipeline.predict_proba.X": 313,
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.max_depth": 309,
    "sklearn.linear_model._logistic.LogisticRegression.__init__.n_jobs": 305,
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.tokenizer": 304,
    "sklearn.ensemble._voting.VotingClassifier.__init__.estimators": 304,
    "sklearn.linear_model._ridge.Ridge.__init__.fit_intercept": 302,
    "sklearn.model_selection._validation.cross_validate.estimator": 299,
    "sklearn.model_selection._validation.cross_validate.X": 299,
    "sklearn.model_selection._validation.cross_validate.y": 298,
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.loss": 294,
    "sklearn.base.TransformerMixin.fit_transform.y": 294,
    "sklearn.model_selection._validation.cross_validate.cv": 291,
    "sklearn.ensemble._voting.VotingClassifier.predict.X": 291,
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.random_state": 288,
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.verbose": 282,
    "sklearn.multiclass.OneVsRestClassifier.__init__.estimator": 280,
    "sklearn.preprocessing._label.LabelBinarizer.transform.y": 279,
    "sklearn.preprocessing._data.QuantileTransformer.__init__.random_state": 277,
    "sklearn.preprocessing._data.QuantileTransformer.__init__.n_quantiles": 274,
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.class_weight": 274,
    "sklearn.linear_model._base.LinearRegression.__init__.fit_intercept": 274,
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.learning_rate": 274,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.hidden_layer_sizes": 274,
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.predict_proba.X": 274,
    "sklearn.ensemble._voting.VotingClassifier.__init__.voting": 273,
    "sklearn.model_selection._split.ShuffleSplit.__init__.n_splits": 271,
    "sklearn.ensemble._gb.GradientBoostingClassifier.predict.X": 271,
    "sklearn.model_selection._split.ShuffleSplit.__init__.test_size": 267,
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.n_components": 266,
    "sklearn.preprocessing._data.PolynomialFeatures.get_feature_names.input_features": 266,
    "sklearn.linear_model._coordinate_descent.ElasticNet.__init__.alpha": 261,
    "sklearn.ensemble._voting.VotingClassifier.fit.X": 259,
    "sklearn.ensemble._voting.VotingClassifier.fit.y": 259,
    "sklearn.feature_extraction.text.CountVectorizer.__init__.binary": 258,
    "sklearn.neighbors._classification.KNeighborsClassifier.predict_proba.X": 257,
    "sklearn.model_selection._search.RandomizedSearchCV.__init__.random_state": 257,
    "sklearn.preprocessing._label.LabelBinarizer.__init__.sparse_output": 254,
    "sklearn.utils.class_weight.compute_class_weight.class_weight": 251,
    "sklearn.cluster._kmeans.KMeans.fit_predict.X": 251,
    "sklearn.preprocessing._function_transformer.FunctionTransformer.__init__.validate": 251,
    "sklearn.model_selection._split.ShuffleSplit.__init__.random_state": 250,
    "sklearn.tree._classes.DecisionTreeRegressor.__init__.max_depth": 249,
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.max_depth": 249,
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.n_jobs": 249,
    "sklearn.metrics._classification.precision_score.labels": 249,
    "sklearn.metrics._classification.recall_score.labels": 248,
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.class_weight": 245,
    "sklearn.feature_selection._variance_threshold.VarianceThreshold.fit.X": 243,
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.min_samples_split": 242,
    "sklearn.preprocessing._data.StandardScaler.inverse_transform.X": 241,
    "sklearn.feature_extraction.text.CountVectorizer.__init__.tokenizer": 238,
    "sklearn.linear_model._coordinate_descent.ElasticNet.__init__.l1_ratio": 237,
    "sklearn.pipeline.Pipeline.score.X": 236,
    "sklearn.pipeline.Pipeline.score.y": 236,
    "sklearn.model_selection._split.StratifiedShuffleSplit.__init__.n_splits": 234,
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.__init__.n_estimators": 231,
    "sklearn.feature_extraction.text.CountVectorizer.__init__.max_df": 231,
    "sklearn.base.clone.estimator": 231,
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.n_estimators": 230,
    "sklearn.naive_bayes.MultinomialNB.__init__.alpha": 229,
    "sklearn.linear_model._ridge.Ridge.__init__.random_state": 228,
    "sklearn.ensemble._gb.GradientBoostingClassifier.predict_proba.X": 227,
    "sklearn.neighbors._classification.KNeighborsClassifier.__init__.weights": 226,
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.max_features": 226,
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.binary": 225,
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.fit_transform.X": 225,
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.fit.X": 223,
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.fit.y": 223,
    "sklearn.model_selection._search.GridSearchCV.__init__.return_train_score": 223,
    "sklearn.metrics._classification.log_loss.eps": 222,
    "sklearn.metrics._ranking.roc_auc_score.average": 219,
    "sklearn.svm._classes.SVC.__init__.degree": 219,
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.min_samples_leaf": 217,
    "sklearn.svm._classes.LinearSVC.fit.X": 216,
    "sklearn.svm._classes.LinearSVC.fit.y": 216,
    "sklearn.compose._column_transformer.ColumnTransformer.fit_transform.X": 216,
    "sklearn.model_selection._split.StratifiedShuffleSplit.split.X": 216,
    "sklearn.model_selection._split.StratifiedShuffleSplit.split.y": 216,
    "sklearn.feature_selection._from_model.SelectFromModel.__init__.estimator": 215,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.random_state": 215,
    "sklearn.model_selection._validation.cross_val_predict.estimator": 214,
    "sklearn.model_selection._validation.cross_val_predict.X": 214,
    "sklearn.model_selection._validation.cross_val_predict.y": 214,
    "sklearn.model_selection._search.GridSearchCV.__init__.refit": 213,
    "sklearn.neighbors._regression.KNeighborsRegressor.predict.X": 212,
    "sklearn.model_selection._validation.cross_validate.scoring": 212,
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.max_features": 211,
    "sklearn.svm._classes.SVR.__init__.kernel": 209,
    "sklearn.model_selection._split.StratifiedShuffleSplit.__init__.random_state": 207,
    "sklearn.tree._classes.DecisionTreeClassifier.__init__.criterion": 206,
    "sklearn.neighbors._regression.KNeighborsRegressor.__init__.n_neighbors": 203,
    "sklearn.preprocessing._data.PolynomialFeatures.transform.X": 203,
    "sklearn.manifold._t_sne.TSNE.__init__.perplexity": 203,
    "sklearn.tree._export.export_graphviz.decision_tree": 202,
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.criterion": 201,
    "sklearn.metrics._ranking.precision_recall_curve.y_true": 201,
    "sklearn.metrics._ranking.precision_recall_curve.probas_pred": 201,
    "sklearn.preprocessing._data.QuantileTransformer.fit.X": 200,
    "sklearn.linear_model._base.LinearRegression.__init__.n_jobs": 200,
    "sklearn.tree._export.export_graphviz.out_file": 199,
    "sklearn.linear_model._ridge.Ridge.__init__.solver": 198,
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.lowercase": 194,
    "sklearn.preprocessing._data.normalize.axis": 194,
    "sklearn.model_selection._split.StratifiedShuffleSplit.__init__.test_size": 194,
    "sklearn.model_selection._validation.cross_val_predict.cv": 193,
    "sklearn.linear_model._coordinate_descent.ElasticNet.__init__.random_state": 192,
    "sklearn.decomposition._truncated_svd.TruncatedSVD.fit.X": 191,
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.random_state": 191,
    "sklearn.feature_extraction.text.CountVectorizer.__init__.lowercase": 191,
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.bootstrap": 190,
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.predict.X": 189,
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.bootstrap": 188,
    "sklearn.svm._classes.SVR.__init__.C": 187,
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.min_samples_split": 186,
    "sklearn.linear_model._base.LinearRegression.__init__.normalize": 186,
    "sklearn.decomposition._fastica.FastICA.__init__.n_components": 186,
    "sklearn.metrics._ranking.roc_curve.pos_label": 185,
    "sklearn.linear_model._coordinate_descent.Lasso.__init__.random_state": 182,
    "sklearn.neighbors._regression.KNeighborsRegressor.fit.X": 180,
    "sklearn.neighbors._regression.KNeighborsRegressor.fit.y": 180,
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix.estimator": 180,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.solver": 180,
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.min_samples_leaf": 179,
    "sklearn.manifold._t_sne.TSNE.__init__.n_iter": 179,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.predict.X": 179,
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix.X": 179,
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix.y_true": 179,
    "sklearn.compose._column_transformer.ColumnTransformer.transform.X": 178,
    "sklearn.neighbors._classification.KNeighborsClassifier.__init__.p": 178,
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.n_jobs": 178,
    "sklearn.tree._export.export_graphviz.feature_names": 176,
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.norm": 175,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.alpha": 175,
    "sklearn.impute._base.SimpleImputer.fit.X": 175,
    "sklearn.cluster._kmeans.MiniBatchKMeans.predict.X": 174,
    "sklearn.utils.resample.n_samples": 174,
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.covariance_type": 169,
    "sklearn.neighbors._classification.KNeighborsClassifier.__init__.n_jobs": 169,
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.fit.X": 169,
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.fit.y": 169,
    "sklearn.feature_selection._univariate_selection.SelectPercentile.__init__.score_func": 167,
    "sklearn.model_selection._split.RepeatedKFold.__init__.n_splits": 166,
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.transform.X": 166,
    "sklearn.utils.resample.replace": 166,
    "sklearn.decomposition._truncated_svd.TruncatedSVD.__init__.algorithm": 165,
    "sklearn.feature_extraction.text.CountVectorizer.__init__.preprocessor": 164,
    "sklearn.decomposition._fastica.FastICA.fit_transform.X": 163,
    "sklearn.model_selection._split.RepeatedKFold.__init__.n_repeats": 161,
    "sklearn.manifold._t_sne.TSNE.__init__.init": 161,
    "sklearn.compose._column_transformer.ColumnTransformer.__init__.remainder": 160,
    "sklearn.decomposition._truncated_svd.TruncatedSVD.__init__.n_iter": 159,
    "sklearn.decomposition._fastica.FastICA.__init__.random_state": 158,
    "sklearn.impute._base.SimpleImputer.__init__.fill_value": 158,
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.__init__.random_state": 157,
    "sklearn.linear_model._logistic.LogisticRegression.__init__.dual": 157,
    "sklearn.cluster._kmeans.KMeans.__init__.n_init": 157,
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.criterion": 156,
    "sklearn.feature_selection._univariate_selection.SelectPercentile.__init__.percentile": 156,
    "sklearn.metrics._ranking.average_precision_score.y_true": 154,
    "sklearn.metrics._ranking.average_precision_score.y_score": 154,
    "sklearn.random_projection.BaseRandomProjection.transform.X": 153,
    "sklearn.utils.resample.random_state": 152,
    "sklearn.multiclass.OneVsRestClassifier.predict.X": 151,
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.max_features": 151,
    "sklearn.linear_model._logistic.LogisticRegression.__init__.verbose": 150,
    "sklearn.preprocessing._data.RobustScaler.transform.X": 149,
    "sklearn.linear_model._logistic.LogisticRegression.__init__.tol": 149,
    "sklearn.decomposition._fastica.FastICA.transform.X": 146,
    "sklearn.multiclass.OneVsRestClassifier.fit.X": 146,
    "sklearn.multiclass.OneVsRestClassifier.fit.y": 146,
    "sklearn.metrics._classification.matthews_corrcoef.y_true": 145,
    "sklearn.metrics._classification.matthews_corrcoef.y_pred": 145,
    "sklearn.tree._classes.DecisionTreeClassifier.predict_proba.X": 144,
    "sklearn.feature_extraction.text.CountVectorizer.__init__.dtype": 144,
    "sklearn.metrics._classification.fbeta_score.y_true": 143,
    "sklearn.metrics._classification.fbeta_score.y_pred": 143,
    "sklearn.linear_model._ridge.Ridge.__init__.normalize": 142,
    "sklearn.preprocessing._label.MultiLabelBinarizer.fit_transform.y": 142,
    "sklearn.feature_selection._rfe.RFE.__init__.estimator": 142,
    "sklearn.manifold._t_sne.TSNE.__init__.verbose": 142,
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.max_depth": 140,
    "sklearn.svm._classes.SVC.__init__.class_weight": 135,
    "sklearn.metrics.pairwise.cosine_similarity.X": 134,
    "sklearn.metrics._classification.fbeta_score.beta": 133,
    "sklearn.tree._export.export_graphviz.filled": 133,
    "sklearn.model_selection._split.RepeatedKFold.__init__.random_state": 130,
    "sklearn.neighbors._classification.KNeighborsClassifier.__init__.metric": 130,
    "sklearn.model_selection._validation.learning_curve.estimator": 129,
    "sklearn.model_selection._validation.learning_curve.X": 129,
    "sklearn.model_selection._validation.learning_curve.y": 129,
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.preprocessor": 127,
    "sklearn.pipeline.FeatureUnion.__init__.n_jobs": 126,
    "sklearn.preprocessing._encoders.OneHotEncoder.__init__.categories": 125,
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.subsample": 125,
    "sklearn.svm._classes.SVC.__init__.max_iter": 124,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.max_iter": 124,
    "sklearn.model_selection._split.TimeSeriesSplit.__init__.n_splits": 123,
    "sklearn.svm._classes.SVC.__init__.verbose": 123,
    "sklearn.model_selection._split.RepeatedStratifiedKFold.__init__.n_repeats": 123,
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.random_state": 123,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.predict_proba.X": 122,
    "sklearn.model_selection._validation.learning_curve.train_sizes": 122,
    "sklearn.preprocessing._label.LabelBinarizer.fit.y": 121,
    "sklearn.linear_model._bayes.BayesianRidge.predict.X": 121,
    "sklearn.model_selection._validation.learning_curve.cv": 121,
    "sklearn.svm._classes.SVC.__init__.tol": 120,
    "sklearn.pipeline.FeatureUnion.__init__.transformer_weights": 120,
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.min_samples_leaf": 120,
    "sklearn.svm._classes.SVR.__init__.gamma": 119,
    "sklearn.feature_extraction.text.TfidfTransformer.transform.X": 118,
    "sklearn.feature_selection._from_model.SelectFromModel.__init__.prefit": 118,
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.__init__.learning_rate": 117,
    "sklearn.model_selection._split.RepeatedStratifiedKFold.__init__.n_splits": 116,
    "sklearn.multiclass.OneVsRestClassifier.__init__.n_jobs": 115,
    "sklearn.preprocessing._data.StandardScaler.__init__.with_mean": 115,
    "sklearn.preprocessing._data.Normalizer.transform.X": 114,
    "sklearn.neighbors._unsupervised.NearestNeighbors.fit.X": 114,
    "sklearn.svm._classes.SVC.__init__.coef0": 114,
    "sklearn.svm._classes.SVC.__init__.cache_size": 114,
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.max_leaf_nodes": 113,
    "sklearn.metrics._classification.fbeta_score.average": 113,
    "sklearn.ensemble._bagging.BaggingClassifier.__init__.base_estimator": 111,
    "sklearn.model_selection._validation.cross_validate.return_train_score": 111,
    "sklearn.tree._export.export_graphviz.rounded": 111,
    "sklearn.cluster._kmeans.KMeans.__init__.init": 110,
    "sklearn.decomposition._pca.PCA.__init__.whiten": 109,
    "sklearn.svm._classes.SVC.__init__.shrinking": 109,
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.init_params": 108,
    "sklearn.model_selection._split.ShuffleSplit.__init__.train_size": 108,
    "sklearn.neighbors._classification.KNeighborsClassifier.__init__.leaf_size": 107,
    "sklearn.linear_model._ridge.Ridge.__init__.tol": 106,
    "sklearn.metrics.pairwise.cosine_similarity.Y": 106,
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.max_iter": 105,
    "sklearn.cluster._kmeans.MiniBatchKMeans.__init__.n_clusters": 105,
    "sklearn.feature_extraction.text.CountVectorizer.__init__.vocabulary": 105,
    "sklearn.model_selection._split.RepeatedStratifiedKFold.__init__.random_state": 104,
    "sklearn.feature_selection._rfe.RFE.fit.X": 104,
    "sklearn.feature_selection._rfe.RFE.fit.y": 104,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.activation": 104,
    "sklearn.preprocessing._data.PolynomialFeatures.fit.X": 104,
    "sklearn.calibration.CalibratedClassifierCV.__init__.cv": 104,
    "sklearn.linear_model._ridge.Ridge.__init__.max_iter": 104,
    "sklearn.model_selection._validation.learning_curve.n_jobs": 104,
    "sklearn.random_projection.SparseRandomProjection.__init__.n_components": 102,
    "sklearn.ensemble._bagging.BaggingClassifier.__init__.n_estimators": 102,
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.n_init": 102,
    "sklearn.linear_model._coordinate_descent.ElasticNet.__init__.max_iter": 100,
    "sklearn.svm._classes.SVR.__init__.epsilon": 99,
    "sklearn.pipeline.FeatureUnion.transform.X": 99,
    "sklearn.cluster._dbscan.DBSCAN.__init__.eps": 99,
    "sklearn.ensemble._weight_boosting.AdaBoostRegressor.__init__.n_estimators": 98,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.predict.X": 98,
    "sklearn.preprocessing._data.PolynomialFeatures.__init__.include_bias": 97,
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.subsample": 97,
    "sklearn.linear_model._logistic.LogisticRegressionCV.fit.X": 96,
    "sklearn.linear_model._logistic.LogisticRegressionCV.fit.y": 96,
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit.X": 95,
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit.y": 95,
    "sklearn.cluster._kmeans.KMeans.__init__.max_iter": 94,
    "sklearn.random_projection.GaussianRandomProjection.__init__.n_components": 93,
    "sklearn.random_projection.SparseRandomProjection.__init__.dense_output": 93,
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.alpha": 93,
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.__init__.base_estimator": 92,
    "sklearn.cluster._kmeans.MiniBatchKMeans.fit.X": 92,
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.max_leaf_nodes": 91,
    "sklearn.svm._classes.NuSVC.__init__.probability": 91,
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.max_features": 90,
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.dtype": 90,
    "sklearn.preprocessing._encoders.OrdinalEncoder.transform.X": 89,
    "sklearn.tree._export.export_graphviz.class_names": 89,
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.min_weight_fraction_leaf": 88,
    "sklearn.metrics._classification.classification_report.digits": 88,
    "sklearn.linear_model._ridge.RidgeClassifier.fit.X": 88,
    "sklearn.linear_model._ridge.RidgeClassifier.fit.y": 88,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.hidden_layer_sizes": 87,
    "sklearn.random_projection.GaussianRandomProjection.__init__.eps": 87,
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.__init__.reg_param": 87,
    "sklearn.model_selection._validation.cross_validate.n_jobs": 87,
    "sklearn.svm._classes.LinearSVC.__init__.random_state": 86,
    "sklearn.ensemble._weight_boosting.AdaBoostRegressor.__init__.random_state": 86,
    "sklearn.cluster._dbscan.DBSCAN.__init__.min_samples": 86,
    "sklearn.linear_model._logistic.LogisticRegression.__init__.fit_intercept": 85,
    "sklearn.random_projection.SparseRandomProjection.__init__.random_state": 85,
    "sklearn.pipeline.FeatureUnion.fit_transform.X": 85,
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.max_iter": 84,
    "sklearn.tree._classes.DecisionTreeClassifier.__init__.min_samples_leaf": 83,
    "sklearn.preprocessing._encoders.OneHotEncoder.get_feature_names.input_features": 83,
    "sklearn.random_projection.GaussianRandomProjection.__init__.random_state": 82,
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.reg_covar": 81,
    "sklearn.multioutput.MultiOutputRegressor.__init__.estimator": 81,
    "sklearn.decomposition._pca.PCA.__init__.svd_solver": 81,
    "sklearn.kernel_ridge.KernelRidge.__init__.kernel": 81,
    "sklearn.preprocessing._data.StandardScaler.__init__.copy": 81,
    "sklearn.svm._classes.LinearSVC.__init__.C": 80,
    "sklearn.model_selection._validation.cross_val_score.verbose": 80,
    "sklearn.manifold._t_sne.TSNE.__init__.method": 80,
    "sklearn.model_selection._search.RandomizedSearchCV.__init__.return_train_score": 79,
    "sklearn.metrics._regression.explained_variance_score.y_true": 79,
    "sklearn.metrics._regression.explained_variance_score.y_pred": 79,
    "sklearn.ensemble._weight_boosting.AdaBoostRegressor.fit.X": 78,
    "sklearn.ensemble._weight_boosting.AdaBoostRegressor.fit.y": 78,
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.warm_start": 78,
    "sklearn.neighbors._unsupervised.NearestNeighbors.__init__.n_neighbors": 78,
    "sklearn.model_selection._split.TimeSeriesSplit.split.X": 77,
    "sklearn.cluster._kmeans.MiniBatchKMeans.__init__.batch_size": 77,
    "sklearn.ensemble._bagging.BaggingRegressor.__init__.base_estimator": 77,
    "sklearn.ensemble._bagging.BaggingRegressor.__init__.n_estimators": 77,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.verbose": 76,
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.min_impurity_decrease": 76,
    "sklearn.feature_selection._from_model.SelectFromModel.fit.X": 76,
    "sklearn.feature_selection._from_model.SelectFromModel.fit.y": 76,
    "sklearn.kernel_ridge.KernelRidge.__init__.alpha": 76,
    "sklearn.preprocessing._data.StandardScaler.__init__.with_std": 76,
    "sklearn.linear_model._bayes.BayesianRidge.fit.X": 75,
    "sklearn.linear_model._bayes.BayesianRidge.fit.y": 75,
    "sklearn.ensemble._bagging.BaggingRegressor.predict.X": 75,
    "sklearn.preprocessing._data.minmax_scale.feature_range": 75,
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.tol": 74,
    "sklearn.linear_model._base.LinearRegression.__init__.copy_X": 74,
    "sklearn.linear_model._coordinate_descent.Lasso.__init__.max_iter": 73,
    "sklearn.feature_selection._rfe.RFECV.__init__.estimator": 73,
    "sklearn.svm._classes.LinearSVC.__init__.dual": 73,
    "sklearn.model_selection._validation.learning_curve.scoring": 73,
    "sklearn.datasets._samples_generator.make_classification.n_samples": 73,
    "sklearn.feature_extraction.text.CountVectorizer.__init__.strip_accents": 73,
    "sklearn.svm._classes.LinearSVC.__init__.max_iter": 72,
    "sklearn.metrics._scorer.make_scorer.needs_proba": 72,
    "sklearn.feature_selection._rfe.RFECV.__init__.cv": 71,
    "sklearn.decomposition._truncated_svd.TruncatedSVD.__init__.tol": 71,
    "sklearn.datasets._samples_generator.make_classification.n_features": 71,
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.means_init": 71,
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.min_samples_split": 70,
    "sklearn.neighbors._classification.KNeighborsClassifier.__init__.algorithm": 69,
    "sklearn.datasets._samples_generator.make_classification.n_informative": 69,
    "sklearn.feature_selection._mutual_info.mutual_info_classif.X": 69,
    "sklearn.feature_selection._mutual_info.mutual_info_classif.y": 69,
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.precisions_init": 69,
    "sklearn.multioutput.MultiOutputClassifier.__init__.estimator": 68,
    "sklearn.feature_selection._from_model.SelectFromModel.__init__.threshold": 68,
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.cv": 68,
    "sklearn.feature_selection._rfe.RFECV.fit.X": 68,
    "sklearn.feature_selection._rfe.RFECV.fit.y": 68,
    "sklearn.preprocessing._encoders.OneHotEncoder.__init__.drop": 66,
    "sklearn.ensemble._weight_boosting.AdaBoostRegressor.predict.X": 66,
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.loss": 66,
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.encoding": 65,
    "sklearn.ensemble._stacking.StackingRegressor.__init__.estimators": 65,
    "sklearn.decomposition._nmf.NMF.__init__.n_components": 65,
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.bootstrap": 64,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.max_iter": 64,
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix.cmap": 64,
    "sklearn.cluster._dbscan.DBSCAN.fit.X": 64,
    "sklearn.preprocessing._data.minmax_scale.axis": 64,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.learning_rate": 63,
    "sklearn.ensemble._bagging.BaggingClassifier.__init__.random_state": 63,
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.verbose": 62,
    "sklearn.svm._classes.SVC.__init__.decision_function_shape": 62,
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.warm_start": 61,
    "sklearn.model_selection._split.GroupShuffleSplit.__init__.n_splits": 61,
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.verbose": 61,
    "sklearn.neighbors._regression.KNeighborsRegressor.__init__.weights": 61,
    "sklearn.preprocessing._data.PolynomialFeatures.__init__.interaction_only": 61,
    "sklearn.covariance._shrunk_covariance.OAS.fit.X": 61,
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.alphas": 60,
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict_proba.X": 60,
    "sklearn.feature_selection._rfe.RFECV.__init__.step": 60,
    "sklearn.feature_selection._mutual_info.mutual_info_regression.X": 60,
    "sklearn.feature_selection._mutual_info.mutual_info_regression.y": 60,
    "sklearn.metrics._classification.classification_report.output_dict": 60,
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.verbose": 59,
    "sklearn.model_selection._split.GroupShuffleSplit.__init__.test_size": 59,
    "sklearn.preprocessing._encoders.OneHotEncoder.__init__.dtype": 59,
    "sklearn.utils.validation.check_array.array": 59,
    "sklearn.metrics._ranking.label_ranking_average_precision_score.y_true": 59,
    "sklearn.metrics._ranking.label_ranking_average_precision_score.y_score": 59,
    "sklearn.tree._classes.DecisionTreeClassifier.__init__.min_samples_split": 58,
    "sklearn.tree._classes.DecisionTreeClassifier.__init__.class_weight": 58,
    "sklearn.ensemble._voting.VotingRegressor.__init__.estimators": 58,
    "sklearn.kernel_ridge.KernelRidge.__init__.degree": 58,
    "sklearn.metrics._classification.precision_recall_fscore_support.y_true": 58,
    "sklearn.metrics._classification.precision_recall_fscore_support.y_pred": 58,
    "sklearn.tree._export.export_graphviz.max_depth": 58,
    "sklearn.datasets._samples_generator.make_classification.random_state": 58,
    "sklearn.preprocessing._function_transformer.FunctionTransformer.__init__.kw_args": 58,
    "sklearn.tree._classes.DecisionTreeRegressor.__init__.criterion": 57,
    "sklearn.metrics._classification.multilabel_confusion_matrix.y_true": 57,
    "sklearn.metrics._classification.multilabel_confusion_matrix.y_pred": 57,
    "sklearn.feature_selection._rfe.RFECV.__init__.scoring": 57,
    "sklearn.datasets._samples_generator.make_classification.n_redundant": 57,
    "sklearn.neighbors._regression.KNeighborsRegressor.__init__.n_jobs": 57,
    "sklearn.model_selection._validation.cross_val_predict.method": 56,
    "sklearn.feature_extraction.text.TfidfTransformer.fit.X": 56,
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.random_state": 56,
    "sklearn.kernel_ridge.KernelRidge.__init__.coef0": 56,
    "sklearn.linear_model._ridge.Ridge.__init__.copy_X": 56,
    "sklearn.preprocessing._discretization.KBinsDiscretizer.__init__.n_bins": 56,
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.cv": 55,
    "sklearn.tree._classes.DecisionTreeRegressor.__init__.min_samples_split": 55,
    "sklearn.ensemble._weight_boosting.AdaBoostRegressor.__init__.learning_rate": 55,
    "sklearn.metrics._classification.cohen_kappa_score.labels": 55,
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.solver": 55,
    "sklearn.decomposition._nmf.NMF.__init__.random_state": 55,
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.__init__.sparse": 54,
    "sklearn.model_selection._split.GroupShuffleSplit.split.groups": 54,
    "sklearn.model_selection._split.GroupShuffleSplit.split.X": 54,
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.verbose": 54,
    "sklearn.tree._classes.DecisionTreeRegressor.__init__.max_leaf_nodes": 54,
    "sklearn.feature_selection._base.SelectorMixin.get_support.indices": 54,
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.n_components": 54,
    "sklearn.feature_selection._mutual_info.mutual_info_classif.random_state": 54,
    "sklearn.tree._classes.DecisionTreeRegressor.__init__.min_samples_leaf": 52,
    "sklearn.svm._classes.NuSVC.__init__.kernel": 52,
    "sklearn.tree._export.export_graphviz.special_characters": 52,
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.kernel": 52,
    "sklearn.ensemble._bagging.BaggingRegressor.__init__.random_state": 52,
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.random_state": 52,
    "sklearn.neighbors._kde.KernelDensity.score_samples.X": 52,
    "sklearn.metrics._classification.f1_score.zero_division": 52,
    "sklearn.model_selection._split.GroupShuffleSplit.__init__.random_state": 51,
    "sklearn.ensemble._bagging.BaggingClassifier.predict.X": 51,
    "sklearn.model_selection._search.RandomizedSearchCV.__init__.refit": 51,
    "sklearn.svm._classes.NuSVC.__init__.random_state": 51,
    "sklearn.preprocessing._label.MultiLabelBinarizer.transform.y": 51,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.activation": 50,
    "sklearn.utils.validation.check_is_fitted.estimator": 50,
    "sklearn.utils.validation.check_is_fitted.attributes": 50,
    "sklearn.svm._classes.NuSVC.__init__.gamma": 50,
    "sklearn.feature_selection._base.SelectorMixin.inverse_transform.X": 50,
    "sklearn.preprocessing._discretization.KBinsDiscretizer.__init__.encode": 50,
    "sklearn.covariance._graph_lasso.GraphicalLasso.fit.X": 50,
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix.display_labels": 50,
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.max_samples": 49,
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.predict_proba.X": 49,
    "sklearn.multiclass.OneVsRestClassifier.predict_proba.X": 49,
    "sklearn.impute._knn.KNNImputer.__init__.n_neighbors": 49,
    "sklearn.ensemble._voting.VotingClassifier.__init__.weights": 49,
    "sklearn.preprocessing._data.RobustScaler.fit.X": 48,
    "sklearn.ensemble._stacking.StackingClassifier.__init__.estimators": 48,
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.__init__.algorithm": 48,
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.l1_ratio": 48,
    "sklearn.svm._classes.NuSVC.__init__.degree": 48,
    "sklearn.ensemble._stacking.StackingRegressor.__init__.final_estimator": 48,
    "sklearn.preprocessing._data.Normalizer.fit.X": 48,
    "sklearn.ensemble._bagging.BaggingRegressor.__init__.max_samples": 48,
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.n_jobs": 48,
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.n_features": 48,
    "sklearn.preprocessing._encoders.OrdinalEncoder.__init__.dtype": 47,
    "sklearn.cluster._birch.Birch.fit.X": 47,
    "sklearn.feature_selection._rfe.RFE.__init__.n_features_to_select": 47,
    "sklearn.neighbors._kde.KernelDensity.fit.X": 47,
    "sklearn.neighbors._kde.KernelDensity.__init__.bandwidth": 47,
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.n_components": 47,
    "sklearn.ensemble._stacking.StackingRegressor.fit.X": 47,
    "sklearn.ensemble._stacking.StackingRegressor.fit.y": 47,
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.ngram_range": 47,
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.criterion": 47,
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.min_samples_leaf": 46,
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.min_weight_fraction_leaf": 45,
    "sklearn.pipeline.FeatureUnion.fit.X": 45,
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.tol": 45,
    "sklearn.linear_model._base.LinearRegression.fit.sample_weight": 45,
    "sklearn.ensemble._weight_boosting.AdaBoostRegressor.__init__.base_estimator": 45,
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.__init__.assume_centered": 45,
    "sklearn.pipeline.Pipeline.fit_transform.y": 44,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.tol": 44,
    "sklearn.metrics._classification.accuracy_score.normalize": 44,
    "sklearn.model_selection._split.StratifiedShuffleSplit.__init__.train_size": 44,
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.cv": 44,
    "sklearn.svm._classes.NuSVC.__init__.nu": 44,
    "sklearn.tree._export.export_graphviz.precision": 44,
    "sklearn.datasets._samples_generator.make_classification.n_classes": 44,
    "sklearn.datasets._samples_generator.make_classification.n_clusters_per_class": 44,
    "sklearn.datasets._samples_generator.make_classification.flip_y": 44,
    "sklearn.metrics._plot.roc_curve.plot_roc_curve.estimator": 43,
    "sklearn.metrics._plot.roc_curve.plot_roc_curve.X": 43,
    "sklearn.metrics._plot.roc_curve.plot_roc_curve.y": 43,
    "sklearn.tree._classes.DecisionTreeClassifier.__init__.max_features": 43,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.random_state": 43,
    "sklearn.linear_model._logistic.LogisticRegression.__init__.warm_start": 43,
    "sklearn.svm._classes.NuSVC.__init__.coef0": 43,
    "sklearn.metrics._classification.precision_recall_fscore_support.average": 43,
    "sklearn.feature_selection._rfe.RFE.__init__.step": 43,
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.learning_method": 43,
    "sklearn.decomposition._nmf.NMF.fit_transform.X": 43,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.learning_rate_init": 43,
    "sklearn.preprocessing._discretization.KBinsDiscretizer.__init__.strategy": 43,
    "sklearn.cluster._dbscan.DBSCAN.fit_predict.X": 43,
    "sklearn.tree._export.plot_tree.decision_tree": 42,
    "sklearn.ensemble._stacking.StackingClassifier.__init__.final_estimator": 42,
    "sklearn.manifold._t_sne.TSNE.__init__.angle": 42,
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.min_impurity_split": 42,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.solver": 42,
    "sklearn.metrics._regression.mean_squared_error.sample_weight": 42,
    "sklearn.preprocessing._label.MultiLabelBinarizer.fit.y": 42,
    "sklearn.metrics.cluster._unsupervised.silhouette_score.X": 42,
    "sklearn.metrics.cluster._unsupervised.silhouette_score.labels": 42,
    "sklearn.tree._export.export_graphviz.impurity": 42,
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.penalty": 42,
    "sklearn.ensemble._voting.VotingClassifier.__init__.n_jobs": 41,
    "sklearn.cluster._kmeans.KMeans.__init__.n_jobs": 41,
    "sklearn.dummy.DummyRegressor.__init__.strategy": 41,
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.decode_error": 41,
    "sklearn.linear_model._logistic.LogisticRegression.__init__.intercept_scaling": 41,
    "sklearn.preprocessing._data.normalize.norm": 41,
    "sklearn.preprocessing._data.PowerTransformer.fit_transform.X": 40,
    "sklearn.ensemble._stacking.StackingClassifier.fit.X": 40,
    "sklearn.ensemble._stacking.StackingClassifier.fit.y": 40,
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.alphas": 40,
    "sklearn.feature_extraction.text.TfidfTransformer.__init__.use_idf": 40,
    "sklearn.manifold._t_sne.TSNE.__init__.learning_rate": 40,
    "sklearn.cluster._kmeans.KMeans.transform.X": 40,
    "sklearn.tree._classes.DecisionTreeClassifier.__init__.max_leaf_nodes": 40,
    "sklearn.utils.extmath.safe_sparse_dot.a": 40,
    "sklearn.utils.extmath.safe_sparse_dot.b": 40,
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.min_impurity_decrease": 39,
    "sklearn.preprocessing._encoders.OrdinalEncoder.fit.X": 39,
    "sklearn.manifold._t_sne.TSNE.__init__.n_jobs": 39,
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.max_iter": 39,
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.max_iter": 39,
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.random_state": 39,
    "sklearn.preprocessing._data.RobustScaler.__init__.quantile_range": 39,
    "sklearn.ensemble._voting.VotingRegressor.fit.X": 39,
    "sklearn.ensemble._voting.VotingRegressor.fit.y": 39,
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.max_iter": 39,
    "sklearn.kernel_ridge.KernelRidge.predict.X": 39,
    "sklearn.svm._classes.LinearSVC.__init__.penalty": 39,
    "sklearn.metrics._ranking.roc_auc_score.multi_class": 39,
    "sklearn.feature_extraction.text.TfidfTransformer.__init__.norm": 38,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.verbose": 38,
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.min_samples_split": 38,
    "sklearn.model_selection._validation.cross_val_predict.n_jobs": 38,
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.Cs": 38,
    "sklearn.preprocessing._encoders.OrdinalEncoder.__init__.categories": 38,
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.max_samples": 38,
    "sklearn.metrics._classification.recall_score.zero_division": 38,
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.class_weight": 37,
    "sklearn.tree._classes.DecisionTreeClassifier.__init__.splitter": 37,
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.n_jobs": 37,
    "sklearn.metrics._classification.precision_score.zero_division": 37,
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.vocabulary": 37,
    "sklearn.utils.validation.check_random_state.seed": 37,
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.norm": 37,
    "sklearn.svm._classes.LinearSVC.__init__.tol": 36,
    "sklearn.preprocessing._label.label_binarize.y": 36,
    "sklearn.cluster._agglomerative.AgglomerativeClustering.__init__.n_clusters": 36,
    "sklearn.metrics._classification.confusion_matrix.normalize": 36,
    "sklearn.preprocessing._data.MinMaxScaler.__init__.copy": 36,
    "sklearn.neighbors._unsupervised.NearestNeighbors.__init__.metric": 36,
    "sklearn.preprocessing._discretization.KBinsDiscretizer.transform.X": 36,
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.stop_words": 36,
    "sklearn.naive_bayes.BernoulliNB.__init__.alpha": 35,
    "sklearn.cluster._birch.Birch.__init__.n_clusters": 35,
    "sklearn.impute._iterative.IterativeImputer.fit_transform.X": 35,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.alpha": 35,
    "sklearn.metrics._classification.hamming_loss.y_true": 35,
    "sklearn.metrics._classification.hamming_loss.y_pred": 35,
    "sklearn.feature_selection._univariate_selection.chi2.X": 35,
    "sklearn.feature_selection._univariate_selection.chi2.y": 35,
    "sklearn.preprocessing._data.MaxAbsScaler.transform.X": 35,
    "sklearn.metrics.pairwise.linear_kernel.X": 35,
    "sklearn.metrics.pairwise.linear_kernel.Y": 35,
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.min_impurity_split": 34,
    "sklearn.tree._export.plot_tree.filled": 34,
    "sklearn.preprocessing._label.label_binarize.classes": 34,
    "sklearn.ensemble._voting.VotingRegressor.predict.X": 34,
    "sklearn.utils.shuffle.n_samples": 34,
    "sklearn.neighbors._unsupervised.NearestNeighbors.__init__.algorithm": 34,
    "sklearn.ensemble._stacking.StackingClassifier.predict.X": 33,
    "sklearn.linear_model._coordinate_descent.Lasso.__init__.normalize": 33,
    "sklearn.ensemble._bagging.BaggingClassifier.__init__.max_samples": 33,
    "sklearn.preprocessing._data.Binarizer.transform.X": 33,
    "sklearn.utils.class_weight.compute_class_weight.y": 33,
    "sklearn.utils.class_weight.compute_class_weight.classes": 33,
    "sklearn.ensemble._bagging.BaggingClassifier.predict_proba.X": 33,
    "sklearn.ensemble._iforest.IsolationForest.__init__.random_state": 32,
    "sklearn.svm._classes.SVR.__init__.max_iter": 32,
    "sklearn.dummy.DummyClassifier.__init__.strategy": 32,
    "sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay.__init__.confusion_matrix": 32,
    "sklearn.metrics.pairwise.euclidean_distances.X": 32,
    "sklearn.model_selection._validation.validation_curve.estimator": 32,
    "sklearn.model_selection._validation.validation_curve.X": 32,
    "sklearn.model_selection._validation.validation_curve.y": 32,
    "sklearn.svm._classes.SVR.__init__.tol": 32,
    "sklearn.model_selection._split.TimeSeriesSplit.split.y": 32,
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.alpha": 32,
    "sklearn.cluster._birch.Birch.__init__.threshold": 32,
    "sklearn.decomposition._factor_analysis.FactorAnalysis.__init__.n_components": 31,
    "sklearn.svm._classes.SVR.__init__.degree": 31,
    "sklearn.linear_model._coordinate_descent.Lasso.__init__.fit_intercept": 31,
    "sklearn.ensemble._iforest.IsolationForest.__init__.contamination": 31,
    "sklearn.dummy.DummyClassifier.fit.X": 31,
    "sklearn.dummy.DummyClassifier.fit.y": 31,
    "sklearn.multioutput.MultiOutputClassifier.fit.X": 31,
    "sklearn.multioutput.MultiOutputClassifier.fit.Y": 31,
    "sklearn.compose._column_transformer.ColumnTransformer.fit.X": 31,
    "sklearn.cluster._birch.Birch.__init__.branching_factor": 31,
    "sklearn.tree._export.plot_tree.feature_names": 30,
    "sklearn.metrics._ranking.average_precision_score.average": 30,
    "sklearn.tree._classes.DecisionTreeRegressor.__init__.max_features": 30,
    "sklearn.impute._iterative.IterativeImputer.__init__.random_state": 30,
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.lowercase": 30,
    "sklearn.metrics._classification.classification_report.labels": 30,
    "sklearn.utils.validation.check_array.dtype": 30,
    "sklearn.kernel_ridge.KernelRidge.fit.X": 30,
    "sklearn.kernel_ridge.KernelRidge.fit.y": 30,
    "sklearn.linear_model._ridge.RidgeClassifier.__init__.random_state": 29,
    "sklearn.cluster._kmeans.MiniBatchKMeans.__init__.random_state": 29,
    "sklearn.feature_selection._mutual_info.mutual_info_regression.discrete_features": 29,
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.verbose": 29,
    "sklearn.cluster._dbscan.DBSCAN.__init__.metric": 29,
    "sklearn.feature_selection._rfe.RFE.predict.X": 29,
    "sklearn.decomposition._lda.LatentDirichletAllocation.fit.X": 29,
    "sklearn.ensemble._iforest.IsolationForest.fit.X": 28,
    "sklearn.model_selection._validation.cross_val_score.error_score": 28,
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.oob_score": 28,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.early_stopping": 28,
    "sklearn.metrics._regression.mean_absolute_error.sample_weight": 28,
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.max_iter": 28,
    "sklearn.model_selection._validation.validation_curve.scoring": 28,
    "sklearn.svm._classes.LinearSVR.fit.X": 28,
    "sklearn.svm._classes.LinearSVR.fit.y": 28,
    "sklearn.preprocessing._encoders.OrdinalEncoder.__init__.handle_unknown": 28,
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.scoring": 28,
    "sklearn.feature_selection._rfe.RFECV.__init__.n_jobs": 28,
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.warm_start": 28,
    "sklearn.datasets._samples_generator.make_classification.class_sep": 28,
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.eta0": 27,
    "sklearn.cluster._kmeans.KMeans.__init__.tol": 27,
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.warm_start": 27,
    "sklearn.preprocessing._data.PowerTransformer.transform.X": 27,
    "sklearn.impute._iterative.IterativeImputer.__init__.max_iter": 27,
    "sklearn.model_selection._validation.validation_curve.cv": 27,
    "sklearn.preprocessing._data.Binarizer.fit.X": 27,
    "sklearn.model_selection._validation.cross_validate.verbose": 27,
    "sklearn.model_selection._validation.cross_validate.return_estimator": 27,
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.penalty": 27,
    "sklearn.feature_selection._rfe.RFECV.__init__.verbose": 27,
    "sklearn.cluster._birch.Birch.__init__.compute_labels": 27,
    "sklearn.ensemble._iforest.IsolationForest.predict.X": 26,
    "sklearn.neighbors._regression.KNeighborsRegressor.__init__.algorithm": 26,
    "sklearn.neighbors._kde.KernelDensity.__init__.kernel": 26,
    "sklearn.metrics._regression.median_absolute_error.y_true": 26,
    "sklearn.metrics._regression.median_absolute_error.y_pred": 26,
    "sklearn.linear_model._coordinate_descent.ElasticNet.__init__.normalize": 26,
    "sklearn.feature_extraction.text.HashingVectorizer.transform.X": 26,
    "sklearn.pipeline.make_union.n_jobs": 26,
    "sklearn.model_selection._search.ParameterGrid.__init__.param_grid": 26,
    "sklearn.decomposition._factor_analysis.FactorAnalysis.__init__.random_state": 25,
    "sklearn.dummy.DummyRegressor.fit.X": 25,
    "sklearn.dummy.DummyRegressor.fit.y": 25,
    "sklearn.dummy.DummyRegressor.predict.X": 25,
    "sklearn.calibration.calibration_curve.n_bins": 25,
    "sklearn.calibration.calibration_curve.y_true": 25,
    "sklearn.calibration.calibration_curve.y_prob": 25,
    "sklearn.neighbors._regression.KNeighborsRegressor.__init__.p": 25,
    "sklearn.svm._classes.NuSVR.__init__.C": 25,
    "sklearn.preprocessing._data.PowerTransformer.__init__.method": 25,
    "sklearn.feature_selection._mutual_info.mutual_info_regression.random_state": 25,
    "sklearn.ensemble._bagging.BaggingClassifier.__init__.n_jobs": 25,
    "sklearn.dummy.DummyClassifier.predict.X": 25,
    "sklearn.inspection._permutation_importance.permutation_importance.estimator": 25,
    "sklearn.inspection._permutation_importance.permutation_importance.X": 25,
    "sklearn.inspection._permutation_importance.permutation_importance.y": 25,
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.fit_inverse_transform": 25,
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.learning_rate": 24,
    "sklearn.svm._classes.LinearSVC.__init__.loss": 24,
    "sklearn.metrics._classification.multilabel_confusion_matrix.labels": 24,
    "sklearn.compose._column_transformer.make_column_transformer.remainder": 24,
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix.normalize": 24,
    "sklearn.neighbors._regression.KNeighborsRegressor.__init__.leaf_size": 24,
    "sklearn.manifold._t_sne.TSNE.__init__.metric": 24,
    "sklearn._config.set_config.display": 24,
    "sklearn.metrics._ranking.label_ranking_average_precision_score.sample_weight": 24,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.learning_rate": 24,
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.min_weight_fraction_leaf": 24,
    "sklearn.cluster._kmeans.KMeans.fit_transform.X": 24,
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.loss": 24,
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.gamma": 24,
    "sklearn.base.ClusterMixin.fit_predict.X": 24,
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.shuffle": 23,
    "sklearn.ensemble._bagging.BaggingClassifier.__init__.max_features": 23,
    "sklearn.compose._target.TransformedTargetRegressor.__init__.regressor": 23,
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.max_iter": 23,
    "sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay.__init__.display_labels": 23,
    "sklearn.tree._export.export_graphviz.rotate": 23,
    "sklearn.svm._classes.NuSVR.__init__.nu": 23,
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.__init__.n_components": 23,
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.predict.X": 23,
    "sklearn.impute._iterative.IterativeImputer.transform.X": 23,
    "sklearn.metrics._classification.balanced_accuracy_score.y_true": 23,
    "sklearn.metrics._classification.balanced_accuracy_score.y_pred": 23,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.learning_rate_init": 23,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.predict_proba.X": 23,
    "sklearn.preprocessing._label.LabelBinarizer.inverse_transform.Y": 23,
    "sklearn.model_selection._validation.cross_val_score.groups": 23,
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix.values_format": 23,
    "sklearn.metrics._regression.mean_squared_error.multioutput": 23,
    "sklearn.model_selection._validation.cross_val_predict.verbose": 22,
    "sklearn.svm._classes.NuSVR.__init__.gamma": 22,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.batch_size": 22,
    "sklearn.svm._classes.LinearSVC.__init__.verbose": 22,
    "sklearn.pipeline.Pipeline.__init__.verbose": 22,
    "sklearn.cluster._agglomerative.AgglomerativeClustering.__init__.linkage": 22,
    "sklearn.feature_extraction._hash.FeatureHasher.__init__.input_type": 22,
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.n_components": 22,
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.multi_class": 22,
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.learning_offset": 22,
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.n_iter_no_change": 22,
    "sklearn.metrics._classification.f1_score.pos_label": 22,
    "sklearn.metrics._regression.max_error.y_true": 22,
    "sklearn.metrics._regression.max_error.y_pred": 22,
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.l1_ratio": 21,
    "sklearn.svm._classes.SVR.__init__.coef0": 21,
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.min_weight_fraction_leaf": 21,
    "sklearn.utils.validation.check_X_y.X": 21,
    "sklearn.utils.validation.check_X_y.y": 21,
    "sklearn.tree._classes.DecisionTreeRegressor.__init__.splitter": 21,
    "sklearn.impute._base.SimpleImputer.__init__.add_indicator": 21,
    "sklearn.ensemble._weight_boosting.AdaBoostRegressor.__init__.loss": 21,
    "sklearn.cluster._kmeans.MiniBatchKMeans.__init__.init_size": 21,
    "sklearn.svm._classes.LinearSVR.__init__.random_state": 21,
    "sklearn.linear_model._coordinate_descent.Lasso.__init__.selection": 21,
    "sklearn.feature_extraction.text.TfidfTransformer.__init__.smooth_idf": 21,
    "sklearn.decomposition._kernel_pca.KernelPCA.fit_transform.X": 21,
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.max_leaf_nodes": 21,
    "sklearn.metrics._regression.r2_score.multioutput": 21,
    "sklearn.model_selection._validation.cross_val_score.fit_params": 21,
    "sklearn.metrics.pairwise.pairwise_distances.X": 21,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.batch_size": 20,
    "sklearn.linear_model._least_angle.LassoLarsCV.__init__.normalize": 20,
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform.X": 20,
    "sklearn.metrics.pairwise.euclidean_distances.Y": 20,
    "sklearn.cluster._agglomerative.AgglomerativeClustering.fit.X": 20,
    "sklearn.svm._classes.LinearSVR.__init__.C": 20,
    "sklearn.linear_model._coordinate_descent.Lasso.__init__.tol": 20,
    "sklearn.feature_extraction.text.CountVectorizer.__init__.decode_error": 20,
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.random_state": 20,
    "sklearn.svm._classes.SVR.__init__.verbose": 20,
    "sklearn.svm._classes.LinearSVC.__init__.multi_class": 20,
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.eta0": 20,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet.__init__.alpha": 19,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet.__init__.random_state": 19,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet.__init__.l1_ratio": 19,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet.fit.X": 19,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet.fit.y": 19,
    "sklearn.linear_model._coordinate_descent.ElasticNet.__init__.selection": 19,
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.min_weight_fraction_leaf": 19,
    "sklearn.linear_model._logistic.LogisticRegressionCV.score.X": 19,
    "sklearn.linear_model._logistic.LogisticRegressionCV.score.y": 19,
    "sklearn.ensemble._stacking.StackingRegressor.__init__.cv": 19,
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.__init__.contamination": 19,
    "sklearn.base.OutlierMixin.fit_predict.X": 19,
    "sklearn.tree._export.plot_tree.class_names": 19,
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.init": 19,
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.verbose_interval": 19,
    "sklearn.feature_selection._mutual_info.mutual_info_classif.discrete_features": 19,
    "sklearn.preprocessing._label.MultiLabelBinarizer.__init__.classes": 18,
    "sklearn.mixture._gaussian_mixture.GaussianMixture.aic.X": 18,
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.max_leaf_nodes": 18,
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.warm_start": 18,
    "sklearn.utils.validation.check_X_y.accept_sparse": 18,
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.max_leaf_nodes": 18,
    "sklearn.neighbors._regression.KNeighborsRegressor.__init__.metric": 18,
    "sklearn.cluster._kmeans.MiniBatchKMeans.__init__.verbose": 18,
    "sklearn.svm._classes.NuSVR.__init__.tol": 18,
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.average": 18,
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.verbose": 18,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.shuffle": 18,
    "sklearn.compose._column_transformer.make_column_selector.__init__.dtype_include": 18,
    "sklearn.naive_bayes.BernoulliNB.__init__.fit_prior": 18,
    "sklearn.cluster._dbscan.DBSCAN.__init__.n_jobs": 18,
    "sklearn.cluster._agglomerative.AgglomerativeClustering.fit_predict.X": 18,
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.ccp_alpha": 17,
    "sklearn.naive_bayes.BernoulliNB.__init__.binarize": 17,
    "sklearn.compose._target.TransformedTargetRegressor.predict.X": 17,
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.tol": 17,
    "sklearn.preprocessing._data.QuantileTransformer.inverse_transform.X": 17,
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.fit_intercept": 17,
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.warm_start": 17,
    "sklearn.ensemble._bagging.BaggingRegressor.__init__.n_jobs": 17,
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.class_weight": 17,
    "sklearn.linear_model._bayes.BayesianRidge.__init__.compute_score": 17,
    "sklearn.decomposition._nmf.NMF.transform.X": 17,
    "sklearn.cluster._dbscan.DBSCAN.__init__.algorithm": 17,
    "sklearn.feature_selection._rfe.RFECV.__init__.min_features_to_select": 17,
    "sklearn.impute._iterative.IterativeImputer.fit.X": 17,
    "sklearn.naive_bayes.MultinomialNB.__init__.fit_prior": 17,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.early_stopping": 17,
    "sklearn.metrics._classification.cohen_kappa_score.sample_weight": 17,
    "sklearn.utils.multiclass.type_of_target.y": 17,
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.epsilon": 16,
    "sklearn.decomposition._factor_analysis.FactorAnalysis.fit.X": 16,
    "sklearn.preprocessing._data.Normalizer.__init__.copy": 16,
    "sklearn.preprocessing._encoders.OneHotEncoder.inverse_transform.X": 16,
    "sklearn.model_selection._validation.validation_curve.param_name": 16,
    "sklearn.model_selection._validation.validation_curve.param_range": 16,
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups.subset": 16,
    "sklearn.feature_selection._rfe.RFE.__init__.verbose": 16,
    "sklearn.pipeline.Pipeline.__init__.memory": 16,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.beta_1": 16,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.warm_start": 16,
    "sklearn.linear_model._ridge.RidgeClassifier.__init__.alpha": 16,
    "sklearn.cluster._kmeans.KMeans.__init__.algorithm": 16,
    "sklearn.datasets._svmlight_format_io.dump_svmlight_file.X": 16,
    "sklearn.datasets._svmlight_format_io.dump_svmlight_file.y": 16,
    "sklearn.datasets._svmlight_format_io.dump_svmlight_file.f": 16,
    "sklearn.dummy.DummyClassifier.score.X": 16,
    "sklearn.dummy.DummyClassifier.score.y": 16,
    "sklearn.ensemble._stacking.StackingClassifier.predict_proba.X": 16,
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.tokenizer": 16,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.max_iter": 16,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.validation_fraction": 16,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.learning_rate": 16,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.max_depth": 16,
    "sklearn.datasets._samples_generator.make_classification.n_repeated": 16,
    "sklearn.datasets._samples_generator.make_classification.weights": 16,
    "sklearn.linear_model._bayes.BayesianRidge.__init__.n_iter": 16,
    "sklearn.impute._knn.KNNImputer.__init__.weights": 16,
    "sklearn.metrics.pairwise.pairwise_distances.Y": 16,
    "sklearn.covariance._shrunk_covariance.LedoitWolf.fit.X": 16,
    "sklearn.cluster._kmeans.KMeans.__init__.verbose": 15,
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.tol": 15,
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.tol": 15,
    "sklearn.feature_extraction.image.extract_patches_2d.image": 15,
    "sklearn.feature_extraction.image.extract_patches_2d.patch_size": 15,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.fit.X": 15,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.fit.y": 15,
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.n_jobs": 15,
    "sklearn.linear_model._huber.HuberRegressor.fit.X": 15,
    "sklearn.linear_model._huber.HuberRegressor.fit.y": 15,
    "sklearn.cluster._kmeans.MiniBatchKMeans.__init__.n_init": 15,
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.predict.X": 15,
    "sklearn.metrics._ranking.roc_curve.drop_intermediate": 15,
    "sklearn.impute._knn.KNNImputer.transform.X": 15,
    "sklearn.preprocessing._data.scale.axis": 15,
    "sklearn.feature_selection._mutual_info.mutual_info_classif.n_neighbors": 15,
    "sklearn.ensemble._stacking.StackingRegressor.__init__.n_jobs": 15,
    "sklearn.svm._classes.SVR.__init__.cache_size": 15,
    "sklearn.svm._classes.SVR.__init__.shrinking": 15,
    "sklearn.ensemble._bagging.BaggingRegressor.__init__.max_features": 15,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.random_state": 15,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.validation_fraction": 15,
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.learning_rate": 15,
    "sklearn.compose._column_transformer.ColumnTransformer.__init__.sparse_threshold": 15,
    "sklearn.model_selection._split.check_cv.cv": 15,
    "sklearn.linear_model._ridge.RidgeClassifier.__init__.solver": 15,
    "sklearn.tree._classes.DecisionTreeRegressor.__init__.min_impurity_decrease": 14,
    "sklearn.ensemble._stacking.StackingClassifier.__init__.cv": 14,
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.min_impurity_decrease": 14,
    "sklearn.dummy.DummyClassifier.__init__.random_state": 14,
    "sklearn.linear_model._logistic.LogisticRegression.__init__.l1_ratio": 14,
    "sklearn.model_selection._split.PredefinedSplit.__init__.test_fold": 14,
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.power_t": 14,
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.fit.X": 14,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.beta_2": 14,
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.fit.X": 14,
    "sklearn.metrics._regression.r2_score.sample_weight": 14,
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.dtype": 14,
    "sklearn.decomposition._lda.LatentDirichletAllocation.transform.X": 14,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.tol": 14,
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.dual": 14,
    "sklearn.model_selection._split.StratifiedKFold.split.groups": 14,
    "sklearn.decomposition._fastica.FastICA.__init__.max_iter": 14,
    "sklearn.feature_selection._from_model.SelectFromModel.__init__.max_features": 14,
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.random_state": 14,
    "sklearn.tree._export.export_graphviz.proportion": 14,
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.init": 13,
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.bootstrap": 13,
    "sklearn.feature_selection._univariate_selection.f_regression.X": 13,
    "sklearn.feature_selection._univariate_selection.f_regression.y": 13,
    "sklearn.cluster._kmeans.MiniBatchKMeans.__init__.init": 13,
    "sklearn.cluster._kmeans.MiniBatchKMeans.__init__.max_iter": 13,
    "sklearn.preprocessing._encoders.OrdinalEncoder.__init__.unknown_value": 13,
    "sklearn.compose._target.TransformedTargetRegressor.__init__.func": 13,
    "sklearn.compose._target.TransformedTargetRegressor.__init__.inverse_func": 13,
    "sklearn.impute._base.SimpleImputer.__init__.copy": 13,
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.random_state": 13,
    "sklearn.linear_model._ridge.RidgeClassifier.__init__.class_weight": 13,
    "sklearn.metrics._classification.jaccard_score.y_true": 13,
    "sklearn.metrics._classification.jaccard_score.y_pred": 13,
    "sklearn.ensemble._iforest.IsolationForest.__init__.n_estimators": 13,
    "sklearn.multiclass.OneVsOneClassifier.__init__.estimator": 13,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.power_t": 13,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.shuffle": 13,
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.binary": 13,
    "sklearn.ensemble._gb.GradientBoostingRegressor.staged_predict.X": 13,
    "sklearn.model_selection._split.check_cv.y": 13,
    "sklearn.preprocessing._data.binarize.X": 12,
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.criterion": 12,
    "sklearn.preprocessing._data.Normalizer.__init__.norm": 12,
    "sklearn.compose._target.TransformedTargetRegressor.fit.X": 12,
    "sklearn.compose._target.TransformedTargetRegressor.fit.y": 12,
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.verbose": 12,
    "sklearn.tree._classes.DecisionTreeRegressor.__init__.min_weight_fraction_leaf": 12,
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.__init__.solver": 12,
    "sklearn.gaussian_process.kernels.RBF.__init__.length_scale": 12,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.validation_fraction": 12,
    "sklearn.decomposition._pca.PCA.__init__.copy": 12,
    "sklearn.feature_extraction.text.CountVectorizer.__init__.encoding": 12,
    "sklearn.ensemble._iforest.IsolationForest.__init__.max_samples": 12,
    "sklearn.linear_model._huber.HuberRegressor.__init__.max_iter": 12,
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.token_pattern": 12,
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.verbose": 12,
    "sklearn.model_selection._split.GroupShuffleSplit.split.y": 12,
    "sklearn.preprocessing._data.PolynomialFeatures.fit.y": 12,
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.__init__.priors": 12,
    "sklearn.decomposition._nmf.NMF.fit.X": 12,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.momentum": 12,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.warm_start": 12,
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.fit_intercept": 12,
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.intercept_scaling": 12,
    "sklearn.preprocessing._discretization.KBinsDiscretizer.fit.X": 12,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.predict.X": 12,
    "sklearn.utils.validation.check_array.ensure_2d": 12,
    "sklearn.model_selection._split.check_cv.classifier": 12,
    "sklearn.neighbors._lof.LocalOutlierFactor.__init__.n_neighbors": 12,
    "sklearn.feature_extraction.text.TfidfTransformer.__init__.sublinear_tf": 11,
    "sklearn.linear_model._coordinate_descent.ElasticNet.__init__.precompute": 11,
    "sklearn.linear_model._coordinate_descent.ElasticNet.__init__.tol": 11,
    "sklearn.decomposition._sparse_pca.SparsePCA.__init__.n_components": 11,
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.oob_score": 11,
    "sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay.plot.ax": 11,
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.random_state": 11,
    "sklearn.preprocessing._data.RobustScaler.__init__.with_centering": 11,
    "sklearn.metrics._classification.hinge_loss.y_true": 11,
    "sklearn.metrics._classification.hinge_loss.pred_decision": 11,
    "sklearn.metrics._classification.log_loss.normalize": 11,
    "sklearn.svm._classes.LinearSVR.__init__.max_iter": 11,
    "sklearn.svm._classes.LinearSVC.__init__.class_weight": 11,
    "sklearn.model_selection._validation.validation_curve.verbose": 11,
    "sklearn.multioutput.MultiOutputRegressor.__init__.n_jobs": 11,
    "sklearn.datasets._svmlight_format_io.dump_svmlight_file.zero_based": 11,
    "sklearn.utils.validation.check_array.accept_sparse": 11,
    "sklearn.inspection._permutation_importance.permutation_importance.n_repeats": 11,
    "sklearn.naive_bayes.GaussianNB.__init__.priors": 11,
    "sklearn.naive_bayes.MultinomialNB.__init__.class_prior": 11,
    "sklearn.manifold._isomap.Isomap.__init__.n_components": 11,
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.decision_function.X": 11,
    "sklearn.linear_model._ransac.RANSACRegressor.predict.X": 11,
    "sklearn.decomposition._kernel_pca.KernelPCA.transform.X": 11,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.beta_1": 11,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.beta_2": 11,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.epsilon": 11,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.nesterovs_momentum": 11,
    "sklearn.feature_extraction._hash.FeatureHasher.__init__.n_features": 11,
    "sklearn.tree._export.plot_tree.rounded": 11,
    "sklearn.compose._column_transformer.ColumnTransformer.__init__.n_jobs": 11,
    "sklearn.cluster._agglomerative.AgglomerativeClustering.__init__.distance_threshold": 11,
    "sklearn.cluster._agglomerative.AgglomerativeClustering.__init__.affinity": 11,
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.estimator": 11,
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.X": 11,
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.features": 11,
    "sklearn.neighbors._lof.LocalOutlierFactor.__init__.contamination": 11,
    "sklearn.base.is_classifier.estimator": 11,
    "sklearn.feature_selection._rfe.RFE.predict_proba.X": 11,
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.alternate_sign": 11,
    "sklearn.utils.validation.check_array.force_all_finite": 11,
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.covariance_type": 11,
    "sklearn.inspection._permutation_importance.permutation_importance.scoring": 11,
    "sklearn.metrics._ranking.roc_auc_score.sample_weight": 10,
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.criterion": 10,
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.warm_start": 10,
    "sklearn.manifold._spectral_embedding.SpectralEmbedding.__init__.n_components": 10,
    "sklearn.pipeline.FeatureUnion.fit_transform.y": 10,
    "sklearn.decomposition._nmf.NMF.__init__.init": 10,
    "sklearn.svm._classes.NuSVR.__init__.kernel": 10,
    "sklearn.preprocessing._data.scale.with_mean": 10,
    "sklearn.preprocessing._data.scale.with_std": 10,
    "sklearn.impute._base.SimpleImputer.__init__.verbose": 10,
    "sklearn.naive_bayes.GaussianNB.__init__.var_smoothing": 10,
    "sklearn.compose._column_transformer.make_column_selector.__init__.dtype_exclude": 10,
    "sklearn.feature_selection._univariate_selection.f_classif.X": 10,
    "sklearn.feature_selection._univariate_selection.f_classif.y": 10,
    "sklearn.model_selection._validation.validation_curve.n_jobs": 10,
    "sklearn.neighbors._unsupervised.NearestNeighbors.__init__.n_jobs": 10,
    "sklearn.inspection._permutation_importance.permutation_importance.random_state": 10,
    "sklearn.model_selection._validation.cross_validate.groups": 10,
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.verbose": 10,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.predict.X": 10,
    "sklearn.model_selection._search.GridSearchCV.__init__.error_score": 10,
    "sklearn.linear_model._ransac.RANSACRegressor.fit.X": 10,
    "sklearn.linear_model._ransac.RANSACRegressor.fit.y": 10,
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.early_stopping": 10,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.min_samples_leaf": 10,
    "sklearn.linear_model._bayes.BayesianRidge.__init__.alpha_1": 10,
    "sklearn.linear_model._bayes.BayesianRidge.__init__.alpha_2": 10,
    "sklearn.linear_model._bayes.BayesianRidge.__init__.lambda_1": 10,
    "sklearn.linear_model._bayes.BayesianRidge.__init__.lambda_2": 10,
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.weights_init": 10,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.verbose": 10,
    "sklearn.linear_model._perceptron.Perceptron.__init__.random_state": 10,
    "sklearn.model_selection._split.TimeSeriesSplit.__init__.max_train_size": 10,
    "sklearn.preprocessing._data.normalize.copy": 10,
    "sklearn.pipeline.FeatureUnion.fit.y": 10,
    "sklearn.metrics.pairwise.pairwise_distances.metric": 10,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.max_depth": 10,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.learning_rate": 10,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.max_iter": 10,
    "sklearn.datasets._samples_generator.make_moons.noise": 10,
    "sklearn.linear_model._ridge.RidgeClassifier.__init__.tol": 10,
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.min_impurity_split": 9,
    "sklearn.decomposition._sparse_pca.SparsePCA.__init__.random_state": 9,
    "sklearn.metrics._ranking.roc_curve.sample_weight": 9,
    "sklearn.linear_model._coordinate_descent.ElasticNet.__init__.fit_intercept": 9,
    "sklearn.manifold._mds.MDS.__init__.n_components": 9,
    "sklearn.compose._target.TransformedTargetRegressor.__init__.transformer": 9,
    "sklearn.linear_model._ransac.RANSACRegressor.__init__.base_estimator": 9,
    "sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay.plot.cmap": 9,
    "sklearn.metrics._scorer.make_scorer.needs_threshold": 9,
    "sklearn.compose._column_transformer.ColumnTransformer.__init__.verbose": 9,
    "sklearn.feature_extraction.image.extract_patches_2d.max_patches": 9,
    "sklearn.compose._column_transformer.ColumnTransformer.fit_transform.y": 9,
    "sklearn.multioutput.MultiOutputClassifier.__init__.n_jobs": 9,
    "sklearn.manifold._t_sne.TSNE.__init__.early_exaggeration": 9,
    "sklearn.svm._classes.LinearSVR.__init__.epsilon": 9,
    "sklearn.linear_model._bayes.BayesianRidge.__init__.normalize": 9,
    "sklearn.utils.class_weight.compute_sample_weight.class_weight": 9,
    "sklearn.utils.class_weight.compute_sample_weight.y": 9,
    "sklearn.feature_selection._rfe.RFE.score.X": 9,
    "sklearn.feature_selection._rfe.RFE.score.y": 9,
    "sklearn.utils.validation.check_array.copy": 9,
    "sklearn.linear_model._ransac.RANSACRegressor.__init__.random_state": 9,
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.min_impurity_decrease": 9,
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.validation_fraction": 9,
    "sklearn.mixture._gaussian_mixture.GaussianMixture.bic.X": 9,
    "sklearn.cluster._spectral.SpectralClustering.__init__.n_clusters": 9,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.max_leaf_nodes": 9,
    "sklearn.preprocessing._data.MaxAbsScaler.fit.X": 9,
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.__init__.kernel": 9,
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.l1_ratio": 9,
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.fit_intercept": 9,
    "sklearn.cluster._birch.Birch.predict.X": 9,
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.coef0": 9,
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.ax": 9,
    "sklearn.decomposition._incremental_pca.IncrementalPCA.__init__.n_components": 9,
    "sklearn.decomposition._incremental_pca.IncrementalPCA.transform.X": 9,
    "sklearn.metrics._classification.precision_score.pos_label": 9,
    "sklearn.metrics._classification.recall_score.pos_label": 9,
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.predict.X": 9,
    "sklearn.datasets._samples_generator.make_moons.n_samples": 9,
    "sklearn.metrics._ranking.roc_auc_score.labels": 9,
    "sklearn.preprocessing._data.binarize.threshold": 8,
    "sklearn.ensemble._iforest.IsolationForest.__init__.n_jobs": 8,
    "sklearn.feature_extraction.image.PatchExtractor.__init__.patch_size": 8,
    "sklearn.feature_extraction.image.PatchExtractor.__init__.max_patches": 8,
    "sklearn.feature_extraction.image.PatchExtractor.__init__.random_state": 8,
    "sklearn.impute._iterative.IterativeImputer.__init__.estimator": 8,
    "sklearn.cross_decomposition._pls.PLSRegression.__init__.n_components": 8,
    "sklearn.preprocessing._data.PowerTransformer.inverse_transform.X": 8,
    "sklearn.base.BaseEstimator.get_params.deep": 8,
    "sklearn.ensemble._voting.VotingRegressor.__init__.n_jobs": 8,
    "sklearn.tree._classes.DecisionTreeRegressor.__init__.min_impurity_split": 8,
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.tol": 8,
    "sklearn.svm._classes.LinearSVC.__init__.fit_intercept": 8,
    "sklearn.model_selection._validation.learning_curve.return_times": 8,
    "sklearn.preprocessing._data.maxabs_scale.X": 8,
    "sklearn.metrics._classification.brier_score_loss.y_true": 8,
    "sklearn.metrics._classification.brier_score_loss.y_prob": 8,
    "sklearn.metrics._classification.log_loss.sample_weight": 8,
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.input": 8,
    "sklearn.svm._classes.LinearSVR.__init__.loss": 8,
    "sklearn.ensemble._bagging.BaggingClassifier.__init__.bootstrap": 8,
    "sklearn.tree._classes.DecisionTreeClassifier.__init__.min_weight_fraction_leaf": 8,
    "sklearn.tree._classes.DecisionTreeClassifier.__init__.min_impurity_split": 8,
    "sklearn.metrics.cluster._supervised.mutual_info_score.labels_true": 8,
    "sklearn.metrics.cluster._supervised.mutual_info_score.labels_pred": 8,
    "sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay.plot.include_values": 8,
    "sklearn.kernel_ridge.KernelRidge.__init__.gamma": 8,
    "sklearn.cluster._kmeans.KMeans.__init__.precompute_distances": 8,
    "sklearn.linear_model._ransac.RANSACRegressor.__init__.max_trials": 8,
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.min_impurity_split": 8,
    "sklearn.linear_model._coordinate_descent.ElasticNet.__init__.copy_X": 8,
    "sklearn.metrics.cluster._unsupervised.silhouette_score.metric": 8,
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.verbose": 8,
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.max_iter": 8,
    "sklearn.metrics._classification.zero_one_loss.y_true": 8,
    "sklearn.metrics._classification.zero_one_loss.y_pred": 8,
    "sklearn.linear_model._bayes.BayesianRidge.__init__.verbose": 8,
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.fit.X": 8,
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.fit.y": 8,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.l2_regularization": 8,
    "sklearn.preprocessing._data.normalize.return_norm": 8,
    "sklearn.metrics._regression.mean_absolute_error.multioutput": 8,
    "sklearn.ensemble._iforest.IsolationForest.decision_function.X": 8,
    "sklearn.svm._classes.SVC.__init__.break_ties": 8,
    "sklearn.preprocessing._data.quantile_transform.X": 8,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.random_state": 8,
    "sklearn.metrics.pairwise.manhattan_distances.X": 8,
    "sklearn.metrics.pairwise.manhattan_distances.Y": 8,
    "sklearn.preprocessing._encoders.OrdinalEncoder.inverse_transform.X": 8,
    "sklearn.metrics.cluster._supervised.homogeneity_score.labels_true": 8,
    "sklearn.metrics.cluster._supervised.homogeneity_score.labels_pred": 8,
    "sklearn.metrics.cluster._supervised.completeness_score.labels_true": 8,
    "sklearn.metrics.cluster._supervised.completeness_score.labels_pred": 8,
    "sklearn.utils.validation.check_array.estimator": 8,
    "sklearn.metrics._plot.precision_recall_curve.plot_precision_recall_curve.estimator": 7,
    "sklearn.metrics._plot.precision_recall_curve.plot_precision_recall_curve.X": 7,
    "sklearn.metrics._plot.precision_recall_curve.plot_precision_recall_curve.y": 7,
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.n_iter_no_change": 7,
    "sklearn.preprocessing._data.PowerTransformer.fit.X": 7,
    "sklearn.manifold._spectral_embedding.SpectralEmbedding.fit_transform.X": 7,
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.n_jobs": 7,
    "sklearn.svm._classes.LinearSVR.__init__.tol": 7,
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__.n_estimators": 7,
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__.random_state": 7,
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__.max_depth": 7,
    "sklearn.multioutput.RegressorChain.fit.X": 7,
    "sklearn.multioutput.RegressorChain.fit.Y": 7,
    "sklearn.svm._classes.LinearSVR.__init__.verbose": 7,
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.fit.X": 7,
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.fit.y": 7,
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.predict.X": 7,
    "sklearn.feature_extraction.text.HashingVectorizer.fit_transform.X": 7,
    "sklearn.preprocessing._label.MultiLabelBinarizer.__init__.sparse_output": 7,
    "sklearn.linear_model._ridge.RidgeClassifier.__init__.normalize": 7,
    "sklearn.preprocessing._data.scale.copy": 7,
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.verbose": 7,
    "sklearn.model_selection._split.LeaveOneGroupOut.split.X": 7,
    "sklearn.model_selection._split.LeaveOneGroupOut.split.y": 7,
    "sklearn.model_selection._split.LeaveOneGroupOut.split.groups": 7,
    "sklearn.cluster._kmeans.KMeans.__init__.copy_x": 7,
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.__init__.shrinkage": 7,
    "sklearn.svm._classes.OneClassSVM.__init__.kernel": 7,
    "sklearn.model_selection._search.GridSearchCV.__init__.pre_dispatch": 7,
    "sklearn.ensemble._bagging.BaggingRegressor.__init__.bootstrap": 7,
    "sklearn.cluster._spectral.SpectralClustering.__init__.affinity": 7,
    "sklearn.svm._classes.OneClassSVM.__init__.nu": 7,
    "sklearn.svm._classes.OneClassSVM.predict.X": 7,
    "sklearn.semi_supervised._label_propagation.LabelSpreading.__init__.gamma": 7,
    "sklearn.semi_supervised._label_propagation.LabelSpreading.__init__.kernel": 7,
    "sklearn.semi_supervised._label_propagation.LabelSpreading.__init__.max_iter": 7,
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.early_stopping": 7,
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.n_jobs": 7,
    "sklearn.datasets._samples_generator.make_classification.hypercube": 7,
    "sklearn.datasets._samples_generator.make_classification.shuffle": 7,
    "sklearn.linear_model._perceptron.Perceptron.__init__.max_iter": 7,
    "sklearn.decomposition._fastica.FastICA.fit.X": 7,
    "sklearn.decomposition._truncated_svd.TruncatedSVD.inverse_transform.X": 7,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.max_bins": 7,
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.shuffle": 7,
    "sklearn.linear_model._coordinate_descent.ElasticNet.__init__.positive": 7,
    "sklearn.metrics._classification.confusion_matrix.sample_weight": 7,
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.analyzer": 7,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.loss": 7,
    "sklearn.pipeline.make_pipeline.verbose": 7,
    "sklearn.decomposition._nmf.NMF.__init__.alpha": 7,
    "sklearn.metrics._classification.f1_score.sample_weight": 7,
    "sklearn.linear_model._coordinate_descent.Lasso.__init__.precompute": 7,
    "sklearn.ensemble._forest.RandomTreesEmbedding.transform.X": 7,
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.verbose": 7,
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.n_jobs": 7,
    "sklearn.linear_model._ridge.RidgeClassifierCV.fit.X": 7,
    "sklearn.linear_model._ridge.RidgeClassifierCV.fit.y": 7,
    "sklearn.model_selection._search.RandomizedSearchCV.__init__.error_score": 7,
    "sklearn.decomposition._fastica.FastICA.inverse_transform.X": 7,
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.ccp_alpha": 6,
    "sklearn.ensemble._stacking.StackingClassifier.__init__.passthrough": 6,
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.min_impurity_decrease": 6,
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.validation_fraction": 6,
    "sklearn.preprocessing._function_transformer.FunctionTransformer.transform.X": 6,
    "sklearn.manifold._mds.MDS.fit_transform.X": 6,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.max_iter": 6,
    "sklearn.manifold._mds.MDS.__init__.n_init": 6,
    "sklearn.manifold._spectral_embedding.SpectralEmbedding.__init__.n_neighbors": 6,
    "sklearn.feature_extraction.image.extract_patches_2d.random_state": 6,
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.__init__.tol": 6,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.fit.X": 6,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.fit.y": 6,
    "sklearn.linear_model._coordinate_descent.Lasso.__init__.positive": 6,
    "sklearn.impute._knn.KNNImputer.fit.X": 6,
    "sklearn.ensemble._iforest.IsolationForest.__init__.max_features": 6,
    "sklearn.ensemble._stacking.StackingRegressor.__init__.verbose": 6,
    "sklearn.svm._classes.OneClassSVM.fit.X": 6,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.momentum": 6,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.nesterovs_momentum": 6,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.epsilon": 6,
    "sklearn.cluster._spectral.SpectralClustering.__init__.assign_labels": 6,
    "sklearn.svm._classes.OneClassSVM.__init__.gamma": 6,
    "sklearn.tree._export.export_text.decision_tree": 6,
    "sklearn.decomposition._factor_analysis.FactorAnalysis.transform.X": 6,
    "sklearn.neighbors._regression.KNeighborsRegressor.__init__.metric_params": 6,
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.power_t": 6,
    "sklearn.linear_model._coordinate_descent.ElasticNet.__init__.warm_start": 6,
    "sklearn.metrics.cluster._supervised.adjusted_rand_score.labels_true": 6,
    "sklearn.metrics.cluster._supervised.adjusted_rand_score.labels_pred": 6,
    "sklearn.linear_model._bayes.ARDRegression.predict.X": 6,
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.warm_start": 6,
    "sklearn.metrics._regression.mean_absolute_percentage_error.y_true": 6,
    "sklearn.metrics._regression.mean_absolute_percentage_error.y_pred": 6,
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.n_alphas": 6,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.scoring": 6,
    "sklearn.decomposition._nmf.NMF.__init__.l1_ratio": 6,
    "sklearn.metrics._classification.jaccard_score.average": 6,
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix.ax": 6,
    "sklearn.pipeline.Pipeline.decision_function.X": 6,
    "sklearn.metrics._classification.accuracy_score.sample_weight": 6,
    "sklearn.ensemble._stacking.StackingClassifier.__init__.stack_method": 6,
    "sklearn.preprocessing._data.StandardScaler.fit.y": 5,
    "sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path.X": 5,
    "sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path.y": 5,
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.min_impurity_split": 5,
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.max_leaf_nodes": 5,
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.min_weight_fraction_leaf": 5,
    "sklearn.linear_model._bayes.BayesianRidge.__init__.fit_intercept": 5,
    "sklearn.manifold._mds.MDS.__init__.max_iter": 5,
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.max_samples": 5,
    "sklearn.tree._classes.DecisionTreeRegressor.__init__.ccp_alpha": 5,
    "sklearn.preprocessing._data.RobustScaler.__init__.with_scaling": 5,
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.normalize": 5,
    "sklearn.feature_selection._univariate_selection.SelectFpr.__init__.alpha": 5,
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.fit_transform.X": 5,
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.transform.X": 5,
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.__init__.n_components": 5,
    "sklearn.ensemble._voting.VotingRegressor.__init__.weights": 5,
    "sklearn.impute._iterative.IterativeImputer.__init__.min_value": 5,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.random_state": 5,
    "sklearn.svm._classes.LinearSVR.__init__.fit_intercept": 5,
    "sklearn.svm._classes.LinearSVR.__init__.dual": 5,
    "sklearn.gaussian_process.kernels.RBF.__init__.length_scale_bounds": 5,
    "sklearn.tree._classes.DecisionTreeClassifier.__init__.min_impurity_decrease": 5,
    "sklearn.neighbors._classification.KNeighborsClassifier.__init__.metric_params": 5,
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.ccp_alpha": 5,
    "sklearn.ensemble._bagging.BaggingRegressor.__init__.verbose": 5,
    "sklearn.manifold._isomap.Isomap.__init__.n_neighbors": 5,
    "sklearn.manifold._isomap.Isomap.transform.X": 5,
    "sklearn.cluster._spectral.SpectralClustering.fit_predict.X": 5,
    "sklearn.feature_selection._univariate_selection.GenericUnivariateSelect.__init__.mode": 5,
    "sklearn.feature_selection._univariate_selection.GenericUnivariateSelect.__init__.param": 5,
    "sklearn.metrics.cluster._unsupervised.davies_bouldin_score.X": 5,
    "sklearn.metrics.cluster._unsupervised.davies_bouldin_score.labels": 5,
    "sklearn.utils.extmath.cartesian.arrays": 5,
    "sklearn.cluster._mean_shift.MeanShift.fit.X": 5,
    "sklearn.datasets._samples_generator.make_classification.shift": 5,
    "sklearn.datasets._samples_generator.make_classification.scale": 5,
    "sklearn.cluster._kmeans.KMeans.fit.y": 5,
    "sklearn.linear_model._perceptron.Perceptron.__init__.eta0": 5,
    "sklearn.cluster._agglomerative.FeatureAgglomeration.__init__.n_clusters": 5,
    "sklearn.svm._classes.LinearSVC.__init__.intercept_scaling": 5,
    "sklearn.isotonic.IsotonicRegression.fit.X": 5,
    "sklearn.isotonic.IsotonicRegression.fit.y": 5,
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__.n_jobs": 5,
    "sklearn.multiclass.OneVsOneClassifier.fit.X": 5,
    "sklearn.multiclass.OneVsOneClassifier.fit.y": 5,
    "sklearn.metrics._scorer.get_scorer.scoring": 5,
    "sklearn.ensemble._stacking.StackingClassifier.__init__.n_jobs": 5,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.n_iter_no_change": 5,
    "sklearn.datasets._base.load_digits.return_X_y": 5,
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.n_iter_no_change": 5,
    "sklearn.preprocessing._data.quantile_transform.n_quantiles": 5,
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.grid_resolution": 5,
    "sklearn.tree._classes.DecisionTreeClassifier.__init__.ccp_alpha": 5,
    "sklearn.naive_bayes.CategoricalNB.fit.X": 5,
    "sklearn.naive_bayes.CategoricalNB.fit.y": 5,
    "sklearn.decomposition._pca.PCA.__init__.iterated_power": 5,
    "sklearn.linear_model._huber.HuberRegressor.__init__.alpha": 5,
    "sklearn.manifold._isomap.Isomap.fit_transform.X": 5,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.random_state": 5,
    "sklearn.metrics.pairwise.paired_distances.X": 5,
    "sklearn.metrics.pairwise.paired_distances.Y": 5,
    "sklearn.kernel_approximation.Nystroem.__init__.kernel": 5,
    "sklearn.feature_extraction.text.CountVectorizer.__init__.input": 5,
    "sklearn.preprocessing._label.MultiLabelBinarizer.inverse_transform.yt": 5,
    "sklearn.utils.metaestimators.if_delegate_has_method.delegate": 5,
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.strip_accents": 5,
    "sklearn.feature_extraction.text.HashingVectorizer.fit.X": 5,
    "sklearn.linear_model._ridge.RidgeClassifier.__init__.fit_intercept": 5,
    "sklearn.linear_model._ridge.RidgeClassifier.__init__.copy_X": 5,
    "sklearn.linear_model._ridge.RidgeClassifier.__init__.max_iter": 5,
    "sklearn.linear_model._glm.glm.TweedieRegressor.__init__.power": 5,
    "sklearn.linear_model._glm.glm.TweedieRegressor.__init__.link": 5,
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.ccp_alpha": 4,
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.tol": 4,
    "sklearn.ensemble._voting.VotingClassifier.__init__.verbose": 4,
    "sklearn.linear_model._logistic.LogisticRegression.fit.sample_weight": 4,
    "sklearn.manifold._mds.MDS.__init__.dissimilarity": 4,
    "sklearn.manifold._mds.MDS.__init__.random_state": 4,
    "sklearn.linear_model._huber.HuberRegressor.__init__.fit_intercept": 4,
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.ccp_alpha": 4,
    "sklearn.dummy.DummyClassifier.predict_proba.X": 4,
    "sklearn.linear_model._theil_sen.TheilSenRegressor.__init__.random_state": 4,
    "sklearn.impute._iterative.IterativeImputer.__init__.missing_values": 4,
    "sklearn.impute._iterative.IterativeImputer.__init__.sample_posterior": 4,
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.eps": 4,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.tol": 4,
    "sklearn.datasets._samples_generator.make_blobs.n_samples": 4,
    "sklearn.metrics._plot.roc_curve.plot_roc_curve.name": 4,
    "sklearn.metrics._plot.roc_curve.plot_roc_curve.ax": 4,
    "sklearn.ensemble._iforest.IsolationForest.__init__.bootstrap": 4,
    "sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay.plot.xticks_rotation": 4,
    "sklearn.cluster._kmeans.k_means.X": 4,
    "sklearn.cluster._kmeans.k_means.n_clusters": 4,
    "sklearn.metrics._ranking.precision_recall_curve.pos_label": 4,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.power_t": 4,
    "sklearn.linear_model._perceptron.Perceptron.__init__.class_weight": 4,
    "sklearn.manifold._isomap.Isomap.fit.X": 4,
    "sklearn.cluster._spectral.SpectralClustering.fit.X": 4,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.verbose": 4,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.n_iter_no_change": 4,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.n_iter_no_change": 4,
    "sklearn.linear_model._bayes.BayesianRidge.__init__.tol": 4,
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__.min_samples_split": 4,
    "sklearn.model_selection._validation.cross_validate.fit_params": 4,
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.epsilon": 4,
    "sklearn.ensemble._forest.RandomTreesEmbedding.fit.X": 4,
    "sklearn.cluster._mean_shift.MeanShift.__init__.bandwidth": 4,
    "sklearn.cluster._mean_shift.MeanShift.__init__.bin_seeding": 4,
    "sklearn.cluster._affinity_propagation.AffinityPropagation.fit.X": 4,
    "sklearn.feature_extraction._hash.FeatureHasher.transform.raw_X": 4,
    "sklearn.multiclass.OneVsOneClassifier.predict.X": 4,
    "sklearn.ensemble._stacking.StackingClassifier.__init__.verbose": 4,
    "sklearn.model_selection._validation.learning_curve.random_state": 4,
    "sklearn.model_selection._validation.learning_curve.verbose": 4,
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.n_iter_no_change": 4,
    "sklearn.linear_model._least_angle.LassoLarsIC.__init__.criterion": 4,
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.target": 4,
    "sklearn.neighbors._lof.LocalOutlierFactor.fit.X": 4,
    "sklearn.ensemble._bagging.BaggingClassifier.__init__.bootstrap_features": 4,
    "sklearn.preprocessing._data.PowerTransformer.__init__.standardize": 4,
    "sklearn.datasets._base.load_files.container_path": 4,
    "sklearn.metrics._classification.classification_report.zero_division": 4,
    "sklearn.ensemble._bagging.BaggingClassifier.__init__.oob_score": 4,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.min_samples_leaf": 4,
    "sklearn.decomposition._incremental_pca.IncrementalPCA.partial_fit.X": 4,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.l2_regularization": 4,
    "sklearn.metrics._classification.jaccard_score.pos_label": 4,
    "sklearn.covariance._shrunk_covariance.ShrunkCovariance.fit.X": 4,
    "sklearn.linear_model._perceptron.Perceptron.__init__.n_jobs": 4,
    "sklearn.tree._export.plot_tree.fontsize": 4,
    "sklearn.kernel_approximation.Nystroem.transform.X": 4,
    "sklearn.multiclass.OneVsRestClassifier.decision_function.X": 4,
    "sklearn.calibration.calibration_curve.normalize": 4,
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.__init__.random_state": 4,
    "sklearn.tree._classes.ExtraTreeClassifier.__init__.random_state": 4,
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix.xticks_rotation": 4,
    "sklearn.isotonic.IsotonicRegression.transform.T": 4,
    "sklearn.impute._iterative.IterativeImputer.__init__.initial_strategy": 4,
    "sklearn.base.clone.safe": 4,
    "sklearn.metrics._classification.fbeta_score.labels": 4,
    "sklearn.covariance._shrunk_covariance.LedoitWolf.__init__.assume_centered": 4,
    "sklearn.neighbors._lof.LocalOutlierFactor.__init__.p": 4,
    "sklearn.ensemble._gb.GradientBoostingClassifier.staged_decision_function.X": 4,
    "sklearn.ensemble._iforest.IsolationForest.fit.y": 3,
    "sklearn.datasets._samples_generator.make_regression.random_state": 3,
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.tol": 3,
    "sklearn.decomposition._pca.PCA.fit_transform.y": 3,
    "sklearn.ensemble._bagging.BaggingRegressor.__init__.warm_start": 3,
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.__init__.store_covariance": 3,
    "sklearn.covariance._robust_covariance.MinCovDet.fit.X": 3,
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.__init__.eigen_solver": 3,
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.__init__.method": 3,
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.__init__.n_neighbors": 3,
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.__init__.random_state": 3,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.max_iter": 3,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.warm_start": 3,
    "sklearn.svm._classes.LinearSVR.__init__.intercept_scaling": 3,
    "sklearn.cluster._dbscan.DBSCAN.__init__.leaf_size": 3,
    "sklearn.datasets._samples_generator.make_blobs.random_state": 3,
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.__init__.kernel": 3,
    "sklearn.naive_bayes.GaussianNB.fit.sample_weight": 3,
    "sklearn.utils.validation.column_or_1d.y": 3,
    "sklearn.cluster._optics.OPTICS.fit.X": 3,
    "sklearn.cluster._optics.OPTICS.__init__.min_samples": 3,
    "sklearn.ensemble._iforest.IsolationForest.__init__.verbose": 3,
    "sklearn.impute._iterative.IterativeImputer.__init__.verbose": 3,
    "sklearn.svm._classes.NuSVR.__init__.max_iter": 3,
    "sklearn.covariance._graph_lasso.GraphicalLasso.__init__.alpha": 3,
    "sklearn.decomposition._truncated_svd.TruncatedSVD.fit.y": 3,
    "sklearn.neighbors._unsupervised.NearestNeighbors.fit.y": 3,
    "sklearn.linear_model._ransac.RANSACRegressor.__init__.min_samples": 3,
    "sklearn.linear_model._ransac.RANSACRegressor.__init__.loss": 3,
    "sklearn.linear_model._ransac.RANSACRegressor.__init__.residual_threshold": 3,
    "sklearn.linear_model._coordinate_descent.Lasso.__init__.copy_X": 3,
    "sklearn.cluster._spectral.SpectralClustering.__init__.random_state": 3,
    "sklearn.metrics._classification.brier_score_loss.pos_label": 3,
    "sklearn.model_selection._split.StratifiedShuffleSplit.split.groups": 3,
    "sklearn.feature_extraction.text.CountVectorizer.fit.y": 3,
    "sklearn.isotonic.IsotonicRegression.__init__.y_min": 3,
    "sklearn.isotonic.IsotonicRegression.__init__.y_max": 3,
    "sklearn.manifold._t_sne.TSNE.__init__.n_iter_without_progress": 3,
    "sklearn.linear_model._bayes.ARDRegression.fit.X": 3,
    "sklearn.linear_model._bayes.ARDRegression.fit.y": 3,
    "sklearn.cluster._mean_shift.estimate_bandwidth.quantile": 3,
    "sklearn.cluster._mean_shift.estimate_bandwidth.X": 3,
    "sklearn.cluster._mean_shift.MeanShift.__init__.min_bin_freq": 3,
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.degree": 3,
    "sklearn.impute._iterative.IterativeImputer.__init__.add_indicator": 3,
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.positive": 3,
    "sklearn.utils.class_weight.compute_sample_weight.indices": 3,
    "sklearn.preprocessing._data.RobustScaler.__init__.copy": 3,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.loss": 3,
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.fit_intercept": 3,
    "sklearn.metrics.pairwise.paired_euclidean_distances.X": 3,
    "sklearn.metrics.pairwise.paired_euclidean_distances.Y": 3,
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.__init__.warm_start": 3,
    "sklearn.tree._classes.DecisionTreeClassifier.fit.sample_weight": 3,
    "sklearn.metrics._classification.precision_recall_fscore_support.pos_label": 3,
    "sklearn.metrics.cluster._unsupervised.silhouette_samples.X": 3,
    "sklearn.metrics.cluster._unsupervised.silhouette_samples.labels": 3,
    "sklearn.linear_model._perceptron.Perceptron.__init__.tol": 3,
    "sklearn.naive_bayes.CategoricalNB.__init__.alpha": 3,
    "sklearn.decomposition._pca.PCA.__init__.tol": 3,
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.normalize": 3,
    "sklearn.linear_model._bayes.BayesianRidge.predict.return_std": 3,
    "sklearn.utils.extmath.density.w": 3,
    "sklearn.naive_bayes.ComplementNB.__init__.alpha": 3,
    "sklearn.decomposition._incremental_pca.IncrementalPCA.fit.X": 3,
    "sklearn.preprocessing._data.quantile_transform.random_state": 3,
    "sklearn.preprocessing._data.quantile_transform.copy": 3,
    "sklearn.tree._export.plot_tree.max_depth": 3,
    "sklearn.datasets._openml.fetch_openml.name": 3,
    "sklearn.decomposition._sparse_pca.SparsePCA.transform.X": 3,
    "sklearn.linear_model._logistic.LogisticRegression.predict_log_proba.X": 3,
    "sklearn.cross_decomposition._pls.PLSSVD.__init__.n_components": 3,
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.positive": 3,
    "sklearn.linear_model._huber.HuberRegressor.__init__.epsilon": 3,
    "sklearn.decomposition._nmf.NMF.__init__.solver": 3,
    "sklearn.neighbors._lof.LocalOutlierFactor.__init__.n_jobs": 3,
    "sklearn.model_selection._split.LeaveOneGroupOut.get_n_splits.X": 3,
    "sklearn.model_selection._split.LeaveOneGroupOut.get_n_splits.y": 3,
    "sklearn.model_selection._split.LeaveOneGroupOut.get_n_splits.groups": 3,
    "sklearn.preprocessing._data.RobustScaler.inverse_transform.X": 3,
    "sklearn.random_projection.BaseRandomProjection.fit.X": 3,
    "sklearn.metrics.pairwise.pairwise_distances_argmin.X": 3,
    "sklearn.metrics.pairwise.pairwise_distances_argmin.Y": 3,
    "sklearn.cluster._agglomerative.FeatureAgglomeration.__init__.linkage": 3,
    "sklearn.linear_model._least_angle.LassoLarsCV.__init__.cv": 3,
    "sklearn.linear_model._least_angle.LarsCV.fit.X": 3,
    "sklearn.linear_model._least_angle.LarsCV.fit.y": 3,
    "sklearn.preprocessing._data.QuantileTransformer.__init__.copy": 3,
    "sklearn.semi_supervised._label_propagation.LabelSpreading.__init__.n_jobs": 3,
    "sklearn.decomposition._pca.PCA.fit.y": 3,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.validation_fraction": 3,
    "sklearn.feature_selection._sequential.SequentialFeatureSelector.fit.X": 2,
    "sklearn.feature_selection._sequential.SequentialFeatureSelector.fit.y": 2,
    "sklearn.feature_selection._sequential.SequentialFeatureSelector.__init__.direction": 2,
    "sklearn.feature_selection._sequential.SequentialFeatureSelector.__init__.scoring": 2,
    "sklearn.feature_selection._sequential.SequentialFeatureSelector.__init__.cv": 2,
    "sklearn.feature_selection._sequential.SequentialFeatureSelector.__init__.n_features_to_select": 2,
    "sklearn.feature_selection._sequential.SequentialFeatureSelector.__init__.estimator": 2,
    "sklearn.ensemble._iforest.IsolationForest.score_samples.X": 2,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet.__init__.selection": 2,
    "sklearn.datasets._samples_generator.make_regression.n_samples": 2,
    "sklearn.cross_decomposition._pls.PLSRegression.__init__.tol": 2,
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.max_samples": 2,
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.min_impurity_decrease": 2,
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.min_impurity_split": 2,
    "sklearn.linear_model._least_angle.LassoLars.__init__.alpha": 2,
    "sklearn.linear_model._bayes.ARDRegression.__init__.fit_intercept": 2,
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.__init__.n_restarts_optimizer": 2,
    "sklearn.preprocessing._data.robust_scale.axis": 2,
    "sklearn.preprocessing._data.robust_scale.quantile_range": 2,
    "sklearn.preprocessing._data.robust_scale.X": 2,
    "sklearn.neighbors._kde.KernelDensity.sample.n_samples": 2,
    "sklearn.neighbors._kde.KernelDensity.sample.random_state": 2,
    "sklearn.cluster._kmeans.MiniBatchKMeans.partial_fit.X": 2,
    "sklearn.datasets._base.load_sample_image.image_name": 2,
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.__init__.tol": 2,
    "sklearn.linear_model._least_angle.Lars.__init__.fit_intercept": 2,
    "sklearn.model_selection._split.TimeSeriesSplit.__init__.gap": 2,
    "sklearn.feature_selection._univariate_selection.SelectFpr.__init__.score_func": 2,
    "sklearn.feature_selection._variance_threshold.VarianceThreshold.fit.y": 2,
    "sklearn.preprocessing._data.MinMaxScaler.fit.y": 2,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.C": 2,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.verbose": 2,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.loss": 2,
    "sklearn.metrics._ranking.ndcg_score.y_true": 2,
    "sklearn.metrics._ranking.ndcg_score.y_score": 2,
    "sklearn.metrics._ranking.ndcg_score.k": 2,
    "sklearn.metrics._ranking.ndcg_score.sample_weight": 2,
    "sklearn.metrics._ranking.ndcg_score.ignore_ties": 2,
    "sklearn.model_selection._validation.cross_val_predict.fit_params": 2,
    "sklearn.tree._classes.BaseDecisionTree.apply.X": 2,
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.refit": 2,
    "sklearn.utils.validation.column_or_1d.warn": 2,
    "sklearn.cluster._optics.OPTICS.__init__.metric": 2,
    "sklearn.datasets._samples_generator.make_blobs.centers": 2,
    "sklearn.datasets._samples_generator.make_blobs.cluster_std": 2,
    "sklearn.tree._classes.ExtraTreeRegressor.__init__.criterion": 2,
    "sklearn.preprocessing._data.minmax_scale.copy": 2,
    "sklearn.svm._classes.NuSVR.__init__.verbose": 2,
    "sklearn.manifold._spectral_embedding.SpectralEmbedding.__init__.affinity": 2,
    "sklearn.metrics.cluster._supervised.v_measure_score.labels_true": 2,
    "sklearn.metrics.cluster._supervised.v_measure_score.labels_pred": 2,
    "sklearn.feature_extraction.text.CountVectorizer.fit_transform.y": 2,
    "sklearn.decomposition._truncated_svd.TruncatedSVD.fit_transform.y": 2,
    "sklearn.metrics._plot.roc_curve.RocCurveDisplay.__init__.fpr": 2,
    "sklearn.metrics._plot.roc_curve.RocCurveDisplay.__init__.tpr": 2,
    "sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay.__init__.precision": 2,
    "sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay.__init__.recall": 2,
    "sklearn.naive_bayes.GaussianNB.partial_fit.X": 2,
    "sklearn.naive_bayes.GaussianNB.partial_fit.y": 2,
    "sklearn.naive_bayes.GaussianNB.partial_fit.classes": 2,
    "sklearn.model_selection._split.BaseCrossValidator.split.X": 2,
    "sklearn.tree._export.export_text.feature_names": 2,
    "sklearn.datasets._samples_generator.make_regression.n_features": 2,
    "sklearn.datasets._samples_generator.make_regression.noise": 2,
    "sklearn.linear_model._theil_sen.TheilSenRegressor.__init__.verbose": 2,
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.staged_predict.X": 2,
    "sklearn.ensemble._gb.GradientBoostingClassifier.staged_predict.X": 2,
    "sklearn.cluster._agglomerative.FeatureAgglomeration.__init__.connectivity": 2,
    "sklearn.cluster._agglomerative.FeatureAgglomeration.fit.X": 2,
    "sklearn.neighbors._graph.kneighbors_graph.X": 2,
    "sklearn.neighbors._graph.kneighbors_graph.n_neighbors": 2,
    "sklearn.linear_model._ridge.Ridge.fit.sample_weight": 2,
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.warm_start": 2,
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.average": 2,
    "sklearn.manifold._t_sne.TSNE.__init__.min_grad_norm": 2,
    "sklearn.linear_model._bayes.ARDRegression.__init__.alpha_1": 2,
    "sklearn.linear_model._bayes.ARDRegression.__init__.alpha_2": 2,
    "sklearn.linear_model._bayes.ARDRegression.__init__.lambda_1": 2,
    "sklearn.linear_model._bayes.ARDRegression.__init__.lambda_2": 2,
    "sklearn.linear_model._bayes.ARDRegression.__init__.n_iter": 2,
    "sklearn.linear_model._bayes.ARDRegression.__init__.verbose": 2,
    "sklearn.cluster._mean_shift.estimate_bandwidth.n_samples": 2,
    "sklearn.cluster._affinity_propagation.AffinityPropagation.__init__.damping": 2,
    "sklearn.cluster._affinity_propagation.AffinityPropagation.predict.X": 2,
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.kernel_params": 2,
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.alpha": 2,
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.eigen_solver": 2,
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.tol": 2,
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.max_iter": 2,
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.remove_zero_eig": 2,
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.fit_intercept": 2,
    "sklearn.impute._iterative.IterativeImputer.__init__.skip_complete": 2,
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.max_fun": 2,
    "sklearn.decomposition._fastica.FastICA.__init__.tol": 2,
    "sklearn.tree._export.plot_tree.label": 2,
    "sklearn.metrics._regression.mean_squared_log_error.sample_weight": 2,
    "sklearn.metrics._regression.mean_squared_log_error.multioutput": 2,
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.precompute": 2,
    "sklearn.impute._iterative.IterativeImputer.__init__.n_nearest_features": 2,
    "sklearn.impute._base.MissingIndicator.fit.X": 2,
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.validation_fraction": 2,
    "sklearn.ensemble._voting.VotingClassifier.__init__.flatten_transform": 2,
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.mahalanobis.X": 2,
    "sklearn.model_selection._validation.cross_val_predict.groups": 2,
    "sklearn.preprocessing._data.quantile_transform.output_distribution": 2,
    "sklearn.linear_model._least_angle.LassoLarsIC.__init__.fit_intercept": 2,
    "sklearn.impute._base.SimpleImputer.fit.y": 2,
    "sklearn.model_selection._validation.learning_curve.shuffle": 2,
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.__init__.n_jobs": 2,
    "sklearn.neighbors._kde.KernelDensity.__init__.metric": 2,
    "sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay.plot.values_format": 2,
    "sklearn.preprocessing._function_transformer.FunctionTransformer.__init__.inverse_func": 2,
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.weight_concentration_prior_type": 2,
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.weight_concentration_prior": 2,
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.n_init": 2,
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.__init__.radius": 2,
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.predict.X": 2,
    "sklearn.ensemble._stacking.StackingRegressor.__init__.passthrough": 2,
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__.verbose": 2,
    "sklearn.feature_selection._mutual_info.mutual_info_regression.n_neighbors": 2,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.max_leaf_nodes": 2,
    "sklearn.ensemble._gb.GradientBoostingClassifier.staged_predict_proba.X": 2,
    "sklearn.base.RegressorMixin.score.sample_weight": 2,
    "sklearn.ensemble._bagging.BaggingRegressor.__init__.oob_score": 2,
    "sklearn.svm._classes.NuSVC.__init__.tol": 2,
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.copy_X": 2,
    "sklearn.ensemble._gb.GradientBoostingClassifier.predict_log_proba.X": 2,
    "sklearn.cluster._kmeans.k_means.max_iter": 2,
    "sklearn.cluster._kmeans.k_means.random_state": 2,
    "sklearn.naive_bayes.BernoulliNB.__init__.class_prior": 2,
    "sklearn.model_selection._search.RandomizedSearchCV.__init__.pre_dispatch": 2,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.tol": 2,
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.decode_error": 2,
    "sklearn.decomposition._incremental_pca.IncrementalPCA.__init__.batch_size": 2,
    "sklearn.datasets._openml.fetch_openml.version": 2,
    "sklearn.metrics._classification.multilabel_confusion_matrix.sample_weight": 2,
    "sklearn.cluster._spectral.SpectralClustering.__init__.eigen_solver": 2,
    "sklearn.kernel_approximation.RBFSampler.__init__.random_state": 2,
    "sklearn.isotonic.IsotonicRegression.predict.T": 2,
    "sklearn.kernel_approximation.Nystroem.__init__.n_components": 2,
    "sklearn.kernel_approximation.Nystroem.__init__.random_state": 2,
    "sklearn.manifold._isomap.Isomap.__init__.eigen_solver": 2,
    "sklearn.datasets._samples_generator.make_circles.noise": 2,
    "sklearn.datasets._samples_generator.make_circles.factor": 2,
    "sklearn.datasets._samples_generator.make_moons.random_state": 2,
    "sklearn.manifold._mds.smacof.n_components": 2,
    "sklearn.manifold._mds.smacof.dissimilarities": 2,
    "sklearn.inspection._permutation_importance.permutation_importance.n_jobs": 2,
    "sklearn.neural_network._rbm.BernoulliRBM.__init__.n_components": 2,
    "sklearn.feature_extraction._hash.FeatureHasher.__init__.dtype": 2,
    "sklearn.cluster._agglomerative.AgglomerativeClustering.fit.y": 2,
    "sklearn.utils.validation.check_X_y.force_all_finite": 2,
    "sklearn.utils.safe_sqr.X": 2,
    "sklearn.utils.safe_mask.X": 2,
    "sklearn.utils.safe_mask.mask": 2,
    "sklearn.cluster._optics.OPTICS.__init__.xi": 2,
    "sklearn.preprocessing._data.power_transform.method": 2,
    "sklearn.preprocessing._data.power_transform.X": 2,
    "sklearn.cluster._kmeans.KMeans.score.X": 2,
    "sklearn.neighbors._regression.RadiusNeighborsRegressor.__init__.radius": 2,
    "sklearn.neighbors._regression.RadiusNeighborsRegressor.__init__.weights": 2,
    "sklearn.neighbors._regression.RadiusNeighborsRegressor.__init__.metric": 2,
    "sklearn.neighbors._regression.RadiusNeighborsRegressor.__init__.p": 2,
    "sklearn.random_projection.SparseRandomProjection.__init__.eps": 2,
    "sklearn.preprocessing._function_transformer.FunctionTransformer.__init__.check_inverse": 2,
    "sklearn.compose._column_transformer.ColumnTransformer.fit.y": 2,
    "sklearn.preprocessing._data.StandardScaler.partial_fit.X": 2,
    "sklearn.datasets._base.load_iris.return_X_y": 2,
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.n_components": 2,
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.alpha": 2,
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.n_iter": 2,
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.batch_size": 2,
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.random_state": 2,
    "sklearn.cluster._kmeans.MiniBatchKMeans.__init__.tol": 2,
    "sklearn.metrics.pairwise.rbf_kernel.X": 2,
    "sklearn.metrics.pairwise.rbf_kernel.Y": 2,
    "sklearn.metrics.pairwise.polynomial_kernel.X": 2,
    "sklearn.metrics.pairwise.polynomial_kernel.Y": 2,
    "sklearn.datasets._base.load_files.encoding": 2,
    "sklearn.decomposition._lda.LatentDirichletAllocation.perplexity.X": 2,
    "sklearn.decomposition._lda.LatentDirichletAllocation.score.X": 2,
    "sklearn.metrics._regression.mean_tweedie_deviance.power": 2,
    "sklearn.metrics._regression.mean_tweedie_deviance.y_true": 2,
    "sklearn.metrics._regression.mean_tweedie_deviance.y_pred": 2,
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.selection": 2,
    "sklearn.cluster._dbscan.DBSCAN.__init__.metric_params": 2,
    "sklearn.cluster._dbscan.DBSCAN.__init__.p": 2,
    "sklearn.metrics._ranking.roc_auc_score.max_fpr": 2,
    "sklearn.linear_model._least_angle.LassoLarsIC.fit.X": 2,
    "sklearn.linear_model._least_angle.LassoLarsIC.fit.y": 2,
    "sklearn.linear_model._least_angle.LassoLarsCV.__init__.max_iter": 2,
    "sklearn.decomposition._nmf.NMF.__init__.beta_loss": 2,
    "sklearn.decomposition._nmf.NMF.__init__.max_iter": 2,
    "sklearn.linear_model._least_angle.LassoLarsCV.__init__.precompute": 2,
    "sklearn.decomposition._fastica.FastICA.__init__.algorithm": 2,
    "sklearn.decomposition._fastica.FastICA.__init__.whiten": 2,
    "sklearn.semi_supervised._label_propagation.LabelSpreading.__init__.n_neighbors": 2,
    "sklearn.linear_model._bayes.ARDRegression.predict.return_std": 2,
    "sklearn.linear_model._least_angle.Lars.fit.X": 2,
    "sklearn.linear_model._least_angle.Lars.fit.y": 2,
    "sklearn.tree._classes.ExtraTreeClassifier.__init__.max_depth": 2,
    "sklearn.tree._export.plot_tree.proportion": 2,
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.scoring": 2,
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.cv": 2,
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.n_jobs": 2,
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.estimator": 2,
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.param_distributions": 2,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.early_stopping": 2,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.average": 2,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.class_weight": 2,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.n_jobs": 2,
    "sklearn.feature_extraction.text.TfidfVectorizer.fit_transform.y": 2,
    "sklearn.gaussian_process.kernels.ConstantKernel.__init__.constant_value": 2,
    "sklearn.gaussian_process.kernels.ConstantKernel.__init__.constant_value_bounds": 2,
    "sklearn.linear_model._ridge.RidgeClassifierCV.__init__.alphas": 2,
    "sklearn.covariance._shrunk_covariance.ShrunkCovariance.__init__.shrinkage": 2,
    "sklearn.datasets._svmlight_format_io.load_svmlight_file.zero_based": 2,
    "sklearn.datasets._svmlight_format_io.load_svmlight_file.f": 2,
    "sklearn.multioutput.MultiOutputClassifier.score.X": 2,
    "sklearn.multioutput.MultiOutputClassifier.score.y": 2,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.n_iter_no_change": 2,
    "sklearn.metrics.cluster._supervised.normalized_mutual_info_score.labels_true": 2,
    "sklearn.metrics.cluster._supervised.normalized_mutual_info_score.labels_pred": 2,
    "sklearn.covariance._graph_lasso.GraphicalLasso.__init__.max_iter": 2,
    "sklearn.dummy.DummyRegressor.score.X": 1,
    "sklearn.dummy.DummyRegressor.score.y": 1,
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.ccp_alpha": 1,
    "sklearn.linear_model._theil_sen.TheilSenRegressor.__init__.fit_intercept": 1,
    "sklearn.linear_model._least_angle.LassoLars.__init__.fit_intercept": 1,
    "sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay.plot.colorbar": 1,
    "sklearn.preprocessing._data.Binarizer.__init__.threshold": 1,
    "sklearn.preprocessing._data.RobustScaler.__init__.unit_variance": 1,
    "sklearn.covariance._robust_covariance.MinCovDet.__init__.support_fraction": 1,
    "sklearn.linear_model._least_angle.LassoLars.__init__.normalize": 1,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.fit_intercept": 1,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.shuffle": 1,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.epsilon": 1,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.average": 1,
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.__init__.random_state": 1,
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups.download_if_missing": 1,
    "sklearn.gaussian_process.kernels.WhiteKernel.__init__.noise_level": 1,
    "sklearn.linear_model._bayes.BayesianRidge.__init__.alpha_init": 1,
    "sklearn.preprocessing._data.MaxAbsScaler.__init__.copy": 1,
    "sklearn.covariance._shrunk_covariance.ledoit_wolf.X": 1,
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.fit.sample_weight": 1,
    "sklearn.cluster._optics.OPTICS.__init__.max_eps": 1,
    "sklearn.metrics.cluster._supervised.mutual_info_score.contingency": 1,
    "sklearn.feature_extraction.text.TfidfVectorizer.fit.y": 1,
    "sklearn.svm._classes.OneClassSVM.decision_function.X": 1,
    "sklearn.cross_decomposition._pls.PLSRegression.__init__.copy": 1,
    "sklearn.cross_decomposition._pls.PLSRegression.__init__.max_iter": 1,
    "sklearn.cross_decomposition._pls.PLSRegression.__init__.scale": 1,
    "sklearn.impute._iterative.IterativeImputer.__init__.imputation_order": 1,
    "sklearn.decomposition._factor_analysis.FactorAnalysis.__init__.rotation": 1,
    "sklearn.datasets._samples_generator.make_regression.bias": 1,
    "sklearn.model_selection._split.TimeSeriesSplit.split.groups": 1,
    "sklearn.semi_supervised._label_propagation.LabelPropagation.__init__.n_neighbors": 1,
    "sklearn.semi_supervised._label_propagation.LabelPropagation.__init__.max_iter": 1,
    "sklearn.cluster._dbscan.dbscan.X": 1,
    "sklearn.cluster._affinity_propagation.affinity_propagation.S": 1,
    "sklearn.svm._classes.NuSVC.__init__.max_iter": 1,
    "sklearn.linear_model._coordinate_descent.ElasticNet.fit.sample_weight": 1,
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.__init__.n_restarts_optimizer": 1,
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.__init__.max_iter_predict": 1,
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__.sparse_output": 1,
    "sklearn.decomposition._nmf.NMF.__init__.shuffle": 1,
    "sklearn.utils.extmath.weighted_mode.axis": 1,
    "sklearn.utils.extmath.weighted_mode.a": 1,
    "sklearn.utils.extmath.weighted_mode.w": 1,
    "sklearn.base.ClassifierMixin.score.sample_weight": 1,
    "sklearn.linear_model._omp.OrthogonalMatchingPursuit.__init__.n_nonzero_coefs": 1,
    "sklearn.linear_model._omp.OrthogonalMatchingPursuit.__init__.fit_intercept": 1,
    "sklearn.linear_model._omp.OrthogonalMatchingPursuit.__init__.normalize": 1,
    "sklearn.linear_model._omp.OrthogonalMatchingPursuit.__init__.precompute": 1,
    "sklearn.linear_model._omp.OrthogonalMatchingPursuit.__init__.tol": 1,
    "sklearn.linear_model._omp.OrthogonalMatchingPursuit.fit.X": 1,
    "sklearn.linear_model._omp.OrthogonalMatchingPursuit.fit.y": 1,
    "sklearn.impute._base.MissingIndicator.fit_transform.X": 1,
    "sklearn.model_selection._split.TimeSeriesSplit.__init__.test_size": 1,
    "sklearn.ensemble._voting.VotingRegressor.__init__.verbose": 1,
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.copy_X": 1,
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.selection": 1,
    "sklearn.impute._base.MissingIndicator.transform.X": 1,
    "sklearn.compose._column_transformer.ColumnTransformer.__init__.transformer_weights": 1,
    "sklearn.datasets._samples_generator.make_multilabel_classification.n_samples": 1,
    "sklearn.datasets._samples_generator.make_multilabel_classification.n_features": 1,
    "sklearn.datasets._samples_generator.make_multilabel_classification.n_classes": 1,
    "sklearn.datasets._samples_generator.make_multilabel_classification.random_state": 1,
    "sklearn.preprocessing._encoders.OneHotEncoder.fit_transform.y": 1,
    "sklearn.impute._base.MissingIndicator.fit.y": 1,
    "sklearn.preprocessing._label.LabelBinarizer.inverse_transform.threshold": 1,
    "sklearn.model_selection._split.LeaveOneOut.get_n_splits.X": 1,
    "sklearn.utils.validation.check_X_y.dtype": 1,
    "sklearn.utils.validation.check_X_y.y_numeric": 1,
    "sklearn.utils.estimator_checks.check_estimator.Estimator": 1,
    "sklearn.neighbors._unsupervised.NearestNeighbors.__init__.radius": 1,
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.__init__.optimizer": 1,
    "sklearn.dummy.DummyRegressor.__init__.constant": 1,
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.__init__.priors": 1,
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.__init__.store_covariance": 1,
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.__init__.covariance_estimator": 1,
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.fit.X": 1,
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.fit.y": 1,
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.__init__.weights": 1,
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.__init__.algorithm": 1,
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.__init__.leaf_size": 1,
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.__init__.p": 1,
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.__init__.metric": 1,
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.__init__.outlier_label": 1,
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.__init__.metric_params": 1,
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.__init__.n_jobs": 1,
    "sklearn.metrics.pairwise.pairwise_distances_argmin_min.X": 1,
    "sklearn.metrics.pairwise.pairwise_distances_argmin_min.Y": 1,
    "sklearn.datasets._samples_generator.make_blobs.n_features": 1,
    "sklearn.feature_selection._mutual_info.mutual_info_regression.copy": 1,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.loss": 1,
    "sklearn.linear_model._glm.glm.TweedieRegressor.__init__.alpha": 1,
    "sklearn.cross_decomposition._pls.CCA.__init__.n_components": 1,
    "sklearn.metrics._regression.explained_variance_score.multioutput": 1,
    "sklearn.ensemble._bagging.BaggingClassifier.__init__.warm_start": 1,
    "sklearn.ensemble._bagging.BaggingClassifier.__init__.verbose": 1,
    "sklearn.svm._classes.NuSVR.__init__.degree": 1,
    "sklearn.svm._classes.NuSVR.__init__.shrinking": 1,
    "sklearn.decomposition._incremental_pca.IncrementalPCA.__init__.copy": 1,
    "sklearn.cluster._kmeans.MiniBatchKMeans.__init__.reassignment_ratio": 1,
    "sklearn.pipeline.FeatureUnion.__init__.verbose": 1,
    "sklearn.metrics._classification.balanced_accuracy_score.sample_weight": 1,
    "sklearn.metrics._classification.precision_recall_fscore_support.beta": 1,
    "sklearn.cluster._birch.Birch.__init__.copy": 1,
    "sklearn.linear_model._perceptron.Perceptron.__init__.penalty": 1,
    "sklearn.linear_model._perceptron.Perceptron.__init__.alpha": 1,
    "sklearn.linear_model._perceptron.Perceptron.__init__.fit_intercept": 1,
    "sklearn.linear_model._perceptron.Perceptron.__init__.shuffle": 1,
    "sklearn.linear_model._perceptron.Perceptron.__init__.verbose": 1,
    "sklearn.linear_model._perceptron.Perceptron.__init__.warm_start": 1,
    "sklearn.linear_model._theil_sen.TheilSenRegressor.fit.X": 1,
    "sklearn.linear_model._theil_sen.TheilSenRegressor.fit.y": 1,
    "sklearn.linear_model._ransac.RANSACRegressor.score.X": 1,
    "sklearn.linear_model._ransac.RANSACRegressor.score.y": 1,
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.__init__.store_precision": 1,
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.fit.X": 1,
    "sklearn.datasets._base.load_boston.return_X_y": 1,
    "sklearn.metrics._classification.precision_recall_fscore_support.labels": 1,
    "sklearn.kernel_approximation.RBFSampler.__init__.gamma": 1,
    "sklearn.kernel_approximation.RBFSampler.transform.X": 1,
    "sklearn.manifold._spectral_embedding.SpectralEmbedding.__init__.n_jobs": 1,
    "sklearn.tree._export.plot_tree.ax": 1,
    "sklearn.metrics.pairwise.cosine_distances.X": 1,
    "sklearn.inspection._partial_dependence.partial_dependence.features": 1,
    "sklearn.inspection._partial_dependence.partial_dependence.X": 1,
    "sklearn.inspection._partial_dependence.partial_dependence.grid_resolution": 1,
    "sklearn.inspection._partial_dependence.partial_dependence.estimator": 1,
    "sklearn.datasets._samples_generator.make_circles.random_state": 1,
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.preprocessor": 1,
    "sklearn.neural_network._rbm.BernoulliRBM.__init__.random_state": 1,
    "sklearn._config.set_config.print_changed_only": 1,
    "sklearn.impute._iterative.IterativeImputer.__init__.max_value": 1,
    "sklearn.feature_selection._univariate_selection.SelectFdr.__init__.alpha": 1,
    "sklearn.feature_selection._univariate_selection.SelectFdr.__init__.score_func": 1,
    "sklearn.feature_selection._univariate_selection.SelectFwe.__init__.alpha": 1,
    "sklearn.feature_selection._univariate_selection.SelectFwe.__init__.score_func": 1,
    "sklearn.decomposition._kernel_pca.KernelPCA.fit.X": 1,
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.__init__.n_jobs": 1,
    "sklearn.metrics._plot.precision_recall_curve.plot_precision_recall_curve.ax": 1,
    "sklearn.preprocessing._data.KernelCenterer.transform.K": 1,
    "sklearn.neighbors._lof.LocalOutlierFactor.__init__.metric": 1,
    "sklearn.manifold._mds.MDS.__init__.n_jobs": 1,
    "sklearn.manifold._isomap.Isomap.__init__.n_jobs": 1,
    "sklearn.linear_model._base.LinearRegression.__init__.positive": 1,
    "sklearn.neighbors._nearest_centroid.NearestCentroid.fit.X": 1,
    "sklearn.neighbors._nearest_centroid.NearestCentroid.fit.y": 1,
    "sklearn.neighbors._nearest_centroid.NearestCentroid.predict.X": 1,
    "sklearn.cluster._optics.OPTICS.__init__.min_cluster_size": 1,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.tol": 1,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.warm_start": 1,
    "sklearn.isotonic.IsotonicRegression.__init__.out_of_bounds": 1,
    "sklearn.neighbors._regression.RadiusNeighborsRegressor.fit.X": 1,
    "sklearn.neighbors._regression.RadiusNeighborsRegressor.fit.y": 1,
    "sklearn.neighbors._regression.RadiusNeighborsRegressor.predict.X": 1,
    "sklearn.datasets._base.load_breast_cancer.return_X_y": 1,
    "sklearn.feature_extraction.text.TfidfTransformer.transform.copy": 1,
    "sklearn.cluster._kmeans.KMeans.fit_transform.y": 1,
    "sklearn.feature_extraction.text.CountVectorizer.inverse_transform.X": 1,
    "sklearn.datasets._openml.fetch_openml.as_frame": 1,
    "sklearn.model_selection._validation.learning_curve.fit_params": 1,
    "sklearn.impute._knn.KNNImputer.__init__.metric": 1,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.random_state": 1,
    "sklearn.manifold._t_sne.TSNE.fit_transform.y": 1,
    "sklearn.datasets._samples_generator.make_circles.n_samples": 1,
    "sklearn.svm._classes.NuSVC.__init__.cache_size": 1,
    "sklearn.cluster._kmeans.MiniBatchKMeans.__init__.max_no_improvement": 1,
    "sklearn.decomposition._lda.LatentDirichletAllocation.fit.y": 1,
    "sklearn.metrics.pairwise.sigmoid_kernel.X": 1,
    "sklearn.metrics.pairwise.sigmoid_kernel.Y": 1,
    "sklearn.linear_model._least_angle.Lars.__init__.n_nonzero_coefs": 1,
    "sklearn.semi_supervised._label_propagation.LabelPropagation.fit.X": 1,
    "sklearn.semi_supervised._label_propagation.LabelPropagation.fit.y": 1,
    "sklearn.calibration.CalibratedClassifierCV.__init__.ensemble": 1,
    "sklearn.metrics.pairwise.pairwise_distances_chunked.reduce_func": 1,
    "sklearn.metrics.pairwise.pairwise_distances_chunked.metric": 1,
    "sklearn.metrics.pairwise.pairwise_distances_chunked.n_jobs": 1,
    "sklearn.metrics.pairwise.pairwise_distances_chunked.X": 1,
    "sklearn.neural_network._rbm.BernoulliRBM.fit.X": 1,
    "sklearn.neural_network._rbm.BernoulliRBM.score_samples.X": 1,
    "sklearn.preprocessing._data.PowerTransformer.__init__.copy": 1,
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix.labels": 1,
    "sklearn.preprocessing._data.MinMaxScaler.partial_fit.X": 1,
    "sklearn.ensemble._bagging.BaggingRegressor.__init__.bootstrap_features": 1,
    "sklearn.linear_model._coordinate_descent.Lasso.__init__.warm_start": 1,
    "sklearn.tree._classes.ExtraTreeRegressor.__init__.splitter": 1,
    "sklearn.tree._classes.ExtraTreeRegressor.__init__.random_state": 1,
    "sklearn.decomposition._nmf.NMF.__init__.tol": 1,
    "sklearn.feature_selection._univariate_selection.GenericUnivariateSelect.__init__.score_func": 1,
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.eps": 1,
    "sklearn.metrics._classification.multilabel_confusion_matrix.samplewise": 1,
    "sklearn.impute._iterative.IterativeImputer.__init__.tol": 1,
    "sklearn.metrics.pairwise.pairwise_kernels.metric": 1,
    "sklearn.metrics.pairwise.pairwise_kernels.filter_params": 1,
    "sklearn.metrics.pairwise.pairwise_kernels.X": 1,
    "sklearn.neighbors._nca.NeighborhoodComponentsAnalysis.__init__.random_state": 1,
    "sklearn.multiclass.OneVsOneClassifier.decision_function.X": 1,
    "sklearn.feature_selection._univariate_selection.f_regression.center": 1,
    "sklearn.linear_model._bayes.ARDRegression.__init__.tol": 1,
    "sklearn.linear_model._bayes.ARDRegression.__init__.compute_score": 1,
    "sklearn.linear_model._bayes.ARDRegression.__init__.threshold_lambda": 1,
    "sklearn.linear_model._bayes.ARDRegression.__init__.normalize": 1,
    "sklearn.linear_model._bayes.ARDRegression.__init__.copy_X": 1,
    "sklearn.metrics.cluster._unsupervised.silhouette_score.sample_size": 1,
    "sklearn.tree._classes.ExtraTreeClassifier.__init__.min_samples_split": 1,
    "sklearn.tree._classes.ExtraTreeClassifier.__init__.max_features": 1,
    "sklearn.tree._classes.ExtraTreeClassifier.__init__.criterion": 1,
    "sklearn.compose._target.TransformedTargetRegressor.__init__.check_inverse": 1,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.verbose": 1,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.validation_fraction": 1,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.n_iter_no_change": 1,
    "sklearn.dummy.DummyClassifier.__init__.constant": 1,
    "sklearn.preprocessing._function_transformer.FunctionTransformer.__init__.accept_sparse": 1,
    "sklearn.metrics.cluster._supervised.adjusted_mutual_info_score.labels_true": 1,
    "sklearn.metrics.cluster._supervised.adjusted_mutual_info_score.labels_pred": 1,
    "sklearn.metrics._plot.roc_curve.plot_roc_curve.drop_intermediate": 1,
    "sklearn.linear_model._least_angle.LassoLarsCV.__init__.verbose": 1,
    "sklearn.linear_model._least_angle.LassoLarsCV.__init__.max_n_alphas": 1,
    "sklearn.linear_model._least_angle.LassoLarsCV.__init__.n_jobs": 1,
    "sklearn.linear_model._least_angle.LassoLars.__init__.precompute": 1,
    "sklearn.linear_model._least_angle.LassoLars.__init__.max_iter": 1,
    "sklearn.linear_model._least_angle.LassoLars.__init__.verbose": 1,
    "sklearn.linear_model._ridge.RidgeClassifierCV.__init__.cv": 1,
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.__init__.sort": 1,
    "sklearn.model_selection._split.GroupShuffleSplit.__init__.train_size": 1,
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.__init__.random_state": 1,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.early_stopping": 1,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.tol": 1,
    "sklearn.preprocessing._data.MaxAbsScaler.inverse_transform.X": 1,
    "sklearn.linear_model._glm.glm.TweedieRegressor.__init__.max_iter": 1,
    "sklearn.linear_model._glm.glm.TweedieRegressor.__init__.warm_start": 1,
    "sklearn.metrics.pairwise.pairwise_distances.n_jobs": 1,
    "sklearn.semi_supervised._label_propagation.LabelSpreading.__init__.alpha": 1,
    "sklearn.semi_supervised._label_propagation.LabelSpreading.__init__.tol": 1,
    "sklearn.cluster._mean_shift.MeanShift.__init__.cluster_all": 1,
    "sklearn.cluster._mean_shift.MeanShift.predict.X": 1,
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.learning_decay": 1,
    "sklearn.tree._export.export_graphviz.node_ids": 1,
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.resource": 1,
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.max_resources": 1,
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.random_state": 1,
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.verbose": 1,
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.return_train_score": 1,
    "sklearn.metrics.cluster._unsupervised.silhouette_score.random_state": 1,
    "sklearn.linear_model._bayes.BayesianRidge.__init__.lambda_init": 1,
    "sklearn.decomposition._kernel_pca.KernelPCA.fit_transform.y": 1,
    "sklearn.__check_build.raise_build_error.e": 0,
    "sklearn._config.set_config.assume_finite": 0,
    "sklearn._config.set_config.working_memory": 0,
    "sklearn.base.BaseEstimator.__repr__.N_CHAR_MAX": 0,
    "sklearn.base.BaseEstimator.__setstate__.state": 0,
    "sklearn.base.BiclusterMixin.get_indices.i": 0,
    "sklearn.base.BiclusterMixin.get_shape.i": 0,
    "sklearn.base.BiclusterMixin.get_submatrix.i": 0,
    "sklearn.base.BiclusterMixin.get_submatrix.data": 0,
    "sklearn.base.ClusterMixin.fit_predict.y": 0,
    "sklearn.base.DensityMixin.score.X": 0,
    "sklearn.base.DensityMixin.score.y": 0,
    "sklearn.base.OutlierMixin.fit_predict.y": 0,
    "sklearn.base.is_outlier_detector.estimator": 0,
    "sklearn.base.is_regressor.estimator": 0,
    "sklearn.calibration.CalibratedClassifierCV.__init__.n_jobs": 0,
    "sklearn.calibration.CalibratedClassifierCV.fit.sample_weight": 0,
    "sklearn.calibration.calibration_curve.strategy": 0,
    "sklearn.cluster._affinity_propagation.AffinityPropagation.__init__.max_iter": 0,
    "sklearn.cluster._affinity_propagation.AffinityPropagation.__init__.convergence_iter": 0,
    "sklearn.cluster._affinity_propagation.AffinityPropagation.__init__.copy": 0,
    "sklearn.cluster._affinity_propagation.AffinityPropagation.__init__.preference": 0,
    "sklearn.cluster._affinity_propagation.AffinityPropagation.__init__.affinity": 0,
    "sklearn.cluster._affinity_propagation.AffinityPropagation.__init__.verbose": 0,
    "sklearn.cluster._affinity_propagation.AffinityPropagation.__init__.random_state": 0,
    "sklearn.cluster._affinity_propagation.AffinityPropagation.fit.y": 0,
    "sklearn.cluster._affinity_propagation.AffinityPropagation.fit_predict.X": 0,
    "sklearn.cluster._affinity_propagation.AffinityPropagation.fit_predict.y": 0,
    "sklearn.cluster._affinity_propagation.affinity_propagation.preference": 0,
    "sklearn.cluster._affinity_propagation.affinity_propagation.convergence_iter": 0,
    "sklearn.cluster._affinity_propagation.affinity_propagation.max_iter": 0,
    "sklearn.cluster._affinity_propagation.affinity_propagation.damping": 0,
    "sklearn.cluster._affinity_propagation.affinity_propagation.copy": 0,
    "sklearn.cluster._affinity_propagation.affinity_propagation.verbose": 0,
    "sklearn.cluster._affinity_propagation.affinity_propagation.return_n_iter": 0,
    "sklearn.cluster._affinity_propagation.affinity_propagation.random_state": 0,
    "sklearn.cluster._agglomerative.AgglomerativeClustering.__init__.memory": 0,
    "sklearn.cluster._agglomerative.AgglomerativeClustering.__init__.connectivity": 0,
    "sklearn.cluster._agglomerative.AgglomerativeClustering.__init__.compute_full_tree": 0,
    "sklearn.cluster._agglomerative.AgglomerativeClustering.__init__.compute_distances": 0,
    "sklearn.cluster._agglomerative.AgglomerativeClustering.fit_predict.y": 0,
    "sklearn.cluster._agglomerative.FeatureAgglomeration.__init__.affinity": 0,
    "sklearn.cluster._agglomerative.FeatureAgglomeration.__init__.memory": 0,
    "sklearn.cluster._agglomerative.FeatureAgglomeration.__init__.compute_full_tree": 0,
    "sklearn.cluster._agglomerative.FeatureAgglomeration.__init__.pooling_func": 0,
    "sklearn.cluster._agglomerative.FeatureAgglomeration.__init__.distance_threshold": 0,
    "sklearn.cluster._agglomerative.FeatureAgglomeration.__init__.compute_distances": 0,
    "sklearn.cluster._agglomerative.FeatureAgglomeration.fit.y": 0,
    "sklearn.cluster._agglomerative.linkage_tree.X": 0,
    "sklearn.cluster._agglomerative.linkage_tree.connectivity": 0,
    "sklearn.cluster._agglomerative.linkage_tree.n_clusters": 0,
    "sklearn.cluster._agglomerative.linkage_tree.linkage": 0,
    "sklearn.cluster._agglomerative.linkage_tree.affinity": 0,
    "sklearn.cluster._agglomerative.linkage_tree.return_distance": 0,
    "sklearn.cluster._agglomerative.ward_tree.X": 0,
    "sklearn.cluster._agglomerative.ward_tree.connectivity": 0,
    "sklearn.cluster._agglomerative.ward_tree.n_clusters": 0,
    "sklearn.cluster._agglomerative.ward_tree.return_distance": 0,
    "sklearn.cluster._bicluster.SpectralBiclustering.__init__.n_clusters": 0,
    "sklearn.cluster._bicluster.SpectralBiclustering.__init__.method": 0,
    "sklearn.cluster._bicluster.SpectralBiclustering.__init__.n_components": 0,
    "sklearn.cluster._bicluster.SpectralBiclustering.__init__.n_best": 0,
    "sklearn.cluster._bicluster.SpectralBiclustering.__init__.svd_method": 0,
    "sklearn.cluster._bicluster.SpectralBiclustering.__init__.n_svd_vecs": 0,
    "sklearn.cluster._bicluster.SpectralBiclustering.__init__.mini_batch": 0,
    "sklearn.cluster._bicluster.SpectralBiclustering.__init__.init": 0,
    "sklearn.cluster._bicluster.SpectralBiclustering.__init__.n_init": 0,
    "sklearn.cluster._bicluster.SpectralBiclustering.__init__.n_jobs": 0,
    "sklearn.cluster._bicluster.SpectralBiclustering.__init__.random_state": 0,
    "sklearn.cluster._bicluster.SpectralCoclustering.__init__.n_clusters": 0,
    "sklearn.cluster._bicluster.SpectralCoclustering.__init__.svd_method": 0,
    "sklearn.cluster._bicluster.SpectralCoclustering.__init__.n_svd_vecs": 0,
    "sklearn.cluster._bicluster.SpectralCoclustering.__init__.mini_batch": 0,
    "sklearn.cluster._bicluster.SpectralCoclustering.__init__.init": 0,
    "sklearn.cluster._bicluster.SpectralCoclustering.__init__.n_init": 0,
    "sklearn.cluster._bicluster.SpectralCoclustering.__init__.n_jobs": 0,
    "sklearn.cluster._bicluster.SpectralCoclustering.__init__.random_state": 0,
    "sklearn.cluster._birch.Birch.fit.y": 0,
    "sklearn.cluster._birch.Birch.partial_fit.X": 0,
    "sklearn.cluster._birch.Birch.partial_fit.y": 0,
    "sklearn.cluster._birch.Birch.transform.X": 0,
    "sklearn.cluster._dbscan.DBSCAN.fit.y": 0,
    "sklearn.cluster._dbscan.DBSCAN.fit.sample_weight": 0,
    "sklearn.cluster._dbscan.DBSCAN.fit_predict.y": 0,
    "sklearn.cluster._dbscan.DBSCAN.fit_predict.sample_weight": 0,
    "sklearn.cluster._dbscan.dbscan.eps": 0,
    "sklearn.cluster._dbscan.dbscan.min_samples": 0,
    "sklearn.cluster._dbscan.dbscan.metric": 0,
    "sklearn.cluster._dbscan.dbscan.metric_params": 0,
    "sklearn.cluster._dbscan.dbscan.algorithm": 0,
    "sklearn.cluster._dbscan.dbscan.leaf_size": 0,
    "sklearn.cluster._dbscan.dbscan.p": 0,
    "sklearn.cluster._dbscan.dbscan.sample_weight": 0,
    "sklearn.cluster._dbscan.dbscan.n_jobs": 0,
    "sklearn.cluster._kmeans.KMeans.fit.sample_weight": 0,
    "sklearn.cluster._kmeans.KMeans.fit_predict.y": 0,
    "sklearn.cluster._kmeans.KMeans.fit_predict.sample_weight": 0,
    "sklearn.cluster._kmeans.KMeans.fit_transform.sample_weight": 0,
    "sklearn.cluster._kmeans.KMeans.predict.sample_weight": 0,
    "sklearn.cluster._kmeans.KMeans.score.y": 0,
    "sklearn.cluster._kmeans.KMeans.score.sample_weight": 0,
    "sklearn.cluster._kmeans.MiniBatchKMeans.__init__.compute_labels": 0,
    "sklearn.cluster._kmeans.MiniBatchKMeans.fit.y": 0,
    "sklearn.cluster._kmeans.MiniBatchKMeans.fit.sample_weight": 0,
    "sklearn.cluster._kmeans.MiniBatchKMeans.partial_fit.y": 0,
    "sklearn.cluster._kmeans.MiniBatchKMeans.partial_fit.sample_weight": 0,
    "sklearn.cluster._kmeans.MiniBatchKMeans.predict.sample_weight": 0,
    "sklearn.cluster._kmeans.k_means.sample_weight": 0,
    "sklearn.cluster._kmeans.k_means.init": 0,
    "sklearn.cluster._kmeans.k_means.precompute_distances": 0,
    "sklearn.cluster._kmeans.k_means.n_init": 0,
    "sklearn.cluster._kmeans.k_means.verbose": 0,
    "sklearn.cluster._kmeans.k_means.tol": 0,
    "sklearn.cluster._kmeans.k_means.copy_x": 0,
    "sklearn.cluster._kmeans.k_means.n_jobs": 0,
    "sklearn.cluster._kmeans.k_means.algorithm": 0,
    "sklearn.cluster._kmeans.k_means.return_n_iter": 0,
    "sklearn.cluster._kmeans.kmeans_plusplus.X": 0,
    "sklearn.cluster._kmeans.kmeans_plusplus.n_clusters": 0,
    "sklearn.cluster._kmeans.kmeans_plusplus.x_squared_norms": 0,
    "sklearn.cluster._kmeans.kmeans_plusplus.random_state": 0,
    "sklearn.cluster._kmeans.kmeans_plusplus.n_local_trials": 0,
    "sklearn.cluster._mean_shift.MeanShift.__init__.seeds": 0,
    "sklearn.cluster._mean_shift.MeanShift.__init__.n_jobs": 0,
    "sklearn.cluster._mean_shift.MeanShift.__init__.max_iter": 0,
    "sklearn.cluster._mean_shift.MeanShift.fit.y": 0,
    "sklearn.cluster._mean_shift.estimate_bandwidth.random_state": 0,
    "sklearn.cluster._mean_shift.estimate_bandwidth.n_jobs": 0,
    "sklearn.cluster._mean_shift.get_bin_seeds.X": 0,
    "sklearn.cluster._mean_shift.get_bin_seeds.bin_size": 0,
    "sklearn.cluster._mean_shift.get_bin_seeds.min_bin_freq": 0,
    "sklearn.cluster._mean_shift.mean_shift.X": 0,
    "sklearn.cluster._mean_shift.mean_shift.bandwidth": 0,
    "sklearn.cluster._mean_shift.mean_shift.seeds": 0,
    "sklearn.cluster._mean_shift.mean_shift.bin_seeding": 0,
    "sklearn.cluster._mean_shift.mean_shift.min_bin_freq": 0,
    "sklearn.cluster._mean_shift.mean_shift.cluster_all": 0,
    "sklearn.cluster._mean_shift.mean_shift.max_iter": 0,
    "sklearn.cluster._mean_shift.mean_shift.n_jobs": 0,
    "sklearn.cluster._optics.OPTICS.__init__.p": 0,
    "sklearn.cluster._optics.OPTICS.__init__.metric_params": 0,
    "sklearn.cluster._optics.OPTICS.__init__.cluster_method": 0,
    "sklearn.cluster._optics.OPTICS.__init__.eps": 0,
    "sklearn.cluster._optics.OPTICS.__init__.predecessor_correction": 0,
    "sklearn.cluster._optics.OPTICS.__init__.algorithm": 0,
    "sklearn.cluster._optics.OPTICS.__init__.leaf_size": 0,
    "sklearn.cluster._optics.OPTICS.__init__.n_jobs": 0,
    "sklearn.cluster._optics.OPTICS.fit.y": 0,
    "sklearn.cluster._optics.cluster_optics_dbscan.reachability": 0,
    "sklearn.cluster._optics.cluster_optics_dbscan.core_distances": 0,
    "sklearn.cluster._optics.cluster_optics_dbscan.ordering": 0,
    "sklearn.cluster._optics.cluster_optics_dbscan.eps": 0,
    "sklearn.cluster._optics.cluster_optics_xi.reachability": 0,
    "sklearn.cluster._optics.cluster_optics_xi.predecessor": 0,
    "sklearn.cluster._optics.cluster_optics_xi.ordering": 0,
    "sklearn.cluster._optics.cluster_optics_xi.min_samples": 0,
    "sklearn.cluster._optics.cluster_optics_xi.min_cluster_size": 0,
    "sklearn.cluster._optics.cluster_optics_xi.xi": 0,
    "sklearn.cluster._optics.cluster_optics_xi.predecessor_correction": 0,
    "sklearn.cluster._optics.compute_optics_graph.X": 0,
    "sklearn.cluster._optics.compute_optics_graph.min_samples": 0,
    "sklearn.cluster._optics.compute_optics_graph.max_eps": 0,
    "sklearn.cluster._optics.compute_optics_graph.metric": 0,
    "sklearn.cluster._optics.compute_optics_graph.p": 0,
    "sklearn.cluster._optics.compute_optics_graph.metric_params": 0,
    "sklearn.cluster._optics.compute_optics_graph.algorithm": 0,
    "sklearn.cluster._optics.compute_optics_graph.leaf_size": 0,
    "sklearn.cluster._optics.compute_optics_graph.n_jobs": 0,
    "sklearn.cluster._spectral.SpectralClustering.__init__.n_components": 0,
    "sklearn.cluster._spectral.SpectralClustering.__init__.n_init": 0,
    "sklearn.cluster._spectral.SpectralClustering.__init__.gamma": 0,
    "sklearn.cluster._spectral.SpectralClustering.__init__.n_neighbors": 0,
    "sklearn.cluster._spectral.SpectralClustering.__init__.eigen_tol": 0,
    "sklearn.cluster._spectral.SpectralClustering.__init__.degree": 0,
    "sklearn.cluster._spectral.SpectralClustering.__init__.coef0": 0,
    "sklearn.cluster._spectral.SpectralClustering.__init__.kernel_params": 0,
    "sklearn.cluster._spectral.SpectralClustering.__init__.n_jobs": 0,
    "sklearn.cluster._spectral.SpectralClustering.__init__.verbose": 0,
    "sklearn.cluster._spectral.SpectralClustering.fit.y": 0,
    "sklearn.cluster._spectral.SpectralClustering.fit_predict.y": 0,
    "sklearn.cluster._spectral.spectral_clustering.affinity": 0,
    "sklearn.cluster._spectral.spectral_clustering.n_clusters": 0,
    "sklearn.cluster._spectral.spectral_clustering.n_components": 0,
    "sklearn.cluster._spectral.spectral_clustering.eigen_solver": 0,
    "sklearn.cluster._spectral.spectral_clustering.random_state": 0,
    "sklearn.cluster._spectral.spectral_clustering.n_init": 0,
    "sklearn.cluster._spectral.spectral_clustering.eigen_tol": 0,
    "sklearn.cluster._spectral.spectral_clustering.assign_labels": 0,
    "sklearn.cluster._spectral.spectral_clustering.verbose": 0,
    "sklearn.cluster.setup.configuration.parent_package": 0,
    "sklearn.cluster.setup.configuration.top_path": 0,
    "sklearn.compose._column_transformer.ColumnTransformer.get_params.deep": 0,
    "sklearn.compose._column_transformer.make_column_selector.__call__.df": 0,
    "sklearn.compose._column_transformer.make_column_selector.__init__.pattern": 0,
    "sklearn.compose._column_transformer.make_column_transformer.sparse_threshold": 0,
    "sklearn.compose._column_transformer.make_column_transformer.n_jobs": 0,
    "sklearn.compose._column_transformer.make_column_transformer.verbose": 0,
    "sklearn.conftest.pytest_collection_modifyitems.config": 0,
    "sklearn.conftest.pytest_collection_modifyitems.items": 0,
    "sklearn.conftest.pytest_runtest_setup.item": 0,
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.__init__.store_precision": 0,
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.__init__.assume_centered": 0,
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.__init__.support_fraction": 0,
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.fit.y": 0,
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.score.X": 0,
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.score.y": 0,
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.score.sample_weight": 0,
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.score_samples.X": 0,
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.error_norm.comp_cov": 0,
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.error_norm.norm": 0,
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.error_norm.scaling": 0,
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.error_norm.squared": 0,
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.fit.y": 0,
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.score.X_test": 0,
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.score.y": 0,
    "sklearn.covariance._empirical_covariance.empirical_covariance.X": 0,
    "sklearn.covariance._empirical_covariance.empirical_covariance.assume_centered": 0,
    "sklearn.covariance._empirical_covariance.log_likelihood.emp_cov": 0,
    "sklearn.covariance._empirical_covariance.log_likelihood.precision": 0,
    "sklearn.covariance._graph_lasso.GraphicalLasso.__init__.mode": 0,
    "sklearn.covariance._graph_lasso.GraphicalLasso.__init__.tol": 0,
    "sklearn.covariance._graph_lasso.GraphicalLasso.__init__.enet_tol": 0,
    "sklearn.covariance._graph_lasso.GraphicalLasso.__init__.verbose": 0,
    "sklearn.covariance._graph_lasso.GraphicalLasso.__init__.assume_centered": 0,
    "sklearn.covariance._graph_lasso.GraphicalLasso.fit.y": 0,
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.__init__.alphas": 0,
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.__init__.n_refinements": 0,
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.__init__.cv": 0,
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.__init__.tol": 0,
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.__init__.enet_tol": 0,
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.__init__.max_iter": 0,
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.__init__.mode": 0,
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.__init__.verbose": 0,
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.__init__.assume_centered": 0,
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.fit.X": 0,
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.fit.y": 0,
    "sklearn.covariance._graph_lasso.graphical_lasso.emp_cov": 0,
    "sklearn.covariance._graph_lasso.graphical_lasso.alpha": 0,
    "sklearn.covariance._graph_lasso.graphical_lasso.cov_init": 0,
    "sklearn.covariance._graph_lasso.graphical_lasso.mode": 0,
    "sklearn.covariance._graph_lasso.graphical_lasso.tol": 0,
    "sklearn.covariance._graph_lasso.graphical_lasso.enet_tol": 0,
    "sklearn.covariance._graph_lasso.graphical_lasso.max_iter": 0,
    "sklearn.covariance._graph_lasso.graphical_lasso.verbose": 0,
    "sklearn.covariance._graph_lasso.graphical_lasso.return_costs": 0,
    "sklearn.covariance._graph_lasso.graphical_lasso.eps": 0,
    "sklearn.covariance._graph_lasso.graphical_lasso.return_n_iter": 0,
    "sklearn.covariance._robust_covariance.MinCovDet.__init__.store_precision": 0,
    "sklearn.covariance._robust_covariance.MinCovDet.__init__.assume_centered": 0,
    "sklearn.covariance._robust_covariance.MinCovDet.__init__.random_state": 0,
    "sklearn.covariance._robust_covariance.MinCovDet.correct_covariance.data": 0,
    "sklearn.covariance._robust_covariance.MinCovDet.fit.y": 0,
    "sklearn.covariance._robust_covariance.MinCovDet.reweight_covariance.data": 0,
    "sklearn.covariance._robust_covariance.fast_mcd.X": 0,
    "sklearn.covariance._robust_covariance.fast_mcd.support_fraction": 0,
    "sklearn.covariance._robust_covariance.fast_mcd.cov_computation_method": 0,
    "sklearn.covariance._robust_covariance.fast_mcd.random_state": 0,
    "sklearn.covariance._shrunk_covariance.LedoitWolf.__init__.store_precision": 0,
    "sklearn.covariance._shrunk_covariance.LedoitWolf.__init__.block_size": 0,
    "sklearn.covariance._shrunk_covariance.LedoitWolf.fit.y": 0,
    "sklearn.covariance._shrunk_covariance.OAS.fit.y": 0,
    "sklearn.covariance._shrunk_covariance.ShrunkCovariance.__init__.store_precision": 0,
    "sklearn.covariance._shrunk_covariance.ShrunkCovariance.__init__.assume_centered": 0,
    "sklearn.covariance._shrunk_covariance.ShrunkCovariance.fit.y": 0,
    "sklearn.covariance._shrunk_covariance.ledoit_wolf.assume_centered": 0,
    "sklearn.covariance._shrunk_covariance.ledoit_wolf.block_size": 0,
    "sklearn.covariance._shrunk_covariance.ledoit_wolf_shrinkage.X": 0,
    "sklearn.covariance._shrunk_covariance.ledoit_wolf_shrinkage.assume_centered": 0,
    "sklearn.covariance._shrunk_covariance.ledoit_wolf_shrinkage.block_size": 0,
    "sklearn.covariance._shrunk_covariance.oas.X": 0,
    "sklearn.covariance._shrunk_covariance.oas.assume_centered": 0,
    "sklearn.covariance._shrunk_covariance.shrunk_covariance.emp_cov": 0,
    "sklearn.covariance._shrunk_covariance.shrunk_covariance.shrinkage": 0,
    "sklearn.cross_decomposition._pls.CCA.__init__.scale": 0,
    "sklearn.cross_decomposition._pls.CCA.__init__.max_iter": 0,
    "sklearn.cross_decomposition._pls.CCA.__init__.tol": 0,
    "sklearn.cross_decomposition._pls.CCA.__init__.copy": 0,
    "sklearn.cross_decomposition._pls.PLSCanonical.__init__.n_components": 0,
    "sklearn.cross_decomposition._pls.PLSCanonical.__init__.scale": 0,
    "sklearn.cross_decomposition._pls.PLSCanonical.__init__.algorithm": 0,
    "sklearn.cross_decomposition._pls.PLSCanonical.__init__.max_iter": 0,
    "sklearn.cross_decomposition._pls.PLSCanonical.__init__.tol": 0,
    "sklearn.cross_decomposition._pls.PLSCanonical.__init__.copy": 0,
    "sklearn.cross_decomposition._pls.PLSSVD.__init__.scale": 0,
    "sklearn.cross_decomposition._pls.PLSSVD.__init__.copy": 0,
    "sklearn.cross_decomposition._pls.PLSSVD.fit.X": 0,
    "sklearn.cross_decomposition._pls.PLSSVD.fit.Y": 0,
    "sklearn.cross_decomposition._pls.PLSSVD.fit_transform.X": 0,
    "sklearn.cross_decomposition._pls.PLSSVD.fit_transform.y": 0,
    "sklearn.cross_decomposition._pls.PLSSVD.transform.X": 0,
    "sklearn.cross_decomposition._pls.PLSSVD.transform.Y": 0,
    "sklearn.datasets._base.clear_data_home.data_home": 0,
    "sklearn.datasets._base.get_data_home.data_home": 0,
    "sklearn.datasets._base.load_breast_cancer.as_frame": 0,
    "sklearn.datasets._base.load_diabetes.return_X_y": 0,
    "sklearn.datasets._base.load_diabetes.as_frame": 0,
    "sklearn.datasets._base.load_digits.n_class": 0,
    "sklearn.datasets._base.load_digits.as_frame": 0,
    "sklearn.datasets._base.load_files.description": 0,
    "sklearn.datasets._base.load_files.categories": 0,
    "sklearn.datasets._base.load_files.load_content": 0,
    "sklearn.datasets._base.load_files.shuffle": 0,
    "sklearn.datasets._base.load_files.decode_error": 0,
    "sklearn.datasets._base.load_files.random_state": 0,
    "sklearn.datasets._base.load_iris.as_frame": 0,
    "sklearn.datasets._base.load_linnerud.return_X_y": 0,
    "sklearn.datasets._base.load_linnerud.as_frame": 0,
    "sklearn.datasets._base.load_wine.return_X_y": 0,
    "sklearn.datasets._base.load_wine.as_frame": 0,
    "sklearn.datasets._california_housing.fetch_california_housing.data_home": 0,
    "sklearn.datasets._california_housing.fetch_california_housing.download_if_missing": 0,
    "sklearn.datasets._california_housing.fetch_california_housing.return_X_y": 0,
    "sklearn.datasets._california_housing.fetch_california_housing.as_frame": 0,
    "sklearn.datasets._covtype.fetch_covtype.data_home": 0,
    "sklearn.datasets._covtype.fetch_covtype.download_if_missing": 0,
    "sklearn.datasets._covtype.fetch_covtype.random_state": 0,
    "sklearn.datasets._covtype.fetch_covtype.shuffle": 0,
    "sklearn.datasets._covtype.fetch_covtype.return_X_y": 0,
    "sklearn.datasets._covtype.fetch_covtype.as_frame": 0,
    "sklearn.datasets._kddcup99.fetch_kddcup99.subset": 0,
    "sklearn.datasets._kddcup99.fetch_kddcup99.data_home": 0,
    "sklearn.datasets._kddcup99.fetch_kddcup99.shuffle": 0,
    "sklearn.datasets._kddcup99.fetch_kddcup99.random_state": 0,
    "sklearn.datasets._kddcup99.fetch_kddcup99.percent10": 0,
    "sklearn.datasets._kddcup99.fetch_kddcup99.download_if_missing": 0,
    "sklearn.datasets._kddcup99.fetch_kddcup99.return_X_y": 0,
    "sklearn.datasets._kddcup99.fetch_kddcup99.as_frame": 0,
    "sklearn.datasets._lfw.fetch_lfw_pairs.subset": 0,
    "sklearn.datasets._lfw.fetch_lfw_pairs.data_home": 0,
    "sklearn.datasets._lfw.fetch_lfw_pairs.funneled": 0,
    "sklearn.datasets._lfw.fetch_lfw_pairs.resize": 0,
    "sklearn.datasets._lfw.fetch_lfw_pairs.color": 0,
    "sklearn.datasets._lfw.fetch_lfw_pairs.slice_": 0,
    "sklearn.datasets._lfw.fetch_lfw_pairs.download_if_missing": 0,
    "sklearn.datasets._lfw.fetch_lfw_people.data_home": 0,
    "sklearn.datasets._lfw.fetch_lfw_people.funneled": 0,
    "sklearn.datasets._lfw.fetch_lfw_people.resize": 0,
    "sklearn.datasets._lfw.fetch_lfw_people.min_faces_per_person": 0,
    "sklearn.datasets._lfw.fetch_lfw_people.color": 0,
    "sklearn.datasets._lfw.fetch_lfw_people.slice_": 0,
    "sklearn.datasets._lfw.fetch_lfw_people.download_if_missing": 0,
    "sklearn.datasets._lfw.fetch_lfw_people.return_X_y": 0,
    "sklearn.datasets._olivetti_faces.fetch_olivetti_faces.data_home": 0,
    "sklearn.datasets._olivetti_faces.fetch_olivetti_faces.shuffle": 0,
    "sklearn.datasets._olivetti_faces.fetch_olivetti_faces.random_state": 0,
    "sklearn.datasets._olivetti_faces.fetch_olivetti_faces.download_if_missing": 0,
    "sklearn.datasets._olivetti_faces.fetch_olivetti_faces.return_X_y": 0,
    "sklearn.datasets._openml.fetch_openml.data_id": 0,
    "sklearn.datasets._openml.fetch_openml.data_home": 0,
    "sklearn.datasets._openml.fetch_openml.target_column": 0,
    "sklearn.datasets._openml.fetch_openml.cache": 0,
    "sklearn.datasets._openml.fetch_openml.return_X_y": 0,
    "sklearn.datasets._rcv1.fetch_rcv1.data_home": 0,
    "sklearn.datasets._rcv1.fetch_rcv1.subset": 0,
    "sklearn.datasets._rcv1.fetch_rcv1.download_if_missing": 0,
    "sklearn.datasets._rcv1.fetch_rcv1.random_state": 0,
    "sklearn.datasets._rcv1.fetch_rcv1.shuffle": 0,
    "sklearn.datasets._rcv1.fetch_rcv1.return_X_y": 0,
    "sklearn.datasets._samples_generator.make_biclusters.shape": 0,
    "sklearn.datasets._samples_generator.make_biclusters.n_clusters": 0,
    "sklearn.datasets._samples_generator.make_biclusters.noise": 0,
    "sklearn.datasets._samples_generator.make_biclusters.minval": 0,
    "sklearn.datasets._samples_generator.make_biclusters.maxval": 0,
    "sklearn.datasets._samples_generator.make_biclusters.shuffle": 0,
    "sklearn.datasets._samples_generator.make_biclusters.random_state": 0,
    "sklearn.datasets._samples_generator.make_blobs.center_box": 0,
    "sklearn.datasets._samples_generator.make_blobs.shuffle": 0,
    "sklearn.datasets._samples_generator.make_blobs.return_centers": 0,
    "sklearn.datasets._samples_generator.make_checkerboard.shape": 0,
    "sklearn.datasets._samples_generator.make_checkerboard.n_clusters": 0,
    "sklearn.datasets._samples_generator.make_checkerboard.noise": 0,
    "sklearn.datasets._samples_generator.make_checkerboard.minval": 0,
    "sklearn.datasets._samples_generator.make_checkerboard.maxval": 0,
    "sklearn.datasets._samples_generator.make_checkerboard.shuffle": 0,
    "sklearn.datasets._samples_generator.make_checkerboard.random_state": 0,
    "sklearn.datasets._samples_generator.make_circles.shuffle": 0,
    "sklearn.datasets._samples_generator.make_friedman1.n_samples": 0,
    "sklearn.datasets._samples_generator.make_friedman1.n_features": 0,
    "sklearn.datasets._samples_generator.make_friedman1.noise": 0,
    "sklearn.datasets._samples_generator.make_friedman1.random_state": 0,
    "sklearn.datasets._samples_generator.make_friedman2.n_samples": 0,
    "sklearn.datasets._samples_generator.make_friedman2.noise": 0,
    "sklearn.datasets._samples_generator.make_friedman2.random_state": 0,
    "sklearn.datasets._samples_generator.make_friedman3.n_samples": 0,
    "sklearn.datasets._samples_generator.make_friedman3.noise": 0,
    "sklearn.datasets._samples_generator.make_friedman3.random_state": 0,
    "sklearn.datasets._samples_generator.make_gaussian_quantiles.mean": 0,
    "sklearn.datasets._samples_generator.make_gaussian_quantiles.cov": 0,
    "sklearn.datasets._samples_generator.make_gaussian_quantiles.n_samples": 0,
    "sklearn.datasets._samples_generator.make_gaussian_quantiles.n_features": 0,
    "sklearn.datasets._samples_generator.make_gaussian_quantiles.n_classes": 0,
    "sklearn.datasets._samples_generator.make_gaussian_quantiles.shuffle": 0,
    "sklearn.datasets._samples_generator.make_gaussian_quantiles.random_state": 0,
    "sklearn.datasets._samples_generator.make_hastie_10_2.n_samples": 0,
    "sklearn.datasets._samples_generator.make_hastie_10_2.random_state": 0,
    "sklearn.datasets._samples_generator.make_low_rank_matrix.n_samples": 0,
    "sklearn.datasets._samples_generator.make_low_rank_matrix.n_features": 0,
    "sklearn.datasets._samples_generator.make_low_rank_matrix.effective_rank": 0,
    "sklearn.datasets._samples_generator.make_low_rank_matrix.tail_strength": 0,
    "sklearn.datasets._samples_generator.make_low_rank_matrix.random_state": 0,
    "sklearn.datasets._samples_generator.make_moons.shuffle": 0,
    "sklearn.datasets._samples_generator.make_multilabel_classification.n_labels": 0,
    "sklearn.datasets._samples_generator.make_multilabel_classification.length": 0,
    "sklearn.datasets._samples_generator.make_multilabel_classification.allow_unlabeled": 0,
    "sklearn.datasets._samples_generator.make_multilabel_classification.sparse": 0,
    "sklearn.datasets._samples_generator.make_multilabel_classification.return_indicator": 0,
    "sklearn.datasets._samples_generator.make_multilabel_classification.return_distributions": 0,
    "sklearn.datasets._samples_generator.make_regression.n_informative": 0,
    "sklearn.datasets._samples_generator.make_regression.n_targets": 0,
    "sklearn.datasets._samples_generator.make_regression.effective_rank": 0,
    "sklearn.datasets._samples_generator.make_regression.tail_strength": 0,
    "sklearn.datasets._samples_generator.make_regression.shuffle": 0,
    "sklearn.datasets._samples_generator.make_regression.coef": 0,
    "sklearn.datasets._samples_generator.make_s_curve.n_samples": 0,
    "sklearn.datasets._samples_generator.make_s_curve.noise": 0,
    "sklearn.datasets._samples_generator.make_s_curve.random_state": 0,
    "sklearn.datasets._samples_generator.make_sparse_coded_signal.n_samples": 0,
    "sklearn.datasets._samples_generator.make_sparse_coded_signal.n_components": 0,
    "sklearn.datasets._samples_generator.make_sparse_coded_signal.n_features": 0,
    "sklearn.datasets._samples_generator.make_sparse_coded_signal.n_nonzero_coefs": 0,
    "sklearn.datasets._samples_generator.make_sparse_coded_signal.random_state": 0,
    "sklearn.datasets._samples_generator.make_sparse_spd_matrix.dim": 0,
    "sklearn.datasets._samples_generator.make_sparse_spd_matrix.alpha": 0,
    "sklearn.datasets._samples_generator.make_sparse_spd_matrix.norm_diag": 0,
    "sklearn.datasets._samples_generator.make_sparse_spd_matrix.smallest_coef": 0,
    "sklearn.datasets._samples_generator.make_sparse_spd_matrix.largest_coef": 0,
    "sklearn.datasets._samples_generator.make_sparse_spd_matrix.random_state": 0,
    "sklearn.datasets._samples_generator.make_sparse_uncorrelated.n_samples": 0,
    "sklearn.datasets._samples_generator.make_sparse_uncorrelated.n_features": 0,
    "sklearn.datasets._samples_generator.make_sparse_uncorrelated.random_state": 0,
    "sklearn.datasets._samples_generator.make_spd_matrix.n_dim": 0,
    "sklearn.datasets._samples_generator.make_spd_matrix.random_state": 0,
    "sklearn.datasets._samples_generator.make_swiss_roll.n_samples": 0,
    "sklearn.datasets._samples_generator.make_swiss_roll.noise": 0,
    "sklearn.datasets._samples_generator.make_swiss_roll.random_state": 0,
    "sklearn.datasets._species_distributions.fetch_species_distributions.data_home": 0,
    "sklearn.datasets._species_distributions.fetch_species_distributions.download_if_missing": 0,
    "sklearn.datasets._svmlight_format_io.dump_svmlight_file.comment": 0,
    "sklearn.datasets._svmlight_format_io.dump_svmlight_file.query_id": 0,
    "sklearn.datasets._svmlight_format_io.dump_svmlight_file.multilabel": 0,
    "sklearn.datasets._svmlight_format_io.load_svmlight_file.n_features": 0,
    "sklearn.datasets._svmlight_format_io.load_svmlight_file.dtype": 0,
    "sklearn.datasets._svmlight_format_io.load_svmlight_file.multilabel": 0,
    "sklearn.datasets._svmlight_format_io.load_svmlight_file.query_id": 0,
    "sklearn.datasets._svmlight_format_io.load_svmlight_file.offset": 0,
    "sklearn.datasets._svmlight_format_io.load_svmlight_file.length": 0,
    "sklearn.datasets._svmlight_format_io.load_svmlight_files.files": 0,
    "sklearn.datasets._svmlight_format_io.load_svmlight_files.n_features": 0,
    "sklearn.datasets._svmlight_format_io.load_svmlight_files.dtype": 0,
    "sklearn.datasets._svmlight_format_io.load_svmlight_files.multilabel": 0,
    "sklearn.datasets._svmlight_format_io.load_svmlight_files.zero_based": 0,
    "sklearn.datasets._svmlight_format_io.load_svmlight_files.query_id": 0,
    "sklearn.datasets._svmlight_format_io.load_svmlight_files.offset": 0,
    "sklearn.datasets._svmlight_format_io.load_svmlight_files.length": 0,
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups.data_home": 0,
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups.categories": 0,
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups.shuffle": 0,
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups.random_state": 0,
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups.remove": 0,
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups.return_X_y": 0,
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups_vectorized.subset": 0,
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups_vectorized.remove": 0,
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups_vectorized.data_home": 0,
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups_vectorized.download_if_missing": 0,
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups_vectorized.return_X_y": 0,
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups_vectorized.normalize": 0,
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups_vectorized.as_frame": 0,
    "sklearn.datasets.setup.configuration.parent_package": 0,
    "sklearn.datasets.setup.configuration.top_path": 0,
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.n_components": 0,
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.alpha": 0,
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.max_iter": 0,
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.tol": 0,
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.fit_algorithm": 0,
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.transform_algorithm": 0,
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.transform_n_nonzero_coefs": 0,
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.transform_alpha": 0,
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.n_jobs": 0,
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.code_init": 0,
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.dict_init": 0,
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.verbose": 0,
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.split_sign": 0,
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.random_state": 0,
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.positive_code": 0,
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.positive_dict": 0,
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.transform_max_iter": 0,
    "sklearn.decomposition._dict_learning.DictionaryLearning.fit.X": 0,
    "sklearn.decomposition._dict_learning.DictionaryLearning.fit.y": 0,
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.fit_algorithm": 0,
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.n_jobs": 0,
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.shuffle": 0,
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.dict_init": 0,
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.transform_algorithm": 0,
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.transform_n_nonzero_coefs": 0,
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.transform_alpha": 0,
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.verbose": 0,
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.split_sign": 0,
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.positive_code": 0,
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.positive_dict": 0,
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.transform_max_iter": 0,
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.fit.X": 0,
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.fit.y": 0,
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.partial_fit.X": 0,
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.partial_fit.y": 0,
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.partial_fit.iter_offset": 0,
    "sklearn.decomposition._dict_learning.SparseCoder.__init__.dictionary": 0,
    "sklearn.decomposition._dict_learning.SparseCoder.__init__.transform_algorithm": 0,
    "sklearn.decomposition._dict_learning.SparseCoder.__init__.transform_n_nonzero_coefs": 0,
    "sklearn.decomposition._dict_learning.SparseCoder.__init__.transform_alpha": 0,
    "sklearn.decomposition._dict_learning.SparseCoder.__init__.split_sign": 0,
    "sklearn.decomposition._dict_learning.SparseCoder.__init__.n_jobs": 0,
    "sklearn.decomposition._dict_learning.SparseCoder.__init__.positive_code": 0,
    "sklearn.decomposition._dict_learning.SparseCoder.__init__.transform_max_iter": 0,
    "sklearn.decomposition._dict_learning.SparseCoder.fit.X": 0,
    "sklearn.decomposition._dict_learning.SparseCoder.fit.y": 0,
    "sklearn.decomposition._dict_learning.SparseCoder.transform.X": 0,
    "sklearn.decomposition._dict_learning.SparseCoder.transform.y": 0,
    "sklearn.decomposition._dict_learning.dict_learning.X": 0,
    "sklearn.decomposition._dict_learning.dict_learning.n_components": 0,
    "sklearn.decomposition._dict_learning.dict_learning.alpha": 0,
    "sklearn.decomposition._dict_learning.dict_learning.max_iter": 0,
    "sklearn.decomposition._dict_learning.dict_learning.tol": 0,
    "sklearn.decomposition._dict_learning.dict_learning.method": 0,
    "sklearn.decomposition._dict_learning.dict_learning.n_jobs": 0,
    "sklearn.decomposition._dict_learning.dict_learning.dict_init": 0,
    "sklearn.decomposition._dict_learning.dict_learning.code_init": 0,
    "sklearn.decomposition._dict_learning.dict_learning.callback": 0,
    "sklearn.decomposition._dict_learning.dict_learning.verbose": 0,
    "sklearn.decomposition._dict_learning.dict_learning.random_state": 0,
    "sklearn.decomposition._dict_learning.dict_learning.return_n_iter": 0,
    "sklearn.decomposition._dict_learning.dict_learning.positive_dict": 0,
    "sklearn.decomposition._dict_learning.dict_learning.positive_code": 0,
    "sklearn.decomposition._dict_learning.dict_learning.method_max_iter": 0,
    "sklearn.decomposition._dict_learning.dict_learning_online.X": 0,
    "sklearn.decomposition._dict_learning.dict_learning_online.n_components": 0,
    "sklearn.decomposition._dict_learning.dict_learning_online.alpha": 0,
    "sklearn.decomposition._dict_learning.dict_learning_online.n_iter": 0,
    "sklearn.decomposition._dict_learning.dict_learning_online.return_code": 0,
    "sklearn.decomposition._dict_learning.dict_learning_online.dict_init": 0,
    "sklearn.decomposition._dict_learning.dict_learning_online.callback": 0,
    "sklearn.decomposition._dict_learning.dict_learning_online.batch_size": 0,
    "sklearn.decomposition._dict_learning.dict_learning_online.verbose": 0,
    "sklearn.decomposition._dict_learning.dict_learning_online.shuffle": 0,
    "sklearn.decomposition._dict_learning.dict_learning_online.n_jobs": 0,
    "sklearn.decomposition._dict_learning.dict_learning_online.method": 0,
    "sklearn.decomposition._dict_learning.dict_learning_online.iter_offset": 0,
    "sklearn.decomposition._dict_learning.dict_learning_online.random_state": 0,
    "sklearn.decomposition._dict_learning.dict_learning_online.return_inner_stats": 0,
    "sklearn.decomposition._dict_learning.dict_learning_online.inner_stats": 0,
    "sklearn.decomposition._dict_learning.dict_learning_online.return_n_iter": 0,
    "sklearn.decomposition._dict_learning.dict_learning_online.positive_dict": 0,
    "sklearn.decomposition._dict_learning.dict_learning_online.positive_code": 0,
    "sklearn.decomposition._dict_learning.dict_learning_online.method_max_iter": 0,
    "sklearn.decomposition._dict_learning.sparse_encode.X": 0,
    "sklearn.decomposition._dict_learning.sparse_encode.dictionary": 0,
    "sklearn.decomposition._dict_learning.sparse_encode.gram": 0,
    "sklearn.decomposition._dict_learning.sparse_encode.cov": 0,
    "sklearn.decomposition._dict_learning.sparse_encode.algorithm": 0,
    "sklearn.decomposition._dict_learning.sparse_encode.n_nonzero_coefs": 0,
    "sklearn.decomposition._dict_learning.sparse_encode.alpha": 0,
    "sklearn.decomposition._dict_learning.sparse_encode.copy_cov": 0,
    "sklearn.decomposition._dict_learning.sparse_encode.init": 0,
    "sklearn.decomposition._dict_learning.sparse_encode.max_iter": 0,
    "sklearn.decomposition._dict_learning.sparse_encode.n_jobs": 0,
    "sklearn.decomposition._dict_learning.sparse_encode.check_input": 0,
    "sklearn.decomposition._dict_learning.sparse_encode.verbose": 0,
    "sklearn.decomposition._dict_learning.sparse_encode.positive": 0,
    "sklearn.decomposition._factor_analysis.FactorAnalysis.__init__.tol": 0,
    "sklearn.decomposition._factor_analysis.FactorAnalysis.__init__.copy": 0,
    "sklearn.decomposition._factor_analysis.FactorAnalysis.__init__.max_iter": 0,
    "sklearn.decomposition._factor_analysis.FactorAnalysis.__init__.noise_variance_init": 0,
    "sklearn.decomposition._factor_analysis.FactorAnalysis.__init__.svd_method": 0,
    "sklearn.decomposition._factor_analysis.FactorAnalysis.__init__.iterated_power": 0,
    "sklearn.decomposition._factor_analysis.FactorAnalysis.fit.y": 0,
    "sklearn.decomposition._factor_analysis.FactorAnalysis.score.X": 0,
    "sklearn.decomposition._factor_analysis.FactorAnalysis.score.y": 0,
    "sklearn.decomposition._factor_analysis.FactorAnalysis.score_samples.X": 0,
    "sklearn.decomposition._fastica.FastICA.__init__.fun": 0,
    "sklearn.decomposition._fastica.FastICA.__init__.fun_args": 0,
    "sklearn.decomposition._fastica.FastICA.__init__.w_init": 0,
    "sklearn.decomposition._fastica.FastICA.fit.y": 0,
    "sklearn.decomposition._fastica.FastICA.fit_transform.y": 0,
    "sklearn.decomposition._fastica.FastICA.inverse_transform.copy": 0,
    "sklearn.decomposition._fastica.FastICA.transform.copy": 0,
    "sklearn.decomposition._fastica.fastica.X": 0,
    "sklearn.decomposition._fastica.fastica.n_components": 0,
    "sklearn.decomposition._fastica.fastica.algorithm": 0,
    "sklearn.decomposition._fastica.fastica.whiten": 0,
    "sklearn.decomposition._fastica.fastica.fun": 0,
    "sklearn.decomposition._fastica.fastica.fun_args": 0,
    "sklearn.decomposition._fastica.fastica.max_iter": 0,
    "sklearn.decomposition._fastica.fastica.tol": 0,
    "sklearn.decomposition._fastica.fastica.w_init": 0,
    "sklearn.decomposition._fastica.fastica.random_state": 0,
    "sklearn.decomposition._fastica.fastica.return_X_mean": 0,
    "sklearn.decomposition._fastica.fastica.compute_sources": 0,
    "sklearn.decomposition._fastica.fastica.return_n_iter": 0,
    "sklearn.decomposition._incremental_pca.IncrementalPCA.__init__.whiten": 0,
    "sklearn.decomposition._incremental_pca.IncrementalPCA.fit.y": 0,
    "sklearn.decomposition._incremental_pca.IncrementalPCA.partial_fit.y": 0,
    "sklearn.decomposition._incremental_pca.IncrementalPCA.partial_fit.check_input": 0,
    "sklearn.decomposition._kernel_pca.KernelPCA.fit.y": 0,
    "sklearn.decomposition._kernel_pca.KernelPCA.inverse_transform.X": 0,
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.doc_topic_prior": 0,
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.topic_word_prior": 0,
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.batch_size": 0,
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.evaluate_every": 0,
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.total_samples": 0,
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.perp_tol": 0,
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.mean_change_tol": 0,
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.max_doc_update_iter": 0,
    "sklearn.decomposition._lda.LatentDirichletAllocation.partial_fit.X": 0,
    "sklearn.decomposition._lda.LatentDirichletAllocation.partial_fit.y": 0,
    "sklearn.decomposition._lda.LatentDirichletAllocation.perplexity.sub_sampling": 0,
    "sklearn.decomposition._lda.LatentDirichletAllocation.score.y": 0,
    "sklearn.decomposition._nmf.NMF.__init__.verbose": 0,
    "sklearn.decomposition._nmf.NMF.__init__.regularization": 0,
    "sklearn.decomposition._nmf.NMF.fit.y": 0,
    "sklearn.decomposition._nmf.NMF.fit_transform.y": 0,
    "sklearn.decomposition._nmf.NMF.fit_transform.W": 0,
    "sklearn.decomposition._nmf.NMF.fit_transform.H": 0,
    "sklearn.decomposition._nmf.NMF.inverse_transform.W": 0,
    "sklearn.decomposition._nmf.non_negative_factorization.X": 0,
    "sklearn.decomposition._nmf.non_negative_factorization.W": 0,
    "sklearn.decomposition._nmf.non_negative_factorization.H": 0,
    "sklearn.decomposition._nmf.non_negative_factorization.n_components": 0,
    "sklearn.decomposition._nmf.non_negative_factorization.init": 0,
    "sklearn.decomposition._nmf.non_negative_factorization.update_H": 0,
    "sklearn.decomposition._nmf.non_negative_factorization.solver": 0,
    "sklearn.decomposition._nmf.non_negative_factorization.beta_loss": 0,
    "sklearn.decomposition._nmf.non_negative_factorization.tol": 0,
    "sklearn.decomposition._nmf.non_negative_factorization.max_iter": 0,
    "sklearn.decomposition._nmf.non_negative_factorization.alpha": 0,
    "sklearn.decomposition._nmf.non_negative_factorization.l1_ratio": 0,
    "sklearn.decomposition._nmf.non_negative_factorization.regularization": 0,
    "sklearn.decomposition._nmf.non_negative_factorization.random_state": 0,
    "sklearn.decomposition._nmf.non_negative_factorization.verbose": 0,
    "sklearn.decomposition._nmf.non_negative_factorization.shuffle": 0,
    "sklearn.decomposition._pca.PCA.score.X": 0,
    "sklearn.decomposition._pca.PCA.score.y": 0,
    "sklearn.decomposition._pca.PCA.score_samples.X": 0,
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.__init__.n_components": 0,
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.__init__.alpha": 0,
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.__init__.ridge_alpha": 0,
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.__init__.n_iter": 0,
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.__init__.callback": 0,
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.__init__.batch_size": 0,
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.__init__.verbose": 0,
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.__init__.shuffle": 0,
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.__init__.n_jobs": 0,
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.__init__.method": 0,
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.__init__.random_state": 0,
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.fit.X": 0,
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.fit.y": 0,
    "sklearn.decomposition._sparse_pca.SparsePCA.__init__.alpha": 0,
    "sklearn.decomposition._sparse_pca.SparsePCA.__init__.ridge_alpha": 0,
    "sklearn.decomposition._sparse_pca.SparsePCA.__init__.max_iter": 0,
    "sklearn.decomposition._sparse_pca.SparsePCA.__init__.tol": 0,
    "sklearn.decomposition._sparse_pca.SparsePCA.__init__.method": 0,
    "sklearn.decomposition._sparse_pca.SparsePCA.__init__.n_jobs": 0,
    "sklearn.decomposition._sparse_pca.SparsePCA.__init__.U_init": 0,
    "sklearn.decomposition._sparse_pca.SparsePCA.__init__.V_init": 0,
    "sklearn.decomposition._sparse_pca.SparsePCA.__init__.verbose": 0,
    "sklearn.decomposition._sparse_pca.SparsePCA.fit.X": 0,
    "sklearn.decomposition._sparse_pca.SparsePCA.fit.y": 0,
    "sklearn.decomposition.setup.configuration.parent_package": 0,
    "sklearn.decomposition.setup.configuration.top_path": 0,
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.decision_function.X": 0,
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict_log_proba.X": 0,
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.decision_function.X": 0,
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.predict_log_proba.X": 0,
    "sklearn.dummy.DummyClassifier.fit.sample_weight": 0,
    "sklearn.dummy.DummyClassifier.predict_log_proba.X": 0,
    "sklearn.dummy.DummyClassifier.score.sample_weight": 0,
    "sklearn.dummy.DummyRegressor.__init__.quantile": 0,
    "sklearn.dummy.DummyRegressor.fit.sample_weight": 0,
    "sklearn.dummy.DummyRegressor.predict.return_std": 0,
    "sklearn.dummy.DummyRegressor.score.sample_weight": 0,
    "sklearn.ensemble._bagging.BaggingClassifier.decision_function.X": 0,
    "sklearn.ensemble._bagging.BaggingClassifier.predict_log_proba.X": 0,
    "sklearn.ensemble._base.BaseEnsemble.__getitem__.index": 0,
    "sklearn.ensemble._base.BaseEnsemble.__init__.base_estimator": 0,
    "sklearn.ensemble._base.BaseEnsemble.__init__.n_estimators": 0,
    "sklearn.ensemble._base.BaseEnsemble.__init__.estimator_params": 0,
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__.min_samples_leaf": 0,
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__.min_weight_fraction_leaf": 0,
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__.max_leaf_nodes": 0,
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__.min_impurity_decrease": 0,
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__.min_impurity_split": 0,
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__.warm_start": 0,
    "sklearn.ensemble._forest.RandomTreesEmbedding.fit.y": 0,
    "sklearn.ensemble._forest.RandomTreesEmbedding.fit.sample_weight": 0,
    "sklearn.ensemble._forest.RandomTreesEmbedding.fit_transform.X": 0,
    "sklearn.ensemble._forest.RandomTreesEmbedding.fit_transform.y": 0,
    "sklearn.ensemble._forest.RandomTreesEmbedding.fit_transform.sample_weight": 0,
    "sklearn.ensemble._gb.GradientBoostingClassifier.decision_function.X": 0,
    "sklearn.ensemble._gb.GradientBoostingRegressor.apply.X": 0,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.categorical_features": 0,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.monotonic_cst": 0,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.early_stopping": 0,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.decision_function.X": 0,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.staged_decision_function.X": 0,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.staged_predict.X": 0,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.staged_predict_proba.X": 0,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.max_bins": 0,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.categorical_features": 0,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.monotonic_cst": 0,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.warm_start": 0,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.scoring": 0,
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.staged_predict.X": 0,
    "sklearn.ensemble._iforest.IsolationForest.__init__.warm_start": 0,
    "sklearn.ensemble._iforest.IsolationForest.fit.sample_weight": 0,
    "sklearn.ensemble._stacking.StackingClassifier.decision_function.X": 0,
    "sklearn.ensemble._stacking.StackingClassifier.fit.sample_weight": 0,
    "sklearn.ensemble._stacking.StackingClassifier.transform.X": 0,
    "sklearn.ensemble._stacking.StackingRegressor.fit.sample_weight": 0,
    "sklearn.ensemble._stacking.StackingRegressor.transform.X": 0,
    "sklearn.ensemble._voting.VotingClassifier.fit.sample_weight": 0,
    "sklearn.ensemble._voting.VotingClassifier.transform.X": 0,
    "sklearn.ensemble._voting.VotingRegressor.fit.sample_weight": 0,
    "sklearn.ensemble._voting.VotingRegressor.transform.X": 0,
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.decision_function.X": 0,
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.predict_log_proba.X": 0,
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.staged_decision_function.X": 0,
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.staged_predict_proba.X": 0,
    "sklearn.ensemble._weight_boosting.AdaBoostRegressor.fit.sample_weight": 0,
    "sklearn.ensemble._weight_boosting.AdaBoostRegressor.staged_predict.X": 0,
    "sklearn.ensemble.setup.configuration.parent_package": 0,
    "sklearn.ensemble.setup.configuration.top_path": 0,
    "sklearn.externals.conftest.pytest_ignore_collect.path": 0,
    "sklearn.externals.conftest.pytest_ignore_collect.config": 0,
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.__init__.dtype": 0,
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.__init__.separator": 0,
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.fit.y": 0,
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.fit_transform.y": 0,
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.inverse_transform.X": 0,
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.inverse_transform.dict_type": 0,
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.restrict.support": 0,
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.restrict.indices": 0,
    "sklearn.feature_extraction._hash.FeatureHasher.__init__.alternate_sign": 0,
    "sklearn.feature_extraction._hash.FeatureHasher.fit.X": 0,
    "sklearn.feature_extraction._hash.FeatureHasher.fit.y": 0,
    "sklearn.feature_extraction.image.PatchExtractor.fit.X": 0,
    "sklearn.feature_extraction.image.PatchExtractor.fit.y": 0,
    "sklearn.feature_extraction.image.PatchExtractor.transform.X": 0,
    "sklearn.feature_extraction.image.grid_to_graph.n_x": 0,
    "sklearn.feature_extraction.image.grid_to_graph.n_y": 0,
    "sklearn.feature_extraction.image.grid_to_graph.n_z": 0,
    "sklearn.feature_extraction.image.grid_to_graph.mask": 0,
    "sklearn.feature_extraction.image.grid_to_graph.return_as": 0,
    "sklearn.feature_extraction.image.grid_to_graph.dtype": 0,
    "sklearn.feature_extraction.image.img_to_graph.img": 0,
    "sklearn.feature_extraction.image.img_to_graph.mask": 0,
    "sklearn.feature_extraction.image.img_to_graph.return_as": 0,
    "sklearn.feature_extraction.image.img_to_graph.dtype": 0,
    "sklearn.feature_extraction.image.reconstruct_from_patches_2d.patches": 0,
    "sklearn.feature_extraction.image.reconstruct_from_patches_2d.image_size": 0,
    "sklearn.feature_extraction.setup.configuration.parent_package": 0,
    "sklearn.feature_extraction.setup.configuration.top_path": 0,
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.input": 0,
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.encoding": 0,
    "sklearn.feature_extraction.text.HashingVectorizer.fit.y": 0,
    "sklearn.feature_extraction.text.HashingVectorizer.fit_transform.y": 0,
    "sklearn.feature_extraction.text.HashingVectorizer.partial_fit.X": 0,
    "sklearn.feature_extraction.text.HashingVectorizer.partial_fit.y": 0,
    "sklearn.feature_extraction.text.TfidfTransformer.fit.y": 0,
    "sklearn.feature_extraction.text.strip_accents_ascii.s": 0,
    "sklearn.feature_extraction.text.strip_accents_unicode.s": 0,
    "sklearn.feature_extraction.text.strip_tags.s": 0,
    "sklearn.feature_selection._from_model.SelectFromModel.__init__.norm_order": 0,
    "sklearn.feature_selection._from_model.SelectFromModel.__init__.importance_getter": 0,
    "sklearn.feature_selection._from_model.SelectFromModel.partial_fit.X": 0,
    "sklearn.feature_selection._from_model.SelectFromModel.partial_fit.y": 0,
    "sklearn.feature_selection._mutual_info.mutual_info_classif.copy": 0,
    "sklearn.feature_selection._rfe.RFE.__init__.importance_getter": 0,
    "sklearn.feature_selection._rfe.RFE.decision_function.X": 0,
    "sklearn.feature_selection._rfe.RFE.predict_log_proba.X": 0,
    "sklearn.feature_selection._rfe.RFECV.__init__.importance_getter": 0,
    "sklearn.feature_selection._rfe.RFECV.fit.groups": 0,
    "sklearn.feature_selection._sequential.SequentialFeatureSelector.__init__.n_jobs": 0,
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.__init__.copy_X_train": 0,
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.__init__.multi_class": 0,
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.log_marginal_likelihood.theta": 0,
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.log_marginal_likelihood.eval_gradient": 0,
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.log_marginal_likelihood.clone_kernel": 0,
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.predict_proba.X": 0,
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.__init__.alpha": 0,
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.__init__.optimizer": 0,
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.__init__.normalize_y": 0,
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.__init__.copy_X_train": 0,
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.log_marginal_likelihood.theta": 0,
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.log_marginal_likelihood.eval_gradient": 0,
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.log_marginal_likelihood.clone_kernel": 0,
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.predict.return_std": 0,
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.predict.return_cov": 0,
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.sample_y.X": 0,
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.sample_y.n_samples": 0,
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.sample_y.random_state": 0,
    "sklearn.gaussian_process.kernels.CompoundKernel.__call__.X": 0,
    "sklearn.gaussian_process.kernels.CompoundKernel.__call__.Y": 0,
    "sklearn.gaussian_process.kernels.CompoundKernel.__call__.eval_gradient": 0,
    "sklearn.gaussian_process.kernels.CompoundKernel.__eq__.b": 0,
    "sklearn.gaussian_process.kernels.CompoundKernel.__init__.kernels": 0,
    "sklearn.gaussian_process.kernels.CompoundKernel.diag.X": 0,
    "sklearn.gaussian_process.kernels.CompoundKernel.get_params.deep": 0,
    "sklearn.gaussian_process.kernels.ConstantKernel.__call__.X": 0,
    "sklearn.gaussian_process.kernels.ConstantKernel.__call__.Y": 0,
    "sklearn.gaussian_process.kernels.ConstantKernel.__call__.eval_gradient": 0,
    "sklearn.gaussian_process.kernels.ConstantKernel.diag.X": 0,
    "sklearn.gaussian_process.kernels.DotProduct.__call__.X": 0,
    "sklearn.gaussian_process.kernels.DotProduct.__call__.Y": 0,
    "sklearn.gaussian_process.kernels.DotProduct.__call__.eval_gradient": 0,
    "sklearn.gaussian_process.kernels.DotProduct.__init__.sigma_0": 0,
    "sklearn.gaussian_process.kernels.DotProduct.__init__.sigma_0_bounds": 0,
    "sklearn.gaussian_process.kernels.DotProduct.diag.X": 0,
    "sklearn.gaussian_process.kernels.ExpSineSquared.__call__.X": 0,
    "sklearn.gaussian_process.kernels.ExpSineSquared.__call__.Y": 0,
    "sklearn.gaussian_process.kernels.ExpSineSquared.__call__.eval_gradient": 0,
    "sklearn.gaussian_process.kernels.ExpSineSquared.__init__.length_scale": 0,
    "sklearn.gaussian_process.kernels.ExpSineSquared.__init__.periodicity": 0,
    "sklearn.gaussian_process.kernels.ExpSineSquared.__init__.length_scale_bounds": 0,
    "sklearn.gaussian_process.kernels.ExpSineSquared.__init__.periodicity_bounds": 0,
    "sklearn.gaussian_process.kernels.Exponentiation.__call__.X": 0,
    "sklearn.gaussian_process.kernels.Exponentiation.__call__.Y": 0,
    "sklearn.gaussian_process.kernels.Exponentiation.__call__.eval_gradient": 0,
    "sklearn.gaussian_process.kernels.Exponentiation.__eq__.b": 0,
    "sklearn.gaussian_process.kernels.Exponentiation.__init__.kernel": 0,
    "sklearn.gaussian_process.kernels.Exponentiation.__init__.exponent": 0,
    "sklearn.gaussian_process.kernels.Exponentiation.diag.X": 0,
    "sklearn.gaussian_process.kernels.Exponentiation.get_params.deep": 0,
    "sklearn.gaussian_process.kernels.Hyperparameter.__eq__.other": 0,
    "sklearn.gaussian_process.kernels.Hyperparameter.__new__.cls": 0,
    "sklearn.gaussian_process.kernels.Hyperparameter.__new__.name": 0,
    "sklearn.gaussian_process.kernels.Hyperparameter.__new__.value_type": 0,
    "sklearn.gaussian_process.kernels.Hyperparameter.__new__.bounds": 0,
    "sklearn.gaussian_process.kernels.Hyperparameter.__new__.n_elements": 0,
    "sklearn.gaussian_process.kernels.Hyperparameter.__new__.fixed": 0,
    "sklearn.gaussian_process.kernels.Kernel.__add__.b": 0,
    "sklearn.gaussian_process.kernels.Kernel.__call__.X": 0,
    "sklearn.gaussian_process.kernels.Kernel.__call__.Y": 0,
    "sklearn.gaussian_process.kernels.Kernel.__call__.eval_gradient": 0,
    "sklearn.gaussian_process.kernels.Kernel.__eq__.b": 0,
    "sklearn.gaussian_process.kernels.Kernel.__mul__.b": 0,
    "sklearn.gaussian_process.kernels.Kernel.__pow__.b": 0,
    "sklearn.gaussian_process.kernels.Kernel.__radd__.b": 0,
    "sklearn.gaussian_process.kernels.Kernel.__rmul__.b": 0,
    "sklearn.gaussian_process.kernels.Kernel.clone_with_theta.theta": 0,
    "sklearn.gaussian_process.kernels.Kernel.diag.X": 0,
    "sklearn.gaussian_process.kernels.Kernel.get_params.deep": 0,
    "sklearn.gaussian_process.kernels.KernelOperator.__eq__.b": 0,
    "sklearn.gaussian_process.kernels.KernelOperator.__init__.k1": 0,
    "sklearn.gaussian_process.kernels.KernelOperator.__init__.k2": 0,
    "sklearn.gaussian_process.kernels.KernelOperator.get_params.deep": 0,
    "sklearn.gaussian_process.kernels.Matern.__call__.X": 0,
    "sklearn.gaussian_process.kernels.Matern.__call__.Y": 0,
    "sklearn.gaussian_process.kernels.Matern.__call__.eval_gradient": 0,
    "sklearn.gaussian_process.kernels.Matern.__init__.length_scale": 0,
    "sklearn.gaussian_process.kernels.Matern.__init__.length_scale_bounds": 0,
    "sklearn.gaussian_process.kernels.Matern.__init__.nu": 0,
    "sklearn.gaussian_process.kernels.NormalizedKernelMixin.diag.X": 0,
    "sklearn.gaussian_process.kernels.PairwiseKernel.__call__.X": 0,
    "sklearn.gaussian_process.kernels.PairwiseKernel.__call__.Y": 0,
    "sklearn.gaussian_process.kernels.PairwiseKernel.__call__.eval_gradient": 0,
    "sklearn.gaussian_process.kernels.PairwiseKernel.__init__.gamma": 0,
    "sklearn.gaussian_process.kernels.PairwiseKernel.__init__.gamma_bounds": 0,
    "sklearn.gaussian_process.kernels.PairwiseKernel.__init__.metric": 0,
    "sklearn.gaussian_process.kernels.PairwiseKernel.__init__.pairwise_kernels_kwargs": 0,
    "sklearn.gaussian_process.kernels.PairwiseKernel.diag.X": 0,
    "sklearn.gaussian_process.kernels.Product.__call__.X": 0,
    "sklearn.gaussian_process.kernels.Product.__call__.Y": 0,
    "sklearn.gaussian_process.kernels.Product.__call__.eval_gradient": 0,
    "sklearn.gaussian_process.kernels.Product.diag.X": 0,
    "sklearn.gaussian_process.kernels.RBF.__call__.X": 0,
    "sklearn.gaussian_process.kernels.RBF.__call__.Y": 0,
    "sklearn.gaussian_process.kernels.RBF.__call__.eval_gradient": 0,
    "sklearn.gaussian_process.kernels.RationalQuadratic.__call__.X": 0,
    "sklearn.gaussian_process.kernels.RationalQuadratic.__call__.Y": 0,
    "sklearn.gaussian_process.kernels.RationalQuadratic.__call__.eval_gradient": 0,
    "sklearn.gaussian_process.kernels.RationalQuadratic.__init__.length_scale": 0,
    "sklearn.gaussian_process.kernels.RationalQuadratic.__init__.alpha": 0,
    "sklearn.gaussian_process.kernels.RationalQuadratic.__init__.length_scale_bounds": 0,
    "sklearn.gaussian_process.kernels.RationalQuadratic.__init__.alpha_bounds": 0,
    "sklearn.gaussian_process.kernels.Sum.__call__.X": 0,
    "sklearn.gaussian_process.kernels.Sum.__call__.Y": 0,
    "sklearn.gaussian_process.kernels.Sum.__call__.eval_gradient": 0,
    "sklearn.gaussian_process.kernels.Sum.diag.X": 0,
    "sklearn.gaussian_process.kernels.WhiteKernel.__call__.X": 0,
    "sklearn.gaussian_process.kernels.WhiteKernel.__call__.Y": 0,
    "sklearn.gaussian_process.kernels.WhiteKernel.__call__.eval_gradient": 0,
    "sklearn.gaussian_process.kernels.WhiteKernel.__init__.noise_level_bounds": 0,
    "sklearn.gaussian_process.kernels.WhiteKernel.diag.X": 0,
    "sklearn.impute._base.MissingIndicator.__init__.missing_values": 0,
    "sklearn.impute._base.MissingIndicator.__init__.features": 0,
    "sklearn.impute._base.MissingIndicator.__init__.sparse": 0,
    "sklearn.impute._base.MissingIndicator.__init__.error_on_new": 0,
    "sklearn.impute._base.MissingIndicator.fit_transform.y": 0,
    "sklearn.impute._base.SimpleImputer.inverse_transform.X": 0,
    "sklearn.impute._iterative.IterativeImputer.fit.y": 0,
    "sklearn.impute._iterative.IterativeImputer.fit_transform.y": 0,
    "sklearn.impute._knn.KNNImputer.__init__.missing_values": 0,
    "sklearn.impute._knn.KNNImputer.__init__.copy": 0,
    "sklearn.impute._knn.KNNImputer.__init__.add_indicator": 0,
    "sklearn.impute._knn.KNNImputer.fit.y": 0,
    "sklearn.inspection._partial_dependence.partial_dependence.response_method": 0,
    "sklearn.inspection._partial_dependence.partial_dependence.percentiles": 0,
    "sklearn.inspection._partial_dependence.partial_dependence.method": 0,
    "sklearn.inspection._partial_dependence.partial_dependence.kind": 0,
    "sklearn.inspection._permutation_importance.permutation_importance.sample_weight": 0,
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.__init__.pd_results": 0,
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.__init__.features": 0,
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.__init__.feature_names": 0,
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.__init__.target_idx": 0,
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.__init__.pdp_lim": 0,
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.__init__.deciles": 0,
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.__init__.kind": 0,
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.__init__.subsample": 0,
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.__init__.random_state": 0,
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.plot.ax": 0,
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.plot.n_cols": 0,
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.plot.line_kw": 0,
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.plot.contour_kw": 0,
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.feature_names": 0,
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.response_method": 0,
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.n_cols": 0,
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.percentiles": 0,
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.method": 0,
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.n_jobs": 0,
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.verbose": 0,
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.line_kw": 0,
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.contour_kw": 0,
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.kind": 0,
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.subsample": 0,
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.random_state": 0,
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.convert_feature.fx": 0,
    "sklearn.inspection.setup.configuration.parent_package": 0,
    "sklearn.inspection.setup.configuration.top_path": 0,
    "sklearn.isotonic.IsotonicRegression.__init__.increasing": 0,
    "sklearn.isotonic.IsotonicRegression.__setstate__.state": 0,
    "sklearn.isotonic.IsotonicRegression.fit.sample_weight": 0,
    "sklearn.isotonic.check_increasing.x": 0,
    "sklearn.isotonic.check_increasing.y": 0,
    "sklearn.isotonic.isotonic_regression.y": 0,
    "sklearn.isotonic.isotonic_regression.sample_weight": 0,
    "sklearn.isotonic.isotonic_regression.y_min": 0,
    "sklearn.isotonic.isotonic_regression.y_max": 0,
    "sklearn.isotonic.isotonic_regression.increasing": 0,
    "sklearn.kernel_approximation.AdditiveChi2Sampler.__init__.sample_steps": 0,
    "sklearn.kernel_approximation.AdditiveChi2Sampler.__init__.sample_interval": 0,
    "sklearn.kernel_approximation.AdditiveChi2Sampler.fit.X": 0,
    "sklearn.kernel_approximation.AdditiveChi2Sampler.fit.y": 0,
    "sklearn.kernel_approximation.AdditiveChi2Sampler.transform.X": 0,
    "sklearn.kernel_approximation.Nystroem.__init__.gamma": 0,
    "sklearn.kernel_approximation.Nystroem.__init__.coef0": 0,
    "sklearn.kernel_approximation.Nystroem.__init__.degree": 0,
    "sklearn.kernel_approximation.Nystroem.__init__.kernel_params": 0,
    "sklearn.kernel_approximation.Nystroem.__init__.n_jobs": 0,
    "sklearn.kernel_approximation.Nystroem.fit.X": 0,
    "sklearn.kernel_approximation.Nystroem.fit.y": 0,
    "sklearn.kernel_approximation.PolynomialCountSketch.__init__.gamma": 0,
    "sklearn.kernel_approximation.PolynomialCountSketch.__init__.degree": 0,
    "sklearn.kernel_approximation.PolynomialCountSketch.__init__.coef0": 0,
    "sklearn.kernel_approximation.PolynomialCountSketch.__init__.n_components": 0,
    "sklearn.kernel_approximation.PolynomialCountSketch.__init__.random_state": 0,
    "sklearn.kernel_approximation.PolynomialCountSketch.fit.X": 0,
    "sklearn.kernel_approximation.PolynomialCountSketch.fit.y": 0,
    "sklearn.kernel_approximation.PolynomialCountSketch.transform.X": 0,
    "sklearn.kernel_approximation.RBFSampler.__init__.n_components": 0,
    "sklearn.kernel_approximation.RBFSampler.fit.X": 0,
    "sklearn.kernel_approximation.RBFSampler.fit.y": 0,
    "sklearn.kernel_approximation.SkewedChi2Sampler.__init__.skewedness": 0,
    "sklearn.kernel_approximation.SkewedChi2Sampler.__init__.n_components": 0,
    "sklearn.kernel_approximation.SkewedChi2Sampler.__init__.random_state": 0,
    "sklearn.kernel_approximation.SkewedChi2Sampler.fit.X": 0,
    "sklearn.kernel_approximation.SkewedChi2Sampler.fit.y": 0,
    "sklearn.kernel_approximation.SkewedChi2Sampler.transform.X": 0,
    "sklearn.kernel_ridge.KernelRidge.__init__.kernel_params": 0,
    "sklearn.kernel_ridge.KernelRidge.fit.sample_weight": 0,
    "sklearn.linear_model._bayes.BayesianRidge.__init__.copy_X": 0,
    "sklearn.linear_model._bayes.BayesianRidge.fit.sample_weight": 0,
    "sklearn.linear_model._coordinate_descent.ElasticNet.fit.check_input": 0,
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.n_alphas": 0,
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.precompute": 0,
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.copy_X": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet.__init__.fit_intercept": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet.__init__.normalize": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet.__init__.copy_X": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet.__init__.max_iter": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet.__init__.tol": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet.__init__.warm_start": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.l1_ratio": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.eps": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.n_alphas": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.alphas": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.fit_intercept": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.normalize": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.max_iter": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.tol": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.cv": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.copy_X": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.verbose": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.n_jobs": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.selection": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskLasso.__init__.alpha": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskLasso.__init__.fit_intercept": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskLasso.__init__.normalize": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskLasso.__init__.copy_X": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskLasso.__init__.max_iter": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskLasso.__init__.tol": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskLasso.__init__.warm_start": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskLasso.__init__.random_state": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskLasso.__init__.selection": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__.eps": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__.n_alphas": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__.alphas": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__.fit_intercept": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__.normalize": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__.max_iter": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__.tol": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__.copy_X": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__.cv": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__.verbose": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__.n_jobs": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__.random_state": 0,
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__.selection": 0,
    "sklearn.linear_model._coordinate_descent.enet_path.X": 0,
    "sklearn.linear_model._coordinate_descent.enet_path.y": 0,
    "sklearn.linear_model._coordinate_descent.enet_path.l1_ratio": 0,
    "sklearn.linear_model._coordinate_descent.enet_path.eps": 0,
    "sklearn.linear_model._coordinate_descent.enet_path.n_alphas": 0,
    "sklearn.linear_model._coordinate_descent.enet_path.alphas": 0,
    "sklearn.linear_model._coordinate_descent.enet_path.precompute": 0,
    "sklearn.linear_model._coordinate_descent.enet_path.Xy": 0,
    "sklearn.linear_model._coordinate_descent.enet_path.copy_X": 0,
    "sklearn.linear_model._coordinate_descent.enet_path.coef_init": 0,
    "sklearn.linear_model._coordinate_descent.enet_path.verbose": 0,
    "sklearn.linear_model._coordinate_descent.enet_path.return_n_iter": 0,
    "sklearn.linear_model._coordinate_descent.enet_path.positive": 0,
    "sklearn.linear_model._coordinate_descent.enet_path.check_input": 0,
    "sklearn.linear_model._coordinate_descent.lasso_path.X": 0,
    "sklearn.linear_model._coordinate_descent.lasso_path.y": 0,
    "sklearn.linear_model._coordinate_descent.lasso_path.eps": 0,
    "sklearn.linear_model._coordinate_descent.lasso_path.n_alphas": 0,
    "sklearn.linear_model._coordinate_descent.lasso_path.alphas": 0,
    "sklearn.linear_model._coordinate_descent.lasso_path.precompute": 0,
    "sklearn.linear_model._coordinate_descent.lasso_path.Xy": 0,
    "sklearn.linear_model._coordinate_descent.lasso_path.copy_X": 0,
    "sklearn.linear_model._coordinate_descent.lasso_path.coef_init": 0,
    "sklearn.linear_model._coordinate_descent.lasso_path.verbose": 0,
    "sklearn.linear_model._coordinate_descent.lasso_path.return_n_iter": 0,
    "sklearn.linear_model._coordinate_descent.lasso_path.positive": 0,
    "sklearn.linear_model._glm.glm.GammaRegressor.__init__.alpha": 0,
    "sklearn.linear_model._glm.glm.GammaRegressor.__init__.fit_intercept": 0,
    "sklearn.linear_model._glm.glm.GammaRegressor.__init__.max_iter": 0,
    "sklearn.linear_model._glm.glm.GammaRegressor.__init__.tol": 0,
    "sklearn.linear_model._glm.glm.GammaRegressor.__init__.warm_start": 0,
    "sklearn.linear_model._glm.glm.GammaRegressor.__init__.verbose": 0,
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.__init__.alpha": 0,
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.__init__.fit_intercept": 0,
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.__init__.family": 0,
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.__init__.link": 0,
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.__init__.solver": 0,
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.__init__.max_iter": 0,
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.__init__.tol": 0,
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.__init__.warm_start": 0,
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.__init__.verbose": 0,
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.fit.X": 0,
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.fit.y": 0,
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.fit.sample_weight": 0,
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.predict.X": 0,
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.score.X": 0,
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.score.y": 0,
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.score.sample_weight": 0,
    "sklearn.linear_model._glm.glm.PoissonRegressor.__init__.alpha": 0,
    "sklearn.linear_model._glm.glm.PoissonRegressor.__init__.fit_intercept": 0,
    "sklearn.linear_model._glm.glm.PoissonRegressor.__init__.max_iter": 0,
    "sklearn.linear_model._glm.glm.PoissonRegressor.__init__.tol": 0,
    "sklearn.linear_model._glm.glm.PoissonRegressor.__init__.warm_start": 0,
    "sklearn.linear_model._glm.glm.PoissonRegressor.__init__.verbose": 0,
    "sklearn.linear_model._glm.glm.TweedieRegressor.__init__.fit_intercept": 0,
    "sklearn.linear_model._glm.glm.TweedieRegressor.__init__.tol": 0,
    "sklearn.linear_model._glm.glm.TweedieRegressor.__init__.verbose": 0,
    "sklearn.linear_model._huber.HuberRegressor.__init__.warm_start": 0,
    "sklearn.linear_model._huber.HuberRegressor.__init__.tol": 0,
    "sklearn.linear_model._huber.HuberRegressor.fit.sample_weight": 0,
    "sklearn.linear_model._least_angle.Lars.__init__.verbose": 0,
    "sklearn.linear_model._least_angle.Lars.__init__.normalize": 0,
    "sklearn.linear_model._least_angle.Lars.__init__.precompute": 0,
    "sklearn.linear_model._least_angle.Lars.__init__.eps": 0,
    "sklearn.linear_model._least_angle.Lars.__init__.copy_X": 0,
    "sklearn.linear_model._least_angle.Lars.__init__.fit_path": 0,
    "sklearn.linear_model._least_angle.Lars.__init__.jitter": 0,
    "sklearn.linear_model._least_angle.Lars.__init__.random_state": 0,
    "sklearn.linear_model._least_angle.Lars.fit.Xy": 0,
    "sklearn.linear_model._least_angle.LarsCV.__init__.fit_intercept": 0,
    "sklearn.linear_model._least_angle.LarsCV.__init__.verbose": 0,
    "sklearn.linear_model._least_angle.LarsCV.__init__.max_iter": 0,
    "sklearn.linear_model._least_angle.LarsCV.__init__.normalize": 0,
    "sklearn.linear_model._least_angle.LarsCV.__init__.precompute": 0,
    "sklearn.linear_model._least_angle.LarsCV.__init__.cv": 0,
    "sklearn.linear_model._least_angle.LarsCV.__init__.max_n_alphas": 0,
    "sklearn.linear_model._least_angle.LarsCV.__init__.n_jobs": 0,
    "sklearn.linear_model._least_angle.LarsCV.__init__.eps": 0,
    "sklearn.linear_model._least_angle.LarsCV.__init__.copy_X": 0,
    "sklearn.linear_model._least_angle.LassoLars.__init__.eps": 0,
    "sklearn.linear_model._least_angle.LassoLars.__init__.copy_X": 0,
    "sklearn.linear_model._least_angle.LassoLars.__init__.fit_path": 0,
    "sklearn.linear_model._least_angle.LassoLars.__init__.positive": 0,
    "sklearn.linear_model._least_angle.LassoLars.__init__.jitter": 0,
    "sklearn.linear_model._least_angle.LassoLars.__init__.random_state": 0,
    "sklearn.linear_model._least_angle.LassoLarsCV.__init__.fit_intercept": 0,
    "sklearn.linear_model._least_angle.LassoLarsCV.__init__.eps": 0,
    "sklearn.linear_model._least_angle.LassoLarsCV.__init__.copy_X": 0,
    "sklearn.linear_model._least_angle.LassoLarsCV.__init__.positive": 0,
    "sklearn.linear_model._least_angle.LassoLarsIC.__init__.verbose": 0,
    "sklearn.linear_model._least_angle.LassoLarsIC.__init__.normalize": 0,
    "sklearn.linear_model._least_angle.LassoLarsIC.__init__.precompute": 0,
    "sklearn.linear_model._least_angle.LassoLarsIC.__init__.max_iter": 0,
    "sklearn.linear_model._least_angle.LassoLarsIC.__init__.eps": 0,
    "sklearn.linear_model._least_angle.LassoLarsIC.__init__.copy_X": 0,
    "sklearn.linear_model._least_angle.LassoLarsIC.__init__.positive": 0,
    "sklearn.linear_model._least_angle.LassoLarsIC.fit.copy_X": 0,
    "sklearn.linear_model._least_angle.lars_path.X": 0,
    "sklearn.linear_model._least_angle.lars_path.y": 0,
    "sklearn.linear_model._least_angle.lars_path.Xy": 0,
    "sklearn.linear_model._least_angle.lars_path.Gram": 0,
    "sklearn.linear_model._least_angle.lars_path.max_iter": 0,
    "sklearn.linear_model._least_angle.lars_path.alpha_min": 0,
    "sklearn.linear_model._least_angle.lars_path.method": 0,
    "sklearn.linear_model._least_angle.lars_path.copy_X": 0,
    "sklearn.linear_model._least_angle.lars_path.eps": 0,
    "sklearn.linear_model._least_angle.lars_path.copy_Gram": 0,
    "sklearn.linear_model._least_angle.lars_path.verbose": 0,
    "sklearn.linear_model._least_angle.lars_path.return_path": 0,
    "sklearn.linear_model._least_angle.lars_path.return_n_iter": 0,
    "sklearn.linear_model._least_angle.lars_path.positive": 0,
    "sklearn.linear_model._least_angle.lars_path_gram.Xy": 0,
    "sklearn.linear_model._least_angle.lars_path_gram.Gram": 0,
    "sklearn.linear_model._least_angle.lars_path_gram.n_samples": 0,
    "sklearn.linear_model._least_angle.lars_path_gram.max_iter": 0,
    "sklearn.linear_model._least_angle.lars_path_gram.alpha_min": 0,
    "sklearn.linear_model._least_angle.lars_path_gram.method": 0,
    "sklearn.linear_model._least_angle.lars_path_gram.copy_X": 0,
    "sklearn.linear_model._least_angle.lars_path_gram.eps": 0,
    "sklearn.linear_model._least_angle.lars_path_gram.copy_Gram": 0,
    "sklearn.linear_model._least_angle.lars_path_gram.verbose": 0,
    "sklearn.linear_model._least_angle.lars_path_gram.return_path": 0,
    "sklearn.linear_model._least_angle.lars_path_gram.return_n_iter": 0,
    "sklearn.linear_model._least_angle.lars_path_gram.positive": 0,
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.l1_ratios": 0,
    "sklearn.linear_model._logistic.LogisticRegressionCV.fit.sample_weight": 0,
    "sklearn.linear_model._logistic.LogisticRegressionCV.score.sample_weight": 0,
    "sklearn.linear_model._omp.OrthogonalMatchingPursuitCV.__init__.copy": 0,
    "sklearn.linear_model._omp.OrthogonalMatchingPursuitCV.__init__.fit_intercept": 0,
    "sklearn.linear_model._omp.OrthogonalMatchingPursuitCV.__init__.normalize": 0,
    "sklearn.linear_model._omp.OrthogonalMatchingPursuitCV.__init__.max_iter": 0,
    "sklearn.linear_model._omp.OrthogonalMatchingPursuitCV.__init__.cv": 0,
    "sklearn.linear_model._omp.OrthogonalMatchingPursuitCV.__init__.n_jobs": 0,
    "sklearn.linear_model._omp.OrthogonalMatchingPursuitCV.__init__.verbose": 0,
    "sklearn.linear_model._omp.OrthogonalMatchingPursuitCV.fit.X": 0,
    "sklearn.linear_model._omp.OrthogonalMatchingPursuitCV.fit.y": 0,
    "sklearn.linear_model._omp.orthogonal_mp.X": 0,
    "sklearn.linear_model._omp.orthogonal_mp.y": 0,
    "sklearn.linear_model._omp.orthogonal_mp.n_nonzero_coefs": 0,
    "sklearn.linear_model._omp.orthogonal_mp.tol": 0,
    "sklearn.linear_model._omp.orthogonal_mp.precompute": 0,
    "sklearn.linear_model._omp.orthogonal_mp.copy_X": 0,
    "sklearn.linear_model._omp.orthogonal_mp.return_path": 0,
    "sklearn.linear_model._omp.orthogonal_mp.return_n_iter": 0,
    "sklearn.linear_model._omp.orthogonal_mp_gram.Gram": 0,
    "sklearn.linear_model._omp.orthogonal_mp_gram.Xy": 0,
    "sklearn.linear_model._omp.orthogonal_mp_gram.n_nonzero_coefs": 0,
    "sklearn.linear_model._omp.orthogonal_mp_gram.tol": 0,
    "sklearn.linear_model._omp.orthogonal_mp_gram.norms_squared": 0,
    "sklearn.linear_model._omp.orthogonal_mp_gram.copy_Gram": 0,
    "sklearn.linear_model._omp.orthogonal_mp_gram.copy_Xy": 0,
    "sklearn.linear_model._omp.orthogonal_mp_gram.return_path": 0,
    "sklearn.linear_model._omp.orthogonal_mp_gram.return_n_iter": 0,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.C": 0,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.fit_intercept": 0,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.shuffle": 0,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.warm_start": 0,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.fit.coef_init": 0,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.fit.intercept_init": 0,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.partial_fit.X": 0,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.partial_fit.y": 0,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.partial_fit.classes": 0,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.early_stopping": 0,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.validation_fraction": 0,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.n_iter_no_change": 0,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.fit.coef_init": 0,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.fit.intercept_init": 0,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.partial_fit.X": 0,
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.partial_fit.y": 0,
    "sklearn.linear_model._perceptron.Perceptron.__init__.l1_ratio": 0,
    "sklearn.linear_model._perceptron.Perceptron.__init__.early_stopping": 0,
    "sklearn.linear_model._perceptron.Perceptron.__init__.validation_fraction": 0,
    "sklearn.linear_model._perceptron.Perceptron.__init__.n_iter_no_change": 0,
    "sklearn.linear_model._ransac.RANSACRegressor.__init__.is_data_valid": 0,
    "sklearn.linear_model._ransac.RANSACRegressor.__init__.is_model_valid": 0,
    "sklearn.linear_model._ransac.RANSACRegressor.__init__.max_skips": 0,
    "sklearn.linear_model._ransac.RANSACRegressor.__init__.stop_n_inliers": 0,
    "sklearn.linear_model._ransac.RANSACRegressor.__init__.stop_score": 0,
    "sklearn.linear_model._ransac.RANSACRegressor.__init__.stop_probability": 0,
    "sklearn.linear_model._ransac.RANSACRegressor.fit.sample_weight": 0,
    "sklearn.linear_model._ridge.RidgeClassifier.fit.sample_weight": 0,
    "sklearn.linear_model._ridge.RidgeClassifierCV.__init__.fit_intercept": 0,
    "sklearn.linear_model._ridge.RidgeClassifierCV.__init__.normalize": 0,
    "sklearn.linear_model._ridge.RidgeClassifierCV.__init__.scoring": 0,
    "sklearn.linear_model._ridge.RidgeClassifierCV.__init__.class_weight": 0,
    "sklearn.linear_model._ridge.RidgeClassifierCV.__init__.store_cv_values": 0,
    "sklearn.linear_model._ridge.RidgeClassifierCV.fit.sample_weight": 0,
    "sklearn.linear_model._ridge.ridge_regression.X": 0,
    "sklearn.linear_model._ridge.ridge_regression.y": 0,
    "sklearn.linear_model._ridge.ridge_regression.alpha": 0,
    "sklearn.linear_model._ridge.ridge_regression.sample_weight": 0,
    "sklearn.linear_model._ridge.ridge_regression.solver": 0,
    "sklearn.linear_model._ridge.ridge_regression.max_iter": 0,
    "sklearn.linear_model._ridge.ridge_regression.tol": 0,
    "sklearn.linear_model._ridge.ridge_regression.verbose": 0,
    "sklearn.linear_model._ridge.ridge_regression.random_state": 0,
    "sklearn.linear_model._ridge.ridge_regression.return_n_iter": 0,
    "sklearn.linear_model._ridge.ridge_regression.return_intercept": 0,
    "sklearn.linear_model._ridge.ridge_regression.check_input": 0,
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.validation_fraction": 0,
    "sklearn.linear_model._theil_sen.TheilSenRegressor.__init__.copy_X": 0,
    "sklearn.linear_model._theil_sen.TheilSenRegressor.__init__.max_subpopulation": 0,
    "sklearn.linear_model._theil_sen.TheilSenRegressor.__init__.n_subsamples": 0,
    "sklearn.linear_model._theil_sen.TheilSenRegressor.__init__.max_iter": 0,
    "sklearn.linear_model._theil_sen.TheilSenRegressor.__init__.tol": 0,
    "sklearn.linear_model._theil_sen.TheilSenRegressor.__init__.n_jobs": 0,
    "sklearn.linear_model.setup.configuration.parent_package": 0,
    "sklearn.linear_model.setup.configuration.top_path": 0,
    "sklearn.manifold._isomap.Isomap.__init__.tol": 0,
    "sklearn.manifold._isomap.Isomap.__init__.max_iter": 0,
    "sklearn.manifold._isomap.Isomap.__init__.path_method": 0,
    "sklearn.manifold._isomap.Isomap.__init__.neighbors_algorithm": 0,
    "sklearn.manifold._isomap.Isomap.__init__.metric": 0,
    "sklearn.manifold._isomap.Isomap.__init__.p": 0,
    "sklearn.manifold._isomap.Isomap.__init__.metric_params": 0,
    "sklearn.manifold._isomap.Isomap.fit.y": 0,
    "sklearn.manifold._isomap.Isomap.fit_transform.y": 0,
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.__init__.reg": 0,
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.__init__.tol": 0,
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.__init__.max_iter": 0,
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.__init__.hessian_tol": 0,
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.__init__.modified_tol": 0,
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.__init__.neighbors_algorithm": 0,
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.__init__.n_jobs": 0,
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.fit.X": 0,
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.fit.y": 0,
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.fit_transform.y": 0,
    "sklearn.manifold._locally_linear.locally_linear_embedding.X": 0,
    "sklearn.manifold._locally_linear.locally_linear_embedding.n_neighbors": 0,
    "sklearn.manifold._locally_linear.locally_linear_embedding.n_components": 0,
    "sklearn.manifold._locally_linear.locally_linear_embedding.reg": 0,
    "sklearn.manifold._locally_linear.locally_linear_embedding.eigen_solver": 0,
    "sklearn.manifold._locally_linear.locally_linear_embedding.tol": 0,
    "sklearn.manifold._locally_linear.locally_linear_embedding.max_iter": 0,
    "sklearn.manifold._locally_linear.locally_linear_embedding.method": 0,
    "sklearn.manifold._locally_linear.locally_linear_embedding.hessian_tol": 0,
    "sklearn.manifold._locally_linear.locally_linear_embedding.modified_tol": 0,
    "sklearn.manifold._locally_linear.locally_linear_embedding.random_state": 0,
    "sklearn.manifold._locally_linear.locally_linear_embedding.n_jobs": 0,
    "sklearn.manifold._mds.MDS.__init__.metric": 0,
    "sklearn.manifold._mds.MDS.__init__.verbose": 0,
    "sklearn.manifold._mds.MDS.__init__.eps": 0,
    "sklearn.manifold._mds.MDS.fit.X": 0,
    "sklearn.manifold._mds.MDS.fit.y": 0,
    "sklearn.manifold._mds.MDS.fit.init": 0,
    "sklearn.manifold._mds.MDS.fit_transform.y": 0,
    "sklearn.manifold._mds.MDS.fit_transform.init": 0,
    "sklearn.manifold._mds.smacof.metric": 0,
    "sklearn.manifold._mds.smacof.init": 0,
    "sklearn.manifold._mds.smacof.n_init": 0,
    "sklearn.manifold._mds.smacof.n_jobs": 0,
    "sklearn.manifold._mds.smacof.max_iter": 0,
    "sklearn.manifold._mds.smacof.verbose": 0,
    "sklearn.manifold._mds.smacof.eps": 0,
    "sklearn.manifold._mds.smacof.random_state": 0,
    "sklearn.manifold._mds.smacof.return_n_iter": 0,
    "sklearn.manifold._spectral_embedding.SpectralEmbedding.__init__.gamma": 0,
    "sklearn.manifold._spectral_embedding.SpectralEmbedding.__init__.random_state": 0,
    "sklearn.manifold._spectral_embedding.SpectralEmbedding.__init__.eigen_solver": 0,
    "sklearn.manifold._spectral_embedding.SpectralEmbedding.fit.X": 0,
    "sklearn.manifold._spectral_embedding.SpectralEmbedding.fit.y": 0,
    "sklearn.manifold._spectral_embedding.SpectralEmbedding.fit_transform.y": 0,
    "sklearn.manifold._spectral_embedding.spectral_embedding.adjacency": 0,
    "sklearn.manifold._spectral_embedding.spectral_embedding.n_components": 0,
    "sklearn.manifold._spectral_embedding.spectral_embedding.eigen_solver": 0,
    "sklearn.manifold._spectral_embedding.spectral_embedding.random_state": 0,
    "sklearn.manifold._spectral_embedding.spectral_embedding.eigen_tol": 0,
    "sklearn.manifold._spectral_embedding.spectral_embedding.norm_laplacian": 0,
    "sklearn.manifold._spectral_embedding.spectral_embedding.drop_first": 0,
    "sklearn.manifold._t_sne.TSNE.__init__.square_distances": 0,
    "sklearn.manifold._t_sne.TSNE.fit.X": 0,
    "sklearn.manifold._t_sne.TSNE.fit.y": 0,
    "sklearn.manifold._t_sne.trustworthiness.X": 0,
    "sklearn.manifold._t_sne.trustworthiness.X_embedded": 0,
    "sklearn.manifold._t_sne.trustworthiness.n_neighbors": 0,
    "sklearn.manifold._t_sne.trustworthiness.metric": 0,
    "sklearn.manifold.setup.configuration.parent_package": 0,
    "sklearn.manifold.setup.configuration.top_path": 0,
    "sklearn.metrics._classification.balanced_accuracy_score.adjusted": 0,
    "sklearn.metrics._classification.brier_score_loss.sample_weight": 0,
    "sklearn.metrics._classification.classification_report.sample_weight": 0,
    "sklearn.metrics._classification.fbeta_score.pos_label": 0,
    "sklearn.metrics._classification.fbeta_score.sample_weight": 0,
    "sklearn.metrics._classification.fbeta_score.zero_division": 0,
    "sklearn.metrics._classification.hamming_loss.sample_weight": 0,
    "sklearn.metrics._classification.hinge_loss.labels": 0,
    "sklearn.metrics._classification.hinge_loss.sample_weight": 0,
    "sklearn.metrics._classification.jaccard_score.labels": 0,
    "sklearn.metrics._classification.jaccard_score.sample_weight": 0,
    "sklearn.metrics._classification.jaccard_score.zero_division": 0,
    "sklearn.metrics._classification.matthews_corrcoef.sample_weight": 0,
    "sklearn.metrics._classification.precision_recall_fscore_support.warn_for": 0,
    "sklearn.metrics._classification.precision_recall_fscore_support.sample_weight": 0,
    "sklearn.metrics._classification.precision_recall_fscore_support.zero_division": 0,
    "sklearn.metrics._classification.precision_score.sample_weight": 0,
    "sklearn.metrics._classification.recall_score.sample_weight": 0,
    "sklearn.metrics._classification.zero_one_loss.normalize": 0,
    "sklearn.metrics._classification.zero_one_loss.sample_weight": 0,
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix.sample_weight": 0,
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix.include_values": 0,
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix.colorbar": 0,
    "sklearn.metrics._plot.det_curve.DetCurveDisplay.__init__.fpr": 0,
    "sklearn.metrics._plot.det_curve.DetCurveDisplay.__init__.fnr": 0,
    "sklearn.metrics._plot.det_curve.DetCurveDisplay.__init__.estimator_name": 0,
    "sklearn.metrics._plot.det_curve.DetCurveDisplay.__init__.pos_label": 0,
    "sklearn.metrics._plot.det_curve.DetCurveDisplay.plot.ax": 0,
    "sklearn.metrics._plot.det_curve.DetCurveDisplay.plot.name": 0,
    "sklearn.metrics._plot.det_curve.plot_det_curve.estimator": 0,
    "sklearn.metrics._plot.det_curve.plot_det_curve.X": 0,
    "sklearn.metrics._plot.det_curve.plot_det_curve.y": 0,
    "sklearn.metrics._plot.det_curve.plot_det_curve.sample_weight": 0,
    "sklearn.metrics._plot.det_curve.plot_det_curve.response_method": 0,
    "sklearn.metrics._plot.det_curve.plot_det_curve.name": 0,
    "sklearn.metrics._plot.det_curve.plot_det_curve.ax": 0,
    "sklearn.metrics._plot.det_curve.plot_det_curve.pos_label": 0,
    "sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay.__init__.average_precision": 0,
    "sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay.__init__.estimator_name": 0,
    "sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay.__init__.pos_label": 0,
    "sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay.plot.ax": 0,
    "sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay.plot.name": 0,
    "sklearn.metrics._plot.precision_recall_curve.plot_precision_recall_curve.sample_weight": 0,
    "sklearn.metrics._plot.precision_recall_curve.plot_precision_recall_curve.response_method": 0,
    "sklearn.metrics._plot.precision_recall_curve.plot_precision_recall_curve.name": 0,
    "sklearn.metrics._plot.precision_recall_curve.plot_precision_recall_curve.pos_label": 0,
    "sklearn.metrics._plot.roc_curve.RocCurveDisplay.__init__.roc_auc": 0,
    "sklearn.metrics._plot.roc_curve.RocCurveDisplay.__init__.estimator_name": 0,
    "sklearn.metrics._plot.roc_curve.RocCurveDisplay.__init__.pos_label": 0,
    "sklearn.metrics._plot.roc_curve.RocCurveDisplay.plot.ax": 0,
    "sklearn.metrics._plot.roc_curve.RocCurveDisplay.plot.name": 0,
    "sklearn.metrics._plot.roc_curve.plot_roc_curve.sample_weight": 0,
    "sklearn.metrics._plot.roc_curve.plot_roc_curve.response_method": 0,
    "sklearn.metrics._plot.roc_curve.plot_roc_curve.pos_label": 0,
    "sklearn.metrics._ranking.average_precision_score.pos_label": 0,
    "sklearn.metrics._ranking.average_precision_score.sample_weight": 0,
    "sklearn.metrics._ranking.coverage_error.y_true": 0,
    "sklearn.metrics._ranking.coverage_error.y_score": 0,
    "sklearn.metrics._ranking.coverage_error.sample_weight": 0,
    "sklearn.metrics._ranking.dcg_score.y_true": 0,
    "sklearn.metrics._ranking.dcg_score.y_score": 0,
    "sklearn.metrics._ranking.dcg_score.k": 0,
    "sklearn.metrics._ranking.dcg_score.log_base": 0,
    "sklearn.metrics._ranking.dcg_score.sample_weight": 0,
    "sklearn.metrics._ranking.dcg_score.ignore_ties": 0,
    "sklearn.metrics._ranking.det_curve.y_true": 0,
    "sklearn.metrics._ranking.det_curve.y_score": 0,
    "sklearn.metrics._ranking.det_curve.pos_label": 0,
    "sklearn.metrics._ranking.det_curve.sample_weight": 0,
    "sklearn.metrics._ranking.label_ranking_loss.y_true": 0,
    "sklearn.metrics._ranking.label_ranking_loss.y_score": 0,
    "sklearn.metrics._ranking.label_ranking_loss.sample_weight": 0,
    "sklearn.metrics._ranking.precision_recall_curve.sample_weight": 0,
    "sklearn.metrics._ranking.top_k_accuracy_score.y_true": 0,
    "sklearn.metrics._ranking.top_k_accuracy_score.y_score": 0,
    "sklearn.metrics._ranking.top_k_accuracy_score.k": 0,
    "sklearn.metrics._ranking.top_k_accuracy_score.normalize": 0,
    "sklearn.metrics._ranking.top_k_accuracy_score.sample_weight": 0,
    "sklearn.metrics._ranking.top_k_accuracy_score.labels": 0,
    "sklearn.metrics._regression.explained_variance_score.sample_weight": 0,
    "sklearn.metrics._regression.mean_absolute_percentage_error.sample_weight": 0,
    "sklearn.metrics._regression.mean_absolute_percentage_error.multioutput": 0,
    "sklearn.metrics._regression.mean_gamma_deviance.y_true": 0,
    "sklearn.metrics._regression.mean_gamma_deviance.y_pred": 0,
    "sklearn.metrics._regression.mean_gamma_deviance.sample_weight": 0,
    "sklearn.metrics._regression.mean_poisson_deviance.y_true": 0,
    "sklearn.metrics._regression.mean_poisson_deviance.y_pred": 0,
    "sklearn.metrics._regression.mean_poisson_deviance.sample_weight": 0,
    "sklearn.metrics._regression.mean_tweedie_deviance.sample_weight": 0,
    "sklearn.metrics._regression.median_absolute_error.multioutput": 0,
    "sklearn.metrics._regression.median_absolute_error.sample_weight": 0,
    "sklearn.metrics._scorer.check_scoring.estimator": 0,
    "sklearn.metrics._scorer.check_scoring.scoring": 0,
    "sklearn.metrics._scorer.check_scoring.allow_none": 0,
    "sklearn.metrics.cluster._bicluster.consensus_score.a": 0,
    "sklearn.metrics.cluster._bicluster.consensus_score.b": 0,
    "sklearn.metrics.cluster._bicluster.consensus_score.similarity": 0,
    "sklearn.metrics.cluster._supervised.adjusted_mutual_info_score.average_method": 0,
    "sklearn.metrics.cluster._supervised.contingency_matrix.labels_true": 0,
    "sklearn.metrics.cluster._supervised.contingency_matrix.labels_pred": 0,
    "sklearn.metrics.cluster._supervised.contingency_matrix.eps": 0,
    "sklearn.metrics.cluster._supervised.contingency_matrix.sparse": 0,
    "sklearn.metrics.cluster._supervised.contingency_matrix.dtype": 0,
    "sklearn.metrics.cluster._supervised.entropy.labels": 0,
    "sklearn.metrics.cluster._supervised.fowlkes_mallows_score.labels_true": 0,
    "sklearn.metrics.cluster._supervised.fowlkes_mallows_score.labels_pred": 0,
    "sklearn.metrics.cluster._supervised.fowlkes_mallows_score.sparse": 0,
    "sklearn.metrics.cluster._supervised.homogeneity_completeness_v_measure.labels_true": 0,
    "sklearn.metrics.cluster._supervised.homogeneity_completeness_v_measure.labels_pred": 0,
    "sklearn.metrics.cluster._supervised.homogeneity_completeness_v_measure.beta": 0,
    "sklearn.metrics.cluster._supervised.normalized_mutual_info_score.average_method": 0,
    "sklearn.metrics.cluster._supervised.pair_confusion_matrix.labels_true": 0,
    "sklearn.metrics.cluster._supervised.pair_confusion_matrix.labels_pred": 0,
    "sklearn.metrics.cluster._supervised.rand_score.labels_true": 0,
    "sklearn.metrics.cluster._supervised.rand_score.labels_pred": 0,
    "sklearn.metrics.cluster._supervised.v_measure_score.beta": 0,
    "sklearn.metrics.cluster._unsupervised.calinski_harabasz_score.X": 0,
    "sklearn.metrics.cluster._unsupervised.calinski_harabasz_score.labels": 0,
    "sklearn.metrics.cluster._unsupervised.silhouette_samples.metric": 0,
    "sklearn.metrics.cluster.setup.configuration.parent_package": 0,
    "sklearn.metrics.cluster.setup.configuration.top_path": 0,
    "sklearn.metrics.pairwise.additive_chi2_kernel.X": 0,
    "sklearn.metrics.pairwise.additive_chi2_kernel.Y": 0,
    "sklearn.metrics.pairwise.check_paired_arrays.X": 0,
    "sklearn.metrics.pairwise.check_paired_arrays.Y": 0,
    "sklearn.metrics.pairwise.check_pairwise_arrays.X": 0,
    "sklearn.metrics.pairwise.check_pairwise_arrays.Y": 0,
    "sklearn.metrics.pairwise.check_pairwise_arrays.precomputed": 0,
    "sklearn.metrics.pairwise.check_pairwise_arrays.dtype": 0,
    "sklearn.metrics.pairwise.check_pairwise_arrays.accept_sparse": 0,
    "sklearn.metrics.pairwise.check_pairwise_arrays.force_all_finite": 0,
    "sklearn.metrics.pairwise.check_pairwise_arrays.copy": 0,
    "sklearn.metrics.pairwise.chi2_kernel.X": 0,
    "sklearn.metrics.pairwise.chi2_kernel.Y": 0,
    "sklearn.metrics.pairwise.chi2_kernel.gamma": 0,
    "sklearn.metrics.pairwise.cosine_distances.Y": 0,
    "sklearn.metrics.pairwise.cosine_similarity.dense_output": 0,
    "sklearn.metrics.pairwise.euclidean_distances.Y_norm_squared": 0,
    "sklearn.metrics.pairwise.euclidean_distances.squared": 0,
    "sklearn.metrics.pairwise.euclidean_distances.X_norm_squared": 0,
    "sklearn.metrics.pairwise.haversine_distances.X": 0,
    "sklearn.metrics.pairwise.haversine_distances.Y": 0,
    "sklearn.metrics.pairwise.laplacian_kernel.X": 0,
    "sklearn.metrics.pairwise.laplacian_kernel.Y": 0,
    "sklearn.metrics.pairwise.laplacian_kernel.gamma": 0,
    "sklearn.metrics.pairwise.linear_kernel.dense_output": 0,
    "sklearn.metrics.pairwise.manhattan_distances.sum_over_features": 0,
    "sklearn.metrics.pairwise.nan_euclidean_distances.X": 0,
    "sklearn.metrics.pairwise.nan_euclidean_distances.Y": 0,
    "sklearn.metrics.pairwise.nan_euclidean_distances.squared": 0,
    "sklearn.metrics.pairwise.nan_euclidean_distances.missing_values": 0,
    "sklearn.metrics.pairwise.nan_euclidean_distances.copy": 0,
    "sklearn.metrics.pairwise.paired_cosine_distances.X": 0,
    "sklearn.metrics.pairwise.paired_cosine_distances.Y": 0,
    "sklearn.metrics.pairwise.paired_distances.metric": 0,
    "sklearn.metrics.pairwise.paired_manhattan_distances.X": 0,
    "sklearn.metrics.pairwise.paired_manhattan_distances.Y": 0,
    "sklearn.metrics.pairwise.pairwise_distances.force_all_finite": 0,
    "sklearn.metrics.pairwise.pairwise_distances_argmin.axis": 0,
    "sklearn.metrics.pairwise.pairwise_distances_argmin.metric": 0,
    "sklearn.metrics.pairwise.pairwise_distances_argmin.metric_kwargs": 0,
    "sklearn.metrics.pairwise.pairwise_distances_argmin_min.axis": 0,
    "sklearn.metrics.pairwise.pairwise_distances_argmin_min.metric": 0,
    "sklearn.metrics.pairwise.pairwise_distances_argmin_min.metric_kwargs": 0,
    "sklearn.metrics.pairwise.pairwise_distances_chunked.Y": 0,
    "sklearn.metrics.pairwise.pairwise_distances_chunked.working_memory": 0,
    "sklearn.metrics.pairwise.pairwise_kernels.Y": 0,
    "sklearn.metrics.pairwise.pairwise_kernels.n_jobs": 0,
    "sklearn.metrics.pairwise.polynomial_kernel.degree": 0,
    "sklearn.metrics.pairwise.polynomial_kernel.gamma": 0,
    "sklearn.metrics.pairwise.polynomial_kernel.coef0": 0,
    "sklearn.metrics.pairwise.rbf_kernel.gamma": 0,
    "sklearn.metrics.pairwise.sigmoid_kernel.gamma": 0,
    "sklearn.metrics.pairwise.sigmoid_kernel.coef0": 0,
    "sklearn.metrics.setup.configuration.parent_package": 0,
    "sklearn.metrics.setup.configuration.top_path": 0,
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.tol": 0,
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.reg_covar": 0,
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.init_params": 0,
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.mean_precision_prior": 0,
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.mean_prior": 0,
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.degrees_of_freedom_prior": 0,
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.covariance_prior": 0,
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.warm_start": 0,
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.verbose_interval": 0,
    "sklearn.model_selection._search.ParameterGrid.__getitem__.ind": 0,
    "sklearn.model_selection._search.ParameterSampler.__init__.param_distributions": 0,
    "sklearn.model_selection._search.ParameterSampler.__init__.n_iter": 0,
    "sklearn.model_selection._search.ParameterSampler.__init__.random_state": 0,
    "sklearn.model_selection._search.fit_grid_point.X": 0,
    "sklearn.model_selection._search.fit_grid_point.y": 0,
    "sklearn.model_selection._search.fit_grid_point.estimator": 0,
    "sklearn.model_selection._search.fit_grid_point.parameters": 0,
    "sklearn.model_selection._search.fit_grid_point.train": 0,
    "sklearn.model_selection._search.fit_grid_point.test": 0,
    "sklearn.model_selection._search.fit_grid_point.scorer": 0,
    "sklearn.model_selection._search.fit_grid_point.verbose": 0,
    "sklearn.model_selection._search.fit_grid_point.error_score": 0,
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.estimator": 0,
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.param_grid": 0,
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.factor": 0,
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.resource": 0,
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.max_resources": 0,
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.min_resources": 0,
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.aggressive_elimination": 0,
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.cv": 0,
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.scoring": 0,
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.refit": 0,
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.error_score": 0,
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.return_train_score": 0,
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.random_state": 0,
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.n_jobs": 0,
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.verbose": 0,
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.n_candidates": 0,
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.factor": 0,
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.min_resources": 0,
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.aggressive_elimination": 0,
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.refit": 0,
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.error_score": 0,
    "sklearn.model_selection._split.BaseCrossValidator.get_n_splits.X": 0,
    "sklearn.model_selection._split.BaseCrossValidator.get_n_splits.y": 0,
    "sklearn.model_selection._split.BaseCrossValidator.get_n_splits.groups": 0,
    "sklearn.model_selection._split.BaseCrossValidator.split.y": 0,
    "sklearn.model_selection._split.BaseCrossValidator.split.groups": 0,
    "sklearn.model_selection._split.LeaveOneOut.get_n_splits.y": 0,
    "sklearn.model_selection._split.LeaveOneOut.get_n_splits.groups": 0,
    "sklearn.model_selection._split.LeavePGroupsOut.__init__.n_groups": 0,
    "sklearn.model_selection._split.LeavePGroupsOut.get_n_splits.X": 0,
    "sklearn.model_selection._split.LeavePGroupsOut.get_n_splits.y": 0,
    "sklearn.model_selection._split.LeavePGroupsOut.get_n_splits.groups": 0,
    "sklearn.model_selection._split.LeavePGroupsOut.split.X": 0,
    "sklearn.model_selection._split.LeavePGroupsOut.split.y": 0,
    "sklearn.model_selection._split.LeavePGroupsOut.split.groups": 0,
    "sklearn.model_selection._split.LeavePOut.__init__.p": 0,
    "sklearn.model_selection._split.LeavePOut.get_n_splits.X": 0,
    "sklearn.model_selection._split.LeavePOut.get_n_splits.y": 0,
    "sklearn.model_selection._split.LeavePOut.get_n_splits.groups": 0,
    "sklearn.model_selection._split.PredefinedSplit.get_n_splits.X": 0,
    "sklearn.model_selection._split.PredefinedSplit.get_n_splits.y": 0,
    "sklearn.model_selection._split.PredefinedSplit.get_n_splits.groups": 0,
    "sklearn.model_selection._split.PredefinedSplit.split.X": 0,
    "sklearn.model_selection._split.PredefinedSplit.split.y": 0,
    "sklearn.model_selection._split.PredefinedSplit.split.groups": 0,
    "sklearn.model_selection._validation.cross_val_predict.pre_dispatch": 0,
    "sklearn.model_selection._validation.cross_val_score.pre_dispatch": 0,
    "sklearn.model_selection._validation.cross_validate.pre_dispatch": 0,
    "sklearn.model_selection._validation.cross_validate.error_score": 0,
    "sklearn.model_selection._validation.learning_curve.groups": 0,
    "sklearn.model_selection._validation.learning_curve.exploit_incremental_learning": 0,
    "sklearn.model_selection._validation.learning_curve.pre_dispatch": 0,
    "sklearn.model_selection._validation.learning_curve.error_score": 0,
    "sklearn.model_selection._validation.permutation_test_score.estimator": 0,
    "sklearn.model_selection._validation.permutation_test_score.X": 0,
    "sklearn.model_selection._validation.permutation_test_score.y": 0,
    "sklearn.model_selection._validation.permutation_test_score.groups": 0,
    "sklearn.model_selection._validation.permutation_test_score.cv": 0,
    "sklearn.model_selection._validation.permutation_test_score.n_permutations": 0,
    "sklearn.model_selection._validation.permutation_test_score.n_jobs": 0,
    "sklearn.model_selection._validation.permutation_test_score.random_state": 0,
    "sklearn.model_selection._validation.permutation_test_score.verbose": 0,
    "sklearn.model_selection._validation.permutation_test_score.scoring": 0,
    "sklearn.model_selection._validation.permutation_test_score.fit_params": 0,
    "sklearn.model_selection._validation.validation_curve.groups": 0,
    "sklearn.model_selection._validation.validation_curve.pre_dispatch": 0,
    "sklearn.model_selection._validation.validation_curve.error_score": 0,
    "sklearn.model_selection._validation.validation_curve.fit_params": 0,
    "sklearn.multiclass.OneVsOneClassifier.__init__.n_jobs": 0,
    "sklearn.multiclass.OneVsOneClassifier.partial_fit.X": 0,
    "sklearn.multiclass.OneVsOneClassifier.partial_fit.y": 0,
    "sklearn.multiclass.OneVsOneClassifier.partial_fit.classes": 0,
    "sklearn.multiclass.OneVsRestClassifier.partial_fit.X": 0,
    "sklearn.multiclass.OneVsRestClassifier.partial_fit.y": 0,
    "sklearn.multiclass.OneVsRestClassifier.partial_fit.classes": 0,
    "sklearn.multiclass.OutputCodeClassifier.__init__.estimator": 0,
    "sklearn.multiclass.OutputCodeClassifier.__init__.code_size": 0,
    "sklearn.multiclass.OutputCodeClassifier.__init__.random_state": 0,
    "sklearn.multiclass.OutputCodeClassifier.__init__.n_jobs": 0,
    "sklearn.multiclass.OutputCodeClassifier.fit.X": 0,
    "sklearn.multiclass.OutputCodeClassifier.fit.y": 0,
    "sklearn.multiclass.OutputCodeClassifier.predict.X": 0,
    "sklearn.multioutput.ClassifierChain.decision_function.X": 0,
    "sklearn.multioutput.ClassifierChain.fit.X": 0,
    "sklearn.multioutput.ClassifierChain.fit.Y": 0,
    "sklearn.multioutput.ClassifierChain.predict_proba.X": 0,
    "sklearn.multioutput.MultiOutputClassifier.fit.sample_weight": 0,
    "sklearn.multioutput.MultiOutputRegressor.partial_fit.X": 0,
    "sklearn.multioutput.MultiOutputRegressor.partial_fit.y": 0,
    "sklearn.multioutput.MultiOutputRegressor.partial_fit.sample_weight": 0,
    "sklearn.naive_bayes.CategoricalNB.__init__.fit_prior": 0,
    "sklearn.naive_bayes.CategoricalNB.__init__.class_prior": 0,
    "sklearn.naive_bayes.CategoricalNB.__init__.min_categories": 0,
    "sklearn.naive_bayes.CategoricalNB.fit.sample_weight": 0,
    "sklearn.naive_bayes.CategoricalNB.partial_fit.X": 0,
    "sklearn.naive_bayes.CategoricalNB.partial_fit.y": 0,
    "sklearn.naive_bayes.CategoricalNB.partial_fit.classes": 0,
    "sklearn.naive_bayes.CategoricalNB.partial_fit.sample_weight": 0,
    "sklearn.naive_bayes.ComplementNB.__init__.fit_prior": 0,
    "sklearn.naive_bayes.ComplementNB.__init__.class_prior": 0,
    "sklearn.naive_bayes.ComplementNB.__init__.norm": 0,
    "sklearn.naive_bayes.GaussianNB.partial_fit.sample_weight": 0,
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.predict_proba.X": 0,
    "sklearn.neighbors._graph.KNeighborsTransformer.__init__.mode": 0,
    "sklearn.neighbors._graph.KNeighborsTransformer.__init__.n_neighbors": 0,
    "sklearn.neighbors._graph.KNeighborsTransformer.__init__.algorithm": 0,
    "sklearn.neighbors._graph.KNeighborsTransformer.__init__.leaf_size": 0,
    "sklearn.neighbors._graph.KNeighborsTransformer.__init__.metric": 0,
    "sklearn.neighbors._graph.KNeighborsTransformer.__init__.p": 0,
    "sklearn.neighbors._graph.KNeighborsTransformer.__init__.metric_params": 0,
    "sklearn.neighbors._graph.KNeighborsTransformer.__init__.n_jobs": 0,
    "sklearn.neighbors._graph.KNeighborsTransformer.fit.X": 0,
    "sklearn.neighbors._graph.KNeighborsTransformer.fit.y": 0,
    "sklearn.neighbors._graph.KNeighborsTransformer.fit_transform.X": 0,
    "sklearn.neighbors._graph.KNeighborsTransformer.fit_transform.y": 0,
    "sklearn.neighbors._graph.KNeighborsTransformer.transform.X": 0,
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.__init__.mode": 0,
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.__init__.radius": 0,
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.__init__.algorithm": 0,
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.__init__.leaf_size": 0,
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.__init__.metric": 0,
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.__init__.p": 0,
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.__init__.metric_params": 0,
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.__init__.n_jobs": 0,
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.fit.X": 0,
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.fit.y": 0,
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.fit_transform.X": 0,
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.fit_transform.y": 0,
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.transform.X": 0,
    "sklearn.neighbors._graph.kneighbors_graph.mode": 0,
    "sklearn.neighbors._graph.kneighbors_graph.metric": 0,
    "sklearn.neighbors._graph.kneighbors_graph.p": 0,
    "sklearn.neighbors._graph.kneighbors_graph.metric_params": 0,
    "sklearn.neighbors._graph.kneighbors_graph.include_self": 0,
    "sklearn.neighbors._graph.kneighbors_graph.n_jobs": 0,
    "sklearn.neighbors._graph.radius_neighbors_graph.X": 0,
    "sklearn.neighbors._graph.radius_neighbors_graph.radius": 0,
    "sklearn.neighbors._graph.radius_neighbors_graph.mode": 0,
    "sklearn.neighbors._graph.radius_neighbors_graph.metric": 0,
    "sklearn.neighbors._graph.radius_neighbors_graph.p": 0,
    "sklearn.neighbors._graph.radius_neighbors_graph.metric_params": 0,
    "sklearn.neighbors._graph.radius_neighbors_graph.include_self": 0,
    "sklearn.neighbors._graph.radius_neighbors_graph.n_jobs": 0,
    "sklearn.neighbors._kde.KernelDensity.__init__.algorithm": 0,
    "sklearn.neighbors._kde.KernelDensity.__init__.atol": 0,
    "sklearn.neighbors._kde.KernelDensity.__init__.rtol": 0,
    "sklearn.neighbors._kde.KernelDensity.__init__.breadth_first": 0,
    "sklearn.neighbors._kde.KernelDensity.__init__.leaf_size": 0,
    "sklearn.neighbors._kde.KernelDensity.__init__.metric_params": 0,
    "sklearn.neighbors._kde.KernelDensity.fit.y": 0,
    "sklearn.neighbors._kde.KernelDensity.fit.sample_weight": 0,
    "sklearn.neighbors._kde.KernelDensity.score.X": 0,
    "sklearn.neighbors._kde.KernelDensity.score.y": 0,
    "sklearn.neighbors._lof.LocalOutlierFactor.__init__.algorithm": 0,
    "sklearn.neighbors._lof.LocalOutlierFactor.__init__.leaf_size": 0,
    "sklearn.neighbors._lof.LocalOutlierFactor.__init__.metric_params": 0,
    "sklearn.neighbors._lof.LocalOutlierFactor.__init__.novelty": 0,
    "sklearn.neighbors._lof.LocalOutlierFactor.fit.y": 0,
    "sklearn.neighbors._nca.NeighborhoodComponentsAnalysis.__init__.n_components": 0,
    "sklearn.neighbors._nca.NeighborhoodComponentsAnalysis.__init__.init": 0,
    "sklearn.neighbors._nca.NeighborhoodComponentsAnalysis.__init__.warm_start": 0,
    "sklearn.neighbors._nca.NeighborhoodComponentsAnalysis.__init__.max_iter": 0,
    "sklearn.neighbors._nca.NeighborhoodComponentsAnalysis.__init__.tol": 0,
    "sklearn.neighbors._nca.NeighborhoodComponentsAnalysis.__init__.callback": 0,
    "sklearn.neighbors._nca.NeighborhoodComponentsAnalysis.__init__.verbose": 0,
    "sklearn.neighbors._nca.NeighborhoodComponentsAnalysis.fit.X": 0,
    "sklearn.neighbors._nca.NeighborhoodComponentsAnalysis.fit.y": 0,
    "sklearn.neighbors._nca.NeighborhoodComponentsAnalysis.transform.X": 0,
    "sklearn.neighbors._nearest_centroid.NearestCentroid.__init__.metric": 0,
    "sklearn.neighbors._nearest_centroid.NearestCentroid.__init__.shrink_threshold": 0,
    "sklearn.neighbors._regression.RadiusNeighborsRegressor.__init__.algorithm": 0,
    "sklearn.neighbors._regression.RadiusNeighborsRegressor.__init__.leaf_size": 0,
    "sklearn.neighbors._regression.RadiusNeighborsRegressor.__init__.metric_params": 0,
    "sklearn.neighbors._regression.RadiusNeighborsRegressor.__init__.n_jobs": 0,
    "sklearn.neighbors._unsupervised.NearestNeighbors.__init__.leaf_size": 0,
    "sklearn.neighbors._unsupervised.NearestNeighbors.__init__.p": 0,
    "sklearn.neighbors._unsupervised.NearestNeighbors.__init__.metric_params": 0,
    "sklearn.neighbors.setup.configuration.parent_package": 0,
    "sklearn.neighbors.setup.configuration.top_path": 0,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.max_fun": 0,
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.predict_log_proba.X": 0,
    "sklearn.neural_network._rbm.BernoulliRBM.__init__.learning_rate": 0,
    "sklearn.neural_network._rbm.BernoulliRBM.__init__.batch_size": 0,
    "sklearn.neural_network._rbm.BernoulliRBM.__init__.n_iter": 0,
    "sklearn.neural_network._rbm.BernoulliRBM.__init__.verbose": 0,
    "sklearn.neural_network._rbm.BernoulliRBM.fit.y": 0,
    "sklearn.neural_network._rbm.BernoulliRBM.gibbs.v": 0,
    "sklearn.neural_network._rbm.BernoulliRBM.partial_fit.X": 0,
    "sklearn.neural_network._rbm.BernoulliRBM.partial_fit.y": 0,
    "sklearn.neural_network._rbm.BernoulliRBM.transform.X": 0,
    "sklearn.pipeline.FeatureUnion.get_params.deep": 0,
    "sklearn.pipeline.Pipeline.__getitem__.ind": 0,
    "sklearn.pipeline.Pipeline.fit_predict.X": 0,
    "sklearn.pipeline.Pipeline.fit_predict.y": 0,
    "sklearn.pipeline.Pipeline.get_params.deep": 0,
    "sklearn.pipeline.Pipeline.predict_log_proba.X": 0,
    "sklearn.pipeline.Pipeline.score.sample_weight": 0,
    "sklearn.pipeline.Pipeline.score_samples.X": 0,
    "sklearn.pipeline.make_pipeline.memory": 0,
    "sklearn.pipeline.make_union.verbose": 0,
    "sklearn.preprocessing._data.Binarizer.__init__.copy": 0,
    "sklearn.preprocessing._data.Binarizer.fit.y": 0,
    "sklearn.preprocessing._data.Binarizer.transform.copy": 0,
    "sklearn.preprocessing._data.KernelCenterer.fit.K": 0,
    "sklearn.preprocessing._data.KernelCenterer.fit.y": 0,
    "sklearn.preprocessing._data.KernelCenterer.transform.copy": 0,
    "sklearn.preprocessing._data.MaxAbsScaler.fit.y": 0,
    "sklearn.preprocessing._data.MaxAbsScaler.partial_fit.X": 0,
    "sklearn.preprocessing._data.MaxAbsScaler.partial_fit.y": 0,
    "sklearn.preprocessing._data.MinMaxScaler.__init__.clip": 0,
    "sklearn.preprocessing._data.MinMaxScaler.partial_fit.y": 0,
    "sklearn.preprocessing._data.Normalizer.fit.y": 0,
    "sklearn.preprocessing._data.Normalizer.transform.copy": 0,
    "sklearn.preprocessing._data.PolynomialFeatures.__init__.order": 0,
    "sklearn.preprocessing._data.PowerTransformer.fit.y": 0,
    "sklearn.preprocessing._data.PowerTransformer.fit_transform.y": 0,
    "sklearn.preprocessing._data.QuantileTransformer.__init__.ignore_implicit_zeros": 0,
    "sklearn.preprocessing._data.QuantileTransformer.__init__.subsample": 0,
    "sklearn.preprocessing._data.QuantileTransformer.fit.y": 0,
    "sklearn.preprocessing._data.RobustScaler.fit.y": 0,
    "sklearn.preprocessing._data.StandardScaler.fit.sample_weight": 0,
    "sklearn.preprocessing._data.StandardScaler.inverse_transform.copy": 0,
    "sklearn.preprocessing._data.StandardScaler.partial_fit.y": 0,
    "sklearn.preprocessing._data.StandardScaler.partial_fit.sample_weight": 0,
    "sklearn.preprocessing._data.StandardScaler.transform.copy": 0,
    "sklearn.preprocessing._data.add_dummy_feature.X": 0,
    "sklearn.preprocessing._data.add_dummy_feature.value": 0,
    "sklearn.preprocessing._data.binarize.copy": 0,
    "sklearn.preprocessing._data.maxabs_scale.axis": 0,
    "sklearn.preprocessing._data.maxabs_scale.copy": 0,
    "sklearn.preprocessing._data.power_transform.standardize": 0,
    "sklearn.preprocessing._data.power_transform.copy": 0,
    "sklearn.preprocessing._data.quantile_transform.axis": 0,
    "sklearn.preprocessing._data.quantile_transform.ignore_implicit_zeros": 0,
    "sklearn.preprocessing._data.quantile_transform.subsample": 0,
    "sklearn.preprocessing._data.robust_scale.with_centering": 0,
    "sklearn.preprocessing._data.robust_scale.with_scaling": 0,
    "sklearn.preprocessing._data.robust_scale.copy": 0,
    "sklearn.preprocessing._data.robust_scale.unit_variance": 0,
    "sklearn.preprocessing._discretization.KBinsDiscretizer.__init__.dtype": 0,
    "sklearn.preprocessing._discretization.KBinsDiscretizer.fit.y": 0,
    "sklearn.preprocessing._discretization.KBinsDiscretizer.inverse_transform.Xt": 0,
    "sklearn.preprocessing._encoders.OneHotEncoder.fit.y": 0,
    "sklearn.preprocessing._encoders.OrdinalEncoder.fit.y": 0,
    "sklearn.preprocessing._function_transformer.FunctionTransformer.__init__.inv_kw_args": 0,
    "sklearn.preprocessing._function_transformer.FunctionTransformer.fit.X": 0,
    "sklearn.preprocessing._function_transformer.FunctionTransformer.fit.y": 0,
    "sklearn.preprocessing._function_transformer.FunctionTransformer.inverse_transform.X": 0,
    "sklearn.preprocessing._label.LabelBinarizer.__init__.neg_label": 0,
    "sklearn.preprocessing._label.LabelBinarizer.__init__.pos_label": 0,
    "sklearn.preprocessing._label.label_binarize.neg_label": 0,
    "sklearn.preprocessing._label.label_binarize.pos_label": 0,
    "sklearn.preprocessing._label.label_binarize.sparse_output": 0,
    "sklearn.preprocessing.setup.configuration.parent_package": 0,
    "sklearn.preprocessing.setup.configuration.top_path": 0,
    "sklearn.random_projection.BaseRandomProjection.__init__.n_components": 0,
    "sklearn.random_projection.BaseRandomProjection.__init__.eps": 0,
    "sklearn.random_projection.BaseRandomProjection.__init__.dense_output": 0,
    "sklearn.random_projection.BaseRandomProjection.__init__.random_state": 0,
    "sklearn.random_projection.BaseRandomProjection.fit.y": 0,
    "sklearn.random_projection.SparseRandomProjection.__init__.density": 0,
    "sklearn.random_projection.johnson_lindenstrauss_min_dim.n_samples": 0,
    "sklearn.random_projection.johnson_lindenstrauss_min_dim.eps": 0,
    "sklearn.semi_supervised._label_propagation.LabelPropagation.__init__.kernel": 0,
    "sklearn.semi_supervised._label_propagation.LabelPropagation.__init__.gamma": 0,
    "sklearn.semi_supervised._label_propagation.LabelPropagation.__init__.tol": 0,
    "sklearn.semi_supervised._label_propagation.LabelPropagation.__init__.n_jobs": 0,
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.__init__.base_estimator": 0,
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.__init__.threshold": 0,
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.__init__.criterion": 0,
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.__init__.k_best": 0,
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.__init__.max_iter": 0,
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.__init__.verbose": 0,
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.decision_function.X": 0,
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.fit.X": 0,
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.fit.y": 0,
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.predict.X": 0,
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.predict_log_proba.X": 0,
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.predict_proba.X": 0,
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.score.X": 0,
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.score.y": 0,
    "sklearn.setup.configuration.parent_package": 0,
    "sklearn.setup.configuration.top_path": 0,
    "sklearn.setup_module.module": 0,
    "sklearn.svm._bounds.l1_min_c.X": 0,
    "sklearn.svm._bounds.l1_min_c.y": 0,
    "sklearn.svm._bounds.l1_min_c.loss": 0,
    "sklearn.svm._bounds.l1_min_c.fit_intercept": 0,
    "sklearn.svm._bounds.l1_min_c.intercept_scaling": 0,
    "sklearn.svm._classes.LinearSVC.fit.sample_weight": 0,
    "sklearn.svm._classes.LinearSVR.fit.sample_weight": 0,
    "sklearn.svm._classes.NuSVC.__init__.shrinking": 0,
    "sklearn.svm._classes.NuSVC.__init__.class_weight": 0,
    "sklearn.svm._classes.NuSVC.__init__.verbose": 0,
    "sklearn.svm._classes.NuSVC.__init__.decision_function_shape": 0,
    "sklearn.svm._classes.NuSVC.__init__.break_ties": 0,
    "sklearn.svm._classes.NuSVR.__init__.coef0": 0,
    "sklearn.svm._classes.NuSVR.__init__.cache_size": 0,
    "sklearn.svm._classes.OneClassSVM.__init__.degree": 0,
    "sklearn.svm._classes.OneClassSVM.__init__.coef0": 0,
    "sklearn.svm._classes.OneClassSVM.__init__.tol": 0,
    "sklearn.svm._classes.OneClassSVM.__init__.shrinking": 0,
    "sklearn.svm._classes.OneClassSVM.__init__.cache_size": 0,
    "sklearn.svm._classes.OneClassSVM.__init__.verbose": 0,
    "sklearn.svm._classes.OneClassSVM.__init__.max_iter": 0,
    "sklearn.svm._classes.OneClassSVM.fit.y": 0,
    "sklearn.svm._classes.OneClassSVM.fit.sample_weight": 0,
    "sklearn.svm._classes.OneClassSVM.score_samples.X": 0,
    "sklearn.svm.setup.configuration.parent_package": 0,
    "sklearn.svm.setup.configuration.top_path": 0,
    "sklearn.tree._classes.BaseDecisionTree.__init__.criterion": 0,
    "sklearn.tree._classes.BaseDecisionTree.__init__.splitter": 0,
    "sklearn.tree._classes.BaseDecisionTree.__init__.max_depth": 0,
    "sklearn.tree._classes.BaseDecisionTree.__init__.min_samples_split": 0,
    "sklearn.tree._classes.BaseDecisionTree.__init__.min_samples_leaf": 0,
    "sklearn.tree._classes.BaseDecisionTree.__init__.min_weight_fraction_leaf": 0,
    "sklearn.tree._classes.BaseDecisionTree.__init__.max_features": 0,
    "sklearn.tree._classes.BaseDecisionTree.__init__.max_leaf_nodes": 0,
    "sklearn.tree._classes.BaseDecisionTree.__init__.random_state": 0,
    "sklearn.tree._classes.BaseDecisionTree.__init__.min_impurity_decrease": 0,
    "sklearn.tree._classes.BaseDecisionTree.__init__.min_impurity_split": 0,
    "sklearn.tree._classes.BaseDecisionTree.__init__.class_weight": 0,
    "sklearn.tree._classes.BaseDecisionTree.__init__.ccp_alpha": 0,
    "sklearn.tree._classes.BaseDecisionTree.apply.check_input": 0,
    "sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path.sample_weight": 0,
    "sklearn.tree._classes.BaseDecisionTree.decision_path.X": 0,
    "sklearn.tree._classes.BaseDecisionTree.decision_path.check_input": 0,
    "sklearn.tree._classes.BaseDecisionTree.fit.X": 0,
    "sklearn.tree._classes.BaseDecisionTree.fit.y": 0,
    "sklearn.tree._classes.BaseDecisionTree.fit.sample_weight": 0,
    "sklearn.tree._classes.BaseDecisionTree.fit.check_input": 0,
    "sklearn.tree._classes.BaseDecisionTree.fit.X_idx_sorted": 0,
    "sklearn.tree._classes.BaseDecisionTree.predict.check_input": 0,
    "sklearn.tree._classes.DecisionTreeClassifier.fit.check_input": 0,
    "sklearn.tree._classes.DecisionTreeClassifier.fit.X_idx_sorted": 0,
    "sklearn.tree._classes.DecisionTreeClassifier.predict_log_proba.X": 0,
    "sklearn.tree._classes.DecisionTreeClassifier.predict_proba.check_input": 0,
    "sklearn.tree._classes.DecisionTreeRegressor.fit.sample_weight": 0,
    "sklearn.tree._classes.DecisionTreeRegressor.fit.check_input": 0,
    "sklearn.tree._classes.DecisionTreeRegressor.fit.X_idx_sorted": 0,
    "sklearn.tree._classes.ExtraTreeClassifier.__init__.splitter": 0,
    "sklearn.tree._classes.ExtraTreeClassifier.__init__.min_samples_leaf": 0,
    "sklearn.tree._classes.ExtraTreeClassifier.__init__.min_weight_fraction_leaf": 0,
    "sklearn.tree._classes.ExtraTreeClassifier.__init__.max_leaf_nodes": 0,
    "sklearn.tree._classes.ExtraTreeClassifier.__init__.min_impurity_decrease": 0,
    "sklearn.tree._classes.ExtraTreeClassifier.__init__.min_impurity_split": 0,
    "sklearn.tree._classes.ExtraTreeClassifier.__init__.class_weight": 0,
    "sklearn.tree._classes.ExtraTreeClassifier.__init__.ccp_alpha": 0,
    "sklearn.tree._classes.ExtraTreeRegressor.__init__.max_depth": 0,
    "sklearn.tree._classes.ExtraTreeRegressor.__init__.min_samples_split": 0,
    "sklearn.tree._classes.ExtraTreeRegressor.__init__.min_samples_leaf": 0,
    "sklearn.tree._classes.ExtraTreeRegressor.__init__.min_weight_fraction_leaf": 0,
    "sklearn.tree._classes.ExtraTreeRegressor.__init__.max_features": 0,
    "sklearn.tree._classes.ExtraTreeRegressor.__init__.min_impurity_decrease": 0,
    "sklearn.tree._classes.ExtraTreeRegressor.__init__.min_impurity_split": 0,
    "sklearn.tree._classes.ExtraTreeRegressor.__init__.max_leaf_nodes": 0,
    "sklearn.tree._classes.ExtraTreeRegressor.__init__.ccp_alpha": 0,
    "sklearn.tree._export.export_graphviz.label": 0,
    "sklearn.tree._export.export_graphviz.leaves_parallel": 0,
    "sklearn.tree._export.export_text.max_depth": 0,
    "sklearn.tree._export.export_text.spacing": 0,
    "sklearn.tree._export.export_text.decimals": 0,
    "sklearn.tree._export.export_text.show_weights": 0,
    "sklearn.tree._export.export_text.print_tree_recurse.node": 0,
    "sklearn.tree._export.export_text.print_tree_recurse.depth": 0,
    "sklearn.tree._export.plot_tree.impurity": 0,
    "sklearn.tree._export.plot_tree.node_ids": 0,
    "sklearn.tree._export.plot_tree.rotate": 0,
    "sklearn.tree._export.plot_tree.precision": 0,
    "sklearn.tree.setup.configuration.parent_package": 0,
    "sklearn.tree.setup.configuration.top_path": 0,
    "sklearn.utils.Bunch.__getattr__.key": 0,
    "sklearn.utils.Bunch.__setattr__.key": 0,
    "sklearn.utils.Bunch.__setattr__.value": 0,
    "sklearn.utils.Bunch.__setstate__.state": 0,
    "sklearn.utils._estimator_html_repr.estimator_html_repr.estimator": 0,
    "sklearn.utils.all_estimators.type_filter": 0,
    "sklearn.utils.all_estimators.is_abstract.c": 0,
    "sklearn.utils.axis0_safe_slice.X": 0,
    "sklearn.utils.axis0_safe_slice.mask": 0,
    "sklearn.utils.axis0_safe_slice.len_mask": 0,
    "sklearn.utils.check_matplotlib_support.caller_name": 0,
    "sklearn.utils.check_pandas_support.caller_name": 0,
    "sklearn.utils.deprecation.deprecated.__call__.obj": 0,
    "sklearn.utils.deprecation.deprecated.__init__.extra": 0,
    "sklearn.utils.estimator_checks.check_class_weight_balanced_classifiers.name": 0,
    "sklearn.utils.estimator_checks.check_class_weight_balanced_classifiers.classifier_orig": 0,
    "sklearn.utils.estimator_checks.check_class_weight_balanced_classifiers.X_train": 0,
    "sklearn.utils.estimator_checks.check_class_weight_balanced_classifiers.y_train": 0,
    "sklearn.utils.estimator_checks.check_class_weight_balanced_classifiers.X_test": 0,
    "sklearn.utils.estimator_checks.check_class_weight_balanced_classifiers.y_test": 0,
    "sklearn.utils.estimator_checks.check_class_weight_balanced_classifiers.weights": 0,
    "sklearn.utils.estimator_checks.check_class_weight_balanced_linear_classifier.name": 0,
    "sklearn.utils.estimator_checks.check_class_weight_balanced_linear_classifier.Classifier": 0,
    "sklearn.utils.estimator_checks.check_class_weight_classifiers.name": 0,
    "sklearn.utils.estimator_checks.check_class_weight_classifiers.classifier_orig": 0,
    "sklearn.utils.estimator_checks.check_classifier_data_not_an_array.name": 0,
    "sklearn.utils.estimator_checks.check_classifier_data_not_an_array.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_classifier_multioutput.name": 0,
    "sklearn.utils.estimator_checks.check_classifier_multioutput.estimator": 0,
    "sklearn.utils.estimator_checks.check_classifiers_classes.name": 0,
    "sklearn.utils.estimator_checks.check_classifiers_classes.classifier_orig": 0,
    "sklearn.utils.estimator_checks.check_classifiers_multilabel_representation_invariance.name": 0,
    "sklearn.utils.estimator_checks.check_classifiers_multilabel_representation_invariance.classifier_orig": 0,
    "sklearn.utils.estimator_checks.check_classifiers_one_label.name": 0,
    "sklearn.utils.estimator_checks.check_classifiers_one_label.classifier_orig": 0,
    "sklearn.utils.estimator_checks.check_classifiers_predictions.X": 0,
    "sklearn.utils.estimator_checks.check_classifiers_predictions.y": 0,
    "sklearn.utils.estimator_checks.check_classifiers_predictions.name": 0,
    "sklearn.utils.estimator_checks.check_classifiers_predictions.classifier_orig": 0,
    "sklearn.utils.estimator_checks.check_classifiers_regression_target.name": 0,
    "sklearn.utils.estimator_checks.check_classifiers_regression_target.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_classifiers_train.name": 0,
    "sklearn.utils.estimator_checks.check_classifiers_train.classifier_orig": 0,
    "sklearn.utils.estimator_checks.check_classifiers_train.readonly_memmap": 0,
    "sklearn.utils.estimator_checks.check_classifiers_train.X_dtype": 0,
    "sklearn.utils.estimator_checks.check_clusterer_compute_labels_predict.name": 0,
    "sklearn.utils.estimator_checks.check_clusterer_compute_labels_predict.clusterer_orig": 0,
    "sklearn.utils.estimator_checks.check_clustering.name": 0,
    "sklearn.utils.estimator_checks.check_clustering.clusterer_orig": 0,
    "sklearn.utils.estimator_checks.check_clustering.readonly_memmap": 0,
    "sklearn.utils.estimator_checks.check_complex_data.name": 0,
    "sklearn.utils.estimator_checks.check_complex_data.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_decision_proba_consistency.name": 0,
    "sklearn.utils.estimator_checks.check_decision_proba_consistency.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_dict_unchanged.name": 0,
    "sklearn.utils.estimator_checks.check_dict_unchanged.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_dont_overwrite_parameters.name": 0,
    "sklearn.utils.estimator_checks.check_dont_overwrite_parameters.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_dtype_object.name": 0,
    "sklearn.utils.estimator_checks.check_dtype_object.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_estimator.generate_only": 0,
    "sklearn.utils.estimator_checks.check_estimator_get_tags_default_keys.name": 0,
    "sklearn.utils.estimator_checks.check_estimator_get_tags_default_keys.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_estimator_sparse_data.name": 0,
    "sklearn.utils.estimator_checks.check_estimator_sparse_data.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_estimators_data_not_an_array.name": 0,
    "sklearn.utils.estimator_checks.check_estimators_data_not_an_array.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_estimators_data_not_an_array.X": 0,
    "sklearn.utils.estimator_checks.check_estimators_data_not_an_array.y": 0,
    "sklearn.utils.estimator_checks.check_estimators_data_not_an_array.obj_type": 0,
    "sklearn.utils.estimator_checks.check_estimators_dtypes.name": 0,
    "sklearn.utils.estimator_checks.check_estimators_dtypes.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_estimators_empty_data_messages.name": 0,
    "sklearn.utils.estimator_checks.check_estimators_empty_data_messages.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_estimators_fit_returns_self.name": 0,
    "sklearn.utils.estimator_checks.check_estimators_fit_returns_self.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_estimators_fit_returns_self.readonly_memmap": 0,
    "sklearn.utils.estimator_checks.check_estimators_nan_inf.name": 0,
    "sklearn.utils.estimator_checks.check_estimators_nan_inf.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_estimators_overwrite_params.name": 0,
    "sklearn.utils.estimator_checks.check_estimators_overwrite_params.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_estimators_partial_fit_n_features.name": 0,
    "sklearn.utils.estimator_checks.check_estimators_partial_fit_n_features.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_estimators_pickle.name": 0,
    "sklearn.utils.estimator_checks.check_estimators_pickle.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_estimators_unfitted.name": 0,
    "sklearn.utils.estimator_checks.check_estimators_unfitted.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_fit1d.name": 0,
    "sklearn.utils.estimator_checks.check_fit1d.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_fit2d_1feature.name": 0,
    "sklearn.utils.estimator_checks.check_fit2d_1feature.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_fit2d_1sample.name": 0,
    "sklearn.utils.estimator_checks.check_fit2d_1sample.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_fit2d_predict1d.name": 0,
    "sklearn.utils.estimator_checks.check_fit2d_predict1d.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_fit_idempotent.name": 0,
    "sklearn.utils.estimator_checks.check_fit_idempotent.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_fit_non_negative.name": 0,
    "sklearn.utils.estimator_checks.check_fit_non_negative.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_fit_score_takes_y.name": 0,
    "sklearn.utils.estimator_checks.check_fit_score_takes_y.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_get_params_invariance.name": 0,
    "sklearn.utils.estimator_checks.check_get_params_invariance.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_methods_sample_order_invariance.name": 0,
    "sklearn.utils.estimator_checks.check_methods_sample_order_invariance.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_methods_subset_invariance.name": 0,
    "sklearn.utils.estimator_checks.check_methods_subset_invariance.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_n_features_in.name": 0,
    "sklearn.utils.estimator_checks.check_n_features_in.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_n_features_in_after_fitting.name": 0,
    "sklearn.utils.estimator_checks.check_n_features_in_after_fitting.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_no_attributes_set_in_init.name": 0,
    "sklearn.utils.estimator_checks.check_no_attributes_set_in_init.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_non_transformer_estimators_n_iter.name": 0,
    "sklearn.utils.estimator_checks.check_non_transformer_estimators_n_iter.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_nonsquare_error.name": 0,
    "sklearn.utils.estimator_checks.check_nonsquare_error.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_outlier_corruption.num_outliers": 0,
    "sklearn.utils.estimator_checks.check_outlier_corruption.expected_outliers": 0,
    "sklearn.utils.estimator_checks.check_outlier_corruption.decision": 0,
    "sklearn.utils.estimator_checks.check_outliers_fit_predict.name": 0,
    "sklearn.utils.estimator_checks.check_outliers_fit_predict.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_outliers_train.name": 0,
    "sklearn.utils.estimator_checks.check_outliers_train.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_outliers_train.readonly_memmap": 0,
    "sklearn.utils.estimator_checks.check_parameters_default_constructible.name": 0,
    "sklearn.utils.estimator_checks.check_parameters_default_constructible.Estimator": 0,
    "sklearn.utils.estimator_checks.check_parameters_default_constructible.param_filter.p": 0,
    "sklearn.utils.estimator_checks.check_pipeline_consistency.name": 0,
    "sklearn.utils.estimator_checks.check_pipeline_consistency.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_regressor_data_not_an_array.name": 0,
    "sklearn.utils.estimator_checks.check_regressor_data_not_an_array.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_regressor_multioutput.name": 0,
    "sklearn.utils.estimator_checks.check_regressor_multioutput.estimator": 0,
    "sklearn.utils.estimator_checks.check_regressors_int.name": 0,
    "sklearn.utils.estimator_checks.check_regressors_int.regressor_orig": 0,
    "sklearn.utils.estimator_checks.check_regressors_no_decision_function.name": 0,
    "sklearn.utils.estimator_checks.check_regressors_no_decision_function.regressor_orig": 0,
    "sklearn.utils.estimator_checks.check_regressors_train.name": 0,
    "sklearn.utils.estimator_checks.check_regressors_train.regressor_orig": 0,
    "sklearn.utils.estimator_checks.check_regressors_train.readonly_memmap": 0,
    "sklearn.utils.estimator_checks.check_regressors_train.X_dtype": 0,
    "sklearn.utils.estimator_checks.check_requires_y_none.name": 0,
    "sklearn.utils.estimator_checks.check_requires_y_none.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_sample_weights_invariance.name": 0,
    "sklearn.utils.estimator_checks.check_sample_weights_invariance.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_sample_weights_invariance.kind": 0,
    "sklearn.utils.estimator_checks.check_sample_weights_list.name": 0,
    "sklearn.utils.estimator_checks.check_sample_weights_list.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_sample_weights_not_an_array.name": 0,
    "sklearn.utils.estimator_checks.check_sample_weights_not_an_array.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_sample_weights_pandas_series.name": 0,
    "sklearn.utils.estimator_checks.check_sample_weights_pandas_series.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_sample_weights_shape.name": 0,
    "sklearn.utils.estimator_checks.check_sample_weights_shape.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_set_params.name": 0,
    "sklearn.utils.estimator_checks.check_set_params.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_sparsify_coefficients.name": 0,
    "sklearn.utils.estimator_checks.check_sparsify_coefficients.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_supervised_y_2d.name": 0,
    "sklearn.utils.estimator_checks.check_supervised_y_2d.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_supervised_y_no_nan.name": 0,
    "sklearn.utils.estimator_checks.check_supervised_y_no_nan.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_transformer_data_not_an_array.name": 0,
    "sklearn.utils.estimator_checks.check_transformer_data_not_an_array.transformer": 0,
    "sklearn.utils.estimator_checks.check_transformer_general.name": 0,
    "sklearn.utils.estimator_checks.check_transformer_general.transformer": 0,
    "sklearn.utils.estimator_checks.check_transformer_general.readonly_memmap": 0,
    "sklearn.utils.estimator_checks.check_transformer_n_iter.name": 0,
    "sklearn.utils.estimator_checks.check_transformer_n_iter.estimator_orig": 0,
    "sklearn.utils.estimator_checks.check_transformer_preserve_dtypes.name": 0,
    "sklearn.utils.estimator_checks.check_transformer_preserve_dtypes.transformer_orig": 0,
    "sklearn.utils.estimator_checks.check_transformers_unfitted.name": 0,
    "sklearn.utils.estimator_checks.check_transformers_unfitted.transformer": 0,
    "sklearn.utils.estimator_checks.parametrize_with_checks.estimators": 0,
    "sklearn.utils.extmath.cartesian.out": 0,
    "sklearn.utils.extmath.fast_logdet.A": 0,
    "sklearn.utils.extmath.log_logistic.X": 0,
    "sklearn.utils.extmath.log_logistic.out": 0,
    "sklearn.utils.extmath.make_nonnegative.X": 0,
    "sklearn.utils.extmath.make_nonnegative.min_value": 0,
    "sklearn.utils.extmath.randomized_range_finder.A": 0,
    "sklearn.utils.extmath.randomized_range_finder.size": 0,
    "sklearn.utils.extmath.randomized_range_finder.n_iter": 0,
    "sklearn.utils.extmath.randomized_range_finder.power_iteration_normalizer": 0,
    "sklearn.utils.extmath.randomized_range_finder.random_state": 0,
    "sklearn.utils.extmath.randomized_svd.M": 0,
    "sklearn.utils.extmath.randomized_svd.n_components": 0,
    "sklearn.utils.extmath.randomized_svd.n_oversamples": 0,
    "sklearn.utils.extmath.randomized_svd.n_iter": 0,
    "sklearn.utils.extmath.randomized_svd.power_iteration_normalizer": 0,
    "sklearn.utils.extmath.randomized_svd.transpose": 0,
    "sklearn.utils.extmath.randomized_svd.flip_sign": 0,
    "sklearn.utils.extmath.randomized_svd.random_state": 0,
    "sklearn.utils.extmath.row_norms.X": 0,
    "sklearn.utils.extmath.row_norms.squared": 0,
    "sklearn.utils.extmath.safe_sparse_dot.dense_output": 0,
    "sklearn.utils.extmath.softmax.X": 0,
    "sklearn.utils.extmath.softmax.copy": 0,
    "sklearn.utils.extmath.squared_norm.x": 0,
    "sklearn.utils.extmath.stable_cumsum.arr": 0,
    "sklearn.utils.extmath.stable_cumsum.axis": 0,
    "sklearn.utils.extmath.stable_cumsum.rtol": 0,
    "sklearn.utils.extmath.stable_cumsum.atol": 0,
    "sklearn.utils.extmath.svd_flip.u": 0,
    "sklearn.utils.extmath.svd_flip.v": 0,
    "sklearn.utils.extmath.svd_flip.u_based_decision": 0,
    "sklearn.utils.fixes.delayed.function": 0,
    "sklearn.utils.gen_batches.n": 0,
    "sklearn.utils.gen_batches.batch_size": 0,
    "sklearn.utils.gen_batches.min_batch_size": 0,
    "sklearn.utils.gen_even_slices.n": 0,
    "sklearn.utils.gen_even_slices.n_packs": 0,
    "sklearn.utils.gen_even_slices.n_samples": 0,
    "sklearn.utils.get_chunk_n_rows.row_bytes": 0,
    "sklearn.utils.get_chunk_n_rows.max_n_rows": 0,
    "sklearn.utils.get_chunk_n_rows.working_memory": 0,
    "sklearn.utils.graph.single_source_shortest_path_length.graph": 0,
    "sklearn.utils.graph.single_source_shortest_path_length.source": 0,
    "sklearn.utils.graph.single_source_shortest_path_length.cutoff": 0,
    "sklearn.utils.indices_to_mask.indices": 0,
    "sklearn.utils.indices_to_mask.mask_length": 0,
    "sklearn.utils.is_scalar_nan.x": 0,
    "sklearn.utils.multiclass.check_classification_targets.y": 0,
    "sklearn.utils.multiclass.class_distribution.y": 0,
    "sklearn.utils.multiclass.class_distribution.sample_weight": 0,
    "sklearn.utils.multiclass.is_multilabel.y": 0,
    "sklearn.utils.resample.stratify": 0,
    "sklearn.utils.safe_sqr.copy": 0,
    "sklearn.utils.setup.configuration.parent_package": 0,
    "sklearn.utils.setup.configuration.top_path": 0,
    "sklearn.utils.sparsefuncs.count_nonzero.X": 0,
    "sklearn.utils.sparsefuncs.count_nonzero.axis": 0,
    "sklearn.utils.sparsefuncs.count_nonzero.sample_weight": 0,
    "sklearn.utils.sparsefuncs.csc_median_axis_0.X": 0,
    "sklearn.utils.sparsefuncs.incr_mean_variance_axis.X": 0,
    "sklearn.utils.sparsefuncs.incr_mean_variance_axis.axis": 0,
    "sklearn.utils.sparsefuncs.incr_mean_variance_axis.last_mean": 0,
    "sklearn.utils.sparsefuncs.incr_mean_variance_axis.last_var": 0,
    "sklearn.utils.sparsefuncs.incr_mean_variance_axis.last_n": 0,
    "sklearn.utils.sparsefuncs.incr_mean_variance_axis.weights": 0,
    "sklearn.utils.sparsefuncs.inplace_column_scale.X": 0,
    "sklearn.utils.sparsefuncs.inplace_column_scale.scale": 0,
    "sklearn.utils.sparsefuncs.inplace_csr_column_scale.X": 0,
    "sklearn.utils.sparsefuncs.inplace_csr_column_scale.scale": 0,
    "sklearn.utils.sparsefuncs.inplace_csr_row_scale.X": 0,
    "sklearn.utils.sparsefuncs.inplace_csr_row_scale.scale": 0,
    "sklearn.utils.sparsefuncs.inplace_row_scale.X": 0,
    "sklearn.utils.sparsefuncs.inplace_row_scale.scale": 0,
    "sklearn.utils.sparsefuncs.inplace_swap_column.X": 0,
    "sklearn.utils.sparsefuncs.inplace_swap_column.m": 0,
    "sklearn.utils.sparsefuncs.inplace_swap_column.n": 0,
    "sklearn.utils.sparsefuncs.inplace_swap_row.X": 0,
    "sklearn.utils.sparsefuncs.inplace_swap_row.m": 0,
    "sklearn.utils.sparsefuncs.inplace_swap_row.n": 0,
    "sklearn.utils.sparsefuncs.inplace_swap_row_csc.X": 0,
    "sklearn.utils.sparsefuncs.inplace_swap_row_csc.m": 0,
    "sklearn.utils.sparsefuncs.inplace_swap_row_csc.n": 0,
    "sklearn.utils.sparsefuncs.inplace_swap_row_csr.X": 0,
    "sklearn.utils.sparsefuncs.inplace_swap_row_csr.m": 0,
    "sklearn.utils.sparsefuncs.inplace_swap_row_csr.n": 0,
    "sklearn.utils.sparsefuncs.mean_variance_axis.X": 0,
    "sklearn.utils.sparsefuncs.mean_variance_axis.axis": 0,
    "sklearn.utils.sparsefuncs.mean_variance_axis.weights": 0,
    "sklearn.utils.sparsefuncs.mean_variance_axis.return_sum_weights": 0,
    "sklearn.utils.sparsefuncs.min_max_axis.X": 0,
    "sklearn.utils.sparsefuncs.min_max_axis.axis": 0,
    "sklearn.utils.sparsefuncs.min_max_axis.ignore_nan": 0,
    "sklearn.utils.tosequence.x": 0,
    "sklearn.utils.validation.as_float_array.X": 0,
    "sklearn.utils.validation.as_float_array.copy": 0,
    "sklearn.utils.validation.as_float_array.force_all_finite": 0,
    "sklearn.utils.validation.assert_all_finite.X": 0,
    "sklearn.utils.validation.assert_all_finite.allow_nan": 0,
    "sklearn.utils.validation.check_X_y.accept_large_sparse": 0,
    "sklearn.utils.validation.check_X_y.order": 0,
    "sklearn.utils.validation.check_X_y.copy": 0,
    "sklearn.utils.validation.check_X_y.ensure_2d": 0,
    "sklearn.utils.validation.check_X_y.allow_nd": 0,
    "sklearn.utils.validation.check_X_y.multi_output": 0,
    "sklearn.utils.validation.check_X_y.ensure_min_samples": 0,
    "sklearn.utils.validation.check_X_y.ensure_min_features": 0,
    "sklearn.utils.validation.check_X_y.estimator": 0,
    "sklearn.utils.validation.check_array.accept_large_sparse": 0,
    "sklearn.utils.validation.check_array.order": 0,
    "sklearn.utils.validation.check_array.allow_nd": 0,
    "sklearn.utils.validation.check_array.ensure_min_samples": 0,
    "sklearn.utils.validation.check_array.ensure_min_features": 0,
    "sklearn.utils.validation.check_is_fitted.msg": 0,
    "sklearn.utils.validation.check_is_fitted.all_or_any": 0,
    "sklearn.utils.validation.check_memory.memory": 0,
    "sklearn.utils.validation.check_non_negative.X": 0,
    "sklearn.utils.validation.check_non_negative.whom": 0,
    "sklearn.utils.validation.check_scalar.x": 0,
    "sklearn.utils.validation.check_scalar.name": 0,
    "sklearn.utils.validation.check_scalar.target_type": 0,
    "sklearn.utils.validation.check_scalar.min_val": 0,
    "sklearn.utils.validation.check_scalar.max_val": 0,
    "sklearn.utils.validation.check_symmetric.array": 0,
    "sklearn.utils.validation.check_symmetric.tol": 0,
    "sklearn.utils.validation.check_symmetric.raise_warning": 0,
    "sklearn.utils.validation.check_symmetric.raise_exception": 0,
    "sklearn.utils.validation.has_fit_parameter.estimator": 0,
    "sklearn.utils.validation.has_fit_parameter.parameter": 0
  },
  "value_counts": {
    "sklearn.model_selection._split.train_test_split.test_size": {
      "0.2": 6148,
      "0.3": 2244,
      "0.1": 2241,
      "None": 1827,
      "0.25": 951,
      "0.33": 772,
      "0.15": 668,
      "0.05": 278,
      "0.5": 231,
      "0.4": 179,
      "test_size": 156,
      "0.01": 125,
      "0.08": 74,
      "TEST_SIZE": 48,
      "0.35": 46,
      "val_size": 39,
      "0.8": 29,
      "0.02": 28,
      "0.001": 22,
      "validation_size": 22,
      "0.7": 20,
      "0.12": 18,
      "0.22": 16,
      "1 / 3": 15,
      "valid_size": 15,
      "size": 14,
      "0.6": 12,
      "test_rate": 12,
      "3240": 12,
      "0.9": 11,
      "validation_split": 11,
      "0.028059109276941666": 10,
      "0.07": 10,
      "split_coef": 10,
      "0.03": 9,
      "0.0001": 9,
      "6000": 9,
      "split_size": 9,
      "split": 8,
      "ratio": 8,
      "0.18": 8,
      "10000": 7,
      "0.04": 7,
      "testSize": 7,
      "30": 7,
      "self.test_size": 7,
      "0.002": 6,
      "test_percentage": 6,
      "0.75": 6,
      "valid_part": 6,
      "0.45": 5,
      "val_split": 5,
      "0.21": 5,
      "0.025": 5,
      "0.0": 5,
      "VAL_SIZE": 5,
      "TRAIN_VAL_RATIO": 5,
      "split_params['test_size']": 5,
      "c_sample": 5,
      "0.14": 5,
      "TEST_SPLIT": 4,
      "0.17": 4,
      "1e-05": 4,
      "validation_percentage / 100.0": 4,
      "0.95": 4,
      "11": 4,
      "0.16": 4,
      "VALID_SIZE": 4,
      "0.85": 4,
      "0.333": 4,
      "20000": 4,
      "dev_sample_size": 4,
      "0.13": 4,
      "VAL_SPLIT": 4,
      "vldSz": 4,
      "0.0005": 3,
      "0.34": 3,
      "7000": 3,
      "CONFIG['train_val_split']": 3,
      "0.06": 3,
      "0": 3,
      "self.__test_size": 3,
      "tst_size": 3,
      "0.125": 3,
      "0.066": 3,
      "SPLIT_RATIO": 3,
      "VALIDATION_SIZE": 3,
      "0.99": 3,
      "0.98": 3,
      "TRAINING_VALIDATION_RATIO": 3,
      "1 / 5": 3,
      "tr_val_test[2]": 3,
      "tr_val_test[1] / (tr_val_test[0] + tr_val_test[1])": 3,
      "holdout_frac": 2,
      "valid_frac": 2,
      "100000": 2,
      "2 / 3": 2,
      "cfg.val_split": 2,
      "test_ratio": 2,
      "valid_ratio": 2,
      "VALIDATION_RATIO": 2,
      "split_pct": 2,
      "0.075": 2,
      "validation_rate": 2,
      "0.11": 2,
      "conf['test_size']": 2,
      "VALIDATION_SPLIT": 2,
      "1000": 2,
      "p": 2,
      "TRAIN_VAL_SPLIT": 2,
      "self.config.TEST_SIZE": 2,
      "validation_percentage": 2,
      "0.23": 2,
      "va_ratio": 2,
      "self.split": 2,
      "1 / splits": 2,
      "CFG.test_size": 2,
      "test_frac": 2,
      "num_test": 2,
      "0.66": 2,
      "TEST_RATIO": 2,
      "1 - split": 2,
      "0.24": 2,
      "200": 2,
      "fVal_size": 2,
      "1 - part1_ratio": 2,
      "3": 2,
      "TRAIN_VAL_SPLIT_RATIO": 2,
      "VALID_FRACTION": 2,
      "valid_pct": 2,
      "0.086956": 2,
      "1 / 10": 2,
      "Config.TEST_SIZE": 2,
      "test_size_ratio": 2,
      "SIZE": 2,
      "1000000": 2,
      "test_valid_size": 1,
      "param['validatesize']": 1,
      "0.39": 1,
      "len(X_trv[1])": 1,
      "CFG.TEST_SIZE": 1,
      "0.19": 1,
      "0.163": 1,
      "1 / 20": 1,
      "val_size + test_size": 1,
      "val_size / (val_size + test_size)": 1,
      "0.175": 1,
      "valFrac": 1,
      "TEST_PROP": 1,
      "0.99358": 1,
      "tsize": 1,
      "0.004": 1,
      "1800": 1,
      "dev_set_size_rate": 1,
      "split_proportion": 1,
      "my_params.test_size": 1,
      "0.09": 1,
      "split_train_size": 1,
      "PROPORTION_PRIVATE": 1,
      "validation_split_size": 1,
      "0.0356789": 1,
      "4700": 1,
      "2 / 11": 1,
      "0.28": 1,
      "8392": 1,
      "prob": 1,
      "VAL_SPLIT_RATIO": 1,
      "val_ratio": 1,
      "p['TRAIN_VALID_SPLIT']": 1,
      "0.3333": 1,
      "0.667": 1,
      "500": 1,
      "self.nval": 1,
      "cv_size": 1,
      "val_size_percent / 100": 1,
      "25 / 100": 1,
      "self.subset": 1,
      "1 - train_ratio": 1,
      "TEST_PERC": 1,
      "test_size_val": 1,
      "P_SETOUT": 1,
      "0.1925517854845237": 1,
      "TEST_PERCENTAGE": 1,
      "split_ratio": 1,
      "0.2222": 1,
      "1 / folds": 1,
      "validation_set_ratio": 1,
      "0.198": 1,
      "validation_ratio": 1,
      "cfg['validation_ratio']": 1,
      "TEST_PORTION": 1,
      "1 - train_size": 1,
      "1 - eval_size": 1,
      "int(nrow * 0.1)": 1,
      "int(nrow * 0.2)": 1,
      "HyperParameters.VALID_SIZE": 1,
      "num_validation": 1,
      "TEST_SHARE": 1,
      "50000": 1,
      "config['validation_split']": 1,
      "1.0 - ratio": 1,
      "1 / 12": 1,
      "1 - trainSetProportion": 1,
      "config.VAL_SIZE": 1,
      "1 / k": 1,
      "1 / (k - i)": 1,
      "dev_size": 1,
      "1 / CV_STEPS": 1,
      "vld_size": 1,
      "perc_test": 1,
      "CFG.VAL_SIZE": 1,
      "1.5 * NUM_CLASSES / NUM_EXAMPLES": 1,
      "train_val_split": 1,
      "1 - TRAIN_SIZE": 1,
      "0.005": 1,
      "ratio_test": 1,
      "ratio_val_adjusted": 1,
      "418": 1,
      "CFG['test_size']": 1,
      "1 / 4": 1,
      "test_sz": 1,
      "int(len(y_c) / 3.0)": 1,
      "int(len(y_cf) / 3.0)": 1,
      "valid_rate": 1,
      "train_data_perc": 1,
      "1.0 - percent / 100.0": 1,
      "percent / 100.0": 1,
      "549": 1,
      "test_split_size": 1,
      "valRatio": 1,
      "hp_test_size": 1,
      "0.275": 1,
      "test_size_percent": 1,
      "split(15000, len(data))": 1,
      "1 / 9": 1,
      "2e-05": 1,
      "40000": 1,
      "0.65": 1,
      "test_split": 1,
      "57458": 1,
      "0.101": 1,
      "0.9995": 1,
      "valid_fration": 1,
      "t_size": 1,
      "1e-08": 1,
      "1200": 1,
      "1 - Config.train_pcent": 1,
      "0.9999": 1,
      "12212": 1,
      "200000": 1,
      "train_to_valtest_ratio": 1,
      "validate_to_test_ratio": 1,
      "1 - tt_ratio": 1,
      "0.38": 1,
      "DATA_SPLIT_PCT": 1,
      "0.015": 1,
      "TRAINVAL_TEST_SPLIT": 1,
      "1 - split_frac": 1,
      "0.035": 1,
      "percent / 100": 1,
      "traintestsplit": 1,
      "1.0 - train_size": 1,
      "train_cfg['train_val_split']": 1,
      "val_rate": 1,
      "int(x_train.shape[0] * 0.1)": 1,
      "cfg.valsize + cfg.testsize": 1,
      "cfg.testsize": 1,
      "1 - PRC_TRAINING": 1,
      "PRC_TESTING": 1,
      "NUM_TEST_IMAGES": 1,
      "NUM_VAL_IMAGES": 1,
      "1 - SPLIT_RATIO": 1,
      "SPLIT_TEST_SIZE": 1,
      "size_test": 1,
      "vali_size": 1,
      "testsize": 1,
      "p_train_size": 1,
      "frac": 1,
      "1 / 8": 1,
      "PROP_VAL": 1,
      "ratio_val": 1,
      "0.43": 1
    },
    "sklearn.model_selection._split.train_test_split.random_state": {
      "42": 4237,
      "None": 4108,
      "0": 1785,
      "1": 847,
      "123": 334,
      "seed": 293,
      "2018": 244,
      "SEED": 232,
      "101": 207,
      "2": 200,
      "100": 190,
      "2020": 188,
      "2019": 178,
      "10": 169,
      "1234": 138,
      "7": 127,
      "5": 125,
      "23": 105,
      "random_seed": 100,
      "random_state": 87,
      "2021": 86,
      "233": 84,
      "666": 80,
      "RANDOM_STATE": 76,
      "40": 70,
      "111": 69,
      "17": 68,
      "4": 67,
      "99": 66,
      "12": 66,
      "i": 60,
      "50": 56,
      "1337": 56,
      "21": 55,
      "8": 53,
      "RANDOM_SEED": 52,
      "13": 51,
      "144": 46,
      "3": 46,
      "44": 45,
      "80": 44,
      "11": 39,
      "20": 37,
      "2017": 36,
      "43": 35,
      "777": 33,
      "4242": 33,
      "41": 31,
      "34": 31,
      "45": 30,
      "47": 30,
      "420": 29,
      "22": 29,
      "1987": 29,
      "32": 28,
      "12345": 26,
      "18": 24,
      "24": 24,
      "200": 23,
      "69": 22,
      "14": 21,
      "27": 21,
      "9": 20,
      "33": 20,
      "30": 19,
      "6": 17,
      "rs": 16,
      "15": 15,
      "36": 15,
      "314": 15,
      "53": 14,
      "101010": 13,
      "90": 13,
      "37": 12,
      "25": 11,
      "46": 11,
      "self.random_state": 11,
      "48": 11,
      "128": 10,
      "rand_state": 10,
      "52": 10,
      "71": 10,
      "16": 9,
      "35": 9,
      "31": 9,
      "77": 9,
      "64": 9,
      "272": 8,
      "38": 8,
      "999": 8,
      "289": 8,
      "150": 8,
      "RS": 8,
      "63": 8,
      "555": 7,
      "58": 7,
      "112": 7,
      "26": 6,
      "92": 6,
      "56": 6,
      "55": 6,
      "self.seed": 6,
      "85": 6,
      "2000": 6,
      "69278": 6,
      "1001": 6,
      "22391": 6,
      "RSEED": 5,
      "1995": 5,
      "1989": 5,
      "97": 5,
      "19": 5,
      "1993": 5,
      "28": 5,
      "split_params['random_state']": 5,
      "CFG.seed": 5,
      "156": 5,
      "123456": 5,
      "randomState": 5,
      "Config.seed": 4,
      "1984": 4,
      "random_stat": 4,
      "49": 4,
      "1000": 4,
      "82": 4,
      "115": 4,
      "88": 4,
      "121": 4,
      "116214": 4,
      "GLOBAL_SEED": 4,
      "347": 4,
      "rand_seed": 4,
      "687": 4,
      "786": 4,
      "2016": 4,
      "config.seed": 4,
      "39": 4,
      "60": 4,
      "1997": 4,
      "529": 4,
      "seed_split": 4,
      "2701": 4,
      "SPLIT_SEED": 4,
      "77777": 4,
      "123456789": 4,
      "202": 3,
      "randomseed": 3,
      "1982": 3,
      "177": 3,
      "124": 3,
      "True": 3,
      "29": 3,
      "75": 3,
      "54": 3,
      "1301": 3,
      "rstate": 3,
      "78": 3,
      "1212": 3,
      "6666": 3,
      "669": 3,
      "1511": 3,
      "prng": 3,
      "143": 3,
      "rnd": 3,
      "234": 3,
      "255": 3,
      "1024": 3,
      "SEED_VALUE": 3,
      "2090": 3,
      "rs + x + 1": 3,
      "holdout_seed": 2,
      "RNG_SEED": 2,
      "451": 2,
      "CFG.SEED": 2,
      "122": 2,
      "196": 2,
      "400": 2,
      "1026": 2,
      "meta_random_seed": 2,
      "4200": 2,
      "1923": 2,
      "random.seed(28)": 2,
      "142": 2,
      "2048": 2,
      "70": 2,
      "fold": 2,
      "cfg.training.seed": 2,
      "2411": 2,
      "np.random.RandomState(0)": 2,
      "93": 2,
      "224": 2,
      "31415": 2,
      "1220": 2,
      "split_seed": 2,
      "conf['random_state'] + fold * 10": 2,
      "1228": 2,
      "126": 2,
      "65": 2,
      "rng": 2,
      "451816": 2,
      "140001742": 2,
      "random_state_split": 2,
      "223": 2,
      "nr_seed": 2,
      "univ_seed": 2,
      "817": 2,
      "i * 5": 2,
      "369": 2,
      "rdm_state": 2,
      "333": 2,
      "1340": 2,
      "300": 2,
      "41020": 2,
      "1029": 2,
      "59": 2,
      "102": 2,
      "888": 2,
      "74": 2,
      "2121": 2,
      "RE": 2,
      "98": 2,
      "66": 2,
      "96": 2,
      "113": 2,
      "CFG['RANDOM_STATE']": 2,
      "seed(2017)": 2,
      "2666": 2,
      "162": 2,
      "315": 2,
      "20181224": 2,
      "seed_value": 2,
      "576": 2,
      "feed": 2,
      "9999": 2,
      "76": 2,
      "343": 2,
      "1030": 2,
      "20210503": 2,
      "302": 2,
      "42069": 2,
      "98987": 2,
      "133": 2,
      "104": 2,
      "2525": 2,
      "seed_val": 2,
      "state": 2,
      "403": 2,
      "randomstate(x, y)": 2,
      "220": 2,
      "500 * i + i": 2,
      "Config.RANDOM_STATE": 2,
      "137": 2,
      "cfg.seed": 2,
      "1040941203": 2,
      "random_number": 2,
      "randomSeed": 1,
      "randint(1, 100)": 1,
      "__seed": 1,
      "1017": 1,
      "1234123": 1,
      "mySeed": 1,
      "246": 1,
      "79": 1,
      "72": 1,
      "114": 1,
      "118": 1,
      "171": 1,
      "randnum": 1,
      "73": 1,
      "randomstate": 1,
      "1397": 1,
      "2334": 1,
      "1234126": 1,
      "143289": 1,
      "143234": 1,
      "199": 1,
      "1031": 1,
      "1121218": 1,
      "157": 1,
      "1210": 1,
      "my_params.seed": 1,
      "5468": 1,
      "1234565": 1,
      "107": 1,
      "1015": 1,
      "500": 1,
      "31429": 1,
      "411": 1,
      "54321": 1,
      "i * 42": 1,
      "i * 314": 1,
      "some_ramdom_state": 1,
      "False": 1,
      "6969": 1,
      "2103": 1,
      "config['seed']": 1,
      "425": 1,
      "6122018": 1,
      "573": 1,
      "CTL.random_state": 1,
      "1848": 1,
      "seed + 1": 1,
      "99999": 1,
      "43 * i": 1,
      "self.config.SEED": 1,
      "2078": 1,
      "200321": 1,
      "1729": 1,
      "619": 1,
      "random.seed(SEED)": 1,
      "168": 1,
      "6894": 1,
      "20180301": 1,
      "np.random": 1,
      "2015195017": 1,
      "235": 1,
      "i + rand_st": 1,
      "random": 1,
      "10000": 1,
      "20190425": 1,
      "20190501": 1,
      "random.seed(seed)": 1,
      "209321206 + 73": 1,
      "826": 1,
      "114514": 1,
      "159": 1,
      "SEED_VAL": 1,
      "2006": 1,
      "154": 1,
      "86": 1,
      "355": 1,
      "RAND_SEED": 1,
      "33424": 1,
      "params['seed']": 1,
      "base_seed": 1,
      "376": 1,
      "329": 1,
      "705023": 1,
      "597": 1,
      "C * 100": 1,
      "177013": 1,
      "324": 1,
      "912": 1,
      "182": 1,
      "42367": 1,
      "1905": 1,
      "103": 1,
      "seeds[split]": 1,
      "131": 1,
      "7777": 1,
      "1999": 1,
      "80745": 1,
      "201": 1,
      "CFG['seed']": 1,
      "245": 1,
      "i + 6": 1,
      "rand": 1,
      "457": 1,
      "893": 1,
      "947": 1,
      "365": 1,
      "1734": 1,
      "8012": 1,
      "125": 1,
      "3323": 1,
      "5675": 1,
      "6311": 1,
      "120": 1,
      "42421": 1,
      "conf['random_state']": 1,
      "42 + fold_n": 1,
      "1236": 1,
      "654": 1,
      "211": 1,
      "self.settings.RANDOM_STATE": 1,
      "148": 1,
      "4305": 1,
      "random.randint(30, 45)": 1,
      "568": 1,
      "np.random.randint(0, 1000)": 1,
      "1999111000": 1,
      "198": 1,
      "1421": 1,
      "np.random.randint(2)": 1,
      "RND": 1,
      "172": 1,
      "465": 1,
      "1326": 1,
      "8080": 1,
      "321": 1,
      "14113": 1,
      "691": 1,
      "340": 1,
      "8675309": 1,
      "PARAMS['RANDOM_SEED']": 1,
      "567": 1,
      "620402": 1,
      "self.__random_state": 1,
      "201901": 1,
      "value": 1,
      "9127": 1,
      "3041975": 1,
      "1023": 1,
      "33 * ii + 112": 1,
      "850": 1,
      "11568": 1,
      "np.random.randint(0, 100000000.0)": 1,
      "890": 1,
      "e": 1,
      "1004": 1,
      "1338": 1,
      "80000": 1,
      "16446054": 1,
      "1526": 1,
      "42 * i": 1,
      "345": 1,
      "241": 1,
      "217": 1,
      "27014": 1
    },
    "sklearn.linear_model._logistic.LogisticRegression.__init__.C": {
      "1.0": 3587,
      "0.1": 277,
      "1": 152,
      "0.02": 110,
      "0.0001": 98,
      "C": 84,
      "4": 72,
      "10": 65,
      "0.05": 42,
      "0.5": 40,
      "0.01": 36,
      "3": 26,
      "2": 23,
      "i": 21,
      "5": 19,
      "100": 18,
      "100000.0": 18,
      "c": 18,
      "0.001": 17,
      "self.C": 15,
      "1000000": 11,
      "10.0": 9,
      "0.123456789": 8,
      "30": 8,
      "trial.suggest_loguniform('C', 0.01, 1)": 8,
      "12.0": 7,
      "0.45": 7,
      "0.03": 7,
      "0.095": 6,
      "3.5": 6,
      "0.003": 6,
      "C_effective": 6,
      "0.2": 6,
      "0.04": 6,
      "0.9": 6,
      "best_C": 6,
      "5.0": 5,
      "0.005": 5,
      "0.6": 5,
      "20": 5,
      "1e-05": 5,
      "4.0": 5,
      "2.6": 5,
      "1000": 5,
      "c_dict[col]": 4,
      "15": 4,
      "2000": 4,
      "all_parameters['C'][j]": 4,
      "30.0": 4,
      "1.5": 4,
      "0.11248300958542848": 4,
      "0.09": 3,
      "0.54321": 3,
      "1000000.0": 3,
      "7": 3,
      "0.0005": 3,
      "0.125": 3,
      "0.4": 3,
      "value": 3,
      "0.25": 3,
      "best_alpha": 3,
      "24.0": 3,
      "0.12": 3,
      "32": 3,
      "2.65": 3,
      "0.06": 3,
      "0.08": 3,
      "6.0": 2,
      "C1": 2,
      "C2": 2,
      "C_REGULARIZER": 2,
      "4.893900918477489": 2,
      "13.0": 2,
      "1.8": 2,
      "0.09858667904100823": 2,
      "3.0": 2,
      "alpha": 2,
      "8": 2,
      "0.035": 2,
      "2200": 2,
      "3000": 2,
      "0.1338": 2,
      "r": 2,
      "1000.0": 2,
      "96": 2,
      "10**9": 2,
      "1e-09": 2,
      "12": 2,
      "params_log['C']": 2,
      "0.7678243129497218": 2,
      "0.085": 2,
      "0.026": 2,
      "0.019": 2,
      "0.11": 2,
      "0.010068250605161195": 2,
      "0.010143399742532085": 2,
      "0.5980679171662785": 2,
      "0.010057756278091795": 2,
      "1500": 2,
      "0.3": 1,
      "INFINITY": 1,
      "trial.suggest_float('C', 1e-10, 10000000000.0, log=True)": 1,
      "0.002": 1,
      "2.4": 1,
      "59.0": 1,
      "result.best_params_['C']": 1,
      "pow(10, c)": 1,
      "10000": 1,
      "100.0": 1,
      "10000000000.0": 1,
      "C[k]": 1,
      "1.2": 1,
      "8.0": 1,
      "0.008": 1,
      "0.09536298444122952": 1,
      "2.02": 1,
      "min_c": 1,
      "2.78": 1,
      "100000": 1,
      "1.78": 1,
      "params[col]": 1,
      "40": 1,
      "50": 1,
      "0.31": 1,
      "grid_search_lr.best_params_['C']": 1,
      "params[label]['C']": 1,
      "0.0004": 1,
      "35": 1,
      "2.0": 1,
      "0.0075": 1,
      "1.9": 1,
      "0.43651583224016655": 1,
      "1.624": 1,
      "result[0]": 1,
      "15.724316694262722": 1,
      "83.79260077891932": 1,
      "clf.best_params_['C']": 1,
      "15.789557894736841": 1,
      "c0": 1,
      "params['C']": 1,
      "0.07536298444122952": 1,
      "model_config['C']": 1,
      "1e+40": 1,
      "params['C_lr']": 1,
      "params['C_lr2']": 1,
      "gridcv.best_params_['C']": 1,
      "54": 1,
      "hyperpars['C']": 1,
      "lcv.C_[0]": 1,
      "1291.54966501": 1,
      "31.579015789473683": 1,
      "0.8": 1,
      "4.5": 1,
      "0.0036": 1,
      "0.08858667904100823": 1,
      "c_value": 1,
      "cl": 1,
      "c_par": 1,
      "0.17": 1,
      "0.76": 1,
      "C_lr": 1,
      "res.x[1]": 1,
      "0.7": 1,
      "166.81": 1,
      "0.045": 1,
      "0.055": 1,
      "0.065": 1,
      "0.07": 1,
      "0.075": 1,
      "0.105": 1,
      "0.95": 1,
      "0.98": 1,
      "0.99": 1,
      "1.01": 1,
      "1.02": 1,
      "1.05": 1,
      "1.07": 1,
      "1.1": 1,
      "1.25": 1,
      "1.75": 1,
      "2.5": 1,
      "9.0": 1,
      "200": 1,
      "1 / reg": 1,
      "C_best": 1,
      "trial.suggest_uniform('C', 0.1, 1.0)": 1,
      "0.21428": 1,
      "28.072": 1,
      "0.15": 1,
      "6": 1,
      "0.027825594022071243": 1,
      "50.0": 1,
      "500": 1,
      "0.615848211066026": 1,
      "0.6237": 1,
      "0.015550647561600984": 1,
      "grid_search.best_params_.get('C')": 1
    },
    "sklearn.linear_model._logistic.LogisticRegression.__init__.solver": {
      "'lbfgs'": 4243,
      "'liblinear'": 456,
      "'sag'": 192,
      "'saga'": 139,
      "'newton-cg'": 76,
      "'warn'": 9,
      "all_parameters['solver'][j]": 4,
      "solver": 3,
      "params_log['solver']": 2,
      "self.solver": 1,
      "best_solver": 1,
      "model_config['solver']": 1,
      "gridcv.best_params_['solver']": 1,
      "trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'sag'])": 1
    },
    "sklearn.linear_model._logistic.LogisticRegression.__init__.class_weight": {
      "None": 4701,
      "'balanced'": 350,
      "class_weight": 13,
      "{1: 0.46, 0: 1.32}": 9,
      "{1: 0.6, 0: 0.4}": 5,
      "all_parameters['class_weight'][j]": 4,
      "'auto'": 4,
      "{0: 0.4, 1: 0.6}": 3,
      "{1: 0.472008228977, 0: 1.30905513329}": 3,
      "{0: 0.1, 1: 0.9}": 2,
      "{0: 0.85}": 2,
      "{0: y_train.sum(), 1: len(y_train) - y_train.sum()}": 2,
      "c_weight": 2,
      "{0: 0.0619, 1: 0.9381}": 2,
      "{0: 0.9, 1: 0.1}": 2,
      "set_class_weight": 1,
      "{0: 0.07, 1: 1}": 1,
      "{0: 1, 1: 1.5}": 1,
      "{0: 1, 1: 99}": 1,
      "{0: 1.5, 1: 1}": 1,
      "{0: 2.6, 1: 1}": 1,
      "{0: 2.2, 1: 1}": 1,
      "{0: 1, 1: 15}": 1,
      "class_weights": 1,
      "{1: 0.5, 0: 0.5}": 1,
      "{1: 0.8, 0: 0.2}": 1,
      "{0: 1, 1: 1.4}": 1,
      "c_weights": 1,
      "{0: 1.1, 1: 1}": 1,
      "{0: 1.05, 1: 1}": 1,
      "y.mean()": 1,
      "hyperpars['class_weight']": 1,
      "{1: 8, 0: 1}": 1,
      "{0: 0.2, 1: 0.8}": 1,
      "{0: 0.3, 1: 0.7}": 1,
      "{0: 0.8, 1: 1}": 1,
      "{1: 0.4, 0: 1.34}": 1,
      "trial.suggest_categorical('class_weight', ['balanced', None])": 1,
      "{1: 0.4, 0: 0.6}": 1,
      "grid_search.best_params_.get('class_weight')": 1
    },
    "sklearn.linear_model._logistic.LogisticRegression.fit.X": {
      "X_train": 874,
      "X": 509,
      "x_train": 233,
      "train": 131,
      "x_nb": 70,
      "train_features": 61,
      "Xtrain": 53,
      "train_x": 47,
      "train_X": 44,
      "x": 28,
      "train_vectors": 28,
      "X_train[::subsample, :]": 27,
      "train_x_bf": 26,
      "X_train_scaled": 25,
      "xtrain_tfv": 23,
      "xtrain_ctv": 19,
      "train_data": 19,
      "X_train_cv": 19,
      "train_vgg_bf": 14,
      "X_dtm": 14,
      "X_tr": 13,
      "train3[train_index, :]": 12,
      "train_i_bf": 12,
      "features": 12,
      "feattr[:, ::subsample].T": 10,
      "xtrain": 10,
      "X_train[::downsample, :]": 10,
      "X_resampled": 10,
      "X_train_vec": 10,
      "X_train_std": 10,
      "X_train_tfidf": 9,
      "xtr": 9,
      "train_tfidf": 9,
      "train2.loc[train_index][cols]": 9,
      "X_scaled": 8,
      "train_vector": 8,
      "X_train_vectorized": 8,
      "df_train": 7,
      "train_word_features": 7,
      "all_idf[trn_idx]": 7,
      "std_data": 6,
      "tr[train_index]": 6,
      "X1": 6,
      "X_train2": 6,
      "train_log": 6,
      "data_train_fn": 6,
      "x_train_count": 5,
      "X_train[::subsample2, :]": 5,
      "x_tr": 5,
      "xTrain": 5,
      "new_ld[features]": 5,
      "train1": 5,
      "trainX": 5,
      "train_data_features": 5,
      "X_scaled_ranks": 5,
      "X_scaled_experience": 5,
      "X_scaled_stats": 5,
      "x_train_tf_idf_word": 4,
      "train_feats": 4,
      "X_train_word_features": 4,
      "X_train_dtm": 4,
      "train_encoded": 4,
      "bow_train": 4,
      "X_train1": 4,
      "X_Train": 4,
      "X2": 4,
      "train_df": 4,
      "X_train_vect": 4,
      "train_set": 4,
      "x0.reshape(-1, 1)": 4,
      "x_train.T": 4,
      "X_train_reduced": 4,
      "train2": 4,
      "X_train_tfid": 4,
      "dataset_blend_train": 4,
      "x_train_final": 4,
      "tfidf_train": 4,
      "train_": 3,
      "train_tf": 3,
      "X_train_res": 3,
      "X_train_word2vec": 3,
      "train_merge4": 3,
      "X[:nrow_train]": 3,
      "Xtr": 3,
      "times": 3,
      "train[X]": 3,
      "X_SMOTE": 3,
      "X_train.todense()": 3,
      "X_train_pca": 3,
      "pca_X_train": 3,
      "train_sample[feature][mask].cat.codes.values.reshape(-1, 1)": 3,
      "train_sample[feature][mask].values.reshape(-1, 1)": 3,
      "train.loc[train_index].iloc[:, :-1]": 3,
      "train.loc[train_index][cols]": 3,
      "scaled_X_train": 3,
      "X_train_2": 3,
      "training[features]": 3,
      "train[features]": 3,
      "preds_trn": 3,
      "X_train_TF_IDF_vectorize": 3,
      "mean_embedded": 3,
      "x[train_index]": 3,
      "train2[col].values.reshape(-1, 1)": 3,
      "X_train_norm": 3,
      "x_train_train": 3,
      "features_train": 3,
      "lootrain[['group_1', 'char_2', 'char_38']]": 3,
      "train[labels]": 2,
      "X_trn": 2,
      "x_train1": 2,
      "X_fs": 2,
      "pd.DataFrame(encoded_sex)": 2,
      "trainFeatures_factors": 2,
      "train_df_vectors": 2,
      "Xr": 2,
      "X_train_logit": 2,
      "x_train_tfidf_vec": 2,
      "bow_train2": 2,
      "final_bow": 2,
      "df_news.loc[train_index]": 2,
      "xList_d": 2,
      "train_scaled": 2,
      "X_sc": 2,
      "X_over": 2,
      "input_data[input_vars]": 2,
      "features_nd[0:len(train_data_df)]": 2,
      "dtrain": 2,
      "train[idx_tr][col]": 2,
      "normalized_train_X": 2,
      "x_train_res": 2,
      "X_d": 2,
      "Xw_train": 2,
      "train[variables]": 2,
      "inception_train_bottleneck_4": 2,
      "xception_train_bottleneck_4": 2,
      "X_oh": 2,
      "X_train[tr_idx]": 2,
      "train_x2": 2,
      "new_X": 2,
      "tv_X_train": 2,
      "x_train_pca": 2,
      "enc_tr": 2,
      "scaled_train_result_x": 2,
      "stack_train": 2,
      "x_train_emb": 2,
      "train_bag": 2,
      "X_train_rf": 2,
      "headlines_vectored": 2,
      "train_df[features]": 2,
      "X_train_vtreat[used_cols]": 2,
      "X_tn": 2,
      "Xss": 2,
      "X_train_trans": 2,
      "X_tfidf": 2,
      "rf_enc.transform(rf.apply(X_train_lr))": 2,
      "train3p[train_index, :]": 2,
      "scaler.fit_transform(X_train)": 2,
      "X2_train": 2,
      "X_dev": 2,
      "X_train_reg": 2,
      "train_data_feature": 2,
      "selected_x_train": 2,
      "X_scale_train": 2,
      "X_train_counts": 2,
      "x_training": 2,
      "top_train_data": 2,
      "poly_train": 2,
      "X_train_scale": 2,
      "train_predictions": 2,
      "tfidf_data": 2,
      "X_train_": 2,
      "X[train_index]": 2,
      "X_train_transformed": 2,
      "x_train_vector": 2,
      "x_train_mod": 2,
      "v_X_train": 2,
      "train_.drop(['target', 'id'], axis=1)": 2,
      "final_x_train": 2,
      "X_train_tfv": 2,
      "X_train_ctv": 2,
      "indexed_dates": 2,
      "XTrain": 2,
      "text_train": 2,
      "train2[cols]": 2,
      "V[:10158]": 2,
      "ctrain": 2,
      "data": 2,
      "X_train_DFs[i]": 2,
      "Xt": 2,
      "X_train[columns_n]": 2,
      "X_train_2[columns_n]": 2,
      "X_t": 2,
      "x_train_tf_idf_ngram": 2,
      "x_train_tf_idf_chars": 2,
      "X_train_bow2": 2,
      "X_": 2,
      "X_train_matrix": 2,
      "c2_train": 2,
      "X_p": 2,
      "x_train_L2": 2,
      "text_tfidf": 2,
      "train_df[train_df.group == group_i].signal.values.reshape(-1, 1)": 2,
      "data_tr.loc[index_trn, :].values": 2,
      "X_train_cnt_vect": 2,
      "df[cols[:-1]]": 2,
      "trainDtm": 2,
      "trainDtmSvd": 2,
      "x_train_3": 2,
      "X_trainS": 2,
      "X3": 2,
      "x_train_trans": 2,
      "X_train_negd": 2,
      "xtrain_tfidf": 2,
      "xtrain_cv": 2,
      "df_train[features]": 2,
      "ranked_hold.values": 2,
      "poly_hold.values": 2,
      "ranks_pca_hold.values": 2,
      "wf_hold.values": 2,
      "estimators_probas": 2,
      "train_term_doc": 2,
      "train_gene_var_text": 2,
      "train_X_linear": 2,
      "train_char_features": 2,
      "tfidf['all_train']": 2,
      "df[features]": 2,
      "new_train": 1,
      "dft2": 1,
      "x_train_rfecv": 1,
      "X_trans": 1,
      "normX": 1,
      "x_train.values": 1,
      "train_ohe": 1,
      "t_X": 1,
      "logit(rawprobs)": 1,
      "training_data_matrix": 1,
      "X_train_full": 1,
      "cv_train": 1,
      "td_train": 1,
      "train_vecs_dbow": 1,
      "train_vecs_dmc": 1,
      "train_vecs_dmm": 1,
      "train_vecs_dbow_dmc": 1,
      "train_vecs_dbow_dmm": 1,
      "train_X_sub_sc": 1,
      "X_disc": 1,
      "sentence_to_vec": 1,
      "train_df.iloc[trn_idx][features]": 1,
      "lootrain[['group_1', 'char_2', 'char_36', 'char_38']]": 1,
      "xt": 1,
      "preds": 1,
      "S_train": 1,
      "data_train_model": 1,
      "train_generated.values": 1,
      "x_vector": 1,
      "train_vect1": 1,
      "train_vect2": 1,
      "train_vect3": 1,
      "train_vect4": 1,
      "X_test.todense()": 1,
      "training_features_tfidf": 1,
      "data_train": 1,
      "train_update": 1,
      "detailed": 1,
      "train_feats2": 1,
      "x_train_tf": 1,
      "x1": 1,
      "Blend_X": 1,
      "x_train_preproc": 1,
      "train_x_tfidf_f": 1,
      "X_training": 1,
      "STDTrain_2": 1,
      "temp": 1,
      "X1r": 1,
      "train[['mean', 'count', 'neighbor_iceberg']]": 1,
      "train_or": 1,
      "train_or[:, ci_95]": 1,
      "scaled_train_X": 1,
      "xtrain_v": 1,
      "X_mm": 1,
      "X_res": 1,
      "X_train_press": 1,
      "X_train_normal": 1,
      "X_train_soft": 1,
      "training_data_X": 1,
      "train3": 1,
      "df_train.iloc[:, :-1]": 1,
      "final_feature": 1,
      "x_cv": 1,
      "train.drop('target', axis=1)": 1,
      "td[cols]": 1,
      "train_centroids": 1,
      "train[[i]]": 1,
      "public.loc[train_index].iloc[:, :-1]": 1,
      "public[[i]]": 1,
      "train.iloc[:, 2:]": 1,
      "train.iloc[:, :-1]": 1,
      "app_train_enc_imput_med[train, :]": 1,
      "TrainData": 1,
      "tr[tr_idx]": 1,
      "xs_train": 1,
      "images": 1,
      "X_train[:, :]": 1,
      "X_orig_train": 1,
      "train_digit": 1,
      "OH_train": 1,
      "X_train_con": 1,
      "Stacked": 1,
      "x_train_tfidf": 1,
      "train_rows": 1,
      "train_transaction_df.TransactionAmt": 1,
      "X_train_LBP": 1,
      "X_data": 1,
      "train_sentence_vectors": 1,
      "new_train_encoded": 1,
      "x_traintf": 1,
      "x_traincv": 1,
      "np.array(vectors)": 1,
      "x_train_tfvect": 1,
      "X_train_word": 1,
      "X_train_char": 1,
      "results": 1,
      "ml_data": 1,
      "X_train_vect_TFID": 1,
      "X_train_preprocessed_vectorized": 1,
      "train_probs": 1,
      "X_arr": 1,
      "train_tfid": 1,
      "X_treino": 1,
      "table_tf1": 1,
      "X_tr_full": 1,
      "df1[input]": 1,
      "x_nb_cat": 1,
      "x_selected": 1,
      "df[:len(train)]": 1,
      "df_onehot[:len(train)]": 1,
      "tr_x": 1,
      "xtrain_glove": 1,
      "X_train_woe[used_cols]": 1,
      "X_train_woe[no_high_card_cols]": 1,
      "bag[:nrow_train]": 1,
      "X_train_cv1": 1,
      "train_feature": 1,
      "train_rn_bf": 1,
      "part1": 1,
      "part2": 1,
      "X_train[:3263]": 1,
      "train_stack": 1,
      "xtraintf": 1,
      "train_d": 1,
      "X_train_winsor": 1,
      "grd_enc.transform(grd.apply(X_train_lr)[:, :, 0])": 1,
      "train_band_1": 1,
      "oof_all.values": 1,
      "scaler.fit_transform(X2_train)": 1,
      "df_initial_train": 1,
      "x_cv_train": 1,
      "x_pipe_A": 1,
      "x_pipe_B": 1,
      "x_t": 1,
      "s": 1,
      "X_train_f": 1,
      "tr": 1,
      "training_features": 1,
      "x_train_norm": 1,
      "x_train_lr": 1,
      "train_set[:, :-1]": 1,
      "os_data_X": 1,
      "x_cleaned": 1,
      "np.nan_to_num(df_supervised.values)": 1,
      "train_tfv": 1,
      "x_tr_w2v": 1,
      "train_data1": 1,
      "X.drop('Survived', axis=1)": 1,
      "ftr": 1,
      "X_train_no_id": 1,
      "train['nframes'].values.reshape(-1, 1)": 1,
      "x_train2": 1,
      "subset[['day_of_week_encoded', 'pd_district_encoded', 'x', 'y', 'hour']]": 1,
      "X_train1_imp": 1,
      "X_train2_imp": 1,
      "X_train3_imp": 1,
      "X_train_bert": 1,
      "x_over": 1,
      "np.column_stack([nn_oof_tr, lgb_oof_tr, nb_oof_tr])": 1,
      "X_logreg_train": 1,
      "X_train_new_2": 1,
      "X_train_fold": 1,
      "X_vecs": 1,
      "preprocessed": 1,
      "y_pred": 1,
      "ng_v_X_train": 1,
      "train_vectorized": 1,
      "d_f_train": 1,
      "d_f_train_new": 1,
      "x_train_tf_idf": 1,
      "XX_train": 1,
      "landmark_data.drop('Kin', axis=1)": 1,
      "top250_data.drop('Kin', axis=1)": 1,
      "features_scaled_pca": 1,
      "X_train_scal": 1,
      "X_train_scal_sm": 1,
      "n_x_train": 1,
      "meta_X_train": 1,
      "train_vc": 1,
      "x0": 1,
      "x_res_train": 1,
      "X_trcv": 1,
      "dtm": 1,
      "train_std": 1,
      "train_scaledx": 1,
      "train_logx": 1,
      "trx.values": 1,
      "train_df[columos]": 1,
      "X_vect_train": 1,
      "train[x[:10]]": 1,
      "X_train[id_train]": 1,
      "x_xception_train": 1,
      "x_vgg16_train": 1,
      "x_resnet50_train": 1,
      "projected": 1,
      "X_train_ol": 1,
      "X_ol": 1,
      "train.loc[train_index, selected_genes[lab] + selected_cells[lab] + exog_vars].values": 1,
      "train_xx": 1,
      "X_train_one_hot": 1,
      "logit_x": 1,
      "train2.loc[train_index][ok_cols]": 1,
      "features[:train.shape[0]]": 1,
      "X_train_bow_df": 1,
      "X_corr": 1,
      "X_train[['OWN_CAR_AGE', 'OWN_CAR_AGE_NA']]": 1,
      "df_train_oh.drop(['id', 'target'], axis=1)": 1,
      "df_train_le.drop(['id', 'target'], axis=1)": 1,
      "x_test.T": 1,
      "x_train.sign()": 1,
      "x1_train.sign()": 1,
      "X_train_sc": 1,
      "trainDf[features]": 1,
      "global_features": 1,
      "train.drop('Survived', axis=1)": 1,
      "X[columns_n]": 1,
      "X_2[columns_n]": 1,
      "train2[only_new_cols]": 1,
      "X_tfidf_train": 1,
      "X_train.T[el_df.index].T": 1,
      "X_train0": 1,
      "X_train3": 1,
      "train_d.numpy().reshape((-1, 1))": 1,
      "count_train": 1,
      "train_df[columns]": 1,
      "label_X_train": 1,
      "variables_train": 1,
      "trainVector": 1,
      "X_train_bow1": 1,
      "X_train_bow3": 1,
      "X_train_tfidf1": 1,
      "trainDataframeX": 1,
      "trainDataFrameNewX": 1,
      "Xi[i1]": 1,
      "X_treino_transf.fillna(0)": 1,
      "df": 1,
      "x_train_std": 1,
      "x_train_data": 1,
      "trn_term_doc": 1,
      "x_train_tfv": 1,
      "x_train_ctv": 1,
      "train1.iloc[tr][colu]": 1,
      "new_feature1.iloc[:, :]": 1,
      "new_features": 1,
      "rfe_feature2": 1,
      "rfe_feature3": 1,
      "X_train_glove": 1,
      "vt_count_train": 1,
      "tfidf_vt_train": 1,
      "pca_df[['x', 'y']]": 1,
      "titanic_prepared": 1,
      "X_train_bow": 1,
      "X_train_tfidf4": 1,
      "train_tfidf_lemma": 1,
      "train[features_train]": 1,
      "blend_train": 1,
      "np.array(x_train.head(300000)['open_channels']).reshape(-1, 1)": 1,
      "trainf1_input": 1,
      "x_scaled": 1,
      "X2f": 1,
      "X11": 1,
      "final_titanic": 1,
      "vect.transform(df_train.question_text)": 1,
      "sample_x": 1,
      "X_train_ohe": 1,
      "X_dtm_train": 1,
      "Xdt_train": 1,
      "xTrainStack": 1,
      "train_stand": 1,
      "train.loc[train_idx][cols]": 1,
      "train1.loc[train_idx][cols]": 1,
      "X_train_tf": 1,
      "poly_X": 1,
      "stack.iloc[:, :stack.shape[1] - 1]": 1,
      "train_tfidf_char": 1,
      "train_poly_fea": 1,
      "y_multi_pre": 1,
      "embeddings_train": 1,
      "reduced_data": 1,
      "train_f": 1,
      "feats": 1,
      "cosine_similarity(TRu_[:len(train)], TRvh_.T)": 1,
      "train[:lengte]": 1,
      "totaal[:lengte].drop('target', axis=1)": 1,
      "Xreg": 1,
      "np.array(train_scores).T": 1,
      "lootrain[['group_1', 'char_2', 'char_38']][mask]": 1,
      "lootrain[['group_1', 'char_2', 'char_38']][~mask]": 1,
      "data[:, :-1]": 1,
      "xtrain_stra": 1,
      "stacked_predictions": 1,
      "newX": 1,
      "y_train_thresh.reshape((len(y_train_thresh), 1))": 1,
      "X_labelled": 1,
      "X_train_sparse[t]": 1,
      "X_train1hot_scaled": 1,
      "X_trainlabel_scaled": 1,
      "X_resampled_under": 1,
      "newX_train_stack": 1,
      "train_image_vector": 1,
      "X_train_feature": 1,
      "np.array(xtrain)": 1,
      "x_trainnew": 1,
      "X_OH": 1,
      "x_train_imp": 1,
      "X_train_new": 1,
      "train_features_matrix": 1,
      "x_train_bf": 1,
      "x_train_new": 1,
      "train[tr]": 1,
      "dfx": 1,
      "X_kbest": 1,
      "ensemble": 1,
      "test_train": 1,
      "df_train[predictors]": 1,
      "dtm_train": 1,
      "ntrain": 1,
      "Xs_train": 1,
      "X_lr_scaled": 1,
      "tfifd_X": 1,
      "unmissed.drop('survived', axis=1)": 1,
      "unmissed.drop(['survived', 'Q', 'S'], axis=1)": 1,
      "with_alone.drop('survived', axis=1)": 1,
      "unmissed[['class', 'sex', 'age']]": 1,
      "pc_data": 1,
      "pca_with_unmissed": 1,
      "famsize_with_unmissed": 1,
      "X.drop(['survived'], axis=1)": 1,
      "X_val": 1,
      "vector_final": 1,
      "X4": 1,
      "X5": 1,
      "X1_v": 1,
      "X2_v": 1,
      "X_2": 1,
      "train_Xs": 1,
      "X[:5500]": 1,
      "x_train_scale": 1,
      "X.drop(columns=['Ticket_alpha', 'Ticket_num', 'Family_members'])": 1,
      "xtrain_cntv": 1,
      "train_embeddings": 1,
      "X_train_rfe": 1,
      "train[x_cols]": 1,
      "X_train_st": 1,
      "xtrain_svd": 1,
      "np.column_stack((nb_pl.predict_proba(validation_stack), lg_pl.predict_proba(validation_stack), svc_pl.decision_function(validation_stack)))": 1,
      "np.column_stack((nb_pl.predict_proba(data.loc['validation']), lg_pl.predict_proba(data.loc['validation']), svc_pl.decision_function(data.loc['validation'])))": 1,
      "my_transform(train_data.selected_text[:10000])": 1,
      "X_features": 1,
      "x_transform": 1,
      "train_text": 1,
      "text_bow_tr": 1,
      "trainx": 1,
      "train_set['X']": 1,
      "train_array": 1,
      "games[col].fillna(-1)": 1,
      "xtrain_tf": 1,
      "df_train.loc[train_index][cols]": 1,
      "xtrain_tv": 1,
      "xtrain_features": 1,
      "X_train_1": 1,
      "train_stck[train_index]": 1,
      "bow": 1,
      "x_train_svd": 1,
      "kw_tr": 1,
      "concat_tr": 1,
      "lr_train": 1,
      "X_train_roc": 1,
      "mfeat": 1,
      "vectorizer.transform(X_train)": 1,
      "recursive_X_train": 1,
      "stackedX": 1,
      "Xtrain_pca": 1,
      "le": 1,
      "tmp.drop('isFraud', axis=1)": 1,
      "tfidf": 1,
      "TRAIN[ind_train]": 1,
      "X1_train": 1,
      "variables": 1,
      "X_train_lem": 1,
      "train[columns]": 1,
      "featurized_positive_X": 1,
      "featurized_negative_X": 1,
      "fitted_data1": 1,
      "X_smote": 1,
      "train[X_cols]": 1,
      "vect_train": 1,
      "trainon_signals": 1,
      "train_feature_matrics": 1,
      "X_train.iloc[train]": 1,
      "df_X": 1,
      "moa_train_df_all[input_cols]": 1,
      "X_scaled[feature_columns]": 1,
      "oof_preds.loc[train_index]": 1,
      "encoded_train[train]": 1,
      "X_gtrain_scaled": 1,
      "X_trains": 1,
      "X_trains_b": 1,
      "tra_df": 1,
      "X_TREINO": 1,
      "Xtrain[70001:]": 1,
      "log_encs": 1,
      "train_feat": 1,
      "grp_train[f_features]": 1,
      "train_X_scaler": 1,
      "x_train.to_list()": 1,
      "x_localtrain_scaled": 1,
      "X_train_augmented": 1,
      "X_train_stacking": 1,
      "dev_bow": 1,
      "titanic[predictors]": 1,
      "X_important_features": 1,
      "transformed_training_matrix": 1,
      "x_train_1": 1,
      "x_train_2": 1,
      "X_train_trainsplit": 1
    },
    "sklearn.linear_model._logistic.LogisticRegression.fit.y": {
      "y_train": 1219,
      "y": 715,
      "Y_train": 124,
      "train_y": 116,
      "train_labels": 80,
      "ytrain": 66,
      "train_target": 65,
      "(ytr * range(NUM_CLASSES)).sum(axis=1)": 52,
      "target": 47,
      "y_train[::subsample]": 27,
      "train['target']": 25,
      "ytr": 25,
      "Y": 24,
      "train2.loc[train_index]['target']": 22,
      "y_train_cv": 17,
      "y_tr": 16,
      "y_train.values.ravel()": 15,
      "labels": 14,
      "train_df['target']": 13,
      "labels[i, ::subsample]": 10,
      "y[::downsample, i]": 10,
      "y_resampled": 10,
      "train_results": 10,
      "train_label": 9,
      "train[j]": 8,
      "target[trn_idx]": 8,
      "y_hold.values.ravel()": 8,
      "y_train2": 7,
      "train['target'][train_index]": 7,
      "train_Y": 7,
      "yTrain": 7,
      "train_outcome": 7,
      "y_train[j]": 6,
      "df_train['target']": 6,
      "train_sample['HasDetections'][mask]": 6,
      "train.loc[train_index]['target']": 6,
      "y_train_2": 6,
      "unmissed['survived']": 6,
      "y_train1": 5,
      "y_train_res": 5,
      "y_train[::subsample2]": 5,
      "Ytrain": 5,
      "new_ld['target']": 5,
      "y1": 5,
      "y0": 5,
      "y[train_index]": 5,
      "titanic_train['Survived']": 4,
      "(y_train * range(num_classes)).sum(axis=1)": 4,
      "label": 4,
      "target2": 4,
      "train.iloc[:, 1]": 4,
      "y2": 4,
      "normY": 3,
      "y_train_word2vec": 3,
      "train[y]": 3,
      "y_SMOTE": 3,
      "train['outcome']": 3,
      "Y_Train": 3,
      "y_training": 3,
      "train[idx_tr]['target']": 3,
      "train['sentiment']": 3,
      "TARGET": 3,
      "train_targets": 3,
      "train.target": 3,
      "y_train.ravel()": 3,
      "trainy": 3,
      "y_train_lr": 3,
      "train_new[j]": 3,
      "trainY": 3,
      "df_train['Class']": 3,
      "target2.values": 3,
      "labels_train": 3,
      "y_train_train": 3,
      "Target": 3,
      "y[col]": 3,
      "y_train[class_name]": 3,
      "y_trn": 2,
      "df.target.values": 2,
      "yr": 2,
      "train[col]": 2,
      "bin_target.loc[train_index]": 2,
      "labels_d": 2,
      "y_test": 2,
      "input_data[output_var]": 2,
      "train_data_df.Sentiment": 2,
      "y_train[label]": 2,
      "Y1": 2,
      "yw_train": 2,
      "train['signal']": 2,
      "(y_train * range(16)).sum(axis=1)": 2,
      "Y2": 2,
      "y_train[tr_idx]": 2,
      "train_df[j]": 2,
      "train_targets.iloc[train_id]": 2,
      "train_result_y": 2,
      "Y_train_rf": 2,
      "training['crime']": 2,
      "y_treino": 2,
      "train_df[target]": 2,
      "train[train.kfold != fold_i].target.values": 2,
      "y[:, i]": 2,
      "train2p.loc[train_index]['target']": 2,
      "train['target'].values": 2,
      "y2_train": 2,
      "y_dev": 2,
      "y_t": 2,
      "y_train_reg": 2,
      "y_Train": 2,
      "Y_scale_train": 2,
      "y_train_raw_modf": 2,
      "train_true": 2,
      "y_train3": 2,
      "Y_train_resampled": 2,
      "Y_train_over_sample": 2,
      "y_over": 2,
      "y_val": 2,
      "train['Sentiment']": 2,
      "train_['target'].iloc[:, 0]": 2,
      "sent_train": 2,
      "train2['target']": 2,
      "cy": 2,
      "ref": 2,
      "y_labels.values": 2,
      "Y_train[label]": 2,
      "train_labels[cat]": 2,
      "y_train.T": 2,
      "y_2": 2,
      "np.ravel(train_y)": 2,
      "project_is_approved": 2,
      "train_df[train_df.group == group_i].open_channels.values.reshape(-1, 1)": 2,
      "train.loc[index_trn, 'target']": 2,
      "df[cols[-1]]": 2,
      "y[label]": 2,
      "y1_a": 2,
      "y2_a": 2,
      "y_ref_train": 2,
      "labels[:lengte]": 2,
      "y_train_3": 2,
      "df['target']": 2,
      "df_train[target]": 2,
      "val_y.ravel()": 2,
      "df[target]": 2,
      "y_train_tfidf": 2,
      "y[0]": 2,
      "y[1]": 2,
      "y[2]": 2,
      "y[3]": 2,
      "target_": 1,
      "ytrain1": 1,
      "train['target'].values.reshape((-1, ))": 1,
      "t_Y": 1,
      "df.actual": 1,
      "million1": 1,
      "million2": 1,
      "million3": 1,
      "y_train_full": 1,
      "train_y_sub": 1,
      "y_train[[col]].values.ravel()": 1,
      "all_labels.values": 1,
      "Y_disc": 1,
      "target.values": 1,
      "ytrain.loc[diff1.index]": 1,
      "ytrain.loc[diff2.index]": 1,
      "ytrain.loc[diff3.index]": 1,
      "ytrain.loc[diff4.index]": 1,
      "df1['TARGET']": 1,
      "Y_train['surface']": 1,
      "train_under['target']": 1,
      "y_over.values.ravel()": 1,
      "y_train[bad_comment_cat[i]]": 1,
      "train['is_iceberg']": 1,
      "y_d": 1,
      "y_res": 1,
      "df.target": 1,
      "y_train_press": 1,
      "y_train_normal": 1,
      "y_train_soft": 1,
      "training_data_Y": 1,
      "df_train.iloc[:, -1]": 1,
      "train_data['target']": 1,
      "td['target']": 1,
      "public.loc[train_index]['target']": 1,
      "public['target']": 1,
      "train_labels[train]": 1,
      "TrainLabel": 1,
      "train['target'][tr_idx]": 1,
      "ys_train": 1,
      "y_train[:]": 1,
      "y_orig_train": 1,
      "train2.loc[test_index]['target']": 1,
      "train_cols": 1,
      "quora_train": 1,
      "df_train_y": 1,
      "train_transaction_df.isFraud": 1,
      "y_data": 1,
      "training['Category']": 1,
      "y_traintf": 1,
      "y_traincv": 1,
      "yt.ravel()": 1,
      "y_train_word": 1,
      "y_train_char": 1,
      "X_train['sentiment']": 1,
      "author_labels": 1,
      "y_tr_full": 1,
      "df1[output]": 1,
      "tr_y": 1,
      "y_encoded": 1,
      "train.Sentiment": 1,
      "part1_y": 1,
      "part2_y": 1,
      "y_train[:3263]": 1,
      "ytrain[col]": 1,
      "Y_train_lab": 1,
      "val_set": 1,
      "train_targets[target]": 1,
      "target_initial_train": 1,
      "y_cv_train": 1,
      "y_train_f": 1,
      "tg": 1,
      "df.SeriousDlqin2yrs": 1,
      "train_set[:, -1:]": 1,
      "np.ravel(os_data_y)": 1,
      "supervised_labels": 1,
      "train_target_toxic": 1,
      "train_target_threat": 1,
      "train_labels1": 1,
      "train[toxicity]": 1,
      "y_train_encoded": 1,
      "train['label'].values": 1,
      "labels[c]": 1,
      "data['cuisine']": 1,
      "y_trainp": 1,
      "subset['category_predict']": 1,
      "traindf['target']": 1,
      "y_train_new['surface']": 1,
      "y_train_fold": 1,
      "train['isFraud']": 1,
      "tweets['target']": 1,
      "y_pos": 1,
      "y_neg": 1,
      "train_input.target.values": 1,
      "train['author']": 1,
      "d_f2_train": 1,
      "d_f2_train_new": 1,
      "train_data.is_booking_made": 1,
      "train_data.sentiment": 1,
      "yy_train": 1,
      "landmark_data['Kin'].astype('int')": 1,
      "top250_data['Kin'].astype('int')": 1,
      "y_trainR": 1,
      "c_in_province.values[0]": 1,
      "c_in_country.values[0]": 1,
      "Y_train[category[i]]": 1,
      "y_res_train": 1,
      "y_train_lg": 1,
      "train[category]": 1,
      "train_labels[category]": 1,
      "df['is_duplicate'][0:N1].values": 1,
      "y_train[id_train]": 1,
      "y_xception_train": 1,
      "y_vgg16_train": 1,
      "y_resnet50_train": 1,
      "target_array.values": 1,
      "np.array(Yt)": 1,
      "train.loc[train_index, lab].values": 1,
      "list(train_yy)": 1,
      "event_train_clean['HandStart'].values": 1,
      "event_train_clean['FirstDigitTouch'].values": 1,
      "event_train_clean['BothStartLoadPhase'].values": 1,
      "event_train_clean['LiftOff'].values": 1,
      "event_train_clean['Replace'].values": 1,
      "event_train_clean['BothReleased'].values": 1,
      "logit_y": 1,
      "train[label]": 1,
      "train.Category": 1,
      "df_train_oh['target']": 1,
      "df_train_le['target']": 1,
      "y_test.T": 1,
      "y1_train": 1,
      "trainDf['AdoptionSpeed']": 1,
      "train['Survived']": 1,
      "Yt": 1,
      "Y_train.iloc[:, i]": 1,
      "train_y.numpy()": 1,
      "trn_DV": 1,
      "tra_labels[category]": 1,
      "trainDataframeY": 1,
      "trainDataFrameNewY": 1,
      "y[i1]": 1,
      "y_train_data": 1,
      "train1.iloc[tr][['target']]": 1,
      "y_train_glove": 1,
      "pca_df['target']": 1,
      "Ypos": 1,
      "Yneg": 1,
      "titanic_labels": 1,
      "y_train4": 1,
      "tweet['target']": 1,
      "dataset['target']": 1,
      "train[target_train]": 1,
      "np.array(y_train.open_channels).reshape(-1, 1)": 1,
      "trainf1_target": 1,
      "yf": 1,
      "df_train.target": 1,
      "sample_y": 1,
      "train.binary_target": 1,
      "y_train_": 1,
      "ydt_train": 1,
      "yTrain[col]": 1,
      "tweet_df['target']": 1,
      "list(train_y)": 1,
      "train.loc[train_idx]['target']": 1,
      "train1.loc[train_idx]['target']": 1,
      "compresed_xy[1].reset_index(drop=True)": 1,
      "stack.target": 1,
      "y_n_a": 1,
      "y_n": 1,
      "train['action'].values": 1,
      "Y[i]": 1,
      "train.cuisine": 1,
      "train['toxic'].values": 1,
      "y[mask]": 1,
      "y[~mask]": 1,
      "lootrain['outcome']": 1,
      "data[:, -1]": 1,
      "ytrain_stra": 1,
      "val_y": 1,
      "y_y_thresh.reshape((len(y_y_thresh), 1))": 1,
      "y_labelled": 1,
      "y_train[t]": 1,
      "y_resampled_under": 1,
      "newy_stack": 1,
      "np.array(ytrain)": 1,
      "y_train_imp": 1,
      "y_train_new": 1,
      "train_data_labels": 1,
      "train_target_result": 1,
      "one_hot_to_dense(y_train)": 1,
      "target[tr]": 1,
      "np.array(Y_d).ravel()": 1,
      "truth": 1,
      "with_alone['survived']": 1,
      "X['survived']": 1,
      "train.y": 1,
      "y1.ravel()": 1,
      "y2.ravel()": 1,
      "y3.ravel()": 1,
      "y4.ravel()": 1,
      "y5": 1,
      "y[:5500]": 1,
      "train['CategoryEncoded']": 1,
      "y_train_st": 1,
      "validation_stack['Sentiment']": 1,
      "data.loc['validation']['Sentiment']": 1,
      "train_data.sentiment.values[:10000]": 1,
      "(Y_train * range(120)).sum(axis=1)": 1,
      "target['surface']": 1,
      "datatrain['target']": 1,
      "train_data['sentiment']": 1,
      "train_data['Sentiment']": 1,
      "YTrain": 1,
      "train_set['y']": 1,
      "games['Pred']": 1,
      "train[i].values": 1,
      "df_train.loc[train_index]['isFraud']": 1,
      "y_train.reshape(y_train.shape[0])": 1,
      "train_text.target": 1,
      "y[:200000]": 1,
      "y_train_roc": 1,
      "survived": 1,
      "labls": 1,
      "inputy": 1,
      "Y3": 1,
      "tmp.isFraud": 1,
      "target[ind_train]": 1,
      "Y1_train": 1,
      "Y2_train": 1,
      "train_data.loc[:, 'target']": 1,
      "target_train": 1,
      "featurized_positive_Y": 1,
      "featurized_negative_Y": 1,
      "y_train_vect": 1,
      "target_y": 1,
      "y_smote": 1,
      "y_cols": 1,
      "Y_train[:, i]": 1,
      "vect_y": 1,
      "trainon_labels[[label]].values.ravel()": 1,
      "y_train.iloc[train]": 1,
      "df_Y": 1,
      "moa_train_df_all[moa_target]": 1,
      "train_df[target_column]": 1,
      "train.loc[train_index, 'target']": 1,
      "raw_train.target[train]": 1,
      "np.ravel(Ytr)": 1,
      "train_['sentiment']": 1,
      "y_trains": 1,
      "y_trains_b": 1,
      "bin_target": 1,
      "Y_TREINO": 1,
      "y[70001:]": 1,
      "error": 1,
      "y_t.iloc[:, i]": 1,
      "y[c]": 1,
      "grp_train[f_target]": 1,
      "train_y_np": 1,
      "y_localtrain": 1,
      "y_train_stacking": 1,
      "dev_labels": 1,
      "titanic['Survived']": 1,
      "y_train_1": 1,
      "Y_train_split": 1
    },
    "sklearn.linear_model._logistic.LogisticRegression.predict_proba.X": {
      "X_test": 291,
      "test": 138,
      "x_test": 60,
      "X_val": 50,
      "Xtest": 50,
      "X_train": 49,
      "test_x.multiply(r)": 49,
      "test_features": 38,
      "X_valid": 29,
      "valid_x_bf": 26,
      "X_train_scaled": 23,
      "xvalid_tfv": 22,
      "x_train": 20,
      "xvalid_ctv": 19,
      "test_x": 19,
      "X": 18,
      "x.multiply(self._r)": 15,
      "test_X": 15,
      "X_test_scaled": 15,
      "test3": 14,
      "valid_vgg_bf": 14,
      "xvl": 13,
      "test_X_dtm": 13,
      "train3[test_index, :]": 12,
      "x_val": 12,
      "valid_i_bf": 12,
      "V": 12,
      "X_test1[idx]": 12,
      "tmp": 12,
      "XT": 12,
      "val_features": 12,
      "X_train_cv": 11,
      "X_valid_cv": 11,
      "featte.T": 10,
      "X_test2": 10,
      "train2.loc[test_index][cols]": 10,
      "X_test[:seperators[0], :]": 10,
      "X_test[seperators[0]:seperators[1], :]": 10,
      "X_test[seperators[1]:, :]": 10,
      "x_test_32": 10,
      "valid_x": 9,
      "train": 9,
      "df_test": 9,
      "test2[cols]": 9,
      "test_X2": 8,
      "X_resampled": 8,
      "to_test": 8,
      "te": 7,
      "test_df": 7,
      "X1": 7,
      "all_idf[val_idx]": 7,
      "tr[test_index, :]": 6,
      "x_valid": 6,
      "train[features]": 6,
      "test_data": 6,
      "test1_vec": 6,
      "xtest": 5,
      "test_word_features": 5,
      "X_te": 5,
      "X_test_dtm": 5,
      "test[features]": 5,
      "test_ohe": 5,
      "x_train2": 5,
      "preds_val": 5,
      "df_test[features]": 5,
      "test_": 4,
      "test_feats": 4,
      "Xt": 4,
      "df_news.loc[test_index]": 4,
      "features": 4,
      "test_text_features_tf": 4,
      "test_inp": 4,
      "x1.reshape(-1, 1)": 4,
      "np.array(prfull)[:, ii].reshape(-1, 1)": 4,
      "features.as_matrix()": 4,
      "features_train.as_matrix()": 4,
      "features_test.as_matrix()": 4,
      "dataset_blend_test": 4,
      "new_test": 3,
      "X_fs_eval": 3,
      "X_eval": 3,
      "X[nrow_train:]": 3,
      "X[:nrow_train]": 3,
      "times": 3,
      "testtimes": 3,
      "X_for_predict": 3,
      "train_sample[feature][mask].cat.codes.values.reshape(-1, 1)": 3,
      "train_sample[feature][mask].values.reshape(-1, 1)": 3,
      "test_log": 3,
      "train.loc[test_index].iloc[:, :-1]": 3,
      "train.loc[test_index][cols]": 3,
      "val_X": 3,
      "test1": 3,
      "validation[features]": 3,
      "new_X": 3,
      "test_stack": 3,
      "x_tt_new[:, tar].reshape(-1, 1)": 3,
      "testt": 3,
      "X_test_TF_IDF_vectorize": 3,
      "mean_embedded_test": 3,
      "valid_X": 3,
      "df_val[features]": 3,
      "lootest[['group_1', 'char_2', 'char_38']]": 3,
      "X4_test": 3,
      "test[labels]": 2,
      "X_tst": 2,
      "pd.DataFrame(encoded_sex)": 2,
      "X_other": 2,
      "test_df[FEATURES].fillna(0.0).values": 2,
      "Xte": 2,
      "X_test_logit": 2,
      "x_test_tfidf_vec": 2,
      "XTest": 2,
      "X_test_sc": 2,
      "x1": 2,
      "test[idx_te][col]": 2,
      "Y_test": 2,
      "X_train_pca": 2,
      "validation_features": 2,
      "validation": 2,
      "Xtrain": 2,
      "X_oh": 2,
      "test_oh": 2,
      "public.iloc[:, :-1]": 2,
      "private.iloc[:, :-1]": 2,
      "TestData": 2,
      "X_train[val_idx]": 2,
      "test_x2": 2,
      "xTest": 2,
      "enc_val": 2,
      "test_encoded": 2,
      "scaled_train_result_x": 2,
      "scaled_test_result_x": 2,
      "Final": 2,
      "test_x_nb_cat": 2,
      "testX": 2,
      "xtrain_tfv": 2,
      "xtest_tfv": 2,
      "train3[test_index3, :]": 2,
      "X_test_reg": 2,
      "X_train_reg": 2,
      "X_Val": 2,
      "data_submit": 2,
      "final_x_test": 2,
      "X_test_tfv": 2,
      "X_test_ctv": 2,
      "np.c_[xx.ravel(), yy.ravel(), xx.ravel() * yy.ravel()]": 2,
      "val[cols]": 2,
      "test.iloc[:, 1:].values": 2,
      "test[['answered_correctly_user', 'answered_correctly_content']]": 2,
      "X_test_p": 2,
      "X_cv": 2,
      "val_x.multiply(r)": 2,
      "data_tr.drop(labels=index_trn, axis=0).values": 2,
      "data_ts.values": 2,
      "features_sub.as_matrix()": 2,
      "x_train_valid": 2,
      "X_pyang1": 2,
      "X_pyang2": 2,
      "test_tfidf": 2,
      "y_multi_pre": 2,
      "testDtm": 2,
      "trainDtm": 2,
      "testDtmSvd": 2,
      "trainDtmSvd": 2,
      "newX_test_stack": 2,
      "test_image_vector": 2,
      "X_test_tfidf": 2,
      "ensemble": 2,
      "X2": 2,
      "X3": 2,
      "X4": 2,
      "X5": 2,
      "lootrain[['group_1', 'char_2', 'char_38']]": 2,
      "X_train_norm": 2,
      "X_valid_norm": 2,
      "X_test_norm": 2,
      "ranked_hold.values": 2,
      "poly_hold.values": 2,
      "ranks_pca_hold.values": 2,
      "ranks_pca_test.values": 2,
      "wf_hold.values": 2,
      "estimators_probas": 2,
      "test_probas": 2,
      "test_EB7_ns": 2,
      "test_EB4_ns": 2,
      "train_gene_var_text": 2,
      "test_gene_var_text": 2,
      "x_train_final_submission": 2,
      "x_s": 2,
      "test_char_features": 2,
      "test_transaction_new": 1,
      "dfte2": 1,
      "test_matrix.multiply(r)": 1,
      "test_t": 1,
      "subj_cv.transform(df.Tokens)": 1,
      "review_cv.transform(df.Tokens)": 1,
      "subj_cv.transform(df_test.Tokens)": 1,
      "review_cv.transform(df_test.Tokens)": 1,
      "test_data_to_pred": 1,
      "test_data_to_pred_log_norm": 1,
      "new_submission_data_no_id": 1,
      "X_train_dtm": 1,
      "X_multi_dtm": 1,
      "X_translated_dtm": 1,
      "loading2": 1,
      "test_input": 1,
      "train_x_test": 1,
      "X_disc[n:]": 1,
      "X_disc[:n]": 1,
      "train_df.iloc[val_idx][features]": 1,
      "test_df[features]": 1,
      "lootrain[['group_1', 'char_2', 'char_36', 'char_38']]": 1,
      "lootest[['group_1', 'char_2', 'char_36', 'char_38']]": 1,
      "row": 1,
      "xv": 1,
      "predictions": 1,
      "S_train": 1,
      "S_test": 1,
      "vec.transform(['i hate being hateful']).multiply(r)": 1,
      "test_df.iloc[:, 1:]": 1,
      "probe": 1,
      "train_data.drop(['id', 'target'], axis=1)": 1,
      "test_data.drop(['id'], axis=1)": 1,
      "detailed": 1,
      "X_Test": 1,
      "xtrain": 1,
      "x2": 1,
      "x_val_preproc": 1,
      "valid_x_tfidf_f": 1,
      "test_x_tfidf_f": 1,
      "LR_train_set": 1,
      "LR_test_set": 1,
      "temp": 1,
      "test[['mean', 'count', 'neighbor_iceberg']]": 1,
      "test_or": 1,
      "test_or[:, ci_95]": 1,
      "X_test_source": 1,
      "xeval": 1,
      "X_test_soft": 1,
      "X_test_normal": 1,
      "X_test_press": 1,
      "val_tfidf": 1,
      "final_feature": 1,
      "final_feature_test": 1,
      "W": 1,
      "test.drop('target', axis=1)": 1,
      "ss[cols]": 1,
      "train[[i]]": 1,
      "public.loc[test_index].iloc[:, :-1]": 1,
      "public[[i]]": 1,
      "app_train_enc_imput_med[holdout, :]": 1,
      "tr[val_idx, :]": 1,
      "train_term_doc1 + train_term_doc2": 1,
      "val_term_doc1 + val_term_doc2": 1,
      "X_testFinal": 1,
      "train_digit": 1,
      "OH_train": 1,
      "OH_test": 1,
      "xt": 1,
      "test_data_filtered": 1,
      "conv_x_val": 1,
      "Stacked": 1,
      "TargetStacked": 1,
      "list(zip(test1, test2))": 1,
      "X_valid_2": 1,
      "test_data[feature_columns]": 1,
      "new_test_encoded": 1,
      "x_t": 1,
      "test_vectors": 1,
      "X_sparsed_test": 1,
      "xv.multiply(r)": 1,
      "x_test.multiply(r)": 1,
      "train_probs": 1,
      "test_probs": 1,
      "X_test_submission": 1,
      "X_test_file_scaled": 1,
      "test_tfid": 1,
      "table_tf2": 1,
      "df_test_2": 1,
      "df_onehot[len(train):]": 1,
      "xtest_glove": 1,
      "train_df[features]": 1,
      "Xe1": 1,
      "picture": 1,
      "bag[nrow_train:]": 1,
      "bag[:nrow_train]": 1,
      "valid_rn_bf": 1,
      "part1": 1,
      "xvalidtf": 1,
      "xtraintf": 1,
      "dtest": 1,
      "test_d": 1,
      "rf_enc.transform(rf.apply(X_val))": 1,
      "grd_enc.transform(grd.apply(X_val)[:, :, 0])": 1,
      "rf_enc.transform(rf.apply(X_test))": 1,
      "vectorizer.transform(clean_text(test.comment_text))": 1,
      "test_rows": 1,
      "test_band_1": 1,
      "X_val1": 1,
      "preds_all.values": 1,
      "oof_all": 1,
      "test[variables]": 1,
      "val_data": 1,
      "x_cv_train": 1,
      "x_cv_test": 1,
      "opt_pipe_A.transform(df_test.iloc[:, 1:-1])": 1,
      "opt_pipe_B.transform(df_test.iloc[:, 1:-1])": 1,
      "X[:seperators[0], :]": 1,
      "array_myself.values.reshape(1, -1)": 1,
      "s": 1,
      "X_test_f": 1,
      "x_test_lr": 1,
      "X_scale_test": 1,
      "sentence_test_tfidf": 1,
      "np.nan_to_num(df_predict.values)": 1,
      "valid_tfv": 1,
      "x_training": 1,
      "x_validation": 1,
      "train_predictions": 1,
      "X_test_no_id": 1,
      "test.drop(columns=['ID_code'])": 1,
      "test.values": 1,
      "test_df[['answered_correctly_user', 'explanation_mean_user', 'quest_pct', 'avg_questions_seen', 'prior_question_elapsed_time', 'prior_question_had_explanation_enc', 'part', 'part_1', 'part_2', 'part_3', 'part_4', 'part_5', 'part_6', 'part_7', 'type_of_concept', 'type_of_intention', 'type_of_solving_question', 'type_of_starter', 'part_1_boolean', 'part_2_boolean', 'part_3_boolean', 'part_4_boolean', 'part_5_boolean', 'part_6_boolean', 'part_7_boolean', 'type_of_concept_boolean', 'type_of_intention_boolean', 'type_of_solving_question_boolean', 'type_of_starter_boolean']]": 1,
      "test[['day_of_week_encoded', 'pd_district_encoded', 'x', 'y', 'hour']]": 1,
      "X_test_bert": 1,
      "scaler_x_test": 1,
      "test_tfv": 1,
      "test_ctv": 1,
      "np.column_stack([nn_oof_te, lgb_oof_te, nb_oof_te])": 1,
      "X_logreg_test": 1,
      "X_meta": 1,
      "X_meta_test": 1,
      "test_final1": 1,
      "preprocessed_submission": 1,
      "sub_X2": 1,
      "y_train2": 1,
      "yt_test2": 1,
      "y2_test2": 1,
      "x_train_stage2_sub": 1,
      "train_x.multiply(r)": 1,
      "rowEntry": 1,
      "rowEntry_t250": 1,
      "features_scaled_pca": 1,
      "val_vec": 1,
      "val_vec2": 1,
      "n_x_test": 1,
      "x1.multiply(r)": 1,
      "xtest.multiply(r)": 1,
      "np.array(df_test)": 1,
      "test_data_scaled": 1,
      "test_scaledx": 1,
      "test_logx": 1,
      "vectorizer.transform(X_valid)": 1,
      "vectorizer.transform(test.clean_review)": 1,
      "test[x[:10]]": 1,
      "test_df.drop('Season', axis=1)": 1,
      "X_train[id_val]": 1,
      "X_test_ol": 1,
      "Xv": 1,
      "test_df[['answered_correctly_user', 'answered_correctly_content']]": 1,
      "train.loc[test_index, selected_genes[lab] + selected_cells[lab] + exog_vars].values": 1,
      "test[selected_genes[lab] + selected_cells[lab] + exog_vars].values": 1,
      "x[test_index]": 1,
      "train2.loc[val_index][ok_cols]": 1,
      "test2[ok_cols]": 1,
      "features[train.shape[0]:]": 1,
      "X_new": 1,
      "X_test[:, high_corr]": 1,
      "X_train[['OWN_CAR_AGE', 'OWN_CAR_AGE_NA']]": 1,
      "X_test[['OWN_CAR_AGE', 'OWN_CAR_AGE_NA']]": 1,
      "df_test_oh.drop(['id', 'target'], axis=1)": 1,
      "df_test_le.drop(['id', 'target'], axis=1)": 1,
      "x_train.sign()": 1,
      "x_val.sign()": 1,
      "x1_train.sign()": 1,
      "x1_val.sign()": 1,
      "train_X": 1,
      "testing.values": 1,
      "test[sigvars.index.tolist()]": 1,
      "X_val[columns_n]": 1,
      "test2[only_new_cols]": 1,
      "test.drop('sig_id', axis=1)": 1,
      "train_df[columns]": 1,
      "x_validate_std": 1,
      "x_test_std": 1,
      "test_term_doc": 1,
      "rfe_test2": 1,
      "rfe_test3": 1,
      "X_test_nb": 1,
      "pca_data": 1,
      "X_val2": 1,
      "blend_test": 1,
      "train_test_comment_text[nrow_train:]": 1,
      "xtest_lr_elif": 1,
      "xtest_lr_perm": 1,
      "X_test_CV": 1,
      "sample_x": 1,
      "sample_val_x": 1,
      "tfidf_vec.transform(test.comment_text)": 1,
      "X_test_": 1,
      "X_dtm_test": 1,
      "xValidStack": 1,
      "xTestStack": 1,
      "train.loc[val_idx][cols]": 1,
      "train1.loc[val_idx][cols]": 1,
      "X_valid_tf": 1,
      "test.iloc[:, 1:]": 1,
      "poly.transform(test.iloc[:, 1:])": 1,
      "logreg_test.iloc[:, 1:]": 1,
      "poly.transform(val_X)": 1,
      "poly.transform(logreg_test.iloc[:, 1:])": 1,
      "test_tfidf_char": 1,
      "train_poly_fea": 1,
      "yvalid_multi_pre": 1,
      "x": 1,
      "train[:lengte]": 1,
      "np.array(test_scores).T": 1,
      "lootrain[['group_1', 'char_2', 'char_38']][~mask]": 1,
      "lootrain[['group_1', 'char_2', 'char_38']][mask]": 1,
      "train_x": 1,
      "td": 1,
      "datay": 1,
      "val_df": 1,
      "xvalid": 1,
      "test[xtrain.columns]": 1,
      "stacked_test_predictions": 1,
      "cs_test_woe": 1,
      "test_select_bin_x": 1,
      "newX_train_stack": 1,
      "X_test_feature": 1,
      "vector_test": 1,
      "X_test_new": 1,
      "test_features_matrix": 1,
      "x_test_bf": 1,
      "x_test_new": 1,
      "xt.multiply(r)": 1,
      "test_dtm": 1,
      "X[train_index]": 1,
      "X[test_index]": 1,
      "ntest": 1,
      "X_valid_scaled": 1,
      "X_test_lr_scaled": 1,
      "x_train_train": 1,
      "X.drop(['survived'], axis=1)": 1,
      "master_test": 1,
      "test[x_cols]": 1,
      "valid_vectorized": 1,
      "test.drop(['id', 'target'], axis=1)": 1,
      "X_test_pca": 1,
      "X_train_rfe": 1,
      "X_test_rfe": 1,
      "X_train_pca_rfe": 1,
      "X_test_pca_rfe": 1,
      "val_set['X']": 1,
      "df_train.loc[test_index][cols]": 1,
      "df_test[cols]": 1,
      "testing": 1,
      "test.drop(bad_features, axis=1)": 1,
      "X_test_lr": 1,
      "scaled_X_test": 1,
      "valid_features": 1,
      "train_stck[test_index, :]": 1,
      "xtr": 1,
      "xval": 1,
      "kw_tr": 1,
      "kw_val": 1,
      "keyword_test": 1,
      "X_train_roc": 1,
      "X_test_roc": 1,
      "recursive_X_test": 1,
      "sub": 1,
      "xdf1": 1,
      "tmp.drop('isFraud', axis=1)": 1,
      "TRAIN[ind_valid]": 1,
      "TEST": 1,
      "X2_test": 1,
      "dt_test": 1,
      "test_df[['answered_correctly_user', 'explanation_mean_user', 'quest_pct', 'avg_question_seen', 'prior_question_elapsed_time', 'prior_question_had_explanation_enc', 'part', 'part_1', 'part_2', 'part_3', 'part_4', 'part_5', 'part_6', 'part_7', 'type_of_concept', 'type_of_intention', 'type_of_solving_question', 'type_of_starter', 'part_1_boolean', 'part_2_boolean', 'part_3_boolean', 'part_4_boolean', 'part_5_boolean', 'part_6_boolean', 'part_7_boolean', 'type_of_concept_boolean', 'type_of_intention_boolean', 'type_of_solving_question_boolean', 'type_of_starter_boolean']]": 1,
      "test[test.columns[1:]].values": 1,
      "x_test_64": 1,
      "train[columns]": 1,
      "[ft_vect]": 1,
      "stack_test": 1,
      "vect_test": 1,
      "Predictions_2014_scaled": 1,
      "Predictions_2015_scaled": 1,
      "Predictions_2016_scaled": 1,
      "Predictions_2017_scaled": 1,
      "X_scaled_ranks": 1,
      "X_scaled_experience": 1,
      "X_scaled_stats": 1,
      "Predictions_ranks_2014_scaled": 1,
      "Predictions_experience_2014_scaled": 1,
      "Predictions_stats_2014_scaled": 1,
      "Predictions_ranks_2015_scaled": 1,
      "Predictions_experience_2015_scaled": 1,
      "Predictions_stats_2015_scaled": 1,
      "Predictions_ranks_2016_scaled": 1,
      "Predictions_experience_2016_scaled": 1,
      "Predictions_stats_2016_scaled": 1,
      "Predictions_ranks_2017_scaled": 1,
      "Predictions_experience_2017_scaled": 1,
      "Predictions_stats_2017_scaled": 1,
      "Predictions_2018_scaled": 1,
      "teston_signals": 1,
      "test_feature_matrics": 1,
      "X_test_all[input_cols]": 1,
      "oof_preds.loc[test_index, :]": 1,
      "sub_preds": 1,
      "encoded_train[valid]": 1,
      "X_19_colley": 1,
      "X_19": 1,
      "X_test_b": 1,
      "X_dev": 1,
      "test_var": 1,
      "Xtrain[70001:]": 1,
      "tfidf['test']": 1,
      "lr.vector_test": 1,
      "[[np.log(n_encs)]]": 1,
      "np.log(encounters).reshape(-1, 1)": 1,
      "np.log(x).reshape(-1, 1)": 1,
      "test_feat": 1,
      "train_feat": 1,
      "grp_test[f_features]": 1,
      "test_X_scaler": 1,
      "x_localval_scaled": 1,
      "x_test_scaled": 1,
      "test_matrix": 1,
      "transformed_testing_matrix": 1,
      "X_train_testsplit": 1
    },
    "sklearn.preprocessing._label.LabelEncoder.fit_transform.y": {
      "shops['city']": 138,
      "labels": 111,
      "X": 103,
      "Y": 96,
      "y": 93,
      "cats['subtype']": 83,
      "FLS['feature']": 71,
      "np.array(features[col].astype(str)).reshape((-1, ))": 64,
      "cats['type']": 62,
      "X['prior_question_had_explanation']": 60,
      "train['target']": 59,
      "target": 56,
      "values": 53,
      "train[col]": 52,
      "df_cell_train.place_id.values": 51,
      "test_df['prior_question_had_explanation']": 51,
      "y_train": 50,
      "train['Country_Region']": 44,
      "train['primary_use']": 43,
      "col": 42,
      "df[col]": 40,
      "df[col].astype(str)": 39,
      "full_train_df['assetCode']": 38,
      "data[feature]": 31,
      "X_Train['State']": 30,
      "X_Train.Country": 29,
      "train['PdDistrict']": 28,
      "X_Test['State']": 28,
      "X_Train_CS.Country": 28,
      "X_Train_CS['State']": 28,
      "all_data.Date": 28,
      "X_Test.Country": 27,
      "X_xTrain.Country": 27,
      "train['Province_State']": 27,
      "c": 27,
      "test['Country_Region']": 26,
      "X_Test_CS.Country": 26,
      "X_Test_CS['State']": 26,
      "X_xTest.Country": 26,
      "validation['prior_question_had_explanation']": 26,
      "test['primary_use']": 25,
      "X_xTrain['State']": 25,
      "df['idhogar']": 25,
      "test[col]": 24,
      "X_xTest['State']": 24,
      "X.astype(str)": 24,
      "X_xTrain_CS.Country": 23,
      "X_xTest_CS.Country": 23,
      "df['label_group']": 22,
      "X_xTrain_CS['State']": 22,
      "X_xTest_CS['State']": 22,
      "train['type'].values": 22,
      "train['Category']": 21,
      "data[col]": 20,
      "shops.city": 20,
      "train.author.values": 20,
      "y_train['surface']": 20,
      "all_data['Country_Region']": 20,
      "all_data['Province_State']": 20,
      "df_panel.continent": 20,
      "df.labels.values": 20,
      "train_df['Country_Region']": 19,
      "stores['air_genre_name']": 19,
      "stores['air_area_name']": 19,
      "tmp_cat": 19,
      "items.name2": 18,
      "items.name3": 18,
      "train.Country_Region": 18,
      "test.Country_Region": 18,
      "X_val['prior_question_had_explanation']": 18,
      "df['primary_use']": 17,
      "data['hol']['day_of_week']": 17,
      "building.primary_use": 17,
      "all_image_types": 17,
      "shops.category": 16,
      "test[i]": 16,
      "train.Province_State": 16,
      "test.Province_State": 16,
      "df[i]": 16,
      "train_y": 16,
      "target['surface']": 15,
      "train_data['Country_Region']": 15,
      "shops['shop_city']": 14,
      "train[i]": 14,
      "X[col]": 14,
      "shops_df['city']": 14,
      "cats.type_code": 13,
      "self.y": 13,
      "data_all[feat]": 13,
      "test['Province_State']": 13,
      "train['meter']": 13,
      "POS_CASH['NAME_CONTRACT_STATUS'].astype(str)": 12,
      "credit_card['NAME_CONTRACT_STATUS'].astype(str)": 12,
      "input_df[feat].fillna('NULL')": 12,
      "not_null": 12,
      "train['cuisine'].values": 12,
      "data[c].values": 12,
      "df[c]": 12,
      "test['meter']": 12,
      "train_df['primary_use']": 11,
      "items_category_df['type']": 11,
      "items_category_df['subtype']": 11,
      "df_train['Country_Region']": 11,
      "items['name_2']": 10,
      "items['name_3']": 10,
      "train_df['target']": 10,
      "y_test": 10,
      "y['surface']": 10,
      "train_data[col]": 10,
      "y_all": 10,
      "df[column]": 10,
      "data['Sex']": 10,
      "shops['shop_category']": 9,
      "cats['type_code']": 9,
      "list(df[cat].values)": 9,
      "test['PdDistrict']": 9,
      "image_bbox_df['class']": 9,
      "df_train['Province_State']": 9,
      "train[col].values": 9,
      "data[c]": 9,
      "train_cleaned_df.cats": 9,
      "list(train[f].values)": 9,
      "categories['sub_category_id']": 9,
      "train.target": 9,
      "train['matchType']": 9,
      "train['air_store_id']": 9,
      "test['Target']": 9,
      "all_df[col]": 9,
      "output[col]": 8,
      "test['Embarked']": 8,
      "train_df['rad_id']": 8,
      "training_data['Country_Region']": 8,
      "X_train[:, 0]": 8,
      "X_test[:, 0]": 8,
      "train_data['Province_State']": 8,
      "train['prior_question_had_explanation']": 8,
      "categories['main_category_id']": 8,
      "test_df['primary_use']": 8,
      "df[feature]": 8,
      "item_categories['type']": 8,
      "item_categories['subtype']": 8,
      "stores['air_area_name'].map(lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' ')) > i else '')": 8,
      "data['label_group']": 8,
      "train[i].astype(str)": 8,
      "test[i].astype(str)": 8,
      "train['Sex']": 8,
      "df_with[col]": 8,
      "df_without[col]": 8,
      "train['Embarked']": 7,
      "train_df['Sex']": 7,
      "train_df['Province_State']": 7,
      "df['Country_Region']": 7,
      "df['Province_State']": 7,
      "df['target']": 7,
      "data[i]": 7,
      "test['Sex']": 7,
      "col.astype(str)": 7,
      "train['Country']": 7,
      "train['Province']": 7,
      "test['matchType']": 7,
      "stores['air_genre_name'].map(lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' ')) > i else '')": 7,
      "data['Embarked']": 7,
      "df_test['Province_State']": 7,
      "train_df['prior_question_had_explanation']": 7,
      "indep_data[:, x]": 7,
      "test_data[:, x]": 7,
      "a": 7,
      "series[series.notnull()]": 7,
      "df.Country_Region.astype(str)": 6,
      "df.Province_State.astype(str)": 6,
      "df.County.astype(str)": 6,
      "df.Target.astype(str)": 6,
      "train['original_language']": 6,
      "train.sex": 6,
      "X_Test.Country_Region": 6,
      "test['Country']": 6,
      "trainData['Type']": 6,
      "dataframe[i]": 6,
      "train['Patient']": 6,
      "X['Target']": 6,
      "test['prior_question_had_explanation']": 6,
      "items['family'].values": 6,
      "stores['city'].values": 6,
      "stores['state'].values": 6,
      "stores['type'].values": 6,
      "df_shops['city']": 6,
      "train_data.iloc[:, 2].values": 6,
      "train_data.iloc[:, 7].values": 6,
      "Y_train": 6,
      "test_data[col]": 6,
      "X_xTrain['County']": 6,
      "X_xTest['County']": 6,
      "train_data.Category": 6,
      "X_train[c]": 6,
      "train.sentiment.append(test.sentiment)": 6,
      "test_df['Sex']": 5,
      "titanic_train['Sex']": 5,
      "data[feat].fillna('-1').astype(str).values": 5,
      "test['original_language']": 5,
      "list(dfmerge[cat].values)": 5,
      "all_label": 5,
      "df_train[i]": 5,
      "full_df[c]": 5,
      "l_cat": 5,
      "y['Category']": 5,
      "train_data['Sex']": 5,
      "X_Test['Province_State']": 5,
      "namesIn": 5,
      "train.anatom_site_general_challenge": 5,
      "df['Sex']": 5,
      "df['Embarked']": 5,
      "train.cuisine": 5,
      "train.type.values": 5,
      "df_train[col]": 5,
      "df[target].values": 5,
      "test_df['Province_State']": 5,
      "trainData['City Group']": 5,
      "testData['Type']": 5,
      "testData['City Group']": 5,
      "X[:, 1]": 5,
      "categories['subtype']": 5,
      "test[column]": 5,
      "train_df['cuisine']": 5,
      "train['type']": 5,
      "sample[x]": 5,
      "train_df.Country_Region": 5,
      "test_df.Country_Region": 5,
      "df_test['Country_Region']": 5,
      "test_features.Country_Region": 5,
      "train[e]": 5,
      "data['id']": 5,
      "data['landmark_id']": 5,
      "df_all[c].values": 5,
      "test_data.iloc[:, 1].values": 5,
      "test_data.iloc[:, 6].values": 5,
      "items['item_category']": 5,
      "items['item_category_name']": 5,
      "x": 5,
      "train[c]": 5,
      "train['Province_State'].fillna('0')": 5,
      "test['Province_State'].fillna('0')": 5,
      "train_df['cp']": 5,
      "df.Target": 5,
      "train['cuisine']": 5,
      "df[f].astype(str)": 5,
      "train_df['category'][:5000]": 4,
      "data[feat].values": 4,
      "data[feat].astype(str).fillna('-1').values": 4,
      "clicks[feature]": 4,
      "df_test[i]": 4,
      "item_categories['category']": 4,
      "data.sentiment_id": 4,
      "df['wm_yr_wk'].values": 4,
      "df['year']": 4,
      "train['OutcomeType']": 4,
      "ytrain": 4,
      "df.Date": 4,
      "building_metadata['primary_use']": 4,
      "X_all[col]": 4,
      "data": 4,
      "X[:, i]": 4,
      "temp[new_feature].values": 4,
      "train_df.cuisine": 4,
      "train.State.astype('str') + ':' + train.Country.astype('str')": 4,
      "data_all['idhogar']": 4,
      "train_df[col]": 4,
      "train_features['cp_type']": 4,
      "df_data[feat]": 4,
      "total_data[col]": 4,
      "df[var]": 4,
      "train.Category": 4,
      "tmp['Embarked']": 4,
      "categories['type']": 4,
      "train['cp_dose']": 4,
      "X.assetCode": 4,
      "data['Target']": 4,
      "df_train.cuisine": 4,
      "df_all[col]": 4,
      "train_Y": 4,
      "X_train_categorical[feature]": 4,
      "data['Title']": 4,
      "train['group']": 4,
      "combine[col]": 4,
      "X_train_new.Country_Region": 4,
      "alldata[c].round(n)": 4,
      "df_train.Country_Region": 4,
      "df_test.Country_Region": 4,
      "df_test[col]": 4,
      "train_clean.continent": 4,
      "data_df[col]": 4,
      "train.ebird_code.values": 4,
      "train_df.Category": 4,
      "test['Type']": 4,
      "X[i]": 4,
      "shops['shop_type']": 4,
      "shop['city']": 4,
      "X['Country_Region']": 4,
      "df_train.Country": 4,
      "temp": 4,
      "train['Target']": 4,
      "df[col].astype('str')": 4,
      "dataset['brand_name']": 4,
      "df['MSZoning']": 4,
      "train['author'].values": 4,
      "train_data['target']": 4,
      "train_data['Target']": 4,
      "dfx['labels']": 4,
      "test_dfx['labels']": 4,
      "w5te_X": 4,
      "train.sentiment": 4,
      "data['Country/Region']": 4,
      "corona_data.iloc[:, 1]": 4,
      "train_raw.Category": 4,
      "train.pop('Category')": 4,
      "data['Sex'].values": 4,
      "data['SmokingStatus'].values": 4,
      "titanic_test['Sex']": 3,
      "train_df['category']": 3,
      "df[cat_col[i]]": 3,
      "df['original_language']": 3,
      "train['status']": 3,
      "test['status']": 3,
      "train['ebird_code']": 3,
      "train_data['Embarked']": 3,
      "test_data['Sex']": 3,
      "column_values": 3,
      "train.sex.astype('str')": 3,
      "train.anatom_site_general_challenge.astype('str')": 3,
      "shops['city_name']": 3,
      "X_Train['Province_State']": 3,
      "train_df[column]": 3,
      "test_df[column]": 3,
      "x[:, 1]": 3,
      "hadi['action_type']": 3,
      "train_labels": 3,
      "train_copy[data].astype(str)": 3,
      "train.country_province": 3,
      "df['Type']": 3,
      "train_features['cp_dose']": 3,
      "train_df.sex.astype('str')": 3,
      "train_df.anatom_site_general_challenge.astype('str')": 3,
      "shops_data['city']": 3,
      "['NORTH', 'SOUTH', 'EAST', 'WEST', 'CONVERT']": 3,
      "trainData.ix[:, 'species']": 3,
      "item_categories['item_maincategory_name']": 3,
      "item_categories['item_subcategory_name']": 3,
      "df['Date']": 3,
      "df['Country']": 3,
      "df['State']": 3,
      "all_data[feature]": 3,
      "train.iloc[:, 5]": 3,
      "data['action_type']": 3,
      "data['combined_shot_type']": 3,
      "data['shot_type']": 3,
      "data['shot_zone_area']": 3,
      "data['shot_zone_basic']": 3,
      "data['shot_zone_range']": 3,
      "data['opponent']": 3,
      "data['game_date']": 3,
      "data['season']": 3,
      "train[each]": 3,
      "train['cp_type']": 3,
      "list(alldata2[i])": 3,
      "list(df_all[c].values)": 3,
      "data['primary_use']": 3,
      "X_train[col]": 3,
      "df_train.label_group": 3,
      "categories.group_name.values": 3,
      "items.item_name_first4.values": 3,
      "items.item_name_first6.values": 3,
      "items.item_name_first11.values": 3,
      "shops.shop_city.values": 3,
      "shops.shop_type.values": 3,
      "items['name2']": 3,
      "items['name3']": 3,
      "df_train.Sentiment.values": 3,
      "target.values": 3,
      "self.df_itemcat['hl_cat_id']": 3,
      "train['label_group']": 3,
      "list(mtrain['event'].values)": 3,
      "train_X.type": 3,
      "c.astype(str)": 3,
      "shops['category']": 3,
      "df_whole['City']": 3,
      "test.iloc[:, i]": 3,
      "df['ord_3']": 3,
      "df['ord_4']": 3,
      "df['ord_5']": 3,
      "df['breed']": 3,
      "test[i].values": 3,
      "df_train['cuisine']": 3,
      "cat_df[i].astype('str')": 3,
      "train_df['Embarked']": 3,
      "test_df['Embarked']": 3,
      "train_features[col]": 3,
      "X_train['surface']": 3,
      "X2": 3,
      "X3": 3,
      "df_train.author.values": 3,
      "item_cat['type']": 3,
      "item_cat['subtype']": 3,
      "building_df['primary_use']": 3,
      "train['Label']": 3,
      "df_train['Gene'].values.ravel()": 3,
      "df_train['Variation'].values.ravel()": 3,
      "train_cuisine": 3,
      "train['store_and_fwd_flag']": 3,
      "test_data[ct_test]": 3,
      "train['Ticket']": 3,
      "temp_df['unique']": 3,
      "alldata2[i]": 3,
      "x['param_1'].fillna('-1').astype('str')": 3,
      "x['param_2'].fillna('-1').astype('str')": 3,
      "x['param_3'].fillna('-1').astype('str')": 3,
      "x['user_id'].astype('str')": 3,
      "x['city'].astype('str')": 3,
      "test[c].values": 3,
      "X[:, 4]": 3,
      "combined[name].fillna(value=99).values": 3,
      "train['sex']": 3,
      "train['anatom_site_general_challenge']": 3,
      "df['cuisine']": 3,
      "all_data[time_col]": 3,
      "train['DayOfWeek']": 3,
      "dataframe[binary_col]": 3,
      "data['target']": 3,
      "df['PdDistrict']": 3,
      "df.continent": 3,
      "df_all['City']": 3,
      "test_data['Target']": 3,
      "test_data.iloc[:, 0].values": 3,
      "df[col].values": 3,
      "df[cols[1]]": 3,
      "df[cols[i]]": 3,
      "df['BsmtCond']": 3,
      "train[col].astype(str).values": 3,
      "test[col].astype(str).values": 3,
      "train_features[l]": 3,
      "X_Train_CS.loc[:, 'Country']": 3,
      "X_Train_CS.loc[:, 'State']": 3,
      "X_Test_CS.loc[:, 'Country']": 3,
      "X_Test_CS.loc[:, 'State']": 3,
      "data['Continent']": 3,
      "data['Sub_Region']": 3,
      "df['Cabin']": 3,
      "test_data['Country_Region']": 3,
      "X[:, 0]": 3,
      "species": 3,
      "X_train_new['Province_State']": 3,
      "X_train_1.Country_Region": 3,
      "X_train_1['Province_State']": 3,
      "X_test_1.Country_Region": 3,
      "X_test_1['Province_State']": 3,
      "test.sex": 3,
      "test.anatom_site_general_challenge": 3,
      "all_labels": 3,
      "df_col1": 2,
      "df_col2": 2,
      "titanic_train['Pclass']": 2,
      "titanic_train['Cabin']": 2,
      "titanic_train['Age']": 2,
      "titanic_test['Pclass']": 2,
      "titanic_test['Cabin']": 2,
      "data[cols]": 2,
      "X.state": 2,
      "X.fiBaseModel": 2,
      "X.fiProductClassDesc": 2,
      "X.fiModelDesc": 2,
      "X['PdDistrict']": 2,
      "np.ravel(y)": 2,
      "all_df[f]": 2,
      "full_df[feat].values.reshape(-1, 1)": 2,
      "df.loc[:, c]": 2,
      "dataset['Sex']": 2,
      "df.state": 2,
      "df.fiBaseModel": 2,
      "data.iloc[:, col]": 2,
      "temp_df[X]": 2,
      "train['author']": 2,
      "train['has_cactus']": 2,
      "train['IsHoliday']": 2,
      "test['IsHoliday']": 2,
      "true_label": 2,
      "train[name]": 2,
      "df.Cabin": 2,
      "Xtrain.AnimalType": 2,
      "Xtrain.SexuponOutcome": 2,
      "Xtrain.Breed": 2,
      "Xtrain.Color": 2,
      "Xtest.AnimalType": 2,
      "Xtest.SexuponOutcome": 2,
      "Xtest.Breed": 2,
      "Xtest.Color": 2,
      "data_df[cols]": 2,
      "df[x].astype(str)": 2,
      "train.age_approx.astype('str')": 2,
      "X_Train.Country_Region": 2,
      "roman_train[column]": 2,
      "le_data[col]": 2,
      "data_clean['Country/Region']": 2,
      "train.species": 2,
      "x['shot_zone_area']": 2,
      "train.Target_name": 2,
      "merged.idhogar": 2,
      "merged.Id": 2,
      "merged.dependency": 2,
      "merged.edjefe": 2,
      "merged.edjefa": 2,
      "all_df[col].values": 2,
      "df_name['FirstName']": 2,
      "df_name['SecondName']": 2,
      "df_name": 2,
      "dataset[feature]": 2,
      "test[feature]": 2,
      "train_df['Label']": 2,
      "covid_train['Country']": 2,
      "covid_test['Country']": 2,
      "test_X[:, i]": 2,
      "final_x[:, 1]": 2,
      "train_cuisines": 2,
      "train.County": 2,
      "test.County": 2,
      "titanic_data['Embarked']": 2,
      "titanic_data['Sex']": 2,
      "titanic_data['Title']": 2,
      "test['Title']": 2,
      "data_train['Product_Info_2']": 2,
      "targets": 2,
      "df['IsHoliday']": 2,
      "df_train_nomfeatures[cols]": 2,
      "df_test_nomfeatures[cols]": 2,
      "df_train['day']": 2,
      "df_train['month']": 2,
      "df_train['bin_3']": 2,
      "df_test['bin_3']": 2,
      "df_train['bin_4']": 2,
      "df_test['bin_4']": 2,
      "AllTrain['item_id']": 2,
      "AllTrain['store_id']": 2,
      "train_df['age_approx'].astype('str')": 2,
      "train_data['CentralAir']": 2,
      "train['age_approx'].astype('str')": 2,
      "BTW_encoded['primary_use']": 2,
      "BTW_test_encoded['primary_use']": 2,
      "cate_data['main_cate']": 2,
      "cate_data['sub_cate']": 2,
      "np.array([-1, -2, -3])": 2,
      "train_data[feature]": 2,
      "test_data[feature]": 2,
      "grid.loc[:, 'category_shop_inter'].values": 2,
      "yy_": 2,
      "data.cuisine": 2,
      "test_df['Country_Region']": 2,
      "testX.CountryState": 2,
      "X_final[:, 1]": 2,
      "[y['cuisine'] for y in fullData]": 2,
      "full_df.category_name": 2,
      "full_df.brand_name": 2,
      "train.iloc[:, 1]": 2,
      "df['label_group'].values": 2,
      "tmp['Sex']": 2,
      "tmp['SibSp']": 2,
      "tmp['Parch']": 2,
      "alldata2['Make']": 2,
      "train.category": 2,
      "train.host": 2,
      "df_most_common_imputed[column_name]": 2,
      "dt_most_common_imputed[column_name]": 2,
      "sales_train_validation[col].fillna('UNK')": 2,
      "full_data[cat_var]": 2,
      "fullData[col]": 2,
      "test_data['DayOfWeek']": 2,
      "label_int.label": 2,
      "df['labels']": 2,
      "dataset_train[col]": 2,
      "dataset_test[col]": 2,
      "df['matchType']": 2,
      "X_xTrain.State": 2,
      "X_xTest.State": 2,
      "train_data['cuisine']": 2,
      "data['taxdelinquencyflag']": 2,
      "train['place_id']": 2,
      "x_train[i]": 2,
      "group['title']": 2,
      "group['game_time']": 2,
      "group['accuracy_group']": 2,
      "testX[:, i]": 2,
      "training_new[:, 1]": 2,
      "train_df['matchType']": 2,
      "df.Weekday": 2,
      "features.Country_Region": 2,
      "validation_df['prior_question_had_explanation']": 2,
      "df.type": 2,
      "train[column]": 2,
      "train_csv['prior_question_had_explanation']": 2,
      "df_y['surface']": 2,
      "train_transaction.card4": 2,
      "train_transaction.card6": 2,
      "train_transaction.P_emaildomain": 2,
      "train_transaction.M6": 2,
      "test_transaction.card4": 2,
      "test_transaction.card6": 2,
      "test_transaction.P_emaildomain": 2,
      "test_transaction.M6": 2,
      "dataset[col]": 2,
      "y_train.surface": 2,
      "categories": 2,
      "genre_ids": 2,
      "prod_companies": 2,
      "X_train.Country_Region": 2,
      "df['seed_letterTeam1']": 2,
      "data[feat]": 2,
      "train_df['SmokingStatus']": 2,
      "metadata_df['primary_use']": 2,
      "allCuisineInTrain": 2,
      "train_df.author.values": 2,
      "X.iloc[:, i]": 2,
      "df['species']": 2,
      "train['price_cat']": 2,
      "train_numeric['interest_level'].fillna('0')": 2,
      "df_train['Sex']": 2,
      "df_train['Embarked']": 2,
      "air_store['air_genre_name']": 2,
      "air_store['air_area_name0']": 2,
      "y_total": 2,
      "train[cat]": 2,
      "df['bin_3']": 2,
      "df['bin_4']": 2,
      "df['nom_0']": 2,
      "df['nom_2']": 2,
      "df['nom_3']": 2,
      "df['nom_4']": 2,
      "df['nom_1']": 2,
      "df['ord_2']": 2,
      "df['ord_1']": 2,
      "item_cats['type']": 2,
      "item_cats['subtype']": 2,
      "train['license']": 2,
      "train_data['primary_use']": 2,
      "train[i].values": 2,
      "all_data['Country/Region']": 2,
      "all_data['Province/State']": 2,
      "df['signup_method']": 2,
      "df['language']": 2,
      "df['affiliate_channel']": 2,
      "df['affiliate_provider']": 2,
      "df['signup_app']": 2,
      "df['first_device_type']": 2,
      "df['gender']": 2,
      "df['first_browser']": 2,
      "df['first_affiliate_tracked']": 2,
      "train['gender']": 2,
      "train['signup_method']": 2,
      "train['language']": 2,
      "test['gender']": 2,
      "test['signup_method']": 2,
      "test['language']": 2,
      "auxfare": 2,
      "auxage": 2,
      "data[cat_feature]": 2,
      "dataset.iloc[:, i]": 2,
      "train['City Group']": 2,
      "x_train[:, 12]": 2,
      "x_test[:, 12]": 2,
      "df_train['sentiment']": 2,
      "df_test['sentiment']": 2,
      "train_set.cuisine": 2,
      "bureau[f].astype(str)": 2,
      "previous_app[f].astype(str)": 2,
      "frame[data].astype(str)": 2,
      "train['combined_tar']": 2,
      "air_store_info['air_genre_name']": 2,
      "df.Category": 2,
      "df.DayOfWeek": 2,
      "df.PdDistrict": 2,
      "df.Resolution": 2,
      "label": 2,
      "df['Census_OSWUAutoUpdateOptionsName']": 2,
      "df['Census_GenuineStateName']": 2,
      "item_categories['type_1']": 2,
      "item_categories['type_2']": 2,
      "df_fin1['marketCommentary'].astype('str')": 2,
      "n_train_df[col]": 2,
      "birdcall_meta_samp['ebird_code']": 2,
      "x[:, 0]": 2,
      "list(train_df[c].values)": 2,
      "categoria": 2,
      "item_cats['main_category']": 2,
      "item_cats['sub_category']": 2,
      "tt3[c]": 2,
      "categories['cats']": 2,
      "X_train['author']": 2,
      "df.item_nbr": 2,
      "train['keyword']": 2,
      "train['location']": 2,
      "test['keyword']": 2,
      "test['location']": 2,
      "train_fil.Date": 2,
      "comp_df_Italy.Date": 2,
      "df_train['State']": 2,
      "df_test.Country": 2,
      "df_test['State']": 2,
      "x_train_CS.Country": 2,
      "x_train_CS['State']": 2,
      "x_test_CS.Country": 2,
      "x_test_CS['State']": 2,
      "df['education']": 2,
      "newsgroups['target']": 2,
      "all_data[i]": 2,
      "train_[obj_col]": 2,
      "test_[obj_col]": 2,
      "X_train['Province_State']": 2,
      "X_train['Country_Region']": 2,
      "X_test['Province_State']": 2,
      "X_test['Country_Region']": 2,
      "cat_test_df[i].astype('str')": 2,
      "data.color": 2,
      "gatrain.group": 2,
      "kf.folds": 2,
      "test_x['matchType'].astype('str')": 2,
      "test[col].values": 2,
      "validLabel": 2,
      "X[:, 3]": 2,
      "X[:, 5]": 2,
      "data[col].values": 2,
      "train[i].fillna('NA')": 2,
      "labels.breed": 2,
      "train.author": 2,
      "donation_paths['location_student']": 2,
      "dataset['gen_cat']": 2,
      "dataset['sub_cat1']": 2,
      "dataset['sub_cat2']": 2,
      "dataset['name']": 2,
      "X['Sex']": 2,
      "test['anatom_site_general_challenge']": 2,
      "df_train_final['Country_Region']": 2,
      "df_test_final['Country_Region']": 2,
      "train['cat10']": 2,
      "train_df.labels": 2,
      "df[cat]": 2,
      "train_values[col]": 2,
      "train_data['GeoSubregion']": 2,
      "train_data['Income Group']": 2,
      "x_features.Country": 2,
      "test_features.Country": 2,
      "df_as['air_genre_name']": 2,
      "df_as['air_area_name']": 2,
      "df_hs['hpg_genre_name']": 2,
      "df_hs['hpg_area_name']": 2,
      "combo['MM_DD']": 2,
      "test['DayOfWeek']": 2,
      "calendar[col]": 2,
      "X['Province_State']": 2,
      "train[feature]": 2,
      "df['DayOfWeek']": 2,
      "df['ST']": 2,
      "ds[col]": 2,
      "train['Type']": 2,
      "w5_X.astype(str)": 2,
      "w5_X": 2,
      "item_categories['sub_type']": 2,
      "train_df['label_group']": 2,
      "df_train_tran[[col]]": 2,
      "titanic.iloc[:, 2].values": 2,
      "titanic.iloc[:, 7].values": 2,
      "train['MasVnrType'].astype('str')": 2,
      "df_train[['labels']]": 2,
      "previous_application[col].astype(str)": 2,
      "new_df.breed": 2,
      "df.breed": 2,
      "train_data.iloc[:, 1].values": 2,
      "train_data.iloc[:, 6].values": 2,
      "test_data.iloc[:, 5].values": 2,
      "train_data['Province']": 2,
      "test_data['Province']": 2,
      "train_data['Country']": 2,
      "test_data['Country']": 2,
      "x.astype(str)": 2,
      "train['Cabin']": 2,
      "all_df[column].values": 2,
      "preds": 2,
      "df['Street']": 2,
      "df['LotShape']": 2,
      "df['Utilities']": 2,
      "df['SaleType']": 2,
      "df['Neighborhood']": 2,
      "df['Exterior1st']": 2,
      "df['Exterior2nd']": 2,
      "df['BsmtQual']": 2,
      "df['BsmtFinType1']": 2,
      "df['GarageFinish']": 2,
      "df['Functional']": 2,
      "df['KitchenQual']": 2,
      "df['GarageQual']": 2,
      "df['GarageCond']": 2,
      "df['BsmtFinType2']": 2,
      "df['Electrical']": 2,
      "test_data['MSZoning']": 2,
      "test_data['Street']": 2,
      "test_data['LotShape']": 2,
      "test_data['BsmtQual']": 2,
      "test_data['BsmtCond']": 2,
      "test_data['BsmtFinType1']": 2,
      "test_data['GarageFinish']": 2,
      "test_data['CentralAir']": 2,
      "train.iloc[:, 6]": 2,
      "x_train[:, 0]": 2,
      "x_test[:, 0]": 2,
      "df_train[cat_col]": 2,
      "train.loc[:, cat_feat].values.reshape(-1, 1)": 2,
      "pubg_train['matchType']": 2,
      "pubg_test['matchType']": 2,
      "df_train_2['day_name']": 2,
      "pd.cut(train_build['month'], month_season_bins).astype(str)": 2,
      "train_build['primary_use']": 2,
      "new_x_train[feature].values": 2,
      "X_Pred.Country": 2,
      "X_Pred['State']": 2,
      "X_Pred_CS.Country": 2,
      "X_Pred_CS['State']": 2,
      "imputed_df[col].astype(str)": 2,
      "np.reshape(y, (-1, 1))": 2,
      "ds1.iloc[:, 0].values": 2,
      "ds2.iloc[:, 0].values": 2,
      "train_data['anatom_site_general_challenge'].astype('str')": 2,
      "df1.Variation": 2,
      "data['Province/State']": 2,
      "X_train['primary_use']": 2,
      "X[c]": 2,
      "df_obj[i]": 2,
      "test['City Group']": 2,
      "df['Ticket']": 2,
      "Z": 2,
      "cell_train[:, g.pos['idtrain']]": 2,
      "train_df.Date": 2,
      "l2": 2,
      "train_features[f]": 2,
      "train[['walkDistance']]": 2,
      "train[['damageDealt']]": 2,
      "train[['longestKill']]": 2,
      "train[['rideDistance']]": 2,
      "train[['swimDistance']]": 2,
      "train[['winPlacePerc']]": 2,
      "test[['walkDistance']]": 2,
      "test[['damageDealt']]": 2,
      "test[['longestKill']]": 2,
      "test[['rideDistance']]": 2,
      "test[['swimDistance']]": 2,
      "train.OutcomeType": 2,
      "df['Title']": 2,
      "df_test['Sex']": 2,
      "df_test['Embarked']": 2,
      "train_df['ebird_code']": 2,
      "Xx[:, 0]": 2,
      "Xx[:, 1]": 2,
      "df.location.values": 2,
      "df.keyword.values": 2,
      "col.astype('str')": 2,
      "train_label": 2,
      "df_structures.atom": 2,
      "train_csv['rad_id']": 2,
      "trainData.loc[:, 'species']": 2,
      "train_df['sentiment']": 2,
      "test_df['sentiment']": 2,
      "data['Ticket']": 2,
      "df.cp_dose": 2,
      "df.cp_type": 2,
      "labels['breed']": 2,
      "first_labels_set": 2,
      "X_train_enc[cols]": 2,
      "trainingData['interest_level']": 2,
      "returns_train['returnsOpenNextMktres10']": 2,
      "returns_test['returnsOpenNextMktres10']": 2,
      "train_df.PdDistrict": 2,
      "train_data['idhogar']": 2,
      "full_df[col]": 2,
      "item_categories_df['type']": 2,
      "X_train_group.Country": 2,
      "X_train_group.State": 2,
      "X_test_group.Country": 2,
      "X_test_group.State": 2,
      "label['surface']": 2,
      "X[col[0]]": 2,
      "train_df[['Geo']]": 2,
      "crime_train.Category": 2,
      "test_transaction_new[i].astype('str')": 1,
      "train_transaction_new[i].astype('str')": 1,
      "X['color']": 1,
      "data['Location']": 1,
      "data['variable']": 1,
      "json_cuisine": 1,
      "df_all[c]": 1,
      "lables": 1,
      "train_y['surface']": 1,
      "self.df[self.col]": 1,
      "train[cols]": 1,
      "test[cols]": 1,
      "data[encode[0]]": 1,
      "data[encode[1]]": 1,
      "data[encode[2]]": 1,
      "data[encode[3]]": 1,
      "data[encode[4]]": 1,
      "data[encode[5]]": 1,
      "data[encode[6]]": 1,
      "data[encode[7]]": 1,
      "data[encode[8]]": 1,
      "data[encode[9]]": 1,
      "data[encode[10]]": 1,
      "data[encode[11]]": 1,
      "data[encode[12]]": 1,
      "data[encode[13]]": 1,
      "data[encode[14]]": 1,
      "data[encode[15]]": 1,
      "train_df['category'][:2000]": 1,
      "train_df['category'][:1000].values": 1,
      "shops['shop_label']": 1,
      "itemCategories['cat_label']": 1,
      "itemCategories['cat_subLabel']": 1,
      "traindata['color']": 1,
      "testdata['color']": 1,
      "traindata['type'].astype(str)": 1,
      "building_metadata_df['year_built']": 1,
      "building_metadata_df['primary_use']": 1,
      "df.store_and_fwd_flag.values": 1,
      "np.array(train[col].astype(str)).reshape((-1, ))": 1,
      "df['prior_question_had_explanation']": 1,
      "df.loc[:, 'prior_type'].values": 1,
      "imgLabel[0]": 1,
      "new_combine_df.Sex": 1,
      "new_combine_df.Embarked": 1,
      "new_combine_df.Update_Cabin": 1,
      "new_combine_df.Ticket_Category": 1,
      "y_value": 1,
      "list(df_train[i].values)": 1,
      "list(df_test[i].values)": 1,
      "train_merge4[cat_col[i]]": 1,
      "test_merge4[cat_col[i]]": 1,
      "df_labels[col].astype(str)": 1,
      "df_y_train['surface']": 1,
      "data[f].astype(str).fillna('-1').values": 1,
      "test_label": 1,
      "self.train[e]": 1,
      "train['all_genres']": 1,
      "test['all_genres']": 1,
      "train['production_countries']": 1,
      "test['production_countries']": 1,
      "train['all_Keywords']": 1,
      "test['all_Keywords']": 1,
      "X[column]": 1,
      "test_x[feature]": 1,
      "train_data['action_type']": 1,
      "train_data['combined_shot_type']": 1,
      "train_data['shot_type']": 1,
      "train_data['shot_zone_area']": 1,
      "train_data['shot_zone_basic']": 1,
      "train_data['shot_zone_range']": 1,
      "train_data['matchup']": 1,
      "train_data['opponent']": 1,
      "test_data['action_type']": 1,
      "test_data['combined_shot_type']": 1,
      "test_data['shot_type']": 1,
      "test_data['shot_zone_area']": 1,
      "test_data['shot_zone_basic']": 1,
      "test_data['shot_zone_range']": 1,
      "test_data['matchup']": 1,
      "test_data['opponent']": 1,
      "dev_df['type'].values": 1,
      "trainData['brand_name']": 1,
      "testData['brand_name']": 1,
      "trainData['category1_label']": 1,
      "testData['category1_label']": 1,
      "trainData['category2_label']": 1,
      "testData['category2_label']": 1,
      "trainData['category3_label']": 1,
      "testData['category3_label']": 1,
      "item_categories['sub_category']": 1,
      "dataset['Embarked']": 1,
      "cov_train[i]": 1,
      "df['Is_month_end']": 1,
      "df['Is_month_start']": 1,
      "df['Is_quarter_end']": 1,
      "df['Is_quarter_start']": 1,
      "df['Is_year_end']": 1,
      "df['Is_year_start']": 1,
      "X_train[i]": 1,
      "X_val[i]": 1,
      "train_dropped_five[col]": 1,
      "test_dropped_five[col]": 1,
      "test.fiModelDesc": 1,
      "test.fiProductClassDesc": 1,
      "test.fiBaseModel": 1,
      "test.state": 1,
      "concat_df[i]": 1,
      "train_model['target']": 1,
      "data1['Location']": 1,
      "train['AnimalType']": 1,
      "calendar[feature]": 1,
      "df_subset['Sex']": 1,
      "df_subset['Embarked']": 1,
      "df_subset['Title']": 1,
      "df_subset['Cabin_Class']": 1,
      "df_subset['Survived']": 1,
      "df['breed'].values": 1,
      "train_4['location']": 1,
      "train_4['severity_type']": 1,
      "train_4['resource_type']": 1,
      "train_4['log_feature']": 1,
      "train_4['event_type']": 1,
      "test_4['location']": 1,
      "test_4['severity_type']": 1,
      "test_4['resource_type']": 1,
      "test_4['log_feature']": 1,
      "test_4['event_type']": 1,
      "data_new[i]": 1,
      "test[name]": 1,
      "stv[i]": 1,
      "test.Cabin": 1,
      "all_ingredients": 1,
      "cat_data[col]": 1,
      "cat_test[col]": 1,
      "X.store_and_fwd_flag": 1,
      "X_train_tf['Type']": 1,
      "train_test_df['primary_use']": 1,
      "df[each_feature]": 1,
      "target_variable.values": 1,
      "dataset['category_1']": 1,
      "dataset['category_3']": 1,
      "train_data[x]": 1,
      "test_data[x]": 1,
      "train[your_feature + '_qbinned'].values.reshape(-1, 1)": 1,
      "y_df": 1,
      "x.Sex": 1,
      "x.Name": 1,
      "x.Embarked": 1,
      "x.Cabin": 1,
      "x.Ticket": 1,
      "dftrn['primary_use']": 1,
      "dftst['primary_use']": 1,
      "questions['tags'].values": 1,
      "train.cp_dose": 1,
      "dataset['location']": 1,
      "test[x].astype(str)": 1,
      "test_data['Embarked']": 1,
      "train.cuisine.values": 1,
      "df_gender_age_train['group'].values": 1,
      "total_data['Country_Region']": 1,
      "total_data.Date": 1,
      "df_train_preprocess['primary_use']": 1,
      "df_test_preprocess['primary_use']": 1,
      "data['location']": 1,
      "questions[cat_features]": 1,
      "train.cr": 1,
      "test.cr": 1,
      "train.ps": 1,
      "test.ps": 1,
      "data[key].fillna('NULL').astype(str).values": 1,
      "dfle.Ticket": 1,
      "dfle.Sex": 1,
      "dfle.Embarked": 1,
      "t.Sex": 1,
      "t.Embarked": 1,
      "cats['item_type']": 1,
      "cats['item_subtype']": 1,
      "train_data.type.values": 1,
      "df_train['type']": 1,
      "df_struct['atom']": 1,
      "train_total['primary_use']": 1,
      "test_total['primary_use']": 1,
      "train_total['meter']": 1,
      "test_total['meter']": 1,
      "x_test[:, 1]": 1,
      "x['combined_shot_type']": 1,
      "x['season']": 1,
      "x['opponent']": 1,
      "x['shot_zone_range']": 1,
      "x['action_type']": 1,
      "Train_HD_Final[i].values": 1,
      "Test_HD_Final[i].values": 1,
      "titanic_train['Embarked']": 1,
      "titanic_test['Embarked']": 1,
      "train['title']": 1,
      "all_tdata['country']": 1,
      "all_tdata['state']": 1,
      "train_df['Sentiment'].values": 1,
      "train[cols[1]]": 1,
      "sales['wday']": 1,
      "sales['cat_id']": 1,
      "sales['dept_id']": 1,
      "dataframe[cat].astype(str)": 1,
      "train_data.iloc[:, 3].values": 1,
      "train_data.iloc[:, 9].values": 1,
      "test_data.iloc[:, 2].values": 1,
      "test_data.iloc[:, 8].values": 1,
      "X.loc[:, 'idhogar']": 1,
      "X_validate.loc[:, 'idhogar']": 1,
      "temp_train[i]": 1,
      "temp_test[i]": 1,
      "train['teacher_id'].astype(str)": 1,
      "train['teacher_prefix'].astype(str)": 1,
      "train['school_state'].astype(str)": 1,
      "train['project_grade_category'].astype(str)": 1,
      "train['project_subject_categories'].astype(str)": 1,
      "train['project_subject_subcategories'].astype(str)": 1,
      "train['gender'].astype(str)": 1,
      "test['teacher_id'].astype(str)": 1,
      "test['teacher_prefix'].astype(str)": 1,
      "test['school_state'].astype(str)": 1,
      "test['project_grade_category'].astype(str)": 1,
      "test['project_subject_categories'].astype(str)": 1,
      "test['project_subject_subcategories'].astype(str)": 1,
      "test['gender'].astype(str)": 1,
      "train['brand_name']": 1,
      "test['brand_name']": 1,
      "train['category_1']": 1,
      "test['category_1']": 1,
      "train['category_2']": 1,
      "test['category_2']": 1,
      "train['category_3']": 1,
      "test['category_3']": 1,
      "df1['ord_2'].astype(str)": 1,
      "test_list": 1,
      "data[feat].fillna('-1').astype(str)": 1,
      "X['Country/Region']": 1,
      "X['Province/State']": 1,
      "data[categorical_feature]": 1,
      "application_train[col]": 1,
      "dataframe['prior_question_had_explanation']": 1,
      "train_xgb['Country/Region']": 1,
      "train_xgb['Province/State']": 1,
      "test_xgb['Country/Region']": 1,
      "test_xgb['Province/State']": 1,
      "train_data['cabin_adv']": 1,
      "train_data['numeric_ticket']": 1,
      "train_data['ticket_letters']": 1,
      "train_data['name_title']": 1,
      "y_train_ann": 1,
      "train['target'].values": 1,
      "trainData['Sex']": 1,
      "trainData['SmokingStatus']": 1,
      "df_train[feature]": 1,
      "df_test[feature]": 1,
      "df_train['Age']": 1,
      "df_test['Age']": 1,
      "train_details['sex']": 1,
      "train_details['anatom_site_general_challenge']": 1,
      "train['Alley']": 1,
      "train['LandSlope']": 1,
      "train['YearBuilt']": 1,
      "train['WoodDeckSF']": 1,
      "ordinal[col]": 1,
      "ordinal_test[col]": 1,
      "x[i].astype(str)": 1,
      "train.province": 1,
      "train_df[['labels']]": 1,
      "train_df['surface']": 1,
      "df['type']": 1,
      "train_transaction['amt_cat']": 1,
      "train_transaction[col]": 1,
      "train_transaction['P_neq_R']": 1,
      "train_transaction[col].astype(str)": 1,
      "test_transaction['amt_cat']": 1,
      "test_transaction[col]": 1,
      "test_transaction['P_neq_R']": 1,
      "test_transaction[col].astype(str)": 1,
      "df_train_ordfeatures[cols]": 1,
      "df_test_ordfeatures[cols]": 1,
      "df_train['nom_0']": 1,
      "df_test['nom_0']": 1,
      "df_train['nom_1']": 1,
      "df_test['nom_1']": 1,
      "df_train['nom_2']": 1,
      "df_test['nom_2']": 1,
      "df_train['nom_3']": 1,
      "df_test['nom_3']": 1,
      "df_train['nom_4']": 1,
      "df_test['nom_4']": 1,
      "df_train['ord_0']": 1,
      "df_test['ord_0']": 1,
      "df_train['ord_1']": 1,
      "df_test['ord_1']": 1,
      "df_train['ord_2']": 1,
      "df_test['ord_2']": 1,
      "df_train['ord_3']": 1,
      "df_test['ord_3']": 1,
      "df_test['day']": 1,
      "df_test['month']": 1,
      "y_train.values": 1,
      "tr['surface']": 1,
      "test1['StateHoliday']": 1,
      "train['StateHoliday']": 1,
      "train_lbl['Id']": 1,
      "test['Province']": 1,
      "train_data['MSZoning']": 1,
      "train_data['Street']": 1,
      "train_data['Alley']": 1,
      "train_data['LotShape']": 1,
      "train_data['LandContour']": 1,
      "train_data['Utilities']": 1,
      "train_data['LotConfig']": 1,
      "train_data['LandSlope']": 1,
      "train_data['Neighborhood']": 1,
      "train_data['Condition1']": 1,
      "train_data['Condition2']": 1,
      "train_data['BldgType']": 1,
      "train_data['HouseStyle']": 1,
      "train_data['RoofStyle']": 1,
      "train_data['RoofMatl']": 1,
      "train_data['Exterior1st']": 1,
      "train_data['Exterior2nd']": 1,
      "train_data['MasVnrType']": 1,
      "train_data['ExterQual']": 1,
      "train_data['ExterCond']": 1,
      "train_data['Foundation']": 1,
      "train_data['BsmtQual']": 1,
      "train_data['BsmtCond']": 1,
      "train_data['BsmtExposure']": 1,
      "train_data['BsmtFinType1']": 1,
      "train_data['BsmtFinType2']": 1,
      "train_data['Heating']": 1,
      "train_data['HeatingQC']": 1,
      "train_data['Electrical']": 1,
      "train_data['KitchenQual']": 1,
      "train_data['Functional']": 1,
      "train_data['FireplaceQu']": 1,
      "train_data['GarageType']": 1,
      "train_data['GarageFinish']": 1,
      "train_data['GarageQual']": 1,
      "train_data['GarageCond']": 1,
      "train_data['PavedDrive']": 1,
      "train_data['PoolQC']": 1,
      "train_data['Fence']": 1,
      "train_data['MiscFeature']": 1,
      "train_data['SaleType']": 1,
      "train_data['SaleCondition']": 1,
      "cal['event_name_1']": 1,
      "cal['event_type_1']": 1,
      "cal['event_name_2']": 1,
      "cal['event_type_2']": 1,
      "sales_train_val_melted['dept_id']": 1,
      "sales_train_val_melted['cat_id']": 1,
      "sales_train_val_melted['state_id']": 1,
      "sales_train_val_melted['id']": 1,
      "sales_train_val_melted['item_id']": 1,
      "data['year']": 1,
      "data['month']": 1,
      "data['day']": 1,
      "train['sex'].astype(str)": 1,
      "train['anatom_site_general_challenge'].astype(str)": 1,
      "test['age_approx'].astype('str')": 1,
      "data[i].astype(str)": 1,
      "result3[col].astype(str)": 1,
      "data_final['assetCode']": 1,
      "train2.CountryState": 1,
      "df_sales['city']": 1,
      "train_answer": 1,
      "shops.shop_city": 1,
      "shops.shop_type": 1,
      "np.ravel(df_raw[cat])": 1,
      "train_titanic['Embarked']": 1,
      "train_titanic['Sex']": 1,
      "list(df[col].values.astype('str'))": 1,
      "train_labels_df.invasive": 1,
      "df['category_name']": 1,
      "prop2016['propertycountylandusecode']": 1,
      "prop2017['propertycountylandusecode']": 1,
      "prop2016['propertyzoningdesc']": 1,
      "prop2017['propertyzoningdesc']": 1,
      "x_all[cat_col]": 1,
      "XTrain.country": 1,
      "XTrain['state']": 1,
      "XTest.country": 1,
      "XTest['state']": 1,
      "XTrain_CS.country": 1,
      "XTrain_CS['state']": 1,
      "XTest_CS.country": 1,
      "XTest_CS['state']": 1,
      "cat[i]": 1,
      "cat_test[i]": 1,
      "test.iloc[:, 1]": 1,
      "test.iloc[:, 5]": 1,
      "stores['air_store_id']": 1,
      "data['holidays']['day_of_week']": 1,
      "Train['school_state']": 1,
      "Test['school_state']": 1,
      "df_object[i]": 1,
      "df['Diagnosis']": 1,
      "df[label].astype(str)": 1,
      "item_categories['subcat']": 1,
      "itemsa.item_name": 1,
      "Df_cats.ix[:, 0]": 1,
      "Df_cats.ix[:, 1]": 1,
      "Df_cats.ix[:, 2]": 1,
      "Df_cats.ix[:, 3]": 1,
      "Df_cats.ix[:, 4]": 1,
      "Df_cats.ix[:, 5]": 1,
      "Df_cats.ix[:, 6]": 1,
      "Df_cats.ix[:, 7]": 1,
      "Df_cats.ix[:, 8]": 1,
      "Df_cats.ix[:, 9]": 1,
      "Df_cats.ix[:, 10]": 1,
      "Df_cats.ix[:, 11]": 1,
      "Df_cats.ix[:, 12]": 1,
      "Df_cats.ix[:, 13]": 1,
      "Df_cats.ix[:, 14]": 1,
      "Df_cats.ix[:, 15]": 1,
      "Df_cats.ix[:, 16]": 1,
      "Df_cats.ix[:, 17]": 1,
      "Df_cats.ix[:, 18]": 1,
      "Df_cats['activity_category']": 1,
      "Df['activity_id']": 1,
      "train['age_bin']": 1,
      "test['age_bin']": 1,
      "train_df['status']": 1,
      "test_df['status']": 1,
      "train_df['labels']": 1,
      "app[col]": 1,
      "X_full[col]": 1,
      "train.license.values": 1,
      "df.Q24Part4": 1,
      "items['name_1']": 1,
      "train['rating']": 1,
      "test['rating']": 1,
      "X_Train['Country']": 1,
      "X_Test['Country']": 1,
      "y_labels": 1,
      "store['StoreType']": 1,
      "store['Assortment']": 1,
      "train_X[obj_col]": 1,
      "test_X[obj_col]": 1,
      "train['country_destination']": 1,
      "X_train[index]['Province_State']": 1,
      "X_train[index]['Country_Region']": 1,
      "X_test[index]['Province_State']": 1,
      "X_test[index]['Country_Region']": 1,
      "df_train['Category']": 1,
      "df_train['DayOfWeek']": 1,
      "df_test['DayOfWeek']": 1,
      "df_train['PdDistrict']": 1,
      "df_test['PdDistrict']": 1,
      "item_category['basket']": 1,
      "df.author": 1,
      "df2['Category']": 1,
      "df2[each]": 1,
      "new_train[cols]": 1,
      "both_df[both_df['Data'] == 'Train']['cuisine']": 1,
      "list(test[i])": 1,
      "train_feature['cp_type']": 1,
      "train_feature['cp_time']": 1,
      "train_feature['cp_dose']": 1,
      "ht['authorized_flag']": 1,
      "ht['category_1']": 1,
      "ht['category_3']": 1,
      "ht['merchant_category_id']": 1,
      "merge.brand_name": 1,
      "merge.general_cat": 1,
      "merge.subcat_1": 1,
      "merge.subcat_2": 1,
      "x_train[:, 1]": 1,
      "x_train[:, column_id]": 1,
      "dataset.Sex": 1,
      "dataset['AgeBin']": 1,
      "dataset['FareBin']": 1,
      "dataset.Embarked": 1,
      "train_data['Country/Region']": 1,
      "test_data['Country/Region']": 1,
      "features[i]": 1,
      "train_df.primary_use": 1,
      "calendar[col].fillna('UNK')": 1,
      "list(all_data[col].values)": 1,
      "train_df['interest_level']": 1,
      "single[feature]": 1,
      "train_data['DayOfWeek']": 1,
      "dataset['original_language']": 1,
      "object_train[col]": 1,
      "train_df[i].astype('str')": 1,
      "item_cats['subcat1']": 1,
      "item_cats['subcat2']": 1,
      "train_df.cleaned_label": 1,
      "['NORTH', 'EAST', 'SOUTH', 'WEST']": 1,
      "df1['Sex']": 1,
      "test1['Sex']": 1,
      "df1['Embarked']": 1,
      "test1['Embarked']": 1,
      "train[x].fillna('0')": 1,
      "test[x].fillna('0')": 1,
      "df_train1['Country_Region']": 1,
      "traintest[col]": 1,
      "train['labels']": 1,
      "train[target].values": 1,
      "train_df['store_and_fwd_flag']": 1,
      "test_df['store_and_fwd_flag']": 1,
      "train['brand_name'].fillna('Nan')": 1,
      "train['category_name'].fillna('Nan')": 1,
      "pd_total['DayOfWeek']": 1,
      "pd_total['PdDistrict']": 1,
      "pd_total['Address']": 1,
      "train_raw.loc[:, 'title']": 1,
      "train_raw.loc[:, 'type']": 1,
      "train_raw.loc[:, 'world']": 1,
      "train_raw.loc[:, 'event_id']": 1,
      "train_raw.loc[:, 'dayofweek']": 1,
      "train_raw.loc[:, 'event_data']": 1,
      "train_raw.loc[:, 'game_session']": 1,
      "train_raw.loc[:, 'timestamp']": 1,
      "train_raw.loc[:, 'installation_id']": 1,
      "dummies": 1,
      "test_dummies": 1,
      "colors": 1,
      "train_data['Neighborhood'].astype(str)": 1,
      "test_data['Neighborhood'].astype(str)": 1,
      "train_data['Exterior1st'].astype(str)": 1,
      "test_data['Exterior1st'].astype(str)": 1,
      "train_data['Exterior2nd'].astype(str)": 1,
      "test_data['Exterior2nd'].astype(str)": 1,
      "X['molecule_name']": 1,
      "df[old_col]": 1,
      "train_df.County": 1,
      "test_df.County": 1,
      "test_df.Target": 1,
      "train_df.Target": 1,
      "X_xTrain_CS.State": 1,
      "X_xTest_CS.State": 1,
      "train.Target": 1,
      "test.Target": 1,
      "survey_df['Q1'].values[1:]": 1,
      "survey_df['Q2'].values[1:]": 1,
      "survey_df['Q4'].values[1:]": 1,
      "survey_df['Q20'].values[1:]": 1,
      "survey_df['Q6'].values[1:]": 1,
      "survey_df['Q15'].values[1:]": 1,
      "survey_df['Q24'].values[1:]": 1,
      "survey_df['Q5'].values[1:]": 1,
      "train[i].astype('str')": 1,
      "test[i].astype('str')": 1,
      "items['type']": 1,
      "item_categories['cat_global']": 1,
      "item_categories['cat_platform']": 1,
      "trainData.Date": 1,
      "dfTest.Date": 1,
      "x_test[j]": 1,
      "trainDf.author": 1,
      "DF_shops['shop_city']": 1,
      "DF_shops['shop_cat']": 1,
      "DF_items['item_sub_cat_1']": 1,
      "labelsTxt": 1,
      "x['Neighborhood']": 1,
      "listData[:, index]": 1,
      "sf['Category']": 1,
      "data_train['matchType']": 1,
      "test_df['matchType']": 1,
      "data.production_companies": 1,
      "data.collection": 1,
      "data.original_language": 1,
      "data.genres": 1,
      "train.keyword": 1,
      "train.location": 1,
      "train_data['type']": 1,
      "dataset[target].values": 1,
      "train_data['labels']": 1,
      "y_df['surface']": 1,
      "app_ev['app_id']": 1,
      "train[train_mask]": 1,
      "train.loc[:, 'Category']": 1,
      "fold0.loc[:, 'Category']": 1,
      "fold1.loc[:, 'Category']": 1,
      "example_test['prior_question_had_explanation']": 1,
      "categ['gen_categ']": 1,
      "train_transaction.DeviceType": 1,
      "train_transaction.DeviceInfo": 1,
      "train_transaction.id_15": 1,
      "train_transaction.id_16": 1,
      "train_transaction.id_28": 1,
      "train_transaction.id_29": 1,
      "train_transaction.id_30": 1,
      "train_transaction.id_31": 1,
      "train_transaction.id_33": 1,
      "train_transaction.id_34": 1,
      "train_transaction.id_35": 1,
      "train_transaction.id_36": 1,
      "train_transaction.id_37": 1,
      "train_transaction.id_38": 1,
      "test_transaction.DeviceType": 1,
      "test_transaction.DeviceInfo": 1,
      "test_transaction.id_15": 1,
      "test_transaction.id_16": 1,
      "test_transaction.id_28": 1,
      "test_transaction.id_29": 1,
      "test_transaction.id_30": 1,
      "test_transaction.id_31": 1,
      "test_transaction.id_33": 1,
      "test_transaction.id_34": 1,
      "test_transaction.id_35": 1,
      "test_transaction.id_36": 1,
      "test_transaction.id_37": 1,
      "test_transaction.id_38": 1,
      "test['Patient']": 1,
      "train_x['primary_use']": 1,
      "brands": 1,
      "df.loc[:, 'species']": 1,
      "data['city_intersection']": 1,
      "train['collection_id']": 1,
      "df['collection_id']": 1,
      "X_train.Province_State": 1,
      "X_test.Country_Region": 1,
      "X_test.Province_State": 1,
      "combine_df[col]": 1,
      "y_true": 1,
      "tr_ls": 1,
      "te_ls": 1,
      "X_Train_CS.Country_Region": 1,
      "X_Train_CS['Province_State']": 1,
      "X_Test_CS.Country_Region": 1,
      "X_Test_CS['Province_State']": 1,
      "ipsm['date_block_num']": 1,
      "train_sentence['author']": 1,
      "full_train['title_x']": 1,
      "train_with_specs['args']": 1,
      "pd.cut(train_with_specs['event_code'], bins)": 1,
      "test_with_specs['args']": 1,
      "pd.cut(test_with_specs['event_code'], bins)": 1,
      "test_with_specs['title']": 1,
      "cat_df['type']": 1,
      "cat_df['subtype']": 1,
      "df_all['Breed1']": 1,
      "df_all['Age_bins']": 1,
      "df_all['Fee_bins']": 1,
      "df_all['State']": 1,
      "df_all['PhotoAmt_bins']": 1,
      "df_all['len_words_Description_bins']": 1,
      "Shops1.City": 1,
      "Shops1.Type": 1,
      "RawItems.name2": 1,
      "RawItems.name3": 1,
      "RawCategories['item_category_name_2']": 1,
      "allIngredientsInTrain": 1,
      "data[feat].astype('str')": 1,
      "data_test[feat].astype('str')": 1,
      "Y_valid": 1,
      "train_df['hotel_id']": 1,
      "mol_atom_0": 1,
      "mol_atom_1": 1,
      "concat_features[col]": 1,
      "research_data[col]": 1,
      "train_features['drug_id']": 1,
      "dfy.values": 1,
      "y.values": 1,
      "treino.target.values": 1,
      "Labels": 1,
      "store1['air_genre_name']": 1,
      "yl": 1,
      "train_data['color']": 1,
      "test_data['color']": 1,
      "train['dayofweek']": 1,
      "cat_1.values.reshape(-1, 1)": 1,
      "cat_2.values.reshape(-1, 1)": 1,
      "cat_3.values.reshape(-1, 1)": 1,
      "train_users.language": 1,
      "test_users.language": 1,
      "train_users.affiliate_channel": 1,
      "train_users.affiliate_provider": 1,
      "test_users.affiliate_channel": 1,
      "test_users.affiliate_provider": 1,
      "train_users.first_affiliate_tracked": 1,
      "test_users.first_affiliate_tracked": 1,
      "train_users.signup_app": 1,
      "train_users.first_device_type": 1,
      "train_users.first_browser": 1,
      "test_users.signup_app": 1,
      "test_users.first_device_type": 1,
      "test_users.first_browser": 1,
      "data.country_destination": 1,
      "df1.cuisine": 1,
      "df['country']": 1,
      "shops.names": 1,
      "item_catg['type']": 1,
      "item_catg.subtype": 1,
      "items.name1": 1,
      "train1[:, 7]": 1,
      "train1[:, 12]": 1,
      "fullData[var].astype('str')": 1,
      "fullData['Cover_Type'].astype('str')": 1,
      "df_train['Title']": 1,
      "X[column].fillna('Missing')": 1,
      "X_test[column].fillna('Missing')": 1,
      "city_region_unique['region'].values": 1,
      "city_region_unique['city_region'].values": 1,
      "Xx[f'{c}']": 1,
      "shops_featured['shop_city']": 1,
      "shops_featured['shop_type']": 1,
      "cats_featured['category_type']": 1,
      "cats_featured['category_subtype']": 1,
      "[cat.split('/')[0] for cat in data.category_name[category_index].values]": 1,
      "[cat.split('/')[1] for cat in data.category_name[category_index].values]": 1,
      "[cat.split('/')[2] for cat in data.category_name[category_index].values]": 1,
      "data.brand_name[brand_index].values": 1,
      "train['workclass'].values.reshape(-1, 1)": 1,
      "copy['keyword']": 1,
      "all_data[col][:len(train)]": 1,
      "train_test['Country/Region']": 1,
      "corr_df['Q20']": 1,
      "corr_df['Q22']": 1,
      "corr_df['Q24']": 1,
      "corr_df['Q25']": 1,
      "full[c]": 1,
      "df['nom_5']": 1,
      "df['nom_6']": 1,
      "df['nom_7']": 1,
      "df['nom_8']": 1,
      "df['nom_9']": 1,
      "train['species']": 1,
      "out_enc_X_train['Product_Info_2']": 1,
      "out_enc_X_valid['Product_Info_2']": 1,
      "OS_X_train_clean['Product_Info_2']": 1,
      "df_Big['Sex']": 1,
      "df_Big['Embarked']": 1,
      "df_Big['Ticket']": 1,
      "df_Big['FirstName']": 1,
      "df_Big['SecondName']": 1,
      "data['class_label']": 1,
      "df['rad_id']": 1,
      "train['SmokingStatus']": 1,
      "df['cleaned_label']": 1,
      "shops.shop_sub_type": 1,
      "categories.category": 1,
      "categories.sub_category": 1,
      "y_raw": 1,
      "test_data['primary_use']": 1,
      "list(X[col].astype(str).values)": 1,
      "train['first_affiliate_tracked']": 1,
      "train['affiliate_channel']": 1,
      "train['affiliate_provider']": 1,
      "train['signup_app']": 1,
      "train['first_device_type']": 1,
      "train['first_browser']": 1,
      "test['first_affiliate_tracked']": 1,
      "test['affiliate_channel']": 1,
      "test['affiliate_provider']": 1,
      "test['signup_app']": 1,
      "test['first_device_type']": 1,
      "test['first_browser']": 1,
      "train_df[cat_feature]": 1,
      "test_df[cat_feature]": 1,
      "full_df[cat_feature]": 1,
      "data['as']['air_genre_name']": 1,
      "data['as']['air_area_name']": 1,
      "df_train[['Embarked']]": 1,
      "df_train[['Sex']]": 1,
      "full[col].values": 1,
      "df_train['species'].values": 1,
      "df_date.Category": 1,
      "df_date.PdDistrict": 1,
      "test_data_transformed.PdDistrict": 1,
      "train_prepared['air_genre_name']": 1,
      "train_prepared['air_area_name']": 1,
      "train_prepared['holiday_flg']": 1,
      "train_prepared['day_of_week']": 1,
      "test_prepared['air_genre_name']": 1,
      "test_prepared['air_area_name']": 1,
      "test_prepared['holiday_flg']": 1,
      "test_prepared['day_of_week']": 1,
      "dftr1.Loc": 1,
      "dftt1.Loc": 1,
      "df_train.name": 1,
      "df_test.name": 1,
      "df_train[l]": 1,
      "df_test[l]": 1,
      "df_building_metadata['primary_use']": 1,
      "specs['info']": 1,
      "result_col.values": 1,
      "countries": 1,
      "provinces": 1,
      "ct": 1,
      "pt": 1,
      "data_clean['Sex']": 1,
      "train_data['Category']": 1,
      "X_train[['seat']]": 1,
      "X_train[['crew']]": 1,
      "X_test[['seat']]": 1,
      "X_test[['crew']]": 1,
      "X[[i]]": 1,
      "X_train[[i]]": 1,
      "X_test[[i]]": 1,
      "df[col].astype(str).values": 1,
      "train.type": 1,
      "train_contribs.type_x": 1,
      "test_df[i].astype('str')": 1,
      "train['Product_Info_2']": 1,
      "test['Product_Info_2']": 1,
      "df['StateHoliday'].apply(lambda x: str(x))": 1,
      "df['SchoolHoliday'].apply(lambda x: str(x))": 1,
      "df['Open'].apply(lambda x: str(x))": 1,
      "df['Promo'].apply(lambda x: str(x))": 1,
      "y_rf_train": 1,
      "train_dataset['Sex']": 1,
      "train_dataset['Embarked']": 1,
      "train_cleaned.cats": 1,
      "bmdata['primary_use']": 1,
      "train_data_encode['NAME_CONTRACT_TYPE']": 1,
      "train_data_encode['CODE_GENDER']": 1,
      "train_data_encode['FLAG_OWN_CAR']": 1,
      "train_data_encode['FLAG_OWN_REALTY']": 1,
      "train_data_encode['NAME_INCOME_TYPE']": 1,
      "train_data_encode['NAME_EDUCATION_TYPE']": 1,
      "train_data_encode['NAME_FAMILY_STATUS']": 1,
      "train_data_encode['NAME_HOUSING_TYPE']": 1,
      "train_data_encode['WEEKDAY_APPR_PROCESS_START']": 1,
      "train_data_encode['ORGANIZATION_TYPE']": 1,
      "test_data_encode['NAME_CONTRACT_TYPE']": 1,
      "test_data_encode['CODE_GENDER']": 1,
      "test_data_encode['FLAG_OWN_CAR']": 1,
      "test_data_encode['FLAG_OWN_REALTY']": 1,
      "test_data_encode['NAME_INCOME_TYPE']": 1,
      "test_data_encode['NAME_EDUCATION_TYPE']": 1,
      "test_data_encode['NAME_FAMILY_STATUS']": 1,
      "test_data_encode['NAME_HOUSING_TYPE']": 1,
      "test_data_encode['WEEKDAY_APPR_PROCESS_START']": 1,
      "test_data_encode['ORGANIZATION_TYPE']": 1,
      "updated_df_train[i]": 1,
      "all_data['MSZoning']": 1,
      "all_data[bin_feature]": 1,
      "data_train.ord_2.values": 1,
      "df[col_name]": 1,
      "dataframe['label_group']": 1,
      "self.train['session_title']": 1,
      "self.train['world']": 1,
      "data_train['enco_day']": 1,
      "data_train['original_language']": 1,
      "train_final_df['primary_use']": 1,
      "test_final_df['primary_use']": 1,
      "frame['landmark_id']": 1,
      "np.array(train.nom_5).flatten()": 1,
      "['HEPG2', 'HUVEC', 'RPE', 'U2OS']": 1,
      "bureau_balance['STATUS'].astype(str)": 1,
      "POS_CASH_b[f].astype(str)": 1,
      "credit_cb[f].astype(str)": 1,
      "installments_pay[f].astype(str)": 1,
      "stores['store_nbr'].values": 1,
      "stores['cluster'].values": 1,
      "items['item_nbr'].values": 1,
      "items['class'].values": 1,
      "list(train['snap'].astype(str).values)": 1,
      "list(train[col].astype(str).values)": 1,
      "list(train['state_event_name'].astype(str).values)": 1,
      "list(train['state_event_type'].astype(str).values)": 1,
      "list(train['cat_state'].astype(str).values)": 1,
      "list(train['month_item_id'].astype(str).values)": 1,
      "list(train['item_event_name'].astype(str).values)": 1,
      "list(train['item_event_type'].astype(str).values)": 1,
      "shop_data['city']": 1,
      "item_category_data['type']": 1,
      "item_category_data['subtype']": 1,
      "train[col].astype(str)": 1,
      "test[col].astype(str)": 1,
      "ytrain_df['surface']": 1,
      "data_train.Interaction": 1,
      "df_all[lcn]": 1,
      "stores['air_genre_name'].map(lambda _: str(str(_).split(' ')[i]) if len(str(_).split(' ')) > i else '')": 1,
      "stores['air_area_name'].map(lambda _: str(str(_).split(' ')[i]) if len(str(_).split(' ')) > i else '')": 1,
      "encoded_titanic_data.Sex.values": 1,
      "encoded_titanic_data.Embarked.values": 1,
      "encoded_titanic_data.Cabin.values": 1,
      "df[group].astype(str).values": 1,
      "x[:, 12]": 1,
      "x[:, 11]": 1,
      "x_test[:, 11]": 1,
      "train['v3']": 1,
      "train['v22']": 1,
      "train['v24']": 1,
      "train['v30']": 1,
      "train['v31']": 1,
      "train['v47']": 1,
      "train['v52']": 1,
      "train['v56']": 1,
      "train['v66']": 1,
      "train['v71']": 1,
      "train['v74']": 1,
      "train['v75']": 1,
      "train['v79']": 1,
      "train['v91']": 1,
      "train['v107']": 1,
      "train['v110']": 1,
      "train['v112']": 1,
      "train['v113']": 1,
      "train['v125']": 1,
      "test['v3']": 1,
      "test['v22']": 1,
      "test['v24']": 1,
      "test['v30']": 1,
      "test['v31']": 1,
      "test['v47']": 1,
      "test['v52']": 1,
      "test['v56']": 1,
      "test['v66']": 1,
      "test['v71']": 1,
      "test['v74']": 1,
      "test['v75']": 1,
      "test['v79']": 1,
      "test['v91']": 1,
      "test['v107']": 1,
      "test['v110']": 1,
      "test['v112']": 1,
      "test['v113']": 1,
      "test['v125']": 1,
      "data_1.ID": 1,
      "ID_2": 1,
      "data['place_id']": 1,
      "test_features['cp_type']": 1,
      "test_features['cp_dose']": 1,
      "y[:, 1]": 1,
      "train_data[feat].astype(str)": 1,
      "test_data[feat].astype(str)": 1,
      "train[['Sex']].values.ravel()": 1,
      "test[['Sex']].values.ravel()": 1,
      "indep_data[:, 2]": 1,
      "test_data[:, 2]": 1,
      "y_validate": 1,
      "items_data['item_category_name']": 1,
      "shops_data['center']": 1,
      "data['price_bins']": 1,
      "dffin['assetCode'].astype('str')": 1,
      "df_train['type'].astype('str')": 1,
      "df_train['atom_1'].astype('str')": 1,
      "df_test['type'].astype('str')": 1,
      "df_test['atom_1'].astype('str')": 1,
      "item_ctgrs.type_category": 1,
      "df['cat4']": 1,
      "df['cat5']": 1,
      "df['brand_name']": 1,
      "df['brand1']": 1,
      "df['cat2']": 1,
      "df['cat3']": 1,
      "df['item_condition_id']": 1,
      "df['shipping']": 1,
      "X_label[c]": 1,
      "X_test_full[i]": 1,
      "dtrain['type']": 1,
      "x[:, 2]": 1,
      "xtest[:, 2]": 1,
      "xtest[:, 0]": 1,
      "train['Trap'].values": 1,
      "test['Trap'].values": 1,
      "train_df['Id']": 1,
      "train_df.ip": 1,
      "train_df.device": 1,
      "train_df.os": 1,
      "train_df.channel": 1,
      "train_df.app": 1,
      "X.title": 1,
      "X.type": 1,
      "X.world": 1,
      "data['keyword']": 1,
      "tr_set[:, i]": 1,
      "df_test[x].astype(str)": 1,
      "master[col].astype(str).values": 1,
      "df[word_cols].values.flatten()": 1,
      "train['display_address'].astype('str')": 1,
      "dfCateg.grupo.values": 1,
      "dfShops['city']": 1,
      "weekdays": 1,
      "features.values[:, i]": 1,
      "Labels[0:]": 1,
      "class_labels": 1,
      "combined['Sex']": 1,
      "big_df[label_feature].values": 1,
      "df_item_categories['type']": 1,
      "df_item_categories['subtype']": 1,
      "dates[i].astype('str')": 1,
      "item_categories['cat1']": 1,
      "item_categories['cat2']": 1,
      "higgs['Label']": 1,
      "cats['subtype'].fillna('xxx')": 1,
      "items['item_f1'].fillna('xxx')": 1,
      "items['item_f2'].fillna('xxx')": 1,
      "x_tr.Country_Region": 1,
      "list(df[f].values)": 1,
      "df_comp['Deck']": 1,
      "feats['air_store_id'].append(sub_df4['air_store_id_x'])": 1,
      "train['Gene']": 1,
      "test['Gene']": 1,
      "df_train['Date']": 1,
      "df_t['Country_Region']": 1,
      "df_t['Date']": 1,
      "fullVisitorId": 1,
      "tmp['area_split_' + str(i + 1)]": 1,
      "tiendas['city']": 1,
      "tiendas['shop_type']": 1,
      "categorias['cat']": 1,
      "categorias['subcat']": 1,
      "input_data_clean.item_id": 1,
      "input_data_clean.item_category_id": 1,
      "input_data_clean.shop_id": 1,
      "input_data_clean.year": 1,
      "input_data_clean.month": 1,
      "input_data_clean.my_category": 1,
      "input_data_clean.date_block_num": 1,
      "transaction_data[high_card_trans_cols]": 1,
      "identity_data[col]": 1,
      "train['AdoptionSpeed']": 1,
      "sales[feature]": 1,
      "test_df.label_group": 1,
      "train_data_x[:, 0]": 1,
      "np.array(labels)": 1,
      "items['item_name_five']": 1,
      "rf_train.original_language": 1,
      "rf_test.original_language": 1,
      "df[target]": 1,
      "string_list": 1,
      "training_data['original_language']": 1,
      "training_data['status']": 1,
      "testing_data['original_language']": 1,
      "testing_data['status']": 1,
      "ic['type']": 1,
      "ic['subtype']": 1,
      "building['primary_use']": 1,
      "df.iloc[:, 1]": 1,
      "df.iloc[:, 5]": 1,
      "X['Province_State_x']": 1,
      "ds_test['Country_Region']": 1,
      "ds_test['Province_State_x']": 1,
      "cats['main_type']": 1,
      "cats['sub_type']": 1,
      "df[col].fillna('NA')": 1,
      "merged_data[each].astype(str)": 1,
      "df_all['Sex'].values": 1,
      "df_all[cat].values": 1,
      "df": 1,
      "df['Pclass']": 1,
      "df['Titles']": 1,
      "df['Family']": 1,
      "df_categories['type']": 1,
      "df_categories['subtype']": 1,
      "shops_df.city": 1,
      "item_cat['item']": 1,
      "item_cat['item_sub_category']": 1,
      "y_val": 1,
      "X_two.state": 1,
      "X_three.state": 1,
      "X_four.state": 1,
      "X_four.fiBaseModel": 1,
      "X_five.state": 1,
      "X_five.fiBaseModel": 1,
      "X_five.fiProductClassDesc": 1,
      "df_train_set_encode[cols]": 1,
      "df_test_set_encode[cols]": 1,
      "dataset[columns[j]]": 1,
      "dataset[columns[i]]": 1,
      "dataset[i]": 1,
      "test_data[i]": 1,
      "df_train[c]": 1,
      "bin_var": 1,
      "categories['subcats']": 1,
      "df_ytrain['surface']": 1,
      "big_X_imputed[feature]": 1,
      "all_df['MSZoning'].astype(str)": 1,
      "all_df['Exterior1st'].astype(str)": 1,
      "all_df['Exterior2nd'].astype(str)": 1,
      "all_df['KitchenQual'].astype(str)": 1,
      "all_df['Functional'].astype(str)": 1,
      "all_df['SaleType'].astype(str)": 1,
      "all_df['Street']": 1,
      "all_df['LotShape']": 1,
      "all_df['LandContour']": 1,
      "all_df['LotConfig']": 1,
      "all_df['LandSlope']": 1,
      "all_df['Neighborhood']": 1,
      "all_df['Condition1']": 1,
      "all_df['Condition2']": 1,
      "all_df['BldgType']": 1,
      "all_df['HouseStyle']": 1,
      "all_df['RoofStyle']": 1,
      "all_df['RoofMatl']": 1,
      "all_df['MasVnrType']": 1,
      "all_df['ExterQual']": 1,
      "all_df['ExterCond']": 1,
      "all_df['Foundation']": 1,
      "all_df['BsmtQual']": 1,
      "all_df['BsmtCond']": 1,
      "all_df['BsmtExposure']": 1,
      "all_df['BsmtFinType1']": 1,
      "all_df['BsmtFinType2']": 1,
      "all_df['Heating']": 1,
      "all_df['HeatingQC']": 1,
      "all_df['CentralAir']": 1,
      "all_df['Electrical']": 1,
      "all_df['GarageType']": 1,
      "all_df['GarageFinish']": 1,
      "all_df['GarageQual']": 1,
      "all_df['GarageCond']": 1,
      "all_df['PavedDrive']": 1,
      "all_df['SaleCondition']": 1,
      "np.array(y_train)": 1,
      "train_df['OutcomeType'].values": 1,
      "test_df['OutcomeType'].values": 1,
      "x_train['color']": 1,
      "item_category['type']": 1,
      "item_category['subtype']": 1,
      "tage": 1,
      "full_train_ds_pointer['label'].value": 1,
      "df['type'].astype('str')": 1,
      "list(X[f].values)": 1,
      "train['Sex'].values": 1,
      "train['Title'].values": 1,
      "test['Sex'].values": 1,
      "test['Title'].values": 1,
      "test_df1['Province_State']": 1,
      "test_df1['Country_Region']": 1,
      "xdat[cols]": 1,
      "xtrain[cols]": 1,
      "xfolds['StudyInstanceUID']": 1,
      "xfolds['SeriesInstanceUID']": 1,
      "train_df[name]": 1,
      "test_df[name]": 1,
      "df_concat.Wteam": 1,
      "df_concat.Lteam": 1,
      "all_data['language']": 1,
      "BE_data['action_type']": 1,
      "BE_data['season']": 1,
      "BE_data['combined_shot_type']": 1,
      "BE_data['shot_type']": 1,
      "BE_data['shot_zone_area']": 1,
      "BE_data['shot_zone_basic']": 1,
      "BE_data['shot_zone_range']": 1,
      "BE_data['team_name']": 1,
      "BE_data['opponent']": 1,
      "train_data['species']": 1,
      "temp_df['state_id']": 1,
      "dataset['Title']": 1,
      "dataset['Embarked'].fillna('S')": 1,
      "trainData['Country_Region']": 1,
      "titanic['Sex'].values": 1,
      "train_merged[c].astype(str)": 1,
      "list(all_data2[i])": 1,
      "split_groups": 1,
      "dum_df['FareBin']": 1,
      "df_train_features['cp_type'].tolist()": 1,
      "df_train_features['cp_dose'].tolist()": 1,
      "df_test_features['cp_type'].tolist()": 1,
      "df_test_features['cp_dose'].tolist()": 1,
      "data2[feature]": 1,
      "X_test[i]": 1,
      "X_train[j]": 1,
      "df_final[column]": 1,
      "matrix['country']": 1,
      "matrix['state']": 1,
      "matrix['Country_State']": 1,
      "lockdown.Level": 1,
      "subtrain.Country_Region": 1,
      "subtrain.Province_State": 1,
      "subtest.Country_Region": 1,
      "subtest.Province_State": 1,
      "Src_Data[feature]": 1,
      "df_train.sentiment == 'positive'": 1,
      "df_test.sentiment == 'positive'": 1,
      "df_train.sentiment == 'negative'": 1,
      "df_test.sentiment == 'negative'": 1,
      "data_train[data_train.columns[i]]": 1,
      "data_test[data_test.columns[i]]": 1,
      "X[:, 6]": 1,
      "X[:, 7]": 1,
      "X[:, 8]": 1,
      "X[:, 9]": 1,
      "X[:, 10]": 1,
      "X[:, 11]": 1,
      "X[:, 12]": 1,
      "X[:, 13]": 1,
      "X[:, 14]": 1,
      "X[:, 16]": 1,
      "X[:, 17]": 1,
      "X[:, 18]": 1,
      "X[:, 19]": 1,
      "X[:, 20]": 1,
      "X1[:, 3]": 1,
      "X1[:, 4]": 1,
      "X1[:, 5]": 1,
      "X1[:, 6]": 1,
      "X1[:, 7]": 1,
      "X1[:, 8]": 1,
      "X1[:, 9]": 1,
      "X1[:, 10]": 1,
      "X1[:, 11]": 1,
      "X1[:, 12]": 1,
      "X1[:, 13]": 1,
      "X1[:, 14]": 1,
      "X1[:, 16]": 1,
      "X1[:, 17]": 1,
      "X1[:, 18]": 1,
      "X1[:, 19]": 1,
      "X1[:, 20]": 1,
      "phone.device_model": 1,
      "train_data['Geo_Id']": 1,
      "Ytrain": 1,
      "D['item_cat1']": 1,
      "D['item_cat2']": 1,
      "df_target['surface']": 1,
      "data['holiday']['day_of_week']": 1,
      "img_id['Breed1']": 1,
      "tr_y": 1,
      "train.country_destination": 1,
      "df_combine[name].values": 1,
      "list(allData[col])": 1,
      "train_merge['primary_use']": 1,
      "train_data['original_language'].astype('str')": 1,
      "test_data['original_language'].astype('str')": 1,
      "donation_paths['location_professionals']": 1,
      "donation_paths['word_hashtag']": 1,
      "donation_paths1['location_professionals']": 1,
      "donation_paths2['professionals_industry']": 1,
      "X['SmokingStatus']": 1,
      "test_X['Sex']": 1,
      "test_X['SmokingStatus']": 1,
      "pred['Country_Region']": 1,
      "pred['Province_State']": 1,
      "text": 1,
      "train_d[col]": 1,
      "test_d[col]": 1,
      "OH_X_train[col]": 1,
      "OH_X_tset[col]": 1,
      "train_test_monthly['city']": 1,
      "train_test_monthly['type']": 1,
      "train_test_monthly['sub_type']": 1,
      "train_test_monthly['shop_item_id']": 1,
      "train_test_monthly['shop_cat_id']": 1,
      "train_test_monthly['shop_type_id']": 1,
      "train_test_monthly['item_city_id']": 1,
      "train_test_monthly['item_city_month']": 1,
      "train_test_monthly['shop_item_month']": 1,
      "train_test_monthly['shop_cat_month']": 1,
      "train_test_monthly['shop_type_month']": 1,
      "train_data.word": 1,
      "train['cat5']": 1,
      "categories['category']": 1,
      "categories['sub_category']": 1,
      "shops['name_of_shop']": 1,
      "encoded['Turf']": 1,
      "encoded['diffScoreBeforePlay_binary_ob']": 1,
      "train_1.Countries": 1,
      "train_1['States']": 1,
      "te.Countries": 1,
      "te['States']": 1,
      "X_tra.Countries": 1,
      "X_tra['States']": 1,
      "X_te.Countries": 1,
      "X_te['States']": 1,
      "df['interest_level']": 1,
      "h.SMALL_AREA_NAME.values": 1,
      "train_data['label_group']": 1,
      "train_data[feat].fillna('-1')": 1,
      "train_data[TARGET_NAME]": 1,
      "label_train": 1,
      "train_data['County']": 1,
      "traintest_df['Country']": 1,
      "traintest_df['Province']": 1,
      "traintest_df['Country_Province']": 1,
      "traintest_df['country_alpha_2_code']": 1,
      "traintest_df['country_alpha_3_code']": 1,
      "traintest_df['leader']": 1,
      "traintest_df['government']": 1,
      "traintest_df['World_Bank_Name']": 1,
      "traintest_df['Type']": 1,
      "train_dataset.Province_State": 1,
      "train_dataset.Country_Region": 1,
      "test_dataset.Province_State": 1,
      "test_dataset.Country_Region": 1,
      "df_train.target": 1,
      "df['Appellation']": 1,
      "spain_train['Date']": 1,
      "store['air_genre_name']": 1,
      "store['prefecture']": 1,
      "submission['Sex']": 1,
      "group['world']": 1,
      "group['game_session']": 1,
      "X[x]": 1,
      "Sub_test[x]": 1,
      "meter_df['primary_use']": 1,
      "temp_df['primary_use']": 1,
      "combo['Target']": 1,
      "combo['Location']": 1,
      "X_train.primary_use": 1,
      "np.hstack((training_merge_df['Gene'].values.ravel(), testing_merge_df['Gene'].values.ravel()))": 1,
      "np.hstack((training_merge_df['Variation'].values.ravel(), testing_merge_df['Variation'].values.ravel()))": 1,
      "df_train['toxic?']": 1,
      "item_categories['item_category_name_2']": 1,
      "df_concat[field].values": 1,
      "test_y": 1,
      "sessions_df['device']": 1,
      "label_X_train[col]": 1,
      "df1[col]": 1,
      "item_categories.large_category": 1,
      "cats_train[column]": 1,
      "cats_test[column]": 1,
      "test['cat10']": 1,
      "df[columns]": 1,
      "complete_data['target']": 1,
      "t1 + t2": 1,
      "df_block['city']": 1,
      "df_block['type']": 1,
      "df_block['subtype']": 1,
      "df['landmark_id']": 1,
      "all_data['Name']": 1,
      "all_data['Sex']": 1,
      "all_data['Ticket'].astype(str)": 1,
      "all_data['Cabin']": 1,
      "all_data['Embarked'].astype(str)": 1,
      "df['block']": 1,
      "train['Pclass']": 1,
      "test['Pclass']": 1,
      "train['c_p']": 1,
      "X.loc[:, var]": 1,
      "data_train['Type']": 1,
      "data_train['IsHoliday']": 1,
      "data_test['Type']": 1,
      "data_test['IsHoliday']": 1,
      "lr_submission.Survived.values": 1,
      "tabnet_submission.Survived.values": 1,
      "lr_submission.Survived": 1,
      "tabnet_submission.Survived": 1,
      "train['County']": 1,
      "test['County']": 1,
      "df_all['City Group']": 1,
      "df_all['Type']": 1,
      "shop['shop_category']": 1,
      "train['type'].map(lambda x: str(x)[i])": 1,
      "list_categ": 1,
      "df_train_tran_id[[col]]": 1,
      "df_test_tran_id[[col]]": 1,
      "df_train_tran[[cat_cols[i]]]": 1,
      "df_test_tran[[cat_cols[i]]]": 1,
      "test[j]": 1,
      "X_train['prior_question_had_explanation']": 1,
      "X_test['prior_question_had_explanation']": 1,
      "df_train['prior_question_had_explanation']": 1,
      "train_data.Sex.values": 1,
      "train_data.Embarked.values": 1,
      "train['landmark_id']": 1,
      "target_cat": 1,
      "building_meta_df['primary_use']": 1,
      "train_data['prior_question_had_explanation']": 1,
      "lecture['type_of']": 1,
      "categories['type_code']": 1,
      "train['MSZoning'].astype('str')": 1,
      "train['Street'].astype('str')": 1,
      "train['LotShape'].astype('str')": 1,
      "train['LandContour'].astype('str')": 1,
      "train['Utilities'].astype('str')": 1,
      "train['LotConfig'].astype('str')": 1,
      "train['LandSlope'].astype('str')": 1,
      "train['Neighborhood'].astype('str')": 1,
      "train['Condition1'].astype('str')": 1,
      "train['Condition2'].astype('str')": 1,
      "train['BldgType'].astype('str')": 1,
      "train['HouseStyle'].astype('str')": 1,
      "train['RoofStyle'].astype('str')": 1,
      "train['RoofMatl'].astype('str')": 1,
      "train['Exterior1st'].astype('str')": 1,
      "train['Exterior2nd'].astype('str')": 1,
      "train['ExterQual'].astype('str')": 1,
      "train['ExterCond'].astype('str')": 1,
      "train['Foundation'].astype('str')": 1,
      "train['BsmtQual'].astype('str')": 1,
      "train['BsmtCond'].astype('str')": 1,
      "train['BsmtExposure'].astype('str')": 1,
      "train['BsmtFinType1'].astype('str')": 1,
      "train['BsmtFinType2'].astype('str')": 1,
      "train['Heating'].astype('str')": 1,
      "train['HeatingQC'].astype('str')": 1,
      "train['CentralAir'].astype('str')": 1,
      "train['Electrical'].astype('str')": 1,
      "train['KitchenQual'].astype('str')": 1,
      "train['Functional'].astype('str')": 1,
      "train['GarageType'].astype('str')": 1,
      "train['GarageFinish'].astype('str')": 1,
      "train['GarageQual'].astype('str')": 1,
      "train['GarageCond'].astype('str')": 1,
      "train['PavedDrive'].astype('str')": 1,
      "train['SaleType'].astype('str')": 1,
      "train['SaleCondition'].astype('str')": 1,
      "df2['Embarked']": 1,
      "df['surface']": 1,
      "train.category_main": 1,
      "train.subcat_1": 1,
      "train.subcat_2": 1,
      "train.brand_name": 1,
      "test.category_main": 1,
      "test.subcat_1": 1,
      "test.subcat_2": 1,
      "test.brand_name": 1,
      "train_data.iloc[:, 0].values": 1,
      "train_data.iloc[:, 4].values": 1,
      "test_data.iloc[:, 4].values": 1,
      "train_df[col].astype(str)": 1,
      "train_df.iloc[:, 6].values": 1,
      "insurance.smoker": 1,
      "insurance.region": 1,
      "df_features['IsHoliday']": 1,
      "df_train['IsHoliday']": 1,
      "df_test['IsHoliday']": 1,
      "df_store['Size']": 1,
      "df_store['Type']": 1,
      "X.iloc[:, 2]": 1,
      "X.iloc[:, 1]": 1,
      "X_test.iloc[:, 2]": 1,
      "X_test.iloc[:, 1]": 1,
      "data['signup_method']": 1,
      "data['language']": 1,
      "data['affiliate_channel']": 1,
      "data['affiliate_provider']": 1,
      "data['signup_app']": 1,
      "data['first_device_type']": 1,
      "data['first_browser']": 1,
      "df1['Province_State']": 1,
      "z": 1,
      "test['license']": 1,
      "df['LandContour']": 1,
      "df['PoolQC']": 1,
      "df['Fence']": 1,
      "df['MiscFeature']": 1,
      "df['SaleCondition']": 1,
      "df['Alley']": 1,
      "df['LotConfig']": 1,
      "df['LandSlope']": 1,
      "df['Condition1']": 1,
      "df['Condition2']": 1,
      "df['BldgType']": 1,
      "df['HouseStyle']": 1,
      "df['OverallQual']": 1,
      "df['RoofStyle']": 1,
      "df['RoofMatl']": 1,
      "df['MasVnrType']": 1,
      "df['ExterQual']": 1,
      "df['ExterCond']": 1,
      "df['Foundation']": 1,
      "df['BsmtExposure']": 1,
      "df['PavedDrive']": 1,
      "df['Heating']": 1,
      "df['HeatingQC']": 1,
      "df['GarageType']": 1,
      "df['CentralAir']": 1,
      "df['FireplaceQu']": 1,
      "test_data['LandContour']": 1,
      "test_data['Utilities']": 1,
      "test_data['PoolQC']": 1,
      "test_data['Fence']": 1,
      "test_data['MiscFeature']": 1,
      "test_data['SaleType']": 1,
      "test_data['SaleCondition']": 1,
      "test_data['Alley']": 1,
      "test_data['LotConfig']": 1,
      "test_data['LandSlope']": 1,
      "test_data['Neighborhood']": 1,
      "test_data['Condition1']": 1,
      "test_data['Condition2']": 1,
      "test_data['BldgType']": 1,
      "test_data['HouseStyle']": 1,
      "test_data['OverallQual']": 1,
      "test_data['RoofStyle']": 1,
      "test_data['RoofMatl']": 1,
      "test_data['Exterior1st']": 1,
      "test_data['Exterior2nd']": 1,
      "test_data['MasVnrType']": 1,
      "test_data['ExterQual']": 1,
      "test_data['ExterCond']": 1,
      "test_data['Foundation']": 1,
      "test_data['BsmtExposure']": 1,
      "test_data['PavedDrive']": 1,
      "test_data['Functional']": 1,
      "test_data['KitchenQual']": 1,
      "test_data['GarageQual']": 1,
      "test_data['GarageCond']": 1,
      "test_data['BsmtFinType2']": 1,
      "test_data['Heating']": 1,
      "test_data['Electrical']": 1,
      "test_data['HeatingQC']": 1,
      "test_data['GarageType']": 1,
      "test_data['FireplaceQu']": 1,
      "[recipe['cuisine'] for recipe in training_data]": 1,
      "train_csv.iloc[:, 5]": 1,
      "train_csv.iloc[:, 6]": 1,
      "animals[col]": 1,
      "df[feature].astype(str)": 1,
      "X['addr1_card1']": 1,
      "all_df['air_store_id']": 1,
      "all_df['visit_date']": 1,
      "holiday_df['visit_date'].dt.dayofweek": 1,
      "holiday_df8.apply(lambda x: str(x['holiday_flg']) + str(x['dow']), axis=1)": 1,
      "shops.type": 1,
      "df['AnimalType']": 1,
      "df['SexuponOutcome']": 1,
      "df['Color_1']": 1,
      "df['Color_2']": 1,
      "train['OutcomeSubtype']": 1,
      "train_data['{}'.format(i)]": 1,
      "test_data['{}'.format(i)]": 1,
      "X_train['pickup_borough']": 1,
      "X.Embarked": 1,
      "X.Sex": 1,
      "train_test.keyword.values": 1,
      "train_data['AgeBin']": 1,
      "train_data['FareBin']": 1,
      "test_data['AgeBin']": 1,
      "test_data['FareBin']": 1,
      "X['primary_use']": 1,
      "df.year.values": 1,
      "train_X[col]": 1,
      "df_obj[col]": 1,
      "X_train['AdoptionSpeed']": 1,
      "item_cat['main_category_id']": 1,
      "item_cat['sub_category_id']": 1,
      "mdata[cat_name]": 1,
      "train_df_Y['surface']": 1,
      "df_test_2['day_name']": 1,
      "df_cats['cat_type']": 1,
      "df_cats['cat_subtype']": 1,
      "df_shops['cat_tienda']": 1,
      "df5['store_type']": 1,
      "y_train['combined_tar']": 1,
      "FinalTrainData['X0']": 1,
      "FinalTrainData['X1']": 1,
      "FinalTrainData['X2']": 1,
      "FinalTrainData['X3']": 1,
      "FinalTrainData['X5']": 1,
      "FinalTrainData['X6']": 1,
      "FinalTrainData['X8']": 1,
      "['paris', 'paris', 'tokyo', 'amsterdam']": 1,
      "train['msno']": 1,
      "train['song_id']": 1,
      "list(train[col].values)": 1,
      "list(test[col].values)": 1,
      "targets_tr": 1,
      "df['Id']": 1,
      "X_train[i].values": 1,
      "Y.values.tolist()": 1,
      "data.Sex": 1,
      "data.Embarked": 1,
      "data.Age_group": 1,
      "data.Fare_group": 1,
      "data.Title": 1,
      "spotify_music_other_df.artist": 1,
      "train['target_raw'].values": 1,
      "mf[cat]": 1,
      "tf[cat]": 1,
      "train_tc.id": 1,
      "alldata['idhogar']": 1,
      "only_carrier[col]": 1,
      "train_x_full['Country_Region']": 1,
      "train.Country": 1,
      "train.State": 1,
      "test.Country": 1,
      "test.State": 1,
      "df_store[p].values.astype(str)": 1,
      "df_train.StateHoliday.values.astype(str)": 1,
      "df_test.StateHoliday.values.astype(str)": 1,
      "train_attributes['County']": 1,
      "train_attributes['Province_State']": 1,
      "train_attributes['Country_Region']": 1,
      "train_attributes['Date']": 1,
      "train_target_class['Target']": 1,
      "test_attributes['County']": 1,
      "test_attributes['Province_State']": 1,
      "test_attributes['Country_Region']": 1,
      "test_attributes['Date']": 1,
      "test_target_class['Target']": 1,
      "train.iloc[:, i]": 1,
      "X[cname]": 1,
      "data_test[cname]": 1,
      "np.char.add(self.df.toxic.values.astype(str), self.df.lang.values).reshape(-1, 1)": 1,
      "train.grapheme_root.values": 1,
      "train.consonant_diacritic.values": 1,
      "df['anatom_site_general_challenge_feat']": 1,
      "train_df['diagnosis']": 1,
      "main_cat": 1,
      "sub_cat": 1,
      "X_Train['Location']": 1,
      "X_Train['County']": 1,
      "X_Train['Country_Region']": 1,
      "X_Train['Target']": 1,
      "X_Pred['Location']": 1,
      "X_Pred['County']": 1,
      "X_Pred['Province_State']": 1,
      "X_Pred['Country_Region']": 1,
      "X_Pred['Target']": 1,
      "catgs['type']": 1,
      "catgs['subtype']": 1,
      "X['store_and_fwd_flag']": 1,
      "X_train['store_and_fwd_flag']": 1,
      "X_test['store_and_fwd_flag']": 1,
      "mtrain['event']": 1,
      "all_data[i].astype(str)": 1,
      "Y_train_df['surface']": 1,
      "allData.category_name.ravel()": 1,
      "allData.brand_name.str.lower()": 1,
      "allData.item_condition_id": 1,
      "allData.shipping": 1,
      "label_df['breed']": 1,
      "data_train.NAME_TYPE_SUITE.replace(np.nan, 'Unknown')": 1,
      "data_train.NAME_EDUCATION_TYPE": 1,
      "data['Ticket'].values.reshape(-1, 1)": 1,
      "data['First'].values.reshape(-1, 1)": 1,
      "deck.reshape(-1, 1)": 1,
      "df_train['var_68']": 1,
      "train.bin_3": 1,
      "train_df['language']": 1,
      "test_df['language']": 1,
      "train_df['lang_abv']": 1,
      "test_df['lang_abv']": 1,
      "df['sex']": 1,
      "train_info['landmark_id'].values": 1,
      "plays2['passResult']": 1,
      "test_data.iloc[:, 2]": 1,
      "train_data.iloc[:, 2]": 1,
      "train_data.iloc[:, -2]": 1,
      "test_data.iloc[:, -1]": 1,
      "train_meta[[column]]": 1,
      "pc['Product_Info_2']": 1,
      "pc_test_rev['Product_Info_2']": 1,
      "data_train[col].astype(str)": 1,
      "data_test[col].astype(str)": 1,
      "data_train[col]": 1,
      "data_test[col]": 1,
      "target_raw['surface']": 1,
      "X['EntryStreetName']": 1,
      "test_df['EntryStreetName']": 1,
      "X['ExitStreetName']": 1,
      "test_df['ExitStreetName']": 1,
      "sales_cleaned_df.cats": 1,
      "train_df_pop['Country_Region']": 1,
      "test_df_pop['Country_Region']": 1,
      "train_copy['Country']": 1,
      "train_copy['State']": 1,
      "test_copy['Country']": 1,
      "test_copy['State']": 1,
      "df[cols]": 1,
      "train[c].values.reshape((-1, 1))": 1,
      "test[c].values.reshape((-1, 1))": 1,
      "train_csv['anatom_site_general_challenge']": 1,
      "test_csv['anatom_site_general_challenge']": 1,
      "column_as_df[col_].values": 1,
      "y_trn['surface']": 1,
      "train[c].astype(str)": 1,
      "training['type_of']": 1,
      "training['reading_section']": 1,
      "training['prior_question_had_explanation']": 1,
      "traindata['cuisine']": 1,
      "_CombinedData['class'].to_numpy()": 1,
      "df_train_building_left['primary_use']": 1,
      "bureau[col].fillna('nan')": 1,
      "item_cat['item_macro_categ']": 1,
      "item_cat['item_subcateg']": 1,
      "df['color']": 1,
      "df_train['Target']": 1,
      "df_test['Target']": 1,
      "test['store_and_fwd_flag']": 1,
      "train['Address']": 1,
      "test['Address']": 1,
      "df_train['Label']": 1,
      "train[col].append(test[col])": 1,
      "questions['tags']": 1,
      "test[cat]": 1,
      "df['Binned_Age']": 1,
      "df['Binned_fare']": 1,
      "train_new.sex.astype('str')": 1,
      "train_new.anatom_site_general_challenge.astype('str')": 1,
      "dfle": 1,
      "data1[:, 6]": 1,
      "data1[:, 7]": 1,
      "data1[:, 8]": 1,
      "data1[:, 10]": 1,
      "data1[:, 11]": 1,
      "data1[:, 12]": 1,
      "data1[:, 13]": 1,
      "data1[:, 14]": 1,
      "data1[:, 15]": 1,
      "data1[:, 16]": 1,
      "data1[:, 17]": 1,
      "data1[:, 24]": 1,
      "data1[:, 32]": 1,
      "data1[:, 33]": 1,
      "testdata1[:, 6]": 1,
      "testdata1[:, 7]": 1,
      "testdata1[:, 8]": 1,
      "testdata1[:, 10]": 1,
      "testdata1[:, 11]": 1,
      "testdata1[:, 12]": 1,
      "testdata1[:, 13]": 1,
      "testdata1[:, 14]": 1,
      "testdata1[:, 15]": 1,
      "testdata1[:, 16]": 1,
      "testdata1[:, 17]": 1,
      "testdata1[:, 24]": 1,
      "testdata1[:, 32]": 1,
      "testdata1[:, 33]": 1,
      "df_train.ord_3": 1,
      "df_train.ord_4": 1,
      "df_train.ord_5": 1,
      "df_test.ord_3": 1,
      "df_test.ord_4": 1,
      "df_test.ord_5": 1,
      "train_data[colname].astype(str)": 1,
      "test_data[colname].astype(str)": 1,
      "train_data[col].astype(str)": 1,
      "test_data[col].astype(str)": 1,
      "test.Date": 1,
      "df_train_sales_eda['shop_name']": 1,
      "df_train_sales_eda['item_category_name']": 1,
      "train_modified['Cabin']": 1,
      "test_modified['Cabin']": 1,
      "df.loc[:, 'Country']": 1,
      "df.loc[:, 'State']": 1,
      "combined_data.loc[:, col].astype('str')": 1,
      "x_features.Country_Region": 1,
      "X_features.Country_Region": 1,
      "all_data.date": 1,
      "train[col].astype('str')": 1,
      "test[col].astype('str')": 1,
      "train_df_encoded.State": 1,
      "train_df_encoded.Country": 1,
      "test_df_encoded.State": 1,
      "test_df_encoded.Country": 1,
      "covid_train['Province_State']": 1,
      "covid_train['Country_Region']": 1,
      "df['cuisine'].values": 1,
      "test[c]": 1,
      "train_C14['target']": 1,
      "train_C23['target']": 1,
      "train_C12['target']": 1,
      "train_C24['target']": 1,
      "df[f]": 1,
      "train_df[feat]": 1,
      "df[feat]": 1,
      "train['state']": 1,
      "train['country']": 1,
      "test['state']": 1,
      "test['country']": 1,
      "df[col].fillna('-1').astype(str).values": 1,
      "train0[col]": 1,
      "x_test0[col]": 1,
      "df_tran_tr.R_emaildomain": 1,
      "df_tran_ts.R_emaildomain": 1,
      "df_tran_tr.P_emaildomain": 1,
      "df_tran_ts.P_emaildomain": 1,
      "df_tran_tr.ProductCD": 1,
      "df_tran_ts.ProductCD": 1,
      "df_tran_tr.card4": 1,
      "df_tran_tr.card6": 1,
      "df_tran_ts.card4": 1,
      "df_tran_ts.card6": 1,
      "y['Cuisine']": 1,
      "stores.air_genre_name": 1,
      "stores.air_area_name": 1,
      "df_dataset.cmb_latlong": 1,
      "data_chr[i]": 1,
      "X[:, 2]": 1,
      "X_final[:, 2]": 1,
      "X_final[:, 0]": 1,
      "crime_data['Category']": 1,
      "train.AnimalType": 1,
      "train.SexuponOutcome": 1,
      "train.Color": 1,
      "test.AnimalType": 1,
      "test.SexuponOutcome": 1,
      "test.Color": 1,
      "df[column].astype(str)": 1,
      "train_df[col].astype('str')": 1,
      "test_df[col].astype('str')": 1,
      "dataset['Color_1']": 1,
      "dataset['Breed_1']": 1,
      "df_train_store[col].astype('str')": 1,
      "X.loc[unmissed_embark, 'embarked']": 1,
      "train[col].fillna('N/A').astype(str)": 1,
      "train_data.cuisine": 1,
      "gtype": 1,
      "x_data_df[col]": 1,
      "train_set[column].values.reshape(-1, 1)": 1,
      "df_test_set[column].values.reshape(-1, 1)": 1,
      "df.event_type_1": 1,
      "df.event_name_1": 1,
      "df.event_type_2": 1,
      "df.event_name_2": 1,
      "df.dept_id": 1,
      "df.cat_id": 1,
      "df.store_id": 1,
      "df.item_id": 1,
      "df.state_id": 1,
      "item_categories.type_code": 1,
      "train['SalesField7']": 1,
      "X.assetCode_asset": 1,
      "X.assetCode_exchange": 1,
      "df['cp_time']": 1,
      "df['cp_dose']": 1,
      "train['Foundation']": 1,
      "train['RoofStyle']": 1,
      "train['CentralAir']": 1,
      "train['BldgType']": 1,
      "test['Foundation']": 1,
      "test['RoofStyle']": 1,
      "test['CentralAir']": 1,
      "test['BldgType']": 1,
      "train['ord_3']": 1,
      "train['ord_4']": 1,
      "train['ord_5']": 1,
      "df['AgeBin']": 1,
      "df['FareBin']": 1,
      "df_test['Title']": 1,
      "df_test['AgeBin']": 1,
      "df_test['FareBin']": 1,
      "data['AgeBin']": 1,
      "data['FareBin']": 1,
      "train['Position']": 1,
      "data['IsHoliday']": 1,
      "data['Type']": 1,
      "item_cat['sub_category']": 1,
      "T['teacher_id']": 1,
      "all_data['city']": 1,
      "all_data['main_category']": 1,
      "all_data['secondary_category']": 1,
      "tmp['city']": 1,
      "tmp['shop_type']": 1,
      "tmp['main_category']": 1,
      "tmp['secondary_category']": 1,
      "data_by_month['city']": 1,
      "data_by_month['main_category']": 1,
      "data_by_month['secondary_category']": 1,
      "data['source']": 1,
      "data['SmokingStatus']": 1,
      "df_train['favourite_merchant']": 1,
      "df_test['favourite_merchant']": 1,
      "y_train_labels": 1,
      "item_categories_plus['main_category']": 1,
      "item_categories_plus['sub_category']": 1,
      "shops_plus['shop_city']": 1,
      "df['Target']": 1,
      "df['channelGrouping'].astype(str)": 1,
      "df['browser'].astype(str)": 1,
      "df['deviceCategory'].astype(str)": 1,
      "df['operatingSystem'].astype(str)": 1,
      "df['continent'].astype(str)": 1,
      "df['subContinent'].astype(str)": 1,
      "df['region'].astype(str)": 1,
      "df['country'].astype(str)": 1,
      "df['city'].astype(str)": 1,
      "df['campaign'].astype(str)": 1,
      "df['keyword'].astype(str)": 1,
      "df['medium'].astype(str)": 1,
      "df['source'].astype(str)": 1,
      "df['adNetworkType'].astype(str)": 1,
      "test_df['channelGrouping'].astype(str)": 1,
      "test_df['browser'].astype(str)": 1,
      "test_df['deviceCategory'].astype(str)": 1,
      "test_df['operatingSystem'].astype(str)": 1,
      "test_df['continent'].astype(str)": 1,
      "test_df['subContinent'].astype(str)": 1,
      "test_df['region'].astype(str)": 1,
      "test_df['country'].astype(str)": 1,
      "test_df['city'].astype(str)": 1,
      "test_df['campaign'].astype(str)": 1,
      "test_df['keyword'].astype(str)": 1,
      "test_df['medium'].astype(str)": 1,
      "test_df['source'].astype(str)": 1,
      "test_df['adNetworkType'].astype(str)": 1,
      "data['_collection_name'].map(str)": 1,
      "train_data['ebird_code']": 1,
      "cleansed['Tire_Size']": 1,
      "data['label']": 1,
      "train['image_name']": 1,
      "train['patient_id']": 1,
      "z['image_name']": 1,
      "z['patient_id']": 1,
      "z['sex']": 1,
      "z['anatom_site_general_challenge']": 1,
      "merged_df[feature]": 1,
      "merged_df[bin_feature]": 1,
      "df_shop.category": 1,
      "df_shop.city": 1,
      "df_item_cat.type_code": 1,
      "df_item_cat['subtype']": 1,
      "df_item.name2": 1,
      "df_item.name3": 1,
      "train['color']": 1,
      "test1['color']": 1,
      "dataset_y['Country_Region']": 1,
      "X['Type']": 1,
      "X['City Group']": 1,
      "dataset['class']": 1,
      "df['Province_State'].astype(str)": 1,
      "df['Country_Region'].astype(str)": 1,
      "concat_df[column]": 1,
      "concat[column]": 1,
      "df_train['cat0']": 1,
      "df_train['cat1']": 1,
      "df_train['cat2']": 1,
      "df_train['cat3']": 1,
      "df_train['cat4']": 1,
      "df_train['cat5']": 1,
      "df_train['cat6']": 1,
      "df_train['cat7']": 1,
      "df_train['cat8']": 1,
      "df_train['cat9']": 1,
      "test_df['cat0']": 1,
      "test_df['cat1']": 1,
      "test_df['cat2']": 1,
      "test_df['cat3']": 1,
      "test_df['cat4']": 1,
      "test_df['cat5']": 1,
      "test_df['cat6']": 1,
      "test_df['cat7']": 1,
      "test_df['cat8']": 1,
      "test_df['cat9']": 1,
      "lockdown_geo[col].astype(str)": 1,
      "hits.target": 1,
      "list(alldata[c].values)": 1,
      "df['Block']": 1,
      "train_data.species": 1,
      "train_new[e]": 1,
      "list(previous_application[c].values.astype('str'))": 1,
      "list(POS_CASH_balance[c].values.astype('str'))": 1,
      "list(installments_payments[c].values.astype('str'))": 1,
      "list(credit_card_balance[c].values.astype('str'))": 1,
      "data['Deck']": 1,
      "cleaned_data['Country_Region']": 1,
      "concat_df[e]": 1,
      "Y_val": 1,
      "features[c]": 1,
      "df_test[c]": 1,
      "train['nom_0']": 1,
      "df[col].fillna('Missing')": 1,
      "train_df.author": 1,
      "df_new['WSeed']": 1,
      "df_new['LSeed']": 1,
      "df_new['WLoc']": 1,
      "dftest['WSeed']": 1,
      "dftest['LSeed']": 1,
      "br.phone_brand": 1,
      "br.device_model": 1,
      "train.group": 1,
      "house_prices[feature]": 1,
      "df.StateHoliday": 1,
      "store.StoreType": 1,
      "store.Assortment": 1,
      "train_df['ProductCD']": 1,
      "test_df['ProductCD']": 1,
      "train1['atom1']": 1,
      "test['atom1']": 1,
      "train1['atom2']": 1,
      "test['atom2']": 1,
      "train1['coupling_type']": 1,
      "test['coupling_type']": 1,
      "train1['potential_energy']": 1,
      "test['potential_energy']": 1,
      "Y.values": 1,
      "train_df[c].values": 1,
      "test_df[c].values": 1,
      "trainData['cuisine']": 1,
      "x[:, 4]": 1,
      "xx[:, 4]": 1,
      "df[i].astype(str)": 1,
      "df[colname]": 1,
      "project[ft]": 1,
      "X['project_subject_categories']": 1,
      "X['project_subject_subcategories']": 1,
      "X['school_state']": 1,
      "train['premise']": 1,
      "train['hypothesis']": 1,
      "test['premise']": 1,
      "test['hypothesis']": 1,
      "data['Cabin']": 1,
      "data['Last Name']": 1,
      "df['First_Name']": 1,
      "df['Last_Name']": 1,
      "df['Cabin_Class']": 1,
      "data_df['Ticket']": 1,
      "data_df['Cabin']": 1,
      "data_df['Last Name']": 1,
      "data['Last']": 1,
      "data['Class']": 1,
      "data['Pclass']": 1,
      "df_train['target']": 1,
      "train_df['matchTypeReduced']": 1,
      "train_df['type']": 1,
      "train_df['Date']": 1,
      "test_df['Date']": 1,
      "concate_both[col]": 1,
      "cat_array": 1,
      "df_store.StoreType": 1,
      "df_store.Assortment": 1,
      "shop.type": 1,
      "shop.city": 1,
      "item_category.item_type": 1,
      "item_category.item_name": 1,
      "item.sub_name1": 1,
      "item.sub_name2": 1,
      "df5['experiment']": 1,
      "data['bin_3'].values": 1,
      "data['bin_4'].values": 1,
      "df_rossman['StateHoliday']": 1,
      "df_test['StateHoliday']": 1,
      "df_store['StoreType']": 1,
      "df_store['Assortment']": 1,
      "train['Resolution']": 1,
      "train['X']": 1,
      "train['Y']": 1,
      "train_df.target": 1,
      "df['label_group'].to_numpy()": 1,
      "train_csv['Id']": 1,
      "data['Comment Behavor']": 1,
      "X['Name'].astype(str)": 1,
      "new_target['surface']": 1,
      "x_test['Sex']": 1,
      "x_test['Embarked']": 1,
      "X_test[:, 3]": 1,
      "valid_df['prior_question_had_explanation']": 1,
      "last_df['prior_question_had_explanation']": 1,
      "data.loc[:, 'matchType']": 1,
      "X_test.loc[:, 'matchType']": 1,
      "new_values": 1,
      "cat['type']": 1,
      "cat['subtype']": 1,
      "data1.variation": 1,
      "data1.opening": 1,
      "interactions[naming]": 1,
      "alldata.Id": 1,
      "cats_e['type']": 1,
      "cats_e['subtype']": 1,
      "items.item_name_first3_e.values": 1,
      "items.item_name_first5_e.values": 1,
      "items.item_name_first8_e.values": 1,
      "items.item_name_last5_e.values": 1,
      "test.cp_dose": 1,
      "test.cp_type": 1,
      "data.City": 1,
      "test.City": 1,
      "train.benign_malignant": 1,
      "train['benign_malignant']": 1,
      "train['diagnosis']": 1,
      "test['sex']": 1,
      "test['benign_malignant']": 1,
      "df['Sentiment']": 1,
      "y_features": 1,
      "list(alldata2[col])": 1,
      "list(train['type'])": 1,
      "df.surface": 1,
      "x[c]": 1,
      "train_df.Province_State": 1,
      "test_df.Province_State": 1,
      "train['cp_time']": 1,
      "train_x[categorical[i]].astype(str)": 1,
      "test[categorical[i]].astype(str)": 1,
      "train['Census_ChassisTypeName']": 1,
      "train['Census_OSArchitecture']": 1,
      "train1[i].astype(str)": 1,
      "test1[i].astype(str)": 1,
      "df_RFE[column].values": 1,
      "df_mutual[column].values": 1,
      "data[col].values.reshape(-1, 1)": 1,
      "df_train['label_group'].values.reshape(-1, 1)": 1,
      "data['prior_question_had_explanation']": 1,
      "features[col].astype(str)": 1,
      "data_clean.cats": 1,
      "grid_train.place_id.values": 1,
      "all_data['building_id']": 1,
      "all_data['display_address']": 1,
      "all_data['street_address']": 1,
      "all_data['manager_id']": 1,
      "all['brand_name']": 1,
      "categories['main_categories_id']": 1,
      "df_app['ORGANIZATION_TYPE']": 1,
      "tr['sex']": 1,
      "tr['anatom_site_general_challenge']": 1,
      "ts['sex']": 1,
      "ts['anatom_site_general_challenge']": 1,
      "df['location']": 1,
      "df['keyword']": 1,
      "metadata.primary_use": 1,
      "train['ebird_code'].values": 1,
      "train[obj_col]": 1,
      "df['category1']": 1,
      "df['category2']": 1,
      "df['category3']": 1,
      "descritized_vals": 1,
      "name_df['name']": 1,
      "dataset['category_name']": 1,
      "dataset['category1']": 1,
      "dataset['category2']": 1,
      "dataset['category3']": 1,
      "dataset['item_condition_id']": 1,
      "dataset['shipping']": 1,
      "train_features[feature]": 1,
      "test_features[feature]": 1,
      "com_data[col]": 1,
      "pg_train_data['target']": 1,
      "df.Country_Region": 1,
      "X_train.Target": 1,
      "train.groupId": 1,
      "train.Id": 1,
      "test.groupId": 1,
      "test.Id": 1,
      "train.matchId": 1,
      "test.matchId": 1,
      "train.matchType": 1,
      "test.matchType": 1,
      "list(df['_collection_name'].fillna('').astype(str))": 1,
      "ordinal_features['ord_1']": 1,
      "enc_df[dum_col]": 1,
      "train_nom[col]": 1,
      "df.cuisine": 1,
      "df['City']": 1,
      "train_df['Hire_count'].values": 1,
      "training['Label']": 1,
      "train_feat[col]": 1,
      "df[column].values": 1,
      "x[i]": 1,
      "dataframe[column].astype('str')": 1,
      "building_meta['primary_use']": 1,
      "all[col]": 1,
      "training_set_df[col]": 1,
      "X[key]": 1,
      "finalTestData[c]": 1,
      "train_df['cuisine'].values": 1,
      "X_train_CS['Country']": 1,
      "X_train_CS['State']": 1,
      "X_test_CS['Country']": 1,
      "X_test_CS['State']": 1,
      "X[col].astype(str)": 1,
      "small_y": 1,
      "X_train.title": 1,
      "alldata['City']": 1,
      "train['category']": 1,
      "test['category']": 1,
      "train_df[TARGET_COL]": 1,
      "X_test_enc[cols]": 1,
      "train_test[:, jj]": 1,
      "valid[col]": 1,
      "df['building_id']": 1,
      "np.asarray(train_data['Id']).reshape(-1, 1)": 1,
      "df_tra_experiment": 1,
      "df_val_experiment": 1,
      "df_tes_experiment": 1,
      "df_tra_y": 1,
      "df_val_y": 1,
      "df_tes_y": 1,
      "df_full_test[categorical_array]": 1,
      "combined['combined_tar']": 1,
      "df_train['species']": 1,
      "input_df['Gene']": 1,
      "input_df['Variation']": 1,
      "input_df['Class']": 1,
      "test_df['Gene']": 1,
      "test_df['Variation']": 1,
      "train.Sentiment.values": 1,
      "df_train['Ticket']": 1,
      "df_test['Ticket']": 1,
      "df_train['Cabin']": 1,
      "df_test['Cabin']": 1,
      "df_train['Name']": 1,
      "df_test['Name']": 1,
      "all_df[feat].fillna('-1').astype(str).values": 1,
      "X['Embarked']": 1,
      "X['Cabin_code']": 1,
      "X_test_copy['Sex']": 1,
      "X_test_copy['Embarked']": 1,
      "X_test_copy['Cabin_code']": 1,
      "item_cat.type": 1,
      "item_cat.subtype": 1,
      "train_cell.place_id.values": 1,
      "y_train_grid": 1,
      "data['AgeGroup']": 1,
      "train_df2['matchType'].astype(str)": 1,
      "test_df2['matchType'].astype(str)": 1,
      "train_df3['matchType'].astype(str)": 1,
      "test_df3['matchType'].astype(str)": 1,
      "X['Date']": 1,
      "X1['Province_State']": 1,
      "X1['Country_Region']": 1,
      "X1['Date']": 1,
      "ids": 1,
      "y.author.values": 1,
      "train_X['PdDistrict']": 1,
      "train_category": 1,
      "datasets.ebird_code.to_numpy()": 1,
      "train[coluna]": 1,
      "self.data[feature]": 1,
      "train[obj_train]": 1,
      "new_train_df['prior_question_had_explanation']": 1,
      "df_panel['continent']": 1,
      "df['best_model']": 1,
      "list(train_df[col].values)": 1,
      "train_features.cp_time": 1,
      "trainLabels": 1,
      "gender_age_train.group": 1,
      "train_copy['StateHoliday']": 1,
      "train_copy['StoreType']": 1,
      "train_copy['Assortment']": 1,
      "stacked_df[col]": 1,
      "data_train_woid[enc]": 1,
      "data_test_woid[enc]": 1,
      "data_appended[enc]": 1,
      "train_data[enc]": 1,
      "data.loc[(data['TYPE-LABEL'] == 'TRAIN').tolist(), 'cuisine'].values": 1,
      "df['datetime']": 1,
      "dt['datetime']": 1,
      "item_categories_df['subtype']": 1,
      "trainY": 1,
      "MergedData[var].astype('str')": 1,
      "MergedData['Response'].astype('str')": 1,
      "combined[col]": 1,
      "data_mod.AnimalType": 1,
      "data_mod.SexuponOutcome": 1,
      "data_mod.Breed": 1,
      "data_mod.Color": 1,
      "data_mod.OutcomeType": 1,
      "building_metadata.primary_use": 1,
      "df['ord_5a']": 1,
      "df['ord_5b']": 1,
      "train.air_store_id": 1,
      "train.day_of_week": 1,
      "train.air_genre_name": 1,
      "train.air_area_name": 1,
      "train['day_of_week']": 1,
      "cities": 1,
      "dataset.Fare": 1,
      "dataset.Age": 1,
      "x_train.country": 1,
      "x_train['state']": 1,
      "x_test.country": 1,
      "x_test['state']": 1,
      "x_train_all.country": 1,
      "x_train_all['state']": 1,
      "X_xTest_CS.country": 1,
      "X_xTest_CS['state']": 1,
      "train.card_id": 1,
      "df['full'][feature]": 1,
      "training_set['cuisine']": 1,
      "np.array(obj)[:, 0]": 1,
      "np.array(obj)[:, i]": 1,
      "file[features]": 1,
      "test_X[col]": 1,
      "train_categorical_values[:, 0]": 1,
      "train_categorical_values[:, i]": 1,
      "train['city']": 1,
      "train['subtype']": 1,
      "all_data[0].Name.fillna('missing')": 1,
      "df['system:index']": 1,
      "x['Sex']": 1,
      "data_test['Sex']": 1,
      "big[i]": 1,
      "y_des": 1,
      "pd.concat([train_cat, test_cat])[c]": 1,
      "train_full['primary_use']": 1,
      "Building.primary_use": 1,
      "train['Age']": 1,
      "train['Fare']": 1,
      "test['Age']": 1,
      "test['Fare']": 1,
      "full_data[cat_col]": 1,
      "prop_2016[col]": 1,
      "prop_2017[col]": 1,
      "df_raw[col]": 1,
      "items_categories['type']": 1,
      "items_categories['subtype']": 1,
      "df_sales_shop['city']": 1,
      "df_sales_item_cat['type']": 1,
      "df_sales_item_cat['subtype']": 1,
      "train_df['country_destination'].values": 1,
      "df_train[col].append(df_test[col])": 1,
      "df[group].values": 1,
      "application_train[col].astype(str)": 1,
      "application_test[col].astype(str)": 1,
      "data_train2_cat.iloc[:, i:i + 1]": 1,
      "data_test1_cat.iloc[:, i:i + 1]": 1,
      "X_tr['prior_question_had_explanation']": 1,
      "X_te['prior_question_had_explanation']": 1,
      "X_fold['bin_3']": 1,
      "X_fold['bin_4']": 1,
      "tdf.phone_brand": 1,
      "tdf.device_model": 1,
      "df_train['experiment']": 1,
      "df_train['event']": 1,
      "train['sexo'][train_mask]": 1,
      "df_train.primary_use": 1,
      "tmp['year']": 1,
      "item_categories_df['sub_type']": 1,
      "items_df['name2']": 1,
      "items_df['name3']": 1,
      "df['Geo_Code']": 1,
      "tempTr[col]": 1,
      "list(df[i])": 1,
      "cut_Age": 1,
      "cut_Fare": 1,
      "building_df.primary_use": 1,
      "train_part_df['prior_question_had_explanation']": 1,
      "y_tes['label']": 1,
      "train_ds['target']": 1,
      "data['project_subject_categories']": 1,
      "data['project_subject_subcategories']": 1,
      "data['project_grade_category']": 1,
      "df[column].astype('str')": 1,
      "X_train['Sex']": 1,
      "X_train['Embarked']": 1,
      "X_test['Sex']": 1,
      "X_test['Embarked']": 1,
      "X_trn[col]": 1,
      "X_tst[col]": 1,
      "alltrain['part_of_day']": 1,
      "alltrain['primary_use']": 1,
      "alltest['part_of_day']": 1,
      "alltest['primary_use']": 1,
      "train['geography']": 1,
      "test['geography']": 1,
      "air_store_info_df['air_genre_name']": 1,
      "air_store_info_df['prefecture']": 1,
      "air_store_info_df['city']": 1,
      "air_store_info_df['district']": 1,
      "train_df['air_store_id']": 1,
      "train_x['DayOfWeek']": 1,
      "train_x['PdDistrict']": 1,
      "train_x['Address']": 1,
      "test_x['DayOfWeek']": 1,
      "test_x['PdDistrict']": 1,
      "test_x['Address']": 1,
      "train_x.loc[:, col]": 1,
      "fat_table[col]": 1,
      "app_train[x]": 1,
      "sales['shop_0'].astype(str)": 1,
      "sales['shop_1'].astype(str)": 1,
      "sales['category_0'].astype(str)": 1,
      "sales['category_1'].astype(str)": 1
    },
    "sklearn.model_selection._split.KFold.__init__.n_splits": {
      "5": 1199,
      "10": 378,
      "n_splits": 323,
      "n_folds": 242,
      "n_fold": 192,
      "3": 181,
      "folds": 181,
      "num_folds": 171,
      "NFOLDS": 124,
      "NFOLD": 113,
      "FOLDS": 112,
      "N_FOLDS": 89,
      "k": 79,
      "4": 73,
      "NUM_FOLDS": 68,
      "nfolds": 57,
      "self.n_splits": 54,
      "2": 45,
      "N_SPLITS": 44,
      "self.n_folds": 41,
      "K": 40,
      "7": 26,
      "6": 26,
      "splits": 26,
      "8": 20,
      "num_splits": 15,
      "20": 15,
      "nr_splits": 15,
      "nr_folds": 15,
      "cv": 14,
      "self.num_folds": 13,
      "t_splits": 12,
      "num_of_splits": 12,
      "12": 11,
      "cv_num": 10,
      "SPLITS": 10,
      "n_inner_folds": 9,
      "P['NFOLDS']": 9,
      "nfold": 9,
      "n_split": 9,
      "n": 8,
      "num_fold": 8,
      "CFG.nfolds": 7,
      "CFG.n_fold": 7,
      "self.n_fold": 6,
      "N_FOLD": 6,
      "CFG.folds": 6,
      "KFOLDS": 6,
      "self.cv": 5,
      "nFolds": 5,
      "k_folds": 5,
      "fold_no": 5,
      "11": 4,
      "kfolds": 4,
      "9": 4,
      "EPOCHS": 4,
      "n_s": 4,
      "fold": 4,
      "kfold": 4,
      "FOLD": 4,
      "nsplits": 4,
      "kfold_splits": 4,
      "N": 3,
      "Number_of_folds": 3,
      "15": 3,
      "NUM_SPLITS": 3,
      "TOTAL_FOLDS": 3,
      "KFOLD_SPLITS": 3,
      "FOLD_NUM": 3,
      "k_fold": 3,
      "epochs": 3,
      "nSplits": 3,
      "NUMBER_KFOLDS": 2,
      "KFold_N": 2,
      "k_fold_split": 2,
      "nb_folds": 2,
      "self.n_splits_": 2,
      "N_splits": 2,
      "Nfold": 2,
      "n_cv": 2,
      "self.kfolds": 2,
      "18": 2,
      "n_models": 2,
      "50": 2,
      "16": 2,
      "CFG.N_SPLITS": 2,
      "fold_count": 2,
      "FOLD_N": 2,
      "17": 2,
      "cross_validation_folds": 2,
      "len(MODELS)": 2,
      "cfg.n_splits": 2,
      "config['nfolds']": 2,
      "CFG.n_folds": 2,
      "K_SPLITS": 2,
      "kf": 2,
      "NUM_FOLD": 2,
      "100": 2,
      "nn_num_folds": 2,
      "N_folds": 2,
      "40": 2,
      "len(fold_config)": 1,
      "split_num": 1,
      "128": 1,
      "ntrain": 1,
      "num_cv_folds": 1,
      "KFolds": 1,
      "150": 1,
      "conf.n_splits": 1,
      "kfold_n_splits": 1,
      "k_fold_num": 1,
      "self.NFOLDS": 1,
      "BASE_MODEL_KF": 1,
      "NFOLDS_xgb": 1,
      "args.n_folds": 1,
      "args.folds": 1,
      "self.K": 1,
      "splits_nbr": 1,
      "nfd": 1,
      "CFG.n_splits": 1,
      "params['n_splits']": 1,
      "kfoldAmount": 1,
      "23": 1,
      "cv_splits": 1,
      "validation_params['n_folds']": 1,
      "K_FOLDS": 1,
      "32": 1,
      "config.FOLDS": 1,
      "NSPLITS": 1,
      "cfg['kfold']": 1,
      "kf_splits": 1,
      "CV_STEPS": 1,
      "self._n_folds": 1,
      "cv_outer": 1,
      "self.cv_inner_n": 1,
      "CFG['NSPLITS']": 1,
      "Kfold": 1,
      "yapl.config.FOLDS": 1,
      "self.n_split": 1,
      "folds_count": 1,
      "CONFIG.n_folds": 1,
      "nb_split": 1,
      "CV_no": 1,
      "num_of_folds": 1,
      "FOLDER": 1,
      "oth_params['n_fold']": 1,
      "no_splits": 1,
      "len(models)": 1,
      "kfo": 1,
      "foldCount": 1,
      "h_n_splits": 1,
      "n_runs": 1,
      "num_Fold": 1,
      "200": 1,
      "len(dims)": 1,
      "config.n_split": 1,
      "num_slice": 1,
      "CV": 1,
      "self.k_folds": 1,
      "kfold_num": 1,
      "FOLDS_VALID": 1
    },
    "sklearn.model_selection._split.KFold.__init__.shuffle": {
      "True": 2896,
      "False": 1236,
      "shuffle": 181,
      "self.shuffle": 22,
      "SHUFFLE": 6,
      "kfold_shuffle": 1,
      "shuf": 1,
      "self._shuffle": 1
    },
    "sklearn.model_selection._split.KFold.__init__.random_state": {
      "None": 1018,
      "42": 714,
      "seed": 290,
      "SEED": 256,
      "random_state": 249,
      "0": 169,
      "1": 128,
      "2016": 80,
      "15": 77,
      "50": 76,
      "2017": 65,
      "1001": 61,
      "11": 52,
      "2019": 50,
      "7": 45,
      "48": 36,
      "2021": 35,
      "156": 33,
      "2018": 32,
      "1989": 30,
      "71": 29,
      "2020": 28,
      "42 + k": 27,
      "123": 26,
      "self.random_state": 24,
      "546789": 22,
      "137": 20,
      "22": 20,
      "47": 20,
      "i": 20,
      "RANDOM_STATE": 15,
      "random_seed": 15,
      "CFG.seed": 15,
      "100": 15,
      "config['seed']": 15,
      "d_seed": 15,
      "12": 14,
      "RANDOM_SEED": 14,
      "666": 14,
      "6": 13,
      "10": 13,
      "42069": 13,
      "3": 12,
      "2": 12,
      "45": 11,
      "33": 10,
      "self.seed": 10,
      "239": 10,
      "21": 10,
      "101": 9,
      "P['SEED']": 9,
      "2319": 9,
      "50 + seed_varying": 9,
      "1337": 8,
      "228": 8,
      "326": 8,
      "1234": 7,
      "24": 7,
      "2222": 6,
      "3228": 6,
      "108": 6,
      "432013": 5,
      "17": 5,
      "4": 5,
      "41": 5,
      "30": 5,
      "4564": 5,
      "rs": 4,
      "params['random_state']": 4,
      "345665": 4,
      "43": 4,
      "29": 4,
      "12345": 4,
      "233": 4,
      "40": 4,
      "13": 4,
      "69": 4,
      "32": 4,
      "345": 4,
      "319": 4,
      "5": 3,
      "CFG.SEED": 3,
      "77": 3,
      "4991": 3,
      "23": 3,
      "4590": 3,
      "self.random_seed": 3,
      "72": 3,
      "7956112": 3,
      "630": 3,
      "4305": 3,
      "i + 1000": 2,
      "348": 2,
      "(seed + 1)**2": 2,
      "28": 2,
      "1054": 2,
      "34": 2,
      "4520": 2,
      "SEED_ALL": 2,
      "rndseed": 2,
      "882": 2,
      "35": 2,
      "random.randint(0, 1000)": 2,
      "111": 2,
      "fold_gen_seed": 2,
      "CONFIG.seed": 2,
      "rnd_seed_cv": 2,
      "37": 2,
      "114": 2,
      "1111": 2,
      "123456": 2,
      "54321": 2,
      "777": 2,
      "999": 2,
      "46": 2,
      "2645312378": 2,
      "2001": 2,
      "CONFIG.SEED": 2,
      "config.seed": 2,
      "9": 2,
      "seed_val": 2,
      "810": 2,
      "7988": 2,
      "853": 2,
      "420 + k": 1,
      "params['seed']": 1,
      "5473": 1,
      "8": 1,
      "2045": 1,
      "1986": 1,
      "56": 1,
      "231": 1,
      "RAND": 1,
      "9705": 1,
      "kfold_random_state": 1,
      "sklearn_seed": 1,
      "rand_seed": 1,
      "1357": 1,
      "60": 1,
      "loop": 1,
      "2019 + i": 1,
      "99": 1,
      "25000": 1,
      "rep": 1,
      "25": 1,
      "1997": 1,
      "123451": 1,
      "314": 1,
      "20180917": 1,
      "i + 100": 1,
      "1987": 1,
      "1346": 1,
      "234": 1,
      "base_seed": 1,
      "rand": 1,
      "validation_params['seed']": 1,
      "KFOLD_SEED": 1,
      "3438": 1,
      "88": 1,
      "31415": 1,
      "4022": 1,
      "fold_seed": 1,
      "128": 1,
      "100892": 1,
      "config.SEED": 1,
      "50001": 1,
      "6699": 1,
      "RAND_SEED": 1,
      "2014": 1,
      "235": 1,
      "cfg['seed']": 1,
      "1000": 1,
      "95": 1,
      "14": 1,
      "self._random_state": 1,
      "self.random_state + outer_split": 1,
      "379": 1,
      "CFG['RANDOM_STATE']": 1,
      "1024": 1,
      "333": 1,
      "517": 1,
      "True": 1,
      "8982": 1,
      "yapl.config.SEED": 1,
      "20": 1,
      "200": 1,
      "721618": 1,
      "6547": 1,
      "218": 1,
      "randomState": 1,
      "1029": 1,
      "39": 1,
      "SEED + k": 1,
      "87": 1,
      "1127": 1,
      "SEED_VAL": 1,
      "sd": 1,
      "9102": 1,
      "255": 1,
      "6666": 1,
      "21 + n": 1,
      "oth_params['seed']": 1,
      "820": 1,
      "312": 1,
      "44000": 1,
      "fe_id + random_state": 1,
      "114514": 1,
      "1984": 1,
      "19911109": 1,
      "19901028": 1,
      "1086": 1,
      "seed + 1": 1,
      "3 + r": 1,
      "1990": 1,
      "1108": 1,
      "randoms[runs]": 1,
      "hparams.seed": 1
    },
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.n_estimators": {
      "100": 1960,
      "40": 232,
      "200": 170,
      "10": 167,
      "50": 167,
      "500": 142,
      "1000": 115,
      "20": 88,
      "300": 59,
      "30": 52,
      "80": 47,
      "400": 46,
      "15": 45,
      "1": 44,
      "150": 44,
      "25": 42,
      "n_estimators": 41,
      "250": 38,
      "5": 24,
      "70": 22,
      "g['ne']": 17,
      "2000": 14,
      "600": 14,
      "60": 13,
      "120": 13,
      "160": 12,
      "best_n_estimators": 11,
      "110": 10,
      "800": 8,
      "estimator": 7,
      "result.best_params_['n_estimators']": 6,
      "225": 6,
      "1200": 6,
      "128": 6,
      "n_trees": 6,
      "int(params['n_estimators'])": 6,
      "12": 5,
      "35": 5,
      "24": 5,
      "197": 5,
      "i": 5,
      "trees": 5,
      "n_est": 5,
      "125": 5,
      "3000": 5,
      "0": 5,
      "130": 5,
      "3": 4,
      "19": 4,
      "58": 4,
      "num": 4,
      "n": 4,
      "900": 4,
      "4": 4,
      "9": 4,
      "145": 4,
      "190": 4,
      "a['n_estimators']": 4,
      "gsearch.best_params_.get('n_estimators')": 3,
      "1400": 3,
      "260": 3,
      "gs1.best_params_['n_estimators']": 3,
      "820": 3,
      "1500": 3,
      "2": 3,
      "8": 3,
      "n_estimators_min": 3,
      "79": 2,
      "47": 2,
      "2500": 2,
      "7": 2,
      "350": 2,
      "3003": 2,
      "180": 2,
      "90": 2,
      "57": 2,
      "700": 2,
      "16": 2,
      "32": 2,
      "710": 2,
      "17": 2,
      "best_params['n_estimators']": 2,
      "175": 2,
      "72": 2,
      "170": 2,
      "530": 2,
      "75": 2,
      "NUM_TREES": 2,
      "210": 2,
      "230": 2,
      "2200": 2,
      "185": 1,
      "trial.suggest_int('n_estimators', 100, 2000)": 1,
      "rf_regressor.best_params_['n_estimators']": 1,
      "N_ESTIMATORS": 1,
      "199": 1,
      "best_N": 1,
      "86": 1,
      "78": 1,
      "721": 1,
      "train_data.shape[1]": 1,
      "val": 1,
      "285": 1,
      "50 * 5": 1,
      "self.n_estimators": 1,
      "1800": 1,
      "num_trees": 1,
      "estimator_range_optim": 1,
      "estimators": 1,
      "_n_estimators": 1,
      "nestimators": 1,
      "360": 1,
      "66": 1,
      "1600": 1,
      "4000": 1,
      "param": 1,
      "222": 1,
      "450": 1,
      "265": 1,
      "258": 1,
      "1250": 1,
      "1300": 1,
      "1220": 1,
      "99": 1,
      "int(i)": 1,
      "a": 1,
      "j": 1,
      "150 * i": 1,
      "501": 1,
      "63": 1,
      "grid_search_cas.best_params_['n_estimators']": 1,
      "grid_search_reg.best_params_['n_estimators']": 1,
      "trial.suggest_int('n_estimators', 50, 200)": 1,
      "NUM_TREES_CV": 1,
      "p['n_estimators']": 1,
      "best_parameters['n_estimators']": 1,
      "27": 1,
      "result_random_forest.best_params_['n_estimators']": 1,
      "est": 1,
      "535": 1,
      "estim": 1,
      "rf_gs.best_params_['n_estimators']": 1,
      "220": 1,
      "112": 1,
      "320": 1,
      "n_estimators[i]": 1,
      "num_of_estimators": 1,
      "195": 1,
      "149": 1,
      "670": 1,
      "750": 1,
      "39": 1,
      "227": 1,
      "23": 1,
      "best_tree": 1,
      "98": 1,
      "512": 1,
      "460": 1
    },
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.random_state": {
      "None": 2465,
      "0": 451,
      "42": 396,
      "1": 142,
      "2016": 78,
      "seed": 38,
      "10": 31,
      "50": 19,
      "g['rs']": 17,
      "123": 17,
      "7": 16,
      "101": 15,
      "96": 15,
      "17": 12,
      "3": 12,
      "SEED": 11,
      "2": 10,
      "random_state": 9,
      "RANDOM_STATE": 8,
      "2021": 8,
      "1234": 8,
      "2017": 7,
      "12": 6,
      "5": 6,
      "1301": 6,
      "35": 6,
      "40": 5,
      "43": 5,
      "2019": 5,
      "2020": 5,
      "8": 4,
      "11": 4,
      "23": 4,
      "prng": 4,
      "15": 4,
      "500": 4,
      "100": 3,
      "449": 3,
      "37": 3,
      "33": 3,
      "ra1": 3,
      "22": 3,
      "323": 3,
      "rstate": 2,
      "seed_val": 2,
      "my_randome_state": 2,
      "RANDOM_SEED": 2,
      "777": 2,
      "21": 2,
      "ra2": 2,
      "4": 2,
      "58": 2,
      "18": 2,
      "198": 2,
      "31": 2,
      "60": 2,
      "999": 2,
      "49": 2,
      "45": 1,
      "4200": 1,
      "82": 1,
      "12345": 1,
      "333": 1,
      "CTL.random_state": 1,
      "1165842557": 1,
      "520": 1,
      "1337": 1,
      "9": 1,
      "34": 1,
      "141": 1,
      "620": 1,
      "31415": 1,
      "151": 1,
      "25": 1,
      "1937": 1,
      "56": 1,
      "111": 1,
      "16": 1,
      "71": 1,
      "i + 2": 1,
      "3101": 1,
      "42421": 1,
      "False": 1,
      "148": 1,
      "2018": 1,
      "51": 1,
      "random_state1": 1,
      "random_state2": 1,
      "200": 1,
      "6": 1,
      "420": 1,
      "850": 1,
      "47": 1,
      "RSEED": 1,
      "46": 1
    },
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.n_jobs": {
      "None": 2381,
      "-1": 1465,
      "4": 44,
      "1": 21,
      "3": 16,
      "2": 3,
      "12": 3,
      "n_jobs": 3,
      "-2": 2,
      "multiprocessing.cpu_count() - 1": 1,
      "8": 1,
      "32": 1
    },
    "sklearn.metrics._regression.mean_squared_error.y_true": {
      "y_test": 1718,
      "y_train": 500,
      "y_val": 496,
      "y": 450,
      "y_valid": 309,
      "ground_truth": 217,
      "y_true": 214,
      "Y_train": 116,
      "target": 109,
      "y_pred": 102,
      "Y_test": 102,
      "test_y": 85,
      "pred": 77,
      "actual": 74,
      "val_y": 72,
      "true": 66,
      "oof": 65,
      "Y_valid": 55,
      "true.ravel()": 53,
      "val_pred": 47,
      "A1": 39,
      "np.log(y_true.clip(0, 10000000000.0) + 1)": 38,
      "A2": 37,
      "Y_val": 35,
      "train_hist": 35,
      "np.log1p(trn_user_target['target'])": 33,
      "oof_lgb": 32,
      "preds": 30,
      "test": 28,
      "y[:len(predictions)]": 28,
      "dev_df[TARGETS[i]]": 27,
      "np.log(1 + train_p_c_raw.values[:, d])": 25,
      "np.log(1 + train_p_f_raw.values[:, d])": 25,
      "target[val_idx]": 24,
      "x": 23,
      "np.log1p(y_reg)": 23,
      "y_test_rf": 23,
      "oof_xgb": 22,
      "Y_validation": 21,
      "temp_oof": 20,
      "train_y": 20,
      "np.log1p(df_panel[~df_panel.ConfirmedCases_val_lgb.isna()].ConfirmedCases)": 19,
      "np.log1p(df_panel[~df_panel.Fatalities_val_lgb.isna()].Fatalities)": 19,
      "train['target']": 19,
      "validate_y_inv": 18,
      "y_tr": 18,
      "Y_valida": 18,
      "y_test2": 18,
      "np.log1p(val_y)": 18,
      "Y": 18,
      "np.log1p(sub1[t].values)": 17,
      "valid_y": 17,
      "np.log1p(df_panel[~df_panel.ConfirmedCases_val_mad.isna()].ConfirmedCases)": 17,
      "np.log1p(df_panel[~df_panel.Fatalities_val_mad.isna()].Fatalities)": 17,
      "vl1p": 17,
      "yvalid": 17,
      "df_pred['weekly_sales']": 17,
      "target.values": 16,
      "np.log1p(val_pred_df['transactionRevenue'].values)": 16,
      "ytest": 16,
      "Y_val2": 16,
      "y_train_pred": 15,
      "np.log(y_test)": 15,
      "y_actual": 14,
      "y[:, TRAIN_N:TRAIN_N + val_len].flatten()": 14,
      "valid['count']": 14,
      "np.expm1(y_val)": 13,
      "np.log(1 + train_p_f_raw.values[:, TRAIN_N:TRAIN_N + val_len]).flatten()": 13,
      "train[target]": 13,
      "predictions": 13,
      "housing_labels": 13,
      "test_Y": 13,
      "test_target": 13,
      "y_inv": 12,
      "y.iloc[val_idx]": 12,
      "y_hat": 12,
      "np.log(1 + train_p_c_raw.values[:, TRAIN_N:TRAIN_N + val_len]).flatten()": 12,
      "train_oof": 12,
      "label": 12,
      "y_test1": 11,
      "valid['rentals']": 11,
      "df_base.iloc[:, i + 1]": 11,
      "y_train_level2": 11,
      "df_submission.price.values": 11,
      "total_sum": 11,
      "alltargets": 11,
      "np.log1p(v0)": 11,
      "val_predictions": 10,
      "Ytest": 10,
      "ytrain": 10,
      "np.log(1 + train_p_c_raw.values[:, START_PUBLIC:START_PUBLIC + val_len]).flatten()": 10,
      "np.log(1 + train_p_f_raw.values[:, START_PUBLIC:START_PUBLIC + val_len]).flatten()": 10,
      "y_validation": 10,
      "yval": 10,
      "prediction": 9,
      "score[va]": 9,
      "df_train[target]": 9,
      "labels": 9,
      "df_train.target": 9,
      "valid[y_name]": 9,
      "v_Y": 9,
      "labels[mask_val]": 9,
      "y_train_o": 9,
      "y_val_o": 9,
      "pred1": 9,
      "returns_test['returnsOpenNextMktres10']": 9,
      "y_test_scaled": 8,
      "df_train_processed.loc[val_idx, self.target]": 8,
      "y_val[:, :n_public]": 8,
      "df['target']": 8,
      "sub_price": 8,
      "train.target.values": 8,
      "dataList": 8,
      "df_train_processed['target']": 8,
      "y_e": 8,
      "y_pred_2": 8,
      "Model_y_test": 8,
      "y_test_reg_us.TargetValue": 8,
      "np.exp(y_test)": 8,
      "model.predict(X_test)": 7,
      "y_val[:, n_public:]": 7,
      "valy": 7,
      "y_eval": 7,
      "train['rentals']": 7,
      "y_cv": 7,
      "Y_test1": 7,
      "leak_df.pred1_l1p": 7,
      "leak_df.pred2_l1p": 7,
      "leak_df.pred3_l1p": 7,
      "testY": 7,
      "pre_train[target]": 7,
      "df['rentals']": 7,
      "maxval * gp_trn_users['target']": 7,
      "y_test_cases": 6,
      "y_test_cases_f": 6,
      "y_test_fatal_f": 6,
      "Y_pred": 6,
      "all_targets": 6,
      "yscore": 6,
      "y_test.values": 6,
      "df.loc[valid_idx, 'pred']": 6,
      "leak_df.mean_pred_l1p": 6,
      "ensemble_pred": 6,
      "y_pred1": 6,
      "y_pred2": 6,
      "y2.clip(0.0, 20.0)": 6,
      "predictions[model_name].values": 6,
      "y_testFinal": 6,
      "y_test_check": 6,
      "np.log1p(train.target[have_data])": 6,
      "y2_valid": 6,
      "validation_y": 6,
      "confirm_va1": 6,
      "fatal_val1": 6,
      "yhat": 6,
      "yreal": 6,
      "vp": 6,
      "d.loc[q, 'y0']": 6,
      "d.loc[q, 'y1']": 6,
      "avreal": 6,
      "y_validate": 6,
      "y[val_idx]": 6,
      "leak_df.pred_l1p": 6,
      "test['sales']": 6,
      "df[target_col]": 6,
      "np.log(y_train + 1)": 5,
      "np.log(y_test + 1)": 5,
      "y_test_fatal": 5,
      "train['FVC']": 5,
      "np.log1p(validation_res['transactionrevenue'].values)": 5,
      "oof_2": 5,
      "leak_df.median_pred_l1p": 5,
      "val_preds": 5,
      "df_submission['SalePrice']": 5,
      "dtrain_.get_label()": 5,
      "y_dtrain": 5,
      "y_train_test": 5,
      "test[target]": 5,
      "train_1[start_index:end_index]['sales']": 5,
      "y_te": 5,
      "df_Y_validation": 5,
      "np.log1p(val_y.target_revenue.values)": 5,
      "y_val.clip(0, 20)": 5,
      "trainy": 5,
      "sample_labels": 5,
      "tes": 5,
      "d_set[3]": 5,
      "targets": 4,
      "self.train[target]": 4,
      "pred_y_val1": 4,
      "pred_y_val2": 4,
      "pred_y_val3": 4,
      "internal_model.predict(train.ix[indextrain])": 4,
      "y_train_site": 4,
      "np.expm1(y_test)": 4,
      "user_sums": 4,
      "np.log(1 + train_p_c.values[:, d])": 4,
      "np.log(1 + train_p_f.values[:, d])": 4,
      "np.log(1 + train_p_c.values[:, TRAIN_N:TRAIN_N + val_len]).flatten()": 4,
      "np.log(1 + train_p_f.values[:, TRAIN_N:TRAIN_N + val_len]).flatten()": 4,
      "rfh_y_pred": 4,
      "np.log1p(validation_res['transactionRevenue'].values)": 4,
      "y_test_level2": 4,
      "y_train_cases": 4,
      "y_train_fatalities": 4,
      "validacao['count']": 4,
      "data['estimated_generation_gwh']": 4,
      "dsubmit_y": 4,
      "targets_val": 4,
      "y_pred3": 4,
      "mvalid": 4,
      "y_holdout": 4,
      "y['Sales']": 4,
      "dev_labels": 4,
      "y_va": 4,
      "y_test_br": 4,
      "predicted": 4,
      "y_train.clip(0.0, 20.0)": 4,
      "trainY[0]": 4,
      "testY[0]": 4,
      "validation": 4,
      "train_data['SalePrice']": 4,
      "Yt": 4,
      "Yv": 4,
      "Ytest1": 4,
      "cases_test": 4,
      "np.log1p(sub3[t].values)": 4,
      "train['log_revenue']": 4,
      "y_valid_values1": 4,
      "y_valid_values2": 4,
      "y_train2": 4,
      "validation_test['sales']": 4,
      "yp": 4,
      "fcst": 4,
      "np.log1p(y['target'].iloc[val_idx])": 4,
      "np.log1p(y['target'])": 4,
      "yt": 4,
      "Test_us['y']": 4,
      "Y_test_1": 4,
      "Y_test_4": 4,
      "ts_1_shifted": 4,
      "y_true[i]": 4,
      "comparison[:, 0]": 4,
      "gbr_validpred": 4,
      "oof_cb": 4,
      "targets_lst": 4,
      "eval_df.y": 4,
      "yTest": 4,
      "test_label": 3,
      "my_test_y": 3,
      "y_pred_rf": 3,
      "test_sales": 3,
      "inv_y(linear_val_predictions)": 3,
      "inv_y(dtree_val_predictions)": 3,
      "inv_y(rf_val_predictions)": 3,
      "inv_y(gbr_val_predictions)": 3,
      "rf.predict(valid[feats])": 3,
      "targs": 3,
      "y_valid[column]": 3,
      "y_val_cases": 3,
      "y_val_fatalities": 3,
      "y_test_inv": 3,
      "pred_df['true']": 3,
      "df['pred']": 3,
      "y1": 3,
      "df_oof.target": 3,
      "valid_pred": 3,
      "np.log(1 + train_p_c_raw.values[:, 64:64 + val_len]).flatten()": 3,
      "np.log(1 + train_p_f_raw.values[:, 64:64 + val_len]).flatten()": 3,
      "train['count']": 3,
      "val_target": 3,
      "yv": 3,
      "Atest": 3,
      "TARGETS": 3,
      "Y_train_sampled": 3,
      "y_train_b": 3,
      "yCC_test": 3,
      "yF_test": 3,
      "y_tofit": 3,
      "train[label]": 3,
      "y_predTrain": 3,
      "real": 3,
      "oof_df.loc[oof_df.index.isin(val_idx)]['open_channels']": 3,
      "oof_df['open_channels']": 3,
      "Ytrain": 3,
      "y_predict": 3,
      "df['count']": 3,
      "prval[id1, 0]": 3,
      "prval": 3,
      "y[mask_te]": 3,
      "y_tester": 3,
      "y_valid_new": 3,
      "y_train_log": 3,
      "oof_lgb_3": 3,
      "y_valid_f": 3,
      "predict": 3,
      "data": 3,
      "np.log1p(y_train)": 3,
      "X_test['Sales']": 3,
      "self.y_validation": 3,
      "self.y_train": 3,
      "np.log1p(test_y.target_revenue.values)": 3,
      "np.log1p(df[~df.ConfirmedCases_val_lgb.isna()].ConfirmedCases)": 3,
      "np.log1p(df[~df.Fatalities_val_lgb.isna()].Fatalities)": 3,
      "np.log1p(df[~df.ConfirmedCases_val_mad.isna()].ConfirmedCases)": 3,
      "np.log1p(df[~df.Fatalities_val_mad.isna()].Fatalities)": 3,
      "va_y": 3,
      "y_test_pca": 3,
      "df_dict['air_00a91d42b08b08d9']['visitors'].to_numpy()": 3,
      "valid['deal_probability']": 3,
      "train_numeric_Y": 3,
      "ccases_act": 3,
      "deaths_act": 3,
      "test_linear_pred": 3,
      "y_val_ar": 3,
      "scaler_target.inverse_transform(test_y)": 3,
      "train[coly]": 3,
      "dae_data": 3,
      "Y_valid.clip(0.0, 20.0)": 3,
      "d.loc[q, 'y0r']": 3,
      "d.loc[q, 'y1r']": 3,
      "y_val[tar]": 3,
      "model.predict(X_train)": 3,
      "np.log1p(y_train_user['transactionRevenue'])": 3,
      "yts": 3,
      "self.data['Sales'].values.reshape(-1, 1)": 3,
      "self.test_data['Sales'].values.reshape(-1, 1)": 3,
      "self.data['Sales'].values": 3,
      "self.test_data['Sales'].values": 3,
      "xgb_validpred": 3,
      "xgb_final_validpred": 3,
      "adr_validpred": 3,
      "y_mul": 3,
      "y_meas": 3,
      "np.log(prediction)": 3,
      "ylog_train": 3,
      "ylog_val": 3,
      "train_copy['log_revenue']": 2,
      "results.predict(start=1880, end=1911)": 2,
      "results2.predict(start=380, end=411)": 2,
      "results_food.predict(start=1883, end=1911)": 2,
      "results_hobbies.predict(start=1883, end=1911)": 2,
      "results_household.predict(start=1883, end=1911)": 2,
      "test_pred": 2,
      "y_train.loc[val_idx]": 2,
      "val_pred_df['transactionRevenue'].values": 2,
      "y_val[:, :N_DAYS]": 2,
      "y_val[:, N_DAYS:]": 2,
      "np.array(y_val)": 2,
      "validation_labels": 2,
      "Y_predict": 2,
      "pred.clip(0, 20)": 2,
      "oof_train[:, i]": 2,
      "oof_train_nn": 2,
      "model.predict(oof_train)": 2,
      "meta_y_train": 2,
      "np.log1p(session_sums)": 2,
      "oof_5": 2,
      "oof_10": 2,
      "sample_test_y": 2,
      "vl_y": 2,
      "y_case": 2,
      "y_fatal": 2,
      "y_val_case": 2,
      "y_val_fatal": 2,
      "sales_test.values": 2,
      "y_concat.iloc[val_idx]": 2,
      "Y_actual": 2,
      "y_train_": 2,
      "np.log1p(X[i, :])": 2,
      "train_labels": 2,
      "lr_y": 2,
      "svr_y": 2,
      "knn_y": 2,
      "dt_y": 2,
      "rf_y": 2,
      "xgb_y": 2,
      "adb_y": 2,
      "xgh_y_pred": 2,
      "final_pred": 2,
      "y_test_values": 2,
      "treino['count']": 2,
      "dftestY": 2,
      "_y_val": 2,
      "h": 2,
      "y_train[:m]": 2,
      "y_pred4": 2,
      "df['sale']": 2,
      "pred_val": 2,
      "train_df.target": 2,
      "df_gmm_test[target]": 2,
      "np.log1p(df[col1].values)": 2,
      "test_labels": 2,
      "lgb_train_oof": 2,
      "xgb1_train_oof": 2,
      "xgb2_train_oof": 2,
      "combo_preds": 2,
      "raw_train_y": 2,
      "train_df.target[train_idx]": 2,
      "train[TARGET]": 2,
      "train_df[target_col]": 2,
      "train_df.loc[val_idx, target_col].values": 2,
      "train_set[LABEL]": 2,
      "test[target].values": 2,
      "true_cases": 2,
      "true_fatalities": 2,
      "validation.target": 2,
      "validation.target.values": 2,
      "train_predictions": 2,
      "Y_train_encoded": 2,
      "Y_valid_encoded": 2,
      "test_data": 2,
      "y_mean": 2,
      "output['val'].to_numpy()": 2,
      "np.log1p(y)": 2,
      "train_sarima_truth": 2,
      "train_preds": 2,
      "target.iloc[:len(y_prediction)]": 2,
      "y_submission": 2,
      "ln_target": 2,
      "y_val_pred": 2,
      "hold_y": 2,
      "oof_df['FVC']": 2,
      "oof_df.loc[oof_df.iloc[val_idx].index]['target']": 2,
      "oof_df.target": 2,
      "df_global_test['ConfirmedCases']": 2,
      "part_B_y": 2,
      "part_C_y": 2,
      "y_hat_test": 2,
      "Y_valid_expm1": 2,
      "[100]": 2,
      "[1000]": 2,
      "[10000]": 2,
      "Y_train_level2": 2,
      "np.ravel(y_test)": 2,
      "yoof_val": 2,
      "label_df.values": 2,
      "valid_1_df": 2,
      "pred_results_combined.Margin": 2,
      "labelsValidation": 2,
      "srcConf.values": 2,
      "val": 2,
      "np.square(np.exp(y_train))": 2,
      "np.square(np.exp(y_valid))": 2,
      "actuals": 2,
      "fold_pred": 2,
      "YY_valid": 2,
      "y_target": 2,
      "y_test_log": 2,
      "pred_lgb": 2,
      "pred[0].values": 2,
      "y_validation_RF": 2,
      "self.Y_train['y']": 2,
      "self.Y_test": 2,
      "truth": 2,
      "y_preds[idx_to_score]": 2,
      "y_full[:len_ori]": 2,
      "y_full": 2,
      "val['log_revenue']": 2,
      "train['revenue']": 2,
      "y_upper": 2,
      "df_val[label]": 2,
      "np.log1p(y_true)": 2,
      "g": 2,
      "ypred": 2,
      "valid['target'].values": 2,
      "Y_test_mod": 2,
      "y2_test": 2,
      "y[test_index]": 2,
      "validation_predictions": 2,
      "tmp['preds']": 2,
      "tmp1['sflpred']": 2,
      "model.predict(Xt)": 2,
      "np.log1p(data['target'])": 2,
      "leak_df.pred4_l1p": 2,
      "sub.values": 2,
      "y_train[data[1]]": 2,
      "actualFVC": 2,
      "cur_y_test": 2,
      "target_test": 2,
      "y_tst": 2,
      "y_c_train": 2,
      "y_c_valid": 2,
      "y_cf_train": 2,
      "y_cf_valid": 2,
      "stack_val_preds": 2,
      "blend_val_preds": 2,
      "bagging_val_preds": 2,
      "ada_val_preds": 2,
      "train[target][ind]": 2,
      "self.y_test": 2,
      "target.iloc[val_idx]": 2,
      "y_train_k[valid_idx]": 2,
      "meta_valid_Y": 2,
      "train_p": 2,
      "yp1": 2,
      "train['deal_probability']": 2,
      "test['ConfirmedCases']": 2,
      "test['Fatalities']": 2,
      "np.exp(test['logConfirmedCases'])": 2,
      "np.exp(test_y)": 2,
      "train_y.iloc[val_idx]": 2,
      "y_test_actual": 2,
      "public_train_build[TARGETS[i]]": 2,
      "reg.predict(X_val)": 2,
      "all_target[i]": 2,
      "non_moa_test[:, cs]": 2,
      "data_test[:, cs]": 2,
      "non_moa_test[:, gs]": 2,
      "data_test[:, gs]": 2,
      "data_train[:, cs].T": 2,
      "data_test[:, cs].T": 2,
      "data_train[:, gs].T": 2,
      "data_test[:, gs].T": 2,
      "non_moa_test[:, cs].T": 2,
      "moa_train[:, cs].T": 2,
      "non_moa_test[:, gs].T": 2,
      "moa_train[:, gs].T": 2,
      "cells_test": 2,
      "genes_test": 2,
      "X.loc[~X['ConfirmedCases'].isna()]['ConfirmedCases']": 2,
      "oof1": 2,
      "trainSet2['SalePrice']": 2,
      "train_predictions_lgb": 2,
      "log_y_test": 2,
      "pred_train": 2,
      "ts_1_shifted_0": 2,
      "train_pred": 2,
      "y_test_cc": 2,
      "y_test_fat": 2,
      "main_pred": 2,
      "target_fe": 2,
      "target_be": 2,
      "true_sales": 2,
      "y_array": 2,
      "pred_valid": 2,
      "valid.fillna(-1)['count']": 2,
      "y_val[:, 0]": 2,
      "validate_y": 2,
      "val_Y": 2,
      "resp": 2,
      "rGB": 2,
      "rRF": 2,
      "respLGB": 2,
      "y_val_exp": 2,
      "Ycv": 2,
      "test.unit_sold": 2,
      "train_target": 2,
      "valid": 2,
      "pred.label_ids": 2,
      "valid_labels": 2,
      "valid_count_log": 2,
      "final_prediction": 2,
      "model.predict(X_val)": 2,
      "xgb_trainpred": 2,
      "xgb_final_trainpred": 2,
      "gbr_trainpred": 2,
      "gbr_final_trainpred": 2,
      "gbr_final_validpred": 2,
      "adr_trainpred": 2,
      "0.75 * train_oof_lgb + 0.25 * train_oof_xgb": 2,
      "train_oof_2": 2,
      "train_data['target']": 2,
      "modell.predict(X_test)": 2,
      "y_test_pred": 2,
      "y_cases": 2,
      "y2_train": 2,
      "y_test_df": 2,
      "test_final_all[33]": 2,
      "ts_truth": 2,
      "tr.target": 2,
      "np.log(df_v.SalePrice.values)": 2,
      "rf.predict(valid_X)": 2,
      "pred_df[d]": 2,
      "cases.iloc[0:13459]": 2,
      "y_true.detach().numpy()": 1,
      "train_df['log_revenue']": 1,
      "y_trainingSet": 1,
      "y_data[name][1:]": 1,
      "label_list": 1,
      "list(val_data['target'])": 1,
      "Y_val_pred": 1,
      "Y_train_pred": 1,
      "lr_pred": 1,
      "dt_pred": 1,
      "rf_pred": 1,
      "ab_pred": 1,
      "gb_pred": 1,
      "xgb_pred": 1,
      "lgbm_pred": 1,
      "lm.predict(valX[cols])": 1,
      "tree.predict(data=xgboost.DMatrix(valX[cols]))": 1,
      "y[valid_mask]": 1,
      "opt_sigma[valid_mask]": 1,
      "x['y']": 1,
      "x['so']": 1,
      "inv_y": 1,
      "y_1": 1,
      "y_2": 1,
      "target_log": 1,
      "y_val[:, n_public:N_DAYS]": 1,
      "np.array(y_val)[:, :n_public]": 1,
      "np.array(y_val)[:, n_public:]": 1,
      "y_train_final_c": 1,
      "y_train_final_f": 1,
      "Yts": 1,
      "y_train[1:]['target']": 1,
      "np.log(y_true[indstart:indend] + 1)": 1,
      "train_sales": 1,
      "y_valid_": 1,
      "y_test * 10**(-5)": 1,
      "y_monthly_test * 10**(-5)": 1,
      "prediction_val": 1,
      "df_train_preprocess[target]": 1,
      "trainpred.LARIMApred[(trainpred.serd > 70) & (trainpred.serd <= max(train.serd))]": 1,
      "trainpred.RLConfirmedCases[(trainpred.serd > 70) & (trainpred.serd <= max(train.serd))]": 1,
      "trainpred.LFatalities[(trainpred.serd > 70) & (trainpred.serd <= max(train.serd))]": 1,
      "trainpred.RLFatalities[(trainpred.serd > 70) & (trainpred.serd <= max(train.serd))]": 1,
      "Y_dists.mean()": 1,
      "y_val1": 1,
      "y_val2": 1,
      "y_test.astype('float32')": 1,
      "model.predict(dval)": 1,
      "y_test[0]": 1,
      "y_cross": 1,
      "y_log": 1,
      "sales_validation['val_demand']": 1,
      "site.x": 1,
      "site.y": 1,
      "fixed_df.x": 1,
      "fixed_df.y": 1,
      "sample_df.x": 1,
      "forecast_data.loc[i:i + 48, 'y']": 1,
      "y_val_": 1,
      "target.iloc[val_ind]": 1,
      "y_val_sum_true": 1,
      "train_arima_truth": 1,
      "df_train['target']": 1,
      "oof_clf1": 1,
      "oof_stack": 1,
      "oof_lgb_2": 1,
      "y_df['y_test']": 1,
      "df_y": 1,
      "regr.predict(x)": 1,
      "dev_y": 1,
      "xgb1_predict": 1,
      "xgb2_predict": 1,
      "rf1_predict": 1,
      "rf2_predict": 1,
      "lr_predicts": 1,
      "rCV_predicts": 1,
      "y_gt": 1,
      "[target[i]]": 1,
      "y_train[:j]": 1,
      "Y.values[test_index]": 1,
      "Y_testl1": 1,
      "self.y_val": 1,
      "train_revenue_predict": 1,
      "predictions.round()": 1,
      "df_preds_train['y']": 1,
      "y_baseline['y_train']": 1,
      "y_baseline['y_val']": 1,
      "cb_preds": 1,
      "model_val_preds": 1,
      "y_true.clip(0, 10000000000.0)": 1,
      "GBmodel.predict(validationX)": 1,
      "_y_train": 1,
      "y_val[y_val.y > 0]": 1,
      "clf.predict(X_test)": 1,
      "clf2.predict(X_test2)": 1,
      "simple_forest_pred": 1,
      "rf_best_pred": 1,
      "formation": 1,
      "bandgap": 1,
      "sample_y": 1,
      "y_trn_df": 1,
      "data_test['Weekly_Sales']": 1,
      "np.expm1(metrics['y'])": 1,
      "train_df[TARGETS[i]]": 1,
      "y_pred5": 1,
      "train['target'].values[va]": 1,
      "v_data.values": 1,
      "y_train_target": 1,
      "batch_pred": 1,
      "original_df.sales[-28:]": 1,
      "taxi_labels_val": 1,
      "val_test": 1,
      "results": 1,
      "df_train[target].reset_index(drop=True)": 1,
      "df_train.loc[mask_gmm_0, target]": 1,
      "df_train.loc[mask_gmm_1, target]": 1,
      "np.log1p(actuals)": 1,
      "confidence_valid > 0": 1,
      "y_pred_k": 1,
      "_pred": 1,
      "yDataFit01[:len(selectY)]": 1,
      "yDataFit02[:len(selectY)]": 1,
      "trainset_test_ynum": 1,
      "train['AdoptionSpeed']": 1,
      "yv_loc": 1,
      "test_cc": 1,
      "test_f": 1,
      "np.array(train_data.trip_duration)": 1,
      "train[LABEL]": 1,
      "ytr": 1,
      "ans1": 1,
      "ans3": 1,
      "ans3_tr": 1,
      "val_y['deal_probability'].values": 1,
      "np.nan_to_num(val_y[val_universe == 1])": 1,
      "y_train_c": 1,
      "trainY": 1,
      "df.target": 1,
      "table['yhat']": 1,
      "y_repeat": 1,
      "sample_google_distance": 1,
      "t": 1,
      "lr_y_pred": 1,
      "kf_val_y": 1,
      "y_test3": 1,
      "model.predict([train_im, train_measurements]).reshape(2400, 340)": 1,
      "lin_predictions": 1,
      "lin_predictions1": 1,
      "co2eq_test": 1,
      "P_train": 1,
      "P_train['target']": 1,
      "Y_valida1": 1,
      "y_true[:, -1]": 1,
      "y_oof": 1,
      "ModelData201510y": 1,
      "confidence_valid": 1,
      "true_sur": 1,
      "clf.predict(data[train_features])": 1,
      "pred[i]": 1,
      "mt_target_test": 1,
      "test_preds": 1,
      "final_pred_train": 1,
      "final_pred_validation": 1,
      "_y_valid": 1,
      "y_testVerisi": 1,
      "np.log(y_true + 1e-05)": 1,
      "test_predict": 1,
      "predictions_normal": 1,
      "predictions_pca": 1,
      "predictions_all": 1,
      "np.log(actuals)": 1,
      "X": 1,
      "y_hold": 1,
      "np.expm1(real)": 1,
      "y_valid[:, 1]": 1,
      "target_list": 1,
      "train_y.values": 1,
      "np.log1p(train_df['target'].iloc[val_idx])": 1,
      "np.log1p(train_df['target'])": 1,
      "base_data['Monthly Mean Total Sunspot Number']": 1,
      "train_dataset.df[col_target]": 1,
      "train_dataset.df[col_target_2]": 1,
      "y_val_test": 1,
      "y_valid_df": 1,
      "model.predict(val_X)": 1,
      "model.predict(val_x)": 1,
      "valid_yp": 1,
      "valid_yn": 1,
      "valid_prediction": 1,
      "Y_preds": 1,
      "Yval": 1,
      "unit_sales_by_date.values[moving_average_days:]": 1,
      "target_": 1,
      "Y_B": 1,
      "Y_C": 1,
      "y_train_Conf": 1,
      "y_test_Conf": 1,
      "y_train_Fat": 1,
      "y_test_Fat": 1,
      "y_valid[col]": 1,
      "np.expm1(Y_valid)": 1,
      "sales.diff().iloc[1:1001].values": 1,
      "model.predict(test_X)": 1,
      "targ": 1,
      "y_valid['target_carbon_monoxide']": 1,
      "y_valid['target_benzene']": 1,
      "y_valid['target_nitrogen_oxides']": 1,
      "test_actual": 1,
      "true.clip(0.0, 20.0)": 1,
      "prediction1": 1,
      "test.target": 1,
      "y_fit": 1,
      "y_test_1": 1,
      "y_BM_test": 1,
      "actual[:, i]": 1,
      "X_val.price": 1,
      "y_pred_RF": 1,
      "y_pred_df[['y_pred_RF', 'y_pred_XGB']].mean(axis=1)": 1,
      "valid['item_cnt_month']": 1,
      "train_df.SalePrice": 1,
      "dtrain['deal_probability'].values": 1,
      "lg_cf_pred": 1,
      "lg_d_pred": 1,
      "np.log1p(train.target)": 1,
      "res_df[col]": 1,
      "yte": 1,
      "y0_test": 1,
      "Y1_test": 1,
      "Y6_test": 1,
      "np.log(true)": 1,
      "np.log(train_y)": 1,
      "np.log(valid_y)": 1,
      "inv_y(rf_final_val_predictions)": 1,
      "X_train.Mean.values": 1,
      "validations": 1,
      "y_valid_final": 1,
      "y_valid_pca": 1,
      "test_y2": 1,
      "data_test[GENES].values": 1,
      "data_test[CELLS].values": 1,
      "true_pred": 1,
      "np.exp(self.Y_train)": 1,
      "zeroes": 1,
      "val_pred_col": 1,
      "arr['2016-01-01':'2017-01-02']": 1,
      "y_train_cv": 1,
      "y_val_cv": 1,
      "train_ys": 1,
      "pre": 1,
      "y_valid.values": 1,
      "dy_test": 1,
      "Y_target": 1,
      "y_pred_val": 1,
      "meta_lasso.predict(poly_first_level_val)": 1,
      "np.log1p(sub10[t].values)": 1,
      "np.log1p(df_panel[~df_panel.ConfirmedCases_val_xgb1.isna()].ConfirmedCases)": 1,
      "np.log1p(df_panel[~df_panel.Fatalities_val_xgb1.isna()].Fatalities)": 1,
      "np.log1p(df_panel[~df_panel.ConfirmedCases_val_xgb2.isna()].ConfirmedCases)": 1,
      "np.log1p(df_panel[~df_panel.Fatalities_val_xgb2.isna()].Fatalities)": 1,
      "np.log1p(df_panel[~df_panel.ConfirmedCases_val_lgb3.isna()].ConfirmedCases)": 1,
      "np.log1p(df_panel[~df_panel.Fatalities_val_lgb3.isna()].Fatalities)": 1,
      "np.log1p(df_panel[~df_panel.ConfirmedCases_val_lgb2.isna()].ConfirmedCases)": 1,
      "np.log1p(df_panel[~df_panel.Fatalities_val_lgb2.isna()].Fatalities)": 1,
      "Y_val_rf": 1,
      "Y_val_lr": 1,
      "val['revenue']": 1,
      "best_gam.predict(input_data[['label_country_list', 'label_genre_list', 'label_keywords_list', 'label_crew_list', 'label_cast_list', 'label_prod_list', 'label_tagline', 'label_overview_fst', 'img_label', 'year_to_lst_film_col', 'film_count_col', 'log_revenue_col', 'year_to_lst_film_dir', 'film_count_dir', 'log_revenue_dir', 'popularity', 'runtime', 'release_year', 'release_month', 'log_budget', 'release_day']].values)": 1,
      "target.loc[val_idx]": 1,
      "np.vstack(labels)": 1,
      "rescaled_y_test": 1,
      "standard_y_test": 1,
      "actual_labels": 1,
      "dataset_test[label]": 1,
      "L": 1,
      "lgbm_oof": 1,
      "xgb_oof": 1,
      "rf_oof": 1,
      "averaged_oof": 1,
      "bay_oof": 1,
      "np.log1p(y_test)": 1,
      "xgb_pred_val": 1,
      "lgb_pred_val": 1,
      "ridge_pred_val": 1,
      "xgb_pred_val_index": 1,
      "ridge_pred_val_index": 1,
      "lgb_pred_val_index": 1,
      "y_test_new": 1,
      "y_train_samp": 1,
      "np.log1p(dvalid.price)": 1,
      "y_test['target']": 1,
      "y_brute_pred": 1,
      "sales_cnt_valid": 1,
      "ypredtr": 1,
      "ypredtrft": 1,
      "ypred2": 1,
      "y.detach().cpu().numpy()": 1,
      "m.predict(x_test)": 1,
      "validy": 1,
      "y3_test": 1,
      "y4_test": 1,
      "y5_test": 1,
      "y01_test": 1,
      "y12_forest_test": 1,
      "y_valid_train[bayesian_val_index]": 1,
      "train_prediction": 1,
      "df_validation['count']": 1,
      "test_y_ohe": 1,
      "pred_xgb": 1,
      "y_true.cpu().numpy()": 1,
      "ztest": 1,
      "y_true_log": 1,
      "np.log(y_true)": 1,
      "y_val_rain": 1,
      "y_train_meter": 1,
      "to_np(targs.squeeze())": 1,
      "ys": 1,
      "clean_df['signal']": 1,
      "clean_test['signal']": 1,
      "reverse_test[:, store]": 1,
      "pred[[i]]": 1,
      "np.log1p(leak[f'pred{i}'])": 1,
      "log1p_then_mean": 1,
      "mean_then_log1p": 1,
      "gmb.transform(X)": 1,
      "fold_preds.numpy()": 1,
      "augmented_fold_preds.numpy()": 1,
      "y_test[col]": 1,
      "train_df_y.iloc[val_idx]": 1,
      "pred['y'][:-28]": 1,
      "y_valid_pred": 1,
      "validation_data_df.fare_amount": 1,
      "groundtruth['LogSumRevenue']": 1,
      "res1": 1,
      "train_df['AdoptionSpeed']": 1,
      "y_train_fold": 1,
      "y_test_fold": 1,
      "val_predict": 1,
      "pred_tr": 1,
      "va_pred": 1,
      "np.log(y_valid)": 1,
      "y_test_sampled": 1,
      "trueVpredict['true location']": 1,
      "true_y": 1,
      "inv_y(y_pred)": 1,
      "Y_predicted": 1,
      "y_pred_dtone": 1,
      "data1": 1,
      "np.log1p(train_y.values)": 1,
      "np.log1p(oof_pred_df['transactionRevenue'].values)": 1,
      "np.log1p(target['totals.transactionRevenue'])": 1,
      "y_t_knn": 1,
      "ada_train_preds": 1,
      "lgb_val_preds": 1,
      "lgb_train_preds": 1,
      "cat_val_preds": 1,
      "cat_train_preds": 1,
      "valid_['target'].values": 1,
      "clf.predict(X_train)": 1,
      "np.array([2.3])": 1,
      "test_data.loc[~test_data.visitors_predict.isnull(), 'visitors']": 1,
      "test_data['visitors']": 1,
      "val['target'].clip(0, 20)": 1,
      "val_y.values": 1,
      "y[sgd_list[i * 2][3]]": 1,
      "y[sgd_list[i * 2 + 1][3]]": 1,
      "np.log1p(y_reg.fillna(0))": 1,
      "np.log1p(data['target'].iloc[trn_])": 1,
      "np.log1p(data['target'].iloc[val_])": 1,
      "target_train": 1,
      "tr.deal_probability": 1,
      "y_pred_test": 1,
      "tmp_model.predict(train.ix[train_idxs])": 1,
      "y_train_predicted": 1,
      "y_test_predicted": 1,
      "outcome_var2.round()": 1,
      "df_eval['obs'].values": 1,
      "test['y']": 1,
      "meta_train_Y": 1,
      "pred_price": 1,
      "dfValid['scalar_coupling_constant']": 1,
      "yv2_val": 1,
      "yv18_val": 1,
      "yrez_val": 1,
      "np.log(y_true + 1)": 1,
      "np.exp(test['logFatalities'])": 1,
      "train_df['accuracy_group']": 1,
      "y_test_val": 1,
      "te_y": 1,
      "te_1_y": 1,
      "te_2_y": 1,
      "train['visitors']": 1,
      "testpredi": 1,
      "test['prediction']": 1,
      "model1.predict(train[independent_variable])": 1,
      "model1.predict(test[independent_variable])": 1,
      "oof_train[test_index]": 1,
      "o_rf": 1,
      "cat_valpredict": 1,
      "light_valpredict": 1,
      "light_trainPredict": 1,
      "cat_trainPredict": 1,
      "test.item_cnt_day": 1,
      "train_df['SalePrice']": 1,
      "np.log1p(y_pred)": 1,
      "lasso_pred": 1,
      "y_list[i]": 1,
      "reg.predict(X)": 1,
      "y_d": 1,
      "regr.predict(encodedCategories_X_test)": 1,
      "pre_trian[target]": 1,
      "reduce_train[target]": 1,
      "reduce_train[target][ind]": 1,
      "y_true0": 1,
      "y_true1": 1,
      "y_true2": 1,
      "y_true3": 1,
      "y_true4": 1,
      "XGB_classifier_predict_smote": 1,
      "oof2": 1,
      "oof3": 1,
      "y_ts": 1,
      "y_train.reshape(-1, 1)": 1,
      "y_test.reshape(-1, 1)": 1,
      "B_test": 1,
      "np.log1p(df_Train_Out.ConfirmedCases_x)": 1,
      "np.log1p(df_Train_Out.Fatalities_x)": 1,
      "y_pred_valid": 1,
      "y_valid_idx_mse": 1,
      "y_val0": 1,
      "np.log1p(pd.concat(results).sort_index()).loc[mask_9]": 1,
      "Y[valid_idx]": 1,
      "p_LinearModel": 1,
      "p_kNN": 1,
      "p_DT": 1,
      "p_GBR": 1,
      "p_RFR": 1,
      "p_ADA": 1,
      "p_XGB": 1,
      "pred_vals": 1,
      "y_train_val": 1,
      "train_label": 1,
      "dae_data[target_g]": 1,
      "valid_dl.dataset.y": 1,
      "trainDF.PneumSizeLog": 1,
      "validate_y_exp": 1,
      "train_targets": 1,
      "val_targets": 1,
      "Y_test_2": 1,
      "Y_test_3": 1,
      "dt_train_cases_pred": 1,
      "dt_train_fatal_pred": 1,
      "train['Pred_Demand']": 1,
      "val['Pred_Demand']": 1,
      "labels_test": 1,
      "np.exp(y_true)": 1,
      "i": 1,
      "d.loc[qvd, ya]": 1,
      "test['count']": 1,
      "itemObj[predictDateStr:]": 1,
      "df_test_Y.iloc[:, i]": 1,
      "x.target": 1,
      "train.deal_probability": 1,
      "np.log1p(df.target)": 1,
      "train.target": 1,
      "t[t <= threshold]": 1,
      "train.formation_energy_ev_natom": 1,
      "train.bandgap_energy_ev": 1,
      "meta_train[myfilter].distmod": 1,
      "np.log1p(b)": 1,
      "vistrain.visitors": 1,
      "blindtrain.visitors": 1,
      "np.log1p(train.formation_energy_ev_natom.values)": 1,
      "np.log1p(train.bandgap_energy_ev.values)": 1,
      "b": 1,
      "xgbtrainpreds.visitors.ravel()": 1,
      "test_y_pred": 1,
      "predicts_train": 1,
      "predicts_valid": 1,
      "pipe.predict(X_test)": 1,
      "lr_grid_best.predict(X_test)": 1,
      "ada_gs_grid_best.predict(X_test)": 1,
      "bgr_gs_grid_best.predict(X_test)": 1,
      "grad_boost_grid_best.predict(X_test)": 1,
      "Y_cv": 1,
      "Y_pred_lag": 1,
      "y_train.iloc[idxV]": 1,
      "in_y_all": 1,
      "self.y_valid": 1,
      "self.all_targets": 1,
      "y_train_scaled[0:1459]": 1,
      "modelRegression.predict(x_train)": 1,
      "modelRegression.predict(x_test)": 1,
      "modelRegression2.predict(x_train2)": 1,
      "modelRegression2.predict(x_test2)": 1,
      "modelRegression3.predict(x_train3)": 1,
      "modelRegression3.predict(x_test3)": 1,
      "y_test_": 1,
      "svm_test_pred": 1,
      "test_bayesian_pred": 1,
      "y_fullcv_test": 1,
      "model.predict(x_test)": 1,
      "np.log1p(y_reg.astype(np.float))": 1,
      "y_val_reg_pred": 1,
      "real_sales": 1,
      "test[:, -1]": 1,
      "y_test_cv": 1,
      "val[test_index, 0]": 1,
      "y_test_gam": 1,
      "y_test_gam_cc": 1,
      "xgb_model.predict(X_test)": 1,
      "lgbm_regr.predict(X_test)": 1,
      "final_model.predict(S_train)": 1,
      "lgbm.predict(X)": 1,
      "xgbReg.predict(X)": 1,
      "xgbpreds": 1,
      "y_valid_idx": 1,
      "y_dev": 1,
      "y_t": 1,
      "real_Y": 1,
      "targets[:len(toxicity_scores)]": 1,
      "obscenities[:len(toxicity_scores)]": 1,
      "severe_toxicities[:len(toxicity_scores)]": 1,
      "np.array(Y_train)": 1,
      "np.array(Y_test)": 1,
      "y_true_val": 1,
      "y_tests": 1,
      "y_inlier": 1,
      "y_test_knn": 1,
      "test_y_cap": 1,
      "test_y_cap2": 1,
      "training_predictions": 1,
      "y1_test": 1,
      "Xy_test['item_cnt_day']": 1,
      "data_train_copy['target']": 1,
      "label_arr[val_idx]": 1,
      "label_arr": 1,
      "y_label": 1,
      "train_oof_lgb": 1,
      "train_oof_xgb": 1,
      "0.6 * train_oof + 0.4 * train_oof_2": 1,
      "0.5 * train_oof + 0.5 * train_oof_2": 1,
      "x_test": 1,
      "Xs[:, -28:]": 1,
      "Y_test.iloc[:, i]": 1,
      "yptest": 1,
      "pr_sales_by_months['item_cnt_day'][33]": 1,
      "pr_test_categories_without_shops['item_cnt_day', 33]": 1,
      "pr_test_categories_by_shops['item_cnt_day', 33]": 1,
      "regressor.predict(X_valid)": 1,
      "predict(valid_test_dataloader, model)": 1,
      "validation_y.values": 1,
      "np.log1p(df_panel[~df_panel['ConfirmedCases_val_lgb'].isna()]['ConfirmedCases'])": 1,
      "np.log1p(df_panel[~df_panel['Fatalities_val_lgb'].isna()]['Fatalities'])": 1,
      "np.log1p(df_panel[~df_panel['ConfirmedCases_val_mad'].isna()]['ConfirmedCases'])": 1,
      "np.log1p(df_panel[~df_panel['Fatalities_val_mad'].isna()]['Fatalities'])": 1,
      "np.log1p(df_test_full['ConfirmedCases'].values)": 1,
      "np.log1p(df_test_full['Fatalities'].values)": 1,
      "np.log1p(df_test_full[df_test_full['geography'] == country]['ConfirmedCases'].fillna(-1))": 1,
      "np.log1p(df_test_full[df_test_full['geography'] == country]['Fatalities'].fillna(-1))": 1,
      "us_va['Fatalities']": 1,
      "data['ConfirmedCases']": 1,
      "y_test['log(price)'].values": 1,
      "target_data.iloc[index]": 1,
      "Y_valid.values": 1,
      "true_sales_day": 1,
      "train_f_tr['item_cnt_month'].to_numpy()": 1,
      "train_f_t['item_cnt_month'].to_numpy()": 1,
      "train['pred']": 1,
      "final_train[33]": 1,
      "yCM_valid_cv": 1,
      "yB_valid_cv": 1,
      "yNO_valid_cv": 1,
      "ytrain[val_idx]": 1,
      "test_y_bench": 1,
      "X_test_m": 1,
      "country_data.ConfirmedCases.values": 1,
      "y_true.reshape(-1, n_out)": 1,
      "y_true[~mask[:, j], j]": 1,
      "forecast[col]": 1,
      "y_test_CC": 1,
      "y_test_Fa": 1,
      "np.log1p(df_panel[~df_panel.ConfirmedCases_val_logy.isna()].ConfirmedCases)": 1,
      "np.log1p(df_panel[~df_panel.Fatalities_val_logy.isna()].Fatalities)": 1,
      "np.log1p(pred_df['transactionRevenue'].values)": 1,
      "y_org_test": 1,
      "y_shift_test": 1,
      "[y_test.values[i]]": 1,
      "b_test['Lake_Level']": 1,
      "b_test.loc[:datetime.date(2017, 1, 1), 'Lake_Level']": 1,
      "b_test['Flow_Rate']": 1,
      "b_test.loc[:datetime.date(2017, 1, 1), 'Flow_Rate']": 1,
      "error_calc_df['Depth_to_Groundwater_P24']": 1,
      "error_calc_df['Depth_to_Groundwater_P25']": 1,
      "monthly_pred['Depth_to_Groundwater_P24']": 1,
      "monthly_pred['Depth_to_Groundwater_P25']": 1,
      "pred_df.loc[:datetime.date(2019, 1, 1), d]": 1,
      "pred_df.loc[:datetime.date(2015, 1, 1), d]": 1,
      "val_pred2": 1,
      "leak_df.pred5_l1p": 1,
      "prediction_XG": 1,
      "np.log(y_val_in)": 1,
      "y_val_in_log": 1,
      "valid[y]": 1,
      "valid['duration_group']": 1,
      "valid['trip_duration']": 1,
      "processed_img / 255.0": 1,
      "null": 1
    },
    "sklearn.metrics._regression.mean_squared_error.y_pred": {
      "y_pred": 1044,
      "predictions": 459,
      "pred": 260,
      "preds": 258,
      "y_test": 177,
      "target": 167,
      "predicted": 129,
      "oof": 104,
      "y_val": 73,
      "leak_df.meter_reading_l1p": 58,
      "oof_preds": 56,
      "prediction": 55,
      "y_train": 54,
      "pred.ravel()": 53,
      "y_predict": 51,
      "y_predicted": 50,
      "y": 49,
      "p": 46,
      "y_train_pred": 45,
      "Y1": 44,
      "y_pred_rf": 43,
      "y_pred_valid": 42,
      "model.predict(X_val)": 41,
      "y_preds": 40,
      "yhat": 38,
      "np.log(y_pred[:] + 1)": 38,
      "Y2": 38,
      "train_preds": 36,
      "test_hist": 35,
      "oof_reg_preds": 34,
      "val_preds": 33,
      "val_y": 33,
      "y_valid_pred_total": 33,
      "y_test_pred": 32,
      "y_valid": 28,
      "oof_pred": 26,
      "train_pred": 25,
      "oof[val_idx]": 25,
      "preds_valid": 25,
      "val_pred": 24,
      "predict_one(dev_df, models)[:, i]": 23,
      "val_predictions": 22,
      "y_pred_train": 22,
      "val_target": 22,
      "y_valid_pred": 21,
      "np.array(val_pred).transpose()": 21,
      "pred_train": 20,
      "Y_test": 20,
      "lgb_clf.predict(X_valid)": 20,
      "y_train_predict": 20,
      "np.log1p(sub2[t].values)": 19,
      "np.log1p(df_panel[~df_panel.ConfirmedCases_val_lgb.isna()].ConfirmedCases_val_lgb)": 19,
      "np.log1p(df_panel[~df_panel.Fatalities_val_lgb.isna()].Fatalities_val_lgb)": 19,
      "y_val_pred": 19,
      "pred_val": 19,
      "Y_valida_pred": 18,
      "Y_test_predict": 18,
      "y_head": 18,
      "test_y": 18,
      "validate_y_pred_inv": 17,
      "LR.predict(x_train)": 17,
      "ridge_oof_train": 17,
      "np.log1p(df_panel[~df_panel.ConfirmedCases_val_mad.isna()].ConfirmedCases_val_mad)": 17,
      "np.log1p(df_panel[~df_panel.Fatalities_val_mad.isna()].Fatalities_val_mad)": 17,
      "oof_preds[val_idx]": 17,
      "model.predict(X_test)": 17,
      "y_pred_inv": 16,
      "LR.predict(x_test)": 16,
      "housing_predictions": 16,
      "y_simple_linear": 15,
      "np.log1p(val_pred_df['PredictedRevenue'].values)": 15,
      "Y_val": 15,
      "pred_test": 15,
      "y_prediction": 15,
      "tar_valid": 15,
      "RFR.predict(x_train)": 14,
      "RFR.predict(x_test)": 14,
      "test_pred": 14,
      "p[:, TRAIN_N:TRAIN_N + val_len].flatten()": 14,
      "Y_pred": 14,
      "preds_train": 14,
      "y_dummy": 13,
      "y_hat": 13,
      "pred_f": 13,
      "inv_y(y_test)": 13,
      "y_pred1": 13,
      "y_pred['yhat']": 13,
      "pred_rf": 13,
      "ypred": 13,
      "pred2": 12,
      "rfr.predict(x_test)": 12,
      "preds_c[:, d]": 12,
      "preds_f[:, d]": 12,
      "np.log(prediction)": 12,
      "y_val_predict": 12,
      "y_val[i]": 12,
      "predictions_valid": 12,
      "predictions1": 11,
      "estimator.predict(X_val)": 11,
      "rid.predict(x_test)": 11,
      "df_base.iloc[:, j + 1]": 11,
      "allpreds": 11,
      "train['target']": 11,
      "model.predict(train[col])": 11,
      "y_true": 11,
      "pred_y": 11,
      "np.log1p(v1)": 11,
      "oof_stack": 10,
      "y_pred_xgb": 10,
      "preds_val": 10,
      "y_pred_test": 10,
      "las.predict(x_test)": 10,
      "xgb.predict(x_test)": 10,
      "lgb.predict(x_test)": 10,
      "y_pred2": 10,
      "preds_c[:, TRAIN_N:TRAIN_N + val_len].flatten()": 10,
      "preds_f[:, TRAIN_N:TRAIN_N + val_len].flatten()": 10,
      "df_pred['weekly_sales_pred']": 10,
      "tar_train": 10,
      "np.array(val_pred).squeeze(axis=2).transpose()": 9,
      "estimator.predict(X_tr)": 9,
      "predict": 9,
      "np.log1p(tmp['compiled_leak']).fillna(14.49)": 9,
      "y_pred_lgb": 9,
      "train_df['target']": 9,
      "preds2": 9,
      "pred_i": 9,
      "X_train_preds": 9,
      "X_test_preds": 9,
      "pred_oof": 9,
      "rfr.predict(X_train)": 8,
      "y_pred_scaled": 8,
      "valid_pred": 8,
      "lstm_train_pred": 8,
      "np.expm1(predictions)": 8,
      "oof_rg[val_ind]": 8,
      "pred_xgb": 8,
      "y_pred_val": 8,
      "gbr_preds": 8,
      "resposta": 8,
      "predictions2": 7,
      "y_val2": 7,
      "preds_ridge": 7,
      "train_cleaned_df.iloc[:, train_cleaned_df.columns == 33].values": 7,
      "Model.predict(X_val)": 7,
      "pred_knn": 7,
      "y_pred_lr": 7,
      "pred_lr": 7,
      "yhatList[0:34]": 7,
      "pred1": 7,
      "oof[test_index]": 7,
      "y2_pred": 7,
      "oof_pred_arr": 7,
      "valid_y": 7,
      "folds_average_lgbm.oof_preds": 7,
      "clf.predict(X_train)": 6,
      "clf.predict(X_test)": 6,
      "y_pred_dt": 6,
      "xgb_pred": 6,
      "np.minimum(np.array(val_pred).transpose(), np.log1p(MAX_PRED))": 6,
      "clf.predict(train[elt2 + [elt]])": 6,
      "RFG.predict(x_test)": 6,
      "mlp_train_pred": 6,
      "mlp_valid_pred": 6,
      "cnn_train_pred": 6,
      "cnn_valid_pred": 6,
      "lstm_valid_pred": 6,
      "cnn_lstm_train_pred": 6,
      "cnn_lstm_valid_pred": 6,
      "np.mean(preds[:i + 1], axis=0)": 6,
      "Y_valid": 6,
      "xg_oof_train": 6,
      "valid_preds": 6,
      "df.loc[valid_idx, 'target']": 6,
      "test['demand']": 6,
      "df_pred['pred_weekly_sales']": 6,
      "rf_prediction": 6,
      "confirm_test_case": 6,
      "fatal_test_case": 6,
      "pred_labels": 6,
      "y_pred_gb": 6,
      "d.loc[q, 'y0_pred']": 6,
      "d.loc[q, 'y1_pred']": 6,
      "temp_fold_preds": 6,
      "y_predicted_train": 6,
      "ty_pred": 6,
      "reg.predict(X_train)": 5,
      "model.predict(X_train)": 5,
      "np.log1p(validation_res['predictedrevenue'].values)": 5,
      "oof_train": 5,
      "pred3": 5,
      "y_val1": 5,
      "y_val3": 5,
      "all_preds": 5,
      "et_oof_train": 5,
      "rf_oof_train": 5,
      "model.predict(x_test)": 5,
      "train_predictions": 5,
      "oof_reg_preds1": 5,
      "oof_reg_preds2": 5,
      "pred_df['pred']": 5,
      "rf.predict(X_test)": 5,
      "train_predict": 5,
      "test_predict": 5,
      "model.predict(dtrain_)": 5,
      "xgb_train_pred": 5,
      "xgb_val_pred": 5,
      "lr_train_pred": 5,
      "lr_val_pred": 5,
      "final_predictions": 5,
      "tmp_oof_pred": 5,
      "oof_pred_avg": 5,
      "output": 5,
      "pred_ridge": 5,
      "y1": 5,
      "pred_test1": 5,
      "preds1": 5,
      "pre": 5,
      "y_pred + b_test": 5,
      "predictedtest": 5,
      "dmy.predict(X_train)": 4,
      "pred_validation": 4,
      "Dec_Tree": 4,
      "train_pred2": 4,
      "train_pred3": 4,
      "np.log(y_train_pred + 1)": 4,
      "np.log(y_test_pred + 1)": 4,
      "Lpred2": 4,
      "predictions_rforest": 4,
      "deep_predictions": 4,
      "model.predict(dev_df[features])[:, i]": 4,
      "np.array(val_pred).squeeze(axis=2).transpose()[:, :n_public]": 4,
      "np.array(val_pred).squeeze(axis=2).transpose()[:, n_public:]": 4,
      "Y_predict": 4,
      "y.ix[indextrain]": 4,
      "predict_val": 4,
      "y_pred_final": 4,
      "val": 4,
      "y_pred_train_site": 4,
      "y_insample_pred": 4,
      "cb_oof_train": 4,
      "xg_pred": 4,
      "np.expm1(y_val_predictions)": 4,
      "predict1": 4,
      "val_y_pred": 4,
      "np.log1p(validation_res['predictedRevenue'].values)": 4,
      "oof_preds1": 4,
      "both_oof": 4,
      "merge_pred": 4,
      "predicted_values": 4,
      "predict_train_cases": 4,
      "predict_train_fatalities": 4,
      "y_poly_pred": 4,
      "data['predicted_gwh']": 4,
      "oof_vanilla": 4,
      "fun(x, *popt)": 4,
      "submission_preds_df.mean(axis=1)": 4,
      "preds_ensemble_avg": 4,
      "GBR_pred": 4,
      "predict_train": 4,
      "rf_pred": 4,
      "regressor.predict(X_train)": 4,
      "catboost_train_pred": 4,
      "catboost_val_pred": 4,
      "knn_train_pred": 4,
      "knn_val_pred": 4,
      "predict_dt1": 4,
      "rf.predict(valid[feats])": 4,
      "oof_predictions": 4,
      "lasso.predict(X)": 4,
      "y_pred_br": 4,
      "np.clip(oof, a_min=0, a_max=None)": 4,
      "final_prediction": 4,
      "y_predict_rf": 4,
      "predictValues": 4,
      "np.log(y_pred)": 4,
      "y_pre.clip(0.0, 20.0)": 4,
      "Y_guess_train": 4,
      "Y_base_train": 4,
      "Y_guess": 4,
      "Y_base": 4,
      "predictions_test": 4,
      "ytest": 4,
      "rf_preds": 4,
      "pred_trn": 4,
      "pred_Y": 4,
      "validation_test['pred']": 4,
      "Y_pred_train": 4,
      "predictions_fat": 4,
      "predict_test": 4,
      "np.log1p(y_test)": 4,
      "np.log1p(y_test_2)": 4,
      "np.log1p(y_val)": 4,
      "np.log1p(y_val_2)": 4,
      "np.log1p(leak.meter_reading)": 4,
      "Y_valid_pred": 4,
      "train_oof_preds": 4,
      "rf.oob_prediction_": 4,
      "y_eval": 4,
      "Test_us['yhat']": 4,
      "test[dependent_variable]": 4,
      "fold_prediction": 4,
      "y_test_predict": 4,
      "model.predict(df[feature_col].replace(values_dict).values.reshape(-1, 1))[:, 1]": 4,
      "ts_2_shifted": 4,
      "np.exp(y_pred)": 4,
      "comparison[:, 1]": 4,
      "img_array[0]": 4,
      "predictions_lst": 4,
      "gr_predict": 4,
      "y_predV": 3,
      "rfr_preds": 3,
      "knn_preds": 3,
      "y_null": 3,
      "ridge.predict(X_test)": 3,
      "gbr_predictions": 3,
      "df_train_processed['LGBPredictions']": 3,
      "df_train_processed['CBPredictions']": 3,
      "df_train_processed['XGBPredictions']": 3,
      "df_train_processed['RFPredictions']": 3,
      "lr_pred": 3,
      "y_pred[:, 0]": 3,
      "np.array(val_pred)": 3,
      "np.minimum(np.array(val_pred).transpose()[:, :n_public], np.log1p(MAX_PRED))": 3,
      "np.minimum(np.array(val_pred).transpose()[:, n_public:], np.log1p(MAX_PRED))": 3,
      "preds_my_test_mean": 3,
      "np.repeat(np.mean(Y_val.Yards), len(Y_val))": 3,
      "test_prediction": 3,
      "valid['rentals']": 3,
      "test_predictions": 3,
      "model2.predict(X_test)": 3,
      "oof_preds.clip(0.0, 20.0)": 3,
      "np.log1p(p)": 3,
      "rf.predict(X_train)": 3,
      "preds_cv": 3,
      "lasso_predict": 3,
      "train_y": 3,
      "np.log1p(train['compiled_leak']).fillna(14.49)": 3,
      "train_preds_lr_stacking": 3,
      "train_preds_sgdr_stacking": 3,
      "predict_val_cases": 3,
      "predict_val_fatalities": 3,
      "df['oof']": 3,
      "merge_preds": 3,
      "np.zeros(val_x.shape[0])": 3,
      "y_test_preds": 3,
      "Y": 3,
      "df['target']": 3,
      "pred_rfr": 3,
      "cb_model.predict(X_valid)": 3,
      "y_pre": 3,
      "df_oof.oof": 3,
      "valid_targets": 3,
      "y_predicted_r": 3,
      "clf.predict(train_feature[va])": 3,
      "ridge.predict(train_feature[va])": 3,
      "oof_cat": 3,
      "preds_c_cpmp[:, d - START_PUBLIC]": 3,
      "preds_f_cpmp[:, d - START_PUBLIC]": 3,
      "preds_c_cpmp[:, TRAIN_N - START_PUBLIC:TRAIN_N - START_PUBLIC + val_len].flatten()": 3,
      "preds_f_cpmp[:, TRAIN_N - START_PUBLIC:TRAIN_N - START_PUBLIC + val_len].flatten()": 3,
      "preds_c_oscii[:, d - START_PUBLIC]": 3,
      "preds_f_oscii[:, d - START_PUBLIC]": 3,
      "preds_c_oscii[:, TRAIN_N - START_PUBLIC:TRAIN_N - START_PUBLIC + val_len].flatten()": 3,
      "preds_f_oscii[:, TRAIN_N - START_PUBLIC:TRAIN_N - START_PUBLIC + val_len].flatten()": 3,
      "preds_c_blend[:, i]": 3,
      "preds_f_blend[:, i]": 3,
      "preds_c_blend[:, :val_len].flatten()": 3,
      "preds_f_blend[:, :val_len].flatten()": 3,
      "y_test_pred2": 3,
      "best_preds": 3,
      "PREDS": 3,
      "oof_lgb": 3,
      "y_cv": 3,
      "log_pred[have_data]": 3,
      "rf_train_pred": 3,
      "rf_val_pred": 3,
      "Y_validation": 3,
      "forecast": 3,
      "holdout_pred": 3,
      "y_pred_2": 3,
      "linear_pred": 3,
      "train['4_preds']": 3,
      "preds3": 3,
      "Y_train_pred": 3,
      "Y_test_pred": 3,
      "pred_poly": 3,
      "oof_preds2": 3,
      "oof_df.loc[oof_df.index.isin(val_idx)]['oof']": 3,
      "oof_df['oof']": 3,
      "yv": 3,
      "df['count_predicted']": 3,
      "pred_svr": 3,
      "dtrain_predictions": 3,
      "models[num].predict(train_X)": 3,
      "models[num].predict(valid_X)": 3,
      "trainPredict[:, 0]": 3,
      "testPredict[:, 0]": 3,
      "train_1[start_index:end_index]['forecast']": 3,
      "xtrain['target']": 3,
      "np.mean(pred_val_all[:idx + 1], 0)": 3,
      "np.dot(np.hstack(pred_val_all[:idx + 1]), weights.reshape(-1, 1))": 3,
      "y_hold": 3,
      "preds_oof": 3,
      "preds_f": 3,
      "pred_svc": 3,
      "Y_train": 3,
      "actual": 3,
      "np.array(val_preds)": 3,
      "true": 3,
      "X_test['Pred']": 3,
      "oof_total": 3,
      "oof[:, 0]": 3,
      "np.log1p(df[~df.ConfirmedCases_val_lgb.isna()].ConfirmedCases_val_lgb)": 3,
      "np.log1p(df[~df.Fatalities_val_lgb.isna()].Fatalities_val_lgb)": 3,
      "np.log1p(df[~df.ConfirmedCases_val_mad.isna()].ConfirmedCases_val_mad)": 3,
      "np.log1p(df[~df.Fatalities_val_mad.isna()].Fatalities_val_mad)": 3,
      "va_pred": 3,
      "oof_pred[ind]": 3,
      "ytest_pred": 3,
      "np.exp(preds)": 3,
      "y_test1": 3,
      "train_y_pred": 3,
      "ccases_pred[0:ntrain]": 3,
      "deaths_pred[0:ntrain]": 3,
      "a": 3,
      "y_log": 3,
      "testPredictions": 3,
      "test_preds": 3,
      "regr.predict(X_test)": 3,
      "rfr.predict(train[colx])": 3,
      "lgb_pred_test": 3,
      "lgb_pred_train": 3,
      "pred_test_y": 3,
      "rf.predict(X_valid).clip(0.0, 20.0)": 3,
      "clf.predict(X_val)": 3,
      "y_test_confirmed": 3,
      "train_df_label": 3,
      "yp": 3,
      "xgb_grid.predict(X_test)": 3,
      "ensemble_preds": 3,
      "randomForestPredict": 3,
      "y_predicted_d": 3,
      "cases_pred": 3,
      "rdg_predict": 3,
      "rf_predict": 3,
      "model.predict(x_valid_cv, num_iteration=model.best_iteration)": 3,
      "clf1.predict(x)": 3,
      "np.log(y_test)": 3,
      "y_validation": 3,
      "train_copy['log_revenue_pred']": 2,
      "test": 2,
      "test2": 2,
      "test_food": 2,
      "test_hobbies": 2,
      "test_household": 2,
      "Ridge": 2,
      "Lasso": 2,
      "test_pred2": 2,
      "test_pred3": 2,
      "lr_preds": 2,
      "valY": 2,
      "grid_predictions": 2,
      "lightgbm_predictions": 2,
      "svr_predictions": 2,
      "xgboost_predictions": 2,
      "elastic_predictions": 2,
      "lasso_predictions": 2,
      "stack_predictions": 2,
      "blend_predictions": 2,
      "y_pred_ridge": 2,
      "df_train_processed[prediction_column]": 2,
      "df_train_processed['FinalPredictions']": 2,
      "val_pred_df['PredictedRevenue'].values": 2,
      "rfr_pred": 2,
      "val_test_pred_lgb": 2,
      "p_out": 2,
      "X_target[X[X.date_block_num == 33].index].clip(0, 20)": 2,
      "oof_preds[name]": 2,
      "0.6 * oof_preds['lgb'] + 0.4 * oof_preds['xgb']": 2,
      "valid_prediticion": 2,
      "train.LConfirmedCases[train.serd > 70]": 2,
      "train.LFatalities[train.serd > 70]": 2,
      "reg_y_pred": 2,
      "reg_y_test_pred": 2,
      "dtr.predict(x_test)": 2,
      "y_predicted_cases_val": 2,
      "y_predicted_fatal_val": 2,
      "train['preds']": 2,
      "model1.predict(X_test)": 2,
      "lasso.predict(X_test)": 2,
      "predictions.values": 2,
      "lgb.predict(X_val)": 2,
      "oof_svm[val_ind]": 2,
      "oof_rf[val_ind]": 2,
      "rf_model.predict(X_val)": 2,
      "cy": 2,
      "fy": 2,
      "forest_predictions": 2,
      "lr_y": 2,
      "svr_y": 2,
      "knn_y": 2,
      "dt_y": 2,
      "rf_y": 2,
      "xgb_y": 2,
      "adb_y": 2,
      "xgh_y_pred": 2,
      "hadb_y_pred": 2,
      "test_preds_lr_stacking": 2,
      "test_preds_sgdr_stacking": 2,
      "oof_ridge": 2,
      "oof_preds[valid_idx]": 2,
      "testY2": 2,
      "testY1": 2,
      "lr.predict(X_q_train)": 2,
      "y_predicted_values": 2,
      "previsao": 2,
      "treino_preds": 2,
      "y_train_preds": 2,
      "model.predict(X_tr)": 2,
      "predic": 2,
      "alpha * X_train_level2[:, 0] + (1 - alpha) * X_train_level2[:, 1]": 2,
      "XGB.predict(x_train)": 2,
      "XGB.predict(x_test)": 2,
      "LGBM.predict(x_train)": 2,
      "LGBM.predict(x_test)": 2,
      "y_pred_tr": 2,
      "y_baseline['y_train_avg']": 2,
      "val_pred_": 2,
      "pipeline.predict(xvalid)": 2,
      "y_pred_sgd": 2,
      "temp_predict": 2,
      "train_oof": 2,
      "pred_lgb_val": 2,
      "pred_lr_val": 2,
      "gt['sale']": 2,
      "pred_cnt.clip(0.0, 20.0)": 2,
      "np.log1p(predictions)": 2,
      "preds_c[:, START_PUBLIC:START_PUBLIC + val_len].flatten()": 2,
      "preds_f[:, START_PUBLIC:START_PUBLIC + val_len].flatten()": 2,
      "p_c_vopani[:, d]": 2,
      "p_f_vopani[:, d]": 2,
      "p_c_vopani[:, START_PUBLIC:START_PUBLIC + val_len].flatten()": 2,
      "p_f_vopani[:, START_PUBLIC:START_PUBLIC + val_len].flatten()": 2,
      "preds_c_david[:, i]": 2,
      "preds_f_david[:, i]": 2,
      "preds_c_david[:, :val_len].flatten()": 2,
      "preds_f_david[:, :val_len].flatten()": 2,
      "preds_c_oscii[:, d]": 2,
      "preds_f_oscii[:, d]": 2,
      "preds_c_oscii[:, START_PUBLIC:START_PUBLIC + val_len].flatten()": 2,
      "preds_f_oscii[:, START_PUBLIC:START_PUBLIC + val_len].flatten()": 2,
      "preds_c_blend[:, d]": 2,
      "preds_f_blend[:, d]": 2,
      "preds_c_blend[:, START_PUBLIC:START_PUBLIC + val_len].flatten()": 2,
      "preds_f_blend[:, START_PUBLIC:START_PUBLIC + val_len].flatten()": 2,
      "oof_train_lin": 2,
      "np.log1p(df[col2].values)": 2,
      "selectY": 2,
      "Y_validation_pred": 2,
      "model.predict(np.array(val_features))": 2,
      "pred_lgbm": 2,
      "ridge_pred": 2,
      "np.full(train[TARGET].shape, train[TARGET].median())": 2,
      "pred_cases": 2,
      "pred_fatalities": 2,
      "y_valid1_np": 2,
      "cb_preds": 2,
      "estimator.predict(X)": 2,
      "y_c": 2,
      "prediction.cpu().detach().numpy()": 2,
      "y_lr": 2,
      "y_rf": 2,
      "rr100.predict(X_train)": 2,
      "lasso.predict(X_train)": 2,
      "lstm_val_pred": 2,
      "mlp_train_pred2": 2,
      "mlp_val_pred2": 2,
      "y_pred_knn": 2,
      "y_pred_1": 2,
      "stack_pred": 2,
      "y_pred_rfr": 2,
      "y_pred_gbr": 2,
      "pred_valid": 2,
      "output['pred'].to_numpy()": 2,
      "lg_oof_train": 2,
      "valid_prediction": 2,
      "pre_train": 2,
      "pre_test": 2,
      "train_sarima_forecasted": 2,
      "np.mean(y_pred_list, axis=0)": 2,
      "train['2_preds']": 2,
      "oof_stack[test_index]": 2,
      "dt_prediction": 2,
      "gbr.predict(x_train)": 2,
      "validation_y": 2,
      "ridge.predict(X)": 2,
      "train_pred1": 2,
      "val_pred1": 2,
      "val_pred2": 2,
      "val_pred3": 2,
      "y_pred_SVR": 2,
      "y_pred_gbm": 2,
      "y_pred_8": 2,
      "predict_y": 2,
      "regressor.predict(X_val)": 2,
      "oof[test_idx]": 2,
      "hold_pred": 2,
      "np.expm1(pred)": 2,
      "fold_oof_df['pred_FVC'].values": 2,
      "oof_df['pred_FVC']": 2,
      "df_train_processed['RRPredictions']": 2,
      "df_train_processed['SVMPredictions']": 2,
      "df_train_processed['TMLPPredictions']": 2,
      "df_train_processed['RMLPPredictions']": 2,
      "oof_df.loc[oof_df.iloc[val_idx].index]['oof']": 2,
      "oof_df.oof": 2,
      "y_hat_val": 2,
      "lgb_pred": 2,
      "y_hat_avg['SARIMA']": 2,
      "oof[valid_idx]": 2,
      "model.predict(X_valid)": 2,
      "y_predict_1_2": 2,
      "Y_pred_level2": 2,
      "pred_lasso": 2,
      "pred_dt": 2,
      "predictValues1": 2,
      "pred4": 2,
      "pred5": 2,
      "predictValues2": 2,
      "pred6": 2,
      "predictValues3": 2,
      "pred7": 2,
      "yoof_pred": 2,
      "svc.predict(X_e)": 2,
      "pa.predict(X_e)": 2,
      "ridge_predict": 2,
      "RFclass_pred": 2,
      "rf.predict(x2).clip(0.0, 20.0)": 2,
      "Y_guess_val": 2,
      "Y_base_val": 2,
      "lables": 2,
      "predictions_train": 2,
      "pred_results_combined.Pred": 2,
      "np.clip(oof_preds, 0, None)": 2,
      "np.square(np.exp(model.predict(X_train)))": 2,
      "np.square(np.exp(model.predict(X_valid)))": 2,
      "y_pred_pca": 2,
      "DT_random.best_estimator_.predict(DT_Train)": 2,
      "DT_random.best_estimator_.predict(DT_Test)": 2,
      "y_val.iloc[:, i]": 2,
      "y_val_sc[0].values": 2,
      "pred1s": 2,
      "self.xg_prediction_train": 2,
      "self.xg_prediction_test": 2,
      "pred.predicted_mean": 2,
      "np.log1p(oof_preds)": 2,
      "initial_preds": 2,
      "y_true[idx_to_score]": 2,
      "pred_nn": 2,
      "y_pred3": 2,
      "np.log1p(sub4[t].values)": 2,
      "np.repeat(train['log_revenue'].mean(), train.shape[0])": 2,
      "train['log_revenue_mean']": 2,
      "val['log_revenue_mean']": 2,
      "y_pred_GBoost": 2,
      "reg.predict(x2).clip(0.0, 20.0)": 2,
      "i.predict(x_test)": 2,
      "y_train2_pred": 2,
      "y_test2_pred": 2,
      "np.log1p(y_pred)": 2,
      "predict_1": 2,
      "predict_2": 2,
      "y_train_pred_2": 2,
      "y_test_pred_2": 2,
      "test_features.winPlacePerc": 2,
      "y_pred_lgb_scaled_tuned": 2,
      "cases": 2,
      "fatalities": 2,
      "lgb_preds": 2,
      "ytrainpred": 2,
      "ytestpred": 2,
      "y_pred_base": 2,
      "LinReg.predict(x_test)": 2,
      "np.log1p(pred_train_new[have_data])": 2,
      "y_pred_lm": 2,
      "tmp['demand']": 2,
      "tmp1['demand']": 2,
      "pred_no_ship": 2,
      "np.log1p(X_valid_pred['pred_shipped'].clip(0))": 2,
      "np.log1p(X_valid_pred['pred_opt'].clip(0))": 2,
      "sgd_scores_val": 2,
      "ridge_scores_val": 2,
      "lgb_scores_val": 2,
      "sgd_avpred": 2,
      "ridge_avpred": 2,
      "lgb_avpred": 2,
      "LinReg.predict(X_test)": 2,
      "yt": 2,
      "prediction_xgbr": 2,
      "regr_preds": 2,
      "xgb_preds": 2,
      "tree_preds": 2,
      "testPredict_xgb": 2,
      "trainPredict_xgb": 2,
      "np.zeros_like(val_y.target_revenue.values)": 2,
      "y_pred_two": 2,
      "model_xgbreg_ypredict": 2,
      "y_predict_test_linear": 2,
      "y_predict_test_Random": 2,
      "y_predict_test_LGB": 2,
      "y_predict_test_XGB": 2,
      "evaluation_data.loc[sub.index, :].values": 2,
      "train_pred_avg": 2,
      "val_pred_avg": 2,
      "wavg_train_pred1": 2,
      "wavg_train_pred2": 2,
      "wavg_train_pred3": 2,
      "wavg_pred1": 2,
      "wavg_pred2": 2,
      "wavg_pred3": 2,
      "final_val_pred": 2,
      "y_valpred": 2,
      "predictedFVC[:, 1]": 2,
      "xgb_model.predict(X_val)": 2,
      "cv_preds": 2,
      "train[:, -prediction_size:]": 2,
      "predictions_XGB": 2,
      "M1_val": 2,
      "M2_val": 2,
      "M3_val": 2,
      "data['predictions']": 2,
      "predsL2": 2,
      "valid_predicted": 2,
      "pred_logistic_regression": 2,
      "pred_gaussianNB": 2,
      "pred_decision_tree": 2,
      "pred_random_forest": 2,
      "curve": 2,
      "y_preds4": 2,
      "ytrain": 2,
      "pred_rf2": 2,
      "pred_xg2": 2,
      "model.predict(X_train.loc[:, :])": 2,
      "model.predict(X_test.loc[:, :])": 2,
      "np.exp(y_pred_xgb)": 2,
      "np.clip(lgbm_preds, 0, 20)": 2,
      "results.best_estimator_.predict(X_val)": 2,
      "i.predict(X_val)": 2,
      "Stacking.predict(X_val)": 2,
      "model.predict(public_train_build[features])[:, i]": 2,
      "np.exp(predictions)": 2,
      "rce_pred": 2,
      "en_pred_y": 2,
      "ridge_pred_y": 2,
      "dt_pred_y": 2,
      "rf_pred_y": 2,
      "xgb_pred_y": 2,
      "y_test_c": 2,
      "X.loc[~X['ConfirmedCases'].isna()]['yPred']": 2,
      "model.predict(df[feature_col].values.reshape(-1, 1))[:, 1]": 2,
      "lm_pred": 2,
      "predict2": 2,
      "predict3": 2,
      "y_predict_tree": 2,
      "y_predict_rand": 2,
      "y_predict_grad": 2,
      "y_predict_xgbr": 2,
      "ts_2_shifted_0": 2,
      "y_lasso": 2,
      "pred[:, 1]": 2,
      "d.loc[q, mname + '0']": 2,
      "d.loc[q, mname + '1']": 2,
      "pred[i]": 2,
      "cdf[i]": 2,
      "x_pred_": 2,
      "trainpreds": 2,
      "clf.predict(val_x)": 2,
      "expected_yards": 2,
      "lir_preds": 2,
      "sgdr_preds": 2,
      "lir_preds2": 2,
      "pipeline.predict(X_train)": 2,
      "pipeline.predict(X_test)": 2,
      "pdct1": 2,
      "y_1": 2,
      "y_2": 2,
      "linmodel_pred": 2,
      "oof_xgb": 2,
      "validate_y_pred": 2,
      "y_train_lr_pred": 2,
      "result.predict(X_test)": 2,
      "error_pred": 2,
      "y_pred_lreg": 2,
      "y_pred_dtree": 2,
      "y_pred_rforest": 2,
      "valid_data": 2,
      "validation_predict": 2,
      "y_pred_val_exp": 2,
      "Ytrain_pred": 2,
      "Ycv_pred": 2,
      "y_pred_LogReg": 2,
      "y_pred_DTR": 2,
      "pred_nb": 2,
      "train_pred['PredictedLogRevenue']": 2,
      "fcst": 2,
      "pred.predictions": 2,
      "output[0]": 2,
      "train_level2_pred": 2,
      "OOF": 2,
      "sarimax_pred": 2,
      "yTestPredLGB": 2,
      "yTestPredXGB": 2,
      "model.predict(test_X)": 2,
      "best_model.predict(test_X)": 2,
      "best_lgbm.predict(test_X)": 2,
      "modelcat.predict(test_X)": 2,
      "lm_results": 2,
      "lg_results": 2,
      "svm_results": 2,
      "y_predicted_p": 2,
      "Y_pred_test": 2,
      "np.log1p(predicts_cc_mad)": 2,
      "np.log1p(predicts_ft_mad)": 2,
      "y2_train_pred": 2,
      "y_pred_class": 2,
      "xgb_predict": 2,
      "lgb_predict": 2,
      "vote_predict": 2,
      "sr_predict": 2,
      "ts_forecasted": 2,
      "x_test_pred": 2,
      "oof_nn": 2,
      "y_pred_lgbR": 2,
      "np.log(abs(valid_preds))": 2,
      "y_train_fare": 2,
      "y_upper": 2,
      "y_lower": 2,
      "X_val2['FVC_PRE']": 2,
      "pred_k": 2,
      "pred_r": 2,
      "pred_baes": 2,
      "X_val2['end']": 2,
      "null": 2,
      "y_pred.detach().numpy()": 1,
      "clf.predict(test_cv)": 1,
      "train_df['log_revenue_pred']": 1,
      "y_hat_training": 1,
      "y_pred_OLS": 1,
      "rf_predictions": 1,
      "y_pred_test_rf": 1,
      "y_pred_test_rf_val": 1,
      "list(val_preds.predictions.reshape(1, -1)[0])": 1,
      "Y_val.values": 1,
      "Y_train.values": 1,
      "lr.predict(X_train)": 1,
      "lr.predict(X_test)": 1,
      "lso.predict(X_train)": 1,
      "lso.predict(X_test)": 1,
      "ridge.predict(X_train)": 1,
      "rndm_forst.predict(X_train)": 1,
      "rndm_forst.predict(X_test)": 1,
      "grad_boost.predict(X_train)": 1,
      "grad_boost.predict(X_test)": 1,
      "pred_mean[valid_mask]": 1,
      "pred_sigma[valid_mask]": 1,
      "x['p']": 1,
      "x['s']": 1,
      "y_pred_en": 1,
      "y_pred_en2": 1,
      "y_pred_lgbm": 1,
      "inv_yhat": 1,
      "y_1_pred": 1,
      "y_2_pred": 1,
      "oof_preds_log": 1,
      "np.array(val_pred).transpose()[:, :n_public]": 1,
      "np.array(val_pred).transpose()[:, n_public:]": 1,
      "np.array(val_pred)[:, :n_public]": 1,
      "np.array(val_pred)[:, n_public:]": 1,
      "catboost.predict(X_valid).clip(0, 20)": 1,
      "y_x": 1,
      "grid_search.best_estimator_.predict(X_test)": 1,
      "y_test_new": 1,
      "valid_pred_rf": 1,
      "preds_dan": 1,
      "preds_trans": 1,
      "oof_pred[valid_idx]": 1,
      "y_test.target": 1,
      "y_train[1:]['prev']": 1,
      "cat.predict(x_test)": 1,
      "grid_search_rfr_preds": 1,
      "randomCV_rfr_preds": 1,
      "xgbr_preds": 1,
      "grid_search_xgbr_preds": 1,
      "lasso_preds": 1,
      "grid_search_lasso_preds": 1,
      "np.log(y_pred[indstart:indend] + 1)": 1,
      "prediction_nn": 1,
      "simple_mix_pred": 1,
      "meta_model.predict(meta_X_train)": 1,
      "train_prediction": 1,
      "np.abs(model.predict(dvalid))": 1,
      "y_pred * 10**(-5)": 1,
      "y_monthly_pred * 10**(-5)": 1,
      "xgb_tahmin": 1,
      "np.expm1(y_rand_forest_predict)": 1,
      "np.expm1(y_XGB_predict)": 1,
      "np.expm1(y_LGB_predict)": 1,
      "ensembled_prediction": 1,
      "y_pred_int": 1,
      "predictions3": 1,
      "predictions4": 1,
      "y_predict_linreg": 1,
      "yCV": 1,
      "predicts": 1,
      "lval": 1,
      "y_pred.tail(test_size)['yhat']": 1,
      "test_predict[:, 0]": 1,
      "predict_transformed(X_cross, est)": 1,
      "reg.predict(x)": 1,
      "model1.predict(X_train)": 1,
      "model2.predict(X_train)": 1,
      "val[label]": 1,
      "sales_validation['demand']": 1,
      "site.pred_x": 1,
      "site.pred_y": 1,
      "fixed_df.fixed_x": 1,
      "fixed_df.fixed_y": 1,
      "sample_df.pred_x": 1,
      "forecast_data.loc[i:i + 48, 'yhat']": 1,
      "lgb.predict(x_train_)": 1,
      "lgb.predict(x_val_)": 1,
      "y_pred_xgbr": 1,
      "blending(X_train)": 1,
      "ypred_clf": 1,
      "val_preds2": 1,
      "oof_lgb[val_ind]": 1,
      "grid_search.predict(X_train)": 1,
      "y_predicted_naive": 1,
      "y_predicted_ave_28": 1,
      "y_predicted_seasonal_naive": 1,
      "y_predicted_ma": 1,
      "y_predicted_es": 1,
      "y_predicted_croston": 1,
      "y_val_sum_pred": 1,
      "train_arima_forecasted": 1,
      "recruit_predictions": 1,
      "elastic_net_predictions": 1,
      "knn_predictions": 1,
      "svr_preds_tr": 1,
      "svr_preds_cv": 1,
      "rf_preds_tr": 1,
      "rf_preds_cv": 1,
      "lgb_preds_tr": 1,
      "lgb_preds_cv": 1,
      "ridge_preds_tr": 1,
      "ridge_preds_cv": 1,
      "lr.predict(X_train_level2)": 1,
      "prediction_val": 1,
      "val_set_pred": 1,
      "y_df['y_pred']": 1,
      "previsao**(1 / 2)": 1,
      "predicted1": 1,
      "predicted2": 1,
      "predicted3": 1,
      "predicteda": 1,
      "predicteda2": 1,
      "predicteda2a": 1,
      "predicteda4": 1,
      "df['pred']": 1,
      "y_hat_testSAL": 1,
      "pres": 1,
      "pr": 1,
      "predu": 1,
      "y_pred_cat": 1,
      "train_revenue": 1,
      "p(cr)": 1,
      "ETR.predict(x_train)": 1,
      "ETR.predict(x_test)": 1,
      "ADB.predict(x_train)": 1,
      "ADB.predict(x_test)": 1,
      "BYNR.predict(x_train)": 1,
      "BYNR.predict(x_test)": 1,
      "y_valid_combined": 1,
      "y_predict_x": 1,
      "np.dot(X_train_level2, [alpha, 1 - alpha])": 1,
      "df_preds_train[c]": 1,
      "lr_cv_preds": 1,
      "val_labels": 1,
      "preds_test": 1,
      "np.array([0] * len(oof))": 1,
      "prediction_m": 1,
      "clf.predict(x_val)": 1,
      "y_pred[:].clip(0, 10000000000.0)": 1,
      "validationY": 1,
      "train_pred_": 1,
      "pred[y_val.y > 0]": 1,
      "self.y.iloc[val_idx]": 1,
      "y_test2": 1,
      "y_pred_lin_reg": 1,
      "y_pred_xgb_poly": 1,
      "my_y_pred": 1,
      "predict * i": 1,
      "getVal1": 1,
      "getVal2": 1,
      "rf.predict(X_valid)": 1,
      "bst.predict(d_valid)": 1,
      "sample_pred": 1,
      "stack_trn": 1,
      "data_test['Weekly_Sales_pred']": 1,
      "yvalid": 1,
      "np.expm1(metrics['predictions_proba'])": 1,
      "lgb.predict(X_train)": 1,
      "pred_rf_val": 1,
      "model.predict(train_df[features + ['loc']])[:, i]": 1,
      "y_val4": 1,
      "y_val5": 1,
      "lr.predict(train_feature[va])": 1,
      "forecast.drop(columns=['id']).values": 1,
      "yValidXGB": 1,
      "batch_target": 1,
      "unscaled_df.pred_value[-28:]": 1,
      "sgd.predict(train_feature[va])": 1,
      "pac.predict(train_feature[va])": 1,
      "lsvc.predict(train_feature[va])": 1,
      "oof_lgbm": 1,
      "oof_lgbm * 0.4 + oof_cat * 0.4 + oof_xgb * 0.2": 1,
      "oof_lgbm_seeds": 1,
      "oof_car_seeds": 1,
      "oof_gmm_0": 1,
      "oof_gmm_1": 1,
      "df_gmm_test['hyper_blend']": 1,
      "df_gmm_test['super_target']": 1,
      "df_submission['random_forest']": 1,
      "df_submission['GBR']": 1,
      "LASSO_pred": 1,
      "df_submission['LASSO']": 1,
      "XGBoost_pred": 1,
      "df_submission[model]": 1,
      "model_lgb.predict(X_valid)": 1,
      "pred_valid_lgb": 1,
      "pred_valid_cat": 1,
      "pred_valid_lr": 1,
      "pred_valid_knn": 1,
      "stack_train": 1,
      "oof_train_xgb": 1,
      "oof_train_lgb": 1,
      "oof_train_catb": 1,
      "oof_train_mlp": 1,
      "oof_train_cnn": 1,
      "y_valid.astype(float)": 1,
      "predictions[model]": 1,
      "train_copy.iloc[:, train_copy.columns == 33].values": 1,
      "_y_val": 1,
      "tuned_y_pred": 1,
      "df_train['tmp']": 1,
      "df['tmp']": 1,
      "df_train[t]": 1,
      "y_preds_nn": 1,
      "y_preds_rfr": 1,
      "y_preds_gbm": 1,
      "y_preds_cbr": 1,
      "combined_predictions": 1,
      "y_train_pred2": 1,
      "y_train_pred4": 1,
      "y_test_pred4": 1,
      "y_train_pred5": 1,
      "y_test_pred5": 1,
      "y_train_pred6": 1,
      "y_test_pred6": 1,
      "trainset_pred_num": 1,
      "train_meta_ints": 1,
      "best_regressor.predict(X)": 1,
      "best_regressor.predict(Xloc)": 1,
      "pred_sgd": 1,
      "pred_stack": 1,
      "predict_eval": 1,
      "lin_pred": 1,
      "lasso_pred": 1,
      "dtr_pred": 1,
      "clf.predict(X_train[train_idx])": 1,
      "np.array(train_data.baseline)": 1,
      "final_oof_preds": 1,
      "model_xgb_pred": 1,
      "model_lgb_pred": 1,
      "0.75 * model_lgb_pred + 0.25 * model_xgb_pred": 1,
      "model.predict(xtr)": 1,
      "init_preds_ave": 1,
      "final_preds_ave": 1,
      "y_train1_np": 1,
      "knn.predict(knn_val_data) * 20": 1,
      "knn.predict(knn_val_data)": 1,
      "meta_learner.predict(meta_data)": 1,
      "ridge_oof_train_2": 1,
      "ridge_oof_train_3": 1,
      "y_rid": 1,
      "y_xg": 1,
      "np.log1p(pred_train[have_data])": 1,
      "y_simple_lasso": 1,
      "y_simple_randforest": 1,
      "pipe_xgb.predict(X_test)": 1,
      "pipe_lgb.predict(X_test)": 1,
      "ensemble_predict(X_test)": 1,
      "final_pred": 1,
      "2 * model.predict_proba(np.nan_to_num(val_X[val_universe == 1, :]))[:, 1] - 1": 1,
      "y_pred_3": 1,
      "trainPredict": 1,
      "testPredict": 1,
      "df.predict": 1,
      "forecast['yhat'][0:34]": 1,
      "xgb_reg.predict(X_test)": 1,
      "y_glob": 1,
      "y_val[tune_var]": 1,
      "table['y']": 1,
      "y_pred_clf": 1,
      "train.distance_easy[:10]": 1,
      "sample_google_distance[8:10]": 1,
      "y_test_data": 1,
      "y_simple_linear2": 1,
      "y_simple_linear3": 1,
      "y.reshape(2400, 340)": 1,
      "y_hat_test": 1,
      "(pred1 + pred2) / 2": 1,
      "(pred1 + pred2 + pred3) / 3": 1,
      "yCC_test": 1,
      "rfr_predictions": 1,
      "dtr_predictions": 1,
      "ranforclas_predictions": 1,
      "yF_test": 1,
      "rfr_predictions1": 1,
      "dtr_predictions1": 1,
      "ranforclas_predictions1": 1,
      "rd_oof_train": 1,
      "ls_oof_train": 1,
      "co2eq_pred": 1,
      "Y if classifier else Y_train['target']": 1,
      "Y_train['target']": 1,
      "Y_valida_pred1": 1,
      "Y_test_predict1": 1,
      "xgb_tuned.predict(x_train)": 1,
      "xgb_tuned.predict(x_test)": 1,
      "df_pred['mean']": 1,
      "y_pred[:, -1]": 1,
      "i_model(x_tofit, *i_popt)": 1,
      "logistics_fitted(x_tofit)": 1,
      "linear_fitted(x_tofit)": 1,
      "ModelData201509y": 1,
      "seq_n_y_test": 1,
      "oof_predictions[val_id]": 1,
      "pred_sur": 1,
      "Y_pred_lin": 1,
      "Y_pred_lasso": 1,
      "Y_pred_ridge": 1,
      "Y_pred_rf": 1,
      "valid[i]": 1,
      "mt_target_pred": 1,
      "y_pred_0": 1,
      "oof_2[test_index]": 1,
      "oof_3[test_index]": 1,
      "train['1_preds']": 1,
      "train['3_preds']": 1,
      "train['4_preds'] * 0.1 + train['3_preds'] * 0.3 + train['2_preds'] * 0.3 + train['1_preds'] * 0.3": 1,
      "linear_reg.predict(x_train)": 1,
      "linear_reg.predict(x_test)": 1,
      "rr.predict(x_train)": 1,
      "rr.predict(x_test)": 1,
      "svr_pred": 1,
      "y_predictions": 1,
      "LR.predict(x_val)": 1,
      "gbr.predict(x_val)": 1,
      "Ypred": 1,
      "train_y.iloc[train_index]": 1,
      "train_y.iloc[test_index]": 1,
      "predictlinear": 1,
      "predictBayesRidge": 1,
      "pipeline.predict(x_train)": 1,
      "pipeline.predict(x_train_test)": 1,
      "lr.predict(x_train)": 1,
      "lr.predict(x_train_test)": 1,
      "rfr.predict(x_train)": 1,
      "rfr.predict(x_train_test)": 1,
      "df_train_Y": 1,
      "df_validation_Y": 1,
      "_y_pred": 1,
      "tahmin": 1,
      "train_pred_ens1": 1,
      "val_pred_ens1": 1,
      "weighted_val": 1,
      "pca_pred": 1,
      "y_predF": 1,
      "y_predB": 1,
      "y_predS": 1,
      "baseline_predictions": 1,
      "pred_LGB": 1,
      "np.log(y_pred + 1e-05)": 1,
      "predictionsLR": 1,
      "predictionsDTR": 1,
      "predictionsKNNR": 1,
      "y_r": 1,
      "y_result": 1,
      "np.log(predictions)": 1,
      "base_pred": 1,
      "logiPred": 1,
      "knnPrediction": 1,
      "DTCPreds": 1,
      "RMPreds": 1,
      "output_list": 1,
      "predc": 1,
      "predf": 1,
      "predA": 1,
      "base_data['Shifted_Monthly Mean Total Sunspot Number']": 1,
      "y_train_pred_x": 1,
      "y_val_pred_x": 1,
      "ypred2": 1,
      "val_predictions.flatten()": 1,
      "yval": 1,
      "y_pred_trai": 1,
      "df[tg[0]].values": 1,
      "cbr_pred": 1,
      "p1": 1,
      "p2": 1,
      "p3": 1,
      "(p1 + p2) / 2": 1,
      "(p1 + p2 + p3) / 3": 1,
      "house_y_pred": 1,
      "y_hat['naive']": 1,
      "moving_avg": 1,
      "ar_predictions": 1,
      "arma_predictions": 1,
      "arima_predictions": 1,
      "y_train_pred if round == False else np.round(y_train_pred)": 1,
      "y_val_pred if round == False else np.round(y_val_pred)": 1,
      "all_predictions": 1,
      "lasso.predict(numerical_input_B)": 1,
      "lasso.predict(numerical_input_C)": 1,
      "ridge.predict(numerical_input_B)": 1,
      "ridge.predict(numerical_input_C)": 1,
      "lr.predict(X_B)": 1,
      "lr.predict(X_C)": 1,
      "clf_Conf.predict(X_train)": 1,
      "clf_Conf.predict(X_test)": 1,
      "clf_Fat.predict(X_train)": 1,
      "clf_Fat.predict(X_test)": 1,
      "obj_preds": 1,
      "lgb_oof[val_idx]": 1,
      "lgb_oof": 1,
      "Y_pred_correct": 1,
      "Y_pred_correct_add": 1,
      "result.predict(start=1, end=1000)": 1,
      "test_Y": 1,
      "[50]": 1,
      "[500]": 1,
      "[5000]": 1,
      "[25]": 1,
      "[250]": 1,
      "[2500]": 1,
      "regr_pred": 1,
      "act": 1,
      "y_oof_pred": 1,
      "pred[:, 0]": 1,
      "y_": 1,
      "pred.clip(0.0, 20.0)": 1,
      "test_pred_first": 1,
      "clf.predict_proba(X_fit)[:, 1]": 1,
      "clf.predict_proba(X_eval)[:, 1]": 1,
      "lr.predict(X_e)": 1,
      "gs_svm.predict(X_e)": 1,
      "xgb.predict(X_e.values)": 1,
      "xgb.predict(X_e)": 1,
      "grid_pred_neural": 1,
      "pred_knnr": 1,
      "ensemble": 1,
      "valid_predict": 1,
      "reg.predict(X_test)": 1,
      "preds_BM": 1,
      "xgb.predict(X_valid)": 1,
      "ncaa_predictions": 1,
      "predicted[:, i]": 1,
      "oofs": 1,
      "xgb_oofs": 1,
      "lgb_oofs": 1,
      "cb_oofs": 1,
      "t": 1,
      "model.predict(train_data)": 1,
      "model.predict(hold_data)": 1,
      "valPredSGD": 1,
      "y_pred_df['y_val']": 1,
      "a[i]": 1,
      "train_df.Predict": 1,
      "xgb_prediction": 1,
      "lgbm_prediction": 1,
      "cat_prediction": 1,
      "xgboost_pred": 1,
      "lg_cf_label": 1,
      "lg_d_label": 1,
      "np.log1p(pred_train_temp)": 1,
      "model.predict_val()": 1,
      "yhat.values": 1,
      "rg_pred_val[mask_te]": 1,
      "ls_pred_val[mask_te]": 1,
      "xgb_pred_val[mask_te]": 1,
      "res_df['target']": 1,
      "pred_rg": 1,
      "model_lgb.predict(X_te)": 1,
      "pred_rg * (1 - lgb_ratio) + model_lgb.predict(X_te) * lgb_ratio": 1,
      "model.predict(x_tester)": 1,
      "final_LGBM.predict(x_tester)": 1,
      "final_LGBM.predict(x_tester2)": 1,
      "knn.fit(Xtr, ytr).predict(Xte)": 1,
      "results.fittedvalues": 1,
      "tp.fittedvalues": 1,
      "y0_pred": 1,
      "Y1_pred": 1,
      "Y6_pred": 1,
      "clf.predict(X)": 1,
      "y_preds_new": 1,
      "np.log(predicted)": 1,
      "np.log(models[num].predict(train_X))": 1,
      "np.log(models[num].predict(valid_X))": 1,
      "X_train.scalar_coupling_constant.values": 1,
      "dt.predict(X_test)": 1,
      "knn.predict(X_test)": 1,
      "xgb_model.predict(X_test)": 1,
      "kr.predict(X_test)": 1,
      "x_baseline": 1,
      "model.best_estimator_.predict(X_train)": 1,
      "model.best_estimator_.predict(X_test)": 1,
      "ae_genes_test_reconstruction": 1,
      "ae_cells_test_reconstruction": 1,
      "self.xg_predictions": 1,
      "val_actual_col": 1,
      "y_pred_cc": 1,
      "y_pred_f": 1,
      "tree_y_pred_tree": 1,
      "tree_y_pred_xgb": 1,
      "tree_y_pred_lgb": 1,
      "tree_y_pred_xgb * 0.5 + tree_y_pred_lgb * 0.5": 1,
      "tree_y_pred_xgb * 0.4 + tree_y_pred_lgb * 0.4 + tree_y_pred_tree * 0.1 + y_pred_lr * 0.1": 1,
      "pd.DataFrame(y_preds)": 1,
      "pd.DataFrame(y_train_pred).median()": 1,
      "pd.DataFrame(y_val_pred).median()": 1,
      "fitted_values": 1,
      "tuna_pred_test": 1,
      "oof_em": 1,
      "test_scores": 1,
      "model.predict(X_val, [0.5, 1.5])": 1,
      "preds_oof[:len_ori]": 1,
      "preds_oof2[:len_ori]": 1,
      "preds_oof2": 1,
      "preds_d": 1,
      "lgbm.predict(X_target)": 1,
      "data.loc[data.date_block_num == 33]['item_cnt_month'].clip(0.0, 20.0)": 1,
      "pred_lgb": 1,
      "pred_grad": 1,
      "pred_rand": 1,
      "y_pred5": 1,
      "y_pred_new": 1,
      "y_pred_new1": 1,
      "np.log1p(sub20[t].values)": 1,
      "np.log1p(df_panel[~df_panel.ConfirmedCases_val_xgb1.isna()].ConfirmedCases_val_xgb1)": 1,
      "np.log1p(df_panel[~df_panel.Fatalities_val_xgb1.isna()].Fatalities_val_xgb1)": 1,
      "np.log1p(df_panel[~df_panel.ConfirmedCases_val_xgb2.isna()].ConfirmedCases_val_xgb2)": 1,
      "np.log1p(df_panel[~df_panel.Fatalities_val_xgb2.isna()].Fatalities_val_xgb2)": 1,
      "np.log1p(df_panel[~df_panel.ConfirmedCases_val_lgb3.isna()].ConfirmedCases_val_lgb3)": 1,
      "np.log1p(df_panel[~df_panel.Fatalities_val_lgb3.isna()].Fatalities_val_lgb3)": 1,
      "np.log1p(df_panel[~df_panel.ConfirmedCases_val_lgb2.isna()].ConfirmedCases_val_lgb2)": 1,
      "np.log1p(df_panel[~df_panel.Fatalities_val_lgb2.isna()].Fatalities_val_lgb2)": 1,
      "val_predict": 1,
      "target[split:]": 1,
      "pred_train1": 1,
      "pred_train2": 1,
      "pred_test2": 1,
      "pred_train3": 1,
      "pred_test3": 1,
      "GBR.predict(X_validation)": 1,
      "y2": 1,
      "np.repeat(train['revenue'].mean(), train.shape[0])": 1,
      "train['revenue_mean']": 1,
      "val['revenue_mean']": 1,
      "input_data['log_revenue'].values": 1,
      "res": 1,
      "oof[val_idx.tolist()]": 1,
      "np.vstack(logits)": 1,
      "knn_pred": 1,
      "dt_pred": 1,
      "GBR.predict(x_train)": 1,
      "GBR.predict(x_test)": 1,
      "predict_fn(x_test=X_train[train_idx], get='ntk', t=None)": 1,
      "y_pred * 1": 1,
      "L1": 1,
      "stacked.predict(x_test)": 1,
      "np.log1p(y_pred_)": 1,
      "np.log1p(y2)": 1,
      "y_train_predicted": 1,
      "y_test_predicted": 1,
      "y_pred_rf_new": 1,
      "rfr.predict(X_valid[useful_col])": 1,
      "np.array(y_pred)": 1,
      "gs_ypred": 1,
      "tab_net_ypred": 1,
      "cg_oof_train": 1,
      "sales_cnt_valid_pre": 1,
      "rf_tuned.predict(X_val)": 1,
      "y_train_predictions[1]": 1,
      "y_val_predictions[1]": 1,
      "rf_reg.predict(X_val)": 1,
      "gb_reg.predict(X_val)": 1,
      "blend_pred(X_val)": 1,
      "XGB.predict(x_test_std)": 1,
      "RModel.predict(x_test_com)": 1,
      "EModel.predict(x_test_com)": 1,
      "np.repeat(n, len(y_test))": 1,
      "X_test['cases1DaysBefore']": 1,
      "pred_cv": 1,
      "y_hat.detach().cpu().numpy()": 1,
      "preds4": 1,
      "m1.predict(X_valid)": 1,
      "clf_dt.predict(x_val)": 1,
      "clf_rf.predict(x_val)": 1,
      "clf_svr.predict(x_val)": 1,
      "clf_xgb.predict(x_val)": 1,
      "predictions_val": 1,
      "y3_pred": 1,
      "y4_pred": 1,
      "y5_pred": 1,
      "y01_pred": 1,
      "y12_r_pred": 1,
      "lr.predict(x[test_index])": 1,
      "lr_mul.predict(x_mul[test_index])": 1,
      "train_df['target'].values.clip(0, 20)": 1,
      "val_df['target'].clip(0, 20)": 1,
      "oof[idxV]": 1,
      "regr.predict(x_train)": 1,
      "regr.predict(x_test)": 1,
      "regr_trans.predict(x_train)": 1,
      "regr_trans.predict(x_test)": 1,
      "regr_trans_CV.predict(x_train)": 1,
      "regr_trans_CV.predict(x_test)": 1,
      "df_validation['count_predicted']": 1,
      "outputs": 1,
      "yhat.detach().numpy()": 1,
      "LinReg.predict(x)": 1,
      "y_pred.cpu().numpy()": 1,
      "xgb.predict(xtest)": 1,
      "np.log1p(X['pred_mod'].clip(0))": 1,
      "pred_ship_permute": 1,
      "grid.predict(X_val)": 1,
      "grid.predict(X_train)": 1,
      "gbr.predict(self.x_validation)": 1,
      "gbr.predict(self.x_train)": 1,
      "lgbm.predict(self.x_validation)": 1,
      "lgbm.predict(self.x_train)": 1,
      "xg.predict(xgb.DMatrix(x_validation), ntree_limit=xg.best_ntree_limit)": 1,
      "xg.predict(xgb.DMatrix(x_train), ntree_limit=xg.best_ntree_limit)": 1,
      "LinReg.predict(X_train)": 1,
      "y_pred_log": 1,
      "oof_total[y_train_meter.index]": 1,
      "to_np(preds.squeeze())": 1,
      "denoised_df['signal']": 1,
      "denoised_test_df['signal']": 1,
      "en_preds": 1,
      "ada_preds": 1,
      "cross_val_predict(gbr_tuned, data[best_finetune.head(225).index], target)": 1,
      "pred_test_all[:, store]": 1,
      "train_meta[column]": 1,
      "testPredict_xgb_tune": 1,
      "trainPredict_xgb_tune": 1,
      "self.valid[[i]]": 1,
      "np.zeros_like(y_test)": 1,
      "np.zeros_like(test_y.target_revenue.values)": 1,
      "xgb.predict(test_X)": 1,
      "xgb2.predict(test_X)": 1,
      "blend_preds": 1,
      "df[df['fold'] == fold].target": 1,
      "augmented_only[augmented_only['fold'] == fold].target": 1,
      "df['fare_amount']": 1,
      "clf.predict(X_valid_scaled)": 1,
      "clf.predict(x_test)": 1,
      "predict_cc": 1,
      "predict_f": 1,
      "model_forestreg_ypredict": 1,
      "y_validate_pred": 1,
      "val_predictions_tree": 1,
      "val_predictions_XG": 1,
      "val_prediction_LSTM": 1,
      "pred['yhat'][:-28]": 1,
      "predictions_pd.predictions": 1,
      "all0_pred['pred']": 1,
      "y_prob": 1,
      "rfc_pred": 1,
      "clf_pred": 1,
      "ridge_y_train_pred": 1,
      "ridge_y_test_pred": 1,
      "lasso_y_train_pred": 1,
      "lasso_y_test_pred": 1,
      "lr_y_train_pred": 1,
      "lr_y_test_pred": 1,
      "els_y_train_pred": 1,
      "els_y_test_pred": 1,
      "ada_y_train_pred": 1,
      "ada_y_test_pred": 1,
      "enet_train_preds": 1,
      "svr_train_preds": 1,
      "lasso_train_preds": 1,
      "train['y']": 1,
      "model.predict(x_train_fold)": 1,
      "model.predict(x_test_fold)": 1,
      "lgbm.predict(X_val)": 1,
      "cb_model.predict(X_val)": 1,
      "val_predicted": 1,
      "LinReg.predict(X)": 1,
      "pred_lgbp": 1,
      "pred_test_slr_SC": 1,
      "pred_test_en_SC": 1,
      "pred_test_knr_SC": 1,
      "pred_test_dtr_SC": 1,
      "pred_test_slr": 1,
      "pred_test_en": 1,
      "pred_test_knr": 1,
      "pred_test_dtr": 1,
      "trueVpredict['predicted location']": 1,
      "lr_c.predict(X_c_train)": 1,
      "lr_c.predict(X_c_valid)": 1,
      "lr_cf.predict(X_cf_train)": 1,
      "lr_cf.predict(X_cf_valid)": 1,
      "rf_c.predict(X_c_train)": 1,
      "rf_c.predict(X_c_valid)": 1,
      "rf_cf.predict(X_cf_train)": 1,
      "rf_cf.predict(X_cf_valid)": 1,
      "inv_y(targ)": 1,
      "y_predA": 1,
      "y_predC": 1,
      "Y_true": 1,
      "y_pred_rf_two": 1,
      "y_pred_rf_three": 1,
      "y_pred_sv": 1,
      "y_pred_xgb_1": 1,
      "data2": 1,
      "predictions_kNN": 1,
      "predictions_LGBM": 1,
      "predictions_XGB1": 1,
      "predictions_LGBM1": 1,
      "np.log1p(oof_pred_df['PredictedRevenue'].values)": 1,
      "prediction_dtr": 1,
      "prediction_rfr": 1,
      "prediction_xgb": 1,
      "prediction_Linreg": 1,
      "M1_train": 1,
      "M2_train": 1,
      "M3_train": 1,
      "pred_ans": 1,
      "np.array([3])": 1,
      "test_data.loc[~test_data.visitors_predict.isnull(), 'visitors_predict']": 1,
      "test_data['visitors_predict']": 1,
      "for_param_pred": 1,
      "self.df_predicted": 1,
      "y_pred.clip(0, 20)": 1,
      "y_predt": 1,
      "y_predxgb": 1,
      "y_predxgbt": 1,
      "val_preds_1": 1,
      "val_preds_2": 1,
      "liblinear_preds[val_idx]": 1,
      "ridge_preds[val_idx]": 1,
      "liblinear_preds": 1,
      "ridge_preds": 1,
      "oof_l1": 1,
      "oof_l2": 1,
      "oof_l1 * 0.3 + oof_l2 * 0.7": 1,
      "sub_liblinear_preds": 1,
      "sub_ridge_preds": 1,
      "predsL1": 1,
      "np.log1p(preds)": 1,
      "np.log1p(submission_preds)": 1,
      "reg.predict(hist_data[trn_])": 1,
      "reg.predict(hist_data[val_])": 1,
      "model3.predict(X_test)": 1,
      "model4.predict(X_test)": 1,
      "stack_model.predict(X_test)": 1,
      "y_train_reg": 1,
      "y_test_reg": 1,
      "target_train_predict": 1,
      "LinReg.predict(x_train)": 1,
      "y_pred_rfpca": 1,
      "y_pred_xgb1": 1,
      "tr['allzero']": 1,
      "model.predict(train[covar_set + [var]])": 1,
      "y.ix[train_idxs]": 1,
      "[20.44256 for _ in range(296)]": 1,
      "sarimax.predict()": 1,
      "xgb.predict(X_test_scale)": 1,
      "predictions.round()": 1,
      "pred_val[test_index]": 1,
      "df_eval['pred'].values": 1,
      "meta_train[col]": 1,
      "train_costs": 1,
      "label_log": 1,
      "y_test_price": 1,
      "rfr_prediction": 1,
      "targets": 1,
      "dfValid['scalar_coupling_constant_pred']": 1,
      "vote_pred": 1,
      "model.predict(x_val)": 1,
      "yv2_pred": 1,
      "yv18_pred": 1,
      "yrez_pred": 1,
      "train[train[target_column].notnull()][target_column]": 1,
      "np.log(y_pred + 1)": 1,
      "predicted_y": 1,
      "preds_f_delta[:, TRAIN_N:TRAIN_N + val_len].flatten()": 1,
      "Lgb_predictions": 1,
      "pred_test_lightgbm": 1,
      "new_preds": 1,
      "pre_1": 1,
      "pre_2": 1,
      "train['visitors_pre']": 1,
      "Xtrain.iloc[:, 41].values": 1,
      "p_df.iloc[:, -5:].sum(axis=1).values": 1,
      "sgd_predict": 1,
      "tree_pred": 1,
      "ada_pred": 1,
      "bag_pred": 1,
      "svm_pred": 1,
      "svm_poly_pred": 1,
      "svm_rbf_pred": 1,
      "cat_preds": 1,
      "train[dependent_variable]": 1,
      "rid.predict(x_train)": 1,
      "lasso.predict(x_train)": 1,
      "lasso.predict(x_test)": 1,
      "model.predict(x_train)": 1,
      "gbr.predict(x_test)": 1,
      "random_search.predict(x_train)": 1,
      "random_search.predict(x_test)": 1,
      "lg_preds": 1,
      "val_predictions_bow1": 1,
      "val_predictions_bow2": 1,
      "val_predictions_vec1": 1,
      "val_predictions_vec2": 1,
      "y_te": 1,
      "np.exp(predict)": 1,
      "sales_cleaned_df.iloc[:, sales_cleaned_df.columns == 33].values": 1,
      "df_predict": 1,
      "sales_train_cleaned.iloc[:, sales_train_cleaned.columns == 33].values": 1,
      "train_df['SalePrice_hat']": 1,
      "lso_train_pred": 1,
      "lso_val_pred": 1,
      "cat_train_pred": 1,
      "cat_val_pred": 1,
      "np.log1p(y_true)": 1,
      "pred_train_rf": 1,
      "pred_test_rf": 1,
      "Ytest": 1,
      "y_list[i + 1]": 1,
      "ytrain_pred": 1,
      "predictions_d": 1,
      "target_y_test": 1,
      "y_pred0": 1,
      "y_pred4": 1,
      "y_train_predict2": 1,
      "y_test_predict2": 1,
      "autoencoder_cells.decoder(autoencoder_cells_non_moa_test).numpy()": 1,
      "autoencoder_cells.decoder(autoencoder_cells_test).numpy()": 1,
      "autoencoder_genes.decoder(autoencoder_genes_non_moa_test).numpy()": 1,
      "autoencoder_genes.decoder(autoencoder_genes_test).numpy()": 1,
      "pca_cells.inverse_transform(pca_cells.transform(non_moa_test[:, cs]))": 1,
      "pca_cells.inverse_transform(pca_cells.transform(data_test[:, cs]))": 1,
      "pca_genes.inverse_transform(pca_genes.transform(non_moa_test[:, gs]))": 1,
      "pca_genes.inverse_transform(pca_genes.transform(data_test[:, gs]))": 1,
      "autoencoder_cells.decoder(autoencoder_cells.encoder(data_train[:, cs]).numpy()).numpy().T": 1,
      "autoencoder_cells.decoder(autoencoder_cells.encoder(data_test[:, cs]).numpy()).numpy().T": 1,
      "pca_cells.inverse_transform(pca_cells.transform(data_train[:, cs])).T": 1,
      "pca_cells.inverse_transform(pca_cells.transform(data_test[:, cs])).T": 1,
      "autoencoder_genes.decoder(autoencoder_genes.encoder(data_train[:, gs]).numpy()).numpy().T": 1,
      "autoencoder_genes.decoder(autoencoder_genes.encoder(data_test[:, gs]).numpy()).numpy().T": 1,
      "pca_genes.inverse_transform(pca_genes.transform(data_train[:, gs])).T": 1,
      "pca_genes.inverse_transform(pca_genes.transform(data_test[:, gs])).T": 1,
      "pca_cells.inverse_transform(pca_cells.transform(non_moa_test[:, cs])).T": 1,
      "pca_cells.inverse_transform(pca_cells.transform(moa_train[:, cs])).T": 1,
      "autoencoder_cells.decoder(autoencoder_cells_non_moa_test).numpy().T": 1,
      "autoencoder_cells.decoder(autoencoder_cells.encoder(moa_train[:, cs]).numpy()).numpy().T": 1,
      "pca_genes.inverse_transform(pca_genes.transform(non_moa_test[:, gs])).T": 1,
      "pca_genes.inverse_transform(pca_genes.transform(moa_train[:, gs])).T": 1,
      "autoencoder_genes.decoder(autoencoder_genes_non_moa_test).numpy().T": 1,
      "autoencoder_genes.decoder(autoencoder_genes.encoder(moa_train[:, gs]).numpy()).numpy().T": 1,
      "cells_autoencoder.decoder(ae_cells_test).numpy()": 1,
      "pca.inverse_transform(pca.transform(cells_test))": 1,
      "genes_autoencoder.decoder(ae_genes_test).numpy()": 1,
      "pca.inverse_transform(pca.transform(genes_test))": 1,
      "test['Predictions']": 1,
      "dummy_model.predict(X_train)": 1,
      "dummy_model.predict(X_val)": 1,
      "model_lr.predict(X_train)": 1,
      "model_lr.predict(X_val)": 1,
      "model_rf.predict(X_train)": 1,
      "model_rf.predict(X_val)": 1,
      "model_gbr.predict(X_train)": 1,
      "model_gbr.predict(X_val)": 1,
      "model_xgb.predict(X_train)": 1,
      "model_xgb.predict(X_val)": 1,
      "reg.predict(x_ts)": 1,
      "runs_predictions": 1,
      "pred_dtree": 1,
      "pred_cb": 1,
      "pred_cat_boost": 1,
      "y_train_pred_xgb": 1,
      "y_test_pred_xgb": 1,
      "np.log1p(df_Train_Out.ConfirmedCases_y)": 1,
      "np.log1p(df_Train_Out.Fatalities_y)": 1,
      "baseline": 1,
      "predlgb": 1,
      "y_pred_mse": 1,
      "pred_sklearn": 1,
      "pred_tpot": 1,
      "pred_hyperopt": 1,
      "pred_keras_": 1,
      "mljar_pred": 1,
      "gluon_pred": 1,
      "h2o_pred_": 1,
      "caret_pred": 1,
      "test_v['SalePrice_predictions']": 1,
      "sele_pred": 1,
      "pred_line": 1,
      "pred_net": 1,
      "pred_svm": 1,
      "pred_gbm": 1,
      "np.log1p(df_train.loc[mask_9][['ConfirmedCases', 'Fatalities']])": 1,
      "regr.predict(X_train)": 1,
      "Ridge(alpha=1250).fit(X[train_idx], Y[train_idx]).predict(X[valid_idx])": 1,
      "target[i]": 1,
      "emb_pred_test": 1,
      "emb_pred_train": 1,
      "emb_cont_pred_test": 1,
      "emb_cont_pred_train": 1,
      "train_data['target']": 1,
      "cv_train": 1,
      "feature_results": 1,
      "feature_results2": 1,
      "dae_denoised_data": 1,
      "temp_oof": 1,
      "log_lr_preds": 1,
      "log_xgb_preds": 1,
      "forest_preds": 1,
      "y_pred_xg_boost": 1,
      "trOutput": 1,
      "trainPredict_in[0]": 1,
      "testPredict_in[0]": 1,
      "y_pred_exp": 1,
      "df_train[target_col]": 1,
      "val_pre": 1,
      "y_scored": 1,
      "y_pred_nn": 1,
      "y_pred_meta": 1,
      "y_linear": 1,
      "y_dtree": 1,
      "y_gb": 1,
      "model.predict(train)": 1,
      "train_y1": 1,
      "train_y2": 1,
      "train['Demand']": 1,
      "val['Demand']": 1,
      "final_preds": 1,
      "RFR.predict(X_train)": 1,
      "RFR.predict(X_test)": 1,
      "np.exp(base_predictions)": 1,
      "np.exp(pred)": 1,
      "model_lgbm.predict(X_valid)": 1,
      "j": 1,
      "d.loc[qvd, yv[i] + 'r']": 1,
      "d.loc[q, 'y0_preda']": 1,
      "d.loc[q, 'y1_preda']": 1,
      "y_pred[i]": 1,
      "Y_pred_cc_lr": 1,
      "Y_pred_fat_lr": 1,
      "Y_pred_cc_dt": 1,
      "Y_pred_fat_dt": 1,
      "tf_predY": 1,
      "predictions_1": 1,
      "predictions_2": 1,
      "predictions_3": 1,
      "predictions_4": 1,
      "x.prediction": 1,
      "GP(train)": 1,
      "FE1(train)": 1,
      "BE1(train)": 1,
      "FE2(train)": 1,
      "BE2(train)": 1,
      "np.log1p(df.target[knncustom.predict(X)])": 1,
      "a[t <= threshold]": 1,
      "b": 1,
      "c": 1,
      "d": 1,
      "e": 1,
      "f": 1,
      "(a + b + c + d + e + f) / 6": 1,
      "GPFE(train)": 1,
      "GPBE(train)": 1,
      "photoztodist(meta_train[myfilter])": 1,
      "GP(vistrain)": 1,
      "GP(blindtrain)": 1,
      "clf.predict(traindata)": 1,
      "FE(train)": 1,
      "BE(train)": 1,
      "xgbx": 1,
      "y_test[:, i]": 1,
      "train_pred4": 1,
      "val_pred4": 1,
      "reg.predict(X_valid)": 1,
      "reg_ridge.predict(X_valid)": 1,
      "train1_vis_dumm['target']": 1,
      "train2_vis_dumm['target']": 1,
      "Y_pred_cv": 1,
      "Y_cv_lag": 1,
      "best_model.predict(x_test)": 1,
      "rf_random.predict(X_test)": 1,
      "predicted_sales": 1,
      "y_pred_kernal": 1,
      "pls.predict(scale(X_test))": 1,
      "self.all_preds": 1,
      "ridge_prediction": 1,
      "y_train1": 1,
      "y_train12": 1,
      "y_test12": 1,
      "y_train13": 1,
      "y_test13": 1,
      "np.log(y_train_pred2 + 1)": 1,
      "np.log(y_test_predd + 1)": 1,
      "oof_": 1,
      "temp_stack_fold_pred": 1,
      "oof_cb": 1,
      "oof_cbx": 1,
      "oof_xgbx": 1,
      "oof_lgb_incremental": 1,
      "(oof_cbx + oof_xgbx) / 2": 1,
      "(oof_cbx + oof_xgbx + oof_lgb_incremental) / 3": 1,
      "stack_oof": 1,
      "test_naive['forecast']": 1,
      "test_simpleavg['forecast']": 1,
      "simp_avgmov['forecast']": 1,
      "ses_test['forecast']": 1,
      "hes_test['forecast']": 1,
      "lightgbm.predict(x_train)": 1,
      "lightgbm.predict(x_val)": 1,
      "xgboost.predict(np.ascontiguousarray(x_train))": 1,
      "xgboost.predict(np.ascontiguousarray(x_val))": 1,
      "svr.predict(x_train)": 1,
      "svr.predict(x_val)": 1,
      "stacking.predict(np.ascontiguousarray(x_train))": 1,
      "stacking.predict(np.ascontiguousarray(x_val))": 1,
      "m5.predict(X_valid)": 1,
      "sgd.predict(X_valid)": 1,
      "lr.predict(X_valid)": 1,
      "cv_predict": 1,
      "self.y_hat": 1,
      "y_lasso_train": 1,
      "predictions_rf": 1,
      "est.predict(X_test)": 1,
      "oof[val_idx].cpu()": 1,
      "oof.cpu()": 1,
      "y_val_reg": 1,
      "forecast['yhat']": 1,
      "predictions_cc": 1,
      "y_pred[:len(y)]": 1,
      "y_test.white": 1,
      "prediction_holt.Holt_linear": 1,
      "prediction_holtwinter.Holt_Winter": 1,
      "lgbm_model.predict(x_valid_idx)": 1,
      "Predict_Validation_data": 1,
      "Yts": 1,
      "Y_cnn": 1,
      "np.ones(len(train)) - 1": 1,
      "np.ones(len(train))": 1,
      "np.ones(len(train)) + 1": 1,
      "np.ones(len(train)) + 2": 1,
      "np.ones(len(train)) - 2": 1,
      "np.ones(len(train)) - 3": 1,
      "np.ones(len(train)) - 4": 1,
      "correct_y": 1,
      "model.predict(X_val, num_iteration=model.best_iteration)": 1,
      "y_holdout": 1,
      "mean_prediction": 1,
      "model.predict(xval)": 1,
      "toxicity_scores[:len(toxicity_scores)]": 1,
      "obscenity_scores[:len(toxicity_scores)]": 1,
      "severe_toxicity_scores[:len(toxicity_scores)]": 1,
      "y_model": 1,
      "random_model.predict(X_train)": 1,
      "model.predict(X_train, num_iteration_predict=model.best_iteration)": 1,
      "model.predict(X_val, num_iteration_predict=model.best_iteration)": 1,
      "lr.predict(X_val)": 1,
      "model_lr.predict(df_val)": 1,
      "best_model_lr.predict(X_val_LR)": 1,
      "y_predtrain.astype(int)": 1,
      "y_pred_without_outliers": 1,
      "training_targets": 1,
      "validation_targets": 1,
      "las.predict(X_test_scaled)": 1,
      "tdf1.index": 1,
      "y1_pred": 1,
      "regressor.predict(X_valid.copy())": 1,
      "y_predmodel5": 1,
      "reg_pred": 1,
      "data_train_copy['pred']": 1,
      "cat_pred": 1,
      "oof[val_idx, 0]": 1,
      "oof_pred_wavg": 1,
      "prediction_for_rf": 1,
      "oof_xgb_3": 1,
      "target.flatten()": 1,
      "y_oof": 1,
      "y_oof_2": 1,
      "y_oof_3": 1,
      "y_oof_4": 1,
      "y_oof_5": 1,
      "y_oof_6": 1,
      "y_oof_7": 1,
      "1.4 * (1.6 * y_oof_7 - 0.6 * y_oof_6) - 0.4 * y_oof_5": 1,
      "-0.5 * y_oof - 0.5 * y_oof_2 - y_oof_3 + 3 * y_oof_4": 1,
      "0.75 * (1.4 * (1.6 * y_oof_7 - 0.6 * y_oof_6) - 0.4 * y_oof_5) + 0.25 * (-0.5 * y_oof - 0.5 * y_oof_2 - y_oof_3 + 3 * y_oof_4)": 1,
      "y_oof_8": 1,
      "0.7 * (0.75 * (1.4 * (1.6 * y_oof_7 - 0.6 * y_oof_6) - 0.4 * y_oof_5) + 0.25 * (-0.5 * y_oof - 0.5 * y_oof_2 - y_oof_3 + 3 * y_oof_4)) + 0.3 * y_oof_8": 1,
      "y_oof_9": 1,
      "0.5 * y_oof_9 + 0.5 * (0.7 * (0.75 * (1.4 * (1.6 * y_oof_7 - 0.6 * y_oof_6) - 0.4 * y_oof_5) + 0.25 * (-0.5 * y_oof - 0.5 * y_oof_2 - y_oof_3 + 3 * y_oof_4)) + 0.3 * y_oof_8)": 1,
      "[train_data['target'].median()] * len(train_data)": 1,
      "[train_data['target'].mean()] * len(train_data)": 1,
      "eval_df.rf": 1,
      "eval_df.cb": 1,
      "eval_df.knn": 1,
      "eval_df.lr": 1,
      "Xp[:, -56:-28]": 1,
      "val_split_y": 1,
      "y_train_pred_lg": 1,
      "y_val_pred_lg": 1,
      "y_train_pred_r": 1,
      "y_val_pred_r": 1,
      "y_val_pred_lg.clip(0, 20)": 1,
      "y_val_pred_r.clip(0, 20)": 1,
      "Pred_data.iloc[:, i]": 1,
      "train.target": 1,
      "y_mul_pred": 1,
      "y_mlpReg_pred": 1,
      "lm_results_nolab": 1,
      "svr_results": 1,
      "lda_results": 1,
      "pred_lr_val.clip(0, 20)": 1,
      "model_lr_scaled.predict(X_valid_std)": 1,
      "model_lr_scaled.predict(X_val)": 1,
      "model_lr_scaled.predict(X_val).clip(0, 20)": 1,
      "pred_lgb_val.clip(*target_range)": 1,
      "preds['mid']": 1,
      "y_preed": 1,
      "ypred1": 1,
      "pr_sales_by_months['item_cnt_days']['predicted 33']": 1,
      "pr_test_categories_without_shops['item_cnt_days', 'predicted 33']": 1,
      "pr_test_categories_by_shops['item_cnt_days', 'predicted 33']": 1,
      "model2.predict(x)": 1,
      "model2.predict(sm.add_constant(X_val.fillna(0)))": 1,
      "valid_data['target'].tolist()": 1,
      "alg_y_pred": 1,
      "best_fit": 1,
      "np.log1p(df_panel[~df_panel['ConfirmedCases_val_lgb'].isna()]['ConfirmedCases_val_lgb'])": 1,
      "np.log1p(df_panel[~df_panel['Fatalities_val_lgb'].isna()]['Fatalities_val_lgb'])": 1,
      "np.log1p(df_panel[~df_panel['ConfirmedCases_val_mad'].isna()]['ConfirmedCases_val_mad'])": 1,
      "np.log1p(df_panel[~df_panel['Fatalities_val_mad'].isna()]['Fatalities_val_mad'])": 1,
      "lm_fatal_pred": 1,
      "sgd_pred": 1,
      "sgd_fatal_pred": 1,
      "data['Predicted cases']": 1,
      "svr_predict": 1,
      "gb_predict": 1,
      "kn_predict": 1,
      "baseline_preds": 1,
      "val_pred_pred": 1,
      "model.predict(val_x)": 1,
      "submission": 1,
      "submission_day": 1,
      "predictions_tr.clip(0.0, 20.0)": 1,
      "predictions_t.clip(0.0, 20.0)": 1,
      "ensemble_oof": 1,
      "ensemble_oof_2": 1,
      "ensemble_oof_3": 1,
      "predictions_m": 1,
      "y_pred.reshape(-1, n_out)": 1,
      "y_pred[~mask[:, j], j]": 1,
      "test_data[col]": 1,
      "prediction_CC": 1,
      "prediction_Fa": 1,
      "np.log1p(df_panel[~df_panel.ConfirmedCases_val_logy.isna()].ConfirmedCases_val_logy)": 1,
      "np.log1p(df_panel[~df_panel.Fatalities_val_logy.isna()].Fatalities_val_logy)": 1,
      "oof_val": 1,
      "randomForestImprovedPredict": 1,
      "clf.predict(tr[features])": 1,
      "clf1.predict(tr[features])": 1,
      "np.log1p(val_pred_df['predictedRevenue'].values)": 1,
      "np.log1p(pred_df['predictedRevenue'].values)": 1,
      "y_preds_lgb": 1,
      "clf.predict(data[features])": 1,
      "forecast_stp": 1,
      "train_1[start_index:end_index]['forecast_7']": 1,
      "train_1[start_index:end_index]['forecast_3']": 1,
      "y_org_pred": 1,
      "y_shift_pred": 1,
      "inv_test_predict": 1,
      "y_predict_dummy_mean": 1,
      "reg_LR.predict(X_train)": 1,
      "reg_LR.predict(X_test)": 1,
      "reg_SGD.predict(X_train)": 1,
      "reg_SGD.predict(X_test)": 1,
      "reg_xgb.predict(xgb.DMatrix(X_test), ntree_limit=reg_xgb.best_ntree_limit)": 1,
      "reg_DNN.predict(X_train)": 1,
      "reg_DNN.predict(X_test)": 1,
      "xgb_prediction(X_test[i])": 1,
      "pd.Series(level_predictions)": 1,
      "pd.Series(level_predictions).loc[:datetime.date(2017, 1, 1)]": 1,
      "pd.Series(flow_predictions)": 1,
      "pd.Series(flow_predictions).loc[:datetime.date(2017, 1, 1)]": 1,
      "error_calc_df['pred_24']": 1,
      "error_calc_df['pred_25']": 1,
      "monthly_pred['pred_24']": 1,
      "monthly_pred['pred_25']": 1,
      "pred_df.loc[:datetime.date(2019, 1, 1), 'pred']": 1,
      "pred_df.loc[:datetime.date(2015, 1, 1), 'pred']": 1,
      "predxg": 1,
      "lineertahmin.predict(x)": 1,
      "polinom_model.predict(xyenix)": 1,
      "validation_predictions": 1,
      "testpreds": 1,
      "model.predict(X_train_ss)": 1,
      "model.predict(X_test_ss)": 1,
      "model1.predict(X_train_ss)": 1,
      "model1.predict(X_test_ss)": 1,
      "y_prediction_DT": 1,
      "y_ranfor_pred": 1,
      "y_bagg_pred": 1,
      "y_adareg_pred": 1,
      "y_gradient_pred": 1,
      "y_xgreg_pred": 1,
      "y_lgb_pred": 1,
      "predictions_validation": 1,
      "predictions_testingData": 1,
      "predictions_validationData": 1,
      "np.log(y_pred_in)": 1,
      "y_pred_in_log": 1,
      "duration_pred": 1,
      "train_cleaned_img": 1,
      "regNN.predict(X_train)": 1,
      "regNN.predict(X_val)": 1,
      "rfr.predict(X_val)": 1
    },
    "sklearn.linear_model._base.LinearRegression.fit.X": {
      "X_train": 666,
      "X": 239,
      "x_train": 164,
      "x": 83,
      "train": 69,
      "idx.reshape(-1, 1)": 66,
      "train_x": 32,
      "train_X": 30,
      "train[elt2 + [elt]]": 27,
      "train[elt]": 27,
      "X_poly": 27,
      "X0_train_iter": 26,
      "X_train_scaled": 19,
      "overview_text": 16,
      "X_": 15,
      "X_train_level2": 15,
      "X_train.values": 13,
      "x_train_m.reshape(-1, 1)": 10,
      "pipe.transform(X)": 9,
      "dataTrain": 9,
      "np.array(train[col].values).reshape(-1, 1)": 9,
      "train_features": 8,
      "X1": 8,
      "X2": 8,
      "np.arange(len(series_comf_cases_test)).reshape(-1, 1)": 8,
      "np.arange(len(series_fatal_test)).reshape(-1, 1)": 8,
      "train_data": 7,
      "Xtrain": 7,
      "xtrain": 7,
      "x_poly": 7,
      "X.reshape(-1, 1)": 7,
      "tr_x": 7,
      "np.array(framework_by_occupation.Year).reshape(-1, 1)": 6,
      "train[cols_to_fit]": 6,
      "subX.as_matrix()": 6,
      "np.array(o.train[col].fillna(d_mean).loc[y_is_within_cut, 'technical_20'].values).reshape(-1, 1)": 5,
      "pipe.transform(X_train)": 5,
      "X_train2": 5,
      "X_Train": 5,
      "first_level": 5,
      "x2_train": 5,
      "lr_train": 5,
      "features": 5,
      "X_rfe": 5,
      "housing_prepared": 5,
      "data": 5,
      "x1_train": 5,
      "np.array(pd.to_numeric(team_over_time.index).tolist()).reshape(-1, 1)": 5,
      "ix": 5,
      "linreg_X": 5,
      "pipe1.transform(Xshort)": 4,
      "fit_X": 4,
      "x_train_final": 4,
      "X_tr": 4,
      "pr": 4,
      "submission_preds_df.values": 4,
      "x.drop('Patient', 1)": 4,
      "X_train_2_d": 4,
      "X_train_rfe": 4,
      "df['days'].values.reshape(-1, 1)": 4,
      "channel_list": 4,
      "np.array(train[cols_to_use])": 4,
      "xdata": 4,
      "X.T": 4,
      "stacked_predictions": 4,
      "cyc_data[x_ipts]": 4,
      "cyc_data_train[x_ipts]": 4,
      "polynomial_features.fit_transform(pd.DataFrame(d['Date']))": 4,
      "trainX": 3,
      "x1": 3,
      "x2": 3,
      "np.array(x_train.values).reshape(-1, 1)": 3,
      "np.arange(4, 13, 1).reshape(-1, 1)": 3,
      "X_train1": 3,
      "xtr1": 3,
      "xtr2": 3,
      "X_train_poly": 3,
      "X.values.reshape(-1, 1)": 3,
      "train[top10_cols]": 3,
      "df_train": 3,
      "X_train_cur.values": 3,
      "df_x": 3,
      "x_transformed": 3,
      "X_train_2": 3,
      "poly_X_train_confirmed": 3,
      "np.array(pd.to_numeric(team_over_time[-1000:].index).tolist()).reshape(-1, 1)": 3,
      "count_train3": 3,
      "X_sub_train": 3,
      "train.drop(['ConfirmedCases', 'ForecastId', 'Fatalities'], axis=1)": 2,
      "X_features": 2,
      "X_scaled": 2,
      "X_trainsc": 2,
      "x_train2": 2,
      "Xhetero": 2,
      "Xshort": 2,
      "X_data": 2,
      "X_train3": 2,
      "feature_train.reshape(-1, 1)": 2,
      "feature_values[index1].reshape(-1, 1)": 2,
      "feature_values[index2].reshape(-1, 1)": 2,
      "x_in": 2,
      "np.nan_to_num(X)": 2,
      "X_q_train": 2,
      "t[-10:].reshape(-1, 1)": 2,
      "Xt": 2,
      "X_clustered": 2,
      "X_train_sc": 2,
      "train.drop('target', axis=1)": 2,
      "X_val_level2": 2,
      "march_train[['date_ordinal']]": 2,
      "temp.filter(regex='^fea_').values": 2,
      "x4_train": 2,
      "temp.loc[~test_ids, ['Base_Percent', 'Percent_aug', 'Base_FVC']]": 2,
      "train_expv": 2,
      "X_2": 2,
      "train2": 2,
      "dt": 2,
      "X_train[['abs_lat_diff', 'abs_lon_diff', 'passenger_count']]": 2,
      "train_hour": 2,
      "train_hour_sqr": 2,
      "x_train_poly": 2,
      "Xs_train": 2,
      "train_data[features]": 2,
      "public": 2,
      "X_trainNorm": 2,
      "X_trainNorm1": 2,
      "X_trainNorm2": 2,
      "X_linear": 2,
      "train_level2": 2,
      "p_list": 2,
      "lg_train": 2,
      "x_train_store": 2,
      "x_feature2": 2,
      "train[features]": 2,
      "X_xTrain_CS": 2,
      "X_train_quadratic": 2,
      "X_train_quadratic_f": 2,
      "X_train_quadratic1": 2,
      "np.array(train.loc[y_is_within_cut, col].values).reshape(-1, 1)": 2,
      "res": 2,
      "x_mul": 2,
      "LotFrontage_train_scaled.iloc[:, 0:5]": 2,
      "_df[~nan_mask][attr_list]": 2,
      "val_predictions": 2,
      "df_linear": 2,
      "train_fit['derived_feat'].reshape(len(train_fit), 1)": 2,
      "x_train[feat]": 2,
      "input_data": 2,
      "np.array(pd.to_numeric(team_over_time[-100:].index).tolist()).reshape(-1, 1)": 2,
      "wf_hold.values": 2,
      "poly_x1_train": 2,
      "poly_x2_train": 2,
      "Quebec_x_train": 2,
      "Ontario_x_train": 2,
      "Alberta_x_train": 2,
      "British_Columbia_x_train": 2,
      "Nova_Scotia_x_train": 2,
      "xtr": 2,
      "predictions": 2,
      "x_train.values": 2,
      "val_pred[['lr', 'xgb']]": 2,
      "days": 2,
      "combined_preds": 2,
      "one[['date_block_num']]": 2,
      "df_X": 2,
      "training_examples_transform": 2,
      "tx": 2,
      "without_nulls[reg_fields]": 2,
      "X_train_kneigboards[X_train_kneigboards.columns.tolist()[:-11]]": 2,
      "[seq[i:i + number_of_points] for i in range(len(seq) - number_of_points)]": 1,
      "X_train_poly3": 1,
      "housing_train_num": 1,
      "reg": 1,
      "X_train_features": 1,
      "metaTrain": 1,
      "train.drop(columns='Age')": 1,
      "X_train[['abs_lat_diff', 'abs_lon_diff', 'haversine', 'passenger_count']]": 1,
      "Z[idxT]": 1,
      "train_data[col]": 1,
      "x_train1": 1,
      "train.drop(['ID', 'y'], 1)": 1,
      "x_train_dum": 1,
      "all_models_preds_train": 1,
      "f_ind_w": 1,
      "f_ind": 1,
      "newpipe.transform(Xhetero)": 1,
      "newerpipe.transform(xh)": 1,
      "R_train_x": 1,
      "sub": 1,
      "X_train[rfe_selected]": 1,
      "X_df_train": 1,
      "x_": 1,
      "data_x": 1,
      "train_cont": 1,
      "OH_X_train": 1,
      "X_n": 1,
      "meta_X_train": 1,
      "np.array(train.loc[:, selected])": 1,
      "np.array(train.loc[y_is_within_cut, 'next_technical_30_technical_20']).reshape(-1, 1)": 1,
      "test.loc[:, selected]": 1,
      "np.array(train2.head(6000).distance).reshape(-1, 1)": 1,
      "np.column_stack((wkday1, wkday2))": 1,
      "overview_transf": 1,
      "df": 1,
      "time_2": 1,
      "time": 1,
      "trainFactors": 1,
      "df_tn[['xgb_pred', 'rf_pred']]": 1,
      "trainData.drop(columns=['PatientID', 'target_FVC'])": 1,
      "train_df": 1,
      "X_train_scalled": 1,
      "X_input": 1,
      "train_poly": 1,
      "X_train_pc": 1,
      "X_store": 1,
      "xtrain2": 1,
      "indices": 1,
      "e_train": 1,
      "x_train_normalized": 1,
      "Xtfidf": 1,
      "np.array([all_used_trees, [x**2 for x in all_used_trees]]).transpose()": 1,
      "X_train_rd": 1,
      "X_all_rd": 1,
      "np.array(train.loc[y_is_within_cut, cols_to_use].values)": 1,
      "dataset.drop('target', axis=1)": 1,
      "avg_sq_feet['square_feet'].values.reshape(-1, 1)": 1,
      "today": 1,
      "normalizer(x_train)": 1,
      "X_lev2_train": 1,
      "X_train_train": 1,
      "features_train": 1,
      "train_df[train_df['ps_car_14'] != -1][corr_list]": 1,
      "inputs": 1,
      "td[cols]": 1,
      "train[l].values": 1,
      "X_cc[['yc-1', 'days_1st_conf']]": 1,
      "X_ft[['yf-1', 'yc-1', 'yc-2', 'yc-3', 'yc-4', 'yc-5', 'yc-6', 'yc-7', 'yc-8', 'yc-9', 'yc-10', 'yc-11', 'yc-12', 'yc-13', 'days_1st_fata']]": 1,
      "np.array(dataTrain[feature_cols])": 1,
      "train.values": 1,
      "train_feature[tr]": 1,
      "my_X": 1,
      "X_train_lr": 1,
      "train_new": 1,
      "new_feature": 1,
      "X_treino": 1,
      "X[:X_train.shape[0]]": 1,
      "train_xs_pca": 1,
      "week_data.values.reshape(-1, 1)": 1,
      "df_true[parameters]": 1,
      "X_train_b_2": 1,
      "X_train_bc_2": 1,
      "pred": 1,
      "temp[train_cols]": 1,
      "temp[['FVC_pred', 'Confidence']]": 1,
      "temp[['Base_FVC', 'cum_pms']]": 1,
      "temp.loc[temp.Where == 'Train', train_cols]": 1,
      "np.array(x).reshape(-1, 1)": 1,
      "x[:8]": 1,
      "f_.reshape(-1, 1)": 1,
      "X[['LotArea']]": 1,
      "self.x_train_data": 1,
      "X_1": 1,
      "train3": 1,
      "xCC_train": 1,
      "xF_train": 1,
      "energy_treino": 1,
      "X_in": 1,
      "x_age_train": 1,
      "X2_train": 1,
      "stats_groupedby_position_X": 1,
      "cl_d_train": 1,
      "Xtrain[cols].values": 1,
      "diabetes_X_train": 1,
      "train_data_x": 1,
      "np.array(group.Weeks).reshape(-1, 1)": 1,
      "X_Train_new": 1,
      "X_new": 1,
      "df_train_X": 1,
      "data2d_d": 1,
      "x_egitimVerisi": 1,
      "x_pca_train": 1,
      "lr_train_x": 1,
      "df_train_data": 1,
      "df[['public', 'week1']]": 1,
      "train_distance": 1,
      "train_dist_sqr": 1,
      "X_train_rf1": 1,
      "X_train_rf2": 1,
      "train_df[feat_cols_list]": 1,
      "x_hp1_train": 1,
      "x_df1_train": 1,
      "tmp_train_data.values": 1,
      "self.train[self.train['Patient'] == patient_name]['Weeks'].values[-2:].reshape(-1, 1)": 1,
      "train_x[['dis', 'year', 'hour', 'passenger_count']]": 1,
      "train_x_poly": 1,
      "yptraina[backy_fset].values.reshape(-1, len(backy_fset))": 1,
      "prep_linear(traincut)": 1,
      "xtsc": 1,
      "sxtr": 1,
      "X.loc[y_is_within_cut, cols]": 1,
      "data_train[['budget', 'popularity', 'runtime', 'days_week']]": 1,
      "df_trainx": 1,
      "S_train": 1,
      "X_train_ss": 1,
      "np.array(x_train.values).reshape(-5, 5)": 1,
      "train[col]": 1,
      "X_t": 1,
      "trn_data[['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'passenger_count']]": 1,
      "train_X_budget_known": 1,
      "train_X_budget_missing": 1,
      "df_train_xs": 1,
      "poly_x_train": 1,
      "y_pred_df[['y_pred_RF', 'y_pred_XGB']]": 1,
      "train_set['X']": 1,
      "x0_train": 1,
      "X1_train": 1,
      "X6_train": 1,
      "positive_X": 1,
      "neutral_X": 1,
      "negative_X": 1,
      "X_train_preprocessed": 1,
      "X_train_permutation": 1,
      "df_X_train": 1,
      "train[['event_count']]": 1,
      "train_df[Selcol]": 1,
      "X_train_final": 1,
      "x_train_store_day7": 1,
      "x_train_store_daynot7": 1,
      "X_train_prepared": 1,
      "states[mask].reshape(-1, 1)": 1,
      "np.arange(seq_len - selected_len, seq_len, 1).reshape((-1, 1))": 1,
      "colArr": 1,
      "lr_train_compl": 1,
      "first_level_df.iloc[:, :-1]": 1,
      "stds[['high_ci', 'high_ci2']]": 1,
      "X_Scaler_train": 1,
      "train['year'].values.reshape(-1, 1)": 1,
      "X_train_ol": 1,
      "X_train_normalised": 1,
      "clfpreds.as_matrix()": 1,
      "part_2[['gb_pred', 'rf_pred']]": 1,
      "Train_ADS": 1,
      "np.array(o.train[col_new].fillna(d_mean).loc[y_is_within_cut, lr_column].values)": 1,
      "np.arange(len(y)).reshape(-1, 1)": 1,
      "train[['score', 'count_stop_words']].values.reshape(-1, 2)": 1,
      "np.array(trainSet[['type_1JHC', 'type_1JHN', 'type_2JHC', 'type_2JHH', 'type_2JHN', 'type_3JHC', 'type_3JHH', 'dist', 'dist_to_type_mean']])": 1,
      "df_seasonality_selected": 1,
      "data_train": 1,
      "X_poly3": 1,
      "taxi_train[['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'passenger_count']]": 1,
      "x_train_com": 1,
      "pred_result": 1,
      "pred_data": 1,
      "datas_in": 1,
      "X3": 1,
      "X4": 1,
      "X100_train": 1,
      "x3_train": 1,
      "x5_train": 1,
      "x01_train": 1,
      "x[train_index]": 1,
      "x_mul[train_index]": 1,
      "nn_model.predict([X_processed_f['item_id'], X_processed_f['shop_id'], X_processed_f['date_block_num'], X_processed_f['item_category_id']])": 1,
      "mercedes_features_train": 1,
      "train_no_na_encoded.values": 1,
      "Xtrain[:, np.newaxis]": 1,
      "np.array(train['budget']).reshape(-1, 1)": 1,
      "new_feature_vector": 1,
      "Xs_train_a": 1,
      "df[['diff_lat', 'diff_long', 'pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude', 'distance', 'passenger_count']]": 1,
      "x_train_train": 1,
      "X_train[data[0]]": 1,
      "X_all": 1,
      "train_block": 1,
      "scaled_train_lr_2.iloc[:, :-1]": 1,
      "train_lr_3[highest_correlated_lr_3]": 1,
      "X_poly_train_lr_4": 1,
      "train[refined_final_vars]": 1,
      "train.fc.values.reshape(-1, 1)": 1,
      "x.values": 1,
      "X_train_SC": 1,
      "df_train_new_sel.iloc[:, 1:]": 1,
      "X_c_train": 1,
      "X_cf_train": 1,
      "c.quantity.values[:, None]": 1,
      "np.array(train[feat].loc[y_is_within_cut, 'technical_20'].values).reshape(-1, 1)": 1,
      "x_tr": 1,
      "train_lr": 1,
      "blend_df_valid": 1,
      "X_train[cool_features]": 1,
      "inputs_scaled": 1,
      "train_F": 1,
      "X_train_pca": 1,
      "train[covar_set + [var]]": 1,
      "train[covar_set]": 1,
      "X_layer2_train": 1,
      "prepared_housing_train": 1,
      "one_hot_df[['city_NYC', 'city_SF', 'city_Seattle']]": 1,
      "dummy_df[['city_SF', 'city_Seattle']]": 1,
      "effect_df[['city_SF', 'city_Seattle']]": 1,
      "meta_train": 1,
      "train_two.drop(['count'], axis=1)": 1,
      "featureSet": 1,
      "dfTrain.drop(['id', 'scalar_coupling_constant'], axis=1)": 1,
      "df.drop(['id', 'scalar_coupling_constant'], axis=1)": 1,
      "x_train_s": 1,
      "X_train_sal_lr": 1,
      "x.reshape(-1, 1)": 1,
      "train[independent_variable]": 1,
      "np.array(train_linear_models[cols_to_use])": 1,
      "sources": 1,
      "trainx": 1,
      "LB.private.reshape(-1, 1)": 1,
      "final_X_train": 1,
      "ser.index.values.reshape(-1, 1)": 1,
      "x.index.values.reshape(-1, 1)": 1,
      "annual_mean_diffs.index.values.reshape(-1, 1)": 1,
      "annual_std_diffs.index.values.reshape(-1, 1)": 1,
      "encodedCategories": 1,
      "encodedCategories_X_train": 1,
      "all_X": 1,
      "data_sc": 1,
      "pfC.fit_transform(X_Train_CS_SS)": 1,
      "pfF.fit_transform(X_Train_CS_SS)": 1,
      "x_train_pf_s": 1,
      "X_train_linear": 1,
      "X[pred_cols]": 1,
      "train[['user_resid_mean', 'content_mean']]": 1,
      "self.x_train": 1,
      "df_D['TransactionDT'].loc[df_D[i].T != 0].values.reshape(-1, 1)": 1,
      "X_train.drop(columns=['extra'])": 1,
      "X_trainS": 1,
      "tmp_df.site_predicted_fixed.values.reshape(-1, 1)": 1,
      "unmissed.drop('age', axis=1)": 1,
      "unmissed.drop('fare', axis=1)": 1,
      "X_pca": 1,
      "np.reshape(train.dist.values, (-1, 1))": 1,
      "meta_train[['pred_1', 'pred_2']]": 1,
      "tfidf_train": 1,
      "cur_X_train.fillna(0)": 1,
      "pl.array([Yvl1, Yvl2, Yvl3]).T": 1,
      "meta_features": 1,
      "np.array(ts.index).reshape((-1, 1))": 1,
      "X_train_cc": 1,
      "X_train_fat": 1,
      "x_train_scaled": 1,
      "x[x.Where == 'train'].drop('Where', 1)": 1,
      "train_stack": 1,
      "pd.concat([pd.get_dummies(train_2.type), train_2.distance], axis=1)": 1,
      "X_train_lag": 1,
      "X_conf": 1,
      "X_fat": 1,
      "rescaledX": 1,
      "X_reduced_train[:, :15]": 1,
      "K": 1,
      "xTrain": 1,
      "xTrainTrans": 1,
      "sentiment_ru2": 1,
      "X_trainer": 1,
      "train_set[['acoustic_data_transform']]": 1,
      "x1[col]": 1,
      "Xs": 1,
      "train_data.drop(['SalePrice'], axis=1)": 1,
      "xtrain_poly": 1,
      "np.array(train['Days Since']).reshape(-1, 1)": 1,
      "np.array([i for i in range(len(X))]).reshape(-1, 1)": 1,
      "np.array([i for i in range(len(Z))]).reshape(-1, 1)": 1,
      "X_train[['passenger_count', 'abs_lat_diff', 'abs_lon_diff']]": 1,
      "stack_valid": 1,
      "X_full": 1,
      "new_polydata_train": 1,
      "x_train.fillna(0)": 1,
      "df_country_recent[['DatePassed']]": 1,
      "df_country[['RecentConfirmedCases']]": 1,
      "X.iloc[train, :]": 1,
      "df_stacking[['lasso', 'rf', 'Ridge', 'Bayesian']].values": 1,
      "df['temp'].values.reshape(-1, 1)": 1,
      "confirmed_value": 1,
      "Deaths_data_poly": 1,
      "stacked_valid_predictions": 1,
      "train.loc[train[correlated].notna() & train[f].notna(), correlated].values.reshape(-1, 1)": 1,
      "X_valid": 1,
      "X_transform_train": 1,
      "train_processed": 1,
      "x_train_mms": 1,
      "X_casa_treino": 1,
      "X_casa_treino_poly": 1,
      "w_train": 1,
      "self.data['Customers'].values.reshape(-1, 1)": 1,
      "self.data.drop(columns=['Sales', 'Customers']).values": 1,
      "X_train_pca_df_final": 1,
      "X_inlier": 1,
      "dataset.dropna()[input_columns]": 1,
      "dataset.dropna()[['Date_diff']]": 1,
      "dataset.dropna()[['ConfirmedCases_lagn']]": 1,
      "lr_X_train": 1,
      "train['excerpt'].str.replace('[^a-zA-Z0-9-]', '').str.len().to_frame()": 1,
      "feature.reshape(-1, 1)": 1,
      "eval_df.iloc[:, :-2]": 1,
      "X[tr_idx]": 1,
      "X_min": 1,
      "X_TRAIN": 1,
      "budget_train_X": 1,
      "X_train_std": 1,
      "train[feature]": 1,
      "X_train.values.reshape(-1, 1)": 1,
      "final_train.drop(33, axis=1)": 1,
      "test_final_all.drop(33, axis=1)": 1,
      "X_train[['haversine', 'abs_lat_diff', 'abs_lon_diff', 'passenger_count']]": 1,
      "X_train[features]": 1,
      "feat": 1,
      "d_set[0]": 1,
      "linreg_x": 1,
      "Embedded_Features": 1,
      "xyenix": 1,
      "train_input": 1,
      "train_features_CC": 1,
      "train_features_F": 1,
      "df_train[cols_to_fit]": 1,
      "DataTrain": 1,
      "merged_df.iloc[:len_train]": 1,
      "az": 1,
      "polynomial_features.fit_transform(pd.DataFrame(d['Date']), pd.DataFrame(d['ConfirmedCases']))": 1,
      "new_train": 1,
      "dataTrain_poly": 1,
      "x_train2_modifyed": 1,
      "x_train3_modifyed": 1,
      "train[x]": 1,
      "train_predictors": 1,
      "edited_train": 1,
      "x_hour_1": 1,
      "x_hour_2": 1,
      "x_hour_3": 1,
      "x_hour_4": 1,
      "x_hour_5": 1,
      "null": 1
    },
    "sklearn.linear_model._base.LinearRegression.fit.y": {
      "y_train": 796,
      "y": 399,
      "Y_train": 118,
      "arr": 69,
      "Y": 60,
      "train_y": 47,
      "target": 31,
      "y1": 14,
      "yLabelsLog": 14,
      "y1_train_iter": 13,
      "y2_train_iter": 13,
      "y_train_level2": 13,
      "train.y.values": 13,
      "y2": 10,
      "y_train_m": 10,
      "ytrain": 9,
      "series_comf_cases_test": 8,
      "series_fatal_test": 8,
      "y.values": 7,
      "y2_train": 7,
      "tr_y": 7,
      "y1_train": 7,
      "o.train.loc[y_is_within_cut, 'y']": 6,
      "y_true": 6,
      "train['log_revenue']": 6,
      "y_train_log": 6,
      "Y_valid": 6,
      "train[target]": 6,
      "y_valid": 6,
      "qq['orientation_Z'].values": 6,
      "y_train1": 5,
      "y_tr": 5,
      "np.log1p(y_train)": 5,
      "train_Y": 5,
      "yLabelslog": 5,
      "Ytrain": 5,
      "np.log(y)": 5,
      "housing_labels": 5,
      "log_re": 5,
      "fatalities": 5,
      "team_over_time.values": 5,
      "iy": 5,
      "y_train2": 4,
      "train_labels": 4,
      "target_train": 4,
      "train['revenue']": 4,
      "train_temp_cc": 4,
      "train_temp_ft": 4,
      "Y2": 4,
      "sub_price": 4,
      "train['target']": 4,
      "mean_list": 4,
      "ytr": 4,
      "ydata": 4,
      "confirmed": 4,
      "val_y": 4,
      "qq['orientation_X'].values": 4,
      "qq['orientation_Y'].values": 4,
      "np.log(train_y_conf + 1)": 4,
      "np.log(train_y_fat + 1)": 4,
      "train_depth_data['delta_Depth_to_Groundwater_P24']": 4,
      "trainY": 3,
      "month_avgs[3:].reshape(-1, 1)": 3,
      "np.array(y).reshape(-1, 1)": 3,
      "Y1.ravel()": 3,
      "Y2.ravel()": 3,
      "ytr1": 3,
      "ytr2": 3,
      "y_train_cc": 3,
      "y_train_cases": 3,
      "y_train_fatalities": 3,
      "label_log": 3,
      "y_train_cur": 3,
      "Y_validation": 3,
      "y_val": 3,
      "yvalid": 3,
      "train_targets": 3,
      "team_over_time[-1000:].values": 3,
      "labels": 3,
      "train_cnt": 3,
      "train_target": 3,
      "y_cases": 3,
      "y_fatal": 3,
      "d['ConfirmedCases']": 3,
      "y_sub_train": 3,
      "y_train_scaled": 2,
      "train['y']": 2,
      "log_y": 2,
      "resids2": 2,
      "lnres2": 2,
      "y_data": 2,
      "y_train3": 2,
      "y_train_final_c_input": 2,
      "y_train_final_f_input": 2,
      "train[TARGET].values[index1]": 2,
      "y_trans": 2,
      "signal": 2,
      "y_test": 2,
      "np.nan_to_num(var)": 2,
      "y_train_ft": 2,
      "y[-10:]": 2,
      "np.array(framework_by_occupation.Framework__TensorFlow).reshape(-1, 1)": 2,
      "np.array(framework_by_occupation.Framework__Keras).reshape(-1, 1)": 2,
      "np.array(framework_by_occupation.Framework__PyTorch).reshape(-1, 1)": 2,
      "Yt": 2,
      "train.loc[y_is_within_cut, target]": 2,
      "y_pred": 2,
      "Y_Train": 2,
      "temp.feature.values": 2,
      "temp['FVC']": 2,
      "temp.loc[~test_ids, 'FVC']": 2,
      "train_objv": 2,
      "trg[ok]": 2,
      "y_NbDay": 2,
      "np.log(df['ConfirmedCases'].values)": 2,
      "np.log(df['Fatalities'].values)": 2,
      "ln_target": 2,
      "private": 2,
      "y_linear": 2,
      "target_level2": 2,
      "y3": 2,
      "y4": 2,
      "y5": 2,
      "y6": 2,
      "D_list": 2,
      "train_data['SalePrice']": 2,
      "y_train_store": 2,
      "y_feature2": 2,
      "y1_xTrain_CS": 2,
      "confirmed_train": 2,
      "fatalities_train": 2,
      "Y.reshape(-1, 1)": 2,
      "yvaliate": 2,
      "y[train_index]": 2,
      "LotFrontage_train_scaled.iloc[:, -1]": 2,
      "train.loc[y_is_within_cut, 'y']": 2,
      "qq['orientation_W'].values": 2,
      "_df[~nan_mask]['target']": 2,
      "df_linear_y": 2,
      "train_fit['y']": 2,
      "targets": 2,
      "cyc_data.casual": 2,
      "cyc_data.registered": 2,
      "cyc_data_train.casual": 2,
      "cyc_data_train.registered": 2,
      "y_train_c": 2,
      "y_train_2": 2,
      "team_over_time[-100:].values": 2,
      "train.scalar_coupling_constant.values": 2,
      "y_target": 2,
      "yTrain": 2,
      "y_hold.values.ravel()": 2,
      "y_casa_treino": 2,
      "Y_val": 2,
      "test_target": 2,
      "one['item_cnt_day']": 2,
      "df_Y": 2,
      "data_train_cleaned['log_revenue']": 2,
      "training_targets": 2,
      "ty": 2,
      "without_nulls['ground_truth']": 2,
      "d['Fatalities']": 2,
      "seq[number_of_points:]": 1,
      "train['ConfirmedCases']": 1,
      "train['Fatalities']": 1,
      "y_train_poly3": 1,
      "housing_label": 1,
      "y_sales": 1,
      "train_price": 1,
      "Y_train.values": 1,
      "train['Age']": 1,
      "sigma_target[idxT]": 1,
      "train['FVC']": 1,
      "y_train_dum": 1,
      "np.array(x[i1_left:i1_right])": 1,
      "x": 1,
      "R_train_y": 1,
      "df.SalePrice": 1,
      "df.Percent": 1,
      "y_df_train": 1,
      "data_y": 1,
      "meta_y_train": 1,
      "train[TARGET].values[index2]": 1,
      "1 / (threshold + 0.01 - train[TARGET].values[index2])": 1,
      "train.loc[:, 'next_technical_30_technical_20']": 1,
      "y[y_is_within_cut]": 1,
      "test.loc[:, 'next_technical_30_technical_20']": 1,
      "y_confirm": 1,
      "y_fatality": 1,
      "np.array(train2.head(6000).fare_amount).reshape(-1, 1)": 1,
      "Y - regressor.intercept_": 1,
      "train.TARGET": 1,
      "trainResponse": 1,
      "y_train.values.flatten()": 1,
      "X_valid.values": 1,
      "trainData['target_FVC']": 1,
      "y_input": 1,
      "y_store": 1,
      "nzv": 1,
      "y_Train['target_carbon_monoxide']": 1,
      "y_Train['target_benzene']": 1,
      "y_Train['target_nitrogen_oxides']": 1,
      "y_shaped": 1,
      "np.array(point_reward_list, ndmin=2).transpose()": 1,
      "avg_sq_feet.index.values.reshape(-1, 1)": 1,
      "tomorrow": 1,
      "y_train_train_log": 1,
      "train_df['log_revenue']": 1,
      "targets_train": 1,
      "train_df[train_df['ps_car_14'] != -1]['ps_car_14']": 1,
      "plays['epa']": 1,
      "y.iloc[:, 0]": 1,
      "y.iloc[:, 1]": 1,
      "y.iloc[:, 2]": 1,
      "td['target']": 1,
      "train.y": 1,
      "X_cc['yc']": 1,
      "X_ft['yf']": 1,
      "np.array(dataTrain['unit_sales'])": 1,
      "y_train[index].iloc[:, 0]": 1,
      "y_train[index].iloc[:, 1]": 1,
      "march_train['ConfirmedCases']": 1,
      "march_train['Fatalities']": 1,
      "train['target'].values[tr]": 1,
      "my_y": 1,
      "val_train": 1,
      "y_treino": 1,
      "Y_train_CC": 1,
      "Y_train_Fat": 1,
      "train_ys_df": 1,
      "d['FVC'].values": 1,
      "y_train_int": 1,
      "train_data['target']": 1,
      "df_true[feature]": 1,
      "y_train_b": 1,
      "y_train_bc": 1,
      "Regressor['tValue']": 1,
      "temp[['Best_conf']]": 1,
      "temp.loc[temp.Where == 'Train', 'FVC']": 1,
      "sample_google_distance[:8]": 1,
      "t": 1,
      "self.y_train_data": 1,
      "ts.tail(n_periods_1)": 1,
      "ts.tail(n_perionds_2)": 1,
      "yCC_train": 1,
      "yF_train": 1,
      "co2eq_treino": 1,
      "y_in": 1,
      "age_train.Age": 1,
      "stats_groupedby_position_Y": 1,
      "'winPlacePerc'": 1,
      "diabetes_y_train": 1,
      "train_data_y": 1,
      "np.array(group.FVC)": 1,
      "df_train_Y": 1,
      "data2d_lncc": 1,
      "y_egitimVerisi": 1,
      "y_pca_train": 1,
      "y_train_total": 1,
      "df_train_label": 1,
      "df['week2']": 1,
      "y_train_rf1": 1,
      "y_train_rf2": 1,
      "df[target_cols_list[i]]": 1,
      "train_df[target_cols_list[2]]": 1,
      "y_hp1_train": 1,
      "y_df1_train": 1,
      "tmp_y_train_data": 1,
      "z": 1,
      "y_train_con": 1,
      "y_train_fatal": 1,
      "train_data['ConfirmedCases']": 1,
      "train_data['Fatalities']": 1,
      "yptraina.y_prev.fillna(0)": 1,
      "traincut.y": 1,
      "ar": 1,
      "y.loc[y_is_within_cut]": 1,
      "data_train['revenue']": 1,
      "Y_train_level2": 1,
      "df_trainy": 1,
      "y_log": 1,
      "price": 1,
      "y_t": 1,
      "np.log1p(train_y)": 1,
      "trn_data['fare_amount']": 1,
      "train_y_budget_known": 1,
      "train_y_budget_missing": 1,
      "df_train_y": 1,
      "y_pred_df['y_val']": 1,
      "train_set['y']": 1,
      "lg_cf_label": 1,
      "lg_d_label": 1,
      "y_label_log": 1,
      "y0_train": 1,
      "Y1_train": 1,
      "Y6_train": 1,
      "positive_y": 1,
      "neutral_y": 1,
      "negative_y": 1,
      "df_Y_train": 1,
      "train['accuracy_group']": 1,
      "train_df['revenue']": 1,
      "y_train_store_day7": 1,
      "y_train_store_daynot7": 1,
      "y_trainl": 1,
      "train['resp']": 1,
      "means[mask]": 1,
      "means_[-selected_len:]": 1,
      "col2Arr": 1,
      "Target": 1,
      "pd.concat([Y_train, Y_val])": 1,
      "first_level_df.iloc[:, -1]": 1,
      "stds[['std']]": 1,
      "confirmed_train0": 1,
      "fatalities_train0": 1,
      "train['sales'].values": 1,
      "part_2.sales": 1,
      "train_data['log_prices']": 1,
      "train['target'].values": 1,
      "trainSet['scalar_coupling_constant']": 1,
      "train['fare_amount']": 1,
      "select_store_item(df, store, item)": 1,
      "taxi_train['fare_amount']": 1,
      "cases": 1,
      "datas_out": 1,
      "Y1": 1,
      "Y3": 1,
      "Y4": 1,
      "confirmados": 1,
      "mortos": 1,
      "Y100_train": 1,
      "y3_train": 1,
      "y4_train": 1,
      "y5_train": 1,
      "y01_train": 1,
      "train_label": 1,
      "mercedes_labels_train": 1,
      "np.log(Y.values)": 1,
      "class_value_vector": 1,
      "df['fare_amount']": 1,
      "train['log_loss']": 1,
      "y_train_train": 1,
      "y_train[data[0]]": 1,
      "y_all": 1,
      "y_train_block": 1,
      "scaled_train_lr_2['SalePrice']": 1,
      "y_train_lr_3": 1,
      "y_train_lr_4": 1,
      "df_train['price_doc']": 1,
      "y_c_train": 1,
      "y_cf_train": 1,
      "c.cost.values": 1,
      "target_lr": 1,
      "train_df.y": 1,
      "xtrain['log_revenue']": 1,
      "y_train_pca": 1,
      "y_layer2_train": 1,
      "one_hot_df['Rent']": 1,
      "dummy_df['Rent']": 1,
      "effect_df['Rent']": 1,
      "meta_train_Y": 1,
      "y_2": 1,
      "labelSet": 1,
      "observation.train.y": 1,
      "dfTrain['scalar_coupling_constant']": 1,
      "df['scalar_coupling_constant']": 1,
      "y_train_s": 1,
      "y_train_sal": 1,
      "train[dependent_variable]": 1,
      "y_linear_models": 1,
      "np.log1p(train.y)": 1,
      "trainy": 1,
      "LB.public.reshape(-1, 1)": 1,
      "y_train.values": 1,
      "final_y_train.values": 1,
      "ser.values": 1,
      "x.values": 1,
      "annual_mean_diffs.values": 1,
      "annual_std_diffs.values": 1,
      "target_y_train": 1,
      "all_y": 1,
      "confirmed_cases_Afghanistan": 1,
      "yC_Train_CS_SS": 1,
      "yF_Train_CS_SS": 1,
      "y_train_linear": 1,
      "X['answered_correctly']": 1,
      "train['answered_correctly']": 1,
      "self.y_train": 1,
      "x_train": 1,
      "df_D[i].loc[df_D[i].T != 0].values.reshape(-1, 1)": 1,
      "tmp_df[c].values": 1,
      "unmissed['age']": 1,
      "unmissed['fare']": 1,
      "preprocess_df['total_sales']": 1,
      "y_meta_train": 1,
      "target1": 1,
      "target2": 1,
      "target3": 1,
      "cur_y_train": 1,
      "Tar_val": 1,
      "y_confrm": 1,
      "y_fat": 1,
      "train_upper_50['y'].values": 1,
      "ts.values": 1,
      "y_train_fat": 1,
      "train_2.scalar_coupling_constant": 1,
      "Y_train_lag": 1,
      "train_y_conf": 1,
      "train_y_fat": 1,
      "np.array(Y).astype(np.float)": 1,
      "sentiment_ru['Polarity']": 1,
      "Y_trainer": 1,
      "y_train_confirmed": 1,
      "train_set['time_to_failure_mean']": 1,
      "np.array(train['Confirmed']).reshape(-1, 1)": 1,
      "X": 1,
      "Z": 1,
      "y_val_s": 1,
      "Quebec_y_train_1": 1,
      "Quebec_y_train_2": 1,
      "Ontario_y_train_1": 1,
      "Ontario_y_train_2": 1,
      "Alberta_y_train_1": 1,
      "Alberta_y_train_2": 1,
      "British_Columbia_y_train_1": 1,
      "British_Columbia_y_train_2": 1,
      "Nova_Scotia_y_train_1": 1,
      "Nova_Scotia_y_train_2": 1,
      "y_train_1": 1,
      "y_full": 1,
      "nr_adopted": 1,
      "ytrain[col[0]]": 1,
      "ytrain[col[1]]": 1,
      "df_country_recent['LogConfirmedCases']": 1,
      "df_country['NewFatalities']": 1,
      "y.iloc[train, :]": 1,
      "df_stacking['y'].values": 1,
      "df['atemp'].values.reshape(-1, 1)": 1,
      "dead_value": 1,
      "Confirmed_data": 1,
      "y_conf": 1,
      "y_death": 1,
      "train.loc[train[correlated].notna() & train[f].notna(), f]": 1,
      "z_train": 1,
      "s_train": 1,
      "self.data['Sales'].values.reshape(-1, 1)": 1,
      "self.data['Sales'].values": 1,
      "y_inlier": 1,
      "train['winPlacePerc']": 1,
      "dataset.dropna()['ConfirmedCases_inc_use']": 1,
      "np.log(dataset.dropna()['ConfirmedCases_inc_use'])": 1,
      "dataset.dropna()['Fatalities']": 1,
      "cases[:, [1]]": 1,
      "cases[:, [0]]": 1,
      "y.reshape(-1, 1)": 1,
      "eval_df.y": 1,
      "y[tr_idx]": 1,
      "y_min": 1,
      "Y_TRAIN": 1,
      "y_mul": 1,
      "case_array": 1,
      "death_array": 1,
      "budget_train_Y": 1,
      "train[labels].fillna(0)": 1,
      "np.ravel(y)": 1,
      "y_train.values.reshape(-1, 1)": 1,
      "y_train_df": 1,
      "final_train[33]": 1,
      "test_final_all[33]": 1,
      "abs(allFVC - allPredFVC)": 1,
      "d_set[2]": 1,
      "train_depth_data['delta_Depth_to_Groundwater_P25']": 1,
      "deltadepth_train['delta_' + d]": 1,
      "train_target_CC": 1,
      "train_target_F": 1,
      "df_train['winPlacePerc']": 1,
      "pd.DataFrame(d['Fatalities'])": 1,
      "temp_target": 1,
      "y_train2_modifyed": 1,
      "y_train3_modifyed": 1,
      "train[y]": 1,
      "train_hour_1['count'].values": 1,
      "train_hour_2['count'].values": 1,
      "train_hour_3['count'].values": 1,
      "train_hour_4['count'].values": 1,
      "train_hour_5['count'].values": 1
    },
    "sklearn.base.RegressorMixin.score.X": {
      "X_test": 426,
      "X_train": 351,
      "x_train": 121,
      "x_test": 73,
      "X": 69,
      "X_val": 52,
      "X_valid": 30,
      "df": 23,
      "X_validation": 18,
      "Xtest": 18,
      "X_train_pc": 16,
      "X_test_pc": 16,
      "x": 15,
      "train_x": 14,
      "Xs_train": 14,
      "input_data": 14,
      "test_data": 14,
      "Xs_train_a": 13,
      "Xtrain": 11,
      "trainX.iloc[:, 1:]": 10,
      "X_train_2": 8,
      "train": 8,
      "X_test1": 8,
      "cyc_data[x_ipts]": 8,
      "xTrain": 7,
      "Train_SS": 7,
      "Test_SS": 7,
      "X_Test": 7,
      "X_kpca_train": 7,
      "df_X": 7,
      "trainFactors": 6,
      "X2": 6,
      "X_trainWorst": 6,
      "train_X": 6,
      "x_val": 5,
      "test_X": 5,
      "X_train_scaled": 5,
      "data_train": 5,
      "dataTrain": 5,
      "X_Train": 4,
      "X_test_scaled": 4,
      "val_X": 4,
      "Train_ADS": 4,
      "Test_ADS": 4,
      "x_valid": 4,
      "x_train_com": 4,
      "x_test_com": 4,
      "X.T": 4,
      "test_x": 4,
      "features": 4,
      "dataTest": 4,
      "count_test3": 4,
      "X_casa_treino": 4,
      "x1": 3,
      "x2": 3,
      "X_": 3,
      "AgeKnown_X": 3,
      "xtest": 3,
      "X_test2": 3,
      "X_kpca_test": 3,
      "X_testWorst": 3,
      "X_cv": 3,
      "X_test_rfe": 3,
      "df_trainx": 3,
      "trainX": 3,
      "data_val_x": 3,
      "data_tr_x": 3,
      "df_tmp.drop('SalePrice', axis=1)": 3,
      "Xs_test": 3,
      "x_cv": 3,
      "X_test_1": 3,
      "X_test_4": 3,
      "train_df": 3,
      "x_train_scaled": 3,
      "dummy_test[prediction_var]": 3,
      "xTest": 3,
      "X_casa_scaled": 3,
      "train_tfIdf.todense()": 3,
      "val_tfIdf.todense()": 3,
      "testX": 2,
      "pipe.transform(X)": 2,
      "pipe1.transform(Xshort)": 2,
      "X_data": 2,
      "x_": 2,
      "val_x": 2,
      "x_tr": 2,
      "Cross_data": 2,
      "X_train_test": 2,
      "df_train": 2,
      "x_test_opt": 2,
      "Xs": 2,
      "df_trn": 2,
      "X2_valid": 2,
      "dt": 2,
      "X_test_neg": 2,
      "trn": 2,
      "val": 2,
      "train_df[feature_list]": 2,
      "train_df[important_features]": 2,
      "lg_train": 2,
      "df_X_validation": 2,
      "features_test": 2,
      "X_val_normalised": 2,
      "x12_forest_test": 2,
      "Model_X_test": 2,
      "X_train_new": 2,
      "va_x": 2,
      "X_c_train": 2,
      "X_c_valid": 2,
      "X_cf_train": 2,
      "X_cf_valid": 2,
      "X_test_pca": 2,
      "RX1": 2,
      "XD_train": 2,
      "d_set[0]": 2,
      "d_set[1]": 2,
      "test_input": 2,
      "[seq[i:i + number_of_points] for i in range(len(seq) - number_of_points)]": 1,
      "X_train_poly3": 1,
      "X_valid_poly3": 1,
      "reg": 1,
      "valX[cols]": 1,
      "x_var": 1,
      "sub": 1,
      "X_train_5": 1,
      "train_cont": 1,
      "finalData": 1,
      "X_scaled": 1,
      "X_train.toarray()": 1,
      "X_test.toarray()": 1,
      "train_LF_xtrain": 1,
      "train_LF_xtrain_test_data": 1,
      "x_te": 1,
      "train[['store_nbr', 'item_nbr']]": 1,
      "test[['store_nbr', 'item_nbr']]": 1,
      "x_train_normalized": 1,
      "solo_X": 1,
      "duo_X": 1,
      "squad_X": 1,
      "other_X": 1,
      "df_test": 1,
      "train_test_concat": 1,
      "d_train_X2[col_2]": 1,
      "Xte": 1,
      "X_train_train": 1,
      "train_features": 1,
      "X_tr": 1,
      "stats_groupedby_position_X": 1,
      "X_train_out.select_dtypes(exclude=['object'])": 1,
      "train_sample.drop(['meter_reading'], axis='columns')": 1,
      "x_egitimVerisi": 1,
      "x_test_df": 1,
      "X_train_comps": 1,
      "X_test_comps": 1,
      "x_df1_train": 1,
      "x_validation": 1,
      "ttextdataemx_test": 1,
      "testfeature": 1,
      "tsiftdatax_test": 1,
      "train_df[features]": 1,
      "test_df[features]": 1,
      "X.drop(['count', 'casual', 'registered'], axis=1)": 1,
      "X_linear": 1,
      "train_work": 1,
      "X_stnd": 1,
      "X_test_preprocessed": 1,
      "X_hold": 1,
      "df_X_train": 1,
      "df_train_set_encode[columns]": 1,
      "train[features]": 1,
      "colArr": 1,
      "df.drop(labels=target, axis=1)": 1,
      "test_X1": 1,
      "stds[['high_ci', 'high_ci2']]": 1,
      "trainn": 1,
      "train_val": 1,
      "test_important": 1,
      "X_test_ol": 1,
      "train_df_engineered": 1,
      "train_LotFrontage_xtrain": 1,
      "train_LotFrontage_xtrain.fillna(0)": 1,
      "x4_test": 1,
      "features_rdf": 1,
      "train_cross_test_x": 1,
      "x_train_0.drop(labels=['price_doc'], axis=1).values": 1,
      "x_train_1.drop(labels=['price_doc'], axis=1).values": 1,
      "rl_train": 1,
      "modified_train": 1,
      "X100_forest_test": 1,
      "x_forest1_test": 1,
      "x_forest2_test": 1,
      "x11_forest_test": 1,
      "test_features": 1,
      "train.values": 1,
      "x_train_test": 1,
      "sample[['vendor_id', 'passenger_count', 'pickup_longitude', 'pickup_latitude']]": 1,
      "train[refined_final_vars]": 1,
      "xtrain": 1,
      "xtrain_name": 1,
      "xtrain_item_description": 1,
      "xtrain_missing": 1,
      "X_train_cc": 1,
      "X_train_fat": 1,
      "X_test[cool_features]": 1,
      "df_pred[['Season', 'SeedDiff']].values": 1,
      "X_pca": 1,
      "X_layer2_validation": 1,
      "X_2": 1,
      "x_train1": 1,
      "x_test1": 1,
      "X_c": 1,
      "Xnew": 1,
      "x_tt": 1,
      "xPC_tr": 1,
      "xPC_tt": 1,
      "xNS_tr": 1,
      "xNS_tt": 1,
      "unmissed.drop('age', axis=1)": 1,
      "unmissed.drop('fare', axis=1)": 1,
      "X_meta_val": 1,
      "x_test_f": 1,
      "wind1[wind_col]": 1,
      "X_test_2": 1,
      "X_train_lag": 1,
      "X_cv_lag": 1,
      "X_test_lag": 1,
      "trainData": 1,
      "K_test": 1,
      "K": 1,
      "XD": 1,
      "xTestTrans": 1,
      "X_tetemp": 1,
      "X[f30]": 1,
      "xvl": 1,
      "xFatalities_train": 1,
      "xFatalities_test": 1,
      "xConfirmCases_train": 1,
      "xConfirmCases_test": 1,
      "X.iloc[test, :]": 1,
      "X_transform_train": 1,
      "df_train_data": 1,
      "X_casa_treino_poly": 1,
      "xts": 1,
      "self.data['Customers'].values.reshape(-1, 1)": 1,
      "train[feature]": 1,
      "X_test.values.reshape(-1, 1)": 1,
      "final_train.drop(33, axis=1)": 1,
      "test_final_all.drop(33, axis=1)": 1,
      "test": 1,
      "X_val_pf": 1,
      "test['x'][0]": 1,
      "test['x'][1]": 1,
      "test['x'][0].ix[:, range(34)]": 1,
      "test['x'][1].ix[:, range(34)]": 1,
      "test['x'][0].ix[:, range(10)]": 1,
      "test['x'][1].ix[:, range(10)]": 1,
      "test['x'][0].ix[:, range(1)]": 1,
      "test['x'][1].ix[:, range(1)]": 1,
      "test['x'][i]": 1,
      "Known_Survived_droped": 1,
      "valid_X": 1,
      "std_training_set": 1,
      "validation_set": 1,
      "xyenix": 1,
      "merged_df.iloc[:len_train]": 1,
      "dataTrain_poly": 1,
      "train_final": 1
    },
    "sklearn.base.RegressorMixin.score.y": {
      "y_test": 519,
      "y_train": 499,
      "y": 107,
      "y_val": 61,
      "Y_train": 55,
      "Y_test": 34,
      "y_valid": 32,
      "Y": 23,
      "Y_validation": 18,
      "train_y": 16,
      "ytest": 11,
      "Ytrain": 11,
      "Ytest": 11,
      "val_y": 10,
      "y_test1": 9,
      "yTrain": 8,
      "y1": 7,
      "target": 7,
      "test_y": 7,
      "df_Y": 7,
      "y_train_cc": 6,
      "trainResponse": 6,
      "y_trainWorst": 6,
      "yLabelsLog": 6,
      "y1Train": 6,
      "y2Train": 6,
      "y2": 5,
      "y_train1": 5,
      "y_train_ft": 5,
      "Y2": 5,
      "y_cv": 5,
      "y_casa_treino": 5,
      "y_pred": 4,
      "y_trn": 4,
      "train_df['item_cnt_month'].clip(0.0, 20.0)": 4,
      "ytrain": 4,
      "np.exp(predsTest)": 4,
      "cyc_data.casual": 4,
      "cyc_data.registered": 4,
      "yTest": 4,
      "test['y'][0]": 4,
      "test['y'][1]": 4,
      "Y_val": 3,
      "AgeKnown_y": 3,
      "y_test2": 3,
      "Y_Test": 3,
      "y_testWorst": 3,
      "y2_valid": 3,
      "df_trainy": 3,
      "data_val_y": 3,
      "data_tr_y": 3,
      "df_tmp['SalePrice']": 3,
      "targets": 3,
      "Y_test_1": 3,
      "Y_test_4": 3,
      "dummy_test['trip_duration']": 3,
      "y_casa_scaled.ravel()": 3,
      "y_data": 2,
      "y_te": 2,
      "Y_cross": 2,
      "y_test_opt": 2,
      "submit['winPlacePerc']": 2,
      "trg[ok]": 2,
      "y_test.flatten()": 2,
      "y_test_neg": 2,
      "df_Y_validation": 2,
      "cases_test": 2,
      "train_LotFrontage_ytrain": 2,
      "y12_forest_test": 2,
      "pred": 2,
      "Model_y_test": 2,
      "va_y": 2,
      "train_Y": 2,
      "y_c_train": 2,
      "y_c_valid": 2,
      "y_cf_train": 2,
      "y_cf_valid": 2,
      "y_test_pca": 2,
      "Ry1": 2,
      "Y_train.clip(0.0, 20.0)": 2,
      "YD_train": 2,
      "d_set[2]": 2,
      "d_set[3]": 2,
      "test_target": 2,
      "seq[number_of_points:]": 1,
      "y_train_poly3": 1,
      "y_valid_poly3": 1,
      "testY": 1,
      "y_sales": 1,
      "valY": 1,
      "y_var": 1,
      "df.SalePrice": 1,
      "y_train_5": 1,
      "y_log": 1,
      "train_LF_ytrain": 1,
      "train_LF_ytrain_test_data": 1,
      "y_tr": 1,
      "train['unit_sales']": 1,
      "test['unit_sales']": 1,
      "testY2": 1,
      "y_train_log": 1,
      "y_Train['target_carbon_monoxide']": 1,
      "y_Test['target_carbon_monoxide']": 1,
      "y_Train['target_benzene']": 1,
      "y_Test['target_benzene']": 1,
      "y_Train['target_nitrogen_oxides']": 1,
      "y_Test['target_nitrogen_oxides']": 1,
      "solo_y": 1,
      "duo_y": 1,
      "squad_y": 1,
      "other_y": 1,
      "y_concat": 1,
      "d_train_y2": 1,
      "Yte": 1,
      "y_train_train_log": 1,
      "y_train_test_log": 1,
      "test_Y": 1,
      "train_labels": 1,
      "Regressor['tValue']": 1,
      "rf_y_train": 1,
      "rf_y_test": 1,
      "train_t": 1,
      "stats_groupedby_position_Y": 1,
      "train_sample['meter_reading']": 1,
      "y_egitimVerisi": 1,
      "predictions": 1,
      "y_df1_train": 1,
      "y_validation": 1,
      "ttextdataemy_test": 1,
      "ttexty_test": 1,
      "tsiftdatay_test": 1,
      "trainY": 1,
      "train_df['age']": 1,
      "test_df['age']": 1,
      "np.log(pd.concat([X['casual'], X['registered']], axis=1) + 1)": 1,
      "y_linear": 1,
      "lg_cf_label": 1,
      "lg_d_label": 1,
      "y_hold": 1,
      "df_Y_train": 1,
      "train['resp']": 1,
      "col2Arr": 1,
      "Y1": 1,
      "df[target]": 1,
      "train_y1": 1,
      "predict_Y1": 1,
      "stds[['std']]": 1,
      "train_val_y": 1,
      "y_test_predicted": 1,
      "prices[Y]": 1,
      "y4_test": 1,
      "target_rdf": 1,
      "train_cross_test_y": 1,
      "y1_train": 1,
      "y1_valid": 1,
      "y2_train": 1,
      "x_train_0.price_doc.values": 1,
      "x_train_1.price_doc.values": 1,
      "log_price": 1,
      "price.values": 1,
      "Y100_forest_test": 1,
      "y_forest1_test": 1,
      "y_forest2_test": 1,
      "y11_forest_test": 1,
      "test_label": 1,
      "Y_train_test": 1,
      "train_y_inf": 1,
      "train_y_ft": 1,
      "sp_train": 1,
      "lasso_pred": 1,
      "en_pre": 1,
      "rfr_pred": 1,
      "y_train_test": 1,
      "sample['trip_duration']": 1,
      "train['y']": 1,
      "y_test[:, i]": 1,
      "np.log(test_y)": 1,
      "y_train_fat": 1,
      "df_pred.diff_score.values": 1,
      "y_layer2_validation": 1,
      "y_2": 1,
      "y_c": 1,
      "y_": 1,
      "y.ravel()": 1,
      "y_tr[:, 0]": 1,
      "y_tt[:, 0]": 1,
      "yPC_tr[:, 0]": 1,
      "yPC_tt[:, 0]": 1,
      "yNS_tr[:, 0]": 1,
      "yNS_tt[:, 0]": 1,
      "unmissed['age']": 1,
      "unmissed['fare']": 1,
      "y_meta_val": 1,
      "wind1['windspeed']": 1,
      "target1": 1,
      "target2": 1,
      "target3": 1,
      "Y_test_2": 1,
      "Y_Train": 1,
      "Y_cv": 1,
      "Y_train_lag": 1,
      "Y_cv_lag": 1,
      "Y_lag": 1,
      "YD": 1,
      "y_val_reg": 1,
      "y_tetemp": 1,
      "yvl": 1,
      "yFatalities_train": 1,
      "yFatalities_test": 1,
      "yConfirmCases_train": 1,
      "yConfirmCases_test": 1,
      "y.iloc[test, :]": 1,
      "df_train_target": 1,
      "yts": 1,
      "self.data['Sales'].values.reshape(-1, 1)": 1,
      "target_labels": 1,
      "y_test.ravel()": 1,
      "train[labels].fillna(0)": 1,
      "y_cases": 1,
      "y_test.values.reshape(-1, 1)": 1,
      "y_train_df": 1,
      "final_train[33]": 1,
      "test_final_all[33]": 1,
      "test['y'][i]": 1,
      "Known_Survived_1": 1,
      "valid_y": 1,
      "training_label": 1,
      "val_label": 1
    },
    "sklearn.model_selection._split.StratifiedKFold.__init__.n_splits": {
      "5": 1296,
      "10": 374,
      "n_splits": 311,
      "folds": 155,
      "11": 134,
      "num_folds": 111,
      "3": 108,
      "N_SPLITS": 108,
      "n_folds": 102,
      "CFG['fold_num']": 95,
      "n_fold": 90,
      "self.n_splits": 83,
      "4": 83,
      "N_FOLDS": 82,
      "NFOLDS": 76,
      "nfolds": 72,
      "2": 67,
      "FOLDS": 65,
      "k": 62,
      "kfold": 48,
      "K": 46,
      "CFG.n_fold": 44,
      "nfold": 39,
      "25": 33,
      "num_splits": 31,
      "nr_fold": 26,
      "nr_folds": 23,
      "splits": 21,
      "FOLD": 20,
      "config['nfolds']": 19,
      "NUM_FOLDS": 18,
      "n_split": 17,
      "CFG.N_FOLDS": 16,
      "15": 15,
      "20": 15,
      "12": 14,
      "self.num_folds": 13,
      "7": 12,
      "NFOLD": 12,
      "num_of_folds": 12,
      "cv": 11,
      "50": 10,
      "8": 10,
      "fold": 10,
      "numCVSplits": 10,
      "9": 9,
      "NUM_SPLITS": 8,
      "6": 8,
      "config.n_folds": 8,
      "fold_n": 8,
      "SPLITS": 7,
      "N_FOLD": 7,
      "kfolds": 7,
      "30": 7,
      "num_fold": 7,
      "self.cv": 6,
      "N": 6,
      "CFG['n_splits']": 6,
      "N_Splits": 5,
      "number_of_folds": 5,
      "N_FILES": 5,
      "split": 5,
      "CFG['n_fold']": 5,
      "NUM_SHARDS": 4,
      "k_fold": 4,
      "total_folds": 4,
      "cross_validation_folds": 4,
      "n_s": 4,
      "n_inner_folds": 4,
      "n": 4,
      "config.k": 4,
      "num_shards": 3,
      "NUMBER_OF_FOLDS": 3,
      "outer_n": 3,
      "inner_n": 3,
      "nsplits": 3,
      "Config.N_SPLITS": 3,
      "n_models": 3,
      "TrainConfig.FOLDS": 3,
      "cv_total": 3,
      "self.n_folds": 3,
      "kf_split": 3,
      "params['nfolds']": 3,
      "CV_STEPS": 3,
      "numFolds": 3,
      "NUM_FOLD": 3,
      "self._num_folds": 3,
      "17": 3,
      "__n_folds": 3,
      "settings.Nfolds": 3,
      "nb_folds": 2,
      "N_TRAINFILES": 2,
      "config.num_folds": 2,
      "16": 2,
      "CONFIG['num_folds']": 2,
      "21": 2,
      "Config.n_folds": 2,
      "self.n_fold": 2,
      "config['num_folds']": 2,
      "self.n_splits_": 2,
      "CFG.folds": 2,
      "num_split": 2,
      "kfold_n_splits": 2,
      "config.N_FOLDS": 2,
      "nb_fold": 2,
      "49": 2,
      "kfold_splits": 2,
      "CV_SPLIT": 2,
      "no_of_folds": 2,
      "K_FOLDS": 2,
      "config.TRAIN_SPLITS": 2,
      "config['CROSS_VALIDATION']['NUM_FOLDS']": 2,
      "nFolds": 2,
      "noOfFolds": 2,
      "100": 2,
      "31": 2,
      "24": 2,
      "Conf.n_fold": 2,
      "PARAMS['folds']": 2,
      "2020": 2,
      "folds_num": 1,
      "N_SHARDS_TRAIN": 1,
      "NumFold": 1,
      "fold_num": 1,
      "40": 1,
      "opt.n_fold": 1,
      "config.num_fold": 1,
      "nsplit": 1,
      "CFG['nfolds']": 1,
      "CONFIG.n_fold": 1,
      "y_train": 1,
      "KFOLDS": 1,
      "N_folds": 1,
      "Config.fold_num": 1,
      "self.kfolds": 1,
      "N_SPLIT": 1,
      "myFolds": 1,
      "CONFIGURATION['nbr_folds']": 1,
      "k_fold_n_splits": 1,
      "splits_nbr": 1,
      "self.len": 1,
      "self.n_bags": 1,
      "14": 1,
      "TOTAL_FOLDS": 1,
      "FOLD_NUM": 1,
      "c.num_cv_splits": 1,
      "num_model": 1,
      "config.nfold": 1,
      "NUM_SPLIT": 1,
      "CFG.lgb_folds": 1,
      "config['CV_FOLDS']": 1,
      "N_TRIALS": 1,
      "sk_n": 1,
      "model_count": 1,
      "config['FOLDS']": 1,
      "INNER_FOLDS": 1,
      "CFG.n_folds": 1,
      "CFG['NUM_FOLDS']": 1,
      "y": 1,
      "train_splits": 1,
      "hparam['KFOLDS']": 1,
      "fold_split": 1,
      "CFG['folds']": 1,
      "data_config['n_splits']": 1,
      "split_size": 1,
      "GCONF.n_splits": 1,
      "CFG.n_splits": 1,
      "Config.n_fold": 1,
      "num_round": 1,
      "n_splits[bag]": 1,
      "self._n_splits": 1,
      "net_cfg['num_folds']": 1,
      "Config.num_folds": 1,
      "n_sp": 1,
      "splits_kfold": 1,
      "self.NUM_FOLDS": 1,
      "N_splits": 1,
      "config['fold']": 1,
      "cfg.NSPLITS": 1,
      "params['k_folds']": 1,
      "params['n_folds']": 1,
      "self.kfold": 1,
      "Config.k": 1,
      "config['NUM_FOLDS']": 1,
      "fold__": 1,
      "cfg.CV_fold_num": 1,
      "66": 1,
      "Number_of_folds": 1,
      "200": 1,
      "CFG.num_of_fold": 1,
      "int(train_df.shape[0] / 10000)": 1,
      "folds_number": 1
    },
    "sklearn.model_selection._split.StratifiedKFold.__init__.shuffle": {
      "True": 3101,
      "False": 1239,
      "shuffle": 8,
      "kfold_shuffle": 4,
      "shuffle_data": 2,
      "self.shuffle": 1,
      "shuf": 1,
      "config.shuffle": 1,
      "SHUFFLE": 1,
      "seed != None": 1
    },
    "sklearn.model_selection._split.StratifiedKFold.__init__.random_state": {
      "42": 913,
      "None": 893,
      "SEED": 336,
      "seed": 247,
      "1": 130,
      "random_state": 121,
      "0": 110,
      "1001": 81,
      "CFG['seed']": 66,
      "2019": 55,
      "1337": 54,
      "15": 52,
      "10": 49,
      "CFG.seed": 44,
      "777": 44,
      "7": 42,
      "123": 40,
      "RANDOM_STATE": 37,
      "2020": 32,
      "2": 32,
      "13": 29,
      "47": 24,
      "2016": 23,
      "44000": 22,
      "4590": 21,
      "2018": 21,
      "11": 21,
      "config['seed']": 20,
      "2434": 20,
      "2319": 19,
      "DATA_SPLIT_SEED": 19,
      "101": 17,
      "14": 17,
      "rs": 15,
      "100": 15,
      "2048": 14,
      "2021": 14,
      "random_seed": 13,
      "21": 13,
      "44": 13,
      "1234": 13,
      "1017": 13,
      "22": 12,
      "RANDOM_SEED": 11,
      "12": 11,
      "5": 10,
      "326": 10,
      "CFG.SEED": 10,
      "41": 10,
      "48": 10,
      "20": 10,
      "24": 10,
      "seed_value": 9,
      "self.seed": 9,
      "314": 9,
      "2017": 9,
      "RS": 9,
      "time.time": 9,
      "17": 8,
      "1024": 8,
      "8": 8,
      "flags.seed": 8,
      "split_seed": 7,
      "31415": 7,
      "545167": 7,
      "546789": 7,
      "137": 7,
      "1213": 7,
      "rng_seed": 6,
      "3": 6,
      "config.seed": 6,
      "99999": 6,
      "random_state_int": 6,
      "FOLD_RANDOM_SEED": 6,
      "4": 6,
      "16": 5,
      "218": 5,
      "1989": 5,
      "1881": 4,
      "777 + x": 4,
      "1991": 4,
      "config.SEED": 4,
      "1996": 3,
      "1054": 3,
      "231": 3,
      "outer_seed": 3,
      "inner_seed + n_outer_fold": 3,
      "69": 3,
      "4950": 3,
      "Config.SEED": 3,
      "6": 3,
      "CONFIG.seed": 3,
      "59": 3,
      "105641": 3,
      "20190301": 3,
      "32": 3,
      "random.randint(100, 999)": 3,
      "45": 3,
      "BaseConfig.SEED": 3,
      "2233": 3,
      "1111": 3,
      "719": 3,
      "config['SEED']": 3,
      "randomSeed": 3,
      "321": 3,
      "1990": 3,
      "myseed": 3,
      "config.random_state": 3,
      "11111": 3,
      "RANDAM_SEED": 3,
      "644": 3,
      "23": 2,
      "49": 2,
      "420": 2,
      "42 + k": 2,
      "1301": 2,
      "12345786": 2,
      "5756": 2,
      "CONFIG['seed']": 2,
      "1812": 2,
      "True": 2,
      "37": 2,
      "2007": 2,
      "s + 1": 2,
      "Config.seed": 2,
      "12345": 2,
      "33": 2,
      "fold_seed": 2,
      "4422": 2,
      "25": 2,
      "2600": 2,
      "self.random_state": 2,
      "229": 2,
      "60": 2,
      "546": 2,
      "26": 2,
      "67594235": 2,
      "110": 2,
      "RE": 2,
      "4042": 2,
      "98": 2,
      "50": 2,
      "xseed": 2,
      "params['seed']": 2,
      "1984": 2,
      "500": 2,
      "4321": 2,
      "seeds[bag]": 2,
      "29": 2,
      "seed_split + j": 2,
      "Conf.seed": 2,
      "345": 2,
      "662": 1,
      "3263": 1,
      "5678": 1,
      "2**10": 1,
      "1226": 1,
      "13 + i": 1,
      "111222": 1,
      "562": 1,
      "R": 1,
      "46": 1,
      "5272020": 1,
      "opt.seed": 1,
      "77": 1,
      "191": 1,
      "3829": 1,
      "31829": 1,
      "234": 1,
      "1994": 1,
      "kfold_random_state": 1,
      "42 + RANDOM_STATE": 1,
      "sklearn_seed": 1,
      "888": 1,
      "65535": 1,
      "108": 1,
      "123123": 1,
      "1212": 1,
      "4141": 1,
      "5451": 1,
      "25000": 1,
      "args.seed": 1,
      "self.random_seed": 1,
      "model_seed[num_mod]": 1,
      "91": 1,
      "CONFIGURATION['seed']": 1,
      "39": 1,
      "1029": 1,
      "88": 1,
      "5555555": 1,
      "cv_random_seed": 1,
      "620": 1,
      "SEED + j": 1,
      "SEED + 1234": 1,
      "911": 1,
      "1997": 1,
      "7418880": 1,
      "state_": 1,
      "2052": 1,
      "721991": 1,
      "42 + i": 1,
      "54": 1,
      "20011998": 1,
      "876": 1,
      "311": 1,
      "68": 1,
      "seed_val": 1,
      "28": 1,
      "model_seed": 1,
      "31416": 1,
      "43": 1,
      "SEED + base_seed - 1": 1,
      "SEED_SKF": 1,
      "np.random.randint(100000)": 1,
      "1906": 1,
      "DefaultConfig.seed": 1,
      "111": 1,
      "4242": 1,
      "N": 1,
      "99": 1,
      "213": 1,
      "666": 1,
      "RANDOM_STATE + rs_n": 1,
      "9": 1,
      "529": 1,
      "62": 1,
      "GCONF.seed": 1,
      "3228": 1,
      "57": 1,
      "2702": 1,
      "i": 1,
      "1032": 1,
      "1112": 1,
      "1600": 1,
      "2333": 1,
      "__seed": 1,
      "__seed + 2": 1,
      "__seed + 4": 1,
      "2407": 1,
      "1993": 1,
      "317": 1,
      "7654": 1,
      "self.randomSeed": 1,
      "PARAMS['RANDOM_SEED']": 1,
      "416": 1,
      "567": 1,
      "369": 1,
      "620402": 1,
      "12212": 1,
      "cfg.SEED": 1,
      "1974": 1,
      "cfg.random_seed": 1,
      "40": 1,
      "PARAMS['seed']": 1,
      "76": 1,
      "rand_state": 1,
      "5168": 1,
      "721": 1,
      "6017": 1,
      "3456": 1,
      "121": 1,
      "14 + seed": 1,
      "217": 1
    },
    "sklearn.model_selection._split.StratifiedKFold.split.X": {
      "X": 706,
      "train": 306,
      "X_train": 253,
      "df": 126,
      "train_df": 123,
      "x_train": 112,
      "np.arange(train.shape[0])": 99,
      "train2": 98,
      "data": 75,
      "train_X": 74,
      "y": 71,
      "train3": 70,
      "df_folds.index": 67,
      "df_train": 62,
      "input_ids": 58,
      "train_df.values": 55,
      "x": 54,
      "reduce_train": 47,
      "self.train_df": 46,
      "folds": 42,
      "train_data": 39,
      "np.zeros(len(X_train))": 36,
      "train3p": 29,
      "xtrain": 29,
      "features": 29,
      "train_all": 25,
      "train_x": 24,
      "X.values": 24,
      "train.values": 23,
      "target": 21,
      "all_df": 21,
      "xdat": 20,
      "tr": 16,
      "train_features": 16,
      "train_ids": 15,
      "train[features]": 14,
      "range(train.shape[0])": 13,
      "y_map": 13,
      "folds.values": 12,
      "Xtrain": 12,
      "np.arange(train_df.shape[0])": 12,
      "table.index": 10,
      "train_feature": 10,
      "train_df.index.values": 10,
      "train.index": 9,
      "train2.iloc[:, 1:-1]": 9,
      "aptos2019_img_paths": 9,
      "dataset_dicts": 8,
      "X_train.values": 8,
      "bike_train": 8,
      "file_list": 7,
      "data.values": 7,
      "image_ids": 7,
      "l1_train": 7,
      "targets": 7,
      "self.df": 7,
      "new_train": 7,
      "images": 7,
      "data.loc[:, 'path']": 7,
      "X1": 7,
      "train[columns]": 7,
      "all_idf": 7,
      "X_train_full": 6,
      "y_train": 6,
      "df['image_id']": 6,
      "df_ids": 6,
      "df.id": 6,
      "np.arange(len(df))": 6,
      "ids": 6,
      "np.arange(df.shape[0])": 6,
      "Xtrain_id": 6,
      "data_df": 6,
      "X.sample(frac=0.05)": 6,
      "train_new[columns]": 6,
      "train[feats]": 5,
      "train_inputs_all": 5,
      "X_data": 5,
      "df.index": 5,
      "train_data.values": 5,
      "pre_train": 5,
      "tfidf_train": 5,
      "train_df.text": 4,
      "trn_df.values": 4,
      "S_train": 4,
      "df_train['image_id']": 4,
      "np.arange(train_df_2019.shape[0])": 4,
      "train4p": 4,
      "train_stack": 4,
      "train.iloc[:, 1:-1]": 4,
      "train['id']": 4,
      "train.image_name": 4,
      "data[feature]": 4,
      "data.iloc[infold]": 4,
      "train_paths": 4,
      "X['text_cleaned']": 4,
      "X_p": 4,
      "x_train_pca": 4,
      "train_df['text_cleaned']": 4,
      "X.index": 4,
      "df_images": 3,
      "np.arange(len(train_df))": 3,
      "X_out": 3,
      "df['ImageId']": 3,
      "train_df[feats]": 3,
      "train_df[cat_vars + cont_vars]": 3,
      "data_tr": 3,
      "train_preprocessed": 3,
      "train_full_df": 3,
      "X_train_scaled": 3,
      "slim_train_features": 3,
      "train2[train2.columns[train2.columns != 'target']]": 3,
      "df_benign": 3,
      "train4": 3,
      "df_trn": 3,
      "X_train_oof.values": 3,
      "X_all3": 3,
      "train_per_patient_char['key']": 3,
      "dataset": 3,
      "trn2": 3,
      "x.iloc[:, 1:-1]": 3,
      "featuresDB": 3,
      "train_df_site": 3,
      "np.zeros(len(t))": 3,
      "X_PCA_train": 3,
      "X_TRAIN": 3,
      "av_data": 3,
      "labels": 3,
      "train_s": 3,
      "image_id": 3,
      "TRAIN": 3,
      "train_df.index": 2,
      "clearTrainImg": 2,
      "np.zeros(n)": 2,
      "y_split[:, 0]": 2,
      "df_train_tp.recording_id.values": 2,
      "train_data['text']": 2,
      "train_set": 2,
      "x0": 2,
      "train[features_to_keep]": 2,
      "train_data.drop('target', axis=1)": 2,
      "train_scale": 2,
      "train[cols]": 2,
      "XGB_train_set": 2,
      "train_df['image_id']": 2,
      "X_resampled": 2,
      "app_train_enc_imput_med": 2,
      "processed_train_labels_df": 2,
      "train_set[['segment_id']]": 2,
      "feature_train": 2,
      "data_train": 2,
      "df_train.index": 2,
      "df['text']": 2,
      "np.arange(pivot_df.shape[0])": 2,
      "train_new": 2,
      "df_train.id_code": 2,
      "train_ohe": 2,
      "tt": 2,
      "df_clean": 2,
      "df_noisy": 2,
      "radboud_csv": 2,
      "karolinska_csv": 2,
      "sample_list": 2,
      "is_fold_train": 2,
      "train_labels": 2,
      "X_train_cat": 2,
      "img_feats": 2,
      "X_train_std": 2,
      "oof_df": 2,
      "train_df[all_features]": 2,
      "df_train['id_code']": 2,
      "ptrain_add_np": 2,
      "new_training_data": 2,
      "data_X": 2,
      "X_trn": 2,
      "stack_train": 2,
      "df_train_X_normalized": 2,
      "train_meta": 2,
      "df.index.values": 2,
      "train['target']": 2,
      "split[0]['modi']": 2,
      "label_df.index": 2,
      "traincsv.image_id.values": 2,
      "df_train.values": 2,
      "groups": 2,
      "user_ID": 2,
      "X_tr": 2,
      "final_train_features": 2,
      "x_valid": 2,
      "df_train['text_cleaned']": 2,
      "fe_train": 2,
      "imgs": 2,
      "train_ds": 2,
      "train['clean_txt']": 2,
      "wtrain": 2,
      "stacked_df[columns]": 2,
      "files": 2,
      "np.zeros(len(train_df))": 2,
      "perm_target": 2,
      "filenames": 2,
      "dfmat": 2,
      "df.image_id": 2,
      "df_folds[config['DATA']['IMAGE_COL_NAME']]": 2,
      "tr[cols_to_use]": 2,
      "dfx": 2,
      "train_folds_df": 2,
      "Y": 2,
      "X_node": 2,
      "self.X": 2,
      "_t": 2,
      "X_raw": 2,
      "train_kf_feature": 2,
      "train_image_id": 2,
      "train_preprocessed[features].values": 2,
      "encoded_train": 2,
      "np.arange(train_study.shape[0])": 2,
      "X_train_public": 2,
      "X_train_5": 2,
      "train[feature_names]": 2,
      "np.zeros(y_train.shape[0])": 1,
      "target_": 1,
      "df.drop(labels='target', axis=1)": 1,
      "X_all[:samp_size]": 1,
      "df.values": 1,
      "x_opt_sc": 1,
      "P.Patient": 1,
      "ans.drop(['target'], axis=1)": 1,
      "trainData": 1,
      "train[training_features]": 1,
      "data[TARGET]": 1,
      "df.image": 1,
      "train_set_balanced": 1,
      "external_train": 1,
      "train_df.drop('target', axis=1).index.values": 1,
      "np.arange(traindf.shape[0])": 1,
      "X_scaled": 1,
      "df_img": 1,
      "df_train_preprocess": 1,
      "lit_data": 1,
      "aml_train_preds_df": 1,
      "train_points.values": 1,
      "tr_ids": 1,
      "padded_train_sequences": 1,
      "df_cb": 1,
      "df1": 1,
      "df2": 1,
      "train_clean": 1,
      "range(train_count)": 1,
      "np.zeros(len(Y))": 1,
      "application_train": 1,
      "attention_masks": 1,
      "data_traindf": 1,
      "train[num_feat]": 1,
      "train_text": 1,
      "train_dataset.df": 1,
      "train_df.image_name": 1,
      "df_train_scale": 1,
      "extra_train.values": 1,
      "probaFeature": 1,
      "resnet50_feature_train": 1,
      "df_train['text']": 1,
      "X['text']": 1,
      "train_data['image_id']": 1,
      "train_text_tfidf": 1,
      "rescuer_ids": 1,
      "np.zeros(len(data))": 1,
      "df_train_scores": 1,
      "df_train[cols + cols2 + cols3 + cols6]": 1,
      "X_final": 1,
      "train_df['id_code']": 1,
      "train_std_df": 1,
      "np.zeros(len(targets))": 1,
      "numpy.arange(len(train))": 1,
      "train_x_numeric": 1,
      "X[:300000]": 1,
      "loaded_dfs[SEL_FTS]": 1,
      "input_idsx": 1,
      "train4_pse": 1,
      "x_train.values": 1,
      "train_agg": 1,
      "X_tfidf": 1,
      "tr_desc_pad": 1,
      "train_input['input_word_ids']": 1,
      "Xtrain.values": 1,
      "self.train_data['path']": 1,
      "df_train_sum": 1,
      "dfx.values": 1,
      "tp_file_list": 1,
      "data_list": 1,
      "combine[features]": 1,
      "help_df": 1,
      "self.train": 1,
      "grouped_df_all['Group'].values": 1,
      "dataset.index.values": 1,
      "full_train_df": 1,
      "df_x": 1,
      "train[independent_feat]": 1,
      "newX_train": 1,
      "X3_train.values": 1,
      "X3_train": 1,
      "df_train.drop(['ID_code', 'target'], axis=1)": 1,
      "cl_features": 1,
      "train_df[feat_choices].values": 1,
      "data.loc[:, 'site']": 1,
      "data[target]": 1,
      "fm_train": 1,
      "train_data[features]": 1,
      "train.drop('AdoptionSpeed', axis=1)": 1,
      "local_X_train": 1,
      "pca_tr_df": 1,
      "train.values[:, top_feats]": 1,
      "train_targets": 1,
      "data.drop('target', axis=1)": 1,
      "train_features_slim[idx_train_other]": 1,
      "model01_lgb_X_train": 1,
      "model01_xgb_X_train": 1,
      "model01_cb_X_train": 1,
      "model012_lgb_X_train": 1,
      "model012_xgb_X_train": 1,
      "model012_cb_X_train": 1,
      "model0123_lgb_X_train": 1,
      "model0123_xgb_X_train": 1,
      "model0123_cb_X_train": 1,
      "model01234_lgb_X_train": 1,
      "model01234_cb_X_train": 1,
      "teTrain": 1,
      "df.path": 1,
      "X_t": 1,
      "train_xS": 1,
      "train_x2d": 1,
      "train_dataset": 1,
      "train_pet_ids": 1,
      "train_final_df": 1,
      "df_stra['stratify']": 1,
      "xtrain1": 1,
      "train.drop(columns='target')": 1,
      "X_embed": 1,
      "X_scaled_rs": 1,
      "train_df[cols]": 1,
      "train_data['image']": 1,
      "trn": 1,
      "data[[feature_name]]": 1,
      "x_train_val": 1,
      "train_df['target']": 1,
      "tr_zval": 1,
      "layer2_df": 1,
      "data_x": 1,
      "Xtr_more": 1,
      "patient_df[['Age', 'Sex', 'SmokingStatus']]": 1,
      "X_train_drop": 1,
      "rescuer_idx": 1,
      "train.text.values": 1,
      "stacked_train": 1,
      "X_vecs": 1,
      "df_train['premise']": 1,
      "train[idx_tr][oof_features]": 1,
      "trainX": 1,
      "train_y_raw": 1,
      "train_images": 1,
      "list(self.train.text)": 1,
      "new_train_feature": 1,
      "train_seq": 1,
      "X_exam": 1,
      "ID": 1,
      "data_dict['train_data']": 1,
      "all_images": 1,
      "X_train_imputed": 1,
      "train_df['diagnosis']": 1,
      "train_data['image_path']": 1,
      "train_df[features].values": 1,
      "yards_label": 1,
      "train_df['id']": 1,
      "patient_only_train[Cols]": 1,
      "input_ids_train": 1,
      "source_X": 1,
      "df['image_name'].to_numpy()": 1,
      "np.arange(N_IMGS)": 1,
      "df_small.image_name.values": 1,
      "dataX": 1,
      "X_valid_train": 1,
      "X_3Ch_train": 1,
      "train2.values": 1,
      "train_embeds": 1,
      "X_val_lang": 1,
      "trn2_add": 1,
      "full_features": 1,
      "padded_train": 1,
      "train_word_sequences": 1,
      "trn_y_zeros": 1,
      "train_dataset_2019": 1,
      "train['excerpt']": 1,
      "train['image_id']": 1,
      "X_log": 1,
      "train_df.drop('target', axis=1)": 1,
      "annotations['image_id'].values": 1,
      "train_df.image_id": 1,
      "train[selected_column].values": 1,
      "X_train_used.values": 1,
      "features_oof": 1,
      "source['id_code']": 1,
      "external_train_df": 1,
      "train_df_bal": 1,
      "train.drop(target, axis=1)": 1,
      "train_pd['id_code']": 1,
      "train_csv": 1,
      "trn_l1_y": 1,
      "full_meta": 1,
      "full_data": 1,
      "xtrain_lr_elif": 1,
      "xtrain_lr_perm": 1,
      "data.iloc[:, 1:]": 1,
      "np.arange(len(df_train_single))": 1,
      "np.arange(len(df_train_multi))": 1,
      "np.zeros(len(y_data))": 1,
      "train_data[target_col].values": 1,
      "input_ids_t": 1,
      "train1[cols]": 1,
      "x_train_padded_seqs_split": 1,
      "df_all['image']": 1,
      "train_df3": 1,
      "np.zeros_like(train_label_ids)": 1,
      "id_images": 1,
      "valid_df['toxic'].values": 1,
      "train_trans": 1,
      "train_sel": 1,
      "train_df['image_id'].values": 1,
      "train_df.iloc[:, 1:]": 1,
      "data_train['text_cleaned']": 1,
      "range(len(train_dataset))": 1,
      "train.drop(['Target'], axis=1)": 1,
      "train2.drop(['Target'], axis=1)": 1,
      "train_select_bin_x": 1,
      "train_transaction.values": 1,
      "train['image_path']": 1,
      "df[features]": 1,
      "train_transformed": 1,
      "train_list['image_id']": 1,
      "df_folds[config.image_col_name]": 1,
      "xTrain": 1,
      "df[:600000]": 1,
      "df_keep": 1,
      "X_lr": 1,
      "X_nb": 1,
      "X_train_rule": 1,
      "train_X_all": 1,
      "_y": 1,
      "train_df_vs": 1,
      "x1_train": 1,
      "mtr": 1,
      "row_no_lists": 1,
      "X_train_input": 1,
      "train.id": 1,
      "transformed_data_train": 1,
      "X_tra.values": 1,
      "DATA": 1,
      "dataset_year": 1,
      "list(range((data_ffm['dataset'] == 'Train').sum()))": 1,
      "list(range(len(train_data)))": 1,
      "list(train.index)": 1,
      "sparsedata[:len(target)]": 1,
      "new_df.values": 1,
      "X_kmeans_train": 1,
      "original_Xtrain": 1,
      "df_train[feats]": 1,
      "files_ls": 1,
      "in_X_all": 1,
      "df.image_id.values": 1,
      "train_df.iloc[:, 2:]": 1,
      "data.image_id": 1,
      "df_train.iloc[:, 1:-1]": 1,
      "train_projected['target']": 1,
      "x_train_sm": 1,
      "features.values": 1,
      "fnc_train": 1,
      "df[feats]": 1,
      "new_train_X_scaled_smoted": 1,
      "np.arange(len(df_train))": 1,
      "df_RFE": 1,
      "df_train_": 1,
      "X_Train": 1,
      "X_train_pad": 1,
      "train['cleaned_excerpt']": 1,
      "train['cleaned_excerpt'].values": 1,
      "knn_train": 1,
      "train_selected.values": 1,
      "crossvalidation_df": 1,
      "train_df_2020": 1,
      "new_train.drop(['accuracy_group'], axis=1)": 1,
      "train_df[good_features].drop('isFraud', axis=1)": 1,
      "train.query('date>150')[just_features]": 1,
      "train[feat_imp.features]": 1,
      "X_resized": 1,
      "np.arange(retrain.shape[0])": 1,
      "train2[cols].values": 1,
      "x.values": 1,
      "combined": 1,
      "train[variables]": 1,
      "X_resamp_tr": 1,
      "input_df['ImageId']": 1,
      "raw_train_data": 1,
      "unique_train_patients": 1,
      "samples_df.filepath": 1,
      "train_ds_scaled": 1,
      "oof_preds": 1,
      "X_gtrain_scaled": 1,
      "training_features_scaled": 1,
      "df_new['image']": 1,
      "trainc": 1,
      "X2": 1,
      "X_train.loc[:, feature_base]": 1,
      "X_train.loc[:, features_selected]": 1,
      "df.text": 1,
      "np.arange(train_data.shape[0])": 1,
      "x_train1": 1,
      "x_train_padded": 1,
      "train_labels.values": 1,
      "X.iloc[:, 3:]": 1,
      "np.arange(train_tab.shape[0])": 1,
      "train_index": 1,
      "range(len(train))": 1
    },
    "sklearn.model_selection._split.StratifiedKFold.split.y": {
      "y": 890,
      "y_train": 279,
      "train2['target']": 159,
      "target": 153,
      "train_y": 115,
      "Y": 106,
      "train.label.values": 91,
      "target.values": 66,
      "df_folds['stratify_group']": 65,
      "train['target']": 64,
      "X_train['AdoptionSpeed'].values": 58,
      "labels": 47,
      "self.train_df[self.target]": 46,
      "reduce_train[target]": 44,
      "train.sentiment.values": 43,
      "bins": 38,
      "train2p['target']": 32,
      "Y_train": 31,
      "X_train['interest_level'].ravel()": 29,
      "data.bins.values": 28,
      "train_df['target']": 25,
      "train_all['ebird_code']": 24,
      "train_labels": 21,
      "y.values": 21,
      "train['outliers'].values": 21,
      "train_df.sentiment.values": 20,
      "all_df[TARGET]": 19,
      "train['building_id']": 19,
      "train.target": 18,
      "ytrain": 18,
      "train.target.values": 17,
      "label": 17,
      "df_train['target']": 16,
      "folds[CFG.target_col]": 15,
      "train_df['label']": 15,
      "groups": 15,
      "train_df.target.values": 13,
      "y_map": 13,
      "cl": 12,
      "Y.values": 12,
      "targets": 11,
      "train_target": 11,
      "train.iloc[:, -1]": 11,
      "df_train['outliers'].values": 11,
      "train['Survived']": 11,
      "train['label']": 10,
      "table.species_id": 10,
      "train_label": 10,
      "train_df['group_target']": 10,
      "df_train['label']": 9,
      "score": 9,
      "train['test_patient'].astype(int)": 9,
      "aptos2019_labels": 9,
      "df.label": 9,
      "y_train['surface']": 8,
      "label_list": 8,
      "df.label.values": 8,
      "df.isup_grade": 8,
      "train_df['isup_grade']": 8,
      "folds['InChI_length']": 8,
      "target_train": 8,
      "Ytrain_strat": 8,
      "Ytrain": 8,
      "year_month": 8,
      "train.label_idx": 7,
      "target['surface'].values": 7,
      "df['label']": 7,
      "train['SN_filter']": 7,
      "train_df['target'].values": 7,
      "y_train.values": 7,
      "train_df.coverage_class.values": 7,
      "data.loc[:, 'path']": 7,
      "y_train_full": 6,
      "sources": 6,
      "y_df": 6,
      "df_target": 6,
      "y_categorized": 6,
      "df.bin": 6,
      "train[CFG.target_col]": 6,
      "train_Y": 6,
      "df.label_id.values": 6,
      "target['surface']": 6,
      "train_targets": 6,
      "data[target]": 6,
      "train_df.isFraud.values": 6,
      "y.sample(frac=0.05)": 6,
      "train_new['target']": 6,
      "df['target']": 5,
      "X_train['interest_level']": 5,
      "data['bins'].values": 5,
      "train_df.sentiment": 5,
      "data_df.bins.values": 5,
      "df.bins.values": 5,
      "pre_train[target]": 5,
      "train_df.label.values": 5,
      "dataset.target": 5,
      "y_trainAll": 5,
      "folds[CFG['target_col']]": 5,
      "new_cat": 5,
      "train_df['outliers'].values": 4,
      "train[target]": 4,
      "target_data": 4,
      "train_data.target": 4,
      "y_": 4,
      "train_df_2019['label']": 4,
      "train_df.target": 4,
      "train3['target']": 4,
      "train_df['Character Count']": 4,
      "data.loc[infold, target]": 4,
      "df_train['isup_grade']": 4,
      "train['any'].values": 4,
      "self.y": 4,
      "df.target.values": 4,
      "train_data['target']": 4,
      "df_train.grapheme": 4,
      "y.astype(int)": 4,
      "folds['label']": 4,
      "X['keyword']": 4,
      "train2_y": 4,
      "df_labels": 3,
      "train.AdoptionSpeed": 3,
      "df.sentiment.values": 3,
      "self.df['label']": 3,
      "y_out": 3,
      "df['has_mask']": 3,
      "label_df": 3,
      "train_df['AdoptionSpeed']": 3,
      "id_mask_count['count']": 3,
      "train_df['interest_level']": 3,
      "train[label_column]": 3,
      "train_df['Survived']": 3,
      "df['building_id']": 3,
      "train.interest_level": 3,
      "df_benign.id.values": 3,
      "train['primary_label']": 3,
      "train_df.coverage_class": 3,
      "y_data['bin_age_7'].values": 3,
      "y_train_oof.values": 3,
      "y_all3": 3,
      "train['label_group']": 3,
      "train_per_patient_char['key']": 3,
      "ydat": 3,
      "train['isup_grade']": 3,
      "folds.target": 3,
      "target2": 3,
      "X_train.date_bin": 3,
      "labelsDB": 3,
      "train_df_site['building_id']": 3,
      "t": 3,
      "train.bin": 3,
      "X1['tm_hour_of_day']": 3,
      "Y_TRAIN": 3,
      "train[ycol]": 3,
      "TARGET": 3,
      "new_train['target']": 3,
      "X['building_id']": 3,
      "df_train['class'].values": 3,
      "encodeTrainLabels": 2,
      "train_data.target.values": 2,
      "train['sentiment']": 2,
      "y_split[:, 0]": 2,
      "train_y_raw": 2,
      "trn_df.target.values": 2,
      "df_train_tp.species_id.values": 2,
      "train_data['sentiment']": 2,
      "df.label_group": 2,
      "avreal": 2,
      "y0": 2,
      "cupy.asnumpy(train[target].values)": 2,
      "y['surface'].values": 2,
      "data['Sentiment']": 2,
      "y.argmax(1)": 2,
      "raw_train.target": 2,
      "X[self.targetName]": 2,
      "y_resampled": 2,
      "ys_train.numpy()": 2,
      "train_df['diagnosis']": 2,
      "gmm_label[:X_train.shape[0]]": 2,
      "train_targets[target]": 2,
      "original_labels": 2,
      "np.argmax(y_train, axis=1)": 2,
      "processed_train_labels_df['source']": 2,
      "df[label_column]": 2,
      "train_set['label_strat']": 2,
      "df.target": 2,
      "df['sentiment']": 2,
      "pivot_df['any'].values": 2,
      "X[target]": 2,
      "df_train.diagnosis": 2,
      "y_train_one_hot.argmax(1)": 2,
      "df_clean['y_cat']": 2,
      "df_noisy['y_cat']": 2,
      "train['defects']": 2,
      "sentiment": 2,
      "radboud_csv.isup_grade": 2,
      "karolinska_csv.isup_grade": 2,
      "train_df['target_num']": 2,
      "df_train.target.values": 2,
      "df_label.train": 2,
      "is_fold_train.target": 2,
      "train_labels.argmax(1)": 2,
      "train_labels['target']": 2,
      "y.values.astype(int)": 2,
      "answer": 2,
      "y_train['surface'].values": 2,
      "df_train['diagnosis']": 2,
      "ptrain_add['target']": 2,
      "df['is_test']": 2,
      "self.df['labels']": 2,
      "y_trn": 2,
      "stack_train_target": 2,
      "data_y": 2,
      "y_strat": 2,
      "df['defects']": 2,
      "df.diagnosis.values": 2,
      "split[0]['open_channels']": 2,
      "label_df.label.values": 2,
      "traincsv.label.values": 2,
      "dummy": 2,
      "user_ID['class']": 2,
      "train['TARGET'].values": 2,
      "y_clf": 2,
      "df[var_stratified]": 2,
      "LABELS": 2,
      "train_data.bins": 2,
      "trn2['target']": 2,
      "train_target.TARGET": 2,
      "df.Group": 2,
      "fe_train.Choice.values": 2,
      "np.array(train_lbls)": 2,
      "df_train.language_label": 2,
      "reduce_train['accuracy_group']": 2,
      "train_data['building_id']": 2,
      "stacked_df['target']": 2,
      "[''] * len(files)": 2,
      "train_df['open_channels']": 2,
      "perm_target": 2,
      "Y_data": 2,
      "train1['target']": 2,
      "df_train['target'].values": 2,
      "train_df['RFMScore'].values": 2,
      "df_folds[config['DATA']['TARGET_COL_NAME']]": 2,
      "tr[target_col]": 2,
      "dfx.label.values": 2,
      "train_full_df['ebird_code']": 2,
      "train_df['month']": 2,
      "av_data['target']": 2,
      "labels.values": 2,
      "train_target.values": 2,
      "label1": 2,
      "label2": 2,
      "df.sentiment": 2,
      "train['bins_target']": 2,
      "data_tr['target_bins']": 2,
      "_t": 2,
      "y.to_array()": 2,
      "df['ebird_code']": 2,
      "Y_split": 2,
      "train_kf_label": 2,
      "folds[target_col]": 2,
      "folds[Conf.target_col]": 2,
      "y_tr": 2,
      "data['bins'].tolist()": 2,
      "train_study.label.values": 2,
      "y_train_5": 2,
      "y_target": 2,
      "y_trian": 1,
      "y_train.set_index('object_id')": 1,
      "target_": 1,
      "y_all[:samp_size]": 1,
      "folds['has_mask']": 1,
      "train_df[dep_var]": 1,
      "data.toxic.values": 1,
      "P.group": 1,
      "trainTarget": 1,
      "data[TARGET]": 1,
      "combination_label_target": 1,
      "train_labels_balanced": 1,
      "external_train.target.values": 1,
      "traindf['any'].values": 1,
      "df[target].values": 1,
      "ytrain['target']": 1,
      "df_train_preprocess['meter']": 1,
      "lit_data['bins'].values": 1,
      "target_df['surface']": 1,
      "train[TARGET_COL]": 1,
      "train['AdoptionSpeed'].values": 1,
      "train_set.target": 1,
      "target_clean": 1,
      "y_a": 1,
      "y['surface']": 1,
      "application_train['TARGET']": 1,
      "cv_lbls": 1,
      "train3[dep_var]": 1,
      "train3[dep_var].values": 1,
      "df['study_level']": 1,
      "train_dataset.df.sentiment.values": 1,
      "resnet50_feature_train['target']": 1,
      "train3p['target']": 1,
      "X['target']": 1,
      "train_data['label']": 1,
      "rescuer_as_mean.astype(np.int)": 1,
      "X_train['AdoptionSpeed'].astype(np.int)": 1,
      "train_df['labels']": 1,
      "data.label.values": 1,
      "df_train_scores['age_bins']": 1,
      "known": 1,
      "df_train['HasDetections']": 1,
      "y_train[:, 0]": 1,
      "y_train_data": 1,
      "label_tr": 1,
      "train_std_df['target']": 1,
      "y_dummy": 1,
      "stratified_kfold_ytrain": 1,
      "split_idx": 1,
      "train_cls": 1,
      "folds['labels']": 1,
      "data[data['type'].notnull()]['type']": 1,
      "loaded_dfs['label_strat']": 1,
      "df.category_id": 1,
      "train[target_col]": 1,
      "train.lang_label.values": 1,
      "train2_pse['target']": 1,
      "train_agg['feature_1']": 1,
      "Ytrain.values": 1,
      "train_full_df['type']": 1,
      "Initial": 1,
      "self.train_data['path']": 1,
      "dfx.sentiment.values": 1,
      "train['ebird_code']": 1,
      "tp_label_list": 1,
      "combine['Survived']": 1,
      "buildings": 1,
      "y_for_split": 1,
      "train.labels": 1,
      "train_df['sentiment']": 1,
      "self.split_target": 1,
      "grouped_df_all['quality_factor'].values": 1,
      "dataset['source'].values": 1,
      "full_train_df['building_id']": 1,
      "df_y": 1,
      "train[dependent_feat]": 1,
      "newY_train": 1,
      "y3_train": 1,
      "y1": 1,
      "cl_target": 1,
      "data.loc[:, 'site']": 1,
      "df_joint[:nrows][target_col]": 1,
      "cY_train.argmax(axis=1)": 1,
      "train_data['type']": 1,
      "local_y_train": 1,
      "df_train.label.values": 1,
      "new_train['Survived']": 1,
      "train2['Survived']": 1,
      "train_df['num_target']": 1,
      "pca_tr_df['num_target']": 1,
      "target_counts": 1,
      "Y_train.values": 1,
      "data.target.values": 1,
      "train_label.iloc[idx_train_other]": 1,
      "model01_lgb_X_train['model']": 1,
      "model01_xgb_X_train['model']": 1,
      "model01_cb_X_train['model']": 1,
      "model012_lgb_X_train['model']": 1,
      "model012_xgb_X_train['model']": 1,
      "model012_cb_X_train['model']": 1,
      "model0123_lgb_X_train['model']": 1,
      "model0123_xgb_X_train['model']": 1,
      "model0123_cb_X_train['model']": 1,
      "model01234_lgb_X_train['model']": 1,
      "model01234_cb_X_train['model']": 1,
      "cl_y": 1,
      "df.diagnosis": 1,
      "Y_t": 1,
      "up": 1,
      "df_train.isup_grade": 1,
      "train_yS": 1,
      "train_dataset.grapheme": 1,
      "yaux": 1,
      "train_final_df['building_id']": 1,
      "train[CFG['target']]": 1,
      "self.labels": 1,
      "df_stra['stratify']": 1,
      "mini_train['target']": 1,
      "ytrain1": 1,
      "target_df": 1,
      "train4.iloc[:, -1]": 1,
      "df_folds.bbox_count": 1,
      "x['feature_1']": 1,
      "train_df['bin_target']": 1,
      "train.labels.values": 1,
      "data[feature_name]": 1,
      "ID": 1,
      "layer2_df[target]": 1,
      "Ytr_more": 1,
      "patient_df['SS']": 1,
      "X_train_drop['AdoptionSpeed']": 1,
      "rescuer_ids['count'].values": 1,
      "train.hotel_id.values": 1,
      "np.array([np.argmax(row) for row in y])": 1,
      "y_stacked": 1,
      "train[idx_tr]['target']": 1,
      "data['readability']": 1,
      "data['bins']": 1,
      "all_df['is_train']": 1,
      "list(self.train.target)": 1,
      "y_cut": 1,
      "ydat[:, 0]": 1,
      "target['bins']": 1,
      "train['label'].values": 1,
      "y_exam": 1,
      "df['age_bins']": 1,
      "data_dict['train_labels']": 1,
      "all_labels": 1,
      "y_train_9": 1,
      "train_data.label": 1,
      "train_label.values": 1,
      "split_groups": 1,
      "train['TARGET']": 1,
      "yards_label": 1,
      "train[lab].values": 1,
      "train_df['delta'].values": 1,
      "np.argmax(Y, axis=1)": 1,
      "patient_only_train['target']": 1,
      "source_Y": 1,
      "df['target'].to_numpy()": 1,
      "Y_tr": 1,
      "df_small['target'].values": 1,
      "datay": 1,
      "y_valid_train": 1,
      "target2.values": 1,
      "y_val_lang": 1,
      "trn2['tgt']": 1,
      "trn2_add['tgt']": 1,
      "y_valid": 1,
      "train_labels.argmax(-1)": 1,
      "df_train.sentiment.values": 1,
      "train_data['outliers'].values": 1,
      "trn_y_zeros": 1,
      "cv_targets": 1,
      "df['target_bin_label'].astype(int)": 1,
      "train_df.Choice.values": 1,
      "data['class_name']": 1,
      "folds.label": 1,
      "train['bins'].values": 1,
      "annotations['label'].values": 1,
      "train_df.label": 1,
      "target_train.values": 1,
      "source['diagnosis']": 1,
      "X['Sex']": 1,
      "external_train_df['target']": 1,
      "train_df_bal.label": 1,
      "train_df.language_label": 1,
      "train_pd['diagnosis']": 1,
      "train_csv.isup_grade.values": 1,
      "trn_l1_y": 1,
      "full_meta['is_train']": 1,
      "data.iloc[:, 0]": 1,
      "df_train_single[labels].values.argmax(axis=1)": 1,
      "reduced_label": 1,
      "y_data": 1,
      "xyw['floor']": 1,
      "labs": 1,
      "train_data[target_col]": 1,
      "train_df['target_relabeled']": 1,
      "test.sentiment.values": 1,
      "data_df['target']": 1,
      "df_all['labels']": 1,
      "train_df2['target']": 1,
      "train_label_ids": 1,
      "valid_df['toxic'].values": 1,
      "df_folds.integer_label": 1,
      "train_df['label'].values": 1,
      "train_df.iloc[:, -1]": 1,
      "data_train['target']": 1,
      "train['Target']": 1,
      "train2['Target']": 1,
      "cs_df['most_cs_same_target']": 1,
      "train_df['feature_comb_index'].values": 1,
      "train_df['category_month_lag'].values": 1,
      "self.training_data['target']": 1,
      "train_list['label']": 1,
      "df_folds[config.class_col_name]": 1,
      "tr['target']": 1,
      "yTrain['label']": 1,
      "train_y_all": 1,
      "train_df['sentiment'].values": 1,
      "df.open_channels.values": 1,
      "_y": 1,
      "train_df_vs['label']": 1,
      "av_data[target]": 1,
      "y1_train": 1,
      "train_df['ebird_code']": 1,
      "train_label_df": 1,
      "X1['target']": 1,
      "y_train_input": 1,
      "x_train.sentiment.values": 1,
      "y_binary": 1,
      "Y_tra['surface'].values": 1,
      "dataset_year": 1,
      "data_ffm.loc[data_ffm['dataset'] == 'Train', 'release_year']": 1,
      "train_data['release_year']": 1,
      "train['target'].values": 1,
      "folds['target']": 1,
      "df.is_duplicate.values": 1,
      "train_folds_df[CFG.target_col]": 1,
      "new_df.target.values": 1,
      "original_ytrain": 1,
      "df_train['TARGET']": 1,
      "valid.lang.values": 1,
      "tmp_labels": 1,
      "train['PatientID'].values": 1,
      "in_outlier_all": 1,
      "training_set.sentiment.values": 1,
      "X_train[target]": 1,
      "train.label": 1,
      "sizes": 1,
      "data.label": 1,
      "y_true": 1,
      "df_train['isFraud']": 1,
      "train_projected['target']": 1,
      "y_train_sm": 1,
      "scores.stratify": 1,
      "Strain": 1,
      "df['Target']": 1,
      "train_y_smoted": 1,
      "target_s": 1,
      "target_s.values": 1,
      "train_df['HasDetections']": 1,
      "df_RFE['QuoteConversion_Flag']": 1,
      "df_train_[target]": 1,
      "Y_Train": 1,
      "train['bins-target'].values": 1,
      "train_df['rebuild_target']": 1,
      "train_df['keyword']": 1,
      "train_df['stock_id']": 1,
      "primary_labels": 1,
      "crossvalidation_df['target_bin']": 1,
      "train_df.level_1": 1,
      "train_df.isup_grade": 1,
      "train_data.sentiment.values": 1,
      "train_df_2020.label": 1,
      "train['Sex_female']": 1,
      "new_train['accuracy_group']": 1,
      "np.argmax(y, axis=1)": 1,
      "df_train['sentiment']": 1,
      "df_train.label": 1,
      "target[class_name].values": 1,
      "train_df.isFraud": 1,
      "train.query('date>150')['action']": 1,
      "train_preprocessed['Survived'].values": 1,
      "train_preprocessed['target'].values": 1,
      "train_all['primary_label']": 1,
      "df_train['ebird_code']": 1,
      "df[TARGET_COL]": 1,
      "train.action": 1,
      "retrain.label.values": 1,
      "train['language']": 1,
      "train2['target'].to_array()": 1,
      "combined[target_col].values": 1,
      "y_resamp_tr": 1,
      "df_train['labels']": 1,
      "input_df['allMissing']": 1,
      "tgt": 1,
      "train_data.iloc[:, -1]": 1,
      "raw_train_data['sentiment']": 1,
      "np.zeros(unique_train_patients.shape[0])": 1,
      "samples_df.label": 1,
      "train[final_stratify_col]": 1,
      "train.isup_grade.values": 1,
      "train_c['target']": 1,
      "data['TARGET']": 1,
      "label['surface'].values": 1,
      "np.zeros(shape=(labels_train.shape[0], 1))": 1,
      "SN_filter_mask": 1,
      "training_targets": 1,
      "df_new['labels']": 1,
      "targetc": 1,
      "target_C_public": 1,
      "target_C": 1,
      "target_F_public": 1,
      "target_F": 1,
      "train['AdoptionSpeed']": 1,
      "train_data[target_col].values": 1,
      "train_data['AdoptionSpeed']": 1,
      "y_train1": 1,
      "stratify": 1,
      "target_binary": 1,
      "train_labels[k].values": 1,
      "df_train['label_group']": 1,
      "X.Target": 1,
      "train_yc": 1,
      "train_yf": 1,
      "train_tab.species_id.values": 1
    },
    "sklearn.metrics._classification.cohen_kappa_score.weights": {
      "'quadratic'": 935,
      "None": 137
    },
    "sklearn.metrics._classification.cohen_kappa_score.y1": {
      "y": 139,
      "y_true": 94,
      "y_val": 92,
      "y_test": 67,
      "reduce_train[target]": 39,
      "torch.round(y_hat)": 35,
      "y1": 34,
      "y_train": 29,
      "pred_val": 24,
      "labels": 22,
      "val_labels": 21,
      "torch.round(y_pred)": 20,
      "flatten(self.y_val)": 19,
      "y_hat": 18,
      "train_preds": 18,
      "y_ts": 15,
      "valid_df['diagnosis'].astype('int')": 14,
      "y_pred": 12,
      "t": 12,
      "preds": 12,
      "valid_y.numpy().astype(int)": 11,
      "true_labels": 10,
      "targets": 9,
      "pred_y1_rank": 9,
      "train_labels": 8,
      "test_y": 7,
      "y_actual": 6,
      "np.argmax(y_true, axis=1)": 5,
      "pred": 5,
      "train_predictions": 5,
      "torch.argmax(y_hat, 1)": 5,
      "actual": 5,
      "y_test_pred": 5,
      "gt": 4,
      "Y_test": 4,
      "self.bincut(coef, X)": 4,
      "self.y_val": 4,
      "Y_val": 4,
      "y_val_act": 4,
      "y_valid": 4,
      "PREDS": 4,
      "PREDS[df_valid['data_provider'] == 'karolinska']": 4,
      "PREDS[df_valid['data_provider'] == 'radboud']": 4,
      "y_real": 4,
      "y_vl": 3,
      "validation_preds": 3,
      "y_test.values": 3,
      "y_train.values": 3,
      "validation_predictions": 3,
      "val_preds_df['diagnosis']": 3,
      "X_p": 3,
      "rounder(preds)": 3,
      "all_targets": 3,
      "train_df['accuracy_group']": 3,
      "f_pred": 3,
      "df_gt_simulated": 3,
      "valid_labels": 2,
      "df['y']": 2,
      "train_pred.argmax(axis=1)": 2,
      "valid_pred.argmax(axis=1)": 2,
      "test_labels": 2,
      "val_y": 2,
      "preds_list": 2,
      "fold_val_label": 2,
      "val_labels.astype(np.uint8)": 2,
      "train_y": 2,
      "val_target.reshape(-1)": 2,
      "train_preds + validation_preds": 2,
      "y.cpu()": 2,
      "train.AdoptionSpeed.loc[valid_probs.index]": 2,
      "np.argmax(self.Y, axis=1)": 2,
      "targets_eval": 2,
      "gridoper.predict(X_attributes)": 2,
      "_targs": 2,
      "y_val_pred": 2,
      "oofPred": 2,
      "X_train['AdoptionSpeed'].values": 2,
      "train[target][ind]": 2,
      "Y_valid": 2,
      "np.array(final_targets)": 2,
      "train['open_channels']": 2,
      "pre_train[target]": 2,
      "gt_labels": 2,
      "train_df['diagnosis'].astype('int')": 2,
      "y_test9": 2,
      "y_hat.argmax(dim=-1)": 2,
      "[np.argmax(x) for x in pred_results]": 2,
      "dummy_model.predict(df_val[features])": 2,
      "predictions": 2,
      "y['accuracy_group']": 2,
      "reg_df['predict']": 1,
      "oof": 1,
      "torch.argmax(y_pred, dim=-1)": 1,
      "yhat": 1,
      "df['c']": 1,
      "df_preds_train[c]": 1,
      "y_train[val_index]": 1,
      "X_test": 1,
      "train[label]": 1,
      "labels.astype(np.uint8)": 1,
      "train_labels.astype(np.uint8)": 1,
      "y_total": 1,
      "train['AdoptionSpeed']": 1,
      "yclass": 1,
      "Xcopy.loc[subset_bool, 'y']": 1,
      "y_loc": 1,
      "y_test_fold": 1,
      "np.append(train_preds, validation_preds)": 1,
      "torch.round(y_hat).cpu()": 1,
      "valid_fold[target]": 1,
      "Y_pred": 1,
      "val_label": 1,
      "torch.argmax(pred[..., :-1], dim=1).cpu().numpy()": 1,
      "test['AdoptionSpeed']": 1,
      "val_generator.classes": 1,
      "y_train[idx]": 1,
      "y_val.sum(axis=1) - 1": 1,
      "y.loc[valid_idx]": 1,
      "results.astype('int')": 1,
      "self.models[first]['model'].true": 1,
      "t1": 1,
      "all_preds": 1,
      "df.open_channels": 1,
      "xpred": 1,
      "mvalid": 1,
      "pred.argmax(1)": 1,
      "valid_predictions": 1,
      "final_pred": 1,
      "val_y.argmax(1).numpy()": 1,
      "flip.diagnosis": 1,
      "eff_b3_300_val_preds_flip.sort_values('id_code').diagnosis": 1,
      "train_labels.accuracy_group.values": 1,
      "np.round(a)": 1,
      "np.around(y_hat)": 1,
      "pred_labels": 1,
      "cv_targets": 1,
      "test_Y": 1,
      "train_predicted": 1,
      "y_test_sampled": 1,
      "expected_y": 1,
      "test['diagnosis'].astype(int)": 1,
      "np.array(targets_reduced.cpu())": 1,
      "np.array(targets_reduced)": 1,
      "reduce_train[target][ind]": 1,
      "rand_forest_gridsearch.predict(clean_df)": 1,
      "ground_truths": 1,
      "np.argmax(y_val, axis=1)": 1,
      "y_test10": 1,
      "y_test2": 1,
      "y_test1": 1,
      "y_test3": 1,
      "y_test4": 1,
      "y_test5": 1,
      "y_test6": 1,
      "y_test7": 1,
      "y_test8": 1,
      "y_val.argmax(axis=1)": 1,
      "optR.predict(y_pred_rank, coef=optR.coefficients())": 1,
      "optR.predict(y_eval_pred_rank, coef=optR.coefficients())": 1,
      "np.array(y_val)": 1,
      "target_validation": 1,
      "target_train": 1,
      "preds_valid": 1,
      "preds_valid_1": 1,
      "preds_valid_2": 1,
      "val_preds": 1,
      "df_train_[target]": 1,
      "val_target.argmax(axis=2).reshape(-1)": 1,
      "torch.round(y_pred.float())": 1,
      "results.iloc[:, 0]": 1,
      "a": 1,
      "np.round(train_pred)": 1,
      "np.round(val_pred)": 1,
      "final_preds": 1,
      "np.round(loss_kpre)": 1,
      "np.round(loss_rpre)": 1,
      "np.round(qwk_kpre)": 1,
      "np.round(qwk_rpre)": 1,
      "optqwk_kpre": 1,
      "optqwk_rpre": 1,
      "X_train_non_null['AdoptionSpeed']": 1,
      "groundtruths": 1,
      "ground_truth": 1,
      "torch.round(y_hat.type(torch.FloatTensor))": 1,
      "valid_y": 1,
      "self.y_true['train'][-1]": 1,
      "self.y_true['val'][-1]": 1,
      "original": 1
    },
    "sklearn.metrics._classification.cohen_kappa_score.y2": {
      "y_pred": 201,
      "y": 91,
      "X_p": 87,
      "preds": 54,
      "np.argmax(oof_pred, axis=1)": 35,
      "y2": 34,
      "y_test": 29,
      "flatten(y_pred)": 23,
      "y_val_pred": 17,
      "pred": 16,
      "val_y": 15,
      "y_pr": 15,
      "opt_val_predictions": 13,
      "train['diagnosis'].astype('int')": 12,
      "y_pred_train": 12,
      "y_pred_val": 12,
      "y_pred_test": 12,
      "y_pred6": 12,
      "pred_labels": 11,
      "valid_predictions": 11,
      "predicted": 11,
      "predictions": 11,
      "p": 10,
      "y_val_preds": 10,
      "pred_test_y_k": 10,
      "y_true": 9,
      "y_train_preds": 9,
      "y_pred.round()": 6,
      "Y_pred": 6,
      "target": 6,
      "valid_pred": 6,
      "prediction": 6,
      "val_target": 5,
      "targs": 5,
      "Y_train": 4,
      "oof_pred": 4,
      "y_hat": 4,
      "TARGETS": 4,
      "df_valid[df_valid['data_provider'] == 'karolinska'].isup_grade.values": 4,
      "df_valid[df_valid['data_provider'] == 'radboud'].isup_grade.values": 4,
      "y_predict": 4,
      "get_label(oof_pred)": 4,
      "y_train_pred_rf": 3,
      "y_pred_test_rf": 3,
      "y_pred_test_rf_val": 3,
      "y_val_pre2": 3,
      "train_meta_ints": 3,
      "train_labels": 3,
      "validation_labels": 3,
      "y_learned": 3,
      "validation_truth": 3,
      "val_preds_df['preds']": 3,
      "self.targs": 3,
      "df_pred_simulated": 3,
      "df[col]": 2,
      "train_target": 2,
      "np.argmax(y_pred, axis=1)": 2,
      "y_valid": 2,
      "df_preds_train['y']": 2,
      "targets_list": 2,
      "valid_p": 2,
      "train_predictions": 2,
      "np.round(pred, 0)": 2,
      "train_labels + validation_labels": 2,
      "pred_val_y_k": 2,
      "y_hat.cpu()": 2,
      "probs": 2,
      "valid_probs": 2,
      "np.argmax(pred, axis=1)": 2,
      "y_target": 2,
      "_preds": 2,
      "simple_blending_predictions": 2,
      "simple_blending_features_predictions": 2,
      "pred_to_int(all_preds)": 2,
      "eval_qwk_lgb_regr(oof_pred[ind], train)": 2,
      "np.array(final_outputs).argmax(axis=1)": 2,
      "train['signal_tr']": 2,
      "train_preds": 2,
      "Y_test": 2,
      "y_train_pred": 2,
      "y_pred9": 2,
      "label_valid_1": 2,
      "train_data.get_label()": 2,
      "df_val['AdoptionSpeed']": 2,
      "val_truth": 2,
      "test['diagnosis'].astype('int')": 2,
      "oof_opt_valid": 2,
      "knn_pred": 1,
      "knn9_pred": 1,
      "y_train": 1,
      "valid['label'][:20]": 1,
      "gt": 1,
      "train.diagnosis": 1,
      "predict": 1,
      "np.round(oof_preds[val_idx])": 1,
      "np.round(oof_preds)": 1,
      "fix_distribution(y_train[train_index], valid_preds)": 1,
      "fix_distribution(y_train, train_preds_nn_1.mean(axis=0))": 1,
      "fix_distribution(y_train, train_preds_nn_2.mean(axis=0))": 1,
      "fix_distribution(y_train, train_preds_nn_3.mean(axis=0))": 1,
      "fix_distribution(y_train, train_preds_lgb.mean(axis=0))": 1,
      "fix_distribution(y_train, train_preds_ffm.mean(axis=0))": 1,
      "train_df['diagnosis'].astype('int')": 1,
      "t_total": 1,
      "df_train_train['diagnosis'].astype('int')": 1,
      "df_train_test['diagnosis'].astype('int')": 1,
      "y_val_pre": 1,
      "yclasspred": 1,
      "yp": 1,
      "subset_yp": 1,
      "yp_loctest": 1,
      "get_pred_classes(y_pred_result)": 1,
      "np.append(train_labels, validation_labels)": 1,
      "y.cpu()": 1,
      "Y_val": 1,
      "val_prediction": 1,
      "y_final": 1,
      "y_test_k": 1,
      "tree.predict(val_fea)": 1,
      "y.cpu().numpy()": 1,
      "np.argmax(y_pred_1, axis=1)": 1,
      "np.argmax(y_pred_2, axis=1)": 1,
      "np.argmax(y_true, axis=1)": 1,
      "df_Predicciones['Resultado_Stacking']": 1,
      "fix_distribution(y_train[idx], train_preds_lgb[r, idx])": 1,
      "y_predicted": 1,
      "m.predict(train.iloc[valid_idx])": 1,
      "prediction1": 1,
      "all_targets": 1,
      "df.open_channels_pred": 1,
      "m.predict(X_train)": 1,
      "m.predict(X_valid)": 1,
      "y1": 1,
      "xtrain[['open_channels']]": 1,
      "y_val_true": 1,
      "y_val_pred_best_estimator": 1,
      "y_val_pred_voting_classifier": 1,
      "yValidLGBM": 1,
      "yValidXGB": 1,
      "full_labels": 1,
      "reduce_train['accuracy_group']": 1,
      "get_output_preds((val_preds > 0.5).numpy())": 1,
      "get_output_preds(val_preds_avg > 0.5)": 1,
      "get_output_preds(val_preds_avg > i)": 1,
      "np.argmax(val_preds, 1)": 1,
      "lr_prediction": 1,
      "np.round(b)": 1,
      "pred_y": 1,
      "true_labels": 1,
      "test_predictions": 1,
      "pred_to_int(cv_preds[valid_index])": 1,
      "pred_to_int(cv_preds)": 1,
      "yhat_classes": 1,
      "train_y": 1,
      "rounded_val_preds": 1,
      "df['diagnosis'].astype('int')": 1,
      "final_pred": 1,
      "pred_to_int(oof)": 1,
      "pred_to_int(oof_opt)": 1,
      "y_pred.astype(int)": 1,
      "list(tta_df['diagnosis'])": 1,
      "np.array(outputs_reduced.cpu()).argmax(axis=1)": 1,
      "np.array(outputs_reduced).argmax(axis=1)": 1,
      "eval_qwk_lgb_regr(oof_pred, reduce_train)": 1,
      "eval_qwk_lgb_regr(oof_pred[ind], reduce_train)": 1,
      "y_val": 1,
      "predictions_output": 1,
      "final": 1,
      "validation_generator.classes": 1,
      "np.argmax(y_score, axis=1)": 1,
      "train_new['diagnosis'].astype('int')": 1,
      "y_pred10": 1,
      "y_pred2": 1,
      "y_pred1": 1,
      "y_pred3": 1,
      "y_pred4": 1,
      "y_pred5": 1,
      "y_pred7": 1,
      "y_pred8": 1,
      "y_pred.argmax(axis=1)": 1,
      "y_eval_true": 1,
      "np.array(y_pred)": 1,
      "eval_qwk_lgb_regr(pred, y)": 1,
      "label_valid": 1,
      "val_targets": 1,
      "valid['label'][:200]": 1,
      "val_preds": 1,
      "results.iloc[:, 1]": 1,
      "train_truth": 1,
      "loss_ktru": 1,
      "loss_rtru": 1,
      "qwk_ktru": 1,
      "qwk_rtru": 1,
      "optqwk_ktru": 1,
      "optqwk_rtru": 1,
      "np.array(train_data.iloc[val_indices][label])": 1,
      "y.type(torch.FloatTensor)": 1,
      "y_holdout": 1,
      "self.y_pred['train'][-1]": 1,
      "self.y_pred['val'][-1]": 1,
      "pred[1]": 1,
      "cls.predict(X_train)": 1,
      "cls.predict(X_test)": 1
    },
    "sklearn.metrics._classification.f1_score.y_true": {
      "y_test": 676,
      "y_true": 291,
      "val_y": 287,
      "cm_correct_labels": 262,
      "y_train": 159,
      "y_val": 155,
      "y": 149,
      "yvalid": 141,
      "y_valid": 111,
      "labels": 50,
      "truth": 49,
      "ty": 45,
      "vy": 45,
      "oy": 45,
      "val.target": 40,
      "train_y": 36,
      "target": 34,
      "self.targets": 31,
      "test_y": 29,
      "y_pred": 27,
      "np.argmax(valid_y, axis=2).reshape(-1)": 24,
      "np.argmax(train_tr, axis=2).reshape(-1)": 24,
      "olid_test.toxic": 24,
      "olid_test1k.toxic": 24,
      "olid_test2k.toxic": 24,
      "olid_test5k.toxic": 24,
      "olid_test10k.toxic": 24,
      "ts_y": 24,
      "Y_train": 23,
      "val_labels": 17,
      "self.y_val": 17,
      "targets": 17,
      "Y_val": 16,
      "Y_test": 16,
      "global_y_true": 16,
      "validate['target']": 15,
      "self.y_train": 14,
      "tsiftdatay_test": 14,
      "pred": 12,
      "y_Val": 12,
      "test_Y": 12,
      "validate_y": 11,
      "val_targ": 11,
      "model_labels": 11,
      "y_cv": 11,
      "yval": 10,
      "y_test.argmax(axis=1)": 10,
      "test_labels": 10,
      "y_dev": 10,
      "ytest": 9,
      "correct_labels": 9,
      "preds": 9,
      "preds.cpu().data.numpy()": 9,
      "predictedVals": 9,
      "ttexty_test": 9,
      "valid_labels": 9,
      "epoch_predictions": 8,
      "to_np(y)": 8,
      "ttextdataemy_test": 8,
      "testY": 8,
      "true": 7,
      "yv": 7,
      "train_target": 7,
      "valid_y": 7,
      "model0_labels": 7,
      "model1_labels": 7,
      "model2_labels": 7,
      "model3_labels": 7,
      "y2": 7,
      "X_val['target']": 7,
      "pre_train[target]": 7,
      "train.open_channels": 7,
      "predict": 7,
      "testing_labels": 6,
      "Y": 6,
      "oof_df['open_channels']": 6,
      "y_true_test": 6,
      "quora_train.target.values": 6,
      "valid['target']": 6,
      "np.rint(y_val)": 6,
      "true_state": 6,
      "model4_labels": 6,
      "df['open_channels']": 6,
      "target.values": 6,
      "self.y_test": 5,
      "y[valid_index]": 5,
      "labels_hot": 5,
      "y_": 5,
      "y_test2": 5,
      "pred_tag": 5,
      "labels_flat": 5,
      "train_df.iloc[valid_idx][target].values": 5,
      "y_validation_set": 5,
      "predictions": 5,
      "dev_y": 5,
      "y_valid['target']": 5,
      "np.round(np.clip(oof_valid_lgb, 0, 10)).astype(int)": 5,
      "np.round(np.clip(oof_valid_xgb, 0, 10)).astype(int)": 5,
      "np.round(np.clip(oof_valid_cb, 0, 10)).astype(int)": 5,
      "gt": 4,
      "train_true.cpu().detach().numpy()": 4,
      "val_true.cpu().detach().numpy()": 4,
      "label": 4,
      "ground_truth": 4,
      "yhat": 4,
      "val_true": 4,
      "valid_generator.classes": 4,
      "y_sets[i]": 4,
      "oof_df.loc[oof_df.iloc[val_idx].index]['open_channels']": 4,
      "y_tes": 4,
      "targ": 4,
      "trues_train": 4,
      "trues_valid": 4,
      "ytrain": 4,
      "train_targets": 4,
      "val_target.argmax(axis=2).reshape(-1)": 4,
      "true_bio_labels": 4,
      "val_targets": 4,
      "y_mtest": 4,
      "FinalTrainLabels": 4,
      "FinalTestLabels": 4,
      "val_data.labels": 4,
      "Y_validate": 4,
      "y_test_label": 3,
      "train.target": 3,
      "valdiate_y": 3,
      "all_val_labels": 3,
      "Val_y": 3,
      "train['open_channels']": 3,
      "y_valid.reshape(-1)": 3,
      "long_labels + short_labels": 3,
      "long_labels": 3,
      "short_labels": 3,
      "validation_labels": 3,
      "y_train.values.astype(np.float)": 3,
      "true_state[ix]": 3,
      "y_train.iloc[val_idx].values": 3,
      "targs": 3,
      "y_batch": 3,
      "val_correct_labels": 3,
      "trainResponse": 3,
      "lastFullValLabels[:, i]": 3,
      "train_labels": 3,
      "preds.cpu().numpy()": 3,
      "target[df.Id.isin(ids1)]": 3,
      "target.cpu().data.numpy()": 3,
      "folds.loc[val_idx]['category_id'].values": 3,
      "y_batch_np": 3,
      "outputs": 3,
      "train[target]": 3,
      "y_train.values": 3,
      "val_generator.classes": 3,
      "predicted_df['predicted_values']": 2,
      "y_train_label": 2,
      "y_validation_label": 2,
      "y_true_train": 2,
      "fold_cv['actual']": 2,
      "cv['actual']": 2,
      "y_test[X_test['difficulty'] == difficulty]": 2,
      "y_le[valid_index]": 2,
      "pred1": 2,
      "pred2": 2,
      "pred3": 2,
      "y1": 2,
      "df_train['open_channels']": 2,
      "true_y": 2,
      "test_result": 2,
      "target.data.to('cpu')": 2,
      "y_val.cpu().numpy()": 2,
      "test_1_y_val": 2,
      "test_2_y_val": 2,
      "Y_valid": 2,
      "df.open_channels": 2,
      "cv_target": 2,
      "dev_targets.long().numpy()": 2,
      "TARGETS": 2,
      "y.cpu()": 2,
      "true_labels": 2,
      "train_preds": 2,
      "y[test]": 2,
      "y_true[:, i]": 2,
      "train['open_channels'].values": 2,
      "y_train.iloc[val_idx]": 2,
      "df.loc[df['site'] > 0, 'site']": 2,
      "v_y": 2,
      "oof['targets']": 2,
      "time_level_prediction['targets']": 2,
      "y_Test": 2,
      "y_validation": 2,
      "validate_labels": 2,
      "y_dev.values": 2,
      "train_ckwe['open_channels'].values": 2,
      "middle100['open_channels']": 2,
      "Holdy": 2,
      "oof_target": 2,
      "y_train_temp": 2,
      "y_test_temp": 2,
      "valid_dataset.targets": 2,
      "train_clean['open_channels']": 2,
      "test_set_y": 2,
      "preds.cpu()": 2,
      "np.array(results)": 2,
      "Y[test]": 2,
      "ycv": 2,
      "y[:5000000]": 2,
      "df.iloc[:5000000]['open_channels']": 2,
      "perfection.target": 2,
      "Y_Val": 2,
      "hot_labels.data.cpu().numpy()": 2,
      "all_labels.cpu()": 2,
      "tgts": 2,
      "true_ent_labels": 2,
      "y_new": 2,
      "y.iloc[val_idx].values": 2,
      "y_test3": 2,
      "y_test4": 2,
      "temp.open_channels": 2,
      "one": 2,
      "to_numpy(target)": 2,
      "y_val_down": 2,
      "np.concatenate((df1.open_channels, df2.open_channels))": 2,
      "target[val_idx]": 2,
      "(oof_prob > thresh_mean).astype(np.int)": 2,
      "prediction_cvalid": 2,
      "prediction_test": 2,
      "test_batches.labels": 2,
      "f_target": 2,
      "self.y": 2,
      "y_test9": 2,
      "val_df['target']": 2,
      "y_cv - 1": 2,
      "Y_test_": 2,
      "Ym_test": 2,
      "Ycv": 2,
      "pred[calc_idx[1]]": 2,
      "train.open_channels[batch_size * (batch - 1):batch_size * batch]": 2,
      "df_train.open_channels[batch_size * (batch - 1):batch_size * batch]": 2,
      "TRAIN.open_channels": 2,
      "y_val.values": 2,
      "clf_svc.predict(train_data.clip(0, 100000000))": 2,
      "np.argmax(val_y, axis=1)": 2,
      "np.argmax(train_y, axis=1)": 2,
      "d_test['label']": 2,
      "dftrain.open_channels": 2,
      "y_cat_train_dic[ii]": 2,
      "test_lab": 2,
      "list1": 2,
      "p": 1,
      "(y.isManPred >= best_idx / 100).astype(int)": 1,
      "test_generator.classes": 1,
      "test['Insult']": 1,
      "y_true_eval": 1,
      "y_true_val": 1,
      "y_train_dum": 1,
      "y_test_dum": 1,
      "[1, 0, 1]": 1,
      "ttt": 1,
      "fo['open_channels']": 1,
      "all_labels.values": 1,
      "label_list": 1,
      "pred4": 1,
      "y_batch_actual_np": 1,
      "train_actuals": 1,
      "val_actuals": 1,
      "sub['prediction']": 1,
      "train_open_channels": 1,
      "validY": 1,
      "target_test[:len(predictions)]": 1,
      "y_test[:len(predictions)]": 1,
      "VL": 1,
      "np.argmax(Y_val, axis=1)": 1,
      "y_out": 1,
      "y_train_val": 1,
      "data.y_val": 1,
      "te_labels": 1,
      "df_train['target']": 1,
      "LSTM_y_test": 1,
      "GRU_y_test": 1,
      "sepcnn_y_test": 1,
      "testy": 1,
      "test_x_y['labels'].to_numpy()": 1,
      "y_pred2_lr": 1,
      "y_pred2_lrcv": 1,
      "raw_train.target": 1,
      "test_pred": 1,
      "t[:data_count]": 1,
      "tr_true": 1,
      "origin_labels": 1,
      "targets[700:]": 1,
      "model.y_val": 1,
      "P > threshold": 1,
      "y_tst": 1,
      "val_preds_bool": 1,
      "goldSet_yTrue": 1,
      "Y_test_old": 1,
      "test": 1,
      "baseline_true": 1,
      "pure_target_for_f1_score": 1,
      "[0, 0, 1, 0, 0]": 1,
      "pred_survived": 1,
      "lr.predict(X_test_cv1)": 1,
      "knn.predict(X_test_cv1)": 1,
      "xgb.predict(X_test_cv1)": 1,
      "svm_model.predict(X_test_cv1)": 1,
      "randomforest.predict(X_test_cv1)": 1,
      "y_vldt": 1,
      "gold_train": 1,
      "titanic_labels": 1,
      "np.argmax(valid_y, axis=1)": 1,
      "fin_targets": 1,
      "lgb_y_train": 1,
      "model01_lgb_y_train.iloc[val_idx].values": 1,
      "model01_lgb_y_train": 1,
      "model01_xgb_y_train.iloc[val_idx].values": 1,
      "model01_xgb_y_train": 1,
      "model01_cb_y_train.iloc[val_idx].values": 1,
      "model01_cb_y_train": 1,
      "model012_lgb_y_train.iloc[val_idx].values": 1,
      "model012_lgb_y_train": 1,
      "model012_xgb_y_train.iloc[val_idx].values": 1,
      "model012_xgb_y_train": 1,
      "model012_cb_y_train.iloc[val_idx].values": 1,
      "model012_cb_y_train": 1,
      "model0123_lgb_y_train.iloc[val_idx].values": 1,
      "model0123_lgb_y_train": 1,
      "model0123_xgb_y_train.iloc[val_idx].values": 1,
      "model0123_xgb_y_train": 1,
      "model0123_cb_y_train.iloc[val_idx].values": 1,
      "model0123_cb_y_train": 1,
      "model01234_lgb_y_train.iloc[val_idx].values": 1,
      "model01234_lgb_y_train": 1,
      "model01234_cb_y_train.iloc[val_idx].values": 1,
      "model01234_cb_y_train": 1,
      "df_train[df_train['is_filtered'] == 0]['open_channels']": 1,
      "df_train.target.values": 1,
      "y_train[idxV]": 1,
      "y_test_cv": 1,
      "true_class": 1,
      "y_train_4": 1,
      "timagey_test.values": 1,
      "pre": 1,
      "y_training": 1,
      "result": 1,
      "labels.asnumpy()": 1,
      "predictions['actual']": 1,
      "yVal": 1,
      "stack_y_val": 1,
      "targets_va": 1,
      "targets_train": 1,
      "trainHResponse": 1,
      "long_answers2.values": 1,
      "y1[:, shift]": 1,
      "truths": 1,
      "y_actual": 1,
      "predictionsTR": 1,
      "predictionsTE": 1,
      "t['y_test']": 1,
      "np.concatenate(tests)": 1,
      "df.test": 1,
      "comps.test": 1,
      "y[good_id]": 1,
      "y_valid_sub": 1,
      "fake_test['target']": 1,
      "Ytest": 1,
      "train_df.open_channels": 1,
      "(train_df.open_channels == oc).astype(int)": 1,
      "target[df.Id.isin(test2.Id)]": 1,
      "target[~df.Id.isin(test2.Id)]": 1,
      "class_labels": 1,
      "y_t": 1,
      "valid_truth": 1,
      "target_array.values": 1,
      "val_preds": 1,
      "pred_temp": 1,
      "proba_tr.pred": 1,
      "y_true[:batch_size]": 1,
      "sample_label": 1,
      "res[1]": 1,
      "train_df_all.outliers": 1,
      "y_val[:, j]": 1,
      "rm_correct_labels": 1,
      "y1_pred": 1,
      "pipe3_pred": 1,
      "y2_pred": 1,
      "eclfY": 1,
      "df['open_channels'].iloc[:5000000]": 1,
      "train_logistic_pred": 1,
      "valid_logistic_pred": 1,
      "pred_nval_y": 1,
      "pred_glove_val_y": 1,
      "y_ts": 1,
      "cm_correct_labelsall": 1,
      "cm_correct_labels_n": 1,
      "test_target": 1,
      "y_pred_rfc": 1,
      "y_pred_dec_tree": 1,
      "y_pred_logreg": 1,
      "ypred_Logreg": 1,
      "ypred_rfc": 1,
      "ypred_naive": 1,
      "set_validacion_ordenado.classes": 1,
      "test['isup_grade']": 1,
      "test_label": 1,
      "y_train_": 1,
      "y_test_lr": 1,
      "y_test_rf": 1,
      "y_test_dt1": 1,
      "y_test_dt2": 1,
      "y_test_xg1": 1,
      "y_test_xg2": 1,
      "val['target']": 1,
      "oofs.open_channels.drop(train_df.loc[3642932:3822753].index)": 1,
      "train_ann['CorrectString'].values": 1,
      "pred_df['CorrectString'].fillna('').values": 1,
      "y['target']": 1,
      "y_test['target']": 1,
      "y_test_": 1,
      "results_dataframe['target']": 1,
      "np.argmax(train_target[val_idx].reshape(-1, NUM_CLASSES), axis=1)": 1,
      "binarizer.transform(y_true)": 1,
      "y_train_c": 1,
      "y_test_c": 1,
      "Y_Train.flatten()": 1,
      "Dev_Y.flatten()": 1,
      "label_val_split": 1,
      "actuals": 1,
      "y_validate": 1,
      "y_train_valid": 1,
      "y_train_valid.values": 1,
      "ytrue": 1,
      "z": 1,
      "pred_df['CorrectString'].values": 1,
      "actual_labels": 1,
      "y_preds": 1,
      "trans_class": 1,
      "test_targets": 1,
      "np.argmax(np.array(y_true), axis=1)": 1,
      "y_test10": 1,
      "y_test1": 1,
      "y_test5": 1,
      "y_test6": 1,
      "y_test7": 1,
      "y_test8": 1,
      "mnist_labels": 1,
      "results['y_val']": 1,
      "clf.predict(vX)": 1,
      "lb": 1,
      "np.round(np.clip(valid_predict_LGBM, 0, 10)).astype(int)": 1,
      "np.round(np.clip(valid_predict_XGB, 0, 10)).astype(int)": 1,
      "np.round(np.clip(valid_predict_CAT, 0, 10)).astype(int)": 1,
      "np.round(np.clip(Ensemble_predict, 0, 10)).astype(int)": 1,
      "y_test_fold": 1,
      "d['target']": 1,
      "train_predicted": 1,
      "state_train": 1,
      "state": 1,
      "train0.open_channels": 1,
      "train1.open_channels": 1,
      "train2.open_channels": 1,
      "train.open_channels.values": 1,
      "train0.open_channels.values": 1,
      "temp_df.open_channels": 1,
      "svm.predict(X_test)": 1,
      "truth_class": 1,
      "model.predict(train_df)": 1,
      "np.array(train_orig)": 1,
      "np.array(vo)": 1,
      "self.Y": 1,
      "Y_test.reshape(-1)": 1,
      "preds_val[:, i] > th": 1,
      "np.round(clf_svr.predict(train_data.clip(0, 100000000)))": 1,
      "np.round(clf_svr.predict(train_data.clip(0, 100000000))).clip(1, 4)": 1,
      "train_true_list": 1,
      "valid_true_list": 1,
      "y_tr": 1,
      "y_te": 1,
      "y_chk_treated": 1,
      "validation_y": 1,
      "y_true > hp.border": 1,
      "prediction": 1,
      "cm_labels": 1,
      "valid_label": 1,
      "y_cat_train_dic[idx]": 1,
      "y_val2": 1,
      "xgb.predict(X_test)": 1,
      "catb.predict(X_test)": 1,
      "validation": 1,
      "train_predictions": 1,
      "current_y_val": 1,
      "y_val_stacking": 1,
      "y_is9_validation": 1,
      "X.Target": 1,
      "y.iloc[test_idx_3]": 1,
      "true_value": 1,
      "Y_validation": 1
    },
    "sklearn.metrics._classification.f1_score.y_pred": {
      "y_pred": 382,
      "cm_predictions": 260,
      "predictions": 205,
      "y_proba > threshold": 142,
      "pred": 138,
      "(pred_val_y > thresh).astype(int)": 107,
      "preds": 89,
      "y_test": 70,
      "(pred_glove_val_y > thresh).astype(int)": 48,
      "np.array(train_preds) > tmp[0]": 40,
      "vc.predict(X_test)": 36,
      "pred_labels": 32,
      "p > p_th": 32,
      "pred > th": 30,
      "(pred_fasttext_val_y > thresh).astype(int)": 28,
      "(pred_noemb_val_y > thresh).astype(int)": 28,
      "(pred_paragram_val_y > thresh).astype(int)": 26,
      "y_pred_train": 25,
      "y_pred_class": 25,
      "np.argmax(oof_, axis=1)": 24,
      "olid_test.toxic_predict_binary": 24,
      "olid_test1k.toxic_predict_binary": 24,
      "olid_test2k.toxic_predict_binary": 24,
      "olid_test5k.toxic_predict_binary": 24,
      "olid_test10k.toxic_predict_binary": 24,
      "ts_p": 24,
      "y_pred_test": 23,
      "np.argmax(preds_f, axis=2).reshape(-1)": 23,
      "train_predictions": 23,
      "val_predictions": 22,
      "prediction": 19,
      "clf_final.predict(X_test)": 19,
      "classes": 18,
      "validate_pred": 15,
      "test_predictions": 15,
      "np.array(y2)": 15,
      "y_pred_val": 14,
      "y_predict": 13,
      "predicted": 12,
      "y_preds": 12,
      "val_predict": 12,
      "y_val": 12,
      "(y_pred > thresh).astype(int)": 12,
      "y_pred6": 12,
      "y_pred1": 11,
      "test_y": 11,
      "(pred > thresh).astype(int)": 10,
      "(pred_val_y > 0.33).astype(int)": 10,
      "train_oof_preds": 10,
      "vc2.predict(X_test.drop(et_drop_cols, axis=1))": 10,
      "y_pred_cat": 9,
      "y_hat.argmax(axis=1)": 9,
      "Y_pred_rand": 9,
      "labels.cpu().data.numpy()": 9,
      "validVals": 9,
      "X_p": 9,
      "(pred_cnn_val_y > thresh).astype(int)": 9,
      "y_val_pred": 9,
      "y_predicted": 9,
      "pred_train": 9,
      "val_pred": 9,
      "combo_preds": 9,
      "valid_pred": 8,
      "y_train_pred": 8,
      "np.argmax(p, axis=1)": 8,
      "y_pred_valid": 8,
      "epoch_targets": 8,
      "oof_pred": 8,
      "(google_y_pre > thresh).astype(int)": 8,
      "(pred_test_y > thresh).astype(int)": 7,
      "train_pred": 7,
      "(y_pre > thresh).astype(int)": 7,
      "valid_preds": 7,
      "Y_pred": 7,
      "pred1": 6,
      "pred_class": 6,
      "y_test_pred": 6,
      "predicted_class": 6,
      "train_preds": 6,
      "val_preds": 6,
      "oof_df['oof']": 6,
      "(y_prob_test >= best_threshold).astype(int)": 6,
      "valid['prediction']": 6,
      "np.rint(predicted_labels)": 6,
      "viterbi_state": 6,
      "pred > 0.5": 6,
      "y_hat": 6,
      "np.argmax(train_preds.values, axis=1)": 6,
      "y_prediction": 6,
      "ypred_class": 5,
      "preds_hot": 5,
      "validate_y_pred": 5,
      "pred4": 5,
      "pred_y": 5,
      "predict": 5,
      "test_pred": 5,
      "y_pred2": 5,
      "yhat": 5,
      "predicted_labels": 5,
      "train_meta > 0.33": 5,
      "Clf1.predict(X)": 5,
      "Clf2.predict(X)": 5,
      "Clf1.predict(X_test)": 5,
      "Clf2.predict(X_test)": 5,
      "y_pred.round()": 5,
      "preds_valid": 5,
      "predictcombine": 5,
      "predict_t": 5,
      "predicts": 5,
      "oof[valid_idx].round()": 5,
      "y_valid": 5,
      "y_pred_lstm": 5,
      "tp > 0.1": 5,
      "tp > 0.2": 5,
      "tp > 0.3": 5,
      "tp > 0.4": 5,
      "tp > 0.5": 5,
      "tp > 0.6": 5,
      "tp > 0.7": 5,
      "tp > 0.8": 5,
      "tp > 0.9": 5,
      "vp > 0.1": 5,
      "vp > 0.2": 5,
      "vp > 0.3": 5,
      "vp > 0.4": 5,
      "vp > 0.5": 5,
      "vp > 0.6": 5,
      "vp > 0.7": 5,
      "vp > 0.8": 5,
      "vp > 0.9": 5,
      "op > 0.1": 5,
      "op > 0.2": 5,
      "op > 0.3": 5,
      "op > 0.4": 5,
      "op > 0.5": 5,
      "op > 0.6": 5,
      "op > 0.7": 5,
      "op > 0.8": 5,
      "op > 0.9": 5,
      "lgb_clf.predict(X_val)": 4,
      "train_preds.cpu().detach().numpy().argmax(1)": 4,
      "val_preds.cpu().detach().numpy().argmax(1)": 4,
      "predict_val": 4,
      "y_true": 4,
      "(pred_val > thresh).astype(int)": 4,
      "train_y_pred": 4,
      "pred > 0.0": 4,
      "xv > th_i": 4,
      "estimator.predict(X_train)": 4,
      "(pred_y > thresh).astype(int)": 4,
      "(val_preds > threshold).astype(int)": 4,
      "Y_valid": 4,
      "oof_df.loc[oof_df.iloc[val_idx].index]['oof']": 4,
      "np.round(np.clip(lgb_oof, y_true.min(), y_true.max()))": 4,
      "np.round(np.clip(xgb_oof, y_true.min(), y_true.max()))": 4,
      "np.round(np.clip(cb_oof, y_true.min(), y_true.max()))": 4,
      "np.round(np.clip(equal_blend_oof, y_true.min(), y_true.max()))": 4,
      "np.round(np.clip(global_lgb_oof, global_y_true.min(), global_y_true.max()))": 4,
      "np.round(np.clip(global_xgb_oof, global_y_true.min(), global_y_true.max()))": 4,
      "np.round(np.clip(global_cb_oof, global_y_true.min(), global_y_true.max()))": 4,
      "np.round(np.clip(global_equal_blend_oof, global_y_true.min(), global_y_true.max()))": 4,
      "preds_s > th": 4,
      "to_np(preds_s) > th_t": 4,
      "to_np(preds_s) > th_val": 4,
      "result": 4,
      "preds_train": 4,
      "label_pre": 4,
      "label_pre >= thresh": 4,
      "p": 4,
      "np.around(y_pred)": 4,
      "np.argmax(y_pred, axis=-1)": 4,
      "y_pred_DTC": 4,
      "google_y_pre > thresh": 4,
      "(glove_y_pre > thresh).astype(int)": 4,
      "(para_y_pre > thresh).astype(int)": 4,
      "(wiki_y_pre > thresh).astype(int)": 4,
      "pred_bio_labels": 4,
      "oof": 4,
      "y_pred_bidirectional_lstm": 4,
      "y_pred_cnn": 4,
      "y_pred_lstm_cnn": 4,
      "y_pred_bidirectional_lstm_cnn": 4,
      "predicted_y > threshold": 4,
      "predIdxs_VGG": 4,
      "vc.predict(X_test.drop(xgb_drop_cols, axis=1))": 4,
      "np.clip(train.signal.round(), 0, 10)": 4,
      "Y_train_predicted": 4,
      "Y_validate_predicted": 4,
      "train_label": 4,
      "(y_pred_proba > thresh).astype(int)": 4,
      "y_predi": 4,
      "ytest": 3,
      "pred > thresh": 3,
      "y_train_pred_rf": 3,
      "y_pred_test_rf": 3,
      "y_pred_test_rf_val": 3,
      "(y_pred > 0.5).astype(int)": 3,
      "pred3": 3,
      "predictionTrain": 3,
      "(y_predicted > thresh).astype(int)": 3,
      "estimator.predict(X_test)": 3,
      "valid_pred.reshape(-1)": 3,
      "preds_flat": 3,
      "long_preds + short_preds": 3,
      "long_preds": 3,
      "short_preds": 3,
      "y_pred_lr": 3,
      "clf.predict(X_train_tfidf)": 3,
      "outputs": 3,
      "y": 3,
      "np.argmax(mlp_pred, axis=-1)": 3,
      "F.softmax(preds, dim=1)[:, 1] > threshold": 3,
      "pred(xx)": 3,
      "model.predict(X_test)": 3,
      "roc_predictions": 3,
      "trainPredResponse": 3,
      "clf_predit": 3,
      "y_train": 3,
      "labels.cpu().numpy()": 3,
      "pred[df.Id.isin(ids1)]": 3,
      "pipeline.predict(X_train)": 3,
      "(output > 0.5).cpu().data.numpy()": 3,
      "np.round(np.clip(oof_preds, 0, 10)).astype(int)": 3,
      "y_pred_svc": 3,
      "preds_batch_np": 3,
      "targets": 3,
      "Y": 3,
      "(pred_val_y_2 > thresh).astype(int)": 3,
      "(val_preds > thresh).astype(int)": 3,
      "pred_mode": 3,
      "pred_int": 3,
      "data": 3,
      "train_y": 3,
      "test_ds_predicted": 3,
      "valy": 3,
      "Y_predict": 3,
      "oof_preds": 3,
      "pred_test_y": 3,
      "Y_val": 3,
      "preds >= t": 2,
      "predicted_df['test_label']": 2,
      "y_validation_pred": 2,
      "(pred_noemb_val_y_gru > thresh).astype(int)": 2,
      "(pred_noemb_val_y_lstm > thresh).astype(int)": 2,
      "(pred_glove_val_y_gru > thresh).astype(int)": 2,
      "(pred_glove_val_y_lstm > thresh).astype(int)": 2,
      "(pred_fasttext_val_y_gru > thresh).astype(int)": 2,
      "(pred_fasttext_val_y_lstm > thresh).astype(int)": 2,
      "(pred_paragram_val_y_gru > thresh).astype(int)": 2,
      "(pred_paragram_val_y_lstm > thresh).astype(int)": 2,
      "(pred_val_y_gru > thresh).astype(int)": 2,
      "(pred_val_y_lstm > thresh).astype(int)": 2,
      "dtree_predictions": 2,
      "y.playingMan": 2,
      "(y_valpred > thresh).astype(int)": 2,
      "predictions_2": 2,
      "fold_cv['predict']": 2,
      "cv['predict']": 2,
      "y_pred[X_test['difficulty'] == difficulty]": 2,
      "final_train_predictions": 2,
      "np.argmax(y_pred1, axis=1)": 2,
      "all_val_preds": 2,
      "y2": 2,
      "y_valid_pred": 2,
      "nb_predict": 2,
      "pred5": 2,
      "model.predict(train)": 2,
      "y_pred_rf": 2,
      "predictions.astype(int)": 2,
      "opt_predsf": 2,
      "valid_pr": 2,
      "(prob_val > thresh).astype('int32')": 2,
      "tes": 2,
      "output.data.to('cpu') > 0.5": 2,
      "train_preds > threshold": 2,
      "val_preds > threshold": 2,
      "(torch.sigmoid(val_preds).cpu().numpy() > threshold).astype(int)": 2,
      "(torch.sigmoid(train_preds).cpu().numpy() > best_threshold).astype(int)": 2,
      "rf_predictions": 2,
      "(cv_predictions > thresh).astype(int)": 2,
      "y_pred4": 2,
      "y_predicted_r": 2,
      "(pred_noemb_val_y > np.round(thresh, 2)).astype(int)": 2,
      "PREDS": 2,
      "test_preds": 2,
      "clf.predict(X_train)": 2,
      "clf.predict(X_test)": 2,
      "pred_flat": 2,
      "logit.predict(X_valid)": 2,
      "rf.predict(X_valid)": 2,
      "rf.predict(X_train)": 2,
      "svc.predict(X_valid)": 2,
      "svc.predict(X_train)": 2,
      "yhat > threshold": 2,
      "predict_nb": 2,
      "predict_svm": 2,
      "np.round(signal[:5000000])": 2,
      "np.clip(np.round(site_oof_predictions), 1, 2)": 2,
      "np.clip(np.round(df.loc[df['site'] > 0, 'site_predicted']), 1, 2)": 2,
      "(y_hat > thresh).astype(int)": 2,
      "y_train_predict": 2,
      "vc.predict(ttextdataemx_test)": 2,
      "clf.predict(testfeature)": 2,
      "vc.predict(testfeature)": 2,
      "vc.predict(tsiftdatax_test)": 2,
      "(y_pred.cpu().detach().numpy() > 0.5).astype(int)": 2,
      "y_pred_round": 2,
      "validate_pre_label": 2,
      "Y_prediction_RF": 2,
      "train_ckwe['pred'].values": 2,
      "train['preds']": 2,
      "middle100['preds']": 2,
      "OG": 2,
      "YOne": 2,
      "np.where(pred_val >= 0.5, 1, 0)": 2,
      "(baseline_ngram_lr_preds_prob > threshold).astype(int)": 2,
      "label_predict": 2,
      "predictions_va > threshold": 2,
      "y_pred_LR": 2,
      "b.cpu()": 2,
      "test_labels": 2,
      "new_y_pred": 2,
      "scores": 2,
      "y_rf_pred": 2,
      "y_gb_pred": 2,
      "new_predictions": 2,
      "np.argmax(gbc_pred, axis=-1)": 2,
      "(ypred > thresh).astype(int)": 2,
      "np.round(np.clip(oof_preds[val_ind], 0, 10)).astype(int)": 2,
      "np.round(np.clip(oof_preds[:5000000], 0, 10)).astype(int)": 2,
      "oof_preds.argmax(axis=1)": 2,
      "val_y": 2,
      "train_prediction": 2,
      "glove_y_pre > thresh": 2,
      "para_y_pre > thresh": 2,
      "wiki_y_pre > thresh": 2,
      "y_pre > thresh": 2,
      "y_pred_svm": 2,
      "outputs.data.cpu().numpy()": 2,
      "y_pred_batch": 2,
      "pred2": 2,
      "all_pred.cpu()": 2,
      "np.int16(val_pred > t)": 2,
      "nb_train_preds": 2,
      "svc_train_preds": 2,
      "lr_train_preds": 2,
      "pred_ent_labels": 2,
      "val_outputs": 2,
      "label": 2,
      "(y_pred_val > t).astype('int')": 2,
      "y_pred_test > t": 2,
      "y_oof[val_idx].round()": 2,
      "(pred_val_y_4 > thresh).astype(int)": 2,
      "ypredictions": 2,
      "to_numpy(torch.argmax(out, dim=1))": 2,
      "prediction_train": 2,
      "prediction_train_1": 2,
      "predictions_1": 2,
      "(pred_glove_train_y > thresh).astype(int)": 2,
      "oof_part": 2,
      "oof[val_idx].round()": 2,
      "ycvalid": 2,
      "train_ds_predicted": 2,
      "np.argmax(oof_lgb, axis=1)": 2,
      "oof_lgb": 2,
      "pred_label": 2,
      "pred_validation > 0.5": 2,
      "f_output": 2,
      "np.where(y_pred > threshold, 1, 0)": 2,
      "np.array(val_pred) > tmp[0]": 2,
      "y_pred9": 2,
      "clf_final.predict(X_test.drop(xgb_drop_cols, axis=1))": 2,
      "vc3.predict(X_test.drop(lgb_drop_cols, axis=1))": 2,
      "et_cv_preds": 2,
      "lgb_cv_preds": 2,
      "rf_cv_preds": 2,
      "y_pred_xgboost.round()": 2,
      "model_knn.predict(X_test)": 2,
      "Ym_test_pred": 2,
      "Ycv_pred": 2,
      "np.array(valid_target_XGB)": 2,
      "(val_y > thresh).astype(int)": 2,
      "y_predict > t": 2,
      "y_pred > threshold": 2,
      "y_train[test_index[calc_idx[1]]]": 2,
      "pred_val": 2,
      "y_": 2,
      "prediction_int": 2,
      "np.round(np.clip(y_pred_train_lgb, 0, 10)).astype(int)": 2,
      "l_test": 2,
      "(y_pred > threshold).astype(int)": 2,
      "p_lab": 2,
      "y2_preds": 2,
      "uniform_prediction": 2,
      "distance_prediction": 2,
      "predict_svc": 1,
      "predictions_DCmodel_1": 1,
      "predictions_LSTM_model_1": 1,
      "predictions_DCmodel_2": 1,
      "predictions_LSTM_model_2": 1,
      "predictions_DCmodel_3": 1,
      "predictions_LSTM_model_3": 1,
      "predicted_y": 1,
      "(predictions > threshold).astype(int)": 1,
      "train_preds > thresh": 1,
      "y_pred_eval": 1,
      "knn_y_train_pred": 1,
      "knn_y_test_pred": 1,
      "[1, 0, 1]": 1,
      "y_pred_NN": 1,
      "fo['prediction']": 1,
      "val_pred > thresh": 1,
      "pred_list": 1,
      "(y_pred[i] >= thresh).astype(int)": 1,
      "(y_pred_final >= thresh).astype(int)": 1,
      "y_pred_test2_final_class": 1,
      "y_pred_train1": 1,
      "y_pred_val1": 1,
      "y_pred_train2": 1,
      "y_pred_val2": 1,
      "y_pred_train3": 1,
      "y_pred_val3": 1,
      "ytest.loc[diff_test1.index]": 1,
      "ytest.loc[diff_test2.index]": 1,
      "ytest.loc[diff_test3.index]": 1,
      "ytest.loc[diff_test4.index]": 1,
      "y_test_predict": 1,
      "df_train['gm_label']": 1,
      "y_batch_predicted_np": 1,
      "y_pred_changed": 1,
      "train_y_predict": 1,
      "val_y_predict": 1,
      "model.predict(train_X_)": 1,
      "model.predict(val_X_)": 1,
      "(y_pred[:train_count] > thresh).astype(int)": 1,
      "pred_xg": 1,
      "(with_attention_val_y > thresh).astype(int)": 1,
      "np.argmax(oof_, axis=2).reshape(-1)": 1,
      "np.argmax(org_oof_, axis=2).reshape(-1)": 1,
      "(expit(predictions) >= MAX_THRESHOLD).astype(int)": 1,
      "(expit(predictions) >= threshold).astype(int)": 1,
      "VP": 1,
      "train_pr": 1,
      "y_oof.iloc[inner_val_idx]": 1,
      "y_oof": 1,
      "pred_test_y_thresh": 1,
      "np.round(oof_preds[val_idx])": 1,
      "np.round(oof_preds)": 1,
      "train_pred_int": 1,
      "LSTM_yhat_test": 1,
      "GRU_yhat_test": 1,
      "RandomForestClassifier_yhat_test": 1,
      "SGDClassifier_yhat_test": 1,
      "MultinomialNB_yhat_test": 1,
      "sepcnn_yhat_test": 1,
      "y_pred_val_blstm_fast": 1,
      "y_pred_val_cnn_fast": 1,
      "y_pred_val_blstm_keras": 1,
      "y_pred_val_cnn_keras": 1,
      "predict_val_nb": 1,
      "predict_val_svm": 1,
      "predict_val_sgd": 1,
      "y_dev_predict[0].map(lambda x: cutoff(x, i / 10))": 1,
      "np.argmax(pred.numpy(), 1)": 1,
      "np.where(pred_LSTM > 0.5, 1, 0)": 1,
      "np.where(pred_CNN_LSTM > 0.5, 1, 0)": 1,
      "np.where(pred_LSTM_FC > 0.5, 1, 0)": 1,
      "pred_bert": 1,
      "y_pred2_lr": 1,
      "y_pred_lrcv": 1,
      "y_pred2_lrcv": 1,
      "total_test_1_preds": 1,
      "total_test_2_preds": 1,
      "(test_1_preds > best_threshold).astype(int)": 1,
      "(test_2_preds > best_threshold).astype(int)": 1,
      "validPre > Threshold": 1,
      "tmp_preds": 1,
      "test_preds_local.mean(axis=1) > search_result['threshold']": 1,
      "p[:data_count]": 1,
      "anomalies": 1,
      "change(anomalies.values, 5, 250)": 1,
      "(tr_pred > thresh).astype(int)": 1,
      "pred_results": 1,
      "train_meta > thresh['threshold']": 1,
      "opt_valsf": 1,
      "m.predict(X_train)": 1,
      "m.predict(X_valid)": 1,
      "R": 1,
      "np.array(pred)": 1,
      "preds[:, 1] > i": 1,
      "pred[:, 1] > thresh": 1,
      "ys": 1,
      "val_pred > 0.5": 1,
      "temp_val_pred": 1,
      "clf.predict(x_val)": 1,
      "goldSet_yPred": 1,
      "xgb_model.predict(X_train)": 1,
      "xgb_model.predict(X_valid)": 1,
      "vc.predict(X_valid)": 1,
      "np.round(val_prob[:, 1], 0).astype(int)": 1,
      "val_preds > 0.26": 1,
      "(val_y_pred > thresh).astype(int)": 1,
      "(yprediction > thresh).astype(int)": 1,
      "logit_cv.predict(X_valid)": 1,
      "logit_cv.predict(X_train)": 1,
      "rf_grid.best_estimator_.predict(X_valid)": 1,
      "logit.predict(X_train)": 1,
      "(y_pred.iloc[:, 0] > thresh).astype(int)": 1,
      "y.cpu()": 1,
      "pred_bool": 1,
      "get_predictions_from_prob(y_pred)": 1,
      "rf_predict_resampled": 1,
      "baseline_pred": 1,
      "(pred_model > thresh).astype(int)": 1,
      "pred_target_for_f1_score": 1,
      "y_test_prediction": 1,
      "submission_": 1,
      "predict_dtc": 1,
      "predict_nn_plp": 1,
      "data_submittion": 1,
      "y_pred_XGB": 1,
      "(val_pred > thresh).astype(int)": 1,
      "predicted_val_bin": 1,
      "y_pred_valid.round()": 1,
      "y_pred_int": 1,
      "devOut": 1,
      "train_targets": 1,
      "y_pred_M": 1,
      "y_pred_B": 1,
      "y_pred[:, i] > 0.5": 1,
      "yp_train > t": 1,
      "yp_val > t": 1,
      "yp_test > t": 1,
      "clf.predict(X_val_prepared)": 1,
      "np.argmax(pred_valid, axis=1)": 1,
      "valid_pred_01_lstm": 1,
      "y_pred_train_hyper": 1,
      "y_pred_hyper": 1,
      "(predicted_val > threshold).astype(int)": 1,
      "pred_val_y": 1,
      "fin_outputs": 1,
      "y_preds_rand": 1,
      "train_predictions[ix]": 1,
      "viterbi_predictions[ix]": 1,
      "pos_dec_predictions[ix]": 1,
      "viterbi_predictions": 1,
      "pos_dec_predictions": 1,
      "np.round(np.clip(lgb_oof_predictions, y_train.min(), y_train.max()))": 1,
      "np.round(np.clip(self.lgb_oof, y_train.min(), y_train.max()))": 1,
      "np.round(np.clip(xgb_oof_predictions, y_train.min(), y_train.max()))": 1,
      "np.round(np.clip(self.xgb_oof, y_train.min(), y_train.max()))": 1,
      "np.round(np.clip(cb_oof_predictions, y_train.min(), y_train.max()))": 1,
      "np.round(np.clip(self.cb_oof, y_train.min(), y_train.max()))": 1,
      "np.round(np.clip(self.blend_oof, lgb_y_train.min(), lgb_y_train.max()))": 1,
      "np.round(np.clip(model01_lgb_oof_predictions, model01_lgb_y_train.min(), model01_lgb_y_train.max()))": 1,
      "np.round(np.clip(model_oof, model01_lgb_y_train.min(), model01_lgb_y_train.max()))": 1,
      "np.round(np.clip(model01_lgb_oof, model01_lgb_y_train.min(), model01_lgb_y_train.max()))": 1,
      "np.round(np.clip(model01_xgb_oof_predictions, model01_xgb_y_train.min(), model01_xgb_y_train.max()))": 1,
      "np.round(np.clip(model_oof, model01_xgb_y_train.min(), model01_xgb_y_train.max()))": 1,
      "np.round(np.clip(model01_xgb_oof, model01_xgb_y_train.min(), model01_xgb_y_train.max()))": 1,
      "np.round(np.clip(model01_cb_oof_predictions, model01_cb_y_train.min(), model01_cb_y_train.max()))": 1,
      "np.round(np.clip(model_oof, model01_cb_y_train.min(), model01_cb_y_train.max()))": 1,
      "np.round(np.clip(model01_cb_oof, model01_cb_y_train.min(), model01_cb_y_train.max()))": 1,
      "np.round(np.clip(model012_lgb_oof_predictions, model012_lgb_y_train.min(), model012_lgb_y_train.max()))": 1,
      "np.round(np.clip(model_oof, model012_lgb_y_train.min(), model012_lgb_y_train.max()))": 1,
      "np.round(np.clip(model012_lgb_oof, model012_lgb_y_train.min(), model012_lgb_y_train.max()))": 1,
      "np.round(np.clip(model012_xgb_oof_predictions, model012_xgb_y_train.min(), model012_xgb_y_train.max()))": 1,
      "np.round(np.clip(model_oof, model012_xgb_y_train.min(), model012_xgb_y_train.max()))": 1,
      "np.round(np.clip(model012_xgb_oof, model012_xgb_y_train.min(), model012_xgb_y_train.max()))": 1,
      "np.round(np.clip(model012_cb_oof_predictions, model012_cb_y_train.min(), model012_cb_y_train.max()))": 1,
      "np.round(np.clip(model_oof, model012_cb_y_train.min(), model012_cb_y_train.max()))": 1,
      "np.round(np.clip(model012_cb_oof, model012_cb_y_train.min(), model012_cb_y_train.max()))": 1,
      "np.round(np.clip(model0123_lgb_oof_predictions, model0123_lgb_y_train.min(), model0123_lgb_y_train.max()))": 1,
      "np.round(np.clip(model_oof, model0123_lgb_y_train.min(), model0123_lgb_y_train.max()))": 1,
      "np.round(np.clip(model0123_lgb_oof, model0123_lgb_y_train.min(), model0123_lgb_y_train.max()))": 1,
      "np.round(np.clip(model0123_xgb_oof_predictions, model0123_xgb_y_train.min(), model0123_xgb_y_train.max()))": 1,
      "np.round(np.clip(model_oof, model0123_xgb_y_train.min(), model0123_xgb_y_train.max()))": 1,
      "np.round(np.clip(model0123_xgb_oof, model0123_xgb_y_train.min(), model0123_xgb_y_train.max()))": 1,
      "np.round(np.clip(model0123_cb_oof_predictions, model0123_cb_y_train.min(), model0123_cb_y_train.max()))": 1,
      "np.round(np.clip(model_oof, model0123_cb_y_train.min(), model0123_cb_y_train.max()))": 1,
      "np.round(np.clip(model0123_cb_oof, model0123_cb_y_train.min(), model0123_cb_y_train.max()))": 1,
      "np.round(np.clip(model01234_lgb_oof_predictions, model01234_lgb_y_train.min(), model01234_lgb_y_train.max()))": 1,
      "np.round(np.clip(model_oof, model01234_lgb_y_train.min(), model01234_lgb_y_train.max()))": 1,
      "np.round(np.clip(model01234_lgb_oof, model01234_lgb_y_train.min(), model01234_lgb_y_train.max()))": 1,
      "np.round(np.clip(model01234_cb_oof_predictions, model01234_cb_y_train.min(), model01234_cb_y_train.max()))": 1,
      "np.round(np.clip(model_oof, model01234_cb_y_train.min(), model01234_cb_y_train.max()))": 1,
      "np.round(np.clip(model01234_cb_oof, model01234_cb_y_train.min(), model01234_cb_y_train.max()))": 1,
      "np.round(df_train[df_train['model'] == 0]['lgb_solo_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['model'] == 0]['xgb_solo_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['model'] == 0]['cb_solo_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['model'] == 0]['lgb_duo_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['model'] == 0]['xgb_duo_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['model'] == 0]['cb_duo_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['model'] == 0]['blend_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['model'] == 1]['lgb_solo_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['model'] == 1]['xgb_solo_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['model'] == 1]['cb_solo_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['model'] == 1]['lgb_duo_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['model'] == 1]['xgb_duo_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['model'] == 1]['cb_duo_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['model'] == 1]['blend_oof']).astype(np.uint8)": 1,
      "np.round(df_train[(df_train['model'] == 2) & (df_train['is_filtered'] == 0)]['lgb_solo_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[(df_train['model'] == 2) & (df_train['is_filtered'] == 0)]['xgb_solo_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[(df_train['model'] == 2) & (df_train['is_filtered'] == 0)]['cb_solo_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[(df_train['model'] == 2) & (df_train['is_filtered'] == 0)]['lgb_trio_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[(df_train['model'] == 2) & (df_train['is_filtered'] == 0)]['xgb_trio_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[(df_train['model'] == 2) & (df_train['is_filtered'] == 0)]['cb_trio_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[(df_train['model'] == 2) & (df_train['is_filtered'] == 0)]['blend_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['model'] == 3]['lgb_solo_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['model'] == 3]['xgb_solo_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['model'] == 3]['cb_solo_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['model'] == 3]['lgb_quad_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['model'] == 3]['xgb_quad_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['model'] == 3]['cb_quad_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['model'] == 3]['blend_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['model'] == 4]['lgb_solo_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['model'] == 4]['xgb_solo_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['model'] == 4]['cb_solo_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['model'] == 4]['lgb_penta_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['model'] == 4]['cb_penta_model_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['model'] == 4]['blend_oof']).astype(np.uint8)": 1,
      "np.round(df_train[df_train['is_filtered'] == 0]['blend_oof']).astype(np.uint8)": 1,
      "np.ones(len(df_train))": 1,
      "(t_y >= thresh).astype(int)": 1,
      "(pvy[:, 0] > thresh).astype(int)": 1,
      "(out > self.threshold).astype(int)": 1,
      "(y_pred > self.threshold).astype(int)": 1,
      "oof['pred'] > 0.1": 1,
      "oof['pred'] > 0.3": 1,
      "time_level_prediction['pred'] > 0.1": 1,
      "time_level_prediction['pred'] > 0.08": 1,
      "np.argmax(gbc_pred, axis=1)": 1,
      "np.argmax(y_pred, axis=1)": 1,
      "eval_pred_class": 1,
      "y_val_predict": 1,
      "y_predicit_4": 1,
      "svc.predict(ttextdataemx_test)": 1,
      "clf.predict(ttextdataemx_test)": 1,
      "dt.predict(ttextdataemx_test)": 1,
      "rf.predict(ttextdataemx_test)": 1,
      "ab.predict(ttextdataemx_test)": 1,
      "est.predict(ttextdataemx_test)": 1,
      "svc.predict(testfeature)": 1,
      "dt.predict(testfeature)": 1,
      "rf.predict(testfeature)": 1,
      "ab.predict(testfeature)": 1,
      "est.predict(testfeature)": 1,
      "clf.predict(timagearrayx_test)": 1,
      "svc.predict(tsiftdatax_test)": 1,
      "clf.predict(tsiftdatax_test)": 1,
      "dt.predict(tsiftdatax_test)": 1,
      "rf.predict(tsiftdatax_test)": 1,
      "ab.predict(tsiftdatax_test)": 1,
      "est.predict(tsiftdatax_test)": 1,
      "tphasharrayy_test.values": 1,
      "clf2.predict(tsiftdatax_test)": 1,
      "y_pred_training": 1,
      "y_pred_validation": 1,
      "predictions_lgbm_01": 1,
      "np.array(val_pred) > thr": 1,
      "result_test": 1,
      "exact_pred": 1,
      "log_reg.predict(X_train)": 1,
      "outputs.asnumpy() > tmp[0]": 1,
      "scores[:, 1] > thresh": 1,
      "(scores[:, 1] > best_thresh).astype(np.int)": 1,
      "predictions['prediction']": 1,
      "p_binary": 1,
      "p['.1']": 1,
      "p['.2']": 1,
      "p['.3']": 1,
      "p['.4']": 1,
      "p['.5']": 1,
      "p['.6']": 1,
      "p['.7']": 1,
      "p['.8']": 1,
      "p['.9']": 1,
      "Y_pred_grid": 1,
      "model.predict(X_train)": 1,
      "(validate_hat > threshold).astype(int)": 1,
      "y_hats": 1,
      "np.array(val_preds) > delta": 1,
      "np.array(test_preds) > delta": 1,
      "y_pred_acc": 1,
      "Holdgrouped['MLPPred']": 1,
      "predknn": 1,
      "predTree": 1,
      "predsvm": 1,
      "predlr": 1,
      "np.where(pred_val_hashtags >= 0.5, 1, 0)": 1,
      "np.where(pred_val_stem >= 0.5, 1, 0)": 1,
      "np.where(pred_val_other >= 0.5, 1, 0)": 1,
      "np.where(pred_val_glove >= 0.5, 1, 0)": 1,
      "np.where(pred_val_binary >= 0.5, 1, 0)": 1,
      "np.where(pred_val_lda >= 0.5, 1, 0)": 1,
      "new_pred": 1,
      "stack_y_pred": 1,
      "(oof_test > i).astype(int)": 1,
      "(oof_test > 0.34).astype(int)": 1,
      "predictions_train_reduced > t": 1,
      "predictions_va > t": 1,
      "train_clean['open_channels_pred']": 1,
      "trainPredHResponse": 1,
      "y_proba > best_threshold": 1,
      "predict_rfc": 1,
      "train_meta > search_result['threshold']": 1,
      "long_prediction_strings.values": 1,
      "m.predict(X1)": 1,
      "infold_pred.round().astype(int)": 1,
      "outfold_pred.round().astype(int)": 1,
      "train_pred > thresh": 1,
      "preds > thresh": 1,
      "(predicted >= threshold).astype(int)[:, 1]": 1,
      "model_svc.predict(X_test)": 1,
      "predict_l": 1,
      "y_01": 1,
      "sgd_pred": 1,
      "scaled.clip(0, 10).round()": 1,
      "train['scaled_signal'].clip(0, 10).round()": 1,
      "np.concatenate(predictions)": 1,
      "s.values": 1,
      "comps.pred": 1,
      "Yopt[:5000000][good_id]": 1,
      "best_val_preds": 1,
      "cbc.predict(X_valid_sub)": 1,
      "y_pred > n": 1,
      "np.round(model.predict(X_valid), 0).astype(int)": 1,
      "np.round(second_model.predict(X_valid), 0).astype(int)": 1,
      "np.round(third_model.predict(X_valid), 0).astype(int)": 1,
      "np.round(gbm.predict(X_valid, num_iteration=gbm.best_iteration), 0).astype(int)": 1,
      "fake_test['pred'].astype(int)": 1,
      "(Glove_Result > thresh).astype(int)": 1,
      "test_pred_mnb": 1,
      "test_pred_bnb": 1,
      "train_df.prediction": 1,
      "(train_df.prediction == oc).astype(int)": 1,
      "pred[val_index]": 1,
      "pred[df.Id.isin(test2.Id)]": 1,
      "pred[~df.Id.isin(test2.Id)]": 1,
      "class_preds": 1,
      "clf2.predict(X_test_vect)": 1,
      "y_pred_train > 0": 1,
      "np.array(valid_pred) > tmp[0]": 1,
      "train_df['target']": 1,
      "val['target']": 1,
      "np.where(y_pred >= t, 1, 0)": 1,
      "real_temp": 1,
      "proba_tr.open_channels": 1,
      "classifier.predict(X_val_bow_df)": 1,
      "y_test_split": 1,
      "np.where(y_pred > thresh, 1, 0)": 1,
      "clf.fit(X_train, y_train).predict(X_train)": 1,
      "clf.fit(X_train, y_train).predict(X_val)": 1,
      "pred_temp": 1,
      "y_true[:batch_size]": 1,
      "pred > i": 1,
      "(pred > thr).astype(int)": 1,
      "(predicted_sample > thresh).astype(int)": 1,
      "train_df_all.predict_outliers": 1,
      "val_predictions[:, j]": 1,
      "rm_predictions": 1,
      "preds_valid1": 1,
      "preds_valid2": 1,
      "y_preds.argmax(axis=1)": 1,
      "oof_preds[:5000000].argmax(axis=1)": 1,
      "np.argmax(preds_f + preds_f_tta, axis=2).reshape(-1)": 1,
      "np.argmax(oof_ + oof_tta, axis=1)": 1,
      "df['wave_pred']": 1,
      "df['xgb_pred']": 1,
      "df.iloc[:5000000]['xgb_pred']": 1,
      "df['ensemble_pred']": 1,
      "df.iloc[:5000000]['ensemble_pred']": 1,
      "y_predic": 1,
      "preds > i": 1,
      "np.array(all_preds).flatten() > 0.5": 1,
      "y_pred_gnb": 1,
      "logregpredict": 1,
      "svmpredict": 1,
      "probs": 1,
      "y_full_oof": 1,
      "cm_predictionsall": 1,
      "cm_predictions_n": 1,
      "train_predictions_gbc": 1,
      "test_predictions_gbc": 1,
      "yhat_classes": 1,
      "bag_train_preds": 1,
      "emb_train_preds": 1,
      "rf_train_preds": 1,
      "predicciones_val": 1,
      "(pred_cnn_val_y1 > thresh).astype(int)": 1,
      "(pred_cnn_val_y2 > thresh).astype(int)": 1,
      "test['y_pred']": 1,
      "y_finalpred": 1,
      "y_preds_new": 1,
      "test": 1,
      "(pred_prob > thresh).astype(int)": 1,
      "np.array(train_preds_) > tmp[0]": 1,
      "(pred_val_y_1 > thresh).astype(int)": 1,
      "(pred_val_y_3 > thresh).astype(int)": 1,
      "(pred_val_y_5 > thresh).astype(int)": 1,
      "(val_pred_cnn_glove > thresh).astype(int)": 1,
      "(val_pred_bgru_glove > thresh).astype(int)": 1,
      "(val_pred_bgru_wiki > thresh).astype(int)": 1,
      "(val_pred_bgru_paragram > thresh).astype(int)": 1,
      "y_pred_bow": 1,
      "y_pred_bow2": 1,
      "y_pred_tfidf": 1,
      "y_pred_tfidf4": 1,
      "y_pred_stem_dt": 1,
      "y_pred_lemma_dt": 1,
      "pred_stem_xg": 1,
      "pred_lemma_xg": 1,
      "np.round(np.clip(two, 0, 10)).astype(np.int8)": 1,
      "np.round(np.clip(two, 0, 10))": 1,
      "np.round(np.clip(oofs[blend_name].drop(train_df.loc[3642932:3822753].index), 0, 10))": 1,
      "(preds > thresh) * 1": 1,
      "train_ann['PredictionString'].values": 1,
      "pred_df['PredictionString'].fillna('').values": 1,
      "(y_pred['prediction'] > threshold).astype(int)": 1,
      "(predictions_proba['prediction'] > threshold).astype(int)": 1,
      "y_pred_": 1,
      "results_dataframe['target_predictions']": 1,
      "labels": 1,
      "test_pred_label": 1,
      "y_pred_mbet": 1,
      "y_pred_mbrf": 1,
      "y_pred_mxgB": 1,
      "y_mpred_lgbm": 1,
      "np.array(test_preds[epoch]) > delta": 1,
      "binarizer.transform(y_pred)": 1,
      "(pred_val_y > thres).astype(int)": 1,
      "y_preds[:, i]": 1,
      "y_pred_down_C_cv": 1,
      "y_pred_down_C_tfidf": 1,
      "y_hat_train": 1,
      "y_hat_test": 1,
      "temp": 1,
      "temp_D": 1,
      "prediction_tuned_linear_svc": 1,
      "predictions_tuned_linear_svc": 1,
      "prediction_tuned_logistic_regression": 1,
      "predictions_tuned_logistic_regression": 1,
      "prediction_tuned_extra_trees": 1,
      "predictions_tuned_extra_trees": 1,
      "prediction_tuned_random_forest": 1,
      "predictions_tuned_random_forest": 1,
      "pred_tuned_mode": 1,
      "to_labels(val_pred, t)": 1,
      "round_y_pred": 1,
      "y_test_pred_sgd": 1,
      "val_y_pred > threshold": 1,
      "val_y_pred > 0.5": 1,
      "oof_pred2": 1,
      "val_pred > threshold": 1,
      "classifyrank(clf.predict(X_val), train_dist)": 1,
      "ypred": 1,
      "NB_pred": 1,
      "SDG_pred": 1,
      "(np.array(all_preds) > thresh).astype(int)": 1,
      "binarize(preds, thresh)": 1,
      "pred21": 1,
      "pred22": 1,
      "pred_df['PredictionString'].values": 1,
      "(pred_dev_y > thresh).astype(int)": 1,
      "train_pre": 1,
      "val_pre": 1,
      "(y_pre > 0.5).astype(int)": 1,
      "(valid_predict > thresh).astype(int)": 1,
      "pred_test": 1,
      "p_train": 1,
      "p_test": 1,
      "original_ytrain[valid_id]": 1,
      "val_answers > _": 1,
      "test_answers > best_threshold": 1,
      "y_ran_pred": 1,
      "cm_pre": 1,
      "np.argmax(np.array(y_pred), axis=1)": 1,
      "PREDICTIONS": 1,
      "np.round(oof).astype(np.int)": 1,
      "model13.predict(selected_data_test)": 1,
      "y_pred_temp": 1,
      "(y_proba > thres).astype(int)": 1,
      "y_test_pred_gru.round()": 1,
      "y_test_pred_lstm.round()": 1,
      "np.round(np.clip(preds_f, 0, 10)).astype(int)": 1,
      "np.round(np.clip(oof_, 0, 10)).astype(int)": 1,
      "y_pred10": 1,
      "y_pred3": 1,
      "y_pred5": 1,
      "y_pred7": 1,
      "y_pred8": 1,
      "tmp_pred": 1,
      "np.clip(np.round(df_train['modified_signal']), 0, 10)": 1,
      "pred_validate_y": 1,
      "mnist_label_preds": 1,
      "estimator.predict(X_cv)": 1,
      "clf_final.predict(X_test.drop(lgb_drop_cols, axis=1))": 1,
      "clf_final.predict(X_cv.drop(lgb_drop_cols, axis=1))": 1,
      "vc.predict(X_cv.drop(lgb_drop_cols, axis=1))": 1,
      "cv_predictions": 1,
      "p > 0.5": 1,
      "ground_truth": 1,
      "results['y_hat']": 1,
      "y_pred_t": 1,
      "(pred_val_y > thr).astype(int)": 1,
      "vy": 1,
      "model_svm.predict(X_test)": 1,
      "model_sgd.predict(X_test)": 1,
      "model_mlp.predict(X_test)": 1,
      "model_ada.predict(X_test)": 1,
      "model_voting.predict(X_test)": 1,
      "model_gradient.predict(X_test)": 1,
      "model_xgb.predict(X_test)": 1,
      "model_lgbm.predict(X_test)": 1,
      "op": 1,
      "(y_pred > threshold).astype('int')": 1,
      "y_mixed": 1,
      "train.prediction": 1,
      "ypred.round()": 1,
      "np.array(valid_target_LGBM)": 1,
      "np.array(valid_target_CAT)": 1,
      "yt_pred": 1,
      "val_prediction": 1,
      "pred.argmax(1).cpu()": 1,
      "tmp": 1,
      "valid_predict": 1,
      "predictions2": 1,
      "class_predict_train": 1,
      "class_predict": 1,
      "np.round(oof)": 1,
      "opt_preds": 1,
      "(pred_glove_train_y > 0.4).astype(int)": 1,
      "(pretrained_model_pred > thresh).astype(int)": 1,
      "(predictions > thresh).astype(int)": 1,
      "np.clip(TRAIN.signal.round(), 0, 10)": 1,
      "np.clip(TRAIN.signal_filter.round(), 0, 10)": 1,
      "np.clip(train0.signal.round(), 0, 10)": 1,
      "np.clip(train1.signal.round(), 0, 10)": 1,
      "np.clip(train2.signal.round(), 0, 10)": 1,
      "np.clip(train.signal.round().values, 0, 10)": 1,
      "np.clip(train0.signal.round().values, 0, 10)": 1,
      "out.max(dim=1)[1].cpu().data.numpy()": 1,
      "vout.max(dim=1)[1].cpu().data.numpy()": 1,
      "ensamble_predict(models, X_val)": 1,
      "ensamble_predict(models, sc.transform(Xb))": 1,
      "ensamble_predict(models, sc.transform(X))": 1,
      "Pred_train": 1,
      "temp_y": 1,
      "pred_train_y": 1,
      "submission['target']": 1,
      "nn_pred_result": 1,
      "lgb_result": 1,
      "svc_result": 1,
      "test622_result": 1,
      "test433_result": 1,
      "val_preds > 0.1": 1,
      "oof_pred > i": 1,
      "final": 1,
      "train.target": 1,
      "np.array(train_pred)": 1,
      "np.array(vp)": 1,
      "predictions.reshape(-1)": 1,
      "np.round(np.clip(y_pred_train_wnet, 0, 10)).astype(int)": 1,
      "y_train_preds": 1,
      "(y_proba > threshold).astype('int')": 1,
      "target_val[:, i]": 1,
      "y_predicted_d": 1,
      "xg_pred": 1,
      "y_preed": 1,
      "ypred1": 1,
      "np.array(train_hat_list) >= 0.5": 1,
      "np.array(valid_hat_list) >= 0.5": 1,
      "estimator.predict_proba(X_tr).argmax(axis=1)": 1,
      "estimator.predict_proba(X_te).argmax(axis=1)": 1,
      "train_pred1": 1,
      "train_pred2": 1,
      "predict_val_bool": 1,
      "Y_predict_balanced": 1,
      "model_LR.predict(X_valid)": 1,
      "y_pred > hp.border": 1,
      "y_train.iloc[test]": 1,
      "cm_preds": 1,
      "test_df": 1,
      "pred_mc": 1,
      "pred_valid": 1,
      "out_of_fold": 1,
      "y_pred_k": 1,
      "preds_df['prediction']": 1,
      "threshold0 < pred[:, idx]": 1,
      "threshold_dic[ii] < pred[:, ii]": 1,
      "0.5 < pred[:, ii]": 1,
      "means_b": 1,
      "ova_preds": 1,
      "pred_glove_val_y > thresh": 1,
      "pred_noemb_val_y > thresh": 1,
      "pred_val_y > thresh": 1,
      "(y_val_pred[:, 1] > thresh).astype(int)": 1,
      "y_true_tag": 1,
      "temp_pred": 1,
      "y_predictions": 1,
      "y_train[:50000]": 1,
      "current_predictions": 1,
      "val_predictions_flat": 1,
      "pred_train > to": 1,
      "real_test_predict": 1,
      "real_train_predict": 1,
      "discrete_test_predict": 1,
      "discrete_train_predict": 1,
      "lgb_train_predict": 1,
      "np.round(predictions_all[str(weight)])": 1,
      "(train_preds > thresh).astype(int)": 1,
      "lr_preds": 1,
      "p2": 1,
      "np.array(pred) > tmp[0]": 1,
      "pred_logit": 1
    },
    "sklearn.preprocessing._data.RobustScaler.fit.X": {
      "pd.concat([train[features], test[features]], axis=0)": 12,
      "train_data": 5,
      "X_train": 3,
      "wide[fit_mask].values": 2,
      "X": 2,
      "df": 2,
      "X_test": 2,
      "masks_probas.reshape(-1, 1)": 1,
      "box_cox_train": 1,
      "train[num_features]": 1,
      "train[predictors]": 1,
      "test.values": 1,
      "train.values": 1,
      "train_features[col].values.reshape(-1, 1)": 1,
      "y_train": 1,
      "y_test": 1,
      "x[cols]": 1,
      "train_df[Columns.scaling_cols.value]": 1,
      "train[col]": 1,
      "train_data[col]": 1,
      "x_train.values": 1,
      "df[[col]]": 1,
      "X[col].values.reshape(-1, 1)": 1,
      "np.concatenate((train_df.drop('target', axis=1), test_df), axis=0)": 1,
      "np.array(train_data['Weeks']).reshape(-1, 1)": 1,
      "np.array(train_data['Percent']).reshape(-1, 1)": 1,
      "np.array(train_data['Age']).reshape(-1, 1)": 1
    },
    "sklearn.preprocessing._data.RobustScaler.transform.X": {
      "X_test": 12,
      "train[features]": 12,
      "test[features]": 12,
      "test": 11,
      "X_train": 5,
      "train_data": 5,
      "test_data": 4,
      "self.df[self.df.columns.difference(['Patient', 'FVC', 'Percent', 'Weeks', 'base_Weeks'])]": 4,
      "X": 3,
      "test.values": 3,
      "wide.values": 2,
      "test_set": 2,
      "df": 2,
      "submission_df[submission_df.columns]": 2,
      "X_final[:, 2:]": 2,
      "test[predictors]": 2,
      "X_test[nonCat]": 2,
      "y_test": 2,
      "train.values": 2,
      "valid_feat": 2,
      "X_val": 2,
      "x_test": 2,
      "X_test[:14]": 2,
      "X1[:14]": 2,
      "df_test": 1,
      "masks_probas[i, :].reshape(-1, 1)": 1,
      "train[num_features]": 1,
      "test[num_features]": 1,
      "X_test[quan]": 1,
      "test_copy[num_cols]": 1,
      "train[predictors]": 1,
      "x": 1,
      "x_tt": 1,
      "test_X_df": 1,
      "test[name].values.reshape(-1, 1)": 1,
      "X_test.loc[:, num]": 1,
      "train_features[col].values.reshape(-1, 1)": 1,
      "test_features[col].values.reshape(-1, 1)": 1,
      "y_train": 1,
      "x[cols]": 1,
      "test[cols]": 1,
      "train_df[Columns.scaling_cols.value]": 1,
      "test_df[Columns.scaling_cols.value]": 1,
      "X_tst": 1,
      "X_test[numeric_features]": 1,
      "x_test[col].values.reshape(-1, 1)": 1,
      "X_valid": 1,
      "Xtest": 1,
      "ytest.reshape(-1, 1)": 1,
      "features_test": 1,
      "test_df[feature_cols]": 1,
      "TestData": 1,
      "test_features": 1,
      "X_validation[num_list]": 1,
      "X_test[num_list]": 1,
      "train[col]": 1,
      "test[col]": 1,
      "train_data[col]": 1,
      "test_data[col]": 1,
      "test_X": 1,
      "test[feats_sorted]": 1,
      "x_train.values": 1,
      "x_test.values": 1,
      "df[[col]]": 1,
      "test_chunk": 1,
      "Test1": 1,
      "test_df": 1,
      "X_test_nn": 1,
      "np.array(train_data['Weeks']).reshape(-1, 1)": 1,
      "np.array(train_data['Percent']).reshape(-1, 1)": 1,
      "np.array(train_data['Age']).reshape(-1, 1)": 1,
      "np.array(test_data['Weeks']).reshape(-1, 1)": 1,
      "np.array(test_data['Percent']).reshape(-1, 1)": 1,
      "np.array(test_data['Age']).reshape(-1, 1)": 1
    },
    "sklearn.model_selection._split.train_test_split.stratify": {
      "None": 14558,
      "y": 665,
      "y_train": 86,
      "train_df.coverage_class": 63,
      "target": 49,
      "Y": 47,
      "balanced_train_df['ships']": 32,
      "train_labels": 28,
      "train_dfY": 25,
      "labels": 25,
      "y_true": 24,
      "df['label']": 22,
      "train.toxic.values": 22,
      "labels.label": 22,
      "train['target']": 19,
      "unique_img_ids['ships']": 19,
      "df.label.values": 17,
      "Y_train": 17,
      "dfx.label.values": 16,
      "y_target": 15,
      "y_train_full": 14,
      "labels.has_cactus": 14,
      "train_df['target']": 14,
      "df['defects']": 14,
      "train_y": 12,
      "train_df['Class'].map(lambda x: str(sorted(list(x))))": 12,
      "data['class_name']": 11,
      "rr_df['level']": 11,
      "df_data['label']": 11,
      "adv_y": 10,
      "train_data.target": 10,
      "df['target']": 10,
      "y_all": 10,
      "df_train.diagnosis": 10,
      "image_df['class']": 9,
      "targets": 9,
      "data_frame['label']": 9,
      "train.SN_filter": 9,
      "train.target": 9,
      "clearalllabels": 9,
      "train_target": 8,
      "df.Survived": 8,
      "train_df['label']": 7,
      "train_df.target": 6,
      "df.image_level.values": 6,
      "df.label": 6,
      "data['target']": 6,
      "data_y": 6,
      "train['isup_grade']": 6,
      "mask_df.labels": 6,
      "img_categ['CategoryId']": 6,
      "label": 5,
      "df1.Survived": 5,
      "train.diagnosis": 5,
      "id_mask_count['count']": 5,
      "train_data['stratify']": 5,
      "x_train['stratify']": 5,
      "y_train[:, i]": 5,
      "clearTrainLabel": 5,
      "train_df.label.values": 5,
      "train_df[target]": 5,
      "train['Target']": 5,
      "data['label']": 4,
      "unique_img_ids['counts']": 4,
      "external_train.target.values": 4,
      "Y_tr": 4,
      "cat_df['category']": 4,
      "train_valid['category']": 4,
      "df_train.target.values": 4,
      "df['category']": 4,
      "y_under": 4,
      "df.target": 4,
      "labels_train": 4,
      "train['label']": 4,
      "train['Survived']": 4,
      "trainLabels": 4,
      "train_df.labels.values": 4,
      "y_test": 4,
      "dfx.sentiment.values": 4,
      "train['sentiment']": 4,
      "dfx.encoded_labels.values": 4,
      "y_resampled": 4,
      "train_gp['class'].tolist()": 3,
      "target[:, 0]": 3,
      "y_valid": 3,
      "y['surface']": 3,
      "data['Target'].map(lambda x: x[:3] if '27' not in x else '0')": 3,
      "y_rus": 3,
      "df[classToPredict]": 3,
      "df.target.values": 3,
      "mnist.label": 3,
      "train_csv.diagnosis": 3,
      "train['labels']": 3,
      "df_all[df_all['id'].notnull()]['is_duplicate'].values": 3,
      "data['Survived']": 3,
      "train_data.landmark_id": 3,
      "X_train['sentiment']": 3,
      "train.iloc[:, 0]": 3,
      "y_data": 3,
      "df[f0]['target']": 3,
      "finalData['class_name']": 3,
      "train_val['delta']": 3,
      "y_trainval": 3,
      "rr_df['diagnosis']": 3,
      "X.toxic.values": 3,
      "meter_cut": 3,
      "y_train['surface']": 3,
      "image_df['Target'].map(lambda x: x[:3] if '27' not in x else '0')": 3,
      "test_batch.target.values": 3,
      "train_values": 3,
      "train_data_detail['label']": 3,
      "filter_train['target']": 3,
      "target_labels": 3,
      "self.y[tmask]": 2,
      "self.y[trainval_idx]": 2,
      "train_ohe_df['Label'].map(lambda x: str(sorted(list(x))))": 2,
      "df_merge['class']": 2,
      "train['fare-bin']": 2,
      "csv[['label']]": 2,
      "train_df['target'].tolist()": 2,
      "pre_y": 2,
      "train_df['target'].values": 2,
      "train_df['is_attributed']": 2,
      "labels[:, 27]": 2,
      "train_labels['label']": 2,
      "train_df['labels']": 2,
      "y.values": 2,
      "df_train.TARGET": 2,
      "train['chain']": 2,
      "patient_means > 0": 2,
      "train_df.has_cactus": 2,
      "y_new": 2,
      "all_train['Survived']": 2,
      "df.pass_stopped": 2,
      "train_validate.pass_stopped": 2,
      "df['target'].values": 2,
      "label_combinations.loc[non_unique_combo_bool_idx]": 2,
      "np.array(train_labels)": 2,
      "train_target[:, i]": 2,
      "np.array(target_labels)": 2,
      "train.label": 2,
      "train[target]": 2,
      "train['AdoptionSpeed']": 2,
      "train_df['label'].values": 2,
      "data.has_cactus": 2,
      "train['label_code']": 2,
      "np.array(Y_new)": 2,
      "label_combinations[non_unique_label_comb_bool_idx]": 2,
      "selected_imgs['has_ship']": 2,
      "train['has_cactus']": 2,
      "df['labels']": 2,
      "tr_df.diagnosis": 2,
      "df.sirna": 2,
      "train_data['target']": 2,
      "y_clust": 2,
      "birdcall_meta_samp[['ebird_code']]": 2,
      "df['author']": 2,
      "train.Survived": 2,
      "y_train_csv": 2,
      "df_train['label'].to_numpy()": 2,
      "y_targets": 2,
      "df['has_cactus']": 2,
      "train_texts['author_code']": 2,
      "train_df.diagnosis": 2,
      "train_img_df['images'].map(lambda x: '{}'.format(np.shape))": 2,
      "all_paths_df[['cat_id']]": 2,
      "pd.qcut(train_df['loss'], 10)": 2,
      "quora_best['target']": 2,
      "y_train_val": 2,
      "data_df[CLASSES]": 2,
      "stratify_df": 2,
      "y_val": 2,
      "data.Survived": 2,
      "traindf['label']": 2,
      "df_train.target": 2,
      "labels[:10000]": 2,
      "y_resample_cluster": 2,
      "train_preproc.target": 2,
      "train_df.target.values": 2,
      "df['label_group']": 2,
      "train_label": 2,
      "df_train['Class']": 2,
      "oversampled_trainY": 2,
      "y_train_all": 2,
      "train_df_whole[['class_id']].copy()": 2,
      "y_1": 2,
      "train_data['release_year']": 2,
      "input_data['class']": 2,
      "table_tp['species_id']": 2,
      "trainy": 2,
      "data.label": 2,
      "y_trn": 2,
      "Y_test": 2,
      "df['encoded_label_group'].values": 2,
      "df.diagnosis": 2,
      "y_train_data": 2,
      "inputData1['matchType']": 2,
      "train['category']": 2,
      "data['fare-bin']": 2,
      "train_df['defects']": 2,
      "ships_df['ships']": 2,
      "train_df['nb_labels']": 1,
      "train_data_y": 1,
      "imgLabelOhe": 1,
      "sub.loc[:, 'label']": 1,
      "all_df['is_train']": 1,
      "Y_full": 1,
      "df['disease_name']": 1,
      "y_sampletrain": 1,
      "image_map['names']": 1,
      "df_train_file_cat.category_id": 1,
      "df_train['isFraud']": 1,
      "_y_test": 1,
      "y_labels": 1,
      "reduced_train_df.target.values": 1,
      "train['is_attributed']": 1,
      "result_y": 1,
      "df.integer_label.values": 1,
      "dfx.diagnosis.values": 1,
      "trainy.Survived": 1,
      "alltrain_Y": 1,
      "ytrain": 1,
      "df['target'][idx]": 1,
      "types": 1,
      "train.target.to_list()": 1,
      "df_train['Finding']": 1,
      "df.category": 1,
      "train_data[train_data['length'] > 1]['Sentiment']": 1,
      "stratifiing_y": 1,
      "train_final['diagnosis']": 1,
      "train_csv['class_name']": 1,
      "d_masked['isup_grade']": 1,
      "y_t_m[column]": 1,
      "train_short.label": 1,
      "dataframe['class']": 1,
      "strata_train": 1,
      "y_over": 1,
      "endog_train": 1,
      "remaining.target.values": 1,
      "main_df['has_cactus']": 1,
      "train_data['label']": 1,
      "df['labels'].values": 1,
      "df_train_label.target.to_numpy()": 1,
      "sample_segmentations['ship_count']": 1,
      "train_df['Survived']": 1,
      "y_sp": 1,
      "dfY": 1,
      "df_qf['Label'].values": 1,
      "df_qf_val_test['Label'].values": 1,
      "df_stego['Label'].values": 1,
      "df_stego_val_test['Label'].values": 1,
      "df_balanced['target'].values": 1,
      "data_raw.target": 1,
      "train_df[self.target_filed]": 1,
      "y_prj": 1,
      "train_df.category_id": 1,
      "dataset['sentiment']": 1,
      "train['toxic']": 1,
      "balanced_train_df.target": 1,
      "y0": 1,
      "train_df.label": 1,
      "data.shot_made_flag": 1,
      "y_train_sample": 1,
      "all_y": 1,
      "df_target_num['hasMask']": 1,
      "data_d.iloc[:, 0]": 1,
      "train_df_subset['hotel_id']": 1,
      "train.Resp": 1,
      "df['is_duplicate']": 1,
      "train.cuisine": 1,
      "yTrain": 1,
      "train_df['target_round']": 1,
      "self.dataset[['label', 'language']]": 1,
      "tmp[['label', 'language']]": 1,
      "temp_labels": 1,
      "df_play.target": 1,
      "all_data.Survived": 1,
      "y_val_test": 1,
      "train['diagnosis'].values": 1,
      "data_new['Class']": 1,
      "target_train": 1,
      "data_train.TARGET": 1,
      "X_train['class']": 1,
      "train_df.sentiment.values": 1,
      "df_xy_bown['action']": 1,
      "train['hotel_id']": 1,
      "y_df['surface']": 1,
      "X_test['sentiment']": 1,
      "X['sentiment']": 1,
      "df['TARGET']": 1,
      "Labels": 1,
      "rr_df['level_a']": 1,
      "X_cov_class": 1,
      "self.df['ebird_code']": 1,
      "y_tr_full": 1,
      "train_df[label_column]": 1,
      "train[dependent_feat]": 1,
      "dl.train_df['target']": 1,
      "label_train": 1,
      "X.language_label": 1,
      "TRAIN['primary_label']": 1,
      "fare": 1,
      "valid_df.target": 1,
      "y_converted": 1,
      "transactions.target": 1,
      "clicks['is_attributed']": 1,
      "train_dataset['is_attributed']": 1,
      "df_merge['isTest'].values": 1,
      "train_data.coverage_class": 1,
      "train['class_name']": 1,
      "y_train_res": 1,
      "training_label": 1,
      "self.df['label']": 1,
      "df[label]": 1,
      "num_atoms": 1,
      "image_label_data['disease_name']": 1,
      "data['label_name']": 1,
      "train_df[['target']]": 1,
      "tr_df['diagnosis']": 1,
      "tr_df['has_cactus']": 1,
      "tr_df.sirna": 1,
      "df.cellline": 1,
      "df.site": 1,
      "train_stack[:, -1]": 1,
      "y_res": 1,
      "data.label.values": 1,
      "train[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']]": 1,
      "X[['Pclass']]": 1,
      "y_master_train": 1,
      "train_data.diagnosis": 1,
      "train['breed']": 1,
      "data.coverage": 1,
      "df['cuisine']": 1,
      "original_labels": 1,
      "all_data[target_name]": 1,
      "rescuer_ids['count']": 1,
      "y_j": 1,
      "cl": 1,
      "targetMLP": 1,
      "targetS": 1,
      "train['grapheme_root']": 1,
      "id_label['label']": 1,
      "convertedlabels": 1,
      "train_df['isup_grade']": 1,
      "df_type['open_channels']": 1,
      "[1, 2, 3, 4]": 1,
      "df[['label']]": 1,
      "resample_df['loan_status']": 1,
      "Y_sm": 1,
      "full_train_df['category']": 1,
      "any_category_positive": 1,
      "full_food_df['category']": 1,
      "toxicity_df['content_category']": 1,
      "pd.qcut(flat_train_df['defects_count'], 10)": 1,
      "total_toxicity": 1,
      "tweets.target": 1,
      "trainbase_2019_df[['diagnosis']]": 1,
      "trainbase_2015_df[['diagnosis']]": 1,
      "x['Sex']": 1,
      "train_merged.iloc[:, -1]": 1,
      "train_df.coverage": 1,
      "train_data.label": 1,
      "train['TARGET']": 1,
      "data.country_destination": 1,
      "train.sentiment": 1,
      "trainlabel": 1,
      "train_df[CLASSES]": 1,
      "df_train['label']": 1,
      "np.argmax(df_train[labels].to_numpy(), axis=1)": 1,
      "np.argmax(X_train[labels].to_numpy(), axis=1)": 1,
      "trainset.target.values": 1,
      "train_total.label": 1,
      "unique_img_ids['ships_count']": 1,
      "train_df['has_cactus']": 1,
      "source_Y": 1,
      "new_target": 1,
      "y_train['toxic']": 1,
      "train_df_master['target']": 1,
      "test_df['target']": 1,
      "y_train_cat": 1,
      "nm_y": 1,
      "y_test_val": 1,
      "target_df": 1,
      "train_tag['tag']": 1,
      "resamp_y": 1,
      "tweets[['target']]": 1,
      "classes": 1,
      "aux_data['Target']": 1,
      "y_2": 1,
      "train_map.label.values": 1,
      "y_train_k": 1,
      "train['author']": 1,
      "csum": 1,
      "_label": 1,
      "y_valid1": 1,
      "y_valid2": 1,
      "data.sentiment": 1,
      "y_inp": 1,
      "train['target'].values": 1,
      "df['fold']": 1,
      "df_train_shuffled.target": 1,
      "X[:, 0]": 1,
      "labels1": 1,
      "df_Train_path.coverage_class": 1,
      "df_train[target_column]": 1,
      "df[target_column]": 1,
      "siam_data['label']": 1,
      "class_info['class']": 1,
      "df.has_cactus": 1,
      "train.coverage_class": 1,
      "X['Sex']": 1,
      "external_train_df['target']": 1,
      "y_resample": 1,
      "train['target'].tolist()": 1,
      "train_model['sentiment']": 1,
      "train_sent['sentiment']": 1,
      "train_csv_df.has_cactus": 1,
      "np.array(labels)": 1,
      "df_in['maskCount']": 1,
      "df['isTest']": 1,
      "train_data.labels": 1,
      "y_copy": 1,
      "y_train_raw": 1,
      "image_ids.Mask": 1,
      "t_arr[:, 1]": 1,
      "y_bins": 1,
      "balanced['target'].values": 1,
      "input_dataframe['target']": 1,
      "y_train_pre_processed_original": 1,
      "new_train.sentiment.values": 1,
      "stratify": 1,
      "y_filtered": 1,
      "df_labels.label": 1,
      "Mlabel[:samlen]": 1,
      "y_sm": 1,
      "df_new['diagnosis']": 1,
      "data_train_cl.TARGET": 1,
      "train.bin": 1,
      "df['target_cat']": 1,
      "data_csv['class_name']": 1,
      "source[i]['target']": 1,
      "y_train['surface_label']": 1,
      "train_df.landmark_id.values": 1,
      "pre_train[target]": 1,
      "cv_y": 1,
      "data_detail['label']": 1,
      "non_moa_stratifier.values": 1,
      "new_train_df['isup_grade']": 1,
      "final_train['isup_grade']": 1,
      "output_500['mapped_label']": 1,
      "train_modified['Survived']": 1,
      "dummy_y": 1,
      "train['cuisine'].values": 1,
      "df['label'].values": 1,
      "tweet['target'].values": 1,
      "train_C14.target": 1,
      "train_C23.target": 1,
      "train_C12.target": 1,
      "train_C24.target": 1,
      "train_df['label_group']": 1,
      "df_train_ml['OverallQual']": 1,
      "labeled_sm.label": 1,
      "train_new[target_column]": 1,
      "train.has_cactus": 1,
      "Ttr_tar": 1,
      "train_df_whole[['defected']].copy()": 1,
      "df['salt'].values": 1,
      "train_data.target.values": 1,
      "history.repeater": 1,
      "self.df_train['target']": 1,
      "yvalid": 1,
      "train['class']": 1,
      "np.array(train['label'])": 1,
      "train_table['label']": 1,
      "np.array(Y_train)": 1,
      "labels['label']": 1,
      "target_raw": 1,
      "train['Category']": 1,
      "val_df.target": 1,
      "y_train_under": 1,
      "train['class'].values": 1,
      "df.image_label.values": 1,
      "df[['breed']]": 1,
      "en_notoxic_data['len']": 1,
      "train_data['lang_label']": 1,
      "label_data": 1,
      "split_data['int_ebird_code']": 1,
      "split_data['stratify']": 1,
      "outlier": 1,
      "train_labels_m['label']": 1,
      "owners_data.Target": 1,
      "clean_df['label']": 1,
      "train.Frequency": 1,
      "trainX.Frequency": 1,
      "udf['ClassId']": 1,
      "gp['class'].tolist()": 1,
      "train_dfx.label.values": 1,
      "labeled_sample.label": 1,
      "train.fare_amount_bin": 1,
      "new_train_df['target']": 1,
      "VALIDATION_LABELS": 1,
      "data_subset_images['landmark_id']": 1,
      "train.target.values": 1,
      "y[:, i]": 1,
      "train['target_bool']": 1,
      "y_real": 1,
      "all_data.diagnosis.values": 1,
      "df2['Label']": 1,
      "scores.stratify": 1,
      "S": 1,
      "te_y": 1,
      "mr_y_train": 1,
      "not_mr_y_train": 1,
      "traindf2.diagnosis": 1,
      "df_mutual['QuoteConversion_Flag']": 1,
      "df_RFE['QuoteConversion_Flag']": 1,
      "labelNameList": 1,
      "dataset['label']": 1,
      "spacegroup[:len(merged) - len(test)]": 1,
      "targets[i].values": 1,
      "data['target_bins'].values": 1,
      "train['is_turkey']": 1,
      "df['target_bin']": 1,
      "det1_total.iloc[:, -1]": 1,
      "det2_total.iloc[:, -1]": 1,
      "det3_total.iloc[:, -1]": 1,
      "proc_train_df.sirna": 1,
      "train_data.iloc[:, 1].values": 1,
      "y_gr_temp.surface": 1,
      "train_df['interest_level']": 1,
      "self.train_dataset.labels": 1,
      "train.author": 1,
      "train_df['name']": 1,
      "train_y_subsample": 1,
      "df['species_id']": 1,
      "np.array(train.label)": 1,
      "top_cats['category_id']": 1,
      "df['accuracy_group']": 1,
      "testtargets": 1,
      "y1": 1,
      "y_cuisine": 1,
      "img_lbl['label']": 1,
      "image_label": 1,
      "data['group'].values": 1,
      "data_frame.target.values": 1,
      "labels_df[label_col]": 1,
      "data['all']": 1,
      "train.label.values": 1,
      "labels['has_cactus']": 1,
      "y_beta": 1,
      "train_val_sampled['benign_malignant']": 1,
      "data_sample['labels']": 1,
      "train['diagnosis']": 1,
      "new_y": 1,
      "df_train['isup_grade']": 1,
      "train_df['sirna']": 1,
      "self.train_2019_df.diagnosis": 1,
      "y_dev_test": 1,
      "oh_us_train_df['target']": 1,
      "dataset_csv['diagnosis']": 1,
      "train_info.ebird_code_cat": 1,
      "resampled_df.ebird_code_cat": 1,
      "Y_data": 1,
      "train2['target']": 1,
      "train_csv['label']": 1,
      "train_val_df[train_val_df.columns[1:]]": 1,
      "app_train.TARGET": 1
    },
    "sklearn.model_selection._split.train_test_split.shuffle": {
      "True": 16545,
      "False": 263,
      "shuffle": 6,
      "1": 4,
      "self.shuffle": 4,
      "2": 2,
      "shuffle_data": 2,
      "y": 1,
      "0.2": 1,
      "'true'": 1
    },
    "sklearn.metrics._ranking.roc_auc_score.y_true": {
      "y_test": 953,
      "y_valid": 562,
      "y": 425,
      "train['target']": 418,
      "y_val": 416,
      "y_train": 385,
      "y_true": 292,
      "target": 263,
      "df_train['is_duplicate']": 168,
      "labels": 150,
      "self.y_val": 147,
      "valid_y": 124,
      "val_y": 119,
      "y_true[:, i]": 81,
      "train_df['TARGET']": 69,
      "train_y": 60,
      "yvalid": 57,
      "Y_test": 56,
      "train_df['target']": 55,
      "true_labels": 43,
      "true": 42,
      "test_y": 42,
      "train[target]": 41,
      "self.y": 39,
      "oof_tar[-1]": 39,
      "test_predictions[TARGET]": 38,
      "targets": 37,
      "Y_train": 37,
      "y_valid.tolist()": 36,
      "test_labels": 35,
      "valid_targets": 34,
      "train_target": 34,
      "Titanic_test_y": 32,
      "train.target.values": 29,
      "y_df": 28,
      "oof_targets_all[:, task_id]": 27,
      "X_valid[target].values": 27,
      "oof['target']": 26,
      "y_test.values": 26,
      "train_dfY": 25,
      "val_dfY": 25,
      "actual": 25,
      "RESULTS[TARGET]": 25,
      "target.iloc[val_idx]": 24,
      "y1": 24,
      "ts_y": 24,
      "train2['target']": 23,
      "np.array(t) >= 0.5": 22,
      "val_target": 22,
      "train.TARGET.values": 22,
      "vy": 21,
      "sick_vec": 20,
      "Y_val": 18,
      "y_true[mask]": 18,
      "results_df['target']": 18,
      "labs[:, i]": 18,
      "y_hold": 18,
      "self.y_train": 17,
      "y_": 17,
      "a": 17,
      "train_labels": 17,
      "y_actual": 16,
      "y.iloc[val_idx]": 16,
      "ytrain": 16,
      "y_va": 16,
      "yval": 16,
      "train['target'][idx1]": 16,
      "targs[:, i]": 15,
      "y[test]": 14,
      "target[val_idx]": 14,
      "blindtrain.TARGET.values": 13,
      "np.array(y_test)": 12,
      "label[:, i]": 12,
      "y_validate": 12,
      "y[i_val]": 12,
      "olid_test.toxic": 12,
      "olid_test1k.toxic": 12,
      "olid_test2k.toxic": 12,
      "olid_test5k.toxic": 12,
      "olid_test10k.toxic": 12,
      "ytest": 11,
      "yvl": 11,
      "y_.iloc[val_idx]": 11,
      "y_valid_cv": 11,
      "target_test": 11,
      "train.outcome.values": 11,
      "valid_labels": 10,
      "target_train": 10,
      "train_df.target.values": 10,
      "np.array(y_test)[:PUBLIC_CUTOFF]": 10,
      "np.array(y_test)[PUBLIC_CUTOFF:]": 10,
      "y_validation": 10,
      "self.y_true": 10,
      "xxx.target": 9,
      "test['is_attributed']": 9,
      "avreal": 9,
      "y_resampled": 9,
      "train['target'].values": 9,
      "v_y": 9,
      "train_df[target]": 9,
      "val_labels": 9,
      "df['target']": 9,
      "av_data[target]": 9,
      "preds": 9,
      "y_val[:, i]": 8,
      "fold_df.target": 8,
      "df_i.target": 8,
      "y_cv": 8,
      "target.values": 8,
      "test_df[target].values": 8,
      "y_valid[:, i]": 8,
      "np.argmax(valid_Y, -1) == 0": 8,
      "dfs2['target'] == mel_idx": 8,
      "public['target']": 8,
      "self.validation_data[1]": 8,
      "y_train_rus": 8,
      "y_test_rus": 8,
      "np.array(y_valid)": 8,
      "y_train_valid.astype('float32')": 8,
      "y_target.iloc[test_index]": 8,
      "to_np(last_target)": 7,
      "y_pred": 7,
      "np.vstack(y_true)": 7,
      "train.outcome": 7,
      "actual.reshape(-1)": 7,
      "Y": 7,
      "truths": 7,
      "y_train > 0.5": 7,
      "y_dev": 7,
      "valid['target']": 7,
      "pseudo_label[target_col]": 7,
      "1 - train['target']": 7,
      "df.target": 6,
      "train['action'].values": 6,
      "self.y_test": 6,
      "temp": 6,
      "oof_target": 6,
      "val_tgt": 6,
      "y_tr": 6,
      "y_train.values": 6,
      "labels.detach().cpu()": 6,
      "tt_df[TARGET]": 6,
      "[0] * (total - positive) + [1] * positive": 6,
      "bayes_y_test": 6,
      "np.rint(y_val)": 6,
      "y_pre": 6,
      "y.cpu().numpy()": 6,
      "target2": 6,
      "y_val_kf.values": 6,
      "df[target_col]": 6,
      "val_y_": 6,
      "mybest.toxic.round().astype(int)": 6,
      "ty": 6,
      "targets[:, j]": 5,
      "test_target": 5,
      "dev_y": 5,
      "bin_target.loc[test_index].values": 5,
      "y_val[class_name]": 5,
      "df_train['outcome']": 5,
      "pred": 5,
      "yTest": 5,
      "train2.loc[test_index]['target']": 5,
      "train['toxic'].values": 5,
      "valid[valid['lang'] == lang[key]].reset_index(drop=True)['toxic'].values": 5,
      "valid['toxic'].values": 5,
      "private['target']": 5,
      "train_Y": 5,
      "l": 5,
      "Yv": 5,
      "valid['toxic']": 5,
      "testy": 5,
      "Y[idx]": 5,
      "test[TARGET]": 5,
      "out_of_time[TARGET]": 5,
      "self.y_tra": 5,
      "train_df.iloc[valid_idx][target].values": 5,
      "labels.detach().cpu().numpy()": 5,
      "x": 5,
      "valid_y.astype(np.float32)": 5,
      "val_Y": 5,
      "Y_valid[:, i]": 5,
      "of.toxic.round().astype(int)": 5,
      "oy": 5,
      "valid[target_cols].values": 4,
      "y_train[:, i]": 4,
      "y_tst": 4,
      "train[j]": 4,
      "valid['is_attributed']": 4,
      "eval_y": 4,
      "y.values": 4,
      "y2": 4,
      "y.loc[valid_index]": 4,
      "targ.cpu().numpy()": 4,
      "examples[label]": 4,
      "val_targets": 4,
      "valid_y.values": 4,
      "Y[test]": 4,
      "target.values[:, st]": 4,
      "target.values[:, mc]": 4,
      "(TARGETS == mel_idx).astype(float)": 4,
      "(TARGETS[is_ext == 0] == mel_idx).astype(float)": 4,
      "dfs['target'] == mel_idx": 4,
      "dfs[dfs['is_ext'] == 0]['target'] == mel_idx": 4,
      "train['TARGET']": 4,
      "y_list": 4,
      "y_test_fold": 4,
      "train_df.iloc[val_idx]['target'].values": 4,
      "train_df.iloc[bayesian_val_index][target].values": 4,
      "clf.predict(test_set)": 4,
      "m.predict(X_train)": 4,
      "train.target": 4,
      "validY": 4,
      "ptrain['target']": 4,
      "test_valid_df['target']": 4,
      "_oof['target']": 4,
      "df_oof['target']": 4,
      "test['target'].values >= 0.5": 4,
      "Y_valid": 4,
      "1 - train2['target']": 4,
      "y_valid_idx": 4,
      "list(valid_translated.toxic)": 4,
      "y[:1000]": 4,
      "train_label": 4,
      "train_df[TARGET]": 4,
      "server_labels": 4,
      "test_set['binary_true'].values": 4,
      "test['action'].values.reshape(-1, 1)": 4,
      "t": 4,
      "y_target": 4,
      "y[target]": 4,
      "y0[0:lim]": 4,
      "y0[lim:y0.shape[0]]": 4,
      "y_test[x]": 4,
      "targets.detach().cpu().numpy()": 4,
      "label": 4,
      "train_df.TARGET": 4,
      "valid_df[track_column]": 4,
      "df_val['toxic']": 4,
      "y_test_b": 4,
      "cl_y": 4,
      "df_train.loc[:, 'target']": 4,
      "df_valid.loc[:, 'target']": 4,
      "df_train['TARGET']": 3,
      "df_train_[target_name]": 3,
      "tar": 3,
      "train_y.values": 3,
      "y_train[:, 1]": 3,
      "y_valid[:, 1]": 3,
      "y_test[:public_cutoff]": 3,
      "y_test[public_cutoff:]": 3,
      "y_te": 3,
      "y_test1": 3,
      "all_targets": 3,
      "test[target]": 3,
      "y_test[:, col]": 3,
      "train_target[val_idx]": 3,
      "gt": 3,
      "Y_test_split": 3,
      "val_targs.reshape(-1)": 3,
      "y[val_idx]": 3,
      "y_cv_test": 3,
      "TARGETS": 3,
      "yy": 3,
      "train['target'].iloc[idx1]": 3,
      "y_vl": 3,
      "val_y_fold": 3,
      "y_val.values": 3,
      "new_train['target']": 3,
      "y_true1": 3,
      "Y_train.values": 3,
      "target_wheezy[test_index]": 3,
      "target_wheezy[train_index]": 3,
      "train_target.iloc[val_idx]": 3,
      "y_valid_df": 3,
      "y.iloc[valid_idx]": 3,
      "y_eval": 3,
      "valid_X.target": 3,
      "y_train_fold": 3,
      "y_valid_fold": 3,
      "y_test[:, j]": 3,
      "train_part_df[target].values": 3,
      "ydat": 3,
      "Y_test.T": 3,
      "target_test_Public": 3,
      "target_test_Private": 3,
      "test_dset[target].values": 3,
      "trn_new.loc[trn_new['target_old'].notnull()]['target_old']": 3,
      "y_treino": 3,
      "validation_generator.classes": 3,
      "train_df.iloc[bayesian_val_idx][target].values": 3,
      "sample_y": 3,
      "sample_val_y": 3,
      "y_train_valid": 3,
      "tourney_results['win']": 3,
      "valid_label": 3,
      "trainfreq.isFraud": 3,
      "y[test_index]": 3,
      "y_test_split": 3,
      "label_arr[val_idx]": 3,
      "label_arr": 3,
      "val_true": 3,
      "target.get()": 3,
      "y_true_flat": 3,
      "predict": 3,
      "train.query('content_type_id == 0').answered_correctly.values": 3,
      "(train.loc[te]['resp'] > 0).astype('int').values.reshape(-1, 1)": 2,
      "y_test[:, i]": 2,
      "target_": 2,
      "df[target]": 2,
      "TARGETS[:, cid]": 2,
      "dfs.values[:, 1:-3].astype(float)[:, cid]": 2,
      "y.cpu().detach().numpy()": 2,
      "np.vstack(allActualPreds)": 2,
      "valid_fold_labels": 2,
      "y_val_f.values": 2,
      "y_train >= 0.5": 2,
      "yt": 2,
      "real": 2,
      "np.array(y_val)": 2,
      "y_true.reshape(-1)": 2,
      "test['toxic']": 2,
      "test[col]": 2,
      "OOF_CSV[0].target": 2,
      "TRUE": 2,
      "dff['isFraud']": 2,
      "y_test2": 2,
      "valid_data['target'].values": 2,
      "subgroup_df['target']": 2,
      "batch_y[:, 1]": 2,
      "Y.iloc[:, j]": 2,
      "np.array(targets) >= 0.5": 2,
      "df_validation.TARGET": 2,
      "self.answered_correctly": 2,
      "y_v": 2,
      "train_y_valid.astype('float32')": 2,
      "dtrain['target']": 2,
      "y_train[label_name]": 2,
      "y_val[label_name]": 2,
      "train_raw.iloc[valid_idx].target.values": 2,
      "df.iloc[valid_idx].target": 2,
      "valid_gt.T": 2,
      "yv": 2,
      "y[val_index]": 2,
      "saved_targets": 2,
      "vpred_y": 2,
      "y_train[i_train]": 2,
      "y_train[i_valid]": 2,
      "y_sample": 2,
      "label_df": 2,
      "y_cv_train": 2,
      "Y_valid.values": 2,
      "Y.values": 2,
      "y_true_train": 2,
      "y_true_val": 2,
      "df_preds.y_true": 2,
      "train_y[val_idx]": 2,
      "y.detach().cpu().numpy()": 2,
      "all_y_pu_pr": 2,
      "all_y_pu": 2,
      "all_y_pr": 2,
      "df_comb['HasDetections']": 2,
      "train3['d' + str(k)].values": 2,
      "train3[['d1', 'd2', 'd3', 'd4']].values.reshape(-1)": 2,
      "y_train[valid_index]": 2,
      "trn_istoxic": 2,
      "train_labels[holdout]": 2,
      "y_train1": 2,
      "target_np": 2,
      "train_target.values[val_idx]": 2,
      "train[label]": 2,
      "y_train[col]": 2,
      "np.round(train_pred)": 2,
      "np.round(valid_pred)": 2,
      "train.loc[train_used, 'target']": 2,
      "train.iloc[bayesian_val_idx][target].values": 2,
      "ytarget[:, n]": 2,
      "ytarget.flatten()": 2,
      "y[split:]": 2,
      "validLabels": 2,
      "train_targets.iloc[valid_id]": 2,
      "train_orig['target']": 2,
      "train_result_y": 2,
      "test_result_y": 2,
      "Ytarget.values": 2,
      "val['answered_correctly']": 2,
      "train_eval['signal']": 2,
      "df_fold['Label']": 2,
      "y_train.detach().to(device).numpy()": 2,
      "y_test.detach().to(device).numpy()": 2,
      "self.__testing_set[self.__predictive_variable]": 2,
      "df_train_naive['y']": 2,
      "df_test_naive['y']": 2,
      "results_df['HasDetections']": 2,
      "valy": 2,
      "y_truec": 2,
      "y_test[:validation_length]": 2,
      "y_test[validation_length:]": 2,
      "dvalid.label": 2,
      "temp_df[TARGET]": 2,
      "train[train.kfold != fold_i].target.values": 2,
      "train[train.kfold == fold_i].target.values": 2,
      "test.target.values": 2,
      "dtrain['TARGET']": 2,
      "xtePred[:, 1].round()": 2,
      "y_true_all": 2,
      "X_train.iloc[val_idx]['target'].values": 2,
      "fin_valid_df_rfc['target']": 2,
      "fin_valid_df_lr['target']": 2,
      "fin_valid_df_xgb['target']": 2,
      "TrueLabels": 2,
      "y_valid[:, task_idx]": 2,
      "pub_y": 2,
      "y_train_reg": 2,
      "y_train_nb": 2,
      "m.predict(X_val)": 2,
      "y_test_f": 2,
      "Ytest": 2,
      "cv_y": 2,
      "v_train_y": 2,
      "v_cv_y": 2,
      "self.targets": 2,
      "validate_y[v:v + 128]": 2,
      "y.values[te]": 2,
      "df['is_test']": 2,
      "pred_tr['target_y']": 2,
      "y_app_bureau_prev_pos_credit_test": 2,
      "df_valid.target.values": 2,
      "resnet50_test_data_gen.classes": 2,
      "Holdy": 2,
      "validate['is_attributed']": 2,
      "val_df['target'] > 0.5": 2,
      "target > 0.5": 2,
      "fold_ytest": 2,
      "y_train_csv": 2,
      "y_0_1": 2,
      "Y_true": 2,
      "valid_lab": 2,
      "y_res_test": 2,
      "label.cpu().detach().numpy()": 2,
      "all_df[TARGET]": 2,
      "np.array(y_train)": 2,
      "val['target']": 2,
      "y_smote_v": 2,
      "ground_truth": 2,
      "res['target']": 2,
      "(TARGETS == melanoma_idx).astype(float)": 2,
      "classes": 2,
      "train_file['is_duplicate']": 2,
      "y_labels[valid_idx]": 2,
      "validy": 2,
      "dtrain['Disbursed']": 2,
      "y_valid[:, 0]": 2,
      "trn2['target']": 2,
      "trn2.loc[trn2['target_old'].notnull()]['target_old']": 2,
      "trn2_add[trn2_add['target_old'].notnull()]['target_old']": 2,
      "test_gramolin['signal']": 2,
      "data['target']": 2,
      "m.predict(X_valid)": 2,
      "missing['miss_' + col_w_missing[i]]": 2,
      "fe_train.Choice.values": 2,
      "df_ytrain[test_index].values": 2,
      "df_train.target": 2,
      "y_ts": 2,
      "validate_df['binary_true'].values": 2,
      "identity_examples['binary_true'].values": 2,
      "tgts": 2,
      "target_val_small": 2,
      "y_values": 2,
      "val_y_npy": 2,
      "y.loc[val_idx]": 2,
      "valid_df.sentiment.values": 2,
      "y.iloc[val_idx].values": 2,
      "oof_val_true": 2,
      "test_true": 2,
      "df[get_target_feature()]": 2,
      "train['target'].iloc[fold_ids[0][1]]": 2,
      "train['target'].iloc[fold_ids[1][1]]": 2,
      "train['target'].iloc[fold_ids[2][1]]": 2,
      "train['target'].iloc[fold_ids[3][1]]": 2,
      "train['target'].iloc[fold_ids[4][1]]": 2,
      "oof[class_names[i_class]]": 2,
      "oof[class_names[i_class]].iloc[val_idx]": 2,
      "train.drop(labels=index_trn, axis=0)['target']": 2,
      "y_test_CV": 2,
      "d_test.toxic": 2,
      "y_train_valid_part": 2,
      "self._train_data['target']": 2,
      "labels[:lengte]": 2,
      "train_df['target'].values": 2,
      "y_true.T[i]": 2,
      "np.array(final_targets)": 2,
      "y_valid2": 2,
      "targets[:, k]": 2,
      "(y_val > 0.5).astype(int)": 2,
      "D_test.get_label()": 2,
      "val_gt_label_array": 2,
      "Y_TRUE": 2,
      "y_true_binary": 2,
      "TRAIN_TARGETS[:, n]": 2,
      "y.unsqueeze(1).detach().cpu().numpy()": 2,
      "y_val_sample": 2,
      "y_test_pca": 2,
      "train_df.target": 2,
      "target_list": 2,
      "labels_test": 2,
      "labels_train[:i * 1000]": 2,
      "y_preds": 2,
      "label_all": 2,
      "train.result": 2,
      "lootrain.outcome": 2,
      "label.view(-1).data.cpu().numpy()": 2,
      "val_y.ravel()": 2,
      "data[actual_label]": 2,
      "train_t['target']": 2,
      "Y_prob": 2,
      "y.iloc[idxT]": 2,
      "y.iloc[idxV]": 2,
      "df_val[df_val['lang'] == language]['toxic']": 2,
      "final_targets": 2,
      "np.array(val_labs)": 2,
      "train_data['target']": 2,
      "batch['target'].cpu().numpy()": 2,
      "train_target_array": 2,
      "solution": 2,
      "test_lab": 2,
      "prds.round().astype(int)": 2,
      "y_localval": 2,
      "y.cpu()": 2,
      "y_is9_validation": 2,
      "yf.values": 2,
      "data.loc[train_index, 'TARGET']": 1,
      "np.append(y_test, (1, 0))": 1,
      "cv_true": 1,
      "np.array(corr)": 1,
      "df.answered_correctly": 1,
      "y_train_split": 1,
      "y_valid_split": 1,
      "y_t": 1,
      "y_train.iloc[tes]": 1,
      "y_test_d": 1,
      "Y_p_x": 1,
      "class_labels": 1,
      "test_generator.classes": 1,
      "y_test[:PUBLIC_CUTOFF]": 1,
      "y_test[PUBLIC_CUTOFF:]": 1,
      "validation_y": 1,
      "valid_trues": 1,
      "valid_labels[:, i]": 1,
      "y_train_2": 1,
      "y_test_2": 1,
      "y_train_3": 1,
      "y_test_3": 1,
      "t_test": 1,
      "df_y_valid": 1,
      "test_data_gen.classes": 1,
      "y_01": 1,
      "y[t]": 1,
      "y[:, i]": 1,
      "y_tot[:, i]": 1,
      "dmvalid.get_label()": 1,
      "df[target].values": 1,
      "Y_tr_2": 1,
      "np.array(y_pred > 0.5, dtype='int')": 1,
      "kytest": 1,
      "ytrain['target']": 1,
      "y_train.loc[valid_index]": 1,
      "result": 1,
      "processed_dev_target": 1,
      "test_labels.astype('uint8')": 1,
      "val_df['target']": 1,
      "train[TARGET_COL]": 1,
      "new_train[TARGET_COL]": 1,
      "logModel.predict(X)": 1,
      "validation_labels": 1,
      "Y_test.astype('int32')": 1,
      "X_test_labels": 1,
      "train['target'].iloc[valid_idx]": 1,
      "final_y_train[valid_idx][:, 0]": 1,
      "dtrain[target].values": 1,
      "y_train_val": 1,
      "target.values[val_idx]": 1,
      "train3[dep_var].values[val_idx]": 1,
      "train_df[dep_var]": 1,
      "df_oof_no_isic2019['target']": 1,
      "rf_val_predictions": 1,
      "v['target']": 1,
      "vl_y": 1,
      "y_test_bin": 1,
      "train_df.target.astype(int).values": 1,
      "all_labels.ravel()": 1,
      "labels[:, i]": 1,
      "df.iloc[val_idx]['target']": 1,
      "newtrain1['target']": 1,
      "adversarial_y": 1,
      "_train['target']": 1,
      "train['isFraud']": 1,
      "validation_df[target].values": 1,
      "control": 1,
      "y[valid]": 1,
      "train2['d' + str(k)].values": 1,
      "train2[['d1', 'd2', 'd3', 'd4']].values.reshape(-1)": 1,
      "train.target.values[idxV2]": 1,
      "X_train.isFraud.to_array()": 1,
      "y_val_cv": 1,
      "RID_oof_df['target']": 1,
      "LGB_oof_df['target']": 1,
      "NN_oof_df['target']": 1,
      "Y_val_fold": 1,
      "chunk.answered_correctly": 1,
      "y_true[:, i].astype(int)": 1,
      "y_valid_l": 1,
      "y_valid_x": 1,
      "quora_train.target.values": 1,
      "test_df[target]": 1,
      "validation_set['has_cactus']": 1,
      "ys": 1,
      "y_cv[:, i]": 1,
      "y_train_selected[:, i]": 1,
      "y_train_array[:, i]": 1,
      "y_true_binarized": 1,
      "oo['target']": 1,
      "oof_df['target']": 1,
      "np.concatenate(oof_labels)": 1,
      "y_true3": 1,
      "y_true2": 1,
      "test_lbls": 1,
      "train2.loc[train_index]['target']": 1,
      "train2.loc[val_index]['target']": 1,
      "Y_val.values": 1,
      "train_toxic['toxic']": 1,
      "train['toxic']": 1,
      "Ytarget": 1,
      "tsty": 1,
      "test['TARGET']": 1,
      "total_labels": 1,
      "np.array(probs) > 0.5": 1,
      "train['answered_correctly']": 1,
      "data[int(95000000.0):, 'answered_correctly'].to_pandas()": 1,
      "ytest[:, 0]": 1,
      "ytest[:, 1]": 1,
      "ytest[:, 2]": 1,
      "ytest[:, 3]": 1,
      "ytest[:, 4]": 1,
      "[0] * (total - positive * 2) + [0, 1] * positive": 1,
      "[0] * (total - positive * 3) + [0, 0, 1] * positive": 1,
      "y_f_test": 1,
      "df_results['true']": 1,
      "Y_test_old": 1,
      "y_pseudo": 1,
      "y_LB": 1,
      "df_train['y']": 1,
      "df_test['y']": 1,
      "valid_fold[target]": 1,
      "df_train_smooth['y']": 1,
      "df_test_smooth['y']": 1,
      "df_train_cv['y']": 1,
      "df_test_cv['y']": 1,
      "Y_full.values": 1,
      "train_df['Survived']": 1,
      "y[ds]": 1,
      "y_test['toxic']": 1,
      "y_test['severe_toxic']": 1,
      "y_test['obscene']": 1,
      "y_test['threat']": 1,
      "y_test['insult']": 1,
      "y_test['identity_hate']": 1,
      "y_tra": 1,
      "train[dependent_feat]": 1,
      "val[dependent_feat]": 1,
      "y3_valid": 1,
      "y1.loc[val_idx]": 1,
      "y_label.values": 1,
      "y_vldt": 1,
      "df_train['target']": 1,
      "train['target_class']": 1,
      "train_dataset_df.query('group == 5')['is_related']": 1,
      "to_np(targ)": 1,
      "y_true[p]": 1,
      "target.cpu().numpy()": 1,
      "local_y_train": 1,
      "y_train[:i]": 1,
      "test[label_cols].values[:, index]": 1,
      "test[label_cols].values": 1,
      "preds.cpu().numpy()": 1,
      "val_df['Survived'].values": 1,
      "target.ravel()": 1,
      "y_train.iloc[valid_idx].values": 1,
      "train.loc[idx, 'target']": 1,
      "rf_results_df[TARGET]": 1,
      "df_train.loc[questions, 'answered_correctly']": 1,
      "y_true[:, 1]": 1,
      "to_np(y_true)": 1,
      "train[train['fold'] == fold][cols]": 1,
      "train[train['fold'] == fold][col]": 1,
      "val_df['Label']": 1,
      "pri_y": 1,
      "m.predict(X_tr)": 1,
      "m.predict(X_v)": 1,
      "oof_df.loc[val_idx, 'target']": 1,
      "true[:, i]": 1,
      "y_valid_list": 1,
      "train_pred['result']": 1,
      "y_val[:, -1]": 1,
      "data.iloc[val_idx]['target'].values": 1,
      "targ": 1,
      "oof['targets']": 1,
      "time_level_prediction['targets']": 1,
      "train_df_y": 1,
      "y_train_x": 1,
      "y_train_v": 1,
      "np.round(cancer_predictions).astype('int32')": 1,
      "y_fit": 1,
      "oof[class_true[i_class]]": 1,
      "np.array(oof_one.target)": 1,
      "train_df[target].values": 1,
      "y_app_test": 1,
      "y_app_bureau_test": 1,
      "y_app_bureau_prev_test": 1,
      "y_app_bureau_prev_pos_test": 1,
      "train_sample['isFraud']": 1,
      "valid_split['isFraud']": 1,
      "mobilenetv2_test_data_gen.classes": 1,
      "model_pred": 1,
      "First['Man']": 1,
      "Second['Man']": 1,
      "y_val_opt": 1,
      "valid_dataset.targets": 1,
      "targets_va": 1,
      "y_batch['is_attributed'].astype(int)": 1,
      "dtrain['is_attributed']": 1,
      "y_batch['is_attributed']": 1,
      "y_validate['is_attributed']": 1,
      "model.predict(X_val)": 1,
      "model.predict(X_test)": 1,
      "model.predict(X)": 1,
      "df_['Target']": 1,
      "y_Q1": 1,
      "y_Q2": 1,
      "y_Q3": 1,
      "y_Q4": 1,
      "uni[TGT]": 1,
      "train[idx_tr]['target']": 1,
      "y_batch.cpu()": 1,
      "train_target[valid_idx]": 1,
      "torch.cat(targs)": 1,
      "targs": 1,
      "ts": 1,
      "val2": 1,
      "y_valid.values": 1,
      "y_perfect": 1,
      "y_flliped": 1,
      "xpred[1]": 1,
      "ymat[:, ii]": 1,
      "train['Response']": 1,
      "train_label[valid_indices]": 1,
      "tt_df[mask][TARGET]": 1,
      "df[TOXICITY_COLUMN]": 1,
      "test_df['target']": 1,
      "torch.tensor(test_y).cpu().detach().numpy()": 1,
      "y_train[id_val]": 1,
      "valid['truth'].values": 1,
      "df_test[target].values": 1,
      "Target.iloc[val_idx]": 1,
      "Target": 1,
      "target_df": 1,
      "new_train['target'].iloc[-usefull_test.shape[0]:]": 1,
      "y_prob": 1,
      "true_label": 1,
      "y_adv": 1,
      "y_oof": 1,
      "y[test_idx]": 1,
      "target_val": 1,
      "Y_train.T": 1,
      "df_test_oh['target']": 1,
      "df_test_le['target']": 1,
      "ctargets": 1,
      "data_test[category]": 1,
      "validation_df['target'].values": 1,
      "y_val['action']": 1,
      "test_y > 0.5": 1,
      "train_df_all['outliers']": 1,
      "vallabels.detach().cpu().numpy()": 1,
      "dtest_y": 1,
      "[i[0] for i in y_val_lang]": 1,
      "val_merged.target_x": 1,
      "train_merged.target_x": 1,
      "trn['target']": 1,
      "dev_Y": 1,
      "true_result.cpu()": 1,
      "y_val_res": 1,
      "results": 1,
      "test_Y": 1,
      "y_np": 1,
      "y_batch": 1,
      "y_val_cat": 1,
      "y_val_small": 1,
      "trn_y_npy": 1,
      "(train.loc[te][target_cols[i]] > 0).astype('int').values.reshape(-1, 1)": 1,
      "target_train.iloc[val_idx]": 1,
      "target_train.iloc[trn_idx]": 1,
      "target_fake": 1,
      "true_valid_labels.reshape(-1, 1)": 1,
      "y_valCV[:, k]": 1,
      "y_valCVi": 1,
      "train_labels[:, i]": 1,
      "test_labels[:, i]": 1,
      "dtrain[target]": 1,
      "Statistics.idx2onehot(self.target)": 1,
      "new_actual_class": 1,
      "y_crossvalidation": 1,
      "val_ac": 1,
      "train_df2.iloc[val_idx]['target'].values": 1,
      "model.predict(X_test)[:, 1]": 1,
      "full_meta['is_train']": 1,
      "y_clf": 1,
      "train_true_list": 1,
      "valid_true_list": 1,
      "kfold_y_test": 1,
      "y_train == 1": 1,
      "y_test == 1": 1,
      "y_traintd": 1,
      "y_testtd": 1,
      "y_traincos": 1,
      "y_testcos": 1,
      "self.Y": 1,
      "d_test.toxic.drop(d_test.index[rows_to_delete])": 1,
      "valid_fold_y": 1,
      "y_test_": 1,
      "sample_y_val": 1,
      "batch_y.data.cpu().numpy()": 1,
      "target[train_idx]": 1,
      "target[tst_idx]": 1,
      "y[:, resp_type]": 1,
      "yvalid[:, resp_type]": 1,
      "train['action']": 1,
      "valid['action']": 1,
      "np.array(t)": 1,
      "df_valid.toxic.values": 1,
      "df_valid[df_valid.lang == lang].toxic.values": 1,
      "valid_df['toxic'].values": 1,
      "val_labels.view(-1).cpu()": 1,
      "dtrain[predlabel]": 1,
      "y_train[x]": 1,
      "y_val[x]": 1,
      "y[~mask]": 1,
      "y_train[0].values > 0.5": 1,
      "y_train_true": 1,
      "y_test_true": 1,
      "m.predict(train_X)": 1,
      "m.predict(val_X)": 1,
      "np.array(oof_01.target)": 1,
      "val_rust_idx": 1,
      "val_scab_idx": 1,
      "val_multiple_idx": 1,
      "val_healthy_idx": 1,
      "np.array(targets_reduced.cpu())": 1,
      "np.array(targets_reduced)": 1,
      "targetTest": 1,
      "pred[:, 0:1]": 1,
      "validation_set[1]": 1,
      "newy_stack": 1,
      "Y_test.values": 1,
      "tr_ef1['target']": 1,
      "tr_ef2['target']": 1,
      "tr_ef3['target']": 1,
      "tr_ef4['target']": 1,
      "X['answered_correctly']": 1,
      "y_true[:, label_num]": 1,
      "train_t": 1,
      "test_t": 1,
      "train_set[-1]": 1,
      "test_set[-1]": 1,
      "X_va['target']": 1,
      "tr['target']": 1,
      "valid_df['target'].values": 1,
      "TRAIN_TARGETS[te, tar]": 1,
      "yVal": 1,
      "y_train[::step]": 1,
      "y_test[::step]": 1,
      "self.val_target": 1,
      "torch.cat(tot_y_train_in).cpu().numpy()": 1,
      "torch.cat(tot_y_valid_out).cpu()": 1,
      "mia_y_test": 1,
      "y_train_train": 1,
      "y_batch_valid.data.cpu().numpy()": 1,
      "y_valid.to_numpy()": 1,
      "X['survived']": 1,
      "pred_train['target']": 1,
      "_actual": 1,
      "torch_y_val.cpu()": 1,
      "targets_val": 1,
      "train_true.cpu().detach().numpy()": 1,
      "val_true.cpu().numpy()": 1,
      "train_target[valid_index].values": 1,
      "tr.isFraud": 1,
      "train.is_attributed": 1,
      "a.isFraud": 1,
      "visibletrain.TARGET.values": 1,
      "train.TARGET": 1,
      "testtargets": 1,
      "traintargets": 1,
      "train.project_is_approved": 1,
      "label_validate": 1,
      "lab_train[test_index]": 1,
      "lab_train": 1,
      "lab_test": 1,
      "testFoldTarget": 1,
      "z.detach().cpu().numpy()": 1,
      "Y_eval": 1,
      "data['payout'].round()": 1,
      "labels.cpu().detach().numpy()": 1,
      "result_oof['target']": 1,
      "base[target]": 1,
      "train['target'].iloc[fold_ids[5][1]]": 1,
      "train['target'].iloc[fold_ids[6][1]]": 1,
      "train['target'].iloc[fold_ids[7][1]]": 1,
      "train['target'].iloc[fold_ids[8][1]]": 1,
      "train['target'].iloc[fold_ids[9][1]]": 1,
      "train['target'].iloc[fold_ids[10][1]]": 1,
      "train['target'].iloc[fold_ids[11][1]]": 1,
      "train['target'].iloc[fold_ids[12][1]]": 1,
      "train['target'].iloc[fold_ids[13][1]]": 1,
      "train['target'].iloc[fold_ids[14][1]]": 1,
      "train['target'].iloc[fold_ids[15][1]]": 1,
      "train['target'].iloc[fold_ids[16][1]]": 1,
      "train['target'].iloc[fold_ids[17][1]]": 1,
      "train['target'].iloc[fold_ids[18][1]]": 1,
      "train['target'].iloc[fold_ids[19][1]]": 1,
      "train['target'].iloc[fold_ids[20][1]]": 1,
      "train['target'].iloc[fold_ids[21][1]]": 1,
      "train['target'].iloc[fold_ids[22][1]]": 1,
      "train['target'].iloc[fold_ids[23][1]]": 1,
      "train['target'].iloc[fold_ids[24][1]]": 1,
      "t_y": 1,
      "df_train['isFraud']": 1,
      "np.array(y)": 1,
      "prev_answers": 1,
      "train_projected['target']": 1,
      "test_data['answered_correctly']": 1,
      "valid_df[target].astype('int32')": 1,
      "CLF_dict[c]['True'][:, ii]": 1,
      "Yval[:, ii]": 1,
      "evalid['toxic'].values": 1,
      "target_s": 1,
      "test['target']": 1,
      "train_df['HasDetections']": 1,
      "lb": 1,
      "valid[TARGET].astype('int32')": 1,
      "y_targets_all[:, task_id]": 1,
      "labels.squeeze(-1)": 1,
      "targ_np": 1,
      "df_train.TARGET.values": 1,
      "np.array(labels)[:, i]": 1,
      "pred[1]": 1,
      "targ.cpu()": 1,
      "t_reduced.cpu()": 1,
      "y_check": 1,
      "true_valid": 1,
      "train_targets": 1,
      "to_cpu(y_valid_)": 1,
      "to_cpu(y_valid)": 1,
      "train_qda['target']": 1,
      "train_pse['target']": 1,
      "train_GMM['target']": 1,
      "y_trues": 1,
      "target_tensor": 1,
      "self.targs": 1,
      "blindtest": 1,
      "tmp.isFraud": 1,
      "TARGET": 1,
      "train['target'].values[px]": 1,
      "df_val['label']": 1,
      "class_y_train": 1,
      "class_y_test": 1,
      "actions": 1,
      "verify1": 1,
      "(y_true == classes[i]).astype(int)": 1,
      "valid_target": 1,
      "val_true[:, i]": 1,
      "test_data.answered_correctly": 1,
      "np.array(train[:, 'HasDetections'])[:, 0]": 1,
      "cp.asnumpy(y_vl.flatten())": 1,
      "cp.asnumpy(y.flatten())": 1,
      "predictions": 1,
      "model.predict(X2)": 1,
      "y_train_pesudo": 1,
      "valtargets": 1,
      "valtargets_pesudo": 1,
      "y_test.reshape((6, 1))": 1,
      "target[val_index]": 1,
      "val_dfs.iloc[:, 1:-1]": 1,
      "solution.T[i]": 1,
      "true_list": 1,
      "y_val2": 1,
      "actuals": 1,
      "y_true[col]": 1,
      "sub.toxic.round().astype(int)": 1,
      "y_val.round().astype(int)": 1,
      "y.round().astype(int)": 1,
      "df2": 1,
      "y_true >= 0.5": 1,
      "y_train[valid_idx, 0] > 0.5": 1,
      "train['target'][IDX]": 1,
      "labels.detach().numpy()": 1,
      "y_test_5": 1,
      "eval_labels": 1,
      "valid_data['requester_received_pizza']": 1,
      "all_preds['y_true']": 1,
      "true_train_labels": 1,
      "true_valid_labels": 1,
      "T_valid": 1,
      "T_tr.values": 1,
      "T_va.values": 1,
      "Y[columns]": 1,
      "y.iloc[test_idx_3]": 1,
      "Y_validation": 1,
      "val['toxic']": 1
    },
    "sklearn.metrics._ranking.roc_auc_score.y_score": {
      "y_pred": 715,
      "oof": 442,
      "preds": 209,
      "oof_preds": 201,
      "pred": 162,
      "predictions": 148,
      "check": 84,
      "val_preds": 83,
      "oof_preds[valid_idx]": 83,
      "train_word_match": 80,
      "tfidf_train_word_match.fillna(0)": 80,
      "out_of_fold": 76,
      "y_pred[:, i]": 76,
      "probas": 73,
      "val_pred": 67,
      "y_pred_valid": 63,
      "oof_preds[val_idx]": 63,
      "pred[:, 1]": 61,
      "valid_preds": 61,
      "train_preds": 54,
      "outs": 50,
      "p": 47,
      "predicted_labels": 46,
      "y_pred_val": 44,
      "oof_pred[-1]": 39,
      "test_predictions['prediction']": 38,
      "np.array(train_res)": 36,
      "p_valid": 36,
      "oof[val_idx]": 35,
      "y_pred[:, 1]": 33,
      "train_pred": 28,
      "clf.predict_proba(X_train)[:, 1]": 28,
      "y_pred_prob": 27,
      "oof_preds_all[:, task_id]": 27,
      "y_pred_proba": 27,
      "prval": 27,
      "clf.predict_proba(tr)[:, 1]": 27,
      "valid_pred": 26,
      "gbc_clf_scores": 26,
      "oof['predict']": 25,
      "y_pred_train": 25,
      "preds[:, i]": 25,
      "y_hat": 25,
      "predictions_probas_list[:, 1]": 25,
      "yhat": 24,
      "gbc_val_scores": 24,
      "pred_val": 24,
      "ts_p": 24,
      "o": 23,
      "pred_test": 23,
      "y_valid_pred": 23,
      "y_val_pred": 22,
      "train_oof": 22,
      "torch.sigmoid(y_pred)[:, 1]": 22,
      "y_test": 22,
      "train_oof_preds": 22,
      "clf.predict_proba(X_test)[:, 1]": 22,
      "vp": 22,
      "pred_train": 21,
      "y_scores": 21,
      "sick_score": 20,
      "probs": 20,
      "logit_scores": 20,
      "predict": 19,
      "y": 19,
      "temp_oof": 19,
      "outputs": 18,
      "y_prob": 18,
      "oof[idx1]": 18,
      "y_pred[mask]": 18,
      "ensemble_holdout": 18,
      "oof_knn": 17,
      "proba": 17,
      "y_train_pred": 17,
      "ypred": 16,
      "oof2": 16,
      "y_oof": 16,
      "predictions_probas[:, 1]": 16,
      "x": 16,
      "oof_lr": 15,
      "pred[:, i]": 15,
      "prob": 15,
      "b": 15,
      "oof_pred": 15,
      "oof_svc": 14,
      "clf.predict_proba(X_sel, ntree_limit=clf.best_iteration)[:, 1]": 13,
      "y_score": 13,
      "dtrain_predprob": 13,
      "preds[test]": 13,
      "preds_val": 13,
      "probabilities": 13,
      "test_pred": 12,
      "logreg.predict(X_test)": 12,
      "oof_svnu": 12,
      "oof_qda": 12,
      "verySimpleLearner.predict_proba(validInputFeature)[:, 1]": 12,
      "predictions[0]": 12,
      "test_preds": 12,
      "model.predict_proba(X_val)[:, 1]": 12,
      "blind_preds": 12,
      "p[i_val]": 12,
      "olid_test.toxic_predict": 12,
      "olid_test1k.toxic_predict": 12,
      "olid_test2k.toxic_predict": 12,
      "olid_test5k.toxic_predict": 12,
      "olid_test10k.toxic_predict": 12,
      "model.predict(X_test)": 11,
      "y_pred_test": 11,
      "preds_train": 11,
      "oof_preds_[val_idx]": 11,
      "oof_preds_": 11,
      "y_valid_hat": 11,
      "oof[test_index]": 11,
      "pred_test[:, i]": 10,
      "pred_y": 10,
      "xgb_pred": 10,
      "val": 10,
      "class_pred": 10,
      "pre": 10,
      "m2_xgb.predict_proba(X_test)[:, 1]": 10,
      "y_val": 10,
      "result": 10,
      "y_preds": 10,
      "p_train": 10,
      "pred_train_y": 10,
      "y_train_predict": 10,
      "y_test_predict": 9,
      "valid_fold_preds": 9,
      "xxx.pred": 9,
      "predict_batch(clf, X)": 9,
      "scores_val": 9,
      "ytrain": 9,
      "y_pre": 9,
      "scores": 9,
      "Y_pred_rand": 9,
      "model.predict_proba(test_df)[:, 1]": 9,
      "sumpreds[:, i]": 9,
      "predicted": 9,
      "logit_scores_val": 9,
      "val_preds.cpu()": 9,
      "y_test_proba": 9,
      "self.y_pred": 9,
      "y_hat[:, 1]": 9,
      "fold_df.pred": 8,
      "df_i.pred": 8,
      "y_pred[:PUBLIC_CUTOFF]": 8,
      "y_pred[PUBLIC_CUTOFF:]": 8,
      "preds[:, 1]": 8,
      "val_preds[:, i]": 8,
      "model.predict(valid[FEATURES])": 8,
      "class_pred[val_idx]": 8,
      "pred_Y[:, 0]": 8,
      "val_preds.reshape(-1)": 8,
      "dfs2['pred']": 8,
      "logit_resampled_scores": 8,
      "y_scores_test": 8,
      "ns_probs": 8,
      "p_train2": 8,
      "p_train1": 8,
      "oof[valid_idx]": 8,
      "y_valid_proba": 8,
      "oof_mlp": 7,
      "oof_lrr": 7,
      "validation": 7,
      "predicted.reshape(-1)": 7,
      "train_predict": 7,
      "weakLearner.predict_proba(validInputFeatures)[:, 1]": 7,
      "prediction": 7,
      "y_train": 7,
      "oof_blend": 7,
      "y_pred1": 7,
      "valid_proba": 7,
      "tp": 7,
      "oof[idx_train[val_index]]": 7,
      "Y_pred": 7,
      "p_tst": 7,
      "pred_val_y": 7,
      "y_probs": 7,
      "lr.predict_proba(all_idf[val_idx])[:, 1]": 7,
      "traininv1": 7,
      "X_train_prob[1]": 7,
      "X_test_prob[1]": 7,
      "cv_pred": 6,
      "oof_svnu * 0.7 + oof_svc * 0.05 + oof_knn * 0.2 + oof_mlp * 0.05": 6,
      "oof[te]": 6,
      "yp": 6,
      "train_predictions": 6,
      "oof_prediction": 6,
      "model.predict(valid[FEATS])": 6,
      "oof_preds.ravel()": 6,
      "lgb_cv_result": 6,
      "model.predict(X_val)": 6,
      "to_np(preds[:, 1])": 6,
      "y_pred_score": 6,
      "oof_train": 6,
      "oof_ls": 6,
      "lr_pred": 6,
      "lr.predict_proba(X_test)[:, 1]": 6,
      "GBC_scores": 6,
      "tt_df['prediction']": 6,
      "tr_pred": 6,
      "oof_gmm": 6,
      "rf.oob_decision_function_[:, 1]": 6,
      "valid_prediction": 6,
      "np.array(proba)": 6,
      "benchmark_proba": 6,
      "test_y": 6,
      "model.predict_proba(test_X)[:, 1]": 6,
      "pre_class": 6,
      "op": 6,
      "tcn_predictions": 6,
      "nn_predictions": 6,
      "ensembeled": 6,
      "mybest.toxic.values": 6,
      "input": 5,
      "pred_train[:, i]": 5,
      "pred_val[:, i]": 5,
      "test_pred_proba": 5,
      "y_pred_rf": 5,
      "predictions[:, 1]": 5,
      "clf.predict(X_test)": 5,
      "guess_dev": 5,
      "np.vstack(y_predicted)": 5,
      "lr_avpred": 5,
      "xgb_cv_result": 5,
      "cb_cv_result": 5,
      "(lgb_cv_result + cb_cv_result) / 2": 5,
      "(lgb_cv_result + xgb_cv_result + cb_cv_result) / 3": 5,
      "y_prob[:, i]": 5,
      "model.predict_proba(X_train_tf)": 5,
      "OOF": 5,
      "y_pred_keras": 5,
      "model.predict_proba(test_df[features])[:, 1]": 5,
      "y_pred2": 5,
      "oof_nusvc": 5,
      "o[:, 1]": 5,
      "oof[bayesian_val_idx]": 5,
      "train['pred']": 5,
      "RESULTS[current_strategy]": 5,
      "oof_predict[test_index]": 5,
      "preds_valid": 5,
      "oof[idx]": 5,
      "Y_val": 5,
      "test_prediction": 5,
      "train_prediction": 5,
      "clf.predict_proba(X_val)[:, 1]": 5,
      "pred_test[:, 1]": 5,
      "y_pred_tra": 5,
      "outputs.detach().cpu().numpy()": 5,
      "predict(val_dist_dataset)": 5,
      "avg_pred": 5,
      "temp_fold_preds": 5,
      "val_preds_3[:, i]": 5,
      "of.toxic.values": 5,
      "pre_y2": 5,
      "y_pred_xgb": 4,
      "LOGITS[:, cid]": 4,
      "df.pred": 4,
      "avpred": 4,
      "y_prob_train[:, 1]": 4,
      "stack_model.predict_proba(X_train)[:, 1]": 4,
      "S_train[:, i]": 4,
      "pred['Mean'].fillna(0.5)": 4,
      "rfc_pred": 4,
      "val_f": 4,
      "predictions2": 4,
      "inp.cpu().numpy()": 4,
      "examples[model]": 4,
      "y_hat_test": 4,
      "yhat_test.eval()[:, 1]": 4,
      "predicts": 4,
      "val_y_pred": 4,
      "dfs['pred']": 4,
      "dfs[dfs['is_ext'] == 0]['pred']": 4,
      "verySimpleLearner.predict_proba(trainInputFeature)[:, 1]": 4,
      "oof_qda2": 4,
      "m.predict_proba(train)[:, 1]": 4,
      "m.predict_proba(test)[:, 1]": 4,
      "predictions[1]": 4,
      "preds.sigmoid().detach().cpu()": 4,
      "lr_probs": 4,
      "pred_proba": 4,
      "train_word_related": 4,
      "tfidf_train_word_share.fillna(0)": 4,
      "lgb_model.predict_proba(X_val)[:, 1]": 4,
      "Y_pred_class": 4,
      "y_hat[:, col]": 4,
      "test_label": 4,
      "Y_pred_train": 4,
      "oofPreds[validXId]": 4,
      "prob_pred": 4,
      "oof_var": 4,
      "oof_var2": 4,
      "0.5 * (oof_var + oof_var2)": 4,
      "_oof['pred']": 4,
      "pred[:, 0]": 4,
      "model.predict_proba(X_test)[:, 1]": 4,
      "lgbm_model.predict_proba(x_valid_idx)[:, 1]": 4,
      "lr.predict(X)": 4,
      "torch.sigmoid(outputs).detach().cpu().numpy()": 4,
      "y_prob[:, 1]": 4,
      "test_set['binary_prediction'].values": 4,
      "y_predict": 4,
      "model.predict(X_train)[:, -1]": 4,
      "model.predict(X_valid)[:, -1]": 4,
      "clf.predict_proba(X_test.values.reshape(-1, 1))[:, 1]": 4,
      "y1[0:lim, 0]": 4,
      "y1[lim:y0.shape[0], 0]": 4,
      "model.predict_proba(df[feature_col].replace(values_dict).values.reshape(-1, 1))[:, 1]": 4,
      "GP(train)": 4,
      "valid_df['predicted_target']": 4,
      "m.predict_proba(xs)[:, 1]": 4,
      "m.predict_proba(valid_xs)[:, 1]": 4,
      "m.oob_decision_function_[:, 1]": 4,
      "oof[idx1, 0] + oof[idx1, 1]": 4,
      "clf.predict_proba(train_x)[:, 1]": 4,
      "S_train_2.mean(axis=1)": 4,
      "cl_oof": 4,
      "val_preds_bce": 3,
      "out.cpu().detach().numpy()": 3,
      "y_scores_rf": 3,
      "predicted_probabilities": 3,
      "full_val_preds": 3,
      "oof_qda * 0.5 + oof_svnu * 0.35 + oof_svc * 0.025 + oof_knn * 0.1 + oof_mlp * 0.025": 3,
      "scores_val_run": 3,
      "y_prob_val[:, 1]": 3,
      "y_pred[:public_cutoff]": 3,
      "y_pred[public_cutoff:]": 3,
      "expit(cvdata[c])": 3,
      "np.array(test_preds)": 3,
      "np.array(test_preds)[:PUBLIC_CUTOFF]": 3,
      "np.array(test_preds)[PUBLIC_CUTOFF:]": 3,
      "np.full_like(temp, 0)": 3,
      "np.random.rand(len(temp))": 3,
      "oof_pred_deepfm": 3,
      "model.predict(x_tr)[:, 0]": 3,
      "model.predict(x_te)[:, 0]": 3,
      "proba[:, 1]": 3,
      "p[:, j]": 3,
      "probs[:, 1]": 3,
      "mlp_pred": 3,
      "predprobs": 3,
      "y_pred[:, col]": 3,
      "y_hat_train": 3,
      "oof1": 3,
      "oof3": 3,
      "oof4": 3,
      "val_predict": 3,
      "y_pred_lgb": 3,
      "y_valid": 3,
      "train_preds[:, fold // 5]": 3,
      "y_pred_lr[:, 1]": 3,
      "val_y_predict_fold": 3,
      "model.predict_proba(val_x)[:, 1]": 3,
      "ypred_valid": 3,
      "oof_lgb": 3,
      "oof_cb": 3,
      "val_predictions": 3,
      "y_val_pred[:, 1]": 3,
      "range(total)": 3,
      "cv_predict": 3,
      "lr.predict_proba(X_val)[:, 1]": 3,
      "val_preds[:, 1]": 3,
      "train_preds[:, 1]": 3,
      "pred_prob": 3,
      "RESULTS['no_validation_' + str(n_rounds)]": 3,
      "RESULTS['kfold']": 3,
      "RESULTS['stratifiedkfold']": 3,
      "RESULTS['lbo']": 3,
      "RESULTS['groupkfold_timeblocks']": 3,
      "RESULTS['groupkfold_uid']": 3,
      "preds_test": 3,
      "wt_avg": 3,
      "oof_GMM": 3,
      "yhat_prob": 3,
      "xgb_model.predict_proba(X_test)[:, 1]": 3,
      "model.predict(X)": 3,
      "val_pred / sub_train_n": 3,
      "nn_val_pred": 3,
      "Y_pred_test": 3,
      "self.preds": 3,
      "oof[class_preds[i_class]]": 3,
      "pred_valid": 3,
      "y_test_pred_gru": 3,
      "y_test_pred_lstm": 3,
      "gridcv.predict_proba(X_test)[:, 1]": 3,
      "lgbm.predict_proba(X_test)[:, 1]": 3,
      "valid_X.predict": 3,
      "test['challenger']": 3,
      "out_of_time['challenger']": 3,
      "lgbm.predict_proba(train_part_df[features])[:, 1]": 3,
      "y_pred_xgb_pr": 3,
      "test_predict": 3,
      "y_pred_xgboost": 3,
      "y_percs": 3,
      "y_percs_selected": 3,
      "pred_test_y": 3,
      "lre_oof_preds": 3,
      "clf.predict(train2)": 3,
      "y_proba": 3,
      "train['pred_avg']": 3,
      "train['pred_rank']": 3,
      "train['pred_power']": 3,
      "validation_predictions": 3,
      "rfr.oob_decision_function_[:, 1]": 3,
      "output.detach().cpu().numpy()": 3,
      "np.array([y.value_counts(normalize=True)[0]] * y.shape[0])": 3,
      "predicted_proba[:, -1]": 3,
      "y_val_pred_prob": 3,
      "y_train_pred_proba_logreg": 3,
      "pred[1]": 3,
      "train_proba": 3,
      "val_y": 3,
      "model.predict(x_train)": 3,
      "y_pred_gslgb": 3,
      "m.predict_proba(X_val)[:, 1]": 3,
      "valid_preds2": 3,
      "0.5 * valid_preds + 0.5 * valid_preds2": 3,
      "rankdata(valid_preds, method='dense') + rankdata(valid_preds2, method='dense')": 3,
      "val_pre": 3,
      "xgb_test_preds": 3,
      "cat_test_preds": 3,
      "lgbm_test_preds": 3,
      "oof_avg": 3,
      "oof_pred_arr": 3,
      "y_pred_flat": 3,
      "y_preds2": 3,
      "y_test_preds": 3,
      "train_pred_proba": 2,
      "pred_mean": 2,
      "valid_probs": 2,
      "np.vstack(allPreds)": 2,
      "valid_preds[valid_indices]": 2,
      "lr_cv_pred": 2,
      "ypred_cat": 2,
      "ypred_lgb": 2,
      "yproba": 2,
      "xgb_pred_val": 2,
      "lgb_pred_val": 2,
      "(xgb_pred_val + lgb_pred_val) / 2": 2,
      "y_pred.reshape(-1)": 2,
      "y_pred_acc": 2,
      "y_prediction[col]": 2,
      "x[:, k]": 2,
      "tmp": 2,
      "val_pred1": 2,
      "y_prediction": 2,
      "y_true": 2,
      "val_tf": 2,
      "trainedModel_B.predict_proba(df_news.loc[test_index])[:, 1]": 2,
      "trainedModel_C.predict_proba(df.loc[test_index])[:, 1]": 2,
      "dff[feature]": 2,
      "predictions1": 2,
      "clf.predict_proba(X_test, ntree_limit=clf.best_iteration)[:, 1]": 2,
      "all_preds": 2,
      "p_test": 2,
      "p_val": 2,
      "y_preds_lr": 2,
      "y_preds_lgb": 2,
      "weighted_preds": 2,
      "valid_preds.cpu()": 2,
      "l2_ridge_train_preds": 2,
      "l2_lgbm_train_preds": 2,
      "subgroup_df[model]": 2,
      "results_df['w/o pretrained']": 2,
      "results_df['fasttext']": 2,
      "results_df['glove']": 2,
      "results_df['numberbatch']": 2,
      "results_df['glove+fast']": 2,
      "results_df['weighted']": 2,
      "results_df['meta']": 2,
      "results_df['meta-glove+fasttext']": 2,
      "results_df['meta-weighted']": 2,
      "clf.predict_proba(X_valid, ntree_limit=clf.best_iteration)[:, 1]": 2,
      "features[f]": 2,
      "Y_pred.iloc[:, j]": 2,
      "clf.predict_proba(val_x)[:, 1]": 2,
      "self.predictions": 2,
      "tmp_val": 2,
      "rf.predict(X_test)": 2,
      "train_oof[valid_idx]": 2,
      "lgb_model.predict_proba(test_df)[:, 1]": 2,
      "model.predict_proba(test_df)[:, 1] * 0.8 + lgb_model.predict_proba(test_df)[:, 1] * 0.2": 2,
      "model.predict_proba(test_df)[:, 1] * i + lgb_model.predict_proba(test_df)[:, 1] * (1 - i)": 2,
      "preds_train[:, i]": 2,
      "preds_valid[:, i]": 2,
      "y_pred_log": 2,
      "val_preds[0][:, 1].numpy()": 2,
      "average_valid_predicts": 2,
      "pred_labels": 2,
      "valid_preds_fold": 2,
      "blend": 2,
      "y_train_pred_proba": 2,
      "y_predicted": 2,
      "indices": 2,
      "valid_probs_rs": 2,
      "y_vtest": 2,
      "model.predict_proba(X_sample)[:, 1]": 2,
      "LOGITS": 2,
      "clf.predict(data[train_features])": 2,
      "LOGITS[:, mel_idx]": 2,
      "LOGITS[is_ext == 0, mel_idx]": 2,
      "df_preds.y_pred": 2,
      "ans": 2,
      "y_pred_rfc[:, 1]": 2,
      "verySimpleLearner2.predict_proba(trainInputFeatures)[:, 1]": 2,
      "verySimpleLearner2.predict_proba(validInputFeatures)[:, 1]": 2,
      "clf.predict_proba(X_sel)[:, 1]": 2,
      "y_hat.detach().cpu().numpy()": 2,
      "all_preds_pu_pr": 2,
      "all_preds_pu": 2,
      "all_preds_pr": 2,
      "useless": 2,
      "train[str(i)]": 2,
      "predsPU": 2,
      "predsPR": 2,
      "train[i]": 2,
      "train3['o' + str(k)].values": 2,
      "train3[['o1', 'o2', 'o3', 'o4']].values.reshape(-1)": 2,
      "y_val_preds": 2,
      "y_hat_list": 2,
      "oof_nusvc2": 2,
      "x_train_second_layer.mean(1)": 2,
      "oof[col]": 2,
      "xgb_pred_valid": 2,
      "lgb_train_preds": 2,
      "ypred[:, n]": 2,
      "ypred.flatten()": 2,
      "val_pred[:, 1]": 2,
      "output.sigmoid().detach().cpu()": 2,
      "PREDS": 2,
      "oof_qda_vt": 2,
      "train_preds_result": 2,
      "test_preds_result": 2,
      "valid['pred']": 2,
      "blend_cv": 2,
      "output": 2,
      "data[int(95000000.0):, 'lgb_pred'].to_pandas()": 2,
      "train_eval_probs": 2,
      "df_fold['Pred']": 2,
      "torch.sigmoid(y_pred).detach().to(device).numpy()": 2,
      "torch.sigmoid(y_val).detach().to(device).numpy()": 2,
      "Y_pred_lr": 2,
      "Y_pred_knn": 2,
      "Y_pred_gnb": 2,
      "Y_pred_rf": 2,
      "gbc.predict_proba(df_train_naive[cat_cols])[:, 1]": 2,
      "gbc.predict_proba(df_test_naive[cat_cols])[:, 1]": 2,
      "results_df['Prediction']": 2,
      "y_predc": 2,
      "tmp_pred": 2,
      "y_train_prob": 2,
      "oof_bc_qda": 2,
      "oof_bc_knn": 2,
      "oof_gm": 2,
      "sub_preds": 2,
      "sub_preds_regular": 2,
      "sub_preds_weighted": 2,
      "y_hat[:validation_length, col]": 2,
      "RESULTS['lbo_full']": 2,
      "temp_df[current_strategy]": 2,
      "m.predict(valid_xs)": 2,
      "temp": 2,
      "prediction_list": 2,
      "y_pred_probability": 2,
      "yte": 2,
      "fin_valid_df_rfc['random_forest']": 2,
      "fin_valid_df_lr['logisticRegression']": 2,
      "fin_valid_df_xgb['xgboost']": 2,
      "oof_QDA[idx1]": 2,
      "oof_best": 2,
      "oof_QDA": 2,
      "oof_NuSVC": 2,
      "oof_fold['target'].values": 2,
      "oof['target'].values": 2,
      "pre_y": 2,
      "rf_oof_preds[valid_idx]": 2,
      "PredictionProb": 2,
      "task_pred[:, 1]": 2,
      "PROBS[:, mel_idx]": 2,
      "PROBS[is_ext == 0, mel_idx]": 2,
      "pub_pred": 2,
      "Y_train": 2,
      "model.predict(prepare_val(X_val, y_val), verbose=1)": 2,
      "all_predictions": 2,
      "np.mean(rankdata(oof_list, axis=1), axis=0) / oof_df.shape[0]": 2,
      "clf_non_cv.predict(X_test)": 2,
      "df_pred_final.values": 2,
      "df_scaled_final.values": 2,
      "Y_pred_true": 2,
      "oofPreds": 2,
      "v_pred": 2,
      "predict_y": 2,
      "pred_eval": 2,
      "predict_y_[:, 1]": 2,
      "predict_y[:, 1]": 2,
      "poof[idx1]": 2,
      "poof": 2,
      "final_prediction": 2,
      "model.predict_proba(X.values[te])[:, 1]": 2,
      "model.predict_proba(X_transformed_test)[:, 1]": 2,
      "pred_tr['target_x']": 2,
      "p[:, 1]": 2,
      "Y_prediction_RF": 2,
      "resnet50_model_predictions": 2,
      "lgb_pred": 2,
      "y_test_pred": 2,
      "predictions_va": 2,
      "xgb.predict_proba(X_test)[:, 1]": 2,
      "valid_prob": 2,
      "oof_gmm_2": 2,
      "log_reg_pred": 2,
      "knears_pred": 2,
      "svc_pred": 2,
      "tree_pred": 2,
      "p_fold": 2,
      "Nivel_1_train['train_yhat']": 2,
      "models[model_num].predict_proba(X_train)[:, 1]": 2,
      "models[model_num].predict_proba(X_test)[:, 1]": 2,
      "lgbm_best.predict(X_train)": 2,
      "lgbm_best.predict(X_test)": 2,
      "models[num].predict(X_train)": 2,
      "models[num].predict(X_test)": 2,
      "cb_pred": 2,
      "vc_pred": 2,
      "clf.predict(valid)": 2,
      "train_preds[valid_idx]": 2,
      "test_prediction2": 2,
      "Y_preds": 2,
      "m.predict(X_train)": 2,
      "m.predict(X_valid)": 2,
      "oof_predictions": 2,
      "outputs.cpu().detach().numpy()": 2,
      "all_df['preds']": 2,
      "estimator.predict(train_df[features_columns])": 2,
      "np.array(proba_train)": 2,
      "np.array(probabilities)": 2,
      "p_test[:, 1]": 2,
      "oof.catboost_oof": 2,
      "oof[idx1[test_index]]": 2,
      "res['preds']": 2,
      "prediction.T": 2,
      "predictions.T": 2,
      "model.predict(X_valid)": 2,
      "test_pred_Public": 2,
      "test_pred_Private": 2,
      "train.char_38": 2,
      "prediction[:, 1]": 2,
      "y_train_pred_log / num_fold": 2,
      "validation_prediction": 2,
      "oof_tmp": 2,
      "cat_pred": 2,
      "rf_pred": 2,
      "y_prob_batch[:, 1]": 2,
      "clf.predict_proba(x_ts)[:, 1]": 2,
      "weight_avg": 2,
      "validate_df['binary_prediction'].values": 2,
      "identity_examples['binary_prediction'].values": 2,
      "best_pred_val": 2,
      "output[:, 1] - output[:, 0]": 2,
      "score": 2,
      "xgpred[:, 1]": 2,
      "y_score[:, 1]": 2,
      "lr.predict_proba(train[features])[:, 1]": 2,
      "preds_oof_cum": 2,
      "preds_test_cum": 2,
      "preds_train_cum": 2,
      "preds_nn_oof": 2,
      "preds_nn_test": 2,
      "rfr.predict_proba(x_train)[:, 1]": 2,
      "rfr.predict_proba(x_valid)[:, 1]": 2,
      "preds.detach().cpu().numpy()": 2,
      "y_oof[val_idx]": 2,
      "y_pred_l": 2,
      "train_oof_3": 2,
      "oof_svm": 2,
      "0.6 * oof_svm + 0.4 * oof_lr": 2,
      "lgbm.predict(X_train)": 2,
      "lgbm.predict(X_test)": 2,
      "pd.read_csv('val_preds_fold_1.txt', header=None).values[:, 0]": 2,
      "pd.read_csv('val_preds_fold_2.txt', header=None).values[:, 0]": 2,
      "pd.read_csv('val_preds_fold_3.txt', header=None).values[:, 0]": 2,
      "pd.read_csv('val_preds_fold_4.txt', header=None).values[:, 0]": 2,
      "pd.read_csv('val_preds_fold_5.txt', header=None).values[:, 0]": 2,
      "preds_1": 2,
      "preds_2": 2,
      "oof_2": 2,
      "oof[class_preds[i_class]].iloc[val_idx]": 2,
      "est_train": 2,
      "y_pred_prob[:, 1]": 2,
      "trainModel(i).predict_proba(X_test)[:, 1]": 2,
      "lr.predict(X_test)": 2,
      "lgbm_clf.predict_proba(X_test)[:, 1]": 2,
      "oof_part": 2,
      "np.vstack(y_hat)": 2,
      "self._oof": 2,
      "predictions_probas": 2,
      "train_df['oof'].values": 2,
      "y_pred.T[i]": 2,
      "np.array(final_outputs)": 2,
      "model.predict_proba(X_train)[:, 1]": 2,
      "lgbm.predict_proba(X_train)[:, 1]": 2,
      "automl.predict(X_val)": 2,
      "automl.predict(X_train)": 2,
      "probabilities[:, k]": 2,
      "model_valid_predict": 2,
      "Y_PROBS": 2,
      "y_preds_binary": 2,
      "ytrain[:, n]": 2,
      "model_pred": 2,
      "y_pred.sigmoid().detach().cpu().numpy()": 2,
      "res_p[:, 1]": 2,
      "model.predict_proba(df[feature_col].values.reshape(-1, 1))[:, 1]": 2,
      "y_hat_4_7": 2,
      "y_hat_val": 2,
      "self.model.predict(self.validation_data[0], batch_size=self.predict_batch_size)": 2,
      "Y_predict": 2,
      "average_score['xgboost']": 2,
      "average_score['lgbm']": 2,
      "average_score['catboost']": 2,
      "average_score['average1']": 2,
      "average_score['average2']": 2,
      "average_score['average3']": 2,
      "average_score['average4']": 2,
      "average_score['average5']": 2,
      "average_score['average6']": 2,
      "oof_probas[val_idx]": 2,
      "oof_c": 2,
      "pred_list": 2,
      "pred_pr[:, 1]": 2,
      "pred_1": 2,
      "pred_all": 2,
      "x.values": 2,
      "ari": 2,
      "clf.predict_proba(train3[test_index, :])[:, 1]": 2,
      "isooof": 2,
      "GP1(train_df)": 2,
      "GP2(train_df)": 2,
      "cv_train": 2,
      "verySimpleLearner.predict_proba(trainInputFeatures)[:, 1]": 2,
      "verySimpleLearner.predict_proba(validInputFeatures)[:, 1]": 2,
      "xgb_clf.predict_proba(X_val)[:, 1]": 2,
      "y_pred_catboost": 2,
      "y_pred_avg": 2,
      "torch.sigmoid(output).view(-1).data.cpu().numpy()": 2,
      "df_holdout[column]": 2,
      "data[pred_label]": 2,
      "val_preds_EB7_lr": 2,
      "val_preds_xgb_1": 2,
      "0.5 * val_preds_xgb_1 + 0.5 * val_preds_EB7_lr": 2,
      "val_preds_EB4_lr": 2,
      "pred_train_mtx": 2,
      "xgb_clf.predict_proba(x_test)[:, 1]": 2,
      "gridcv.predict_proba(x_test)[:, 1]": 2,
      "lgb_clf.predict_proba(x_test)[:, 1]": 2,
      "y_predictedtrain": 2,
      "y_predictedCV": 2,
      "preds[tag]": 2,
      "tempPred[:, ii]": 2,
      "valid_cb": 2,
      "valid": 2,
      "esemble_lgbm_cat": 2,
      "esemble": 2,
      "y_scores_forest": 2,
      "oof_qda1": 2,
      "logreg.predict(X_train)": 2,
      "Z": 2,
      "to_cpu(y_pred_valid.data)": 2,
      "y_pred_split": 2,
      "m.predict_proba(xs[cols].iloc[idxT])[:, 1]": 2,
      "m.predict_proba(xs[cols].iloc[idxV])[:, 1]": 2,
      "df_val[df_val['lang'] == language]['pred']": 2,
      "y_scores[:, 1]": 2,
      "final_outputs": 2,
      "0.4 * (oof_qda.flatten() * 0.5 + oof_svnu.flatten() * 0.35 + oof_svc.flatten() * 0.025 + oof_knn.flatten() * 0.1 + oof_mlp.flatten() * 0.025) + 0.6 * oof_lrr": 2,
      "train_oof_lr_0": 2,
      "0.5 * train_oof_lgbm_0 + 0.5 * train_oof_lgbm_1": 2,
      "y_pred_res50": 2,
      "y_pred_res50v2": 2,
      "y_pred_res152": 2,
      "y_pred_res152v2": 2,
      "train['avg']": 2,
      "tr_preds2": 2,
      "stack_score": 2,
      "stack_score[:, i]": 2,
      "submission": 2,
      "(y_preds + y_preds2) * 0.5": 2,
      "y_preds3": 2,
      "(y_preds + y_preds3) * 0.5": 2,
      "p_lab": 2,
      "prds": 2,
      "y_proba > threshold": 2,
      "y_hat.sigmoid().detach().cpu()": 2,
      "df_train.loc[:, 'y_mle_pred']": 2,
      "df_train.loc[:, 'y_map_pred']": 2,
      "df_valid.loc[:, 'y_mle_pred']": 2,
      "df_valid.loc[:, 'y_map_pred']": 2,
      "res[1]": 2,
      "y_train_logreg_pred": 2,
      "y_val_logreg_pred": 2,
      "v['toxic']": 2,
      "model_lgb.predict(val[model_lgb.feature_name()])": 1,
      "model.predict(valid_feat[feat_cols])": 1,
      "clf.predict_proba(X_test)[:, -1]": 1,
      "s": 1,
      "clf.predict_proba(data.loc[train_index, train_columns])[:, 1]": 1,
      "test_pred_proba[valid_idx]": 1,
      "df_train[c]": 1,
      "prediction_train": 1,
      "y_pred_lrg": 1,
      "y_pred_knn": 1,
      "get_blended_prediction(df_train_, flag, params)": 1,
      "valid_score": 1,
      "train_pred['valid']": 1,
      "Y_pred_proba": 1,
      "np.append(np.where(prediction < 0.5, 0, 1), (1, 0))": 1,
      "val_preds_focal": 1,
      "val_preds_bce + val_preds_focal": 1,
      "rankdata(val_preds_bce, method='dense') + rankdata(val_preds_focal, method='dense')": 1,
      "pred1": 1,
      "np.array(preds)": 1,
      "df.preds": 1,
      "to_np(preds[:, -1])": 1,
      "clf.predict_proba(xtest)[:, 1]": 1,
      "outputs[:, j]": 1,
      "clf.predict_proba(x_opt)[:, 1]": 1,
      "model.predict(xvalid)": 1,
      "nb.predict(X_test)": 1,
      "tree.predict(X_test)": 1,
      "model.predict(X_test_d)": 1,
      "prediction_y": 1,
      "nbg.predict(x_test)": 1,
      "dt.predict(x_test)": 1,
      "forest_model.predict(x_test)": 1,
      "t_y": 1,
      "outOfFold": 1,
      "model_probs": 1,
      "predicted_probas": 1,
      "mod.predict_proba(X_val)[:, 1]": 1,
      "cvdata[c]": 1,
      "nn_test_predictions": 1,
      "m.predict(train_X)": 1,
      "m.predict(test_X)": 1,
      "model.predict(df_X)": 1,
      "model.predict(df_X_copy)": 1,
      "model.predict(X_train)": 1,
      "model.predict(X_train_2)": 1,
      "model.predict(X_test_2)": 1,
      "model.predict(X_train_3)": 1,
      "model.predict(X_test_3)": 1,
      "log_pred": 1,
      "gbm_pred": 1,
      "deepl_pred": 1,
      "predict_val": 1,
      "v": 1,
      "df[f]": 1,
      "pred_tot[:, i]": 1,
      "lgb.predict_proba(df.loc[test_index])[:, 1]": 1,
      "self.predict(self.x_train)[:, 1]": 1,
      "lr.predict_proba(X_valid)[:, 1]": 1,
      "gbm.predict_proba(X_valid)[:, 1]": 1,
      "lr.predict_proba(xv)[:, 1]": 1,
      "gbm.predict_proba(xv)[:, 1]": 1,
      "y_real": 1,
      "test_res": 1,
      "xgbmodel.predict(dtrain)": 1,
      "y_pred_test2_final_class": 1,
      "fraud_detection_pipeline.predict(X_train)": 1,
      "model_cat.predict_proba(test_df)[:, 1]": 1,
      "(xgb_cv_result + cb_cv_result) / 2": 1,
      "(xgb_cv_result + lgb_cv_result) / 2": 1,
      "aml_l2_ridge_train_preds": 1,
      "aml_l2_lgbm_train_preds": 1,
      "y_val_test": 1,
      "oofs.round()": 1,
      "cb_oofs * 1": 1,
      "rf_probs_train": 1,
      "rf_probs": 1,
      "clf_preds": 1,
      "clf3.predict_proba(val_x)[:, 1]": 1,
      "y_test.values": 1,
      "validation_outputs": 1,
      "y_pred_en": 1,
      "y_pred_xg": 1,
      "y_p": 1,
      "nbg.predict(X_test)": 1,
      "dt.predict(X_test)": 1,
      "xgb.predict(X_test)": 1,
      "train_pred[:, 1]": 1,
      "valid_pred[:, 1]": 1,
      "pred_lr_val": 1,
      "pred_svm_val": 1,
      "pred_xgb_val": 1,
      "model.predict(dtrain, ntree_limit=rounds)": 1,
      "model.predict(dvalid, ntree_limit=rounds)": 1,
      "dtrain_probabilities": 1,
      "classifier_etc.predict_proba(X_test)[:, 1]": 1,
      "classifier_k_best.predict_proba(X_test)[:, 1]": 1,
      "y_val_naive1": 1,
      "y_val_naive2": 1,
      "y_pred_nb": 1,
      "model.predict_proba(X_train_val)": 1,
      "p1[:, 1]": 1,
      "oof.values": 1,
      "y_scores_gbdt": 1,
      "y_scores_logreg": 1,
      "df_oof_no_isic2019['pred']": 1,
      "np.array(v['preds'])": 1,
      "vv_v": 1,
      "y_pred_score_bin": 1,
      "oof_preds.target.values": 1,
      "self._blend(oof, initial_weights)": 1,
      "self.blend(oof)": 1,
      "all_preds.ravel()": 1,
      "y_pred_proba_pca": 1,
      "predicting_probability[:, 1]": 1,
      "yv_prob": 1,
      "oof[val_index]": 1,
      "valid_probs_rf": 1,
      "valid_probs_xgb_single": 1,
      "train_probs_xgb_single": 1,
      "valid_probs_best": 1,
      "val_pred.cpu()": 1,
      "pipeline.predict_proba(X_train[i_train])[:, 1]": 1,
      "pipeline.predict_proba(X_train[i_valid])[:, 1]": 1,
      "model.predict_proba(X_train[i_train])[:, 1]": 1,
      "model.predict_proba(X_train[i_valid])[:, 1]": 1,
      "y_cv_train_predict_proba[:, 1]": 1,
      "y_cv_test_predict_proba[:, 1]": 1,
      "log.predict_proba(final_feature)[:, 1]": 1,
      "oof_main_avg": 1,
      "oof_tot": 1,
      "oof_single_target_avg": 1,
      "oof[:, st]": 1,
      "oof_main_avg[:, st]": 1,
      "oof_tot[:, st]": 1,
      "oof_single_target_avg[:, st]": 1,
      "oof[:, mc]": 1,
      "oof_main_avg[:, mc]": 1,
      "oof_tot[:, mc]": 1,
      "oof_single_target_avg[:, mc]": 1,
      "metLearn.predict_proba(X)[:, 1]": 1,
      "calib_pred": 1,
      "sig_pred": 1,
      "preds_class": 1,
      "y_pred_lr": 1,
      "ensemble_score": 1,
      "y_scorexgb": 1,
      "y_score2": 1,
      "model.predict_proba(validation_df[features])[:, 1]": 1,
      "y_pred_sgd[:, 1]": 1,
      "y_pred_gnb[:, 1]": 1,
      "y_pred_knc[:, 1]": 1,
      "clf.predict_proba(X_sel[valid], ntree_limit=clf.best_iteration)[:, 1]": 1,
      "y_train_pred_geom": 1,
      "train_predprob": 1,
      "rfc.predict_proba(X_valid)[:, 1]": 1,
      "rfc.predict_proba(X_v)[:, 1]": 1,
      "validation[:, 1]": 1,
      "ensemble_predsB": 1,
      "ensemble_preds": 1,
      "logr.predict_proba(train[[i]])[:, 1]": 1,
      "logr.predict_proba(public[[i]])[:, 1]": 1,
      "train2['o' + str(k)].values": 1,
      "train2[['o1', 'o2', 'o3', 'o4']].values.reshape(-1)": 1,
      "u0.dot(public.iloc[:, :-1].values.transpose())": 1,
      "u0.dot(private.iloc[:, :-1].values.transpose())": 1,
      "u2.dot(public.iloc[:, :-1].values.transpose())": 1,
      "u2.dot(private.iloc[:, :-1].values.transpose())": 1,
      "public[i]": 1,
      "predPU": 1,
      "predPR": 1,
      "oof_preds_NN": 1,
      "oof_preds_SVM": 1,
      "oof_preds_SVM + oof_preds_NN": 1,
      "oof[idxV2]": 1,
      "xgbclass.predict(X_test)": 1,
      "trn_pred": 1,
      "trn_aux": 1,
      "log_predictions": 1,
      "pcp_pred": 1,
      "logreg.predict(test_df)": 1,
      "clf.predict(test_df)": 1,
      "clf.predict(xv)": 1,
      "oof_qda[idx1]": 1,
      "oof_qda2[idx1]": 1,
      "oof_svnu[idx1]": 1,
      "oof_ens": 1,
      "oof_ens_stack": 1,
      "RID_oof_df['predictions']": 1,
      "LGB_oof_df['predictions']": 1,
      "NN_oof_df['predictions']": 1,
      "output_np": 1,
      "output_np[:, 1]": 1,
      "y_train_pred_log / 5": 1,
      "chunk.answered_correctly_pred": 1,
      "oof['target']": 1,
      "train_std_df['norm_2']": 1,
      "train_sk_stack_x_l2.mean(axis=1)": 1,
      "oof_gnb": 1,
      "model_lgb.predict(val_df[model_lgb.feature_name()])": 1,
      "(y_val_pred > 0.5) * 1": 1,
      "valid_preds_lgb": 1,
      "oof_preds[train_used]": 1,
      "expit(oof_preds[train_used])": 1,
      "xgb_train_preds": 1,
      "cb_train_preds": 1,
      "ridge_train_preds": 1,
      "sgd_train_preds": 1,
      "hgbc_train_preds": 1,
      "model.predict_proba(train)[:, 1]": 1,
      "first_gmm_valid_pred": 1,
      "gmm_add_valid_pred": 1,
      "new_gmm_valid_pred": 1,
      "first_aug_valid_pred": 1,
      "validDf['target']": 1,
      "norm_valid_df['target']": 1,
      "y_cv_pred[idx2, i]": 1,
      "y_train_selected_pred[idx1, i, k]": 1,
      "y_cv_pred[:, i]": 1,
      "roc_pred_list": 1,
      "y_pred_logreg": 1,
      "tuna_pred_test_proba": 1,
      "dt_class.predict(x)": 1,
      "rf_class.predict(y)": 1,
      "clf_adab.predict_proba(X_validation)[:, 1]": 1,
      "pred_valid_LSTMwith": 1,
      "pred_valid_df": 1,
      "oo['oof_prediction']": 1,
      "oof_df['oof_prediction']": 1,
      "train[i].values": 1,
      "np.concatenate(oof_preds)": 1,
      "oof_cb[val_idx]": 1,
      "preds_ensemble_val_on_train": 1,
      "preds_ensemble_val_on_val": 1,
      "preds_val_ens": 1,
      "y_pred3": 1,
      "pred_MNB": 1,
      "rfc.predict_proba(X_test)": 1,
      "cboost.predict(X_valid).reshape(-1)": 1,
      "cboost2.predict(X_valid2).reshape(-1)": 1,
      "train['preds_knn']": 1,
      "train['preds_mlp']": 1,
      "train['preds_svc']": 1,
      "train['preds_nusvc']": 1,
      "train['preds_qda']": 1,
      "train['preds_svcs']": 1,
      "train['preds_avg']": 1,
      "train['preds_avg2']": 1,
      "train_toxic['pred']": 1,
      "preds[indice]": 1,
      "y_train_predicted[:, 1]": 1,
      "y_dev_predicted[:, 1]": 1,
      "y_train_predicted": 1,
      "y_dev_predicted": 1,
      "predicted_proba_y": 1,
      "total_outputs": 1,
      "label_valid": 1,
      "model.predict(train.drop('answered_correctly', 1), categorical_feature=cat_cols)": 1,
      "model.predict(val.drop('answered_correctly', 1), categorical_feature=cat_cols)": 1,
      "np.concatenate(ol_preds)": 1,
      "np.concatenate(preds)": 1,
      "pipeline_RandomGrid.predict_proba(X_train)[:, 1]": 1,
      "pipeline_RandomGrid.predict_proba(X_test)[:, 1]": 1,
      "yhat[:, 0]": 1,
      "yhat[:, 1]": 1,
      "yhat[:, 2]": 1,
      "yhat[:, 3]": 1,
      "yhat[:, 4]": 1,
      "y_pred.round(0).astype(int)": 1,
      "train_preds_deep_model": 1,
      "xgb_model.predict_proba(X_train)[:, 1]": 1,
      "range(total)[::-1]": 1,
      "[total - 1] + list(range(total - 1))": 1,
      "list(range(total - 1)) + [-1]": 1,
      "list(range(total - 2)) + [-2, -1]": 1,
      "list(range(total - 3)) + list(range(-3, 0))": 1,
      "df_results['predict']": 1,
      "rf_predict_resampled": 1,
      "p_cv_predict": 1,
      "LB_pre": 1,
      "gbc.predict_proba(train_onehot)[:, 1]": 1,
      "gbc.predict_proba(test_onehot)[:, 1]": 1,
      "gbc.predict_proba(df_train_smooth[cat_cols])[:, 1]": 1,
      "gbc.predict_proba(df_test_smooth[cat_cols])[:, 1]": 1,
      "gbc.predict_proba(df_train_cv[cat_cols])[:, 1]": 1,
      "gbc.predict_proba(df_test_cv[cat_cols])[:, 1]": 1,
      "model.predict_proba(X_full)[:, 1]": 1,
      "average_all_df['average']": 1,
      "average_cat_df['average']": 1,
      "average_cont_df['average']": 1,
      "average_tuned_df['average']": 1,
      "y_predict_proba[ds]": 1,
      "toxic_prediction": 1,
      "severe_toxic_prediction": 1,
      "obscene_prediction": 1,
      "threat_prediction": 1,
      "insult_prediction": 1,
      "identity_hate_prediction": 1,
      "y_pred[test]": 1,
      "h_preds_.isFraud": 1,
      "preds.argmax(axis=1)": 1,
      "preds_2.argmax(axis=1)": 1,
      "preds_3.argmax(axis=1)": 1,
      "rfc.predict_proba(X_test)[:, 1]": 1,
      "rfc.predict_proba(X_t)[:, 1]": 1,
      "model.predict_proba(X_valid)[:, 1]": 1,
      "logreg.predict_proba(X_test)[:, 1]": 1,
      "rf.predict_proba(X_test)[:, 1]": 1,
      "y3_pred.round()": 1,
      "LR_probs": 1,
      "XGB_probs": 1,
      "LGBM_probs": 1,
      "LGBM_par_probs": 1,
      "y_pred_XGB": 1,
      "predict_rf": 1,
      "gs.predict_proba(X_test)[:, 1]": 1,
      "logit_searcher.predict_proba(X_test)[:, 1]": 1,
      "y_test_prob": 1,
      "y_proba_pred": 1,
      "cv_val": 1,
      "y_pred_0": 1,
      "train['class_preds']": 1,
      "probs1": 1,
      "lr_predict": 1,
      "cat_predict": 1,
      "off_predict": 1,
      "y_pred_proba_xgb_default[:, 1]": 1,
      "y_pred_proba_xgb[:, 1]": 1,
      "model.predict_proba(train_dataset_df.query('group == 5').iloc[:, 4:])[:, 1]": 1,
      "bst.predict(train_mat)": 1,
      "bst.predict(test_mat)": 1,
      "to_np(np.exp(inp[:, 1]))": 1,
      "predics": 1,
      "oof_preds[val_index]": 1,
      "predicted_probs": 1,
      "rf_RandomGrid.predict_proba(X_train)[:, 1]": 1,
      "rf_RandomGrid.predict_proba(X_test)[:, 1]": 1,
      "p4.predict_proba(X_train)[:, 1]": 1,
      "p4.predict_proba(X_test)[:, 1]": 1,
      "xgb_RandomGrid.predict_proba(X_train)[:, 1]": 1,
      "xgb_RandomGrid.predict_proba(X_test)[:, 1]": 1,
      "model.predict(x_val)": 1,
      "y_pred_logistic": 1,
      "y_pred_gnb": 1,
      "y_pred_dt": 1,
      "np.mean(prob_all_train, axis=0)": 1,
      "train['TARGET2']": 1,
      "y_score[p]": 1,
      "y_score_all": 1,
      "y_score_all_norm": 1,
      "preds.cpu().numpy()": 1,
      "predictions_bin": 1,
      "predictions_NN_01": 1,
      "clf.predict(np.expand_dims(X_test, axis=-1))": 1,
      "oof[local_train_idx, reg_idx]": 1,
      "oof[:, reg_idx]": 1,
      "xgbooster.predict_proba(X_train[:i], ntree_limit=xgbooster.best_iteration)[:, 1]": 1,
      "xgbooster.predict_proba(X_test, ntree_limit=xgbooster.best_iteration)[:, 1]": 1,
      "preds[:, index]": 1,
      "y_pred_train_hyper": 1,
      "y_pred_hyper": 1,
      "m.predict_proba(X_train)[:, 1]": 1,
      "m.predict_proba(X_valid)[:, 1]": 1,
      "xgboost.predict_proba(X_train)[:, 1]": 1,
      "oof_QDA2[idx1]": 1,
      "oof_QDA2": 1,
      "oof_GMM[idx1]": 1,
      "oof_NuSVC[idx1]": 1,
      "oof_KNN[idx1]": 1,
      "oof_MLP[idx1]": 1,
      "oof_KNN": 1,
      "oof_MLP": 1,
      "float(results[i][0]) * oof + float(results[i][1]) * oof_2 + float(results[i][2]) * oof_3 + float(results[i][3]) * oof_4 + float(results[i][4]) * oof_5": 1,
      "y_preds_rand": 1,
      "logreg.predict(X_val1)": 1,
      "oof_highest": 1,
      "y_validate_p": 1,
      "model_lr.predict(X_test)": 1,
      "lgb_oof_preds": 1,
      "train_preds[idx]": 1,
      "rf_results_df['RFHasDetScore']": 1,
      "y_cv_train_pred": 1,
      "y_cv_test_pred": 1,
      "df_train.loc[questions, 'answered_correctly']": 1,
      "to_np(F.sigmoid(y_pred))[:, 1]": 1,
      "pred_prob[:, 1]": 1,
      "stack_final_pred": 1,
      "y_test_score[:, 1]": 1,
      "r": 1,
      "r[col]": 1,
      "pri_pred": 1,
      "Y_tp": 1,
      "Y_vp": 1,
      "Y_tr": 1,
      "Y_v": 1,
      "y_train_pred_rf": 1,
      "y_train_pred_gbm": 1,
      "y_train_pred_lgbm": 1,
      "y_train_pred_xgboost": 1,
      "y_train_pred_all": 1,
      "y_valid_pred_rf": 1,
      "y_valid_pred_gbm": 1,
      "y_valid_pred_lgbm": 1,
      "y_valid_pred_xgboost": 1,
      "y_valid_pred_all": 1,
      "(y_train_prob_tree[:i + 1].mean(0) > 0.5).astype(int)": 1,
      "(y_valid_prob_tree[:i + 1].mean(0) > 0.5).astype(int)": 1,
      "model_rf_fin.predict(X)": 1,
      "model.predict_proba(X)[:, 1]": 1,
      "train_mat": 1,
      "k": 1,
      "train['pre']": 1,
      "train_oof_lgbm_0": 1,
      "y_hat_mean": 1,
      "train_pred['mean']": 1,
      "action": 1,
      "df_oof['pred']": 1,
      "clf.predict_proba(X_val.drop(cols_to_drop, axis=1))[:, 1]": 1,
      "clf.predict_proba(X_test.drop(cols_to_drop, axis=1))[:, 1]": 1,
      "clf_f.predict_proba(X_test_f)[:, 1]": 1,
      "clf_f.predict_proba(X_test_f.drop(cols_to_drop_f, axis=1))[:, 1]": 1,
      "clf.predict_proba(X_val.drop(cols_to_drop + cols_to_drop_f, axis=1))[:, 1]": 1,
      "clf.predict_proba(X_test.drop(cols_to_drop + cols_to_drop_f, axis=1))[:, 1]": 1,
      "blend_preds": 1,
      "out": 1,
      "oof['pred']": 1,
      "time_level_prediction['pred']": 1,
      "clf.predict_proba(train_df_X[train_columns])[:, 1]": 1,
      "rankdata(oof_rank)": 1,
      "prodict_prob_y": 1,
      "results_valid": 1,
      "predict_y_train": 1,
      "test_targets": 1,
      "clf.predict_proba(X_eval)[:, 1]": 1,
      "clf.predict_proba(X_fit)[:, 1]": 1,
      "predictions_lgbm_01": 1,
      "y_fitted": 1,
      "1 - oof": 1,
      "oof_svnu * 0.65 + oof_svc * 0.1 + oof_knn * 0.2 + oof_lr * 0.05": 1,
      "tab_net.predict_proba(X_val)[:, 1]": 1,
      "res['answered_correctly'].values": 1,
      "res[target].values": 1,
      "preds_proba[:, 1]": 1,
      "log_preds": 1,
      "tree_preds": 1,
      "xgb_preds": 1,
      "rf_preds": 1,
      "ada_preds": 1,
      "voting_preds": 1,
      "predictions_app[:, 1]": 1,
      "predictions_app_bureau[:, 1]": 1,
      "predictions_app_bureau_prev[:, 1]": 1,
      "predictions_app_bureau_prev_pos[:, 1]": 1,
      "predictions_app_bureau_prev_pos_credit[:, 1]": 1,
      "predictions['prediction']": 1,
      "p_binary": 1,
      "p['.1']": 1,
      "p['.2']": 1,
      "p['.3']": 1,
      "p['.4']": 1,
      "p['.5']": 1,
      "p['.6']": 1,
      "p['.7']": 1,
      "p['.8']": 1,
      "p['.9']": 1,
      "Y_pred_grid": 1,
      "oof_rf": 1,
      "oof_knn2": 1,
      "oof_svc2": 1,
      "oof_svnu2": 1,
      "oof_rf2": 1,
      "oof_mlp2": 1,
      "oof_qda2 * 0.6 + oof_svnu2 * 0.25 + oof_svc2 * 0.05 + oof_rf2 * 0.1": 1,
      "oof_qda2 * 0.5 + oof_svnu2 * 0.3 + oof_svc2 * 0.05 + oof_knn2 * 0.025 + oof_rf2 * 0.1 + oof_mlp2 * 0.025": 1,
      "true": 1,
      "pred_probs": 1,
      "mobilenetv2_model_predictions": 1,
      "oof_svnu * 0.6 + oof_svc * 0.1 + oof_knn * 0.2 + oof_lr * 0.1": 1,
      "roc_predictions": 1,
      "Holdgrouped['MLPPred']": 1,
      "First['Pred']": 1,
      "Second['Pred']": 1,
      "y_pred_opt": 1,
      "y_pred_proba[:, 0]": 1,
      "full_val_preds[val_idx]": 1,
      "prod_odds": 1,
      "1 / prob1": 1,
      "prob2 / prob1": 1,
      "(oof_gmm + oof_gmm_2) / 2": 1,
      "clf.predict_proba(X_, num_iteration=clf.best_iteration_)[:, 1]": 1,
      "y_val.values.ravel()": 1,
      "y_test.values.ravel()": 1,
      "y.values.ravel()": 1,
      "YY": 1,
      "pred_adv": 1,
      "pred_valid_avg": 1,
      "RFC.predict_proba(X_train)[:, 1]": 1,
      "RFC.predict_proba(X_test)[:, 1]": 1,
      "LGBMC.predict_proba(X_train)[:, 1]": 1,
      "LGBMC.predict_proba(X_test)[:, 1]": 1,
      "predict_models_RFC(rf_models, X_train_csv_encoded)": 1,
      "predict_models_LGBM(lgbm_models, X_train_csv_encoded)": 1,
      "prob_y": 1,
      "oof2 * 0.35 + oof3 * 0.25 + oof4 * 0.4": 1,
      "q1_y_pred": 1,
      "q2_y_pred": 1,
      "q3_y_pred": 1,
      "q4_y_pred": 1,
      "model_svc.predict(X_test)": 1,
      "oof_qda * 0.8 + oof_svnu * 0.2": 1,
      "oof_qda * 0.7 + oof_svnu * 0.3": 1,
      "oof_qda * 0.65 + oof_svnu * 0.35": 1,
      "oof_qda * 0.6 + oof_svnu * 0.4": 1,
      "oof_qda * 0.5 + oof_svnu * 0.5": 1,
      "oof_qda * 0.4 + oof_svnu * 0.6": 1,
      "oof_qda * 0.3 + oof_svnu * 0.7": 1,
      "oof / counter": 1,
      "pL[:, j]": 1,
      "pC[:, j]": 1,
      "pH[:, j]": 1,
      "train['target_final']": 1,
      "rfc.predict(X_test)": 1,
      "rfc.predict(X_t)": 1,
      "oof_preds_lgb.ravel()": 1,
      "et_oof_train": 1,
      "rf_oof_train": 1,
      "ada_oof_train": 1,
      "gb_oof_train": 1,
      "clffinal.predict(train_X)": 1,
      "xgb1.predict(train_X)": 1,
      "xgb2.predict(train_X2)": 1,
      "y_pred_df": 1,
      "ypred[:, 1]": 1,
      "sigmoid(y_pred.cpu().numpy())[:, 0]": 1,
      "train_predict_prob[:, 1]": 1,
      "torch.cat(preds)": 1,
      "preds.softmax(-1)[:, 1]": 1,
      "m.predict(X_train[imp_cols])": 1,
      "m.predict(X_valid[imp_cols])": 1,
      "ys": 1,
      "model_lgb.predict(val_m_train)": 1,
      "lgb_clf.predict(x_valid.values.reshape(-1, 1))": 1,
      "y_flliped": 1,
      "predictions_proba[:, 1]": 1,
      "mvalid[id1, 0]": 1,
      "mvalid": 1,
      "xpred[0][:, 1]": 1,
      "prmat": 1,
      "prv": 1,
      "prval[id1, 0]": 1,
      "predval[test_index, lab_ind]": 1,
      "predval[:, ii]": 1,
      "y_preds_log_reg": 1,
      "y_res_preds_log_reg": 1,
      "y_res_pred": 1,
      "cnn_oof[val_idx, CFG['targets'].index(label)]": 1,
      "lgb_oof[val_idx, CFG['targets'].index(label)]": 1,
      "y_pred_bag": 1,
      "gam.predict_proba(x_val[:, var_ind])": 1,
      "y_pred / 2": 1,
      "rf_wrapper.predict_proba(X_valid)[:, 1]": 1,
      "gbc_wrapper.predict_proba(X_valid)[:, 1]": 1,
      "lgbm_wrapper.predict_proba(X_valid)[:, 1]": 1,
      "(cat_model.predict_proba(X_valid)[:, 1] > 0.5).astype(int)": 1,
      "valid_scores[valid_indices]": 1,
      "valid_scores": 1,
      "tt_df[mask]['prediction']": 1,
      "df[model_name]": 1,
      "estimator.predict_proba(train_df[features_columns])[:, 1]": 1,
      "(pred > 0.5).astype(int)": 1,
      "oof[fold]": 1,
      "lr_pred[:, 1]": 1,
      "rc_pred[:, 1]": 1,
      "pred.cpu().detach().numpy()": 1,
      "pred_train[:, 1]": 1,
      "y_train_pred_logit": 1,
      "y_train_pred_xgb": 1,
      "pred_i": 1,
      "pred_xtest": 1,
      "mean_preds_test": 1,
      "full_preds_test": 1,
      "valid['proba'].values": 1,
      "preds.cpu().numpy().flatten()": 1,
      "test['benchmark_1']": 1,
      "out_of_time['benchmark_1']": 1,
      "test['benchmark_2']": 1,
      "out_of_time['benchmark_2']": 1,
      "log_scores": 1,
      "train_preds[col]": 1,
      "train_preds_[col]": 1,
      "oof[:-usefull_test.shape[0]]": 1,
      "oof[-usefull_test.shape[0]:]": 1,
      "y_pred_xgboost_v1": 1,
      "y_pred_series": 1,
      "oof.astype(np.float32)": 1,
      "y_actual": 1,
      "pred_label": 1,
      "oof.dnn_oof": 1,
      "predict(valid_dataset)": 1,
      "lgbm_model.predict(X_cv_test)": 1,
      "model.predict_proba(valid_X)": 1,
      "oof_preds1[valid_idx]": 1,
      "oof_preds2[valid_idx]": 1,
      "oof_preds1": 1,
      "oof_preds2": 1,
      "pred_oh": 1,
      "pred_le": 1,
      "PREDS[:, melanoma_idx]": 1,
      "PREDICTIONS[:, melanoma_idx]": 1,
      "rf_tuned.predict(X_val)": 1,
      "nf_server_preds": 1,
      "a_server_preds": 1,
      "b_server_preds": 1,
      "federated_preds": 1,
      "cpreds": 1,
      "blend_train": 1,
      "blend_test": 1,
      "blend_test_Public": 1,
      "blend_test_Private": 1,
      "preds1": 1,
      "preds2": 1,
      "preds3": 1,
      "data_result[category]": 1,
      "new_word_match_train_list": 1,
      "word_match_train_list": 1,
      "pred_r": 1,
      "lgbm.predict(valid_x)": 1,
      "m2_xgb.predict_proba(X_important_test)[:, 1]": 1,
      "valoutputs.detach().cpu().numpy()": 1,
      "preds_valid >= best_thres": 1,
      "[x[0] for x in model.predict(xval, verbose=0)]": 1,
      "[x[0] for x in model.predict(xtrain, verbose=0)]": 1,
      "valPred.iloc[val_idx]": 1,
      "val_merged.target_y": 1,
      "train_merged.target_y": 1,
      "lr.predict(X_val)": 1,
      "trn2.loc[trn2['target_old'].notnull()]['pred_qda']": 1,
      "trn2.loc[trn2['target_old'].notnull()]['pred_nusvc']": 1,
      "trn2_add[trn2_add['target_old'].notnull()]['pred_qda']": 1,
      "trn2_add[trn2_add['target_old'].notnull()]['pred_nusvc']": 1,
      "trn_new.loc[trn_new['target_old'].notnull()]['pred_qda']": 1,
      "trn_new.loc[trn_new['target_old'].notnull()]['pred_nusvc']": 1,
      "find_the_threshold2(0.99997, 7e-05, trn_new.loc[trn_new['target_old'].notnull()]['pred_qda'], trn_new.loc[trn_new['target_old'].notnull()]['pred_nusvc'], oof2, 0.5, 0.5)": 1,
      "y_predm": 1,
      "y_train_pred_lgb": 1,
      "y_val_pred_lgb": 1,
      "length_train": 1,
      "pred_result.cpu()": 1,
      "y_pred_gramolin1": 1,
      "y_pred_gramolin2": 1,
      "roc_predict[:, 1]": 1,
      "rf.predict_proba(X_val)[:, 1]": 1,
      "rf_1.predict_proba(x_val_res)[:, 1]": 1,
      "prediction_3": 1,
      "rf_2.predict_proba(X_val)[:, 1]": 1,
      "prediction_4": 1,
      "clfrf.predict_proba(X_test)[:, 1]": 1,
      "dtclf.predict_proba(X_test)[:, 1]": 1,
      "acdt.predict_proba(X_test)[:, 1]": 1,
      "aclr.predict_proba(X_test)[:, 1]": 1,
      "bcdt.predict_proba(X_test)[:, 1]": 1,
      "bclr.predict_proba(X_test)[:, 1]": 1,
      "gbm.predict_proba(X_test)[:, 1]": 1,
      "pred_prob_y": 1,
      "prob_val": 1,
      "missing['miss_' + col_w_missing[j]]": 1,
      "~missing['miss_' + col_w_missing[j]]": 1,
      "y_": 1,
      "fold_val.flatten() / INNER_FOLDS": 1,
      "y_probs > prob": 1,
      "y_val_prob[:, 1] > best_cut['best_prob']": 1,
      "lr.predict_proba(train_df[columns])[:, 1]": 1,
      "m2_xgb.predict_proba(X1)[:, 1]": 1,
      "LRClassifer.predict(X_test)": 1,
      "NBClassifer.predict(X_test)": 1,
      "DTClassifer.predict(X_test)": 1,
      "XGBClassifer.predict(X_test)": 1,
      "model_linreg_ypredict": 1,
      "model_lassoreg_ypredict": 1,
      "model_lassoreg_cv_ypredict": 1,
      "model_ridgereg_ypredict": 1,
      "model_ridgereg_cv_ypredict": 1,
      "model_elasticnetreg_ypredict": 1,
      "model_elasticnetreg_cv_ypredict": 1,
      "model_kernelridgereg_ypredict": 1,
      "model_kernelridgereg_cv_ypredict": 1,
      "model_treereg_ypredict": 1,
      "model_forestreg_ypredict": 1,
      "yhat_probs": 1,
      "net_out_np": 1,
      "lgbmodel.predict(xvl)": 1,
      "deep_model_pred_val": 1,
      "oof_preds[valid_index]": 1,
      "oof_[:, 1] - oof_[:, 0]": 1,
      "Lrpredictions": 1,
      "valid_pred[:, i]": 1,
      "prob_y_valrf": 1,
      "dt.predict_proba(train[features])[:, 1]": 1,
      "lr.predict(xvl)": 1,
      "m_xgb.predict_proba(X_test)[:, 1]": 1,
      "prediction_val1": 1,
      "prediction_test1": 1,
      "prediction_train1": 1,
      "preds_oof_temp[:, j]": 1,
      "preds_test_temp[:, j]": 1,
      "preds_train_temp[:, j]": 1,
      "preds_test.mean(axis=1)": 1,
      "preds_oof_final": 1,
      "preds_test_final": 1,
      "preds_fake_final": 1,
      "oof_xgb_train": 1,
      "train_meta": 1,
      "df[col].values": 1,
      "fin_valid_df.xgb_pred.values": 1,
      "bnb_auc": 1,
      "dt_auc": 1,
      "rfr.predict_proba(X_train.iloc[:, 1:])[:, 1]": 1,
      "valid_pred.reshape(-1, 1)": 1,
      "test_pred_": 1,
      "y_pred_tag": 1,
      "preds[:, k]": 1,
      "ensemble_cv_preds": 1,
      "train_preds[:, i]": 1,
      "test_preds[:, i]": 1,
      "self.probs": 1,
      "new_pred_class": 1,
      "y1": 1,
      "y2": 1,
      "y3": 1,
      "clf1.predict_proba(X_test)[:, 1]": 1,
      "pred_final_train": 1,
      "rf_cv.predict(X_test)": 1,
      "xgb_model.predict(X_train)": 1,
      "xgb_model.predict(X_test)": 1,
      "clf.predict_proba(x_v, num_iteration=clf.best_iteration_)[:, 1]": 1,
      "oof_1": 1,
      "oof_clf_preds[val_]": 1,
      "oof_clf_preds": 1,
      "y_pred_valid[:, 1]": 1,
      "train_hat_list": 1,
      "valid_hat_list": 1,
      "reg.predict(X_test)": 1,
      "0.8 * oof + 0.2 * oof_nusvc": 1,
      "0.95 * oof + 0.05 * oof_nusvc": 1,
      "y_predictions": 1,
      "df_train.oof_preds": 1,
      "log_reg.predict_proba(X_train)[:, 1]": 1,
      "log_reg.predict_proba(X_test_CV)[:, 1]": 1,
      "eclf.predict_proba(X_train)[:, 1]": 1,
      "eclf.predict_proba(X_test_CV)[:, 1]": 1,
      "preds_traintd": 1,
      "preds_testtd": 1,
      "preds_traincos": 1,
      "preds_testcos": 1,
      "ctb_valid_pred": 1,
      "pred2_opt[:, 1]": 1,
      "pred3[:, 1]": 1,
      "trainModel(6).predict_proba(X_test)[:, 1]": 1,
      "cat_model.predict_proba(y[select_features].values)[:, 1]": 1,
      "xgb_model.predict_proba(y[select_features])[:, 1]": 1,
      "lgb_model.predict(y[select_features])": 1,
      "np.average([cat_model.predict_proba(y[select_features].values)[:, 1], xgb_model.predict_proba(y[select_features])[:, 1], lgb_model.predict(y[select_features])], axis=0)": 1,
      "preds_train[val_idx]": 1,
      "preds_train_total": 1,
      "y_pred_": 1,
      "sample_y_pred": 1,
      "y_all_features": 1,
      "y_selected_features": 1,
      "train['prediction']": 1,
      "pred.data.cpu().numpy()": 1,
      "y_pred[sgroup]": 1,
      "y_pred[bpsn]": 1,
      "y_pred[bnsp]": 1,
      "average_pred": 1,
      "w_avg_pred": 1,
      "model.predict(train.iloc[train_idx][features])": 1,
      "model.predict(train.iloc[val_idx][features])": 1,
      "model.predict(train.iloc[tst_idx][features])": 1,
      "pred_test_y2": 1,
      "y_valid_prob": 1,
      "test_preds[:, 1]": 1,
      "test_preds[:, 1][df_valid.lang == lang]": 1,
      "val_preds.view(-1).cpu()": 1,
      "0.3 * oof_gmm + 0.7 * oof_gmm_2": 1,
      "y_train_pred[:, 1]": 1,
      "y_test_pred[:, 1]": 1,
      "pred2": 1,
      "pred4": 1,
      "pred_all_knn": 1,
      "pred_all_dtree": 1,
      "min_max_normalization(error_df.Reconstruction_error.values)": 1,
      "ans[:, 1]": 1,
      "model.predict_proba(train[cols])[:, 1]": 1,
      "modl.predict(X_val)": 1,
      "current_val_pred": 1,
      "xgb_pred_train": 1,
      "train_y": 1,
      "predictions_simple": 1,
      "predictions_lstm": 1,
      "predictions_lstm_deep": 1,
      "predictions_lstm_deep_bi": 1,
      "rust_pred_y": 1,
      "scab_pred_y": 1,
      "np.minimum(scab_pred_y, rust_pred_y)": 1,
      "1 - np.maximum(scab_pred_y, rust_pred_y)": 1,
      "np.array(outputs_reduced.cpu())": 1,
      "np.array(outputs_reduced)": 1,
      "truth": 1,
      "stacked_pipeline.predict(X_valid2) * 0.2855 + lgb_preds * 0.7145": 1,
      "lgb_preds": 1,
      "self.predict(validation_set[0])": 1,
      "oof_svnu * 0.5 + oof_svc * 0.15 + oof_knn * 0.25 + oof_lr * 0.1": 1,
      "pred_stack_train": 1,
      "predictions_train[:, 0]": 1,
      "-tourney_results['T1_seed']": 1,
      "-tourney_results['T1_powerrank']": 1,
      "tourney_results['T1_quality']": 1,
      "tr_ef1['predictions']": 1,
      "tr_ef2['predictions']": 1,
      "tr_ef3['predictions']": 1,
      "tr_ef4['predictions']": 1,
      "df['predictions']": 1,
      "pos_class_prob": 1,
      "model_lgb.predict(x_test)": 1,
      "model_clf.predict_proba(x_test)[:, 1]": 1,
      "model_lgbm_clf.predict_proba(x_test)[:, 1]": 1,
      "valid_pred[:, 1] > 0.5": 1,
      "pred_pro[:, 1]": 1,
      "np.max(pred_pro, axis=1)": 1,
      "p_shuffled": 1,
      "oof_train_sub": 1,
      "grid.predict_proba(X_valid2)[:, 1]": 1,
      "test_predictions": 1,
      "val_preds_softmax_array": 1,
      "val_preds_roc_array": 1,
      "y_preds_softmax_array[:, label_num]": 1,
      "classifier.predict_proba(train_x)[:, 1]": 1,
      "classifier.predict_proba(test_x)[:, 1]": 1,
      "oofs[valid_index]": 1,
      "oofs": 1,
      "ytrain1": 1,
      "ytrain2": 1,
      "ytrain3": 1,
      "ytrain4": 1,
      "ytrain[te, tar]": 1,
      "val[val_index]": 1,
      "keras_fold_val": 1,
      "cls_fold_val": 1,
      "keras_oof": 1,
      "cls_oof": 1,
      "(keras_oof + cls_oof) / 2": 1,
      "oof_DeepFM": 1,
      "oof_xDeepFM": 1,
      "oof_DCN": 1,
      "oof_PNN[valid_idx]": 1,
      "oof_PNN": 1,
      "oof_WideDeep[valid_idx]": 1,
      "oof_WideDeep": 1,
      "oof_AutoInt[valid_idx]": 1,
      "oof_AutoInt": 1,
      "oof_AFM[valid_idx]": 1,
      "oof_AFM": 1,
      "oof_FGCNN[valid_idx]": 1,
      "oof_FGCNN": 1,
      "oof_df.All_models": 1,
      "y_pred_val[:, 1]": 1,
      "oof_final6": 1,
      "oof_final6 + oof": 1,
      "pred_xgb": 1,
      "pred_tabnet": 1,
      "val_predprob": 1,
      "torch.cat(tot_y_train_out).cpu().detach().numpy()": 1,
      "torch.cat(tot_y_valid_in).cpu()": 1,
      "y_prob_valid[:, 1]": 1,
      "y_pred_valid.data.cpu().numpy()": 1,
      "grid.predict_proba(X_test)[:, 1]": 1,
      "y_pred.to_numpy()": 1,
      "new_model_cleaned.predict_proba(X.drop(['survived'], axis=1))[:, 1]": 1,
      "pred_train['pred']": 1,
      "lgb_base.predict_proba(X_train)[:, 1]": 1,
      "lgb_base.predict_proba(X_test)[:, 1]": 1,
      "probs[:, -1]": 1,
      "qda.predict_proba(X_val_sample)[:, 1]": 1,
      "bc.predict(X_val_sample)": 1,
      "Y_predict_smote": 1,
      "Y_predict_pca": 1,
      "Y_predict_rf": 1,
      "trOut": 1,
      "_preds": 1,
      "y_rf_prob_pred[:, 1]": 1,
      "y_gb_prob_pred[:, 1]": 1,
      "y_scored[:, 1]": 1,
      "average_score['average7']": 1,
      "average_score['average9']": 1,
      "oof_cat": 1,
      "oof_action": 1,
      "mns[mn]": 1,
      "pred.numpy()": 1,
      "train_pred.cpu().detach().numpy()": 1,
      "val_preds.cpu().numpy()": 1,
      "clf.predict_proba(df_val)[:, 1]": 1,
      "oof_lgb_rmse": 1,
      "sub_train.target.values": 1,
      "oof_clf1[val_idx]": 1,
      "oof_clf2[val_idx]": 1,
      "oof_clf3[val_idx]": 1,
      "oof_clf4[val_idx]": 1,
      "oof_clf5[val_idx]": 1,
      "oof_clf1_3[val_idx]": 1,
      "GPIndividual1(train)": 1,
      "GPIndividual2(train)": 1,
      "GPIndividual3(train)": 1,
      "(GPIndividual1(train) + GPIndividual2(train) + GPIndividual3(train)) / 3": 1,
      "GP(tr)": 1,
      "GPI(trainfreq)": 1,
      "GPII(trainfreq)": 1,
      "np.sqrt(GPI(trainfreq) * GPII(trainfreq))": 1,
      "a[[c]].sum(axis=1)": 1,
      "glm.predict_proba(train)[:, 1]": 1,
      "traininv2": 1,
      "traininv3": 1,
      "trpreds": 1,
      "lootrain[col]": 1,
      "secondtrainaverager[features].mean(axis=1)": 1,
      "secondtestaverager[features].mean(axis=1)": 1,
      "gp.GrabPredictions(traindata, 514).class_p": 1,
      "cv_train[validate]": 1,
      "final_cv_train / (s + 1.0)": 1,
      "pr": 1,
      "predTest": 1,
      "predictions_test": 1,
      "model.predict_proba(X_train)": 1,
      "model.predict_proba(X_valid)": 1,
      "xgbpred": 1,
      "predictedResult": 1,
      "y_pred_tuning_lightgbm": 1,
      "clf.predict(xvl)": 1,
      "y_pred_lr2[:, 1]": 1,
      "Y_dev_pred": 1,
      "score[:, 1]": 1,
      "bst.predict(dval)": 1,
      "valp": 1,
      "result_oof['pred']": 1,
      "DT_cv_pred": 1,
      "RF_cv_pred": 1,
      "lightGBM_pred": 1,
      "oof_pred_final": 1,
      "np.mean(bags_oof[:, bag * n_models:(bag + 1) * n_models], axis=1)": 1,
      "np.mean(bags_oof, axis=1)": 1,
      "bagged_oof_preds": 1,
      "pd.read_csv('val_preds_fold_6.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_7.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_8.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_9.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_10.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_11.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_12.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_13.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_14.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_15.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_16.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_17.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_18.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_19.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_20.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_21.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_22.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_23.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_24.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_25.txt', header=None).values[:, 0]": 1,
      "oof2[idx1]": 1,
      "oof3[idx1]": 1,
      "ooff": 1,
      "fold_pred": 1,
      "oof_pred_perceptron": 1,
      "lgbm_model.predict(valid[FEATS])": 1,
      "y_pred_xgb_pr2": 1,
      "y_pred_xgb_pr3": 1,
      "y_pred_rf_pr": 1,
      "p_train3": 1,
      "t_pred": 1,
      "m.predict_proba(xtest)[:, 1]": 1,
      "pred_temp": 1,
      "y_probability[:, 1]": 1,
      "np.array(x)": 1,
      "Rfc.predict(X_tst)": 1,
      "cat.predict(X_tst)": 1,
      "clf.predict_proba(train_variables)[:, 1]": 1,
      "val_probs": 1,
      "valid_probabilities": 1,
      "pred_score[:, 1]": 1,
      "y_preds_all[:, task_id]": 1,
      "gs": 1,
      "y_pred[:, 1].reshape(-1, 1)": 1,
      "y_pred_train[:, 1].reshape(-1, 1)": 1,
      "y_avg": 1,
      "pred_np": 1,
      "y_pred_xgb1": 1,
      "yt_pred": 1,
      "y_pred_adam": 1,
      "np.array(predictions)[:, i]": 1,
      "oof_nn": 1,
      "oof_qda3": 1,
      "oof_stack": 1,
      "preds_gm": 1,
      "y_train_pred_probs": 1,
      "y_valid_pred_probs": 1,
      "i.predict(X_test)": 1,
      "i.predict(X_prob)": 1,
      "logreg.predict(X_prob)": 1,
      "torch.argmax(pred[0], dim=-1)": 1,
      "preds.squeeze().cpu()": 1,
      "o_reduced.cpu()": 1,
      "train_out": 1,
      "self.model.predict(X_val)": 1,
      "y_preds_nn": 1,
      "pvl": 1,
      "y_predict_proba": 1,
      "predict_labels": 1,
      "predictions[:, j]": 1,
      "predictions_tensor": 1,
      "preds_p[:i + 1].mean(0)": 1,
      "y_oob": 1,
      "dt_pred": 1,
      "dt1_pred": 1,
      "rf1_pred": 1,
      "xgb.predict_proba(X_val)[:, 1]": 1,
      "grid_xgb.predict_proba(X_val)[:, 1]": 1,
      "xgb1.predict_proba(X_val)[:, 1]": 1,
      "lgbm.predict_proba(X_val)[:, 1]": 1,
      "grid_lgbm.predict_proba(X_val)[:, 1]": 1,
      "lgbm1.predict_proba(X_val)[:, 1]": 1,
      "clf.predict(Xtrain)": 1,
      "clf.predict(Xval)": 1,
      "y_pred_col": 1,
      "y_pred_training": 1,
      "y_pred_validation": 1,
      "PREDICTION": 1,
      "np.mean(logit(pred), axis=1)": 1,
      "oof[idx1, 0] + oof[idx1, 1] + 0.1 * oof3[idx1, 0]": 1,
      "oof[idx1, 0] + oof[idx1, 1] + 0.2 * oof3[idx1, 0]": 1,
      "oof[idx1, 0] + oof[idx1, 1] + 0.4 * oof3[idx1, 0]": 1,
      "oof[idx1, 0] + oof[idx1, 1] + 0.5 * oof3[idx1, 0]": 1,
      "oof[idx1, 0] + oof[idx1, 1] + 0.6 * oof3[idx1, 0]": 1,
      "oof[idx1, 0] + oof[idx1, 1] + 0.8 * oof3[idx1, 0]": 1,
      "oof[idx1, 0] + oof[idx1, 1] + 1.0 * oof3[idx1, 0]": 1,
      "oof[px, 0] + oof[px, 1] + 0.1 * oof3[px, 0]": 1,
      "pred_avg": 1,
      "clf.predict(train_df.loc[:, predictors])": 1,
      "nbh.predict(svd_x_train)": 1,
      "nbh.predict(svd_x_test)": 1,
      "y_pred_proba[:, 1]": 1,
      "OOF_1dcnn": 1,
      "lgb_result": 1,
      "verify2": 1,
      "clf2.predict_proba(X_train)[:, 1]": 1,
      "clf.predict_proba(trainFeatures)[:, 1]": 1,
      "y_pred_classes[:, i]": 1,
      "lgb_train_result": 1,
      "val_pred[:, i]": 1,
      "lgbm.y_pred": 1,
      "0.9 * y_oof + 0.1 * y_oof_knn": 1,
      "val_preds_EB0": 1,
      "0.6 * val_preds_EB1 + 0.4 * val_preds_EB0": 1,
      "val_preds_5": 1,
      "0.6 * val_preds_6 + 0.4 * val_preds_5": 1,
      "0.55 * val_preds_7 + 0.33 * val_preds_6 + 0.12 * val_preds_5": 1,
      "np.array(ftrl.predict(train[:, features]))": 1,
      "train[str(i)].values": 1,
      "train['33'].values": 1,
      "train['65'].values": 1,
      "-train['217'].values": 1,
      "-train['117'].values": 1,
      "-train['91'].values": 1,
      "-train['295'].values": 1,
      "train['24'].values": 1,
      "train['199'].values": 1,
      "-train['80'].values": 1,
      "-train['73'].values": 1,
      "-train['194'].values": 1,
      "0.146 * train['33'].values + 0.12 * train['65'].values - 0.06 * train['217'].values - 0.05 * train['117'].values - 0.05 * train['91'].values - 0.05 * train['295'].values + 0.05 * train['24'].values + 0.05 * train['199'].values - 0.05 * train['80'].values - 0.05 * train['73'].values - 0.05 * train['194'].values": 1,
      "train_oof_0_2": 1,
      "0.95 * train_oof + 0.05 * train_oof_0_2": 1,
      "train_oof_2": 1,
      "0.8 * train_oof_2 + 0.2 * train_oof": 1,
      "0.5 * train_oof_2 + 0.5 * train_oof": 1,
      "train_oof_2_2": 1,
      "train_oof_4": 1,
      "0.25 * train_oof_2 + 0.25 * train_oof + 0.25 * train_oof_3 + 0.25 * train_oof_4": 1,
      "train_oof_4_2": 1,
      "train_oof_5": 1,
      "0.988 * (0.27 * train_oof_2 + 0.27 * train_oof + 0.27 * train_oof_3 + 0.19 * train_oof_4) + 0.012 * train_oof_5": 1,
      "1.082 * (0.99 * (0.25 * train_oof_2 + 0.25 * train_oof + 0.25 * train_oof_3 + 0.25 * train_oof_4) + 0.01 * train_oof_5) - 0.082 * (train_oof_0_2 + train_oof_2_2) / 2": 1,
      "train_oof_6": 1,
      "0.73 * (1.1 * (0.99 * (0.25 * train_oof_2 + 0.25 * train_oof + 0.25 * train_oof_3 + 0.25 * train_oof_4) + 0.01 * train_oof_5) - 0.1 * (train_oof_0_2 + train_oof_2_2) / 2) + 0.27 * train_oof_6": 1,
      "0.9 * (0.73 * (1.1 * (0.99 * (0.25 * train_oof_2 + 0.25 * train_oof + 0.25 * train_oof_3 + 0.25 * train_oof_4) + 0.01 * train_oof_5) - 0.1 * (train_oof_0_2 + train_oof_2_2) / 2) + 0.27 * train_oof_6) + 0.1 * train_oof_4_2": 1,
      "train_lr_oof_0": 1,
      "train_knn_oof_0": 1,
      "0.9 * train_knn_oof_0 + 0.1 * train_lr_oof_0": 1,
      "0.5 * train_knn_oof_0 + 0.5 * train_lr_oof_0": 1,
      "0.45 * train_knn_oof_0 + 0.45 * train_lr_oof_0 + 0.1 * train_rfc_oof_0": 1,
      "0.35 * train_knn_oof_0 + 0.35 * train_lr_oof_0 + 0.1 * train_rfc_oof_0 + 0.2 * train_svc_oof_0": 1,
      "0.225 * train_knn_oof_0 + 0.225 * train_lr_oof_0 + 0.05 * train_rfc_oof_0 + 0.5 * train_svc_oof_0": 1,
      "0.8 * oof + 0.2 * oof_2": 1,
      "0.95 * oof + 0.05 * oof_2": 1,
      "1.05 * oof - 0.05 * oof_2": 1,
      "cp.asnumpy(val_pred.values)": 1,
      "cp.asnumpy(y_oof)": 1,
      "lr.predict_proba(train[columns])[:, 1]": 1,
      "0.85 * train_oof + 0.15 * train_oof_lr_0": 1,
      "0.95 * train_oof_lgbm_1 + 0.05 * train_oof": 1,
      "0.25 * train_oof_lgbm_0 + 0.25 * train_oof_lgbm_1 + 0.5 * train_oof_lgbm_2": 1,
      "xgb_train_oof_0": 1,
      "xgb_train_oof_1": 1,
      "train_oof_lgbm_2": 1,
      "0.7 * train_oof_lgbm_0 + 0.7 * train_oof_lgbm_1 - 0.4 * train_oof_lgbm_2": 1,
      "0.85 * (0.7 * train_oof_lgbm_0 + 0.7 * train_oof_lgbm_1 - 0.4 * train_oof_lgbm_2) + 0.15 * xgb_train_oof_0": 1,
      "-0.1 * train_oof_hgb_0 + 1.1 * xgb_train_oof_0": 1,
      "1.05 * (0.85 * (0.7 * train_oof_lgbm_0 + 0.7 * train_oof_lgbm_1 - 0.4 * train_oof_lgbm_2) + 0.15 * xgb_train_oof_0) - 0.05 * train_oof_hgb_0": 1,
      "0.1 * train_oof_lr_0 + 0.9 * xgb_train_oof_0": 1,
      "1.04 * (1.08 * (0.84 * (0.7 * train_oof_lgbm_0 + 0.7 * train_oof_lgbm_1 - 0.4 * train_oof_lgbm_2) + 0.16 * xgb_train_oof_0) - 0.08 * train_oof_hgb_0) - 0.04 * train_oof_lr_0": 1,
      "lr_train_oof.get()": 1,
      "0.6 * knn_train_oof.get() + 0.4 * lr_train_oof.get()": 1,
      "0.5 * knn_train_oof.get() + 0.25 * lr_train_oof.get() + 0.25 * rf_train_oof.get()": 1,
      "test_labels": 1,
      "y_pred_incept": 1,
      "y_pred_mobilen": 1,
      "Y2": 1,
      "n_probs": 1,
      "lgbm_probs": 1,
      "eclf.predict_proba(X_test)[:, 1]": 1,
      "Val_pred": 1,
      "y_train_pred_pesudo": 1,
      "Val_pred_pesudo": 1,
      "valpreds": 1,
      "valpreds_pesudo": 1,
      "train[arch]": 1,
      "val_preds * folds_.n_splits": 1,
      "classifier_filename[0][i].predict_proba(X_valid)[:, 1]": 1,
      "predictions_train[:, 1]": 1,
      "predictions_test[:, 1]": 1,
      "y_out": 1,
      "tr_preds": 1,
      "clf.predict(train)": 1,
      "val_probabilities[:, 1:2]": 1,
      "np.argmax(pred, axis=1)": 1,
      "random_probs": 1,
      "predict[:, 1]": 1,
      "Y_predict_balanced": 1,
      "model_LR.predict(X_valid)": 1,
      "test_df['answered_correctly']": 1,
      "train_logits": 1,
      "y_predicted[:, 1]": 1,
      "oof_preds[test_idx]": 1,
      "y_predict[:, 1]": 1,
      "F_S_train.mean(axis=1)": 1,
      "oof_QDA_PL": 1,
      "oof_LS": 1,
      "oof_stacking": 1,
      "train_prediction_array": 1,
      "[randint(0, 1) for i in range(len(train_target_array))]": 1,
      "submission.T[i]": 1,
      "preds_list": 1,
      "clf.predict_proba(X_test[features])[:, 1] / folds": 1,
      "y_preds11": 1,
      "y_preds11 * 0.5 + y_preds * 0.5": 1,
      "model.predict(X_test) / folds": 1,
      "model.predict_proba(X_test[features].fillna(-1))[:, 1] / folds": 1,
      "(y_preds + y_preds2 + y_preds3) * 0.33": 1,
      "(y_preds + y_preds2 + y_preds3 * 0.5) * 0.33": 1,
      "(y_preds11 * 0.5 + y_preds * 0.5 + y_preds2 + y_preds3 * 0.5) * 0.33": 1,
      "logreg.predict(X_test_b)": 1,
      "clf.predict(X_test_b)": 1,
      "dt.predict(X_test_b)": 1,
      "model.predict(X_test_b)": 1,
      "traintion": 1,
      "means_b": 1,
      "y_pred[:, i].round()": 1,
      "preds[:len(actuals)]": 1,
      "y_pred[col]": 1,
      "sub.toxic.values": 1,
      "forest_scores": 1,
      "y_preds[:, 1]": 1,
      "train_p": 1,
      "valid_p": 1,
      "oof[IDX]": 1,
      "predicted.detach().numpy().reshape(-1)": 1,
      "rfc_2.predict_proba(X_test_5)[:, 1]": 1,
      "stack_score.mean(axis=1)": 1,
      "cb_model.predict_proba(X_valid)[:, 1]": 1,
      "oof_qda_pseudo[train_idx_origin]": 1,
      "oof_qda_pseudo": 1,
      "rf_valprediction": 1,
      "logit_valprediction": 1,
      "probs.detach().numpy()": 1,
      "pred_valid_prob": 1,
      "y_pred_oof": 1,
      "decision_function": 1,
      "y_prob_nb": 1,
      "all_preds['y_pred']": 1,
      "y_test.tolist()": 1,
      "xgb_proba[:, 1]": 1,
      "lg_proba[:, 1]": 1,
      "model.predict(x_valid.drop(cat_cols, axis=1))": 1,
      "Y_tr_p[:, 1]": 1,
      "Y_va_p[:, 1]": 1,
      "train_preds_lgb": 1,
      "ensemble": 1,
      "Y_pred[columns]": 1,
      "oof_mlp_tf": 1,
      "oof_qda * 0.3 + oof_svnu * 0.3 + oof_svc * 0.15 + oof_mlp_tf * 0.15 + oof_mlp * 0.1": 1,
      "0.4 * (oof_qda.flatten() * 0.3 + oof_svnu.flatten() * 0.3 + oof_svc.flatten() * 0.15 + oof_mlp_tf.flatten() * 0.15 + oof_mlp.flatten() * 0.15) + 0.6 * oof_lrr": 1,
      "pred_valid[valid_idx]": 1,
      "predictions_all[str(weight)]": 1,
      "probs_pos_XGB": 1,
      "probs_pos_test_gnb": 1,
      "combined_preds": 1,
      "ypredtrain": 1,
      "overall_train_predictions": 1,
      "prob_pos": 1,
      "rscv.predict_proba(X_test)[:, 1]": 1,
      "validation['toxic']": 1
    },
    "sklearn.metrics._ranking.average_precision_score.y_true": {
      "y_test": 25,
      "ys": 19,
      "result_flg": 13,
      "y_true": 12,
      "y": 10,
      "targ": 10,
      "y_.iloc[val_idx]": 9,
      "y_": 9,
      "val_targ": 6,
      "self.y_true": 4,
      "val_targ[:, i]": 3,
      "y_val": 3,
      "y_train": 2,
      "y_valid": 2,
      "df_y_valid": 1,
      "target_test[:len(predictions)]": 1,
      "y_test[:len(predictions)]": 1,
      "label >= threshold": 1,
      "y_test[:, i]": 1,
      "y['test']": 1,
      "original_ytest": 1,
      "ts": 1,
      "Ytest": 1,
      "y_oof": 1,
      "y[test_idx]": 1,
      "Statistics.idx2onehot(self.target)": 1,
      "preds['trueLabel']": 1,
      "y_batch_valid.data.cpu().numpy()": 1,
      "labels[:, i]": 1,
      "labels_[:, i]": 1,
      "(y_train == 1).astype(int)": 1,
      "(y_test == 1).astype(int)": 1,
      "true": 1,
      "y_true[:, i]": 1,
      "y_true2[:, i]": 1,
      "y_true2": 1,
      "result_oof['target']": 1,
      "Y_test": 1,
      "Y2_test": 1,
      "y.iloc[test_idx_3]": 1,
      "Y_validation": 1
    },
    "sklearn.metrics._ranking.average_precision_score.y_score": {
      "pred_ys": 18,
      "y_pred": 17,
      "scores": 14,
      "clipwise_output": 10,
      "oof_preds_[val_idx]": 9,
      "oof_preds_": 9,
      "y_pred_prob": 9,
      "val_preds": 6,
      "preds[:, 1]": 4,
      "self.y_pred": 4,
      "val_preds[:, i]": 3,
      "preds": 3,
      "results": 2,
      "x": 2,
      "predictions": 2,
      "yhat_prob": 2,
      "model.predict_proba(X_test[numerical_features])[:, 1]": 2,
      "probs": 2,
      "oof.catboost_oof": 2,
      "oof": 2,
      "y_proba": 2,
      "train_pred[:, 1]": 1,
      "valid_pred[:, 1]": 1,
      "predict": 1,
      "y_score[:, i]": 1,
      "y_score": 1,
      "y_predict_proba['test']": 1,
      "undersample_y_score": 1,
      "ys": 1,
      "oof.dnn_oof": 1,
      "pred_test": 1,
      "self.probs": 1,
      "preds['anomalyScore']": 1,
      "y_pred_valid.data.cpu().numpy()": 1,
      "preds[:, i]": 1,
      "preds_[:, i]": 1,
      "train_preds": 1,
      "test_preds": 1,
      "predsTrain": 1,
      "pred": 1,
      "y_pred[:, i]": 1,
      "y_pred2[:, i]": 1,
      "y_pred2": 1,
      "result_oof['pred']": 1,
      "y_preds": 1,
      "y_pred_proba": 1,
      "cvp[:, 1]": 1,
      "y_score_rf": 1,
      "y_score_rf2": 1,
      "predictions_all[str(weight)]": 1,
      "prob": 1
    },
    "sklearn.metrics._classification.log_loss.y_true": {
      "y": 431,
      "y_test": 380,
      "y_val": 351,
      "y_true[:, i]": 179,
      "val_y": 166,
      "y_valid": 163,
      "Y_valid": 124,
      "y_train": 115,
      "df_train['is_duplicate']": 88,
      "yte": 85,
      "test_y": 85,
      "y_true.loc[:, _target]": 63,
      "target": 60,
      "yv": 53,
      "y_train.values": 49,
      "y_true": 43,
      "np.where(y > 0, 1, 0)": 40,
      "crossval_y": 36,
      "trainlabels": 33,
      "Titanic_test_y": 32,
      "y_cv": 31,
      "train_target": 29,
      "np.ravel(y_val)": 28,
      "np.ravel(y)": 27,
      "va_y": 25,
      "target[:, i]": 24,
      "train_y": 24,
      "labels": 24,
      "cv_y": 24,
      "ground_truth": 23,
      "targets": 23,
      "train_targets.loc[:, _target]": 22,
      "valid_.label.values": 22,
      "preds_df['label_binary']": 18,
      "Y_test": 17,
      "train[j]": 17,
      "blindtrain.TARGET.values": 16,
      "Y_val": 15,
      "ytest": 15,
      "np.array(Y_test)": 15,
      "answer": 15,
      "target_train": 14,
      "train.TARGET.values": 14,
      "y.ravel()": 14,
      "y_true.loc[:, col]": 13,
      "yval": 13,
      "y_true[:, target]": 12,
      "Y_train": 12,
      "yvalid": 12,
      "y_ts": 12,
      "y_valid.tolist()": 11,
      "y_train[j]": 11,
      "y_valid[j]": 11,
      "y_valid_cv": 11,
      "y_test_val": 11,
      "Ytarget.values": 10,
      "val_y_oh": 10,
      "val_target": 10,
      "y_crossval": 10,
      "y_true.values.ravel()": 10,
      "Y_development": 9,
      "y_train_CV": 9,
      "y_valid_CV": 9,
      "y_Val": 9,
      "y_eval": 9,
      "x.y": 8,
      "labels_test": 8,
      "Ytarget": 8,
      "np.array(ytrain)[:, ii]": 8,
      "ytrain.loc[:, _target]": 8,
      "train.target": 8,
      "df_train['interest_level'].values": 8,
      "valid_y": 7,
      "games['Pred']": 7,
      "Y.iloc[:, j]": 7,
      "training_targets": 7,
      "validation_targets": 7,
      "eval.Team1Won": 7,
      "train_targets.loc[:, train_targets.columns[tar]]": 7,
      "valid['upset']": 7,
      "df_test['interest_level'].values": 7,
      "ytrain": 6,
      "y_save[c]": 6,
      "train.is_duplicate": 6,
      "real": 6,
      "yt": 6,
      "labels_train": 6,
      "['REAL', 'FAKE', 'FAKE', 'REAL']": 6,
      "y2": 6,
      "df[target_col]": 6,
      "df_val['interest_level'].values": 6,
      "test['target']": 5,
      "dev_y": 5,
      "Y_cv": 5,
      "Y_tr": 5,
      "train.target.values": 5,
      "target.iloc[test_index]": 5,
      "gptrain.TARGET.values": 5,
      "np.ravel(y_train)": 5,
      "sub2.wl.values": 5,
      "train_targets_scored[target_col]": 5,
      "test_df['author']": 5,
      "valid[target_cols].values": 4,
      "y_test > 0": 4,
      "eval_y": 4,
      "y.iloc[test_index]": 4,
      "y_true[:, col]": 4,
      "y_one_hot": 4,
      "y_te": 4,
      "train['is_duplicate']": 4,
      "y_validation": 4,
      "y_train[col]": 4,
      "train_targets[target]": 4,
      "y_test[1]": 4,
      "np.ravel(y_valid)": 4,
      "validation['crime']": 4,
      "df_val['WinA'].values": 4,
      "y_val_raw_modf": 4,
      "tst_Y": 4,
      "df['is_duplicate']": 4,
      "self.y_valids[ind1]": 4,
      "y_test.values": 4,
      "y[test_index]": 4,
      "y_test_holdout": 4,
      "train.interest_level": 4,
      "train.shot_made_flag.values": 4,
      "gptrain.target": 4,
      "te_y": 4,
      "avreal": 3,
      "val_y[:, j]": 3,
      "np.array(val_df['event'].values)": 3,
      "targets[:, t]": 3,
      "x.Team1Won": 3,
      "val_ys[-1]": 3,
      "df_test.target": 3,
      "y_true.values[:, _target]": 3,
      "Y[test]": 3,
      "df_train[y_cols].iloc[:, i]": 3,
      "Yfit": 3,
      "train_y[test_idx]": 3,
      "ytrain[col]": 3,
      "yvalid[col]": 3,
      "val_cv_labels": 3,
      "train_labels.loc[:, _target]": 3,
      "y[i_val]": 3,
      "classes[np.argmax(Y_test, axis=1)]": 3,
      "df_train.cancer": 3,
      "train['y'].values.tolist()": 3,
      "train['target']": 3,
      "val_true": 3,
      "target_test": 3,
      "y_test1": 3,
      "train_df.iloc[:, -1]": 3,
      "y_valid_idx": 3,
      "y1": 3,
      "val_targets": 3,
      "scores": 3,
      "df_train.is_duplicate": 3,
      "(sub.label == 'FAKE').values": 3,
      "(train.loc[te]['resp'] > 0).astype('int').values.reshape(-1, 1)": 2,
      "target_": 2,
      "y_true_exam[:, i]": 2,
      "y_train_train": 2,
      "y_train_valid": 2,
      "Y_test_part2": 2,
      "y_test.toxic": 2,
      "lst": 2,
      "df['result']": 2,
      "train[target_column]": 2,
      "val_tv_y": 2,
      "Y[cols]": 2,
      "targets.iloc[:, 1:-1].values.flatten()": 2,
      "y_train[valid_index]": 2,
      "train_targets_df.loc[:, _target]": 2,
      "test_Y_Y": 2,
      "validation['Category']": 2,
      "ytr": 2,
      "self.__testing_set[self.__predictive_variable]": 2,
      "train_df[j]": 2,
      "np.ravel(vals)": 2,
      "y_pred": 2,
      "train_targets.loc[:, train_targets.columns[tar]].values": 2,
      "y_valid[:, task_idx]": 2,
      "valid_oob.target": 2,
      "quora_train['is_duplicate']": 2,
      "y_Test": 2,
      "y_fit": 2,
      "np.ravel(y_test)": 2,
      "group.target": 2,
      "[0] * (78545 * 6 - n_positives) + [1] * n_positives": 2,
      "target_exam[col].values": 2,
      "val_labels[category]": 2,
      "y_oof": 2,
      "y_true[:, k]": 2,
      "y_GT": 2,
      "val_labels[cat]": 2,
      "df['open_channels']": 2,
      "np.array(Y_test).reshape(dim)": 2,
      "test['interest_level']": 2,
      "df[get_target_feature()]": 2,
      "train['target'].iloc[fold_ids[0][1]]": 2,
      "train['target'].iloc[fold_ids[1][1]]": 2,
      "train['target'].iloc[fold_ids[2][1]]": 2,
      "train['target'].iloc[fold_ids[3][1]]": 2,
      "train['target'].iloc[fold_ids[4][1]]": 2,
      "Y.loc[:, col].values": 2,
      "Y_train_n": 2,
      "Y_val_n": 2,
      "subtrain['interest_level']": 2,
      "D_test.get_label()": 2,
      "tr['target']": 2,
      "y5": 2,
      "y3": 2,
      "y4": 2,
      "y_dev": 2,
      "y_val2": 2,
      "pred_label": 2,
      "y.iloc[:, i]": 2,
      "Actual[:, i]": 2,
      "yvl": 2,
      "y_val_encoded": 2,
      "train.loc[:, target_cols[i]].values": 2,
      "predictions['result']": 2,
      "data['result']": 2,
      "oho.fit_transform(target.reshape(-1, 1)).toarray()": 2,
      "validation_y": 2,
      "df_train.iloc[ktrain]['interest_level'].values": 2,
      "df_train.iloc[ktest]['interest_level'].values": 2,
      "y_true[:, idx]": 1,
      "y_train_encode": 1,
      "y_val_encode": 1,
      "df.loc[test_index, 'shot_made_flag']": 1,
      "y_out": 1,
      "y_val_cv": 1,
      "np.ravel(y_val_cv)": 1,
      "y[mask_train]": 1,
      "y[mask_test]": 1,
      "y_onehot": 1,
      "y_train[val_idx]": 1,
      "lrModel.predict(test_x)": 1,
      "model.predict(test_x)": 1,
      "stat_model.predict(test_x)": 1,
      "big_test": 1,
      "validate.target": 1,
      "b": 1,
      "np.argmax(Y_val, axis=1)": 1,
      "targets[:, i]": 1,
      "y.iloc[val_idx]": 1,
      "y.values": 1,
      "train.iloc[:, col]": 1,
      "checker['outcome']": 1,
      "label_actual": 1,
      "validation['Crime']": 1,
      "B_valid": 1,
      "Y_valid_fish": 1,
      "train_targets['diuretic']": 1,
      "train_targets['casein_kinase_inhibitor']": 1,
      "np.ravel(truth_data)": 1,
      "df_val['_targetWinA'].values": 1,
      "y_actual": 1,
      "val_2015['lower_win']": 1,
      "val_2016['lower_win']": 1,
      "val_2017['lower_win']": 1,
      "val_2018['lower_win']": 1,
      "val_2019['lower_win']": 1,
      "y_true[col]": 1,
      "y_val_1": 1,
      "y_true[:, i].astype(float)": 1,
      "df_sample_sub_with_truth['truth']": 1,
      "y_cv[:, i]": 1,
      "y_train_selected[:, i]": 1,
      "y_train_array[:, i]": 1,
      "list(df_TestData.label)": 1,
      "validlabels": 1,
      "Ytrain_oh": 1,
      "df_results.true": 1,
      "dog_y_val": 1,
      "dog_y_train": 1,
      "cat_y_val": 1,
      "cat_y_train": 1,
      "ind.classes": 1,
      "np.ravel(y_xgb)": 1,
      "train_gold": 1,
      "valid_gold": 1,
      "train_gold_female": 1,
      "train_gold_male": 1,
      "valid_gold_female": 1,
      "valid_gold_male": 1,
      "gold_train": 1,
      "gold_test": 1,
      "self.cy_val": 1,
      "val_labels": 1,
      "y_val[:, 0]": 1,
      "y_val[:, 1]": 1,
      "y_val[:, 2]": 1,
      "y_val[:, 3]": 1,
      "y_val[:, 4]": 1,
      "y_val[:, 5]": 1,
      "train_data['type'].values": 1,
      "true_target[:, i]": 1,
      "valid_df['target']": 1,
      "ohe.fit_transform(val_Y.reshape(-1, 1)).toarray()": 1,
      "val_Y": 1,
      "test_valid_y": 1,
      "stn_y": 1,
      "vld_y": 1,
      "y_test[:, col]": 1,
      "df_cv.interest_level": 1,
      "train_bag.target": 1,
      "train_yS": 1,
      "y_valid_ohe": 1,
      "target[val_idx]": 1,
      "nm_Y_test": 1,
      "Y[:, i]": 1,
      "Y_validation": 1,
      "pred_valA_y": 1,
      "pred_valB_y": 1,
      "mini_dev_labels": 1,
      "y[te]": 1,
      "classes[np.argmax(val_set_output, axis=1)]": 1,
      "train_set['is_duplicate']": 1,
      "y_train['OUTCOME'].tolist()": 1,
      "y_valid['OUTCOME'].tolist()": 1,
      "train_targets_scored.iloc[:, 1:].loc[:, _target]": 1,
      "y_exam": 1,
      "np.array(Y_val).reshape(dim)": 1,
      "y_vl": 1,
      "yreal": 1,
      "y_train[test_index]": 1,
      "train_cross_target": 1,
      "true_label": 1,
      "data.Result": 1,
      "np.ravel(yvalid)": 1,
      "y_val.iloc[:, j:j + 1]": 1,
      "y_true.iloc[:, i]": 1,
      "datay": 1,
      "y1_train": 1,
      "y1_val": 1,
      "y_train.tolist()": 1,
      "oof_df['open_channels']": 1,
      "[1, 2]": 1,
      "val_DV": 1,
      "train_true": 1,
      "target_train.iloc[val_idx]": 1,
      "target_train.iloc[trn_idx]": 1,
      "test_answ": 1,
      "y_subtest": 1,
      "train_labels": 1,
      "y_label": 1,
      "train_df['is_duplicate']": 1,
      "data[tt]['Judge'].astype(np.float64)": 1,
      "y_traintd": 1,
      "y_testtd": 1,
      "y_traincos": 1,
      "y_testcos": 1,
      "outcome_var": 1,
      "y_train.combined_tar": 1,
      "yTest": 1,
      "y_train_full": 1,
      "trainResponseData": 1,
      "y_true.loc[:, true_col[_target]]": 1,
      "Y": 1,
      "[y]": 1,
      "df_train_targets_nonscored.loc[:, df_train_targets_nonscored.columns[tar]]": 1,
      "y_test.ravel()": 1,
      "your_new_df['target']": 1,
      "y_valids[i][0].values": 1,
      "true_y": 1,
      "y_trn": 1,
      "y_val_st": 1,
      "scaledtrain.interest_level.values": 1,
      "visibletrain.TARGET.values": 1,
      "y_categorical": 1,
      "X_train.interest_level": 1,
      "pd.get_dummies(meta_train.target)": 1,
      "train['target'].iloc[fold_ids[5][1]]": 1,
      "train['target'].iloc[fold_ids[6][1]]": 1,
      "train['target'].iloc[fold_ids[7][1]]": 1,
      "train['target'].iloc[fold_ids[8][1]]": 1,
      "train['target'].iloc[fold_ids[9][1]]": 1,
      "train['target'].iloc[fold_ids[10][1]]": 1,
      "train['target'].iloc[fold_ids[11][1]]": 1,
      "train['target'].iloc[fold_ids[12][1]]": 1,
      "train['target'].iloc[fold_ids[13][1]]": 1,
      "train['target'].iloc[fold_ids[14][1]]": 1,
      "train['target'].iloc[fold_ids[15][1]]": 1,
      "train['target'].iloc[fold_ids[16][1]]": 1,
      "train['target'].iloc[fold_ids[17][1]]": 1,
      "train['target'].iloc[fold_ids[18][1]]": 1,
      "train['target'].iloc[fold_ids[19][1]]": 1,
      "train['target'].iloc[fold_ids[20][1]]": 1,
      "train['target'].iloc[fold_ids[21][1]]": 1,
      "train['target'].iloc[fold_ids[22][1]]": 1,
      "train['target'].iloc[fold_ids[23][1]]": 1,
      "train['target'].iloc[fold_ids[24][1]]": 1,
      "np.floor(targets[:, i])": 1,
      "y.loc[:, _target]": 1,
      "valid_.target.values": 1,
      "results['y_val']": 1,
      "CLF_dict[c]['True'].ravel()": 1,
      "Yval.ravel()": 1,
      "lb": 1,
      "y_train_v": 1,
      "df_train.TARGET.values": 1,
      "image_targets_all": 1,
      "y_valdt": 1,
      "y_test_sub": 1,
      "y_noisy[i]": 1,
      "y[i::3]": 1,
      "y.reshape((-1, 3))": 1,
      "_valid['target']": 1,
      "true_df": 1,
      "y_test_v": 1,
      "train[target]": 1,
      "test[target]": 1,
      "y_test.values.ravel()": 1,
      "labels_val": 1,
      "y_train1": 1,
      "y_train2": 1,
      "y_test2": 1,
      "y_train3": 1,
      "y_test3": 1,
      "y_train4": 1,
      "y_test4": 1,
      "aa": 1,
      "true_values[:, moa_idx].astype(np.float)": 1,
      "true": 1,
      "df_train.iloc[:i]['interest_level'].values": 1,
      "y[cv_index]": 1,
      "train_y_te": 1,
      "ytrue[:, i]": 1,
      "video_lables": 1,
      "y[70001:]": 1,
      "y[70000:]": 1,
      "y[c]": 1,
      "np.ravel(train_target_matrix)": 1,
      "Y_true": 1,
      "train[target_cols_i].values": 1,
      "y_test_min": 1,
      "y_test_max": 1,
      "labelsValidate": 1
    },
    "sklearn.metrics._classification.log_loss.y_pred": {
      "pred": 336,
      "y_pred": 163,
      "y_pred[:, i]": 154,
      "predictions_valid": 152,
      "preds": 145,
      "predict_y": 99,
      "np.zeros_like(df_train['is_duplicate']) + p": 85,
      "pred[itest, :]": 82,
      "y_val_pred": 82,
      "scores_val": 73,
      "val_preds": 73,
      "y_pred.loc[:, _target].astype(float)": 61,
      "train_predictions": 58,
      "predictions": 56,
      "valid_probs": 54,
      "oof": 48,
      "spline_fit": 40,
      "sig_clf_probs": 40,
      "pred_val_y": 39,
      "0.5 * (predb + predm)": 34,
      "train_preds": 32,
      "oof[:, i]": 27,
      "y_pred_proba": 26,
      "model.predict_proba(train)": 26,
      "np.ravel(val_preds)": 25,
      "valid_preds": 24,
      "va_pred": 23,
      "res.loc[:, _target]": 21,
      "clf.predict(train[elt2 + [elt]])": 21,
      "np.ravel(oof_preds)": 20,
      "y_val_pred7": 19,
      "val_pred": 19,
      "model.predict(train)": 17,
      "probs": 15,
      "y_pred_prob": 15,
      "y_predicted": 15,
      "test_predict": 14,
      "train_oof": 14,
      "model.predict_proba(X_val)": 13,
      "y_3l": 13,
      "y_preds": 13,
      "prediction": 12,
      "y_pred[:, target]": 12,
      "y_pred.loc[:, col]": 12,
      "sol": 12,
      "yt": 12,
      "y_enA": 12,
      "y_enB": 12,
      "y_lr": 12,
      "blind_preds": 12,
      "predicted_y": 12,
      "y_pred[:, i].astype(float)": 11,
      "y_pred_val_prob": 11,
      "y_valid_hat": 11,
      "probas": 11,
      "check": 10,
      "preds_train[:, i]": 10,
      "preds_valid[:, i]": 10,
      "pred_probs": 10,
      "pred_a": 10,
      "final_prediction": 10,
      "predicted": 10,
      "y_oof_pred": 10,
      "blend_cv": 10,
      "temp_oof": 10,
      "y_pred_oof": 9,
      "oof_NN_a": 9,
      "y_train_hat_mainLearner": 9,
      "y_valid_hat_mainLearner": 9,
      "oof[ts_idx]": 9,
      "pred_train": 9,
      "oof_preds": 9,
      "pred_valid": 8,
      "y_blend": 8,
      "y_pred_valid": 8,
      "x.pred": 8,
      "model.predict_proba(train)[:, 1]": 8,
      "valid_pred": 7,
      "bst.predict(d_valid)": 7,
      "y_pred_oof_blend": 7,
      "np.clip(predictions.values, 0.01, 0.99)": 7,
      "train_pred": 7,
      "Y_pred.iloc[:, j]": 7,
      "pred_val": 7,
      "y_pred.iloc[:, i]": 7,
      "ypred": 7,
      "rfc.predict_proba(test_x)": 7,
      "logreg.predict_proba(test_x)": 7,
      "rfc2.predict_proba(test_x)": 7,
      "predictions_test.mean(axis=1)": 7,
      "predictions_train.mean(axis=1)": 7,
      "pred_test_xgb": 6,
      "np.ones_like(y_save[c]) * y_save[c].mean()": 6,
      "pred_test_y": 6,
      "pred2": 6,
      "yp": 6,
      "y_ccA": 6,
      "y_ccB": 6,
      "y_gb": 6,
      "[[0.1, 0.9], [0.9, 0.1], [0.8, 0.2], [0.35, 0.65]]": 6,
      "opt_oof": 6,
      "sclf.predict_proba(cv_x_onehotCoding)": 6,
      "oof_pred_arr.ravel()": 6,
      "estimator.predict_proba(dev_X)": 5,
      "model.predict_proba(X_train)[:, 1]": 5,
      "predict_y_tr": 5,
      "training_probabilities": 5,
      "validation_probabilities": 5,
      "bst.predict(xgb.DMatrix(train[col]))": 5,
      "y_valid_pred_log": 5,
      "preds[indice]": 5,
      "y_proba": 5,
      "pd.DataFrame(model.predict_proba(preds_val))": 5,
      "adjusted": 5,
      "xgb_pred": 5,
      "y_pred_train": 5,
      "pred_prob": 5,
      "y_probs": 5,
      "bst.predict(xgb.DMatrix(df_train[feats]))": 5,
      "lgb_pred": 5,
      "oof[target_col]": 5,
      "oof_pred_arr_avg.ravel()": 5,
      "estimator.predict_proba(X)": 5,
      "predict": 4,
      "y_pred_on_test_fold": 4,
      "np.ones_like(y) * np.mean(y)": 4,
      "y_hat": 4,
      "predictions1": 4,
      "model.predict_proba(df.iloc[test_index])": 4,
      "np.clip(x_pred[:, 1] * 1.691, 1e-06, 1 - 1e-06)": 4,
      "ypreds": 4,
      "y_predict": 4,
      "y_train_pred_log": 4,
      "lgb_oof": 4,
      "prval[:, ii]": 4,
      "prval_cal[:, ii]": 4,
      "prval_cal.loc[:, _target]": 4,
      "y_oof": 4,
      "preds_opt": 4,
      "prob_pred": 4,
      "np.clip(predictions.values * 1.0080035, 1e-06, 1 - 1e-06)": 4,
      "p": 4,
      "oof[val_idx]": 4,
      "model.predict_proba(X_test)": 4,
      "model_pred.clip(0.35, 0.65)": 4,
      "larger_range(model_pred, 2).clip(0.35, 0.65)": 4,
      "y_final_pred_prob": 4,
      "scores": 4,
      "np.clip(predictions.values, 1e-05, 1 - 1e-05)": 4,
      "y_test_predict": 4,
      "model.predict_proba(features.as_matrix())": 4,
      "model.predict_proba(features_train.as_matrix())": 4,
      "model.predict_proba(features_test.as_matrix())": 4,
      "weighted_pred": 4,
      "model_merged.predict([X, X])": 4,
      "model.predict_proba(df[feature_col].replace(values_dict).values.reshape(-1, 1))[:, 1]": 4,
      "y_hat1": 4,
      "ctb_pred": 4,
      "pred_xgb": 4,
      "predictions.values": 4,
      "oof_list[i].values.ravel()": 4,
      "y_pred_test": 4,
      "y_predlr": 4,
      "sigmoid(y_pred)": 4,
      "scores_val_run": 3,
      "avpred": 3,
      "y_pred_blend": 3,
      "test_y": 3,
      "np.array(y_pred)": 3,
      "Y_pred": 3,
      "y_pred[:, j]": 3,
      "preds[:, t]": 3,
      "val_preds[-1]": 3,
      "final_test_preds": 3,
      "model.predict(xtrain)": 3,
      "oof_embedding[ts_idx]": 3,
      "oof_forest[ts_idx]": 3,
      "oof_embedding": 3,
      "oof_forest": 3,
      "y_pred[:, _target]": 3,
      "Yhat": 3,
      "np.clip(x_pred[:, 1] * 1.0695, 1e-06, 1 - 1e-06)": 3,
      "result": 3,
      "val_preds[:, i]": 3,
      "np.ravel(preds)": 3,
      "Yval": 3,
      "clf.predict_proba(train_X[test_idx])": 3,
      "word_clf.predict_proba(x_test_word)": 3,
      "prd_train[:, i]": 3,
      "prd_valid[:, i]": 3,
      "docv(clf, x, y, kf)": 3,
      "res_nn.loc[:, _target]": 3,
      "cat_oof": 3,
      "P[i_val]": 3,
      "P": 3,
      "np.zeros_like(df_train.cancer) + df_train.cancer.mean()": 3,
      "preds_train": 3,
      "df": 3,
      "nlp_pipeline.predict_proba(X_test)": 3,
      "pred_prob_train": 3,
      "pred_prob_val": 3,
      "rf.predict_proba(Y)[:, 1]": 3,
      "predictions_proba": 3,
      "y_test_pred_prob": 3,
      "rf_mod.predict_proba(X_train)": 3,
      "rf_mod.predict_proba(X_valid)": 3,
      "pred_row": 3,
      "sig_clf.predict_proba(test_x)": 3,
      "vclf.predict_proba(train_x_onehotCoding)": 3,
      "vclf.predict_proba(cv_x_onehotCoding)": 3,
      "vclf.predict_proba(test_x_onehotCoding)": 3,
      "xbg_mod.predict_proba(X_train)": 3,
      "xbg_mod.predict_proba(X_valid)": 3,
      "te_yprob_pred": 3,
      "valid['upset_prob']": 3,
      "rf_probs": 3,
      "sub.pred": 3,
      "yp_prob": 3,
      "pred_mean": 2,
      "y_pred_exam[:, i]": 2,
      "np.ones_like(y) * y.mean()": 2,
      "model.predict(X_train_train, num_iteration=model.best_iteration)": 2,
      "y_pred_oof[valid_idx]": 2,
      "y_blend_simple": 2,
      "y2": 2,
      "logreg.predict_proba(X_test)": 2,
      "cv_predicted_y": 2,
      "result[1]": 2,
      "logit_test_pred": 2,
      "yptrain": 2,
      "yptest": 2,
      "a": 2,
      "train['prediction']": 2,
      "new_oof": 2,
      "df['Pred']": 2,
      "eval.Prob_NNet": 2,
      "eval.Prob_LGB": 2,
      "eval.Prob_LR": 2,
      "np.ravel(lr_val_preds)": 2,
      "y_predicted[:, col]": 2,
      "avgprobas": 2,
      "predict_probs": 2,
      "ovr_oof[val_idx]": 2,
      "ovr_oof": 2,
      "predictions_prob": 2,
      "oof.flatten()": 2,
      "oof[col]": 2,
      "np.clip(oof[col], 0.025, 0.975)": 2,
      "train_preds_df.loc[:, _target]": 2,
      "p_train": 2,
      "p_valid": 2,
      "model.predict_proba(features.as_matrix(), verbose=0)": 2,
      "model.predict_proba(features_train.as_matrix(), verbose=0)": 2,
      "model.predict_proba(features_test.as_matrix(), verbose=0)": 2,
      "pred.clip(0.0001, 0.99999)": 2,
      "pred.clip(0.1, 0.9)": 2,
      "sclf.predict_proba(validation_data_final)": 2,
      "predicted_proba": 2,
      "y_pred.astype(float)": 2,
      "pred_proba_df['win1']": 2,
      "pred_proba_df['baseline']": 2,
      "dog_y_probs": 2,
      "cat_y_probs": 2,
      "preds_2": 2,
      "res_svc.loc[:, train_targets.columns[tar]]": 2,
      "pred_test_xgb2": 2,
      "res_lr.loc[:, train_targets.columns[tar]].values": 2,
      "cat_oof[val_idx]": 2,
      "lgb_oof[val_idx]": 2,
      "yhat_prob": 2,
      "predict_proba": 2,
      "pred_test": 2,
      "task_pred[:, 1]": 2,
      "train_oof_lgbm_0": 2,
      "np.zeros_like(quora_train['is_duplicate']) + p": 2,
      "np.zeros_like(train['is_duplicate']) + p": 2,
      "preds_proba": 2,
      "clf.predict_proba(X_test)": 2,
      "clf.predict_proba(X_fit)[:, 1]": 2,
      "clf.predict_proba(X_eval)[:, 1]": 2,
      "np.zeros_like(df['is_duplicate']) + duplicate_score": 2,
      "df['prediction_is_duplicate']": 2,
      "model.predict_proba(group.drop(columns=['target']))": 2,
      "np.clip(predictions.values * 1.0080036, 1e-06, 1 - 1e-06)": 2,
      "MNB_pred_val_y[:, 1]": 2,
      "[0.5] * 78545 * 5 + [pred_all] * 78545": 2,
      "random_pred.clip(0.35, 0.65)": 2,
      "allone_pred": 2,
      "allzero_pred": 2,
      "allpoint5_pred": 2,
      "best_model_pred.clip(0.35, 0.65)": 2,
      "larger_range(best_model_pred, 2).clip(0.35, 0.65)": 2,
      "m.predict_proba(X_train).tolist()": 2,
      "m.predict_proba(X_valid).tolist()": 2,
      "np.clip(probs_exam[col].values, epsilon, 1.0 - epsilon)": 2,
      "preds_valid": 2,
      "category_probabs": 2,
      "y_pred[:, k].astype(float)": 2,
      "y_Hat": 2,
      "results": 2,
      "cat_prob": 2,
      "valid": 2,
      "y_valid_predict": 2,
      "oof_preds[valid_idx]": 2,
      "pred_y": 2,
      "clf.predict_proba(test_x)": 2,
      "pd.read_csv('val_preds_fold_1.txt', header=None).values[:, 0]": 2,
      "pd.read_csv('val_preds_fold_2.txt', header=None).values[:, 0]": 2,
      "pd.read_csv('val_preds_fold_3.txt', header=None).values[:, 0]": 2,
      "pd.read_csv('val_preds_fold_4.txt', header=None).values[:, 0]": 2,
      "pd.read_csv('val_preds_fold_5.txt', header=None).values[:, 0]": 2,
      "p_valid[-1]": 2,
      "rf_train_prediction": 2,
      "pred_col": 2,
      "oof_NN_h": 2,
      "oof_NN_v": 2,
      "sig_clf1.predict_proba(cv_x_onehotCoding)": 2,
      "sig_clf2.predict_proba(cv_x_onehotCoding)": 2,
      "sig_clf3.predict_proba(cv_x_onehotCoding)": 2,
      "sclf.predict_proba(train_x_onehotCoding)": 2,
      "sclf.predict_proba(test_x_onehotCoding)": 2,
      "val_Y[:, i].astype(float)": 2,
      "subtrain[['low', 'medium', 'high']]": 2,
      "tr[[f'oof_predictions_class{class_num}' for class_num in range(4)]]": 2,
      "oof_preds[:, i]": 2,
      "valid_results.loc[:, train_targets.columns[tar]]": 2,
      "res_NN.loc[:, train_targets.columns[tar]]": 2,
      "val_preds.ravel().astype('float64')": 2,
      "preds_df['avg_pred_c23']": 2,
      "preds_df['min_pred_c23']": 2,
      "preds_df['max_pred_c23']": 2,
      "preds_df['avg_pred_raw']": 2,
      "preds_df['min_pred_raw']": 2,
      "preds_df['max_pred_raw']": 2,
      "preds_df['naive_pred']": 2,
      "preds_df['max_pred_clipped']": 2,
      "preds_df['max_pred_clipped_raw']": 2,
      "model.predict_proba(df[feature_col].values.reshape(-1, 1))[:, 1]": 2,
      "y_hat2": 2,
      "y_prob": 2,
      "x.values": 2,
      "GP2(gptrain)": 2,
      "GPIndividual1(train)": 2,
      "GPIndividual2(train)": 2,
      "GPIndividual3(train)": 2,
      "GP(train)": 2,
      "y_pred.loc[:, _target]": 2,
      "y_predict_val": 2,
      "yHat_val": 2,
      "pred_aft": 2,
      "res2.iloc[:, i]": 2,
      "val_preds_EB7_lr": 2,
      "val_preds_xgb_1": 2,
      "0.5 * val_preds_xgb_1 + 0.5 * val_preds_EB7_lr": 2,
      "val_preds_EB4_lr": 2,
      "predicted[:, i]": 2,
      "clf_probs": 2,
      "tempPred.ravel()": 2,
      "mNB.predict_proba(xvl)": 2,
      "lgbm_model.predict_proba(x_valid_idx)[:, 1]": 2,
      "training_pred_one_hot": 2,
      "validation_pred_one_hot": 2,
      "predictions['pred_' + str(season) + '_' + str(k) + '_' + str(home_adv) + '_' + str(revert) + '_' + str(option)]": 2,
      "data['pred_' + str(scenario)]": 2,
      "pred_glove_val_y": 2,
      "bst.predict(xgb.DMatrix(df_train[col]))": 2,
      "np.ravel(oof_pred)": 2,
      "et1_oof_train": 2,
      "et2_oof_train": 2,
      "rf1_oof_train": 2,
      "rf2_oof_train": 2,
      "gbc1_oof_train": 2,
      "gbc2_oof_train": 2,
      "xg_oof_train": 2,
      "y_preds_sig": 2,
      "np.reshape(model.predict_proba(val)[:, -1], [-1, 1])": 2,
      "predicted_probs": 2,
      "y_pred[:, idx]": 1,
      "oof_pred[:, i]": 1,
      "mnb_train_prediction": 1,
      "mnb_val_prediction": 1,
      "xgb.predict_proba(df.loc[test_index, predictors])[:, 1]": 1,
      "valid_score": 1,
      "train_pred['valid']": 1,
      "Y_pred_proba": 1,
      "transform_to_submit(y_pred_, X_test_referred_expression)": 1,
      "clf_04.predict(X_trn)": 1,
      "model.predict_proba(x_val)": 1,
      "naive": 1,
      "lgb_meta": 1,
      "y_pred.loc[:, col].astype(float)": 1,
      "model.predict_proba(X_test)[:, 1]": 1,
      "y_pred_blend[mask_train]": 1,
      "y_pred_blend[mask_test]": 1,
      "y1": 1,
      "y_pred_onehot": 1,
      "OOF_PRED": 1,
      "y_pred[:, col]": 1,
      "y_predictions_proba": 1,
      "pred4_on_train_Part2": 1,
      "predict_y_test": 1,
      "sig_clf.predict_proba(data_test)": 1,
      "valid_predictions": 1,
      "big_probs": 1,
      "logreg.predict_proba(X_train)": 1,
      "mod.predict(x_te)": 1,
      "cb.predict_proba(x_te)": 1,
      "np.clip(model.predict_proba(val_x), 0.025, 0.975)": 1,
      "model.predict_proba(val_x)": 1,
      "result[:, 1]": 1,
      "np.array(pred_rf_proba_t)": 1,
      "pred_log_proba_t": 1,
      "pred_xg_proba_t": 1,
      "y_val_naive1": 1,
      "y_val_naive2": 1,
      "y_pred_log": 1,
      "y_pred_svm": 1,
      "y_pred_rf": 1,
      "np.clip(x_pred[:, 1]**1.011011, 1e-06, 0.999999)": 1,
      "tmp_oof": 1,
      "x.Prob_NNet": 1,
      "x.Prob_LGB": 1,
      "x.Prob_LR": 1,
      "eval.ProbAvg": 1,
      "np.ravel(lr_val_preds_0)": 1,
      "np.ravel(lr_val_preds_1)": 1,
      "np.ravel(lr_val_preds_2)": 1,
      "np.ravel(lr_val_preds_3)": 1,
      "np.ravel(lr_val_preds_4)": 1,
      "np.ravel(avg_val_preds)": 1,
      "predict[:, col]": 1,
      "clf.predict_proba(Xtrain)": 1,
      "clf.predict_proba(Xtest)": 1,
      "Y_prob": 1,
      "checker['Pred']": 1,
      "pred_prob.clip(0.001, 0.999)": 1,
      "predicted_loss": 1,
      "b_predictions_valid": 1,
      "np.ones(23814) * 6 / 23814": 1,
      "np.ones(23814) * 36 / 23814": 1,
      "np.ravel(predictions)": 1,
      "output": 1,
      "preds_prob_train": 1,
      "preds_prob_val": 1,
      "voting_clf.predict_proba(val_2015[feature])[:, 1]": 1,
      "voting_clf.predict_proba(val_2016[feature])[:, 1]": 1,
      "voting_clf.predict_proba(val_2017[feature])[:, 1]": 1,
      "voting_clf.predict_proba(val_2018[feature])[:, 1]": 1,
      "voting_clf.predict_proba(val_2019[feature])[:, 1]": 1,
      "np.clip(y_pred[col], c, 1 - c)": 1,
      "get_model_SVM(train_X, test_X, y_train[1])": 1,
      "get_model_Bayes(train_X, test_X, y_train[1])": 1,
      "get_model_forest(train_X, test_X, y_train[1])": 1,
      "get_model_Regression(train_X, test_X, y_train[1])": 1,
      "y_ave + np.zeros(len(y))": 1,
      "yh": 1,
      "yh_adj": 1,
      "df_sample_sub_with_truth['Pred']": 1,
      "validate": 1,
      "y_cv_pred[idx2, i]": 1,
      "y_train_selected_pred[idx1, i, k]": 1,
      "y_cv_pred[:, i]": 1,
      "prediction_knn": 1,
      "model.predict_proba(X_test, verbose=0)": 1,
      "list(df_TestData.prediction)": 1,
      "model.predict_proba(xtr)": 1,
      "sig_clf1.predict_proba(validation_data_final)": 1,
      "sig_clf2.predict_proba(validation_data_final)": 1,
      "sig_clf3.predict_proba(validation_data_final)": 1,
      "sclf.predict_proba(testing_data_final)": 1,
      "pred_proba_val_y": 1,
      "np.clip(y_cv_pred, 0.01, 0.99)": 1,
      "y_pred_meta_lama.data": 1,
      "df_results.predict": 1,
      "create_array(0.2)": 1,
      "create_array(x)": 1,
      "create_array(ratio)": 1,
      "predicted_prob": 1,
      "train[['Class_1', 'Class_2', 'Class_3', 'Class_4']]": 1,
      "np.clip(predictions.values, treshold, 1 - treshold)": 1,
      "np.clip(predictions.values, 1e-06, 1 - 1e-06)": 1,
      "ypredsC1": 1,
      "ypredsC2": 1,
      "model.predict_proba(finaldf.iloc[test_index])": 1,
      "word_clf_pred_proba": 1,
      "char_clf_pred_proba": 1,
      "combined_proba": 1,
      "fpv.as_matrix()": 1,
      "y_test": 1,
      "np.ravel(oof_xgb)": 1,
      "train_pred_female": 1,
      "train_pred_male": 1,
      "valid_pred_female": 1,
      "valid_pred_male": 1,
      "scores_train": 1,
      "scores_test": 1,
      "self.model.predict(self.x_val)": 1,
      "model_list[num].predict(val_data)": 1,
      "val_prediction[:, 0]": 1,
      "val_prediction[:, 1]": 1,
      "val_prediction[:, 2]": 1,
      "val_prediction[:, 3]": 1,
      "val_prediction[:, 4]": 1,
      "val_prediction[:, 5]": 1,
      "p_predicted": 1,
      "predicted_train": 1,
      "predict_proba_train": 1,
      "predict_proba_test": 1,
      "y_val_pred1": 1,
      "y_val_pred2": 1,
      "y_val_pred3": 1,
      "res_lr.loc[:, train_targets.columns[tar]]": 1,
      "tab_oof[valid_index]": 1,
      "tab_oof": 1,
      "yp_val": 1,
      "predicted_target[:, i]": 1,
      "oof_preds[val_idx]": 1,
      "dtrain_predictions": 1,
      "stn_p": 1,
      "vld_p": 1,
      "y_pred[:, col].astype('float')": 1,
      "mNB.predict_proba(x2)": 1,
      "df_cv[['low', 'medium', 'high']].values": 1,
      "preds_valid_oob[cv]": 1,
      "preds_valid_oob_merged": 1,
      "preds_train_cv": 1,
      "bst.predict(xgb.DMatrix(df))": 1,
      "out": 1,
      "train_oof_cat_0": 1,
      "train_oof_smote_0": 1,
      "train_oof_lgbm_2d": 1,
      "y_val_pred_prob": 1,
      "nn_oof[n_model, n_seed, val_idx]": 1,
      "gbt_oof[n_model, n_seed, val_idx]": 1,
      "nn_oof[n_model, n_seed]": 1,
      "gbt_oof[n_model, n_seed]": 1,
      "xgb_oof[val_idx]": 1,
      "cbt_oof[val_idx]": 1,
      "xgb_oof": 1,
      "cbt_oof": 1,
      "nn_oof[val_idx]": 1,
      "nn_oof": 1,
      "nm_Y_predict": 1,
      "kmlp.predict_proba(x_train)": 1,
      "y_pre": 1,
      "Y_pred[i]": 1,
      "full_pred": 1,
      "val_prediction": 1,
      "testA_y": 1,
      "testB_y": 1,
      "np.clip(predictions.values * 1.00890035, 1e-06, 1 - 1e-06)": 1,
      "model.predict_proba(X_)": 1,
      "pred_lr": 1,
      "pred_rf": 1,
      "clipped": 1,
      "p[i_val]": 1,
      "preds_prob": 1,
      "tf_preds": 1,
      "pred_val_best": 1,
      "pred_val_best_tta": 1,
      "pred_val_best_avg": 1,
      "p_tta": 1,
      "pred_val_ens_meta": 1,
      "pred_val_ens_avg": 1,
      "p_v": 1,
      "preds1": 1,
      "clf.fit(vecs_tr, ytrain).predict(vecs_te)": 1,
      "search_cvpred": 1,
      "clf.predict_proba(Xvalid_pca)": 1,
      "y_hat_train": 1,
      "model.predict_proba(X_train)": 1,
      "np.clip(preds, 0.05, 0.95)": 1,
      "cat_pred": 1,
      "LOG_pred_val_y[:, 1]": 1,
      "np.ravel(full_pipeline.predict_proba(X_train))": 1,
      "np.ravel(full_pipeline.predict_proba(X_valid))": 1,
      "np.zeros_like(train_set['is_duplicate']) + duplicateP": 1,
      "np.ravel(y_pred2)": 1,
      "y_val1": 1,
      "y_train_star": 1,
      "valid_preds.loc[:, _target]": 1,
      "prval.loc[:, _target]": 1,
      "prval_xgb.loc[:, _target]": 1,
      "prval_lr.loc[:, _target]": 1,
      "prcombo": 1,
      "oof[:, labels.index(label)]": 1,
      "pred1": 1,
      "logreg2.predict_proba(test_scaledx)": 1,
      "logreg3.predict_proba(test_logx)": 1,
      "rfc3.predict_proba(test_scaledx)": 1,
      "lgb.predict_proba(test_x)": 1,
      "lgb2.predict_proba(test_logx)": 1,
      "lgb3.predict_proba(test_scaledx)": 1,
      "lr_yhat_prob": 1,
      "rf_yhat_prob": 1,
      "nn_yhat_prob": 1,
      "ens_yhat_prob": 1,
      "np.ravel(pred_val)": 1,
      "yv[idx_vl]": 1,
      "yv": 1,
      "y": 1,
      "cv_preds": 1,
      "oof_stack[test_index]": 1,
      "temp_pred": 1,
      "c.predict_proba(x[test_index])": 1,
      "train_prediction": 1,
      "pred_label": 1,
      "y_preds2": 1,
      "y_preds3": 1,
      "y_preds4": 1,
      "y_predsfinal": 1,
      "trimmed_preds": 1,
      "np.ravel(ypred)": 1,
      "proba": 1,
      "predict[target]['valid']": 1,
      "m.predict_proba(x_train)": 1,
      "m.predict_proba(x_val)": 1,
      "oof[valid_idx]": 1,
      "np.clip(predictions.values * 1.0100035, 1e-06, 1 - 1e-06)": 1,
      "y_pred_5layers[:, i]": 1,
      "y_pred_4layers[:, i]": 1,
      "y_pred_3layers[:, i]": 1,
      "y_pred_tabnet[:, i]": 1,
      "y_pred_blend[:, i]": 1,
      "model.predict(xgb.DMatrix(x2), ntree_limit=model.best_ntree_limit)": 1,
      "oof_pred1": 1,
      "oof_pred2": 1,
      "oof_pred3": 1,
      "(oof / 2 + oof_tta / 2)[:5000000]": 1,
      "wavenet_oof": 1,
      "pred.clip(0.45, 0.65)": 1,
      "[1, 2]": 1,
      "result.iloc[:200000].to_numpy()": 1,
      "np.power(clf.predict_proba(X_test), power)": 1,
      "predict_y_proba_gbm": 1,
      "np.clip(x_pred * 1.691, 1e-06, 1 - 1e-06)": 1,
      "np.clip(x_pred[:, 1] * 1.0088, 1e-06, 1 - 1e-06)": 1,
      "predicted_probabilities": 1,
      "y_train_pred_prob": 1,
      "prediction_val1": 1,
      "prediction_test1": 1,
      "prediction_train1": 1,
      "np.exp(preds_oof_temp[:, j])": 1,
      "np.exp(preds_test_temp[:, j])": 1,
      "np.exp(preds_train_temp[:, j])": 1,
      "np.exp(preds_oof_cum)": 1,
      "np.exp(preds_test_cum)": 1,
      "np.exp(preds_train_cum)": 1,
      "clf.predict_proba(X_subtest)": 1,
      "np.ravel(y_pred)": 1,
      "clf.predict_proba(test[features])": 1,
      "clf.predict_proba(xtest)": 1,
      "np.zeros_like(train_df['is_duplicate']) + p": 1,
      "result['train']['pred'][name].values": 1,
      "result['test']['pred'][name].values": 1,
      "data[tt]['Pred'].astype(np.float64)": 1,
      "predict_01": 1,
      "y_pred2": 1,
      "y_pred21": 1,
      "qda_prob": 1,
      "lda_prob": 1,
      "logreg_prob": 1,
      "rforest_prob": 1,
      "preds_test": 1,
      "preds_traintd": 1,
      "preds_testtd": 1,
      "preds_traincos": 1,
      "preds_testcos": 1,
      "np.ravel(model.predict_proba(x_val))": 1,
      "np.ravel(nn_predict)": 1,
      "np.ravel(xgb_predict)": 1,
      "np.ravel((nn_predict + xgb_predict) / 2)": 1,
      "yPred": 1,
      "model.predict(x_train_full)": 1,
      "ovr_probs": 1,
      "mo_probs_pos": 1,
      "np.array(chains_ensemble_proba).mean(axis=0)": 1,
      "y_pred1[:, i]": 1,
      "bst.predict(xgb.DMatrix(train[feats]))": 1,
      "pred_g": 1,
      "oof_NN_g": 1,
      "oof_NN[ts_idx]": 1,
      "oof_GBT_NN[ts_idx]": 1,
      "oof_GBT[ts_idx]": 1,
      "oof_NN": 1,
      "oof_GBT_NN": 1,
      "oof_GBT": 1,
      "xpreds": 1,
      "test_predicted_y": 1,
      "pred_logit_t": 1,
      "pred_logit_v": 1,
      "pred_RF_v": 1,
      "pred_RF_t": 1,
      "trainPredictions[:, 1]": 1,
      "y_pred_xgb": 1,
      "model.predict_proba(train_new)": 1,
      "oof_NN_a / NUM_TOP_MODELS": 1,
      "oof_NN_fold_optimized": 1,
      "Val_pred_DT": 1,
      "y_pred.loc[:, pred_col[_target]].astype(float)": 1,
      "yhat_KNN": 1,
      "yhat_tree": 1,
      "yhat_lr": 1,
      "yhat_svm": 1,
      "yhat_xgbc": 1,
      "yhat_ABC": 1,
      "yhat_CBC": 1,
      "res.loc[:, df_train_targets_nonscored.columns[tar]]": 1,
      "y_pred_prob.ravel()": 1,
      "Y_hat": 1,
      "y_scores": 1,
      "y_hat5": 1,
      "y_hat3": 1,
      "y_hat4": 1,
      "model.predict_proba(X1)[:, 1]": 1,
      "model.predict_proba(X2)[:, 1]": 1,
      "model.predict_proba(X3)[:, 1]": 1,
      "model.predict_proba(X4)[:, 1]": 1,
      "model.predict_proba(X5)[:, 1]": 1,
      "y_hat_4_7": 1,
      "rd.predict_proba(blend_train)": 1,
      "y2_hat": 1,
      "pred_mix": 1,
      "pred_lgb": 1,
      "pred_nn": 1,
      "trn_pred": 1,
      "pred_dev": 1,
      "np.array(probabs)": 1,
      "validatepredict": 1,
      "np.ravel(valid_preds)": 1,
      "y_preds[:, col].astype('float')": 1,
      "y_pred + 0.25": 1,
      "clf.predict(X_test)": 1,
      "totalpredictions": 1,
      "np.clip(predictions.values, clipmin, clipmax)": 1,
      "np.clip(mother.GP1.values, clipmin, clipmax)": 1,
      "np.clip(mother.GP2.values, clipmin, clipmax)": 1,
      "np.clip(mother.GP3.values, clipmin, clipmax)": 1,
      "np.clip(mother.GP4.values, clipmin, clipmax)": 1,
      "np.clip(mother.GP5.values, clipmin, clipmax)": 1,
      "np.clip(mother.GP6.values, clipmin, clipmax)": 1,
      "valpreds": 1,
      "GP1(gptrain)": 1,
      "(GP1(gptrain) + GP2(gptrain) + GP3(gptrain)) / 3.0": 1,
      "X_train[['manager_level_low', 'manager_level_medium', 'manager_level_high']]": 1,
      "train[['building_low', 'building_medium', 'building_high']]": 1,
      "train[['manager_low', 'manager_medium', 'manager_high']]": 1,
      "np.hstack([x1, x2, x3])": 1,
      "GP(X)": 1,
      "clf.predict_proba(val_x, num_iteration=clf.best_iteration_)": 1,
      "predictions[cols]": 1,
      "predictions_1": 1,
      "predictions_2": 1,
      "logisticRegressor_char.predict_proba(X_train_norm)": 1,
      "logisticRegressor_char.predict_proba(X_valid_norm)": 1,
      "logisticRegressor_word.predict_proba(X_train_norm)": 1,
      "logisticRegressor_word.predict_proba(X_valid_norm)": 1,
      "logisticRegressor.predict_proba(X_train)": 1,
      "logisticRegressor.predict_proba(X_valid)": 1,
      "valid_result": 1,
      "rfc.predict_proba(X_test)": 1,
      "svc.predict_proba(X_test)": 1,
      "y_val_predicted": 1,
      "resultBayesian_nonprob": 1,
      "pd.read_csv('val_preds_fold_6.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_7.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_8.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_9.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_10.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_11.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_12.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_13.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_14.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_15.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_16.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_17.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_18.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_19.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_20.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_21.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_22.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_23.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_24.txt', header=None).values[:, 0]": 1,
      "pd.read_csv('val_preds_fold_25.txt', header=None).values[:, 0]": 1,
      "np.diag(cosine_scores)": 1,
      "np.ravel(train_pred_probs.toarray())": 1,
      "train_predictions.loc[:, _target]": 1,
      "np.clip(outputs[:, i], eps, 1 - eps)": 1,
      "Rfc.predict_proba(X_tst)": 1,
      "Rfc.predict_proba(X_tr)": 1,
      "lr.predict_proba(X_tst)": 1,
      "cat.predict_proba(X_tr)": 1,
      "cat.predict_proba(X_tst)": 1,
      "y_predicted_crossval": 1,
      "y_predicted_test": 1,
      "results['y_hat']": 1,
      "training_predict.loc[:, _target]": 1,
      "clf.predict_proba(X_test)[:, 1]": 1,
      "out5": 1,
      "eval(file)": 1,
      "out2": 1,
      "np.clip(out2, 0.0001, 0.99)": 1,
      "op": 1,
      "model.predict(x_cv)": 1,
      "bst3.predict(xgbxte)": 1,
      "etc4.predict_proba(xte)": 1,
      "preds2": 1,
      "y_train_v_pred": 1,
      "predictions_val": 1,
      "predict_probabilities": 1,
      "clipping(valid['upset_prob'])": 1,
      "clipping(valid['upset_prob'], config['const']['clip_min'], config['const']['clip_max'])": 1,
      "valid['upset_prob_manually']": 1,
      "np.clip(valid['upset_prob_manually'], 0.05, 0.95)": 1,
      "yhat": 1,
      "test_pre": 1,
      "np.clip(y_pred, a_min=i, a_max=j)": 1,
      "image_preds_prob_all": 1,
      "valdt_PredProb": 1,
      "y_test_pred": 1,
      "model.predict_proba(X_test_sub)": 1,
      "scores_noisy[i]": 1,
      "val_probas": 1,
      "y_probas": 1,
      "np.clip(x_pred[:, 1] * 1.069, 1e-06, 1 - 1e-06)": 1,
      "np.clip(predictions.values * 1.0135, 1e-06, 1 - 1e-06)": 1,
      "pr_sgmd[:, i]": 1,
      "pr_ABN": 1,
      "val_pr": 1,
      "val_pr_avg[e] / (model_id + 1)": 1,
      "pred_avg / (i + 1)": 1,
      "y_prob_lr": 1,
      "y_prob_lr_b": 1,
      "y_prob_lr_b_2": 1,
      "y_prob_kbest_lr_cv": 1,
      "OOF": 1,
      "model.predict(X_valid)": 1,
      "preds_df": 1,
      "oof_list[0].values.ravel()": 1,
      "oof_list[1].values.ravel()": 1,
      "oof_list[2].values.ravel()": 1,
      "oof_list[3].values.ravel()": 1,
      "oof_list[4].values.ravel()": 1,
      "y_pred.values.ravel()": 1,
      "oof_pred_arr_avg_mlp.ravel()": 1,
      "oof_pred_arr_avg_cnn.ravel()": 1,
      "oof_pred_arr_avg_wo.ravel()": 1,
      "np.array(y_pred_proba_t)[:, :, 1].T.ravel()": 1,
      "0.9 * y_oof + 0.1 * y_oof_knn": 1,
      "val_preds_EB0": 1,
      "0.6 * val_preds_EB1 + 0.4 * val_preds_EB0": 1,
      "val_preds_5": 1,
      "0.6 * val_preds_6 + 0.4 * val_preds_5": 1,
      "0.55 * val_preds_7 + 0.33 * val_preds_6 + 0.12 * val_preds_5": 1,
      "pred_noemb_val_y": 1,
      "pred_fasttext_val_y": 1,
      "pred_paragram_val_y": 1,
      "nb_probs": 1,
      "final_probs": 1,
      "cnb_probs": 1,
      "lr_probs": 1,
      "ada_probs": 1,
      "vote_probs": 1,
      "yfull_train": 1,
      "predicted_values[:, moa_idx].astype(np.float)": 1,
      "pred[:, i]": 1,
      "model.predict(x)": 1,
      "traintion": 1,
      "validation": 1,
      "predicts": 1,
      "predictions_test_prob": 1,
      "predictions_binarizer": 1,
      "predictions_test_binarizer": 1,
      "validation_pred": 1,
      "probabilities[:, 0]": 1,
      "y_valid_pred": 1,
      "np.ravel(np.clip(oof_pred, p_min, p_max))": 1,
      "clf.predict_proba(features_test)": 1,
      "y_preds_raw": 1,
      "y_preds_iso": 1,
      "oof_blend": 1,
      "pred_valid[valid_idx]": 1,
      "x[1].predict_proba(test_min)[:, -1]": 1,
      "x[1].predict_proba(test_max)[:, -1]": 1,
      "y_predprob": 1,
      "np.clip(x_pred[:, 1] * 1.721, 1e-06, 1 - 1e-06)": 1,
      "prob_pos": 1,
      "clf_probs_x": 1
    },
    "sklearn.base.TransformerMixin.fit_transform.X": {
      "X_train": 763,
      "X": 657,
      "train": 223,
      "x_train": 165,
      "X_test": 157,
      "x": 140,
      "test": 109,
      "data.iloc[:, 4:]": 97,
      "train.drop(['y'], axis=1)": 88,
      "data": 75,
      "poly_features": 67,
      "df": 64,
      "x_test": 61,
      "train_df[features]": 57,
      "data[cols]": 53,
      "scale(X)": 49,
      "y_train": 47,
      "domain_features": 44,
      "cdf[numcols]": 37,
      "train_df": 34,
      "X_prep_low[:, i]": 33,
      "tr_indi_df": 29,
      "df_train": 27,
      "train_X": 26,
      "X0_train_iter": 26,
      "train_dfX": 25,
      "features": 25,
      "test1[numcols]": 24,
      "testA[numcols]": 24,
      "train_data": 23,
      "train.values": 21,
      "X_train[:, 0:size]": 21,
      "X_val[:, 0:size]": 21,
      "train_features": 20,
      "test_df": 19,
      "hits[['x2', 'y2', 'z2']].values": 19,
      "market_train[num_cols]": 19,
      "train[features]": 19,
      "test_data": 18,
      "train[col]": 18,
      "xtrain": 18,
      "train.target.reshape(-1, 1)": 17,
      "train[v]": 17,
      "predicted.reshape(-1, 1)": 17,
      "xtrain_glove": 16,
      "df_total[cols_to_scale]": 16,
      "F": 15,
      "train_x": 15,
      "tr_cnts": 15,
      "train.drop(['target'], axis=1)": 14,
      "X.toarray()": 14,
      "train_df.values": 13,
      "sales2014.values.reshape(-1, 1)": 13,
      "sales2015.values.reshape(-1, 1)": 13,
      "X0_test_iter": 13,
      "df_test": 13,
      "X_tr": 13,
      "x_cnts": 13,
      "sales2013.values.reshape(-1, 1)": 12,
      "data[GENES + CELLS]": 12,
      "df[cols]": 12,
      "y": 12,
      "train_temp_X": 12,
      "VarianceThreshold(threshold=2).fit_transform(data[cols])": 12,
      "all_df[numerical_cols]": 12,
      "X[Cols]": 12,
      "all_data[0]": 12,
      "train[num_features]": 11,
      "train_dense[col].values[:, None]": 11,
      "train_df['ConfirmedCases'].values.reshape(len(train_df['ConfirmedCases'].values), 1)": 11,
      "df_subsampled[['q1_n_words', 'q1len', 'q2_n_words', 'q2len', 'word_share']]": 10,
      "dataset": 10,
      "test_X": 10,
      "X_train[X_train.columns[:-1]]": 10,
      "PCA(n_components=40, random_state=4).fit_transform(data[cols])": 10,
      "PCA(svd_solver='full', n_components='mle').fit_transform(data[cols])": 9,
      "train[['Country_Region', 'Province_State']].fillna('')": 9,
      "cvz": 9,
      "dt": 9,
      "X_train_counts": 9,
      "train[['ps_reg_03']]": 9,
      "train[['ps_car_11']]": 9,
      "train[['ps_car_14']]": 9,
      "df[num_cols]": 9,
      "train.loc[train['PdDistrict'] == district, ['X', 'Y']]": 9,
      "X_train.values": 8,
      "df_train['SalePrice'][:, np.newaxis]": 8,
      "sales[[v]]": 8,
      "tmp": 8,
      "df.loc[:, ['Province_State', 'Country_Region']]": 8,
      "train[col].values.reshape(-1, 1)": 8,
      "test_temp_X": 8,
      "app_train_poly": 8,
      "X[:, 2:]": 8,
      "X_sub": 8,
      "rescaleIMG": 8,
      "spectral_centroids.reshape(-1, 1)": 8,
      "X_preprocessed[[col]]": 8,
      "VarianceThreshold(threshold=1.5).fit_transform(data[cols])": 7,
      "train_df[cols]": 7,
      "X[cols]": 7,
      "train_test[numeric_feats].values": 7,
      "merged_dat[numeric_features]": 7,
      "X_val": 7,
      "tv_X_train": 7,
      "train_feat": 7,
      "pd.concat([df_train_.loc[:, input_features], df_test_.loc[:, input_features]])": 7,
      "market_train_df[num_cols]": 7,
      "data.iloc[:, 3:]": 7,
      "train_df[cols_numeric]": 7,
      "train.drop(['id', 'target'], axis=1)": 7,
      "market_train_df[num_columns]": 6,
      "data_in.reshape(-1, 1)": 6,
      "X_valid": 6,
      "X[num]": 6,
      "total": 6,
      "train_X[train_columns]": 6,
      "all_data[scale_list].astype(float)": 6,
      "X[features]": 6,
      "data.reshape(-1, 1)": 6,
      "x_test[:, 0:1]": 6,
      "train_num": 6,
      "num_df": 6,
      "np.log1p(train['price'].values.reshape(-1, 1))": 6,
      "trainX": 6,
      "temp": 6,
      "X.values": 6,
      "sparse_merge": 6,
      "train[features].values": 6,
      "train_features[GENES + CELLS]": 6,
      "X_train[['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4']]": 6,
      "train[cols]": 6,
      "train_df['Fatalities'].values.reshape(len(train_df['Fatalities'].values), 1)": 6,
      "alldata": 6,
      "X_test_preprocessed[[col]]": 6,
      "val_preprocessed[[col]]": 6,
      "df.loc[~df[c].isnull(), c].values.reshape(-1, 1)": 6,
      "X2": 6,
      "test_data.toarray()": 5,
      "all_df": 5,
      "training_data.values": 5,
      "X_train_all": 5,
      "tsne_result": 5,
      "pet_train": 5,
      "pet_submit": 5,
      "test1": 5,
      "y_test": 5,
      "dataset[['desc_len', 'name_len']]": 5,
      "app_train_domain": 5,
      "xTrain": 5,
      "train.loc[:, ['Province_State', 'Country_Region']]": 5,
      "test.loc[:, ['Province_State', 'Country_Region']]": 5,
      "df[features]": 5,
      "x_val": 5,
      "train[['ps_car_12']]": 5,
      "X_t": 5,
      "df[[i]]": 5,
      "df.values": 5,
      "all_data[vcols].fillna(-1)": 5,
      "small_document_term_matrix": 5,
      "data[[v]]": 5,
      "traintest[cols]": 5,
      "X_te": 5,
      "target_data_1": 5,
      "target_data_3": 5,
      "x_data_generated": 5,
      "train.target.values.reshape(-1, 1)": 5,
      "X_tr[i]": 5,
      "X_te[i]": 5,
      "Y_train": 5,
      "DF": 5,
      "DF['sales'].values.reshape(-1, 1)": 5,
      "freq1_term_matrix": 5,
      "freq2_term_matrix": 5,
      "freq3_term_matrix": 5,
      "freq4_term_matrix": 5,
      "train2": 5,
      "data.values.reshape(-1, 1)": 5,
      "pd.DataFrame(d['Date'])": 5,
      "df_to_transform": 4,
      "X_eval": 4,
      "train_set": 4,
      "values": 4,
      "test[features]": 4,
      "y.reshape(-1, 1)": 4,
      "df[temp]": 4,
      "test_df[cols]": 4,
      "trainData": 4,
      "df.loc[ids, features_n]": 4,
      "x_test[:, np.newaxis]": 4,
      "order * np.array([ranks]).T": 4,
      "matrix": 4,
      "full_train_new": 4,
      "dataModified": 4,
      "np.concatenate((train_X, test), axis=0)": 4,
      "train[feature_columns]": 4,
      "train_temp_cc": 4,
      "train_temp_ft": 4,
      "X1": 4,
      "X_num": 4,
      "total_data": 4,
      "df[var].values.reshape(-1, 1)": 4,
      "df_train[['question_body_num_words', 'answer_num_words']].values": 4,
      "df_train_features": 4,
      "train[[c]]": 4,
      "inputs_count": 4,
      "predictors1": 4,
      "np.column_stack([x / d, y / d, z / r])": 4,
      "train['SalePrice'][:, np.newaxis]": 4,
      "tr_te[f_num]": 4,
      "all_dummies_scaled[['Age', 'SibSp', 'Parch', 'norm_fare']]": 4,
      "df_train[col].values.reshape(-1, 1)": 4,
      "train_X_df": 4,
      "dataframe": 4,
      "dtm_lsa": 4,
      "item.reshape((item.shape[0], 1))": 4,
      "train[['num_words', 'num_comas', 'num_bangs', 'num_quotas', 'avg_word']]": 4,
      "Xtrain": 4,
      "X_all": 4,
      "X[col]": 4,
      "X_train[['ord_0', 'ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5']]": 4,
      "target_data_2": 4,
      "train[train.columns.difference(['Patient', 'FVC', 'Percent', 'Weeks', 'base_Weeks'])]": 4,
      "X.append(X_test)": 4,
      "calendar['event_name_1'].to_numpy().reshape(-1, 1)": 4,
      "calendar['event_name_2'].to_numpy().reshape(-1, 1)": 4,
      "freq_term_matrix": 4,
      "all_data[numcols]": 4,
      "train[feat].values.reshape(-1, 1)": 4,
      "np.array(df[col]).reshape(-1, 1)": 4,
      "raw_data": 4,
      "y_train.reshape(-1, 1)": 4,
      "train.iloc[:, 2:]": 4,
      "spectral_rolloff": 4,
      "df[i].values.reshape(-1, 1)": 4,
      "train_two[['temp', 'atemp', 'humidity', 'windspeed']]": 4,
      "merged_df[feat].values.reshape(s1)": 4,
      "freq5_term_matrix": 4,
      "train[kolom]": 4,
      "x_train_solo": 4,
      "x_train_duo": 4,
      "x_train_squad": 4,
      "x_train_solo_fpp": 4,
      "x_train_duo_fpp": 4,
      "x_train_squad_fpp": 4,
      "x_train_flarefpp": 4,
      "x_train_flaretpp": 4,
      "x_train_crashfpp": 4,
      "x_train_crashtpp": 4,
      "[[n]]": 4,
      "training_data": 4,
      "feature_score": 4,
      "x_data": 4,
      "x[features]": 4,
      "test[features_t]": 4,
      "xtrn": 4,
      "test_feat": 4,
      "days_array": 4,
      "data[feat_cols]": 4,
      "x_train[oe_features]": 3,
      "X_train[features]": 3,
      "merged_df[:, cont_feats_idx]": 3,
      "merged_df[:, int_feats_idx]": 3,
      "x_valid": 3,
      "train_reduced": 3,
      "test_reduced": 3,
      "[[past_volatility]]": 3,
      "data[col].values.reshape(-1, 1)": 3,
      "train_diff_series.reshape(-1, 1)": 3,
      "X_train[normalized_features]": 3,
      "images": 3,
      "df[numerical_features]": 3,
      "X[:, :]": 3,
      "df.iloc[:, 1:]": 3,
      "x1": 3,
      "train[nums]": 3,
      "arr": 3,
      "df1": 3,
      "X[:, 0:1]": 3,
      "X[:, 2:3]": 3,
      "X1[:, 0:1]": 3,
      "X1[:, 2:3]": 3,
      "train_df['image_size'].values.reshape(-1, 1)": 3,
      "X[X.columns]": 3,
      "train.drop(columns='SalePrice')": 3,
      "transformed": 3,
      "X[inter_features]": 3,
      "train2[cols]": 3,
      "X_train_num": 3,
      "df[to_ordinal]": 3,
      "df[[v]]": 3,
      "data1": 3,
      "xTest": 3,
      "train_tv_X": 3,
      "X_data": 3,
      "df[['Province_State', 'Country_Region']].values": 3,
      "X_train.astype(np.float64)": 3,
      "train[[col]]": 3,
      "y_train.values.reshape(-1, 1)": 3,
      "train_y": 3,
      "input_df": 3,
      "X_train_o": 3,
      "X_train_plus": 3,
      "train1": 3,
      "counts": 3,
      "test_features": 3,
      "X_test_temp1": 3,
      "df_train2": 3,
      "sales['item_price'].values.reshape(-1, 1)": 3,
      "test_x": 3,
      "mtrain.loc[ids, features_n]": 3,
      "df.drop(['id', 'target'], axis=1)": 3,
      "df['cp_time'].values.reshape(-1, 1)": 3,
      "train_df[num_cols].values": 3,
      "vector": 3,
      "removeNA": 3,
      "final_test": 3,
      "df2": 3,
      "all_data": 3,
      "X[scale_cols]": 3,
      "importance_df": 3,
      "X_train['num_words'].values.reshape(-1, 1)": 3,
      "X_train['num_unique_words'].values.reshape(-1, 1)": 3,
      "X_train['num_char'].values.reshape(-1, 1)": 3,
      "X_train['num_stopwords'].values.reshape(-1, 1)": 3,
      "dfInput[[columnName]]": 3,
      "train_feature": 3,
      "X_train[['ord_0', 'ord_1', 'ord_3', 'ord_4', 'ord_5']]": 3,
      "full_df.loc[:, 'var_0':'var_199'].values": 3,
      "df[numerical]": 3,
      "train_X_encoded": 3,
      "confidence": 3,
      "df[[col]]": 3,
      "x_train[simple_features]": 3,
      "nptrain_xNu": 3,
      "nptest_xNu": 3,
      "np.array(predict_x).reshape(-1, 1)": 3,
      "df[cont_vars].fillna(-1)": 3,
      "X_train.toarray()": 3,
      "X_test1": 3,
      "x_train_fs.astype('float')": 3,
      "train_vectors": 3,
      "X[:, i:i + 1]": 3,
      "df_temp": 3,
      "data_test": 3,
      "to_norm": 3,
      "X_train_vec": 3,
      "df_NoDate": 3,
      "train_X_cc": 3,
      "train_y_cc": 3,
      "train_X_ft": 3,
      "train_y_ft": 3,
      "X_test.values": 3,
      "concat.values": 3,
      "meta.values": 3,
      "train_df.drop(['isFraud'], axis=1)": 3,
      "z": 3,
      "compresed_xy[0].reset_index(drop=True)": 3,
      "preddata": 3,
      "train.loc[:, cols_pca]": 3,
      "imputed_df[col].ravel().reshape(-1, 1)": 3,
      "train.drop([target_col], axis=1)": 3,
      "state_i_data[i]": 3,
      "df_pipe[[col]]": 3,
      "impute_reshape": 3,
      "app_train[c].values.reshape(-1, 1)": 3,
      "X_train.to_pandas()": 3,
      "standardized_train": 3,
      "train[ordinal]": 3,
      "d": 3,
      "df[['revenue']]": 3,
      "X_completo_num": 3,
      "train0": 3,
      "X_train_arr.reshape(-1, 1)": 3,
      "data[scale_cols]": 3,
      "df2.values": 3,
      "[[temp0]]": 3,
      "Correlation_df": 2,
      "Titanic_train_x": 2,
      "Titanic_predict_x": 2,
      "yTrain[['returnsOpenNextMktres10']]": 2,
      "rides": 2,
      "dataset.loc[:, continuous_features]": 2,
      "dfp_subsampled[['cwc_min', 'cwc_max', 'csc_min', 'csc_max', 'ctc_min', 'ctc_max', 'last_word_eq', 'first_word_eq', 'abs_len_diff', 'mean_len', 'token_set_ratio', 'token_sort_ratio', 'fuzz_ratio', 'fuzz_partial_ratio', 'longest_substr_ratio']]": 2,
      "X_trn": 2,
      "full_df.ord_1.values.reshape(-1, 1)": 2,
      "full_df.ord_2.values.reshape(-1, 1)": 2,
      "full_df[feat].values.reshape(-1, 1)": 2,
      "df.iloc[:, 1:3]": 2,
      "news_sentiment_X": 2,
      "user_reduced": 2,
      "df.excerpt": 2,
      "id_lookup[['item_id']]": 2,
      "id_lookup[['dept_id']]": 2,
      "id_lookup[['store_id']]": 2,
      "df[floats]": 2,
      "df[feat_cols].values": 2,
      "X_train_1": 2,
      "test_df2": 2,
      "X_train[num_vars]": 2,
      "xtr[i]": 2,
      "xte[i]": 2,
      "X_train[categorical_cols]": 2,
      "X_train[numeric_features]": 2,
      "df[num_features]": 2,
      "train_df[['FVC']]": 2,
      "train_df[['Percent']]": 2,
      "train_df[['Age']]": 2,
      "tsne_res": 2,
      "sales_values": 2,
      "train[feature_names].values": 2,
      "countsMatrix": 2,
      "train_df[feature_cols]": 2,
      "xtest": 2,
      "train_features[g_c_features]": 2,
      "sample_train_x": 2,
      "np.array(data[enc]).reshape(-1, 1)": 2,
      "train_data_cc": 2,
      "df_num.values": 2,
      "df[x_cols]": 2,
      "y.reshape(-1, 1) + 1": 2,
      "vectorized_text": 2,
      "tfidf": 2,
      "analyzer.fit_transform(frame.comment_text)": 2,
      "all_df['age'].values.reshape((-1, 1))": 2,
      "all_df['idhogar'].values.reshape((-1, 1))": 2,
      "x_train_numerical": 2,
      "y[:, None]": 2,
      "sales_train.values": 2,
      "TEST": 2,
      "test[nums]": 2,
      "final_x": 2,
      "df_p": 2,
      "all_data[cols]": 2,
      "[train_data['AgeGroup']]": 2,
      "[train_data['FareRange']]": 2,
      "air_store_id_reshaped": 2,
      "df_1": 2,
      "target": 2,
      "train[['Embarked']]": 2,
      "X[numeric_cols]": 2,
      "train_set[['Csum']]": 2,
      "test_set[['Csum']]": 2,
      "feature_df['prior_question_elapsed_time'].to_numpy().reshape(-1, 1)": 2,
      "train_df['n_images'].values.reshape(-1, 1)": 2,
      "train_df.image_size_scaled.values.reshape(-1, 1)": 2,
      "train_df['mean_color'].values.reshape(-1, 1)": 2,
      "train_imputed": 2,
      "train_imputed.copy()": 2,
      "train['image_size'].values.reshape(-1, 1)": 2,
      "test_data_X": 2,
      "pred": 2,
      "plot_5d.iloc[:, 2:-2]": 2,
      "clone['GOOG'].values.reshape(-1, 1)": 2,
      "TruncatedSVD(n_components=40, random_state=4).fit_transform(data[cols])": 2,
      "initial_imp.iloc[:, 1:]": 2,
      "aug_imp.iloc[:, 1:]": 2,
      "np.array(all_data[col]).reshape(-1, 1)": 2,
      "sparse": 2,
      "clean_train_df": 2,
      "getColumn(X.index)": 2,
      "train[['Age']].copy()": 2,
      "test[['Age']].copy()": 2,
      "trainSet2": 2,
      "tr1_X": 2,
      "train[train.columns[:10]]": 2,
      "trainN[:]": 2,
      "combined[none_cols]": 2,
      "combined[nom_cols]": 2,
      "combined[cols]": 2,
      "df_work[ordvar[3:]]": 2,
      "df_work[ordvar]": 2,
      "train[cont_cols]": 2,
      "X_train_scaling": 2,
      "numeric_df": 2,
      "X_train[index].iloc[:, 1:4]": 2,
      "X_test[index].iloc[:, 1:4]": 2,
      "np.array(my_df[feat]).reshape(-1, 1)": 2,
      "x_smote": 2,
      "sales": 2,
      "X_ca": 2,
      "train_num_feature": 2,
      "sales_train['item_price'].values.reshape(-1, 1)": 2,
      "X_play": 2,
      "X_ir": 2,
      "X_train_values": 2,
      "X_val_values": 2,
      "test_df_values": 2,
      "play_df": 2,
      "player_df": 2,
      "train_x[im_features].astype(np.float32)": 2,
      "val_x[im_features].astype(np.float32)": 2,
      "results": 2,
      "self.train_df[numerical_features]": 2,
      "df[features].values": 2,
      "X_train_full": 2,
      "test[num_features]": 2,
      "train.loc[:, mask]": 2,
      "comb": 2,
      "np.column_stack([aa, aa / zr, zr, 1 / zr, aa / zr + 1 / zr])": 2,
      "train_data[cont_cols]": 2,
      "data[[feature]]": 2,
      "solutions_set": 2,
      "dfh[['sina1', 'cosa1', 'z1', 'z2', 'x1', 'x2', 'x3', 'x4']].values": 2,
      "train[['v2a1']]": 2,
      "train[['v18q1']]": 2,
      "train[['rez_esc']]": 2,
      "train[['meaneduc']]": 2,
      "train[['SQBmeaned']]": 2,
      "test[['v2a1']]": 2,
      "test[['v18q1']]": 2,
      "test[['rez_esc']]": 2,
      "test[['meaneduc']]": 2,
      "test[['SQBmeaned']]": 2,
      "train['Population'].values[:, np.newaxis]": 2,
      "cases_data['TargetValue'].values[:, np.newaxis]": 2,
      "fatalities_data['TargetValue'].values[:, np.newaxis]": 2,
      "train_X[col]": 2,
      "titanic_train_2[num_vars]": 2,
      "titanic_test_2[num_vars]": 2,
      "train_result_x": 2,
      "df_result_test": 2,
      "X.reshape(-1, 1)": 2,
      "sc": 2,
      "market_train_subset[num_cols]": 2,
      "X[num_cols]": 2,
      "test[num_cols]": 2,
      "X[cat_cols]": 2,
      "df1[feature_cols]": 2,
      "train_weather[cols_with_missing_train_weather]": 2,
      "building_data[cols_with_missing_building]": 2,
      "xvalid_glove": 2,
      "ngs_agg2.fillna(0).values": 2,
      "data_train": 2,
      "train_data[train_numerical[:-1]]": 2,
      "X[col].values.reshape(-1, 1)": 2,
      "dataframe[column].values.reshape(-1, 1)": 2,
      "X_treino": 2,
      "X_train_out.select_dtypes(exclude=['object'])": 2,
      "data['Age'].values.reshape(-1, 1)": 2,
      "train_wheezy": 2,
      "train_users": 2,
      "X[X.columns[-10:]]": 2,
      "train_dataset_weight": 2,
      "train[predictors]": 2,
      "test.drop('ID_code', axis=1)": 2,
      "X_train_vect": 2,
      "X_submission": 2,
      "train['fnlwgt'].values.reshape(-1, 1)": 2,
      "train['age'].values.reshape(-1, 1)": 2,
      "dummied": 2,
      "X_cases": 2,
      "X_fatal": 2,
      "df[col]": 2,
      "ord_5_matrix": 2,
      "data[ordinal_data]": 2,
      "data[day_n_month]": 2,
      "train[feature_cols]": 2,
      "train_hour": 2,
      "test_hour": 2,
      "pop": 2,
      "tests": 2,
      "healthexp": 2,
      "cells_df": 2,
      "genes_df": 2,
      "VT_ALL": 2,
      "x_tr": 2,
      "train.values[:, top_feats]": 2,
      "X[['Fare']]": 2,
      "test_copy[['Fare']]": 2,
      "train[num_cols]": 2,
      "time": 2,
      "xtrain[cols]": 2,
      "train_df[num_cols_train[:-1]]": 2,
      "processed_data": 2,
      "big_X": 2,
      "targets": 2,
      "X[nonCat]": 2,
      "train[['mjd', 'flux', 'flux_err']]": 2,
      "X_test + X_train": 2,
      "dfTreino[dfTreino.columns]": 2,
      "dfTeste[dfTeste.columns]": 2,
      "test_feature": 2,
      "df_train.iloc[:, 2:]": 2,
      "df_test.iloc[:, 1:]": 2,
      "X_hash.values": 2,
      "np_confirmed": 2,
      "train[numeric_cols_train]": 2,
      "test[numeric_cols_test]": 2,
      "sentence_train_counts": 2,
      "X_": 2,
      "genome": 2,
      "testX": 2,
      "train_set.drop('item_cnt_month', axis=1)": 2,
      "train.iloc[:, 4:]": 2,
      "x_train_df": 2,
      "librosa.power_to_db(S)": 2,
      "X_train2": 2,
      "X_temp1": 2,
      "train_new": 2,
      "train.loc[:, train.columns.difference(['Patient', 'FVC', 'Percent', 'Weeks', 'base_Weeks'])]": 2,
      "Features": 2,
      "fea_imp[['imp']]": 2,
      "HoldX[Cols]": 2,
      "PressScore1[['PressScore']]": 2,
      "MAAE1[[var1]]": 2,
      "X[[c]]": 2,
      "oof_df[type_one_column_list]": 2,
      "oof_df[type_three_column_list]": 2,
      "tmp[type_three_column_list]": 2,
      "oof_df[type_four_column_list]": 2,
      "tmp[type_four_column_list]": 2,
      "train_dataset": 2,
      "trn_term_doc": 2,
      "X_concat": 2,
      "train_knn": 2,
      "train_df[SCALE_COLUMNS]": 2,
      "sales_prices['sell_price'].to_numpy().reshape(-1, 1)": 2,
      "train.set_index(['ID_code', 'target'])": 2,
      "test.set_index(['ID_code'])": 2,
      "input_data": 2,
      "labels": 2,
      "dataset[feat_scale]": 2,
      "price.values.reshape(-1, 1).astype(np.float64)": 2,
      "train.drop(['Id', 'Cover_Type'], axis=1)": 2,
      "distance_col": 2,
      "traintest": 2,
      "df_test[col].values.reshape(-1, 1)": 2,
      "vec_arr": 2,
      "train_data[categorical_cols]": 2,
      "count_vectors": 2,
      "X_cats": 2,
      "X_nums": 2,
      "pd.DataFrame(X_cats, columns=[X_cats_names])[ordinal_features]": 2,
      "X_transformed": 2,
      "xtrain[:]": 2,
      "xtest[:]": 2,
      "tdata_local": 2,
      "final_bow_count": 2,
      "final_tfidf_count": 2,
      "x_d": 2,
      "x_train_c": 2,
      "x_train_f": 2,
      "test[['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp', 'humidity', 'year', 'month', 'day', 'hour', 'weekday', 'windspeed']]": 2,
      "numeric": 2,
      "X_train_nn": 2,
      "df.loc[:, features].values": 2,
      "Xx": 2,
      "play_train_df[play_train_num_cols]": 2,
      "VarianceThreshold(threshold=1).fit_transform(data[cols])": 2,
      "data_filtered_1[list_numerical_cols]": 2,
      "xtr": 2,
      "data_set": 2,
      "ord_3": 2,
      "test_new": 2,
      "test_df[features]": 2,
      "data_plot": 2,
      "train_x.values": 2,
      "result": 2,
      "X_train[X_train.type == t].drop(['type'], axis=1)": 2,
      "df_num": 2,
      "test.values": 2,
      "train_ds": 2,
      "copy": 2,
      "train_df[['day']]": 2,
      "train_df[[i]]": 2,
      "X_train[col].values.reshape(-1, 1)": 2,
      "avec": 2,
      "data[column].values.reshape(-1, 1)": 2,
      "hq1": 2,
      "hq2": 2,
      "hq3": 2,
      "Y.reshape(-1, 1)": 2,
      "X_train_firep": 2,
      "tabular_df_encoded.drop('AdoptionSpeed', 1)": 2,
      "x_train[col].values.reshape(-1, 1)": 2,
      "X[i].values.reshape(-1, 1)": 2,
      "test[i].values.reshape(-1, 1)": 2,
      "X1_train": 2,
      "X1_test": 2,
      "X_train0": 2,
      "train_u": 2,
      "train[num_id_colmns]": 2,
      "test[num_id_colmns]": 2,
      "x_LotFrontage_train_lr": 2,
      "total_df": 2,
      "df[real_feature]": 2,
      "train[numerical_train]": 2,
      "test[numerical_test]": 2,
      "market[reduced_cols]": 2,
      "X_train[:, 192:]": 2,
      "X_full": 2,
      "df2['Fare'].to_numpy().reshape((-1, 1))": 2,
      "a": 2,
      "df_tmdb[['budget', 'popularity', 'runtime', 'avg_star_power', 'avg_star_power_total', 'avg_crew_power', 'avg_crew_power_total', 'avg_production_power', 'avg_production_power_total', 'cast_len', 'crew_len', 'production_companies_len', 'production_countries_len', 'keywords_len', 'genres_len', 'original_title_letter_count', 'original_title_word_count', 'title_word_count', 'overview_word_count', 'tagline_word_count', 'log_popularity', 'log_budget', 'release_year', 'log_avg_star_power', 'log_avg_star_power_total', 'log_avg_crew_power', 'log_avg_crew_power_total', 'log_avg_production_power', 'log_avg_production_power_total']]": 2,
      "_model.predict(_df[attr_list]).reshape(-1, 1)": 2,
      "df_ov": 2,
      "train_df[cols_normalize]": 2,
      "self.X": 2,
      "new_train[features].values": 2,
      "df_train_feature.iloc[:, 0:10]": 2,
      "l_train": 2,
      "fnc": 2,
      "pca_df.values": 2,
      "test_df.drop(['date'], 1).values": 2,
      "features.values": 2,
      "df_final": 2,
      "df_train.drop(['ID_code', 'target'], axis=1)": 2,
      "Y[:, None]": 2,
      "data['Ticket'].values.reshape(-1, 1)": 2,
      "data['Fare'].values.reshape(-1, 1)": 2,
      "dataTrain3": 2,
      "dataTest2": 2,
      "np.concatenate((x_train, df_test), axis=0)": 2,
      "X_train_clean": 2,
      "X[:, 0:]": 2,
      "df_tmp[self.cols]": 2,
      "price.reshape(-1, 1)": 2,
      "X[[cname]]": 2,
      "train.ix[indextrain]": 2,
      "X_Test": 2,
      "X_Train": 2,
      "e__": 2,
      "data_all[scale_col]": 2,
      "all_features": 2,
      "train_data['image_size'].values.reshape(-1, 1)": 2,
      "train_data.image_size_scaled.values.reshape(-1, 1)": 2,
      "train[dis_train]": 2,
      "test[dis_test]": 2,
      "df[var_cols]": 2,
      "df[col_n1]": 2,
      "X_train_c": 2,
      "X_test_c": 2,
      "future_forcast": 2,
      "val_X": 2,
      "X_Train_CS_SS": 2,
      "X_Test_CS_SS": 2,
      "df_C": 2,
      "binary_log[feature_train]": 2,
      "binary_log_NO[feature_train]": 2,
      "binary_log_NO_TNO[feature_train]": 2,
      "binary_num[feature_train]": 2,
      "binary_num_NO[feature_train]": 2,
      "binary_num_NO_TNO[feature_train]": 2,
      "ordinal_num[feature_train]": 2,
      "ordinal_num_NO[feature_train]": 2,
      "ordinal_num_NO_TNO[feature_train]": 2,
      "ordinal_log[feature_train]": 2,
      "ordinal_log_NO[feature_train]": 2,
      "ordinal_log_NO_TNO[feature_train]": 2,
      "freq_num[feature_train]": 2,
      "freq_num_NO[feature_train]": 2,
      "freq_num_NO_TNO[feature_train]": 2,
      "freq_log[feature_train]": 2,
      "freq_log_NO[feature_train]": 2,
      "freq_log_NO_TNO[feature_train]": 2,
      "train_sub.drop('target', axis=1).astype(float)": 2,
      "train_sub.drop(columns='target')": 2,
      "market_train[INPUT_COLS]": 2,
      "batch['signal'].values.reshape(-1, 1)": 2,
      "data[fet_num_list]": 2,
      "data[num_cols]": 2,
      "X_counts": 2,
      "terms_matrix": 2,
      "df[feat].values.reshape(-1, 1)": 2,
      "X_train_fat": 2,
      "y_train_fat": 2,
      "X_valid_fat": 2,
      "y_valid_fat": 2,
      "data[Continuos_cols]": 2,
      "meta[num_cols_to_scale]": 2,
      "scaledtrain[features]": 2,
      "testX_Date": 2,
      "df[['age_approx']]": 2,
      "xfull": 2,
      "concat_df[features]": 2,
      "alldata.loc[~alldata[c].isnull(), c].values.reshape(-1, 1)": 2,
      "train[train.columns[3:]]": 2,
      "np.column_stack([f0, f1, f2])": 2,
      "all_data[['BsmtFinType1']]": 2,
      "all_data[['Electrical']]": 2,
      "all_data[['MSZoning']]": 2,
      "all_data[['Functional']]": 2,
      "all_data[['Utilities']]": 2,
      "all_data[['BsmtHalfBath']]": 2,
      "all_data[['BsmtFullBath']]": 2,
      "all_data[['KitchenQual']]": 2,
      "all_data[['Exterior2nd']]": 2,
      "all_data[['Exterior1st']]": 2,
      "all_data[['BsmtFinSF1']]": 2,
      "all_data[['SaleType']]": 2,
      "all_data[['TotalBsmtSF']]": 2,
      "all_data[['BsmtUnfSF']]": 2,
      "all_data[['BsmtFinSF2']]": 2,
      "all_data[['GarageCars']]": 2,
      "all_data[['GarageArea']]": 2,
      "all_data[['MasVnrType']]": 2,
      "all_data[['MasVnrArea']]": 2,
      "summary_df_vect": 2,
      "train_df.drop(['y'], axis=1)": 2,
      "f": 2,
      "poly.fit_transform(scaler.fit_transform(X))": 2,
      "scaler.fit_transform(X)": 2,
      "prepared_sample.reshape(-1, 1)": 2,
      "test.iloc[:, 1:]": 2,
      "Xt": 2,
      "y_test.reshape(-1, 1)": 2,
      "X.append(test)": 2,
      "minmax_x_valid": 2,
      "prices_log.reshape(-1, 1)": 2,
      "df[train_columns]": 2,
      "X_casa_treino": 2,
      "X_teste_submit": 2,
      "train[col].to_frame()": 2,
      "X[quantitatives]": 2,
      "test[quantitatives]": 2,
      "df_train[features]": 2,
      "train[['standard_error']]": 2,
      "train[['target']]": 2,
      "test_X_encoded": 2,
      "traindf[[i]]": 2,
      "[[total_days]]": 2,
      "[[total_days + 1]]": 2,
      "returns_train['returnsOpenNextMktres10'].astype(float).values.reshape(-1, 1)": 2,
      "returns_test['returnsOpenNextMktres10'].astype(float).values.reshape(-1, 1)": 2,
      "lm_results.reshape(-1, 1)": 2,
      "lg_results.reshape(-1, 1)": 2,
      "svm_results.reshape(-1, 1)": 2,
      "df[df.columns[:-1]]": 2,
      "np.concatenate((train_feat, test_feat), axis=0)": 2,
      "train_cluster[bincol_labeled]": 2,
      "train_cluster[normcol_labeled]": 2,
      "df.Response_Answer": 2,
      "X_train[:14]": 2,
      "train_df[['ConfirmedCases']]": 2,
      "train_df[['Fatalities']]": 2,
      "temp_scaled[numerical_columns]": 2,
      "train_X[features]": 2,
      "arr[:, 0:21]": 2,
      "province_confirm": 1,
      "province_fatalities": 1,
      "train[all_feat_cols]": 1,
      "data_set[data_set.columns]": 1,
      "data_test[data_set.columns]": 1,
      "x_train_counts": 1,
      "data[[i]]": 1,
      "np.array(df['index']).reshape(-1, 1)": 1,
      "df_test_over": 1,
      "data_raw[[column]]": 1,
      "featureset[[column]]": 1,
      "apptrain[[col]]": 1,
      "df_dict_train[file][[col]]": 1,
      "df_all[prev_cols]": 1,
      "damageDealt": 1,
      "longestKill": 1,
      "matchDuration": 1,
      "walkDistance": 1,
      "sales6[['item_cnt_day']]": 1,
      "normX": 1,
      "X_fs_eval": 1,
      "delta_list": 1,
      "np.arange(1, n + 1).reshape(-1, 1)": 1,
      "np.array(n).reshape(-1, 1)": 1,
      "train_df_ss[train_numerical_features]": 1,
      "test_df_ss[test_numerical_features]": 1,
      "train[col].values": 1,
      "useful_data": 1,
      "x_opt": 1,
      "X_train[X_train.columns]": 1,
      "train_looe": 1,
      "train_app_domain": 1,
      "df_eda['SalePrice'].to_numpy().reshape(-1, 1)": 1,
      "train_df_ltd.fillna(-1)": 1,
      "X_train_master": 1,
      "X_test_master": 1,
      "ordinal_train": 1,
      "ordinal_test": 1,
      "title": 1,
      "X_test[features]": 1,
      "Y_trn": 1,
      "trainx_base[sensors]": 1,
      "testx_base[sensors]": 1,
      "train_data[col]": 1,
      "sub_data[col]": 1,
      "train_df[target_vars]": 1,
      "X.drop(['PlayId', 'Yards'], axis=1)": 1,
      "df_train[scaling_col]": 1,
      "y.values": 1,
      "np.arange(i1_left, i1_right, 1).reshape(-1, 1)": 1,
      "np.arange(0, len(x)).reshape(-1, 1)": 1,
      "train[['char_count', 'word_count', 'upper_case_word_count', 'punctuation_count', 'title_word_count']]": 1,
      "test[['char_count', 'word_count', 'upper_case_word_count', 'punctuation_count', 'title_word_count']]": 1,
      "arr[:, np.newaxis]": 1,
      "X_train[numerical_col]": 1,
      "X_train[categorical_col]": 1,
      "test_df.values": 1,
      "merged_train_df[['Lat', 'Long', 'age_0-4', 'age_5-9', 'age_10-14', 'age_15-19', 'age_20-24', 'age_25-29', 'age_30-34', 'age_35-39', 'age_40-44', 'age_45-49', 'age_50-54', 'age_55-59', 'age_60-64', 'age_65-69', 'age_70-74', 'age_75-79', 'age_80-84', 'age_85-89', 'age_90-94', 'age_95-99', 'age_100+', 'total_pop', 'smokers_perc', 'density', 'urbanpop', 'hospibed', 'lung', 'femalelung', 'malelung', 'restrictions', 'quarantine', 'schools']]": 1,
      "merged_test_df[['Lat', 'Long', 'age_0-4', 'age_5-9', 'age_10-14', 'age_15-19', 'age_20-24', 'age_25-29', 'age_30-34', 'age_35-39', 'age_40-44', 'age_45-49', 'age_50-54', 'age_55-59', 'age_60-64', 'age_65-69', 'age_70-74', 'age_75-79', 'age_80-84', 'age_85-89', 'age_90-94', 'age_95-99', 'age_100+', 'total_pop', 'smokers_perc', 'density', 'urbanpop', 'hospibed', 'lung', 'femalelung', 'malelung', 'restrictions', 'quarantine', 'schools']]": 1,
      "merged_train_df[['total_pop', 'smokers_perc', 'mean_rate_case_last7', 'mean_rate_fat_last7', 'std_rate_case', 'std_rate_fat', 'density']]": 1,
      "news_volume": 1,
      "news_sentiment": 1,
      "drop_x_train_new": 1,
      "test_consolidated": 1,
      "features_test": 1,
      "column.values[:, np.newaxis]": 1,
      "y_train_1": 1,
      "X_test_1": 1,
      "X_train_3": 1,
      "X_test_3": 1,
      "y_train_3": 1,
      "X_train_4": 1,
      "X_test_4": 1,
      "y_train_4": 1,
      "X_train[all_numerical_features]": 1,
      "X_test[all_numerical_features]": 1,
      "train_df2": 1,
      "full_x_train": 1,
      "X_train[numerical_cols]": 1,
      "X[col].values[:, None]": 1,
      "view[column].values.reshape(-1, 1)": 1,
      "X_test[numeric_features]": 1,
      "X_train[object_cols]": 1,
      "X_test[object_cols]": 1,
      "train['target'].reshape(-1, 1)": 1,
      "unscaled_X": 1,
      "unscaled_X_test": 1,
      "np.log(y_train)": 1,
      "X_res": 1,
      "labels.reshape(-1, 1)": 1,
      "np.array(X_train['Weekly_Sales'] + 1).reshape(-1, 1)": 1,
      "X_train_tf.drop('Date', axis=1).dropna()": 1,
      "train_modified": 1,
      "train_colors_features": 1,
      "train[train.dtypes.loc[train.dtypes == 'object'].index]": 1,
      "test_input[test_input.dtypes.loc[test_input.dtypes == 'object'].index]": 1,
      "counts.astype(float).values.reshape(-1, 1)": 1,
      "X_not_imputed": 1,
      "X_ni_feat_sel": 1,
      "data[numerics]": 1,
      "Xtrain_df[features]": 1,
      "test_data[features]": 1,
      "full_dataset[con_col].values.reshape(-1, 1)": 1,
      "train_data[feature].values.reshape(-1, 1)": 1,
      "boxcox_train_feature.reshape(-1, 1)": 1,
      "boxcox_test_feature.reshape(-1, 1)": 1,
      "test[feature_names].values": 1,
      "weather_train[col].values.reshape(-1, 1)": 1,
      "train['meter_reading'].values.reshape(-1, 1)": 1,
      "market_train[market_numeric_cols]": 1,
      "dataf[['wx', 'wy', 'wz']]": 1,
      "X_train[ints_df]": 1,
      "all_features.values": 1,
      "pd.DataFrame(x_tfidf.toarray())": 1,
      "X[continuous_feature]": 1,
      "test_df[continuous_feature]": 1,
      "dfc": 1,
      "a[['id', 'sequence', 'structure', 'predicted_loop_type']]": 1,
      "pudf_[['id', 'sequence', 'structure', 'predicted_loop_type']]": 1,
      "prdf_[['id', 'sequence', 'structure', 'predicted_loop_type']]": 1,
      "st_cols": 1,
      "T_st_cols": 1,
      "train.LConfirmedCases[train.serd > 70].values.reshape(-1, 1)": 1,
      "train.LFatalities[train.serd > 70].values.reshape(-1, 1)": 1,
      "dfle[cols_to_scale]": 1,
      "t[cols_to_scale]": 1,
      "all_train_df[['Age', 'cabin_multiple', 'Pclass', 'Pclass', 'SibSp', 'Parch', 'Fare']]": 1,
      "work_scaled[['Age', 'cabin_multiple', 'Pclass', 'Pclass', 'SibSp', 'Parch', 'Fare']]": 1,
      "df_train_x": 1,
      "train_data.iloc[:, :-2]": 1,
      "test_data.iloc[:, :-1]": 1,
      "c_matrix": 1,
      "train[continous_cols]": 1,
      "train_data_baseline[['age_approx']]": 1,
      "test_data_baseline[['age_approx']]": 1,
      "train[['label']]": 1,
      "train_df_copy": 1,
      "x_test_numerical": 1,
      "np.atleast_2d(train[col].values.T).T": 1,
      "np.atleast_2d(onedarray.T).T": 1,
      "x2[:, 1].reshape((-1, 1))": 1,
      "X_validate": 1,
      "temp_test": 1,
      "TRAIN": 1,
      "x_train_": 1,
      "X[:, 0:size]": 1,
      "features_data[numerical]": 1,
      "features_to_train[numerical]": 1,
      "data[['ord_1', 'ord_2']].fillna('-1').astype(str)": 1,
      "mx_movies": 1,
      "voxel_mat": 1,
      "data[scale_vars]": 1,
      "np.reshape(np.array(price[self.status]), (-1, 1))": 1,
      "train_data.drop('Survived', axis=1)": 1,
      "X_train_flat": 1,
      "X_test_flat": 1,
      "X[feature_columns]": 1,
      "X1[['WScore_1', 'LScore_1', 'LScore_2', 'WScore_2']]": 1,
      "df[[colname]]": 1,
      "X_train[numerical_feats]": 1,
      "X_train[img_feats]": 1,
      "X_train[text_feats]": 1,
      "[test_data['AgeGroup']]": 1,
      "[test_data['FareRange']]": 1,
      "np.log1p(train_price)": 1,
      "train['LotFrontage'].values.reshape(-1, 1)": 1,
      "train['LotArea'].values.reshape(-1, 1)": 1,
      "train['MasVnrArea'].values.reshape(-1, 1)": 1,
      "train['GarageYrBlt'].values.reshape(-1, 1)": 1,
      "train['SalePrice'].values.reshape(-1, 1)": 1,
      "nom": 1,
      "test_sub": 1,
      "spectrum_df.values": 1,
      "train[['Fare']]": 1,
      "test[['Fare']]": 1,
      "test[['Embarked']]": 1,
      "hits[['r', 't', 'z']].values": 1,
      "hits[['r', 't', 'p']].values": 1,
      "hits[['t', 'p']].values": 1,
      "data[['polar_r', 'polar_p', 'polar_t']]": 1,
      "data[['cylindrical_r', 'cylindrical_t', 'cylindrical_z']]": 1,
      "data[['radn_x', 'radn_y', 'radn_z']]": 1,
      "tr_X": 1,
      "market_train_df1[num_cols]": 1,
      "test_df_X": 1,
      "y_train_cc": 1,
      "y_train_ft": 1,
      "X[-(num_days_to_predict + 1):]": 1,
      "X_filtered": 1,
      "data_train.drop(['id', 'target'], axis=1)": 1,
      "df[['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']]": 1,
      "tr.iloc[:, 0:2]": 1,
      "tr_cc": 1,
      "tr_ft": 1,
      "X_resampled": 1,
      "train_raw": 1,
      "trn_x": 1,
      "train_set[['Dsum']]": 1,
      "test_set[['Dsum']]": 1,
      "train_set[['TransactionAmt']]": 1,
      "test_set[['TransactionAmt']]": 1,
      "train_transaction[time_delta_cols]": 1,
      "train_transaction[counter_cols]": 1,
      "train_transaction[['Csum']]": 1,
      "train_transaction[['Dsum']]": 1,
      "train_transaction[['Msum']]": 1,
      "train_transaction[['TransactionAmt']]": 1,
      "train_transaction[['dist1']]": 1,
      "train_transaction[['dist2']]": 1,
      "train_transaction[['distSum']]": 1,
      "train_transaction[id_numeric_cols]": 1,
      "test_transaction[time_delta_cols]": 1,
      "test_transaction[counter_cols]": 1,
      "test_transaction[['Csum']]": 1,
      "test_transaction[['Dsum']]": 1,
      "test_transaction[['Msum']]": 1,
      "test_transaction[['TransactionAmt']]": 1,
      "test_transaction[['dist1']]": 1,
      "test_transaction[['dist2']]": 1,
      "test_transaction[['distSum']]": 1,
      "test_transaction[id_numeric_cols]": 1,
      "STDTrain": 1,
      "STDTest": 1,
      "Tdata": 1,
      "STDTdata": 1,
      "train_poly": 1,
      "X_word_count": 1,
      "Aquifier_Auser_1_T.iloc[1:11, :]": 1,
      "Aquifier_Auser_1_T.iloc[16:20, :]": 1,
      "Xmod1": 1,
      "np.array(df['City Group']).reshape(-1, 1)": 1,
      "data[:len(train)][numFeatures].fillna(0)": 1,
      "data[len(train):][numFeatures].fillna(0)": 1,
      "train['n_images'].values.reshape(-1, 1)": 1,
      "train.image_size_scaled.values.reshape(-1, 1)": 1,
      "test.image_size_scaled.values.reshape(-1, 1)": 1,
      "train['mean_color'].values.reshape(-1, 1)": 1,
      "df[total_numeric]": 1,
      "df[compound]": 1,
      "train_data.values": 1,
      "test_data.values": 1,
      "train.iloc[:, 1:21]": 1,
      "X_train[quan]": 1,
      "df_all.loc[:, ord_fields[i]].values.reshape(-1, 1)": 1,
      "X_shaped": 1,
      "solo": 1,
      "duo": 1,
      "squad": 1,
      "other": 1,
      "test_solo": 1,
      "test_duo": 1,
      "test_squad": 1,
      "test_other": 1,
      "X_train[:, 0:continuouscatbreakpoint]": 1,
      "X_dev[:, 0:continuouscatbreakpoint]": 1,
      "X.loc[:, num_cols]": 1,
      "X.iloc[:, 2:].values": 1,
      "X_test.iloc[:, 2:].values": 1,
      "train[numFeatures]": 1,
      "X_sp": 1,
      "x_press": 1,
      "x_normal": 1,
      "x_soft": 1,
      "np.array(df[cat]).reshape(-1, 1)": 1,
      "np.array(df[cont]).reshape(-1, 1)": 1,
      "data[lab_cat_cols]": 1,
      "d_train_X[col_list]": 1,
      "d_train_3[['revenue']]": 1,
      "image_vec": 1,
      "train[num_col].fillna(-1).clip(0.0001, 0.99999)": 1,
      "self.train_data.loc[:, genes]": 1,
      "prop2016.loc[:, 'airconditioningtypeid':]": 1,
      "prop2017.loc[:, 'airconditioningtypeid':]": 1,
      "PCA(n_components=40, random_state=4).fit_transform(data[col])": 1,
      "test[['date_block_num', 'shop_id', 'item_id']]": 1,
      "test[['date_block_num', 'shop_id', 'item_id', 'total_price_per_month']]": 1,
      "test[['date_block_num', 'shop_id', 'item_id', 'total_price_per_month', 'min_item_cnt_month']]": 1,
      "test[['date_block_num', 'shop_id', 'item_id', 'total_price_per_month', 'min_price_per_month']]": 1,
      "test[['date_block_num', 'shop_id', 'item_id', 'total_price_per_month', 'max_item_cnt_month']]": 1,
      "test[['date_block_num', 'shop_id', 'item_id', 'total_price_per_month', 'max_item_cnt_month', 'min_item_cnt_month']]": 1,
      "test[['date_block_num', 'shop_id', 'item_id', 'total_price_per_month', 'avg_item_cnt_month']]": 1,
      "test[['date_block_num', 'shop_id', 'item_id', 'total_price_per_month', 'min_item_cnt_month', 'min_price_per_month', 'max_item_cnt_month', 'max_price_per_month', 'avg_item_cnt_month', 'avg_price_per_month']]": 1,
      "trainset_copy[num_cols]": 1,
      "train_copy[num_cols]": 1,
      "X_train[y_train == i, j:j + 1]": 1,
      "train[cat1].astype(str)": 1,
      "df.loc[:, ['Country_Region']]": 1,
      "df.loc[:, ['Province_State']]": 1,
      "train_vectors.todense()": 1,
      "test_vectors.todense()": 1,
      "Y_train.values.reshape(-1, 1)": 1,
      "dataframe[num_features]": 1,
      "train_processed": 1,
      "test_processed": 1,
      "train_x_np": 1,
      "train_y_np": 1,
      "test_x_np": 1,
      "train_x_num": 1,
      "all_num_2020_reduced": 1,
      "all_num_2020_no_Nan": 1,
      "X_cities_[X_cities_.columns]": 1,
      "merged_data": 1,
      "_X": 1,
      "ctx_df.values": 1,
      "tl_df.values": 1,
      "getColumn(global_total_cases.index)": 1,
      "getColumn(canada_total_cases.index)": 1,
      "Xtrain[[col]]": 1,
      "data.drop('cp_type', axis=1)": 1,
      "train[['RescuerID_COUNT_log']].copy()": 1,
      "test[['RescuerID_COUNT_log']].copy()": 1,
      "train[['RescuerID']].copy()": 1,
      "test[['RescuerID']].copy()": 1,
      "x_train.loc[:, ['walkDistance', 'weaponsAcquired', 'boosts', 'killPlace']]": 1,
      "x_test.loc[:, ['walkDistance', 'weaponsAcquired', 'boosts', 'killPlace']]": 1,
      "df_m['item_price'].values.reshape(-1, 1)": 1,
      "train.drop(columns=drop_cols)": 1,
      "test.drop(columns=drop_cols)": 1,
      "data[:, i:i + 1]": 1,
      "data_IF": 1,
      "data_SVM": 1,
      "data_all[GENES]": 1,
      "data_all[CELLS]": 1,
      "titanic_sex": 1,
      "titanic_embarked": 1,
      "titanic": 1,
      "Y.values.reshape(-1, 1)": 1,
      "np.expand_dims(train['target'].to_numpy(), axis=1)": 1,
      "hdf[col].as_data_frame().values": 1,
      "df[col].values.reshape(-1, 1)": 1,
      "real_train[float_cols]": 1,
      "df_cat_dropcols": 1,
      "df_num_dropcols": 1,
      "test[quanColumns]": 1,
      "train[quanColumns]": 1,
      "X_cent": 1,
      "train_x[train_x.columns]": 1,
      "vects": 1,
      "df_fat_pred": 1,
      "data.loc[:, data.columns != 'shot_made_flag'].values": 1,
      "np.array(my_df[enc]).reshape(-1, 1)": 1,
      "X_ph": 1,
      "X_soc": 1,
      "X_sand": 1,
      "app_train_enc_imput_med": 1,
      "month_level": 1,
      "X_1": 1,
      "cv_train": 1,
      "cv_train_": 1,
      "train[num_feature]": 1,
      "train.loc[train_by_district & train_by_cat, ['X', 'Y']]": 1,
      "feature_df": 1,
      "train_df[['var_0', 'var_1', 'var_2']]": 1,
      "train_df[columns]": 1,
      "test_df.drop(['ID_code'], axis=1)": 1,
      "X_test.astype(np.float64)": 1,
      "train_trip_duration_clipped": 1,
      "train_df.astype(float)": 1,
      "df.astype(float)": 1,
      "pre_test[im_features].astype(np.float32)": 1,
      "lr_fea_tr[lr_base_fea_cols[1:35]]": 1,
      "train[['ps_car_03_cat']]": 1,
      "train[['ps_car_05_cat']]": 1,
      "train[['ps_car_07_cat']]": 1,
      "train[['ps_car_09_cat']]": 1,
      "train[var]": 1,
      "x_imputed": 1,
      "guesses": 1,
      "raw_df": 1,
      "train_df[col].values.reshape(-1, 1)": 1,
      "X_final": 1,
      "X_test_filled": 1,
      "X_train[columns_to_scale]": 1,
      "scor": 1,
      "dfcor": 1,
      "scor2": 1,
      "np.array(df.weight).reshape(-1, 1)": 1,
      "np.array(abs(df.resp)).reshape(-1, 1)": 1,
      "days['market_trend'].to_numpy().reshape(-1, 1)": 1,
      "days['market_volat'].to_numpy().reshape(-1, 1)": 1,
      "clf_day_trend.predict(day_features).reshape(-1, 1)": 1,
      "clf_day_volat.predict(day_features).reshape(-1, 1)": 1,
      "train.drop('shot_made_flag', axis=1)": 1,
      "Train_imputed": 1,
      "df_train[train_cols]": 1,
      "df_test[train_cols]": 1,
      "sales_price": 1,
      "simple_engineered_feature": 1,
      "np.array(df).reshape(-1, 1)": 1,
      "train['feature_41'].values.reshape(-1, 1)": 1,
      "train['feature_42'].values.reshape(-1, 1)": 1,
      "train['feature_43'].values.reshape(-1, 1)": 1,
      "train['feature_1'].values.reshape(-1, 1)": 1,
      "train['feature_2'].values.reshape(-1, 1)": 1,
      "dfp_subsampled[['Simple_Ratio', 'Partial_Ratio', 'Token_Sort_Ratio', 'Token_Set_Ratio', 'Q1_Len', 'Q2_Len', 'Q1_Words', 'Q2_Words', 'common_Word', 'word_Total', 'Shared_Word', 'Last_Word', 'First_Word', 'Length_diff', 'StopWord_Ratio', 'Token_Ratio', 'Longest_Substr_ratio']]": 1,
      "df_train1.values": 1,
      "train[[ft]]": 1,
      "X_stack": 1,
      "full_train": 1,
      "X_num_train": 1,
      "sales2": 1,
      "sales[[col]]": 1,
      "X_train_poly": 1,
      "_.loc[:, train_x_col[1:]]": 1,
      "feature_data": 1,
      "pred_user_raw[feature_names]": 1,
      "labeled_dummies.reshape(-1, 1)": 1,
      "test_labeled.reshape(-1, 1)": 1,
      "X_treino.loc[:, :]": 1,
      "train_drug['drug_id'].values.reshape(-1, 1)": 1,
      "[volatility_features]": 1,
      "comb4[pcacols[-16:]]": 1,
      "data[g_features + c_features]": 1,
      "train['sales'].values.reshape(-1, 1)": 1,
      "loaded_dfs[CLUSTER_FTS]": 1,
      "Mat_count": 1,
      "df_simple_imputer[cont_cols]": 1,
      "df_simple_imputer[cat_cols]": 1,
      "df_knn_imputer[feature_cols]": 1,
      "np.array(train_data.target).reshape(-1, 1)": 1,
      "df_train[num_vars]": 1,
      "df_test[num_vars]": 1,
      "np.array(train['popularity']).reshape(-1, 1)": 1,
      "traintest[cols_to_scale]": 1,
      "combine.iloc[:, 1:]": 1,
      "to_counters(X_train)": 1,
      "to_counters(X)": 1,
      "X_train[num_features]": 1,
      "np.log(1 + X)": 1,
      "train[['sales']]": 1,
      "train_data[train_cols_missing_values]": 1,
      "test_data[test_cols_missing_values]": 1,
      "dft": 1,
      "X_train_temp1": 1,
      "X_train_count": 1,
      "image_windowed": 1,
      "train[continuous_cols]": 1,
      "categorical_feat": 1,
      "t_X": 1,
      "X_train[non_cat_features]": 1,
      "train_df_scaled[wanted_columns]": 1,
      "data_train[['Age Group']]": 1,
      "data_test[['Age Group']]": 1,
      "data_train[['Fare Group']]": 1,
      "data_test[['Fare Group']]": 1,
      "np.array(data.budget).reshape((len(data), -1))": 1,
      "train[[column]].values.astype(float)": 1,
      "test[[column]].values.astype(float)": 1,
      "val[[column]].values.astype(float)": 1,
      "test_df[[column]].values.astype(float)": 1,
      "train[['Age', 'Pclass', 'SibSp']]": 1,
      "test_data[cols]": 1,
      "data[features].values": 1,
      "values_y_train": 1,
      "train[features_num]": 1,
      "test[features_num]": 1,
      "array": 1,
      "train_expv": 1,
      "test_expv": 1,
      "train_objv.reshape(-1, 1)": 1,
      "train.loc[:, ['province_state', 'country_region']]": 1,
      "test.loc[:, ['province_state', 'country_region']]": 1,
      "df_full[scale_cols]": 1,
      "testdf[cols]": 1,
      "test_weather[cols_with_missing_test_weather]": 1,
      "train_data[scale_features]": 1,
      "train_data[cols_with_missing_train_data]": 1,
      "test_data[cols_with_missing_test_data]": 1,
      "dftest[x_cols]": 1,
      "df_train[num_housing]": 1,
      "df_train[req_credit]": 1,
      "df_train[cols]": 1,
      "only_val": 1,
      "df_train_norm[feature].values.reshape(-1, 1)": 1,
      "train_test_df": 1,
      "df_train_raw": 1,
      "df_test_raw.drop(['QuoteNumber'], axis=1)": 1,
      "numeric_ftrs": 1,
      "te_numeric_ftrs": 1,
      "score_numeric_ftrs": 1,
      "train.drop('fare_amount', axis=1)": 1,
      "np.array(data[feat]).reshape(-1, 1)": 1,
      "X_arr": 1,
      "te_X": 1,
      "train_stats": 1,
      "whole[[column]]": 1,
      "train_data[numerical_names]": 1,
      "df_all": 1,
      "pd.concat((train.select_dtypes('float64'), train.select_dtypes('int64')), axis=1)": 1,
      "pd.concat((public_df.select_dtypes('float64'), public_df.select_dtypes('int64')), axis=1)": 1,
      "pd.concat((private_df.select_dtypes('float64'), private_df.select_dtypes('int64')), axis=1)": 1,
      "train_data[replace_col]": 1,
      "train_data[train_categorical]": 1,
      "patient_features[['age_approx']]": 1,
      "img_features[img_features.columns.tolist()[2:]]": 1,
      "testcp": 1,
      "df_scale": 1,
      "X[scalercol]": 1,
      "data.iloc[:, 0:200]": 1,
      "data_scaler": 1,
      "np.array(dataframe[col]).reshape(-1, 1)": 1,
      "np.array(submission_data[enc]).reshape(-1, 1)": 1,
      "train_x_helpful": 1,
      "train[np.arange(117, 131)]": 1,
      "test[np.arange(117, 131)]": 1,
      "raw_vec": 1,
      "test_features[col].values.reshape(vec_len_test, 1)": 1,
      "train[independent_feat]": 1,
      "copy_df": 1,
      "train[name].values.reshape(-1, 1)": 1,
      "united": 1,
      "dataset_train_x": 1,
      "dataset_test": 1,
      "train_scale": 1,
      "test_scale": 1,
      "X_train_new": 1,
      "application_train_X": 1,
      "application_test_X": 1,
      "df_train.iloc[:, 3:]": 1,
      "train_numbers": 1,
      "train_labels": 1,
      "numbers_p_imputed": 1,
      "numbers_cat": 1,
      "labels_p_imputed": 1,
      "data['min_FVC'].values.reshape(-1, 1)": 1,
      "data['base_week'].values.reshape(-1, 1)": 1,
      "data['Weeks'].values.reshape(-1, 1)": 1,
      "data['Percent'].values.reshape(-1, 1)": 1,
      "data['min_FVC1'].values.reshape(-1, 1)": 1,
      "data['Neg_Age'].values.reshape(-1, 1)": 1,
      "test[['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp', 'humidity', 'year', 'month', 'day', 'hour', 'dayofweek', 'windspeed']]": 1,
      "np.array([state]).reshape((1, -1))": 1,
      "y_train.reshape([-1, 1])": 1,
      "Y": 1,
      "test_users.drop(['id', 'timestamp_first_active'], axis=1)": 1,
      "train_df[features_to_use]": 1,
      "test_df[features_to_use]": 1,
      "merged1": 1,
      "MyTrainDF[['shop_id', 'item_id', 'item_price', 'item_cnt_day', 'date_block_num', 'dayofyear', 'year', 'month', 'item_cnt_month']]": 1,
      "X_train.loc[:100]": 1,
      "zscore": 1,
      "fourier": 1,
      "anova": 1,
      "binned": 1,
      "words": 1,
      "bigrams": 1,
      "text": 1,
      "ref[cont_vars].values": 1,
      "df[df.columns[2:]]": 1,
      "X_zong.iloc[:, :-7]": 1,
      "all_data[vValues].fillna(-1)": 1,
      "X_train[cols_to_scale]": 1,
      "train_data['ConfirmedCases'].values.reshape(-1, 1)": 1,
      "train_data['Fatalities'].values.reshape(-1, 1)": 1,
      "t_train[cols]": 1,
      "t_test[cols]": 1,
      "t_train[['Sex', 'Embarked']]": 1,
      "t_test[['Sex', 'Embarked']]": 1,
      "X[c].to_numpy().reshape(-1, 1)": 1,
      "X[column].to_numpy().reshape(-1, 1)": 1,
      "X[columns_number]": 1,
      "training_features[normalize_features]": 1,
      "full[col].values.reshape(-1, 1)": 1,
      "encoded_data.loc[:, encoded_data.columns != 'Target']": 1,
      "X_train_cc": 1,
      "X_train_ft": 1,
      "data[['cwc_min', 'cwc_max', 'csc_min', 'csc_max', 'ctc_min', 'ctc_max', 'last_word_eq', 'first_word_eq', 'abs_len_diff', 'mean_len', 'token_set_ratio', 'token_sort_ratio', 'fuzz_ratio', 'fuzz_partial_ratio', 'longest_substr_ratio']]": 1,
      "train_10_percent": 1,
      "ordinal_categorical_data": 1,
      "day_month_data": 1,
      "train.iloc[:, 2:].values": 1,
      "numerical_df_val": 1,
      "out_enc_X_train": 1,
      "OS_X_train": 1,
      "OS_X_valid": 1,
      "df_data": 1,
      "raw_train": 1,
      "X_vect": 1,
      "X_kaggle_test": 1,
      "train_data_1": 1,
      "store_sales": 1,
      "dataset[:, :-1]": 1,
      "predict_data": 1,
      "X_train[:, 1:2]": 1,
      "X_test[:, 1:4]": 1,
      "market_obs_df[num_cols]": 1,
      "dataset[feature].values.reshape(-1, 1)": 1,
      "dataset1[feature].values.reshape(-1, 1)": 1,
      "train_distance": 1,
      "r_inter.T": 1,
      "np.swapaxes(df_sales.loc[:, 'd_1':].to_numpy(), 0, 1)": 1,
      "combo[cols[3:]]": 1,
      "combo[cols[4:]]": 1,
      "family_df": 1,
      "gaussian_num_df[num_feat]": 1,
      "train_df[feat_cols_list]": 1,
      "xtrain_sm": 1,
      "X[feature_columns].values": 1,
      "poly.fit_transform(VarianceThreshold(threshold=1.5).fit_transform(data[cols]))": 1,
      "train3p": 1,
      "train4p": 1,
      "train5p": 1,
      "df_train.loc[:, 'margin1':'margin64']": 1,
      "df_train.loc[:, 'shape1':'shape64']": 1,
      "df_train.loc[:, 'texture1':'texture64']": 1,
      "train_copy[['Fare']]": 1,
      "self.train.drop(columns=self.drop_cols)": 1,
      "dft.loc[:, ['Province_State', 'Country_Region']]": 1,
      "X_svd": 1,
      "combined_data.iloc[:, 4:]": 1,
      "tr_te_ohe": 1,
      "all_data[_vcols].fillna(-1)": 1,
      "df_traintest[feat_to_encode]": 1,
      "df_train_enc": 1,
      "df_test_enc": 1,
      "X2_train": 1,
      "item_descr_counts": 1,
      "train_cats_stats_features": 1,
      "X.ord_5.values.reshape(-1, 1)": 1,
      "X_train.ord_5.values.reshape(-1, 1)": 1,
      "X_test.ord_5.values.reshape(-1, 1)": 1,
      "train_dataset.df[cols_cat]": 1,
      "test_dataset.df[cols_cat]": 1,
      "df_all.loc[:, scale_features]": 1,
      "df_train[df_train['target'] == 0][feature].values.reshape(-1, 1)": 1,
      "df_train[df_train['target'] == 1][feature].values.reshape(-1, 1)": 1,
      "df[spatial_features]": 1,
      "train_df_continuous": 1,
      "submission": 1,
      "y_train_con.reshape(-1, 1)": 1,
      "y_train_fatal.reshape(-1, 1)": 1,
      "X_train_encoded": 1,
      "train_features.iloc[:, col_example_index + 4].values.reshape(-1, 1)": 1,
      "df_full[[column]]": 1,
      "arno_T.iloc[1:-5, :]": 1,
      "data_": 1,
      "dataset_val": 1,
      "train_cleaning[numerical]": 1,
      "test_cleaning[numerical]": 1,
      "calendar.iloc[:, [7, 8, 9, 10]]": 1,
      "df_cols.values": 1,
      "categorical": 1,
      "x[['Age']]": 1,
      "X[['Age', 'Fare']]": 1,
      "train_df[na_cols]": 1,
      "train_df[cat_cols_train]": 1,
      "df[col_list]": 1,
      "df[all_features]": 1,
      "train[var].values.reshape(-1, 1)": 1,
      "df_data[features_num]": 1,
      "df_new": 1,
      "feat_imp_df": 1,
      "X_tfidf": 1,
      "XVec": 1,
      "X[[feature]]": 1,
      "concatenated_features[scale_cols]": 1,
      "X[columns]": 1,
      "part_A_x[numerical_cols].astype('float32')": 1,
      "vectorized_data": 1,
      "dataframe[['Age', 'Fare', 'Pclass']]": 1,
      "dfPreprocess[dfPreprocess.columns]": 1,
      "temp[['count', 'reorder_rate']]": 1,
      "train_cor1": 1,
      "train_cor2": 1,
      "test_cor1": 1,
      "test_cor2": 1,
      "all_df[cont_features]": 1,
      "all_df[features]": 1,
      "all_knn": 1,
      "all_df[cnt_features]": 1,
      "Readydf[cols]": 1,
      "dataset_train_v2[[i]]": 1,
      "np.array(train.ord_2).reshape(-1, 1)": 1,
      "train[ord_columns]": 1,
      "df_pca": 1,
      "mnist_train_data": 1,
      "test[numeric_cols_train]": 1,
      "train[numeric_cols_test]": 1,
      "x_train.to_numpy()": 1,
      "x_val.to_numpy()": 1,
      "X_train[:, 1:]": 1,
      "train_scores": 1,
      "X_train.loc[:, num]": 1,
      "X_predict": 1,
      "data_train['ConfirmedCases'].values.reshape(-1, 1)": 1,
      "data_train['Fatalities_norm'].values.reshape(-1, 1)": 1,
      "train[[c for c in train.columns if c not in ['path']]]": 1,
      "full_extracted_features": 1,
      "fulldf_word_features": 1,
      "TestModels": 1,
      "fake_oof[idx1].reshape(-1, 1)": 1,
      "fake_preds[idx2].reshape(-1, 1)": 1,
      "data2": 1,
      "x.reshape(-1, 1)": 1,
      "x_train['price'].values.reshape(-1, 1)": 1,
      "x_train['teacher_number_of_previously_posted_projects'].values.reshape(-1, 1)": 1,
      "x_train['quantity'].values.reshape(-1, 1)": 1,
      "train[['ord_0', 'ord_1', 'ord_3', 'ord_4', 'ord_5']]": 1,
      "test[['ord_0', 'ord_1', 'ord_3', 'ord_4', 'ord_5']]": 1,
      "Ra": 1,
      "data_1": 1,
      "output_target": 1,
      "df[i].reshape(-1, 1)": 1,
      "xtest_new": 1,
      "X_linear": 1,
      "X_linear_test": 1,
      "_y": 1,
      "X_temp": 1,
      "train_name": 1,
      "test_name": 1,
      "train_desc": 1,
      "test_desc": 1,
      "test[cols]": 1,
      "x_train['WScoreT'].to_numpy().reshape(-1, 1)": 1,
      "x_train['LScoreT'].to_numpy().reshape(-1, 1)": 1,
      "df_test['WScoreT'].to_numpy().reshape(-1, 1)": 1,
      "df_test['LScoreT'].to_numpy().reshape(-1, 1)": 1,
      "df_train['resp'][:, np.newaxis]": 1,
      "df_X": 1,
      "sc.fit_transform(VarianceThreshold(threshold=2).fit_transform(data[cols]))": 1,
      "market_train_fin[['return']]": 1,
      "market_train_fin[['returnsClosePrevRaw1']]": 1,
      "market_train_fin[['returnsOpenPrevRaw1']]": 1,
      "market_train_fin[['returnsClosePrevMktres1']]": 1,
      "market_train_fin[['returnsOpenPrevMktres1']]": 1,
      "market_train_fin[['returnsClosePrevRaw10']]": 1,
      "market_train_fin[['returnsOpenPrevRaw10']]": 1,
      "market_train_fin[['returnsClosePrevMktres10']]": 1,
      "market_train_fin[['returnsOpenPrevMktres10']]": 1,
      "market_train_fin[['returnsOpenNextMktres10']]": 1,
      "y_train_df": 1,
      "all_df[cont_cols + ['daily_shade_sd', 'hydro_dist', 'Mean_Amenities', 'Mean_Fire_Hyd']]": 1,
      "tr[col].values.reshape(-1, 1)": 1,
      "train_features_encoded": 1,
      "X_real_zeros": 1,
      "all_data.loc[:, ~all_data.columns.str.contains('Score')]": 1,
      "X.iloc[:, :-1]": 1,
      "df.loc[:, '48df886f9':].values": 1,
      "df.loc[df.isTrain, 'target'].values.reshape(-1, 1)": 1,
      "X_t[[i for i in X_t.columns if i != 'excerpt']]": 1,
      "housing_best_features": 1,
      "df_sstats[f].reshape(-1, 1)": 1,
      "stats.boxcox(df[col] + shift + 1)[0].reshape(-1, 1)": 1,
      "droppedColumns": 1,
      "tr_set": 1,
      "tr_features": 1,
      "comp_df[p_name]": 1,
      "comp_df[['launch_days']]": 1,
      "comp_df[['open_year']]": 1,
      "full_train_values": 1,
      "train_set[num_vars]": 1,
      "test_set[num_vars]": 1,
      "mean_ranks.values.reshape(-1, 1)": 1,
      "x_train_imp": 1,
      "x_test_imp": 1,
      "trainset[['ps_reg_03']]": 1,
      "trainset[['ps_car_12']]": 1,
      "trainset[['ps_car_14']]": 1,
      "trainset[['ps_car_11']]": 1,
      "Demo_Test": 1,
      "Demo": 1,
      "FloatData_test": 1,
      "FloatData.iloc[:, 0:3]": 1,
      "features_Test": 1,
      "train_X_imputed": 1,
      "train_X_consolidated": 1,
      "train_X_created": 1,
      "train_X_binarized": 1,
      "Xc_train": 1,
      "Xr_train": 1,
      "Xc_test": 1,
      "Xr_test": 1,
      "df_test_sig": 1,
      "train_features_temp": 1,
      "Corporation_climate_2020['KPI engagement'].values.reshape(-1, 1)": 1,
      "Corporation_climate_2020['KPI plan'].values.reshape(-1, 1)": 1,
      "Corporation_climate_2020['KPI education'].values.reshape(-1, 1)": 1,
      "Corporation_water_2020['KPI engagement'].values.reshape(-1, 1)": 1,
      "Corporation_water_2020['KPI plan'].values.reshape(-1, 1)": 1,
      "Corporation_water_2020['KPI education'].values.reshape(-1, 1)": 1,
      "Cities_2020['KPI 1.0a'].values.reshape(-1, 1)": 1,
      "Cities_2020['KPI 6.0'].values.reshape(-1, 1)": 1,
      "Cities_2020['KPI City'].values.reshape(-1, 1)": 1,
      "Group[['Grade']]": 1,
      "MAAE1[['mean']]": 1,
      "AllDetails[['MLPProb']]": 1,
      "AllDetails[['PlayPredProb']]": 1,
      "Numdf": 1,
      "X_train_": 1,
      "X_test_": 1,
      "a1": 1,
      "devicelabelstfidf": 1,
      "hourbintfidf": 1,
      "train_3d[train_3d.columns[:-1]]": 1,
      "train_f2[['PromoOpen']]": 1,
      "train_f2[['CompetitionOpen']]": 1,
      "train_f2[['SalePerCustomer']]": 1,
      "train_f2[['ln_CompetitionDistance']]": 1,
      "train_f2[['ln_Customers']]": 1,
      "train_f2[['ln_Sales']]": 1,
      "df[target_cols].values": 1,
      "X_train[numerical_vars]": 1,
      "cluster_features[['x_-10', 'x_-9', 'x_-8', 'x_-7', 'x_-6', 'x_-5', 'x_-4', 'x_-3', 'x_-2', 'x_-1', 'y_-10', 'y_-9', 'y_-8', 'y_-7', 'y_-6', 'y_-5', 'y_-4', 'y_-3', 'y_-2', 'y_-1']]": 1,
      "cluster_features[['x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'x_8', 'x_9', 'x_10', 'y_1', 'y_2', 'y_3', 'y_4', 'y_5', 'y_6', 'y_7', 'y_8', 'y_9', 'y_10']]": 1,
      "serie": 1,
      "df[['agesq', 'SQBage', 'SQBmeaned', 'SQBedjefe', 'SQBescolari', 'SQBhogar_total', 'SQBovercrowding', 'SQBhogar_nin', 'age', 'SQBdependency', 'meaneduc', 'escolari', 'tamviv', 'rooms', 'hogar_total', 'hhsize', 'overcrowding', 'tamhog', 'qmobilephone', 'r4t2', 'hogar_nin', 'r4t1', 'bedrooms', 'hogar_adul', 'r4h2', 'r4m2', 'r4m1', 'r4h1', 'hogar_mayor']]": 1,
      "foodValues": 1,
      "pdf": 1,
      "train_sales": 1,
      "df.iloc[:, 3:470].values": 1,
      "pca_result": 1,
      "pca_result_200": 1,
      "tsne_result_200": 1,
      "df[['Province/State', 'Country/Region']].values": 1,
      "model_input": 1,
      "x_train_params": 1,
      "features_train_params": 1,
      "features_test_params": 1,
      "n": 1,
      "featuresDF[['exudateScores', 'veinScores']]": 1,
      "test_featuresDF[['exudateScores', 'veinScores']]": 1,
      "X_train[num_cols]": 1,
      "X_valid[num_cols]": 1,
      "X_valid[categorical_cols]": 1,
      "test0[num_cols]": 1,
      "test0[categorical_cols]": 1,
      "full.drop(['Id', 'Hazard'], axis=1)": 1,
      "df_t": 1,
      "train_c": 1,
      "dfn.values": 1,
      "ytr": 1,
      "train_data_cat_full1": 1,
      "test[['ps_reg_03']]": 1,
      "test[['ps_car_12']]": 1,
      "test[['ps_car_14']]": 1,
      "test[['ps_car_11']]": 1,
      "count_matrix": 1,
      "valores": 1,
      "valores2": 1,
      "dtrain": 1,
      "dates['day_of_month'].to_numpy().reshape(-1, 1)": 1,
      "dates['wk_year'].to_numpy().reshape(-1, 1)": 1,
      "train_vectorized": 1,
      "test_vectorized": 1,
      "np.concatenate((X_train, X_test), axis=0)": 1,
      "log_user_data[cols]": 1,
      "X[self.num_columns]": 1,
      "data[columns]": 1,
      "X_sparse": 1,
      "vectorizer.fit_transform(df.Word_list)": 1,
      "t1": 1,
      "moa_train_feat": 1,
      "penguins[['species']]": 1,
      "titanic[['Sex', 'Cabin', 'Embarked']]": 1,
      "X_train[cols_most_freq]": 1,
      "X_train[['Sex']]": 1,
      "X_train[['Cabin_letter']]": 1,
      "X_train[['Embarked']]": 1,
      "X[cols_most_freq]": 1,
      "X[['Sex']]": 1,
      "X[['Cabin_letter']]": 1,
      "X[['Embarked']]": 1,
      "ds_test": 1,
      "normalize(train[features], axis=0)": 1,
      "train_resources[label].astype(np.float64).values.reshape(-1, 1)": 1,
      "sample": 1,
      "count_train": 1,
      "train_df_raw": 1,
      "data_numeric0": 1,
      "TrainData_X": 1,
      "df.loc[:, ['Age', 'Fare']]": 1,
      "train_df[['Country_Region', 'Province_State']]": 1,
      "test_df[['Country_Region', 'Province_State']]": 1,
      "data_sparse": 1,
      "dummy_sparse": 1,
      "train[['shipping', 'item_condition_id']]": 1,
      "self.proc_df": 1,
      "titanic_genre": 1,
      "genre_cat_test_data": 1,
      "test_file_num_attr": 1,
      "np.array(train_data['matchType']).reshape(-1, 1)": 1,
      "removeNA_test": 1,
      "train_df_out_rem[features_names_upd]": 1,
      "num_var": 1,
      "cc_df": 1,
      "dev_x_2": 1,
      "x_new": 1,
      "data[robot_stats]": 1,
      "prerun_data.iloc[:, 1:]": 1,
      "x_train_data.drop(['row_id', 'series_id', 'measurement_number'], axis=1)": 1,
      "train_test_features_df[gc_cols]": 1,
      "df_train.iloc[:, 1:]": 1,
      "train_data[['Age']]": 1,
      "test_data[['Age']]": 1,
      "train_data[['Fare']]": 1,
      "test_data[['Fare']]": 1,
      "dums": 1,
      "dfh[['sina1', 'cosa1', 'zdivrt', 'zdivr', 'xdivr', 'ydivr']].values": 1,
      "pd.DataFrame(y)": 1,
      "first_level": 1,
      "first_level_val": 1,
      "first_level_final": 1,
      "train_no_y": 1,
      "filter_X_train": 1,
      "filter_X_test": 1,
      "filter_X_train_sm": 1,
      "filter_X_test_sm": 1,
      "os_features": 1,
      "bigFrame2[['dir', 'dis', 'o', 'x', 'y']]": 1,
      "bin_df": 1,
      "bin_df_2": 1,
      "train[features_1]": 1,
      "_X_train.loc[:, GENES + CELLS]": 1,
      "pd.concat([_X_train.loc[:, GENES + CELLS], _X_test.loc[:, GENES + CELLS]])": 1,
      "pd.concat([__X_train_dae, __X_test_dae])": 1,
      "df[['shop_type_1']]": 1,
      "df[['shop_type_2']]": 1,
      "df[['shop_city']]": 1,
      "df[['item_category_main']]": 1,
      "df_train[['ps_reg_03']]": 1,
      "df_train[['ps_car_12']]": 1,
      "df_train[['ps_car_14']]": 1,
      "df_train[['ps_car_11']]": 1,
      "df_train[Interval]": 1,
      "df[mask_long & mask_lat][['longitude', 'latitude']]": 1,
      "data[model_x_columns_without_dummies]": 1,
      "data_bis[model_x_columns_without_dummies]": 1,
      "train[['num_words', 'num_unique_words', 'num_chars', 'num_stopwords', 'num_punctuations', 'num_words_upper', 'num_words_title', 'mean_word_len']]": 1,
      "test[['num_words', 'num_unique_words', 'num_chars', 'num_stopwords', 'num_punctuations', 'num_words_upper', 'num_words_title', 'mean_word_len']]": 1,
      "cvec.fit_transform(X_train)": 1,
      "sample_data_train.drop('target', axis=1)": 1,
      "train_df['Age'].values.reshape(-1, 1)": 1,
      "dataset['Age'].values.reshape(-1, 1)": 1,
      "np.array(merge['latitude']).reshape(-1, 1)": 1,
      "np.array(merge['longitude']).reshape(-1, 1)": 1,
      "X_train[cols]": 1,
      "np_train": 1,
      "np_lar_train": 1,
      "np_den_train": 1,
      "train[real_cols]": 1,
      "all_df[feature].values.reshape(-1, 1)": 1,
      "all_df[f'{feature}_count'].values.reshape(-1, 1)": 1,
      "df_train_features_scaled": 1,
      "train_new[num_features]": 1,
      "sales_temp5['item_price_y'].values.reshape(-1, 1)": 1,
      "sales_temp5['cur_items_per_month'].values.reshape(-1, 1)": 1,
      "sales_temp_new['item_price_y'].values.reshape(-1, 1)": 1,
      "sales_temp_new['cur_items_per_month'].values.reshape(-1, 1)": 1,
      "x_train_cc": 1,
      "x_train_ft": 1,
      "df[list_float_var]": 1,
      "X_train_bin_vectorized": 1,
      "X_train_vectorized": 1,
      "all_data[[i]]": 1,
      "df_final[[column]]": 1,
      "X_test_nn": 1,
      "data.loc[:, features].values": 1,
      "df[numeric_cols]": 1,
      "X_trainset[train_columns]": 1,
      "train['matchType'].to_numpy().reshape(-1, 1)": 1,
      "dataset.values": 1,
      "ngs2.values": 1,
      "ngs2_sub.values": 1,
      "train_features.append(test_features)": 1,
      "calendar_feature": 1,
      "moa_df.iloc[:, 3:]": 1,
      "X4": 1,
      "X5": 1,
      "train_cont_phase": 1,
      "test_cont": 1,
      "sales_train.drop(['date', 'anomaly', 'item_cnt_day'], axis=1).values": 1,
      "X_smooth": 1,
      "counts_comb": 1,
      "counts_ind": 1,
      "train_counts": 1,
      "Test_ADS": 1,
      "X_train[:, :3]": 1,
      "train_data[['ConfirmedCases']]": 1,
      "train_data[['Fatalities']]": 1,
      "X_Data_Te": 1,
      "inputdata[continuous]": 1,
      "X[selection].fillna(X[selection].median())": 1,
      "XX_test": 1,
      "xx": 1,
      "titanic2[['Sex']]": 1,
      "titanic_test2[['Sex']]": 1,
      "df_proc": 1,
      "np.array(trainSet[regressors])": 1,
      "fe_train.iloc[:, 2:]": 1,
      "fe_test.iloc[:, 1:]": 1,
      "train_gp_features": 1,
      "test_gp_features": 1,
      "sub_train": 1,
      "X_train[all_stats]": 1,
      "train[high_low]": 1,
      "test[high_low]": 1,
      "weather_tr_scaled[columns]": 1,
      "poly_features_test": 1,
      "ord_data": 1,
      "cyc_data": 1,
      "x_train_sel": 1,
      "x_train_frq": 1,
      "x_test_frq": 1,
      "train['Age'].values.reshape(-1, 1)": 1,
      "test['Age'].values.reshape(-1, 1)": 1,
      "train['Fare'].values.reshape(-1, 1)": 1,
      "test['Fare'].values.reshape(-1, 1)": 1,
      "train[['Age']]": 1,
      "test[['Age']]": 1,
      "float_array.reshape(-1, 1)": 1,
      "payment": 1,
      "train_df.iloc[:, 7:-1].dropna()": 1,
      "example_test.iloc[:, 2:-1].dropna()": 1,
      "df[['scalar_coupling_constant', 'fc', 'sd', 'pso', 'dso', 'X', 'Y', 'Z', 'potential_energy', 'x_0', 'y_0', 'z_0', 'A0_0', 'A1_0', 'A2_0', 'A3_0', 'A4_0', 'XX_0', 'YX_0', 'ZX_0', 'XY_0', 'YY_0', 'ZY_0', 'XZ_0', 'YZ_0', 'ZZ_0', 'mulliken_charge_0', 'x_1', 'y_1', 'z_1', 'A0_1', 'A1_1', 'A2_1', 'A3_1', 'A4_1', 'XX_1', 'YX_1', 'ZX_1', 'XY_1', 'YY_1', 'ZY_1', 'XZ_1', 'YZ_1', 'ZZ_1', 'mulliken_charge_1']]": 1,
      "train_non_cat": 1,
      "test_non_cat": 1,
      "X[['day', 'month']]": 1,
      "count_data": 1,
      "train.groupby(['stock_id', 'time_id'])['target'].first().values.reshape(-1, 1)": 1,
      "trainDataX": 1,
      "IV": 1,
      "temp_data[[columns[1]]]": 1,
      "df_undersampled_xtr": 1,
      "np.log(x_train.price.reshape(-1, 1) + 1)": 1,
      "df_values": 1,
      "add_d": 1,
      "sales_train": 1,
      "monthly_vals_df": 1,
      "shop_category_df": 1,
      "sales_df": 1,
      "features_df": 1,
      "X_train[X_train.columns[~(X_train.columns == 'text')]].to_numpy()": 1,
      "X_test[X_test.columns[~(X_test.columns == 'text')]].to_numpy()": 1,
      "X_train_glove": 1,
      "train_data.loc[:, cont_features]": 1,
      "X_train_sc": 1,
      "np.array(train_data[column]).reshape(-1, 1)": 1,
      "enc.fit_transform(train_values[col]).reshape(-1, 1)": 1,
      "df[['cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13', 'cont14']].as_matrix()": 1,
      "features_t": 1,
      "featuresTest": 1,
      "final_counts": 1,
      "real_data.iloc[:, 4:]": 1,
      "returns": 1,
      "test_df[['day']]": 1,
      "traini_df[[i]]": 1,
      "trainData[numeric_cols]": 1,
      "results_wind": 1,
      "np.array(global_features)": 1,
      "ylog.reshape(-1, 1)": 1,
      "df_all[columns]": 1,
      "df_2[columns]": 1,
      "y_train1": 1,
      "X_train1": 1,
      "df[['Cabin', 'Embarked']]": 1,
      "df['Age']": 1,
      "train_test[v_group].fillna(-1)": 1,
      "img_embed": 1,
      "txt_embed": 1,
      "trian_X": 1,
      "train.loc[:, numerical_features]": 1,
      "data_processed": 1,
      "X_train_multi.loc[:, whichVars]": 1,
      "X_train_multi_y": 1,
      "train.values.reshape(-1, 1)": 1,
      "joined[cats]": 1,
      "joined[conts]": 1,
      "x_encode": 1,
      "test1[num_features]": 1,
      "test2[num_features]": 1,
      "train.drop['target']": 1,
      "X_train_seq.reshape(-1, 10)": 1,
      "X_train_feat.reshape(-1, 10)": 1,
      "test_file": 1,
      "corr_dat": 1,
      "Y_train.reshape(-1, 1)": 1,
      "df_concat.loc[:, fields_that_need_to_be_ordered[i]].values.reshape(-1, 1)": 1,
      "self.data": 1,
      "train[v].values.reshape(-1, 1)": 1,
      "test[v].values.reshape(-1, 1)": 1,
      "X_train_a": 1,
      "X_train_data": 1,
      "test[col].values.reshape(-1, 1)": 1,
      "X[[col]]": 1,
      "xtrans": 1,
      "datatrain[datatrain.columns.values.tolist()]": 1,
      "Test[Test.columns.values.tolist()]": 1,
      "X_Infections": 1,
      "X_Deaths": 1,
      "train[top]": 1,
      "test[top]": 1,
      "trainDF": 1,
      "titanicSex": 1,
      "sexCatTestCSV": 1,
      "testCSVNumberAttribute": 1,
      "train.iloc[:, texture]": 1,
      "train.iloc[:, shape]": 1,
      "train.iloc[:, margin]": 1,
      "train_df[scale_cols]": 1,
      "df['timestamp'].values.reshape(-1, 1)": 1,
      "df['prior_question_elapsed_time'].values.reshape(-1, 1)": 1,
      "df['prior_question_had_explanation'].values.reshape(-1, 1)": 1,
      "idf[featcols[:-2]].fillna(-1)": 1,
      "x_validate": 1,
      "x[['Age', 'Fare', 'Cabin']]": 1,
      "ds[cat_cols]": 1,
      "train.loc[:, 'V1':'V100']": 1,
      "train.loc[:, 'V100':'V321']": 1,
      "test.loc[:, 'V1':'V100']": 1,
      "test.loc[:, 'V100':'V321']": 1,
      "train_data_raw[num_features]": 1,
      "test_data_raw[num_features]": 1,
      "train_data_lr_1": 1,
      "train_data_lr_2.iloc[:, 0:6]": 1,
      "test_data[scaled_train_lr_2.iloc[:, 0:6].columns]": 1,
      "train_lr_4[highest_correlated_lr_4]": 1,
      "test_lr_4[highest_correlated_lr_4]": 1,
      "para": 1,
      "df['GarageArea'].values.reshape(-1, 1)": 1,
      "df['TotalBsmtSF'].values.reshape(-1, 1)": 1,
      "X_test_vec": 1,
      "data[numerical]": 1,
      "df_merged[f'var_{v}'].values.reshape(-1, 1)": 1,
      "df_merged[f'cnt_{v}'].values.reshape(-1, 1)": 1,
      "df_train[feature_columns]": 1,
      "count_vectorized": 1,
      "x_train.iloc[:, 2:11]": 1,
      "x_train.iloc[:, 8:15]": 1,
      "train_df[train_columns]": 1,
      "train_df[train_feature_columns]": 1,
      "train['Cost of Living Index'].values.reshape(-1, 1)": 1,
      "np.array(train['distmod']).reshape(-1, 1)": 1,
      "train[selected_feature]": 1,
      "test[selected_feature]": 1,
      "features_90_final.iloc[:, 2:]": 1,
      "dataset.reshape(-1, 1)": 1,
      "df[['Sex', 'Embarked']]": 1,
      "train[col_StandardScale]": 1,
      "df[cols_to_fit]": 1,
      "house_train[num_cols]": 1,
      "house_train[cat_cols]": 1,
      "train_counts_transformed": 1,
      "df2['Age'].to_numpy().reshape((-1, 1))": 1,
      "X.loc[:, X.columns[3:]]": 1,
      "numpyMatrix": 1,
      "X_train[categorical_feat]": 1,
      "X_train[numerical_feat]": 1,
      "previous_application[categorical]": 1,
      "previous_application[numerical]": 1,
      "bureau[categorical]": 1,
      "bureau[numerical]": 1,
      "X_train[:]": 1,
      "train[:, :-1]": 1,
      "df[dense_variables]": 1,
      "np.array([uwr_f, acw_f, slr_f]).transpose()": 1,
      "X_training": 1,
      "final_df.bmi.values.reshape(-1, 1)": 1,
      "poly.fit_transform(VarianceThreshold(threshold=2).fit_transform(data[cols]))": 1,
      "df_final[['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']]": 1,
      "df_final_test[['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']]": 1,
      "df.loc[~nan_mask, 'SalePrice'].to_numpy().reshape(-1, 1)": 1,
      "_df['LotFrontage'].to_numpy().reshape(-1, 1)": 1,
      "_df['max'].to_numpy().reshape(-1, 1)": 1,
      "_df['_Lat'].to_numpy().reshape(-1, 1)": 1,
      "_df['_Lon'].to_numpy().reshape(-1, 1)": 1,
      "_df['LotArea'].values.reshape(-1, 1)": 1,
      "_df['MasVnrArea'].values.reshape(-1, 1)": 1,
      "_df['_PorchSF'].values.reshape(-1, 1)": 1,
      "_df['1stFlrSF'].values.reshape(-1, 1)": 1,
      "_df['2ndFlrSF'].values.reshape(-1, 1)": 1,
      "_df['GrLivArea'].values.reshape(-1, 1)": 1,
      "_df['OpenPorchSF'].values.reshape(-1, 1)": 1,
      "_df['BsmtUnfSF'].values.reshape(-1, 1)": 1,
      "_df['TotalBsmtSF'].values.reshape(-1, 1)": 1,
      "_df['GarageArea'].to_numpy().reshape(-1, 1)": 1,
      "(1 - np.array(list(dep_acc.values()))).reshape(-1, 1)": 1,
      "x_train1": 1,
      "df_testnorm": 1,
      "test_df[cols_normalize]": 1,
      "test[cols_normalize]": 1,
      "engineered_data": 1,
      "y_val": 1,
      "X_test_new": 1,
      "X_train_lr": 1,
      "X_train_rf": 1,
      "test_feat_imputed": 1,
      "big_df": 1,
      "X[num_features]": 1,
      "train_X[numerical]": 1,
      "preferred_data": 1,
      "preprocessed_test_data": 1,
      "predictors": 1,
      "train_features[gene_cols + cell_cols]": 1,
      "train_csv[['Weeks', 'Age', 'base_week', 'count_from_base_week', 'base_fvc', 'base_fev1', 'base_week_percent', 'base fev1/base fvc', 'base_height', 'base_weight', 'base_bmi']]": 1,
      "l_test": 1,
      "data_g": 1,
      "data_c": 1,
      "mat": 1,
      "feature_train": 1,
      "train_df.target.reshape(-1, 1)": 1,
      "app_train[feat_to_scale]": 1,
      "app_test[feat_to_scale]": 1,
      "train_df.drop(['date', 'sales'], 1).values": 1,
      "data['budget'].values.reshape(-1, 1)": 1,
      "df.drop('target', axis=1)": 1,
      "df_final.iloc[6:, :]": 1,
      "train[cont]": 1,
      "ytrain.reshape(-1, 1)": 1,
      "features_train": 1,
      "X_train.loc[:, numerical_features]": 1,
      "df_train_copy.drop(['ID_code', 'target'], axis=1)": 1,
      "xtrain_lr_elif": 1,
      "xtrain_lr_perm": 1,
      "external_sources": 1,
      "X_train_pca": 1,
      "train_data['item_condition_id'].values.reshape(-1, 1)": 1,
      "test_pred": 1,
      "train_images": 1,
      "test_images": 1,
      "X_filt[x].values.reshape(-1, 1)": 1,
      "train_X_trimmed[cont_columns]": 1,
      "data['Cabin'].values.reshape(-1, 1)": 1,
      "X_scaled[num_vars[1:-2]]": 1,
      "train_clean": 1,
      "df[scale_col]": 1,
      "df.loc[df['train'] == 1, 'item_price'].values.reshape(-1, 1)": 1,
      "df[['item_id', 'similar_item1', 'item_cat_group', 'similar_item2', 'similar_item3', 'city', 'item_cat_id', 'shop_id', 'month', 'year']]": 1,
      "df_num[num]": 1,
      "df_encoded[enc]": 1,
      "df[cols_to_scale]": 1,
      "dfh[['sina1', 'cosa1', 'z1', 'x1', 'x2']].values": 1,
      "df[num_variables]": 1,
      "new_titanic_df[num_cols]": 1,
      "df5[['competition_distance']].values": 1,
      "df5[['competition_time_month']].values": 1,
      "df5[['promo_time_week']].values": 1,
      "df5[['year']].values": 1,
      "FinalTrainData[['X0']]": 1,
      "FinalTrainData[['X1']]": 1,
      "FinalTrainData[['X2']]": 1,
      "FinalTrainData[['X3']]": 1,
      "FinalTrainData[['X5']]": 1,
      "FinalTrainData[['X6']]": 1,
      "FinalTrainData[['X8']]": 1,
      "df['flux'].values.reshape(-1, 1)": 1,
      "observation.train.iloc[:, 2:-1].values": 1,
      "j": 1,
      "pad_audio_data": 1,
      "new_data": 1,
      "new_test": 1,
      "ex1": 1,
      "sample_test1": 1,
      "np.array(tf_df['cp_time']).reshape(-1, 1)": 1,
      "totalf_df.loc[:, 'g-0':'c-99']": 1,
      "highvf_arr": 1,
      "train_df_org": 1,
      "train_df_for_pca": 1,
      "Xorg[column].values.reshape(-1, 1)": 1,
      "df_features": 1,
      "train[g_columns]": 1,
      "dataset1": 1,
      "scaled_only_carrier[non_bin_features]": 1,
      "temp[clmns].values": 1,
      "cdata[['rez_esc']]": 1,
      "train[['Age', 'Fare']]": 1,
      "train_norm[c].values.reshape(-1, 1)": 1,
      "X_train_Auser": 1,
      "o.train[col]": 1,
      "np.array(train['Slope']).reshape(-1, 1)": 1,
      "np.array(train[column]).reshape(-1, 1)": 1,
      "imputed_df[col].as_matrix().reshape(-1, 1)": 1,
      "X_f_train": 1,
      "test[v]": 1,
      "pca_results_train": 1,
      "pca_results_test": 1,
      "Pol.fillna(+1) - 1.5": 1,
      "e_": 1,
      "market[num_cols]": 1,
      "real_data": 1,
      "vgg16_features": 1,
      "vgg19_features": 1,
      "resnet_features": 1,
      "incept_features": 1,
      "pd.DataFrame(data_train_cl[i], columns=[i])": 1,
      "X[featuresToScale]": 1,
      "data['First'].values.reshape(-1, 1)": 1,
      "data['Fare_Family'].values.reshape(-1, 1)": 1,
      "data['FamilySize'].values.reshape(-1, 1)": 1,
      "data['SibSp'].values.reshape(-1, 1)": 1,
      "data['Parch'].values.reshape(-1, 1)": 1,
      "data['Deck'].values.reshape(-1, 1)": 1,
      "all_train1.iloc[:, :-6]": 1,
      "lc.fit_transform(train[col]).reshape(-1, 1)": 1,
      "train_transaction": 1,
      "X_train[num_list]": 1,
      "train_df[['Age', 'Fare_PP']]": 1,
      "X_test[['Age', 'Fare_PP']]": 1,
      "global_features": 1,
      "xTrainNum": 1,
      "xtrain_tfv": 1,
      "numerical_df": 1,
      "players[['heightInches', 'weight']]": 1,
      "tsne_data": 1,
      "house_pred[[target]]": 1,
      "combined[num_column.index]": 1,
      "train[num_col]": 1,
      "train.iloc[:, :879]": 1,
      "data_num_data": 1,
      "process_df": 1,
      "dataset.iloc[:, :3]": 1,
      "column_as_df[col_].values.reshape(-1, 1)": 1,
      "train.drop(['Target', 'Id', 'idhogar'], axis=1)": 1,
      "test.drop(['Id', 'idhogar'], axis=1)": 1,
      "TrainingDF_Input": 1,
      "train[cat_train]": 1,
      "train[con_train]": 1,
      "test[cat_test]": 1,
      "test[con_test]": 1,
      "training[['timestamp', 'prior_question_elapsed_time']]": 1,
      "all_data.loc[:, ordinals[i]].values.reshape(-1, 1)": 1,
      "Data['X']": 1,
      "Data['Time']": 1,
      "X[['ID']].values": 1,
      "X_train1hot": 1,
      "X_trainlabel": 1,
      "X_subset[feature_vector]": 1,
      "train_df.drop(columns=drop_cols)": 1,
      "test_df.drop(columns=drop_cols)": 1,
      "df_green[[col]]": 1,
      "df_green[['sum']]": 1,
      "bureau[col].fillna(bureau[col].mean()).values.reshape(-1, 1)": 1,
      "POS_CASH_balance[col].fillna(POS_CASH_balance[col].mean()).values.reshape(-1, 1)": 1,
      "credit_card_balance[col].fillna(credit_card_balance[col].mean()).values.reshape(-1, 1)": 1,
      "previous_application[col].fillna(previous_application[col].mean()).values.reshape(-1, 1)": 1,
      "installments_payments[col].fillna(installments_payments[col].mean()).values.reshape(-1, 1)": 1,
      "num_features": 1,
      "cat_features": 1,
      "X_train_resampled[cols]": 1,
      "np.array(train_data['Age']).reshape(-1, 1)": 1,
      "np.array(test_data['Age']).reshape(-1, 1)": 1,
      "np.array(train_data['Pclass']).reshape(-1, 1)": 1,
      "np.array(test_data['Pclass']).reshape(-1, 1)": 1,
      "np.array(train_data['SibSp']).reshape(-1, 1)": 1,
      "np.array(test_data['SibSp']).reshape(-1, 1)": 1,
      "np.array(train_data['Parch']).reshape(-1, 1)": 1,
      "np.array(test_data['Parch']).reshape(-1, 1)": 1,
      "np.array(train_data['Fare']).reshape(-1, 1)": 1,
      "np.array(test_data['Fare']).reshape(-1, 1)": 1,
      "future_forcast[60:]": 1,
      "train_textWords.reshape(-1, 1)": 1,
      "train_word_density.reshape(-1, 1)": 1,
      "train_geneCount.reshape(-1, 1)": 1,
      "train_added[features]": 1,
      "test_added[features]": 1,
      "cat_train": 1,
      "train[bin_features].drop(['TARGET'], axis=1)": 1,
      "train[con_features[1:]]": 1,
      "digits.data": 1,
      "train_features.iloc[:, 2:]": 1,
      "train_features.iloc[:, :2]": 1,
      "X[:, np.newaxis]": 1,
      "train_x.loc[:, scale_cols]": 1,
      "X_train_continuous.loc[:, scale_cols2]": 1,
      "test_x.loc[:, scale_cols]": 1,
      "X_test_continuous.loc[:, scale_cols2]": 1,
      "np.array(data).reshape(-1, 1)": 1,
      "test[['date_block_num', 'shop_id', 'item_id', 'total_price']]": 1,
      "tmp.iloc[:, :147]": 1,
      "tmp[:, :6]": 1,
      "df[latest_features]": 1,
      "train[['ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5']]": 1,
      "train_new[['age_approx']]": 1,
      "X_grid": 1,
      "df['Electrical'].values.reshape(-1, 1)": 1,
      "df['GarageType'].values.reshape(-1, 1)": 1,
      "df['GarageFinish'].values.reshape(-1, 1)": 1,
      "df_test['Electrical'].values.reshape(-1, 1)": 1,
      "df_test['GarageType'].values.reshape(-1, 1)": 1,
      "df_test['GarageFinish'].values.reshape(-1, 1)": 1,
      "A_train": 1,
      "polynomial_fearures_data": 1,
      "manhattan_dis_array": 1,
      "eucledian_dis_array": 1,
      "X_Train_CS": 1,
      "yC_Train_CS": 1,
      "yF_Train_CS": 1,
      "x_train_pf": 1,
      "df[cols].astype(float)": 1,
      "np.array(df1).reshape(-1, 1)": 1,
      "dat": 1,
      "df_numeric": 1,
      "df[column].to_numpy().reshape(-1, 1)": 1,
      "x_train[['Age', 'Fare']]": 1,
      "dummy": 1,
      "df_all[cols]": 1,
      "df2[cols]": 1,
      "data.iloc[:, [4, 10]]": 1,
      "data.iloc[:, [9]]": 1,
      "numerical": 1,
      "X_train[numeric_columns]": 1,
      "test[numeric_columns]": 1,
      "Xcr_unscaled": 1,
      "train[i].values.reshape(-1, 1)": 1,
      "y_train.values.reshape([-1, 1])": 1,
      "tmp[INPUT_COLS]": 1,
      "train_test.iloc[:, 5:6]": 1,
      "train_test.iloc[:, 6:7]": 1,
      "train_num[['event_count*event_code', 'accuracy', 'num_incorrect', 'num_correct']]": 1,
      "Xc": 1,
      "train_df.ix[:, 2:]": 1,
      "test_data.ix[:, 1:]": 1,
      "housing_object": 1,
      "df[features_ord].astype(float)": 1,
      "df_train[fet_num_list]": 1,
      "df_train[ordinal_cols]": 1,
      "train[cols].as_matrix()": 1,
      "test[cols].as_matrix()": 1,
      "X_test_test": 1,
      "xVal": 1,
      "df[[x]]": 1,
      "sales_train_val": 1,
      "mcr_small[['Time_Taken']]": 1,
      "train[['var_{}'.format(x) for x in range(0, 200)]]": 1,
      "df[numerical_columns]": 1,
      "nn_prediction_df": 1,
      "X_lr": 1,
      "new_X": 1,
      "test[feature_columns]": 1,
      "df_train[continuous_features]": 1,
      "train[feat_name].values.reshape(-1, 1)": 1,
      "Test": 1,
      "train_df.loc[:, numerical_features + categorical_features]": 1,
      "X_train['num']": 1,
      "X_test['num']": 1,
      "agg_transactions[columns_to_scale]": 1,
      "train[['elapsed_time']]": 1,
      "app_train": 1,
      "x_cont": 1,
      "train_set[column].values.reshape(-1, 1)": 1,
      "df_test_set[column].values.reshape(-1, 1)": 1,
      "y_train['Hazard'].values.reshape(-1, 1)": 1,
      "y['Hazard'].values.reshape(-1, 1)": 1,
      "df_test.drop(['ID_code'], axis=1)": 1,
      "selected_trainX": 1,
      "selected_testX": 1,
      "abs(X_train)": 1,
      "train[feats_sorted]": 1,
      "merged_train_df[['mean_rate_case_last7', 'mean_rate_case_each7', 'mean_rate_fat_last7', 'mean_rate_fat_each7', 'max_rate_case', 'min_rate_case', 'std_rate_case', 'mode_rate_case', 'range_rate_case', 'cases_prev', 'fat_prev', 'max_to_min_rate_case', 'max_rate_fat', 'min_rate_fat', 'std_rate_fat', 'mean_rate_case_last3', 'mean_rate_fat_last3', 'mode_rate_fat', 'mean_rate_case', 'mean_rate_fat', 'range_rate_fat', 'max_to_min_rate_fat', 'rate_ConfirmedCases', 'rate_Fatalities', 'total_pop', 'smokers_perc', 'density']]": 1,
      "train[feature].values.reshape(-1, 1)": 1,
      "data[['game_time']]": 1,
      "np.sum(attributions_0[0][0, :, :].detach().numpy(), axis=1).reshape(-1, 1)": 1,
      "np.sum(attributions_0[0][2, :, :].detach().numpy(), axis=1).reshape(-1, 1)": 1,
      "np.sum(attributions_0[0][1, :, :].detach().numpy(), axis=1).reshape(-1, 1)": 1,
      "np.sum(attributions_0[0][3, :, :].detach().numpy(), axis=1).reshape(-1, 1)": 1,
      "np.clip(1.5**(x_scale + y_scale + vx_scale + vy_scale), -3.5, 3.5).reshape(-1, 1)": 1,
      "citynumvars": 1,
      "data[['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']]": 1,
      "T[numFeatures].fillna(0)": 1,
      "pl.array(Yts).mean(0).reshape(-1, 1)": 1,
      "datasetX": 1,
      "datasetY.reshape(-1, 1)": 1,
      "train_data[float_feat].values": 1,
      "train_features[g_cols + c_cols]": 1,
      "numtrain": 1,
      "X_va": 1,
      "train_without_categoricals.iloc[:, :-1]": 1,
      "train_matrix": 1,
      "test_matrix": 1,
      "meta[['slope']]": 1,
      "fit_samples[0::2].ravel().reshape(-1, 1)": 1,
      "fit_samples[1::2].ravel().reshape(-1, 1)": 1,
      "all_train[numeric_features].fillna(0)": 1,
      "train[numeric_features].fillna(0)": 1,
      "embed": 1,
      "df_train[num_features].drop('deal_probability', axis=1)": 1,
      "df_test[num_features].drop('deal_probability', axis=1)": 1,
      "X.fillna(fill_val)": 1,
      "histograms_df": 1,
      "train['ord_5']": 1,
      "test['ord_5']": 1,
      "trainx": 1,
      "hdf[['AMT_GOODS_PRICE', 'AMT_INCOME_TOTAL', 'AMT_ANNUITY', 'AMT_CREDIT', 'DAYDIFF']]": 1,
      "hd[['AMT_GOODS_PRICE', 'AMT_INCOME_TOTAL_log', 'AMT_ANNUITY', 'AMT_CREDIT', 'DAYDIFF']]": 1,
      "installment_df": 1,
      "features_ord": 1,
      "final_test_data": 1,
      "temp.iloc[:, :-1]": 1,
      "trn": 1,
      "ten": 1,
      "trc": 1,
      "ctri[ordinal]": 1,
      "train_store_Begin[['Store_1', 'Store_2', 'Store_3', 'Store_4', 'Store_5', 'Store_6', 'Store_7', 'Store_8', 'StoreType_a', 'StoreType_c', 'Assortment_a', 'Assortment_c', 'Open', 'Promo', 'Sales']]": 1,
      "X_onehot": 1,
      "X_test_onehot": 1,
      "df_joined['Embarked'].values.reshape(-1, 1)": 1,
      "df[['Age', 'Fare']].values": 1,
      "df[numeric_features]": 1,
      "x__test": 1,
      "df6": 1,
      "train_model_sc": 1,
      "allcats[highcardinality]": 1,
      "train_df[train_df.columns]": 1,
      "alldata[features]": 1,
      "alldata.loc[~alldata[c].isnull(), c].values.astype('float32').reshape(-1, 1)": 1,
      "train_basetable[train_basetable.columns[2:-1]]": 1,
      "kl": 1,
      "1.0 / (50 * math.sqrt(2 * math.pi)) * np.exp(-(1776.82 - train1.mass)**2 / (2 * 50**2))": 1,
      "1.0 / (50 * math.sqrt(2 * math.pi)) * np.exp(-(1776.82 - train2.mass)**2 / (2 * 50**2))": 1,
      "alldata[alldata.columns[:-1]]": 1,
      "alldata[alldata.columns]": 1,
      "np.array(train1['production']).astype(float)": 1,
      "np.array(train2['production']).astype(float)": 1,
      "alldata.loc[:, features]": 1,
      "psdata[psdata.columns[:-1]]": 1,
      "data[['loc_x', 'loc_y']]": 1,
      "X_imputed": 1,
      "X_test_ndarry": 1,
      "np.reshape(dataset, (-1, 1))": 1,
      "comp_train_df[x_col]": 1,
      "comp_test_df[x_col]": 1,
      "market_train.loc[:, num_cols]": 1,
      "t4m[good_features]": 1,
      "t4p[good_features]": 1,
      "t4m[feat]": 1,
      "dataframe_train[age_column].values.reshape(-1, 1)": 1,
      "dataframe_train[fare_column].values.reshape(-1, 1)": 1,
      "dataframe_train[sibsp_column].values.reshape(-1, 1)": 1,
      "dataframe_train[parch_column].values.reshape(-1, 1)": 1,
      "dataframe_train[totalcompanions_column].values.reshape(-1, 1)": 1,
      "dataframe_train[ticketletters_column].values.reshape(-1, 1)": 1,
      "dataframe_train[ticketnumbers_column].values.reshape(-1, 1)": 1,
      "dataframe_train[ticketsymbols_column].values.reshape(-1, 1)": 1,
      "dataframe_train[ticketcharacters_column].values.reshape(-1, 1)": 1,
      "output[:, i].reshape(-1, 1)": 1,
      "train_df['len'].values.reshape(-1, 1)": 1,
      "test_df['len'].values.reshape(-1, 1)": 1,
      "vectorized": 1,
      "column_data": 1,
      "all_data_knn_dummy": 1,
      "np.array([y]).T": 1,
      "M": 1,
      "train[con_columns]": 1,
      "test_features_imputed": 1,
      "X.T": 1,
      "test.drop('Id', axis=1)": 1,
      "train[features].iloc[:, 1:].fillna(train[features].fillna(train[features].mean()))": 1,
      "dummies_scaled[['Age', 'SibSp', 'Parch']]": 1,
      "k1": 1,
      "scale(X_train)": 1,
      "trn['x']": 1,
      "df_train_rus": 1,
      "data[['Pclass', 'Name', 'Age', 'SibSp', 'Parch', 'Fare']]": 1,
      "train_fe": 1,
      "train_df[label].values.reshape(-1, 1)": 1,
      "df1[feature_scale]": 1,
      "df3[feature_scale]": 1,
      "test[all_features].values": 1,
      "data['numeric']": 1,
      "x_train[['item_condition_id', 'shipping']]": 1,
      "x_cv[['item_condition_id', 'shipping']]": 1,
      "T_final[['Age', 'Fare']].values": 1,
      "T_final[['Pclass']].values": 1,
      "chunk": 1,
      "model_train_data_unscaled.astype(np.float64)": 1,
      "train_data.drop(['target'], axis=1)": 1,
      "data_select_wide": 1,
      "df[num_features].values": 1,
      "self.Xm": 1,
      "ytrain.values.reshape(-1, 1)": 1,
      "complete_df[num_cols]": 1,
      "X_smote": 1,
      "X_train.reshape(-1, 1)": 1,
      "X_other": 1,
      "enc_df": 1,
      "poly_ft_train": 1,
      "train.signal.values.reshape(-1, 1)": 1,
      "glcm_df.iloc[:, :-1]": 1,
      "data[feat].fillna('-1').values.reshape(-1, 1).astype(str)": 1,
      "tsne_no_noise": 1,
      "x1_train": 1,
      "x1_test": 1,
      "x2_train": 1,
      "x2_test": 1,
      "xy_data": 1,
      "data[['Pclass']]": 1,
      "X_train[scale_vars]": 1,
      "X_train_confirmed": 1,
      "X_test_confirmed": 1,
      "t": 1,
      "train[['Sex', 'SmokingStatus']]": 1,
      "train[['Weeks', 'Percent', 'Age']]": 1,
      "test[['Sex', 'SmokingStatus']]": 1,
      "test[['Weeks', 'Percent', 'Age']]": 1,
      "train_df[numeric_cols_train_list]": 1,
      "X[column_names]": 1,
      "market_train[num_cols[:-3]]": 1,
      "market_obs_df[num_cols[:-3]]": 1,
      "data.iloc[:, 2:]": 1,
      "hand_crafted_train": 1,
      "concate_both": 1,
      "train[['var1']]": 1,
      "train[['var2']]": 1,
      "train[['var3']]": 1,
      "train[['var4']]": 1,
      "train[['var5']]": 1,
      "train[['var6']]": 1,
      "train[['var8']]": 1,
      "train[['var9']]": 1,
      "train[['var10']]": 1,
      "train[['var11']]": 1,
      "train[['var12']]": 1,
      "train[['var13']]": 1,
      "train[['var14']]": 1,
      "train[['var15']]": 1,
      "train[['var16']]": 1,
      "train[['var17']]": 1,
      "test[['var1']]": 1,
      "test[['var2']]": 1,
      "test[['var3']]": 1,
      "test[['var4']]": 1,
      "test[['var5']]": 1,
      "test[['var6']]": 1,
      "test[['var8']]": 1,
      "test[['var9']]": 1,
      "test[['var10']]": 1,
      "test[['var11']]": 1,
      "test[['var12']]": 1,
      "test[['var13']]": 1,
      "test[['var14']]": 1,
      "test[['var15']]": 1,
      "test[['var16']]": 1,
      "test[['var17']]": 1,
      "train[['dummy']]": 1,
      "test[['dummy']]": 1,
      "data_all[numerical]": 1,
      "xtest_glove": 1,
      "df[self.missing_val_num]": 1,
      "df[self.missing_val_cat]": 1,
      "df[self.numeric_cols]": 1,
      "x_train[cat_features]": 1,
      "x_test[cat_features]": 1,
      "df_test[cat_features]": 1,
      "dtrain.loc[:, cols_for_na]": 1,
      "dtest[['AgeuponOutcome']]": 1,
      "training_scaled[relevant_c.index.drop('SalePrice')]": 1,
      "test_scaled[relevant_c.index.drop('SalePrice')]": 1,
      "train.drop('target', axis=1)": 1,
      "df['Sex'].values.reshape(-1, 1)": 1,
      "df['Title'].values.reshape(-1, 1)": 1,
      "df['Embarked'].values.reshape(-1, 1)": 1,
      "holdout_X": 1,
      "feat_cont": 1,
      "train_df['ConfirmedCases'].values.reshape(-1, 1)": 1,
      "train_df['Fatalities'].values.reshape(-1, 1)": 1,
      "X_train.A": 1,
      "train.drop(columns=['trip_duration'])": 1,
      "X_dummy": 1,
      "predictions_template_df[['confidenceValue']]": 1,
      "label_train[features]": 1,
      "feature": 1,
      "train_csv['prior_question_elapsed_time'].values.reshape(-1, 1)": 1,
      "X_train[numeric_headers]": 1,
      "X_test[numeric_headers]": 1,
      "np.array(dataset.Sex).reshape(-1, 1)": 1,
      "np.array(testset.Sex).reshape(-1, 1)": 1,
      "padded_image.reshape(-1, 1)": 1,
      "pca_train": 1,
      "pca_test.reshape(-1, 1)": 1,
      "train_derived": 1,
      "pd.DataFrame(train_copy[col])": 1,
      "new_train_X": 1,
      "np.reshape(mydata[train_indices], (len(train_indices) * 3780, len(num_cols)))": 1,
      "data_train[features].T": 1,
      "train_df[['ps_reg_03']]": 1,
      "train_df[['ps_car_14']]": 1,
      "train_df[['ps_car_12']]": 1,
      "train_df[['ps_car_11']]": 1,
      "train_df[v]": 1,
      "train_df.drop(['target'], axis=1)": 1,
      "df['signal'].values.reshape(-1, 1)": 1,
      "array.reshape(-1, 1)": 1,
      "df4": 1,
      "train_df[['pickup_longitude']]": 1,
      "train_df[['pickup_latitude']]": 1,
      "train_df[['dropoff_latitude']]": 1,
      "train_df[['dropoff_longitude']]": 1,
      "train_df[['passenger_count']]": 1,
      "train_df[['manhattan']]": 1,
      "train_df[['distance']]": 1,
      "train_df[['latdiff']]": 1,
      "train_df[['londiff']]": 1,
      "train_df[['year']]": 1,
      "train_df[['month']]": 1,
      "train_df[['hour']]": 1,
      "train_df[['minute']]": 1,
      "train_df[['second']]": 1,
      "X_train.iloc[:, :10]": 1,
      "X_test.iloc[:, :10]": 1,
      "stn_x_train": 1,
      "minmax_x_train": 1,
      "df_tmp.iloc[:, :10]": 1,
      "merge_bb_df": 1,
      "minkowsk_dis_array": 1,
      "Deaths_data": 1,
      "df_feat": 1,
      "market1_df": 1,
      "log_userlogs[cols]": 1,
      "xx_train": 1,
      "sc.fit_transform(VarianceThreshold(threshold=1.5).fit_transform(train2p[cols]))": 1,
      "VarianceThreshold(threshold=1.5).fit_transform(train2p[cols])": 1,
      "train2p[cols]": 1,
      "sc.fit_transform(VarianceThreshold(threshold=1.5).fit_transform(train2[cols]))": 1,
      "VarianceThreshold(threshold=1.5).fit_transform(train2[cols])": 1,
      "sc.fit_transform(VarianceThreshold(threshold=1.5).fit_transform(test2[cols]))": 1,
      "VarianceThreshold(threshold=1.5).fit_transform(test2[cols])": 1,
      "test2[cols]": 1,
      "all_features[numerical_cols]": 1,
      "df[['price']]": 1,
      "dataset['name'].str.len().values.reshape(-1, 1)": 1,
      "dataset['item_description'].str.len().values.reshape(-1, 1)": 1,
      "dataset['name'].str.count(' ').values.reshape(-1, 1)": 1,
      "dataset['item_description'].str.count(' ').values.reshape(-1, 1)": 1,
      "f[c].values.reshape(-1, 1)": 1,
      "df_train_add_features": 1,
      "df_test_add_features": 1,
      "np.array(df_train_1)": 1,
      "np.array(df_train_2)": 1,
      "np.array(df_train_3)": 1,
      "np.array(df_valid_1)": 1,
      "np.array(df_valid_2)": 1,
      "np.array(df_valid_3)": 1,
      "train_df.drop('target', axis=1)": 1,
      "df['Age'].values.reshape(-1, 1)": 1,
      "df['Fare'].values.reshape(-1, 1)": 1,
      "df2['Age'].values.reshape(-1, 1)": 1,
      "df2['Fare'].values.reshape(-1, 1)": 1,
      "traing": 1,
      "df[scaling_variables]": 1,
      "data['Embarked'].values.reshape(-1, 1)": 1,
      "test_data['Embarked'].values.reshape(-1, 1)": 1,
      "df_trainval[df_train_col]": 1,
      "df_trainval_sc": 1,
      "df_test_sc": 1,
      "y_casa_treino.reshape(-1, 1)": 1,
      "titanic[['Pclass']]": 1,
      "titanic[['Age']]": 1,
      "titanic[['SibSp']]": 1,
      "titanic[['Parch']]": 1,
      "titanic[['Fare']]": 1,
      "titanic[['EmbarkedCode']]": 1,
      "titanic[['female']]": 1,
      "titanic[['male']]": 1,
      "titanic_test[['Pclass']]": 1,
      "titanic_test[['Age']]": 1,
      "titanic_test[['SibSp']]": 1,
      "titanic_test[['Parch']]": 1,
      "titanic_test[['Fare']]": 1,
      "titanic_test[['EmbarkedCode']]": 1,
      "titanic_test[['female']]": 1,
      "titanic_test[['male']]": 1,
      "df_train[numeric_columns_train]": 1,
      "df_train[object_columns_train]": 1,
      "df_train[df_train.isna().sum().sort_values(ascending=False).head(5).index]": 1,
      "df_test[numeric_columns_test]": 1,
      "df_test[object_columns_train]": 1,
      "df_test[df_test.isna().sum().sort_values(ascending=False).head(8).index]": 1,
      "X_train_df": 1,
      "tags": 1,
      "flat_image": 1,
      "dataset[:, 0:2]": 1,
      "XTrain": 1,
      "XTrainScaled": 1,
      "train_user[['signup_flow']]": 1,
      "train_user_combine[['corrected_age']]": 1,
      "train_x_new": 1,
      "test_x_new": 1,
      "train[[f]]": 1,
      "self.train_final": 1,
      "yrel": 1,
      "df_train_sel[FET_TO_SCALER]": 1,
      "train[list_features]": 1,
      "test[list_features]": 1,
      "np.array(X_train_pca_df_final[col]).reshape(-1, 1)": 1,
      "np.array(X_train[col]).reshape(-1, 1)": 1,
      "titanic_test": 1,
      "test_main": 1,
      "std_error.values.reshape(-1, 1)": 1,
      "c1": 1,
      "a11": 1,
      "c11": 1,
      "train_norm": 1,
      "df_selected": 1,
      "train[features_to_be_scaled_lst]": 1,
      "df[feat_dist['fea_cont']]": 1,
      "transformed_loss.reshape(-1, 1)": 1,
      "train[:, [3]]": 1,
      "valid[:, [3]]": 1,
      "target_num.loc[:, 'ConfirmedCases'].values.reshape(-1, 1)": 1,
      "target_num.loc[:, 'Fatalities'].values.reshape(-1, 1)": 1,
      "train_no_NaN": 1,
      "training": 1,
      "testing": 1,
      "x_predict": 1,
      "x_test_new": 1,
      "train_df[cat_FEATURES]": 1,
      "to_float(X_train)": 1,
      "x_develop": 1,
      "x_develop[cont_cols]": 1,
      "df1[cols]": 1,
      "df1[BOTH]": 1,
      "train_vec": 1,
      "train_vec_b": 1,
      "train_vec_b_2": 1,
      "np_analyze": 1,
      "np_test_analyze": 1,
      "test_users": 1,
      "train_word_features": 1,
      "full_train_w_features.fillna(0)": 1,
      "dat_train[contnames]": 1,
      "dat_valid[contnames]": 1,
      "train_mod[contnames]": 1,
      "test_mod[contnames]": 1,
      "X_tot.cat0.values.reshape(-1, 1)": 1,
      "X_tot.cat1.values.reshape(-1, 1)": 1,
      "X_tot.cat2.values.reshape(-1, 1)": 1,
      "X_tot.cat3.values.reshape(-1, 1)": 1,
      "X_tot.cat4.values.reshape(-1, 1)": 1,
      "X_tot.cat5.values.reshape(-1, 1)": 1,
      "X_tot.cat6.values.reshape(-1, 1)": 1,
      "X_tot.cat7.values.reshape(-1, 1)": 1,
      "X_tot.cat8.values.reshape(-1, 1)": 1,
      "X_tot.cat9.values.reshape(-1, 1)": 1,
      "combo.cat0.values.reshape(-1, 1)": 1,
      "combo.cat1.values.reshape(-1, 1)": 1,
      "combo.cat2.values.reshape(-1, 1)": 1,
      "combo.cat3.values.reshape(-1, 1)": 1,
      "combo.cat4.values.reshape(-1, 1)": 1,
      "combo.cat5.values.reshape(-1, 1)": 1,
      "combo.cat6.values.reshape(-1, 1)": 1,
      "combo.cat7.values.reshape(-1, 1)": 1,
      "combo.cat8.values.reshape(-1, 1)": 1,
      "combo.cat9.values.reshape(-1, 1)": 1,
      "combo.cat10.values.reshape(-1, 1)": 1,
      "combo.cat11.values.reshape(-1, 1)": 1,
      "combo.cat12.values.reshape(-1, 1)": 1,
      "combo.cat13.values.reshape(-1, 1)": 1,
      "combo.cat14.values.reshape(-1, 1)": 1,
      "combo.cat15.values.reshape(-1, 1)": 1,
      "combo.cat16.values.reshape(-1, 1)": 1,
      "combo.cat17.values.reshape(-1, 1)": 1,
      "combo.cat18.values.reshape(-1, 1)": 1,
      "train_ind_aggregated.copy()": 1,
      "X_train[['qlen', 'n_words', 'numeric_words', 'sp_char_words', 'unique_words', 'stopwords']]": 1,
      "X_test[['qlen', 'n_words', 'numeric_words', 'sp_char_words', 'unique_words', 'stopwords']]": 1,
      "train[['qlen', 'n_words', 'numeric_words', 'sp_char_words', 'unique_words', 'stopwords']]": 1,
      "test[['qlen', 'n_words', 'numeric_words', 'sp_char_words', 'unique_words', 'stopwords']]": 1,
      "X_cv": 1,
      "X_features": 1,
      "np.array(df[col + '_bin_counts']).reshape(-1, 1)": 1,
      "np.array(all_data['var_' + str(i)]).reshape(-1, 1)": 1,
      "np.array(train_data[col]).reshape(-1, 1)": 1,
      "np.log(data['target_carbon_monoxide']).to_numpy().reshape(-1, 1)": 1,
      "np.log(1 + data['target_benzene']).to_numpy().reshape(-1, 1)": 1,
      "np.log(data['target_nitrogen_oxides']).to_numpy().reshape(-1, 1)": 1,
      "PCA(svd_solver='full', n_components=100).fit_transform(data[cols].as_gpu_matrix())": 1,
      "df1[features]": 1,
      "PCA(n_components=3, random_state=0).fit_transform(qestn_tagsmap_ohe)": 1,
      "PCA(n_components=9, random_state=0).fit_transform(cor_table)": 1,
      "train_X_prep": 1,
      "train[Numerical_columns]": 1,
      "df[['p1p2x', 'p1p2y', 'p1bx', 'p1by', 'p2bx', 'p2by', 'pl1speed', 'pl2speed', 'bspeed']]": 1,
      "sampled_df.drop(['id', 'qid1', 'qid2', 'question1', 'question2', 'is_duplicate'], axis=1)": 1,
      "PCA(n_components=40, random_state=4).fit_transform(train_X)": 1,
      "data_scale": 1,
      "svr_results.reshape(-1, 1)": 1,
      "lda_results.reshape(-1, 1)": 1,
      "combined_df[['Age', 'Percent', 'min_FVC', 'Deviation_Weeks']]": 1,
      "train_y_reshape": 1,
      "X_test_num": 1,
      "r.reshape(-1, 1)": 1,
      "g.reshape(-1, 1)": 1,
      "b.reshape(-1, 1)": 1,
      "test0": 1,
      "df.loc[:, start_i:end_i]": 1,
      "final_data": 1,
      "train_data_removing_missing[cols]": 1,
      "X_train[columns_int]": 1,
      "y_train[columns_int]": 1,
      "train_data[0:, [1, 2]]": 1,
      "test_data[0:, 1:]": 1,
      "train_df_cont": 1,
      "num_var.values.reshape(-1, 1)": 1,
      "trX[num_cols].values": 1,
      "X_train2_concat": 1,
      "train.loc[tr_idx, cols]": 1,
      "X_train[train_columns]": 1,
      "t2data": 1,
      "t2data_test": 1,
      "train_X_svd": 1,
      "train_X_svd_tfv": 1,
      "features.iloc[:Length2014, 0:13]": 1,
      "features.iloc[:Length2015, 0:13]": 1,
      "features.iloc[:Length2016, 0:13]": 1,
      "features.iloc[:Length2017, 0:13]": 1,
      "df_predictions_tourney.iloc[:1426, 1:3]": 1,
      "df_predictions_tourney.iloc[:1426, 12:13]": 1,
      "df_predictions_tourney.iloc[:1426, 3:12]": 1,
      "df_predictions_tourney.iloc[:1426, 0:1]": 1,
      "features.iloc[:Length2014, 1:3]": 1,
      "features.iloc[:Length2014, 12:13]": 1,
      "features.iloc[:Length2014, 3:12]": 1,
      "features.iloc[:Length2014, 0:1]": 1,
      "features.iloc[:Length2015, 1:3]": 1,
      "features.iloc[:Length2015, 12:13]": 1,
      "features.iloc[:Length2015, 3:12]": 1,
      "features.iloc[:Length2015, 0:1]": 1,
      "features.iloc[:Length2016, 1:3]": 1,
      "features.iloc[:Length2016, 12:13]": 1,
      "features.iloc[:Length2016, 3:12]": 1,
      "features.iloc[:Length2016, 0:1]": 1,
      "features.iloc[:Length2017, 1:3]": 1,
      "features.iloc[:Length2017, 12:13]": 1,
      "features.iloc[:Length2017, 3:12]": 1,
      "features.iloc[:Length2017, 0:1]": 1,
      "features.iloc[:Length2018, 0:13]": 1,
      "x_train[genes + cells]": 1,
      "x_test[genes + cells]": 1,
      "X_train.iloc[:, 2:]": 1,
      "updatedTrainData": 1,
      "np.expand_dims(y_train_nn, axis=-1)": 1,
      "X_prepared": 1,
      "dt_cluster0": 1,
      "dt_cluster1": 1,
      "dt_cluster2": 1,
      "dt_cluster3": 1,
      "dt_cluster4": 1,
      "train.iloc[:, 5:]": 1,
      "combined[['Fare', 'Age', 'Famsize', 'Ticket', 'Pclass', 'Embarked']]": 1,
      "train_df['SalePrice'].values.reshape(-1, 1)": 1,
      "df_full[df_cols]": 1,
      "df_to_return.astype(float)": 1,
      "pd.concat([X.astype(float), dummy_frame.astype(float)], axis=1)": 1,
      "X_train_all_pow": 1,
      "train_df[feature_columns]": 1,
      "train_ds[train_columns]": 1,
      "data[['label']]": 1,
      "train_data.drop(['ID_code', 'target'], axis=1)": 1,
      "np.concatenate((X_train, X_valid), axis=0)": 1,
      "xtrain[['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points']]": 1,
      "train[['AWS', 'ASW', 'word_difficulty', 'syllables_difficulty']]": 1,
      "hh_train": 1,
      "ind_train": 1,
      "hh_test": 1,
      "ind_test": 1,
      "traffic_sum": 1,
      "train_pca": 1,
      "pca.fit_transform(data[cols])": 1,
      "train_": 1,
      "full_data[retain_cols]": 1,
      "train_price_log.reshape(-1, 1)": 1,
      "np_dev_features": 1,
      "X_gtrain": 1,
      "all_data[ord_345]": 1,
      "all_data[ord_cols]": 1,
      "X_train[contFeatureslist + cols].fillna(0)": 1,
      "x['game_time'].values.reshape(-1, 1)": 1,
      "x['stumps'].values.reshape(-1, 1)": 1,
      "x['caterpillars'].values.reshape(-1, 1)": 1,
      "x['pillars'].values.reshape(-1, 1)": 1,
      "x['buckets'].values.reshape(-1, 1)": 1,
      "x['duration'].values.reshape(-1, 1)": 1,
      "x['left_crystals'].values.reshape(-1, 1)": 1,
      "x['right_crystals'].values.reshape(-1, 1)": 1,
      "dsTestAssessment['game_time'].values.reshape(-1, 1)": 1,
      "dsTestAssessment['stumps'].values.reshape(-1, 1)": 1,
      "dsTestAssessment['caterpillars'].values.reshape(-1, 1)": 1,
      "dsTestAssessment['pillars'].values.reshape(-1, 1)": 1,
      "dsTestAssessment['buckets'].values.reshape(-1, 1)": 1,
      "dsTestAssessment['duration'].values.reshape(-1, 1)": 1,
      "dsTestAssessment['left_crystals'].values.reshape(-1, 1)": 1,
      "dsTestAssessment['right_crystals'].values.reshape(-1, 1)": 1,
      "country_gini_data[['country_avg_score', 'gini_cdp_year']]": 1,
      "xtrain_embeddings": 1,
      "self.miner.tra_df.drop(drop_cols, axis=1)": 1,
      "X_TEST": 1,
      "count_matrix_sparse": 1,
      "all_data_scaled[['word_count', 'unique_word_count', 'mean_word_length', 'character_count', 'digit_count', 'non_word_char_count', 'number_of_hashtags', 'number_of_URLs', 'number_of_mentions']]": 1,
      "train_X_f": 1,
      "data1.loc[:, 16]": 1,
      "big": 1,
      "df[cols_1]": 1,
      "train_df[numeric_fea].values.astype(np.float64)": 1,
      "df.isnull().sum(axis=1).values.reshape(-1, 1)": 1,
      "Xtest": 1,
      "all_df[cont_list]": 1,
      "all_data[numeric_feat].values": 1,
      "decodeLabels(valPred[:, 30:])": 1,
      "valPred[:, :30]": 1,
      "decodeLabels(tstPred[:, 30:])": 1,
      "tstPred[:, :30]": 1,
      "predVal_df": 1,
      "predTst_df": 1,
      "df_train[var_cols]": 1,
      "df_test[var_cols]": 1,
      "np.reshape(x_train, (360, look_back * 5))": 1,
      "np.reshape(x_val, (60, look_back * 5))": 1,
      "np.reshape(x_test, (90, look_back * 5))": 1,
      "y_val.reshape(-1, 1)": 1,
      "full_data[num_col].values.reshape(-1, 1)": 1,
      "df.loc[:, 'MSZoning'].values.reshape(-1, 1)": 1,
      "df.loc[:, 'LotFrontage'].values.reshape(-1, 1)": 1,
      "df.loc[:, 'Utilities'].values.reshape(-1, 1)": 1,
      "df.loc[:, 'Exterior1st'].values.reshape(-1, 1)": 1,
      "df.loc[:, 'Exterior2nd'].values.reshape(-1, 1)": 1,
      "df.loc[:, 'MasVnrArea'].values.reshape(-1, 1)": 1,
      "df.loc[:, 'BsmtFinSF1'].values.reshape(-1, 1)": 1,
      "df.loc[:, 'BsmtFinSF2'].values.reshape(-1, 1)": 1,
      "df.loc[:, 'BsmtUnfSF'].values.reshape(-1, 1)": 1,
      "df.loc[:, 'TotalBsmtSF'].values.reshape(-1, 1)": 1,
      "df.loc[:, 'Electrical'].values.reshape(-1, 1)": 1,
      "df.loc[:, 'BsmtFullBath'].values.reshape(-1, 1)": 1,
      "df.loc[:, 'BsmtHalfBath'].values.reshape(-1, 1)": 1,
      "df.loc[:, 'GarageYrBlt'].values.reshape(-1, 1)": 1,
      "df.loc[:, 'GarageCars'].values.reshape(-1, 1)": 1,
      "df.loc[:, 'GarageArea'].values.reshape(-1, 1)": 1,
      "base[feat_to_scale]": 1,
      "df_train[df_train.columns[2:]]": 1,
      "chunk.drop('ID', axis=1)": 1,
      "X1_train_train": 1,
      "X1_train_valid": 1,
      "XXXtrain": 1,
      "x_test.reshape(-1, 1)": 1,
      "tt": 1,
      "ttU": 1,
      "only_notebook_gm_df[['diff_days']]": 1,
      "df['excerpt']": 1,
      "train_X_np": 1,
      "df.loc[ids, features_m]": 1,
      "df_training_": 1,
      "D": 1,
      "np.concatenate((train, test), axis=0)": 1,
      "train_X[cols]": 1,
      "dev_cv": 1,
      "log_price(train['price']).values.reshape(-1, 1)": 1,
      "VT.fit_transform(train)": 1,
      "train_data_v5[['Fare']]": 1,
      "df[nominal_scale_columns]": 1,
      "sale2013.values.reshape(-1, 1)": 1,
      "snap2013.values.reshape(-1, 1)": 1,
      "[[temp]]": 1,
      "depths_df['z'].values.reshape(-1, 1)": 1,
      "matrixTFIDF": 1,
      "oh_us_train_df['age_approx'].values.reshape(-1, 1)": 1,
      "dataset[num_col]": 1,
      "house[colume]": 1,
      "house_test_data[colume]": 1,
      "house_test_data": 1,
      "data_gene": 1,
      "data_cell": 1,
      "train_features[g_columns + c_columns].values": 1,
      "X.iloc[:, 3:]": 1,
      "X_predict.iloc[:, 3:]": 1,
      "dataTrain": 1,
      "dataTest": 1,
      "dfTrain": 1,
      "trainFeatures": 1,
      "recent[[x for x in recent.columns if x not in ['TeamID', 'Season']]]": 1,
      "data[sclcol]": 1,
      "X_dev": 1,
      "text_X_train": 1,
      "text_X_full_train": 1,
      "all_data[data_columns]": 1,
      "train[numerical]": 1,
      "featuresExtended": 1,
      "y_train.reshape(len(y_train), 1)": 1,
      "training_data_noDWT": 1,
      "test_data_noDWT": 1,
      "ts": 1,
      "app_train[x_num]": 1,
      "np.concatenate([train['desc_len'].reshape(-1, 1), test['desc_len'].reshape(-1, 1)])": 1,
      "np.array(df_train['Age']).reshape(-1, 1)": 1,
      "np.array(np.round(df_train['Fare'], 2)).reshape(-1, 1)": 1
    },
    "sklearn.preprocessing._data.MinMaxScaler.fit.X": {
      "train": 101,
      "X": 47,
      "X_train": 37,
      "x_train": 34,
      "data": 13,
      "test": 10,
      "df[['q1len', 'q2len', 'q1_n_words', 'q2_n_words', 'word_share']]": 9,
      "train_features": 7,
      "x": 6,
      "features": 6,
      "train1": 4,
      "lr_train": 4,
      "knn_train": 4,
      "X1": 4,
      "df": 4,
      "features.values": 4,
      "tr_indi_df": 4,
      "X_test": 3,
      "dataset[feature_scale]": 3,
      "train_data": 3,
      "train_set": 3,
      "self.df.loc[:, num_list]": 3,
      "training['sales'].values.reshape(-1, 1)": 3,
      "X_total": 2,
      "xTrain": 2,
      "condition.reshape(-1, 1)": 2,
      "XT": 2,
      "train[features]": 2,
      "df_train.values": 2,
      "pd.concat([train, x_test])": 2,
      "img": 2,
      "yy": 2,
      "yyy": 2,
      "test.values": 2,
      "raw_data": 2,
      "df_train[['q1len', 'q2len', 'q1_n_words', 'q2_n_words', 'word_share']]": 2,
      "train_feature": 2,
      "manhattan_dis_array": 2,
      "eucledian_dis_array": 2,
      "minkowsk_dis_array": 2,
      "train_df[features]": 2,
      "unmissed": 2,
      "df_train[[col]].values": 2,
      "X_train[col].values.reshape(-1, 1)": 2,
      "y_train.values.reshape(-1, 1)": 2,
      "lr_X_train": 2,
      "knn_X_train": 2,
      "tourney_dresults[minicol].values.astype('float64')": 2,
      "tourney_dresults[col].values.astype('float64')": 2,
      "np.array(train_df2_province_conf).reshape(-1, 1)": 1,
      "np.array(train_df2_province_fata).reshape(-1, 1)": 1,
      "train[numerical_columns]": 1,
      "training_set": 1,
      "np.array(target1).reshape(844392, 1)": 1,
      "np.array(merged_train_df)": 1,
      "train_TDF.toarray()": 1,
      "input_data": 1,
      "X_train1": 1,
      "pd.concat([train_data[x], test_data[x]]).values.reshape(-1, 1)": 1,
      "X_Fin_test": 1,
      "np.expand_dims(infection_train, axis=1)": 1,
      "np.expand_dims(fatality_train, axis=1)": 1,
      "np.expand_dims(daily_cases_infected, axis=1)": 1,
      "np.expand_dims(daily_cases_fatality, axis=1)": 1,
      "infections": 1,
      "fatality": 1,
      "x_prediction": 1,
      "train_x": 1,
      "df.iloc[:, 3:]": 1,
      "train[feature_scale]": 1,
      "test[feature_scale]": 1,
      "X_train[num_cols]": 1,
      "data[features_to_scale]": 1,
      "test[features_to_scale]": 1,
      "X[self._vestas_features]": 1,
      "x_test": 1,
      "bench_train": 1,
      "bench_test": 1,
      "main_train": 1,
      "main_test": 1,
      "df[cols_to_scale]": 1,
      "df1": 1,
      "dd.train[dd.numeric_features]": 1,
      "train[['question_num_words', 'answer_num_words']].values": 1,
      "X_final": 1,
      "ts.take([2], axis=1)": 1,
      "X[['distance', 'week', 'offense_score', 'defense_score', 'line_of_scrimmage', 'game_clock']]": 1,
      "df['X'].values.reshape(df.shape[0], 1)": 1,
      "df['Y'].values.reshape(df.shape[0], 1)": 1,
      "X_train[feats]": 1,
      "pd.concat([train, test])": 1,
      "test[['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal']]": 1,
      "project_data['price'].values.reshape(-1, 1)": 1,
      "train2[f].fillna(0).astype('float32').values.reshape(-1, 1)": 1,
      "y_trn_cv": 1,
      "df_train[feature_scale]": 1,
      "quant": 1,
      "norm": 1,
      "pd.concat([train[features], test[features]], axis=0)": 1,
      "Y_train[Y_train != 0]": 1,
      "sales[['item_price']]": 1,
      "x_train.values": 1,
      "feat.values": 1,
      "total2": 1,
      "train[['item_price']]": 1,
      "y": 1,
      "data[cat_count]": 1,
      "source": 1,
      "X_train_reg": 1,
      "X_train_f": 1,
      "dataset[num_features].drop(['SalePrice', 'YrSold'], axis=1)": 1,
      "dataset[['SalePrice']]": 1,
      "df_one_hot": 1,
      "np.array([vals]).T": 1,
      "np.concatenate((normalize_train_df[column].as_matrix(), test_df[column].as_matrix())).reshape(-1, 1)": 1,
      "train_data[['Age']]": 1,
      "TS": 1,
      "df_to_reshape[columns_list]": 1,
      "data_to_cluster": 1,
      "train_data[['Fatalities', 'Population_Size', 'Tourism']]": 1,
      "train[['runtime', 'budget', 'popularity']]": 1,
      "test[['runtime', 'budget', 'popularity']]": 1,
      "tr": 1,
      "trr": 1,
      "prep_df": 1,
      "combined_df[combined_df['FROM'] == 'train'][['Weeks_Passed', 'FVC', 'Percent', 'Age']]": 1,
      "train[meta_features]": 1,
      "alldata2": 1,
      "data_gene[GENES]": 1,
      "data_cell[CELLS]": 1,
      "tr_X": 1,
      "np.array(X.loc[:, self.column], dtype=float).reshape(-1, 1)": 1,
      "oil[['dcoilwtico']]": 1,
      "train_copy.values": 1,
      "columns": 1,
      "df[['q1_word_len', 'q2_word_len', 'q1_char_len', 'q2_char_len', 'common_unigrams_len', 'common_unigrams_ratio', 'common_bigrams_len', 'common_bigrams_ratio', 'common_trigrams_len', 'common_trigrams_ratio']]": 1,
      "df[['q1_word_len', 'q2_word_len', 'q1_char_len', 'q2_char_len', 'common_unigrams_len', 'common_unigrams_ratio', 'common_bigrams_len', 'common_bigrams_ratio', 'common_trigrams_len', 'common_trigrams_ratio', 'q1_q2_intersect', 'q1_freq', 'q2_freq']]": 1,
      "df_test[['q1_word_len', 'q2_word_len', 'q1_char_len', 'q2_char_len', 'common_unigrams_len', 'common_unigrams_ratio', 'common_bigrams_len', 'common_bigrams_ratio', 'common_trigrams_len', 'common_trigrams_ratio', 'q1_q2_intersect', 'q1_freq', 'q2_freq']]": 1,
      "feature_data": 1,
      "df[scale_features]": 1,
      "minmaxv": 1,
      "x_t_knn": 1,
      "data_passenger_count": 1,
      "df[num_feats]": 1,
      "numeric_data": 1,
      "x_train_sub_pca": 1,
      "arr": 1,
      "x_train_s": 1,
      "df[RATINGS]": 1,
      "train_poly_fea": 1,
      "df[[x]]": 1,
      "df1[[x]]": 1,
      "train_X": 1,
      "train_textWords.reshape(-1, 1)": 1,
      "train_word_density.reshape(-1, 1)": 1,
      "train_geneCount.reshape(-1, 1)": 1,
      "train[col]": 1,
      "train_features.append(public_test_features.drop('cp_type', axis=1))": 1,
      "test_train": 1,
      "all[transform_columns]": 1,
      "ntrain": 1,
      "x_train2[[x]]": 1,
      "x_test2[[x]]": 1,
      "Data": 1,
      "df[columns].values": 1,
      "inputs_df[numeric_cols]": 1,
      "train.append(test)": 1,
      "df_all[other_cols]": 1,
      "train_df": 1,
      "np.array([X_train[shop_idx][i]['item_price'].unique()[0] for i in range(0, len(X_train[shop_idx]))]).reshape(-1, 1)": 1,
      "np.array([j for i in range(0, len(Y_train[shop_idx])) for j in list(Y_train[shop_idx][i])]).reshape(-1, 1)": 1,
      "np.array([data_list[shop_index][i]['item_price'].unique()[0] for i in range(0, len(data_list[shop_index]))]).reshape(-1, 1)": 1,
      "np.array([j for i in range(0, len(target_list[shop_index])) for j in list(target_list[shop_index][i])]).reshape(-1, 1)": 1,
      "train.drop('Cover_Type', axis=1)": 1,
      "test.drop('Id', axis=1)": 1,
      "col_matrix": 1,
      "df_test_data": 1,
      "f64.reshape((-1, 1))": 1,
      "train_df['text_NegScore'].values.reshape(-1, 1)": 1,
      "train_df['text_PosScore'].values.reshape(-1, 1)": 1,
      "train_df['text_NeuScore'].values.reshape(-1, 1)": 1,
      "train_df['text_compoundScore'].values.reshape(-1, 1)": 1,
      "df_train[['q1len', 'q2len', 'q1_n_words', 'q2_n_words', 'word_share', 'q1_q2_intersect', 'q1_freq', 'q2_freq']]": 1,
      "np.concatenate([train_features, test_features], axis=0)": 1,
      "FeaturesData": 1,
      "Xtrain0": 1,
      "TargetFreq": 1,
      "Zenc": 1,
      "X_all": 1,
      "rgb_batch_Y": 1,
      "vals": 1,
      "scaling_features_data": 1,
      "train_features[numeric_cols].append(test_features[numeric_cols])": 1,
      "train_data[['Age', 'Fare']]": 1,
      "dftestx": 1,
      "train_data_1": 1,
      "np.concatenate([train['description_length'], test['description_length']]).reshape(-1, 1)": 1,
      "training_features": 1,
      "scale_reshape(data)": 1,
      "numeric_train": 1,
      "X_test_sub": 1,
      "[[1], [7]]": 1
    },
    "sklearn.preprocessing._data.MinMaxScaler.inverse_transform.X": {
      "y_pred": 64,
      "preds": 22,
      "val_preds": 20,
      "testInput": 19,
      "data_predict": 9,
      "trainPredict": 8,
      "testPredict": 8,
      "predicted_test": 6,
      "predictions": 6,
      "dataY_plot": 6,
      "test_predict": 5,
      "[trainY]": 5,
      "[testY]": 5,
      "test_predictions": 5,
      "y_test": 4,
      "np.array(predictions).reshape(-1, 1)": 4,
      "inv_y": 3,
      "train_predict": 3,
      "y_val": 3,
      "y_train": 3,
      "test_pred": 3,
      "np.array([x for sl in pred for x in sl]).reshape(-1, 1)": 3,
      "pred_test_set": 3,
      "dataY_plot.reshape(-1, 1)": 3,
      "pred": 3,
      "inv_yhat": 2,
      "preds0[:, mask].cpu().detach().numpy()": 2,
      "preds1[:, mask].cpu().detach().numpy()": 2,
      "preds2[:, mask].cpu().detach().numpy()": 2,
      "targets[:, mask].cpu().detach().numpy()": 2,
      "new_response": 2,
      "y_eval": 2,
      "np.expand_dims(preds_infection, axis=0)": 2,
      "np.expand_dims(preds_fatality, axis=0)": 2,
      "np.expand_dims(np.array(predictions), axis=0)": 2,
      "[y_train]": 2,
      "[y_test]": 2,
      "Ytest": 2,
      "Ytrain": 2,
      "lst_output": 2,
      "np.swapaxes(output_cases, 0, 1)": 2,
      "np.swapaxes(output_fatalities, 0, 1)": 2,
      "np.reshape(cases_preds, (output_cases.shape[0], -1))": 2,
      "np.reshape(fatalities_preds, (output_fatalities.shape[0], -1))": 2,
      "c_y[:, np.newaxis]": 2,
      "f_y[:, np.newaxis]": 2,
      "predicted_cases": 2,
      "y_pred.reshape(-1, 1)": 2,
      "model['model'].predict(model['dataset'].x_test).squeeze()": 2,
      "forecast": 2,
      "y_predict": 2,
      "seq_pred.cpu().numpy()": 2,
      "predictions['XGB_predictions'].values.reshape(-1, 1)": 2,
      "valid_y.reshape(-1, 1)": 2,
      "test_y.reshape(-1, 1)": 2,
      "prediction_log": 2,
      "predicted.reshape(-1, 1)": 2,
      "output[0][0].detach().numpy().reshape(-1, 1)": 1,
      "output[0][1].detach().numpy().reshape(-1, 1)": 1,
      "model.predict(np.array([n]).reshape(-1, 1))": 1,
      "compare": 1,
      "test.reshape(7, 1)": 1,
      "test_predicted.reshape(7, 1)": 1,
      "preds_train": 1,
      "preds_valid": 1,
      "preds_test": 1,
      "np.reshape(y, (-1, 1))": 1,
      "np.expand_dims(y_test_infection.flatten().numpy(), axis=0)": 1,
      "np.expand_dims(y_test_fatality.flatten().numpy(), axis=0)": 1,
      "infection_train": 1,
      "np.squeeze(testInput, axis=0)": 1,
      "np.array(predictions).reshape(28, 30490)": 1,
      "test_cc": 1,
      "test_ft": 1,
      "traning_pred": 1,
      "model.predict(testX)": 1,
      "y_pred_scaled[:, :, 0]": 1,
      "predicted_values_scaled[:, :, 0]": 1,
      "predictions.reshape(-1, 1)": 1,
      "lstm_predictions_scaled": 1,
      "df": 1,
      "df[1176:]": 1,
      "y_valid_pred_lgb.reshape(-1, 1)": 1,
      "y_pred_lgb.reshape(-1, 1)": 1,
      "vali_yhat": 1,
      "[test['sales']]": 1,
      "model.predict(X_trn_cv)": 1,
      "model.predict(X_val_cv)": 1,
      "model.predict(X_test_f)": 1,
      "test_preds": 1,
      "pred_df['ConfirmedCases_scaled'].values.reshape(1, -1)": 1,
      "pred_df['Fatalities_scaled'].values.reshape(1, -1)": 1,
      "store_sales": 1,
      "model['dataset'].y_test": 1,
      "model['model'].predict(model['dataset'].x_evaluation).squeeze()": 1,
      "test_con": 1,
      "test_fatal": 1,
      "[y_predlr]": 1,
      "[y_predrf]": 1,
      "[y_predgb]": 1,
      "[y_predxgb]": 1,
      "y_confirmed_pred[0]": 1,
      "y_fatalities_pred[0]": 1,
      "X_test_confirmed": 1,
      "X_test_fatalities": 1,
      "forecast_val": 1,
      "np.expand_dims(last_month_forecast, axis=0)": 1,
      "model_1.predict(intermediate_layer_model.predict(X[df.isTest]))": 1,
      "y_test_pred": 1,
      "y_test_1": 1,
      "y_val_pred": 1,
      "ypred": 1,
      "ytest": 1,
      "y_pred[0]": 1,
      "inv_y_pred": 1,
      "prediction_CNN": 1,
      "np.concatenate(y_test)": 1,
      "outputs.data.numpy()": 1,
      "prices.data.numpy()": 1,
      "np.array(pred).reshape(-1, 1)": 1,
      "np.array(pred_f).reshape(-1, 1)": 1,
      "model.predict(X_sub)": 1,
      "two_weeks.squeeze(0).numpy()": 1,
      "YPred_scaled[0]": 1,
      "norm_preds": 1,
      "y[['count']]": 1,
      "norm_preds.reshape(-1, 1)": 1,
      "y_val[s][['count']]": 1,
      "pred.reshape(-1, 1)": 1,
      "Y_pred": 1,
      "dataset": 1,
      "val_X": 1,
      "val_preds_rnn": 1,
      "preds_rnn": 1,
      "arr": 1,
      "y": 1,
      "temp[cols_to_scale]": 1,
      "train_pred.reshape(-1, 1)": 1,
      "test_pred.reshape(-1, 1)": 1,
      "np.array(train_pred).reshape(-1, 1)": 1,
      "np.array(test_pred).reshape(-1, 1)": 1,
      "train_pred": 1,
      "df1": 1,
      "df1[2734:]": 1,
      "df3": 1,
      "test_prediction": 1,
      "trainY": 1,
      "testY": 1,
      "pred_model": 1,
      "np.array(tslope).reshape(-1, 1)": 1,
      "pred[:, 0].reshape(-1, 1)": 1,
      "pred[:, 1].reshape(-1, 1)": 1,
      "pred_sales": 1,
      "np.reshape(reg.predict(X_train), (-1, 1))": 1,
      "np.reshape(reg.predict(X_val), (-1, 1))": 1,
      "np.reshape(reg.predict(X_test), (-1, 1))": 1,
      "pred_list_confirmed.reshape(-1, 1)": 1,
      "pred_list_fatalities.reshape(-1, 1)": 1,
      "df_stacking[col].values.reshape(-1, 1)": 1,
      "df_stacking_test[col].values.reshape(-1, 1)": 1,
      "X_test['XGB_predict'].values.reshape(-1, 1)": 1,
      "predictions['y1'].values.reshape(-1, 1)": 1,
      "predictions['y2'].values.reshape(-1, 1)": 1,
      "predictions['Random_forest_entire'].values.reshape(-1, 1)": 1,
      "predictions['y5'].values.reshape(-1, 1)": 1,
      "model.predict([test_X.toarray(), test_seq]).reshape(-1, 1)": 1,
      "model.predict([X_transform_submit.toarray(), submit_seq]).reshape(-1, 1)": 1,
      "prediction_log_final.reshape(-1, 1)": 1,
      "train_y_scale": 1,
      "result_df": 1,
      "test.reshape(6045, 1)": 1,
      "oof_test": 1,
      "pred.T": 1,
      "ar": 1,
      "yhat.reshape(-1, 1)": 1,
      "testY.reshape(-1, 1)": 1,
      "temp_df[['ConfirmedCases_scaled_predicted']]": 1,
      "temp_df[['Fatalities_scaled_predicted']]": 1,
      "test_df[['ConfirmedCases_scaled']]": 1,
      "test_df[['Fatalities_scaled']]": 1,
      "y_pred_ann_train": 1,
      "y_pred_ann": 1
    },
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.bootstrap": {
      "True": 3869,
      "False": 67,
      "0.7": 3,
      "p['bootstrap']": 1,
      "best_parameters['bootstrap']": 1
    },
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.ccp_alpha": {
      "0.0": 3938,
      "7.135644710065878e-07": 1,
      "0": 1,
      "0.008": 1
    },
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.criterion": {
      "'mse'": 3918,
      "'mae'": 20,
      "trial.suggest_categorical('criterion', ['mse'])": 1,
      "'rmse'": 1,
      "rf_gs.best_params_['criterion']": 1
    },
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.max_depth": {
      "None": 3120,
      "10": 103,
      "3": 84,
      "5": 68,
      "15": 55,
      "20": 54,
      "6": 50,
      "30": 29,
      "2": 29,
      "7": 25,
      "4": 23,
      "8": 22,
      "max_depth": 21,
      "g['md']": 17,
      "80": 17,
      "25": 15,
      "50": 15,
      "depth": 13,
      "100": 12,
      "12": 11,
      "40": 10,
      "27": 10,
      "13": 9,
      "best_max_depth": 9,
      "17": 8,
      "9": 7,
      "16": 7,
      "result.best_params_['max_depth']": 6,
      "i": 6,
      "500": 6,
      "18": 4,
      "rf_cv.best_params_['max_depth']": 4,
      "35": 4,
      "14": 4,
      "a['max_depth']": 4,
      "22": 4,
      "gsearch.best_params_.get('max_depth')": 3,
      "11": 3,
      "90": 3,
      "gs1.best_params_['max_depth']": 3,
      "1000": 3,
      "200": 2,
      "70": 2,
      "26": 2,
      "19": 2,
      "400": 2,
      "best_params['max_depth']": 2,
      "23": 2,
      "md": 2,
      "60": 2,
      "max_depth_min": 2,
      "trial.suggest_int('max_depth', 3, 70)": 1,
      "rf_regressor.best_params_['max_depth']": 1,
      "28": 1,
      "24": 1,
      "21": 1,
      "m_depth": 1,
      "_max_depth": 1,
      "X_train.shape[1]": 1,
      "87": 1,
      "33": 1,
      "45": 1,
      "b": 1,
      "86": 1,
      "grid_search_cas.best_params_['max_depth']": 1,
      "grid_search_reg.best_params_['max_depth']": 1,
      "trial.suggest_int('max_depth', 5, 12)": 1,
      "2000": 1,
      "max_depth[i]": 1,
      "cur_prop[1]": 1,
      "55": 1,
      "300": 1
    },
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.max_features": {
      "'auto'": 3243,
      "0.5": 204,
      "'sqrt'": 133,
      "0.6": 51,
      "None": 28,
      "0.3": 20,
      "g['mf']": 17,
      "'log2'": 16,
      "6": 16,
      "max_features": 16,
      "3": 14,
      "0.2": 14,
      "15": 13,
      "10": 12,
      "12": 10,
      "2": 9,
      "0.9": 8,
      "0.8": 8,
      "20": 7,
      "1": 7,
      "0.99": 6,
      "int(params['max_features'])": 6,
      "0.4": 5,
      "feature": 5,
      "9": 5,
      "rf_cv.best_params_['max_features']": 4,
      "40": 4,
      "5": 4,
      "0.75": 3,
      "7": 3,
      "MAX_FEATS": 3,
      "0.7": 2,
      "gs2.best_params_['max_features']": 2,
      "30": 2,
      "4": 2,
      "50": 2,
      "16": 2,
      "100": 2,
      "mf": 2,
      "rf_regressor.best_params_['max_features']": 1,
      "0.1": 1,
      "25": 1,
      "best_max_features": 1,
      "55": 1,
      "_max_features": 1,
      "49": 1,
      "18": 1,
      "834": 1,
      "36": 1,
      "8": 1,
      "48": 1,
      "int(math.sqrt(n_features))": 1,
      "i": 1,
      "c": 1,
      "best_params['max_features']": 1,
      "0.43709": 1,
      "grid_search_cas.best_params_['max_features']": 1,
      "grid_search_reg.best_params_['max_features']": 1,
      "0.25": 1,
      "trial.suggest_int('max_features', 5, 126)": 1,
      "p['max_features']": 1,
      "best_parameters['max_features']": 1,
      "13": 1,
      "rf_gs.best_params_['max_features']": 1,
      "cur_prop[0]": 1,
      "0.22": 1,
      "79": 1,
      "24": 1,
      "600": 1,
      "90": 1
    },
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.max_leaf_nodes": {
      "None": 3898,
      "1000": 6,
      "10": 6,
      "100": 4,
      "gsearch.best_params_.get('max_leaf_nodes')": 3,
      "16": 3,
      "10000": 3,
      "200": 2,
      "999": 2,
      "leafs": 2,
      "50000": 2,
      "31": 1,
      "8": 1,
      "55100": 1,
      "best_max_leaf_nodes": 1,
      "5": 1,
      "max_leaf_nodes": 1,
      "600": 1,
      "num_leaves": 1,
      "-1": 1,
      "750": 1
    },
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.max_samples": {
      "None": 3899,
      "10000": 9,
      "0.8": 8,
      "max_samples": 5,
      "40000": 4,
      "100000": 4,
      "0.3": 2,
      "0.9": 2,
      "200000": 2,
      "50000": 1,
      "0.6": 1,
      "500000": 1,
      "250": 1,
      "0.1": 1,
      "4000": 1
    },
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.min_impurity_decrease": {
      "0.0": 3932,
      "0.001": 5,
      "0.002": 2,
      "0.0002": 1,
      "0.0001": 1
    },
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.min_impurity_split": {
      "None": 3937,
      "1e-07": 4
    },
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.min_samples_leaf": {
      "1": 3313,
      "3": 283,
      "5": 90,
      "2": 46,
      "10": 37,
      "4": 37,
      "25": 19,
      "15": 17,
      "100": 10,
      "50": 8,
      "min_samples_leaf": 8,
      "7": 7,
      "8": 6,
      "int(params['min_samples_leaf'])": 6,
      "20": 6,
      "a['min_samples_leaf']": 4,
      "result.best_params_['min_samples_leaf']": 4,
      "leaf": 3,
      "best_min_samples_leaf": 3,
      "11": 3,
      "60": 3,
      "6": 2,
      "30": 2,
      "17": 2,
      "200": 2,
      "75": 2,
      "rf_regressor.best_params_['min_samples_leaf']": 1,
      "train_data.shape[1]": 1,
      "gs3.best_params_['min_samples_leaf']": 1,
      "9": 1,
      "_min_samples_leaf": 1,
      "12": 1,
      "31": 1,
      "0.01": 1,
      "22": 1,
      "16": 1,
      "1e-05": 1,
      "26": 1,
      "best_params['min_samples_leaf']": 1,
      "19": 1,
      "trial.suggest_int('min_samples_leaf', 3, 6)": 1,
      "result_random_forest.best_params_['min_samples_leaf']": 1,
      "18": 1,
      "0.1": 1
    },
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.min_samples_split": {
      "2": 3649,
      "5": 44,
      "4": 41,
      "3": 24,
      "10": 23,
      "15": 20,
      "8": 17,
      "25": 16,
      "20": 14,
      "7": 8,
      "6": 6,
      "int(params['min_samples_split'])": 6,
      "best_min_samples_split": 5,
      "14": 4,
      "12": 4,
      "100": 4,
      "0.3": 4,
      "result.best_params_['min_samples_split']": 4,
      "split": 3,
      "30": 3,
      "13": 3,
      "150": 2,
      "40": 2,
      "11": 2,
      "min_samples_split": 2,
      "50": 2,
      "mss": 2,
      "1": 2,
      "1e-05": 1,
      "trial.suggest_int('min_samples_split', 2, 50)": 1,
      "rf_regressor.best_params_['min_samples_split']": 1,
      "gs3.best_params_['min_samples_split']": 1,
      "9": 1,
      "_min_samp_split": 1,
      "93": 1,
      "26": 1,
      "23": 1,
      "49": 1,
      "32": 1,
      "31": 1,
      "17": 1,
      "0.2": 1,
      "i": 1,
      "best_params['min_samples_split']": 1,
      "1000": 1,
      "p['min_samples_split']": 1,
      "best_parameters['min_samples_split']": 1,
      "75": 1,
      "result_random_forest.best_params_['min_samples_split']": 1,
      "x": 1,
      "0.01": 1,
      "min_samples_split[i]": 1,
      "60": 1
    },
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.min_weight_fraction_leaf": {
      "0.0": 3938,
      "0.001": 2,
      "0.1": 1
    },
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.oob_score": {
      "False": 3547,
      "True": 392,
      "4": 1,
      "[True, False]": 1
    },
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.verbose": {
      "0": 3752,
      "1": 140,
      "2": 21,
      "True": 14,
      "10": 4,
      "100": 4,
      "False": 3,
      "3": 2,
      "verbose": 1
    },
    "sklearn.ensemble._forest.RandomForestRegressor.__init__.warm_start": {
      "False": 3922,
      "True": 19
    },
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.analyzer": {
      "'word'": 3014,
      "'char'": 163,
      "lambda x: x": 13,
      "'char_wb'": 9,
      "clean_text": 4,
      "dummy": 3,
      "text_process": 2,
      "TOKEN_MODE": 2,
      "analyzer": 2,
      "ngrams": 2,
      "process": 1
    },
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.lowercase": {
      "True": 3157,
      "False": 56,
      "1": 1,
      "lowercase": 1
    },
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.ngram_range": {
      "(1, 1)": 1694,
      "(1, 2)": 646,
      "(1, 3)": 530,
      "(1, 4)": 66,
      "(1, 6)": 58,
      "(2, 6)": 46,
      "(1, 5)": 44,
      "(2, 2)": 24,
      "(3, 3)": 12,
      "(2, 3)": 11,
      "(2, 4)": 10,
      "ngram_range": 9,
      "(4, 4)": 4,
      "(1, 10)": 4,
      "(1, 7)": 4,
      "(5, 5)": 3,
      "(2, 5)": 3,
      "self.ngram_range": 3,
      "(3, 6)": 3,
      "(ngram, ngram)": 3,
      "[1, 3]": 3,
      "[3, 5]": 3,
      "(4, 6)": 2,
      "n_gram": 2,
      "(3, 5)": 2,
      "(1, n)": 2,
      "(1, ngram)": 2,
      "(0, 4)": 2,
      "NGRAM_RANGE": 2,
      "{1, 2}": 2,
      "(3, 4)": 1,
      "[1, 4]": 1,
      "(1, 8)": 1,
      "(2, 9)": 1,
      "self.n_gram_range": 1,
      "(1, _max_ngrams)": 1,
      "(10, 11)": 1,
      "ngrams[i]": 1,
      "(1, 32)": 1,
      "tfidf_ngram_range": 1,
      "(n, n)": 1,
      "(ngram_range_start, ngram_range_end)": 1,
      "bow_ngrams": 1,
      "ngram_ranges[idx]": 1,
      "(1, self.tfidf_ngram_max)": 1,
      "ngramrange": 1
    },
    "sklearn.feature_extraction.text.TfidfVectorizer.fit_transform.raw_documents": {
      "X_train": 59,
      "X_text.loc[:, i].values": 48,
      "corpus": 38,
      "merge['item_description']": 38,
      "train[COMMENT]": 32,
      "train['text']": 26,
      "X": 25,
      "corpustr": 23,
      "df['item_description']": 21,
      "x_train": 21,
      "train['comment_text']": 21,
      "data": 21,
      "text": 20,
      "txt": 18,
      "train_df['text']": 16,
      "df": 16,
      "train['item_description']": 14,
      "questions": 14,
      "train_data": 13,
      "dfqa['question'].values": 12,
      "train['overview'].fillna('')": 12,
      "train['Phrase']": 11,
      "[text1, text2]": 11,
      "train_df['title'].values.tolist() + test_df['title'].values.tolist()": 11,
      "train_df['description'].values.tolist() + test_df['description'].values.tolist()": 11,
      "name": 11,
      "item_desc": 11,
      "df1_s[1]": 10,
      "df_subsampled.apply(lambda row: row['question1'] + ' ' + row['question2'], axis=1).values": 10,
      "train_df['text'].values.tolist() + test_df['text'].values.tolist()": 10,
      "train_text": 10,
      "train.title": 10,
      "train_df_r[col]": 10,
      "train_data['comment_text']": 9,
      "df['text']": 9,
      "X_train['text']": 9,
      "items['item_name']": 9,
      "train_df['comment_text']": 8,
      "df_train['text']": 8,
      "tfidf_txt": 8,
      "train['question_title'].values": 8,
      "train['question_body'].values": 8,
      "train['answer'].values": 8,
      "train_df['TEXT']": 7,
      "list(all_desc)": 7,
      "all_text": 7,
      "texts": 6,
      "train.Phrase": 6,
      "orig_train2": 6,
      "pd.read_csv(data_folder + 'train.csv').title": 6,
      "alldata.comment_text": 6,
      "X_train.values": 6,
      "df['TEXT']": 6,
      "tokenized_tweet": 6,
      "list(combined_sample['item_description'])": 5,
      "x": 5,
      "train['description'].append(test['description'])": 5,
      "[simple_prepro_tfidf(l) for l in tqdm.tqdm(train['question_title'].values)]": 5,
      "[simple_prepro_tfidf(l) for l in tqdm.tqdm(train['question_body'].values)]": 5,
      "[simple_prepro_tfidf(l) for l in tqdm.tqdm(train['answer'].values)]": 5,
      "X_train.values.astype('U')": 5,
      "train.clean": 5,
      "shops['shop_name']": 5,
      "df.item_description": 5,
      "df['title']": 5,
      "traindf['lemmatized_ingredients_list']": 5,
      "testdf['lemmatized_test_ingredients_list']": 5,
      "processed_text_sent": 5,
      "x_train['question']": 4,
      "train_df['question_text'].values.tolist() + test_df['question_text'].values.tolist()": 4,
      "items_subset['item_name']": 4,
      "premise_train + ' ' + hypothesis_train": 4,
      "train_df['ingredients']": 4,
      "merge['name']": 4,
      "train_data['clean_text']": 4,
      "corpus_train": 4,
      "X_cora_train['stemming_question_for_tfidf']": 4,
      "X_train['stemming_text_for_tfidf']": 4,
      "train['stemming_selected_text_for_tfidf']": 4,
      "qs": 4,
      "[str(i) for i in features]": 4,
      "train_df.question_text": 4,
      "df.name": 4,
      "df['overview']": 4,
      "df['tagline']": 4,
      "X_train['text'].values.tolist() + X_test['text'].values.tolist()": 4,
      "train.comment_text": 4,
      "train_data['text']": 4,
      "train_df['Variation']": 4,
      "trn.comment_text": 4,
      "sub.comment_text": 4,
      "pd.concat([trn.comment_text, sub.comment_text], axis=0)": 4,
      "train_df.question_text.values": 4,
      "train['final_desc']": 4,
      "train_data['question_title'].values": 3,
      "train_data['question_body'].values": 3,
      "train_data['answer'].values": 3,
      "train.question_text": 3,
      "cur_train['text_temp'].values": 3,
      "train": 3,
      "train['item_description'].values.tolist() + test['item_description'].values.tolist()": 3,
      "dataset['text']": 3,
      "train_df['question_text']": 3,
      "train_X_": 3,
      "test['Phrase']": 3,
      "x_corpus_train": 3,
      "train.text": 3,
      "X_train['question']": 3,
      "x_train['text']": 3,
      "sentences": 3,
      "df.excerpt": 3,
      "test_df['description']": 3,
      "xtrain": 3,
      "X.values.astype('U')": 3,
      "train['excerpt']": 3,
      "list(df_train['preprocessed_question_text'].values) + list(df_test['preprocessed_question_text'].values)": 3,
      "series": 3,
      "df_train['Phrase']": 3,
      "train_as_text": 3,
      "tt_combine['item_description']": 3,
      "train_df['param123'].values.tolist() + test_df['param123'].values.tolist()": 3,
      "docs": 3,
      "df_train['item_description']": 3,
      "tr_te.txt2": 3,
      "item_categories['item_category_name']": 3,
      "Corpus1": 3,
      "test_data": 3,
      "df['description']": 3,
      "train_df['Gene']": 3,
      "documents": 3,
      "clean_corpus": 3,
      "a": 3,
      "merge['item_description'][:nrow_valid]": 3,
      "s": 3,
      "tweets_df['Concatenated']": 2,
      "phrase_sents": 2,
      "words": 2,
      "X_test": 2,
      "all_df[feature]": 2,
      "df_train[df_train['host_cat'] == cat]['answer']": 2,
      "data['test'].title.values": 2,
      "df.comment_text": 2,
      "train['Description']": 2,
      "data_train['debugged_questions']": 2,
      "data_test['debugged_questions']": 2,
      "train_comment": 2,
      "dataframe['text']": 2,
      "train_toxic[x_col]": 2,
      "train.ingredients": 2,
      "train.cleaned_phrase": 2,
      "input": 2,
      "features_train": 2,
      "X_train['question_title'].values": 2,
      "X_train['question_body'].values": 2,
      "X_train['answer'].values": 2,
      "train_df['dataset_title']": 2,
      "train_df['cleaned_label']": 2,
      "train_df2['text']": 2,
      "s_data": 2,
      "train_full['Text']": 2,
      "toxic_only": 2,
      "severe_toxic_only": 2,
      "obscene_only": 2,
      "threat_only": 2,
      "insult_only": 2,
      "x_train.astype('U')": 2,
      "home_part['product_title']": 2,
      "desc_part['product_description']": 2,
      "test_part['product_title']": 2,
      "x_train['normalized_text']": 2,
      "train['normalized_text']": 2,
      "df_all['item_description']": 2,
      "df.text": 2,
      "items_english": 2,
      "data['description']": 2,
      "df_all['description']": 2,
      "df['product_description']": 2,
      "phrase_train": 2,
      "all_desc": 2,
      "train_df['item_description']": 2,
      "train_data[3]": 2,
      "test_data[3]": 2,
      "data['title']": 2,
      "df['comment_text']": 2,
      "X_train.text": 2,
      "train['description']": 2,
      "train['features']": 2,
      "Xtrain": 2,
      "xvalid": 2,
      "X_cora_train['lemmatize_question_for_tfidf']": 2,
      "X_cora_train": 2,
      "sent": 2,
      "items_categories_merged['item_name']": 2,
      "df_train['cleaned_text']": 2,
      "ttextx_train.title": 2,
      "df_train['item_description'].apply(str)": 2,
      "train.normalized": 2,
      "data['Phrase']": 2,
      "items_df['item_name']": 2,
      "item_categories_df['item_category_name']": 2,
      "shops_df['shop_name']": 2,
      "df_train['Text']": 2,
      "traindf['text']": 2,
      "X_train_text": 2,
      "all_df['excerpt']": 2,
      "train['x'].values": 2,
      "df['excerpt']": 2,
      "train['question_text']": 2,
      "X_train['question_with_more_wt_title']": 2,
      "final_string": 2,
      "pd.concat([train[col_name], test[col_name]], axis=0)": 2,
      "phs": 2,
      "all_data['item_description']": 2,
      "dt.item_description": 2,
      "items['item_category_name']": 2,
      "sample_question_text": 2,
      "train_df['item_description'].values.tolist() + test_df['item_description'].values.tolist()": 2,
      "train_df['name'].values.tolist() + test_df['name'].values.tolist()": 2,
      "train['text_clean']": 2,
      "train['name']": 2,
      "x['separated_ing_lemma']": 2,
      "train.clean_text": 2,
      "train_texts": 2,
      "train[train.target == 1].question_text": 2,
      "df_train.clean_review": 2,
      "test_data['clean_text']": 2,
      "train['Text']": 2,
      "train.excerpt_clean": 2,
      "X_train['comment_text']": 2,
      "dtrain['txt']": 2,
      "all_qs['Q']": 2,
      "df_tr['ingredients'].values": 2,
      "combinedTxt": 2,
      "train_result['comment_text']": 2,
      "[q1, q2]": 2,
      "trainx_preprocess": 2,
      "train_df['excerpt']": 2,
      "train_X": 2,
      "train_df['comment_text'].values.astype('U')": 2,
      "df_cu['title']": 2,
      "tr_col": 2,
      "tr_brand_col + ' ' + tr_desc_col": 2,
      "Xtrain['ciphertext']": 1,
      "data['ingredients']": 1,
      "json_ingredients_cleaned": 1,
      "X_train.question_text": 1,
      "df_merge.text": 1,
      "df[col_name]": 1,
      "train['question_title']": 1,
      "train_df['question_text'].values.tolist()": 1,
      "test_df['question_text'].values.tolist()": 1,
      "train_data_without_id['ingredients']": 1,
      "train['ciphertext']": 1,
      "train_df['clean_question_text']": 1,
      "X_translated": 1,
      "X_multi": 1,
      "train_texts.question_title": 1,
      "train_texts.question_body": 1,
      "train_texts.answer": 1,
      "comb": 1,
      "train_set['text'].values": 1,
      "df_all['clean_text'].tolist()": 1,
      "list(sentences)": 1,
      "train['ingredients']": 1,
      "dfStandarized['REQUIREMENT_MINIMUM_QUALIFICATION_REDUCED_BIS'].values": 1,
      "df.values": 1,
      "train['text_merged']": 1,
      "feature_tr": 1,
      "title_text_raw": 1,
      "list(train['Description'].values) + list(test['Description'].values)": 1,
      "df_train.question_text.values": 1,
      "df_test.question_text.values": 1,
      "train_data.question1.values": 1,
      "train_data.question2.values": 1,
      "test_data.question1.values": 1,
      "test_data.question2.values": 1,
      "diff1['ciphertext']": 1,
      "diff2['ciphertext']": 1,
      "diff3['ciphertext']": 1,
      "diff4['ciphertext']": 1,
      "train_data.excerpt": 1,
      "train['cleaned']": 1,
      "train_temp['question_text']": 1,
      "train_documents": 1,
      "Full_df[textColumn].astype(str)": 1,
      "alldata['Description']": 1,
      "train[TEXT]": 1,
      "upsampled['question1']": 1,
      "upsampled['question2']": 1,
      "test['question1']": 1,
      "test['question2']": 1,
      "all_comment": 1,
      "allcomment": 1,
      "train_clean": 1,
      "X_text": 1,
      "train_feature.text": 1,
      "train[train.lang_abv == lan].premise": 1,
      "train[train.lang_abv == lan].hypothesis": 1,
      "X_text[col]": 1,
      "train['question_text'].values.tolist() + test['question_text'].values.tolist()": 1,
      "train['name'].values": 1,
      "train['text'].values": 1,
      "train_df['preprocessed_name'].values": 1,
      "train_df['preprocessed_description'].values": 1,
      "X.ciphertext": 1,
      "train_DF['cleaned_comment_text']": 1,
      "df_train['Cleaned_Text']": 1,
      "train_df[comment]": 1,
      "test_data['comment_text']": 1,
      "df['text'].values": 1,
      "final_flood_words": 1,
      "df_all['item_description_clean']": 1,
      "corpus_test": 1,
      "arraytotext(train.ingredients)": 1,
      "a.values": 1,
      "(' '.join(i) for i in sentences)": 1,
      "df_both[txt_col]": 1,
      "np.array(trainx)": 1,
      "train_test.Description": 1,
      "train_df['overview'].fillna('')": 1,
      "final": 1,
      "query.title": 1,
      "train.excerpt.values": 1,
      "retained_processed_text": 1,
      "X_train['question_with_title']": 1,
      "df['item_description'].values.tolist()": 1,
      "test['item_description'].values.tolist()": 1,
      "clensed_train": 1,
      "X_train.apply(lambda x: ' '.join(x))": 1,
      "df['Phrase']": 1,
      "pd.concat([train['name'], test['name']])": 1,
      "pd.concat([train['item_description'], test['item_description']])": 1,
      "combined_data['item_description']": 1,
      "x_train_b": 1,
      "train['new_text2']": 1,
      "train_sequence": 1,
      "data_tr['Description'].fillna('null').tolist()": 1,
      "join_data_all[:n_tr]": 1,
      "meta_desc_all[:n_tr].fillna('nan')": 1,
      "identity_hate_only": 1,
      "test.title": 1,
      "x_text": 1,
      "train['text'].tolist()": 1,
      "[x for x in sentences]": 1,
      "sample.excerpt": 1,
      "train['question_text'].values": 1,
      "df_train['clean_excerpt']": 1,
      "specs['info']": 1,
      "train_text + test_text": 1,
      "training_dataset['question_text']": 1,
      "train['lemmatized_text']": 1,
      "test['lemmatized_text']": 1,
      "xtrain['Variation']": 1,
      "xtrain['Gene']": 1,
      "xtrain['TEXT']": 1,
      "dataset": 1,
      "train_data['excerpt']": 1,
      "trainTxt": 1,
      "trainv['text']": 1,
      "df['product_title']": 1,
      "train['filtered_text']": 1,
      "train.iloc[:, 2]": 1,
      "combined_df.Processed_excerpt": 1,
      "traindata": 1,
      "merge['category_name']": 1,
      "X_new": 1,
      "X_train_ls": 1,
      "unsampled['comment_text']": 1,
      "list(x_train) + list(x_test)": 1,
      "data_list_1": 1,
      "data_list": 1,
      "train_question_text": 1,
      "train_answer_text": 1,
      "df[comment]": 1,
      "allIngredientsTextInTrain": 1,
      "dfX.values": 1,
      "df.overview": 1,
      "df.tagline": 1,
      "x1": 1,
      "df_train_sampled['question_text']": 1,
      "corpus_brand": 1,
      "corpus_name": 1,
      "corpus_description": 1,
      "cat_1": 1,
      "cat_2": 1,
      "cat_3": 1,
      "df_all['project_essay']": 1,
      "df['text_prep_nonstop_lemmatized']": 1,
      "category": 1,
      "X_cora_train_": 1,
      "X_train['lemmatize_text_for_tfidf']": 1,
      "train['lemmatize_selected_text_for_tfidf']": 1,
      "text_detokenized": 1,
      "train_tweet['text']": 1,
      "X[:, 1]": 1,
      "X[:, 0]": 1,
      "items.item_name.values": 1,
      "city_5_4['Response Answer']": 1,
      "train1['text']": 1,
      "df_train.item_description": 1,
      "lem_req": 1,
      "lem_dut": 1,
      "df_train['ingredients_cleaned']": 1,
      "train[f]": 1,
      "shops_list": 1,
      "train_df['Description'].values.astype('U').tolist() + test_df['Description'].values.astype('U').tolist()": 1,
      "corpusStr": 1,
      "df_all['comment_processed']": 1,
      "training_set['text']": 1,
      "input['question_text']": 1,
      "qs['processed']": 1,
      "data_train": 1,
      "self.train_data['clean']": 1,
      "self.test_data['clean']": 1,
      "questions['text']": 1,
      "clean_train_reviews": 1,
      "clean_test_reviews": 1,
      "test['Concatenated']": 1,
      "X_train_clean": 1,
      "list(desc)": 1,
      "train_set.ingredients": 1,
      "tac.tolist()": 1,
      "train_orig.cast_crew.fillna('')": 1,
      "train_orig.production_companies.fillna('')": 1,
      "train_orig.production_countries.fillna('')": 1,
      "train_orig.belongs_to_collection.fillna('')": 1,
      "train_orig.genres.fillna('')": 1,
      "train_orig.Keywords_tagline_overview.fillna('')": 1,
      "test_df['preprocessed']": 1,
      "[product_title_i, search_term_i]": 1,
      "[description_i, search_term_i]": 1,
      "[attribute_i, search_term_i]": 1,
      "[data_all['product_description'][i]]": 1,
      "[data_all['product_title'][i]]": 1,
      "[data_all['attribute'][i]]": 1,
      "data['lemmatized']": 1,
      "tag": 1,
      "plot": 1,
      "refined_data['combined_text']": 1,
      "corpus_training": 1,
      "df_test['cleaned_text']": 1,
      "train_ingredients_text": 1,
      "item_cats['item_category_name']": 1,
      "df_train['item_description'].astype(str).apply(lambda x: x.replace('No description yet', ''))": 1,
      "potDocs": 1,
      "tweets": 1,
      "df[df['source'] == 'train']['item_description']": 1,
      "df[df['source'] == 'test']['item_description']": 1,
      "X_train_df['item_description']": 1,
      "X_test_df['item_description']": 1,
      "X_t.excerpt": 1,
      "input_df.text.values": 1,
      "df['duties']": 1,
      "ingredients_data": 1,
      "ingredients_test": 1,
      "preprocess_title": 1,
      "df['review']": 1,
      "df['hashtags']": 1,
      "text_data": 1,
      "x_train_text": 1,
      "train_ingredients_lists": 1,
      "list(train['comment_text'])": 1,
      "train_stemmed['text']": 1,
      "df_train.text": 1,
      "X_train['item_description']": 1,
      "X_train['name']": 1,
      "train_features['item_description']": 1,
      "x_train['label_annotation']": 1,
      "x_test['label_annotation']": 1,
      "train_resources['subjects']": 1,
      "train_resources['essays']": 1,
      "train_df['clean_text'].values.tolist() + test_df['clean_text'].values.tolist()": 1,
      "train_comments": 1,
      "df_train['name'] + ' ' + df_train['item_description']": 1,
      "trainX1": 1,
      "train_data_corpus": 1,
      "train['Text'].values": 1,
      "train['item_description'].append(test['item_description'])": 1,
      "train_context": 1,
      "traintest['item_description']": 1,
      "train_data['ingredients']": 1,
      "dataframe['sentence']": 1,
      "list(partial_news['tokens'].map(lambda tokens: ' '.join(tokens)))": 1,
      "train['item_description'].apply(str)": 1,
      "X['excerpt']": 1,
      "wrk_df['comment_text_stopword_removed']": 1,
      "[' '.join(doc).lower() for doc in data.ingredients]": 1,
      "merge['description']": 1,
      "df_train.excerpt_1": 1,
      "train_1[txtcol].values": 1,
      "test_1[txtcol].values": 1,
      "model": 1,
      "alldata['Breed']": 1,
      "title": 1,
      "tr['excerpt']": 1,
      "tr_te.txt": 1,
      "X_train['text_lm']": 1,
      "df.title.apply(preprocess)": 1,
      "df.title": 1,
      "df.image_phash": 1,
      "list(train_df['mots_clefs']) + list(test_df['mots_clefs'])": 1,
      "merge.comment_text.values": 1,
      "train_set_stem": 1,
      "merged['item_description']": 1,
      "list(df_text)": 1,
      "X_train['Clean_Text']": 1,
      "predictors": 1,
      "test_predictors": 1,
      "train_df['comment_text'].values.tolist() + test_df['comment_text'].values.tolist()": 1,
      "X_valid": 1,
      "train_data[COMMENT]": 1,
      "ingredients": 1,
      "(str(x) for x in x_train)": 1,
      "train.text.values": 1,
      "x_raw": 1,
      "tqdm(full_text)": 1,
      "data_proc['selected_text'].values.astype('str')": 1,
      "data_proc['tratamento_3']": 1,
      "train[ESSAY1]": 1,
      "train[ESSAY2]": 1,
      "train[TITLE]": 1,
      "train[RESOURCES]": 1,
      "X_train['question_text_preprocessed'].values.astype(str)": 1,
      "dataprep_df['tidy_text']": 1,
      "submission_df['tidy_text']": 1,
      "final['CleanedText'].values": 1,
      "questions_all['question_tokens']": 1,
      "X_train_corrected": 1,
      "X_vect": 1,
      "data['comment_text'].tolist()": 1,
      "cleaned": 1,
      "trn.question_text": 1,
      "sub.question_text": 1,
      "pd.concat([trn.question_text, sub.question_text], axis=0)": 1,
      "train_text.to_list()": 1,
      "X_inp_clean": 1,
      "x_test": 1,
      "train['Address']": 1,
      "dataset['item_description']": 1,
      "df['ingredients']": 1,
      "sentences_train": 1,
      "test_df['text']": 1,
      "data['question_title']": 1,
      "data['question_body']": 1,
      "data['answer']": 1,
      "ingredients_train": 1,
      "df['ingredients'].apply(','.join)": 1,
      "data.total_text": 1,
      "train.Description.fillna('')": 1,
      "df['merge']": 1,
      "train_data[train_data.sentiment == 'positive']['text']": 1,
      "train_data[train_data.sentiment == 'negative']['text']": 1,
      "train_data[train_data.sentiment == 'neutral']['text']": 1,
      "df_dataclean_final['text_lemma']": 1,
      "df_dataclean_final['text_stem']": 1,
      "X_words": 1,
      "test_df['title']": 1,
      "training_recipes": 1,
      "df['txt_processed']": 1,
      "comment_text_all": 1,
      "questions.questions_body": 1,
      "pdesc['product_description']": 1,
      "xtrain['overview'].fillna('')": 1,
      "train_data['item_description']": 1,
      "df_file['text_data']": 1,
      "test['Text']": 1,
      "train['text_temp'].values": 1,
      "cleanq1s": 1,
      "cleanq2s": 1,
      "d_train.comment_text": 1,
      "train['ingredients_tfidf']": 1,
      "train_data['Phrase']": 1,
      "train_df[TEXT]": 1,
      "[''.join(i) for i in train['text']]": 1,
      "train_cl['comment_text']": 1,
      "X_train['description']": 1,
      "df_train['name']": 1,
      "merge_2['item_description']": 1,
      "tokenized_text": 1,
      "X_ref_train.loc[:, 'text']": 1,
      "train['comment_text'].values.astype('U').tolist()": 1,
      "qt": 1,
      "Txt": 1,
      "train.text.fillna(' ') + ' ' + train.sentiment": 1,
      "test['title'] + '. ' + test['content']": 1,
      "qa_pro.questions_title": 1,
      "sample['content']": 1,
      "train_desc.append(test_desc)": 1,
      "train_df[train_df.target == 1].question_text.values": 1,
      "train_df[train_df.target == 0].question_text.values": 1,
      "[train_df.question_text.sum()]": 1,
      "df_train['text'].values": 1,
      "train_X.values.tolist() + val_X.values.tolist() + test_X.values.tolist()": 1,
      "train_new['new_feat_lem']": 1,
      "newX": 1,
      "excerpts_train": 1,
      "corpus1": 1,
      "train.text_clean": 1,
      "train['question1'].astype(str) + train['question2'].astype(str)": 1,
      "processed_text": 1,
      "data.Text": 1,
      "train['preprocessed_name']": 1,
      "train['preprocessed_description']": 1,
      "train_data['question_text_cleaned'].tolist()": 1,
      "utter_list": 1,
      "X_train_lemm": 1,
      "train['ingredients_unrolled']": 1,
      "train['ingredients_unrolled_cleaned']": 1,
      "x_train['Title']": 1,
      "X.astype('U')": 1,
      "token_dict.values()": 1,
      "px": 1,
      "test_df.question_text.values": 1,
      "data['tidy_text']": 1,
      "combined_data['clean_text']": 1,
      "train['Ingredients']": 1,
      "total_duties": 1,
      "total_q_bow": 1,
      "test_df['excerpt_preprocessed']": 1,
      "x_trn": 1,
      "trainData['Phrase']": 1,
      "train['title']": 1,
      "sample.values": 1,
      "process_test_text": 1,
      "train.description": 1,
      "refined_train['tweet']": 1,
      "refined_test['tweet']": 1,
      "full_df['item_description']": 1,
      "test['title_no_sw']": 1,
      "nlp_test_data['text']": 1,
      "data_clean_tr['text'][0:5]": 1,
      "data_clean_tr['text_clean']": 1,
      "df_train['title']": 1,
      "df_train['description']": 1,
      "df_train['param_1_copy']": 1,
      "t": 1,
      "train.text_cleaned": 1,
      "list(xtrain) + list(xvalid)": 1,
      "items_1['item_name']": 1,
      "shops_1['shop_name']": 1,
      "test.text": 1,
      "rows": 1,
      "column": 1,
      "df[col].values": 1,
      "product_descriptions1['product_description']": 1,
      "word_train": 1,
      "data['text']": 1,
      "data['combined_text']": 1,
      "list_of_questions": 1,
      "trainData.clean_ingredients": 1,
      "x_train['item_description']": 1,
      "x_train['name']": 1,
      "X_TFIDF": 1,
      "all_text.text": 1,
      "train_df['text_cleaned']": 1,
      "train_df['text2']": 1,
      "df['clean_text']": 1,
      "train_data['keyword']": 1,
      "train_data['location']": 1,
      "train.token_des.values.tolist() + test.token_des.values.tolist()": 1,
      "train.token_name.values.tolist() + test.token_name.values.tolist()": 1,
      "arraytotext(train.ingredients_lem)": 1,
      "train_df.excerpt": 1,
      "train['ingredients_str']": 1,
      "doc_cleaned": 1,
      "reviews": 1,
      "df['Name'].astype('str')": 1,
      "prod_data": 1,
      "data_train['ingredients']": 1,
      "train_data['Text']": 1,
      "extended_train_data['Text']": 1,
      "train['clean_text']": 1,
      "test['clean_text']": 1,
      "dftrain['clean_text']": 1,
      "df_train['cleaned']": 1,
      "train_df['item_description'].apply(str)": 1,
      "test_df['item_description'].apply(str)": 1,
      "tweet": 1,
      "training": 1,
      "test": 1,
      "train_df['text'].values": 1,
      "full_data['item_description']": 1,
      "full_data['name']": 1,
      "question_list": 1,
      "sequence[:train_size]": 1,
      "tweet_train['text']": 1,
      "tweet_test['text']": 1,
      "df.ingredients": 1,
      "q1_list": 1,
      "q2_list": 1,
      "train_df['text'][0:5]": 1,
      "c_df.excerpt[:-7]": 1,
      "X_trainval['clean_text']": 1,
      "x_train['ingredients']": 1,
      "sentiment_sentences": 1,
      "df_sample.comment_text": 1,
      "combi['tidy_text']": 1,
      "df['cleanedText']": 1,
      "test['comment_text']": 1,
      "xx": 1,
      "train_df['special_char_cleaned_text']": 1,
      "X_train['excerpt']": 1,
      "merge_questions": 1,
      "arraytotext(train['ingredients'])": 1,
      "train_X.values": 1,
      "cleaned_train_reviews": 1,
      "Combined_data['item_description']": 1,
      "train['question_text'].values.astype('U')": 1,
      "tokens_colloc_train": 1,
      "df['clean_question_text']": 1,
      "train_raw.excerpt": 1,
      "merged['Description'].fillna('NaN').values": 1,
      "train_['text']": 1,
      "fast_resp": 1,
      "slow_resp": 1,
      "qa_cbr['questions_body']": 1,
      "g_q_sample['questions_body']": 1,
      "non_nan_list": 1,
      "data['item_description']": 1,
      "X_text_char[c]": 1,
      "X_train['description'].append(X_test['description'])": 1,
      "clean_movie_train['review']": 1,
      "clean_toxic_train['comment_text']": 1,
      "XL1": 1,
      "train_df[col]": 1,
      "train_df.item_description": 1,
      "ques": 1,
      "train['clean']": 1,
      "dev_all_tokens": 1,
      "comment_df[:train_n]['stemmed_comment']": 1,
      "train_corpus": 1,
      "train[col].astype(str)": 1,
      "train_df['project_descp']": 1,
      "train_doc": 1,
      "list(X_train)": 1,
      "data.question_text.fillna('')": 1,
      "train_org['question_text'].values.tolist()": 1,
      "train_cleaned['comment_text']": 1
    },
    "sklearn.feature_extraction.text.TfidfVectorizer.transform.raw_documents": {
      "test_text": 115,
      "X_test": 113,
      "train_text": 108,
      "X_train": 68,
      "traindata": 45,
      "testdata": 45,
      "[str(x)]": 36,
      "test[COMMENT]": 34,
      "train_desc": 32,
      "test_desc": 32,
      "test['text']": 30,
      "xtrain": 28,
      "test['Phrase']": 27,
      "xvalid": 25,
      "x_test": 23,
      "corpusts": 23,
      "test['comment_text']": 21,
      "X_val": 19,
      "txt": 19,
      "train['Phrase']": 18,
      "test_df['text']": 17,
      "clean_corpus.iloc[:train.shape[0]]": 17,
      "clean_corpus.iloc[train.shape[0]:]": 17,
      "test_X": 12,
      "test_data": 12,
      "x_train": 12,
      "test['question_text']": 11,
      "corpus": 11,
      "train_df['text'].values.tolist()": 11,
      "train_df['title'].values.tolist()": 11,
      "test_df['title'].values.tolist()": 11,
      "train_df['description'].values.tolist()": 11,
      "test_df['description'].values.tolist()": 11,
      "txt1": 10,
      "df2_s[1]": 10,
      "test['item_description']": 10,
      "test_df['text'].values.tolist()": 10,
      "df_test['text']": 10,
      "X_test['text']": 10,
      "train_x": 9,
      "test_df['TEXT']": 8,
      "test.Phrase": 8,
      "test": 8,
      "group.text": 8,
      "train['Description'].fillna('')": 8,
      "test_df['comment_text']": 8,
      "s_data": 8,
      "t_data": 8,
      "test['question_title'].values": 8,
      "test['question_body'].values": 8,
      "test['answer'].values": 8,
      "cv_df['TEXT']": 7,
      "x_valid": 7,
      "[question]": 7,
      "X_test.values": 7,
      "test.question_text": 6,
      "preds_df['title_x']": 6,
      "preds_df['title_y']": 6,
      "test_corpus": 6,
      "orig_test2": 6,
      "test['content']": 6,
      "test_x": 6,
      "text": 6,
      "sentences": 6,
      "train['review']": 6,
      "test['review']": 6,
      "X": 6,
      "test_data['comment_text']": 6,
      "corpus_test": 6,
      "test_data['text']": 6,
      "test['clean_text']": 6,
      "df_test['Phrase']": 6,
      "xTrain": 6,
      "xValid": 6,
      "train_texts[col].fillna('')": 5,
      "test_texts[col].fillna('')": 5,
      "test_df['ingredients']": 5,
      "[simple_prepro_tfidf(l) for l in tqdm.tqdm(test['question_title'].values)]": 5,
      "[simple_prepro_tfidf(l) for l in tqdm.tqdm(test['question_body'].values)]": 5,
      "[simple_prepro_tfidf(l) for l in tqdm.tqdm(test['answer'].values)]": 5,
      "test_df['question_text']": 5,
      "X_test.values.astype('U')": 5,
      "[t]": 5,
      "test.clean": 5,
      "test_df['Variation']": 5,
      "df_features.question1.tolist()": 5,
      "df_features.question2.tolist()": 5,
      "df_train.description": 5,
      "df_test.description": 5,
      "train_text_1": 4,
      "test_text_1": 4,
      "train_text_2": 4,
      "test_text_2": 4,
      "train_text_3": 4,
      "test_text_3": 4,
      "holdout_text": 4,
      "x_test['question']": 4,
      "train.Phrase": 4,
      "train_df['question_text'].values.tolist()": 4,
      "test_df['question_text'].values.tolist()": 4,
      "train['item_description'].values.tolist()": 4,
      "X_train.head(5)": 4,
      "train['text']": 4,
      "premise_test + ' ' + hypothesis_test": 4,
      "train['comment_text']": 4,
      "test.text": 4,
      "texts": 4,
      "train_texts": 4,
      "test_texts": 4,
      "test_data['Text']": 4,
      "train['question_text']": 4,
      "df_test.clean_review": 4,
      "train_df['description']": 4,
      "data": 4,
      "X_cora_test['stemming_question_for_tfidf']": 4,
      "test_df.question_text": 4,
      "test.comment_text": 4,
      "df_sub.name": 4,
      "df_sub.item_description": 4,
      "X_train['text']": 4,
      "X_train['text'].values.tolist()": 4,
      "X_test['text'].values.tolist()": 4,
      "validation_X_": 4,
      "test_comments": 4,
      "all_text[traindex]": 4,
      "all_text[tesdex]": 4,
      "test_df['Gene']": 4,
      "cv_df['Variation']": 4,
      "test_text.values": 4,
      "test['final_desc']": 4,
      "test_df['excerpt']": 4,
      "X_val.values.astype('U')": 4,
      "df_val.description": 4,
      "x": 3,
      "test_data['question_title'].values": 3,
      "test_data['question_body'].values": 3,
      "test_data['answer'].values": 3,
      "X_valid": 3,
      "cur_test['text_temp'].values": 3,
      "test['ingredients']": 3,
      "[query]": 3,
      "[test.iloc[index]['text']]": 3,
      "nlp_corpus": 3,
      "nlp_text": 3,
      "x_corpus_test": 3,
      "train_df['seperated_ingredients'].values": 3,
      "test_df['seperated_ingredients'].values": 3,
      "features_test": 3,
      "X_all": 3,
      "valid_x": 3,
      "test['Description']": 3,
      "X_test['question']": 3,
      "x_val": 3,
      "test_data.comment_text": 3,
      "df_test['question_text']": 3,
      "train[COMMENT]": 3,
      "shuffled_train['text']": 3,
      "testTxt": 3,
      "train.comment_text": 3,
      "X_test['stemming_text_for_tfidf_test']": 3,
      "test_X.values.astype('U')": 3,
      "X_train['preprocessed_question_text'].values": 3,
      "X_test['preprocessed_question_text'].values": 3,
      "X_val['preprocessed_question_text'].values": 3,
      "X_val['text']": 3,
      "test_as_text": 3,
      "train_comment_text": 3,
      "test_comment_text": 3,
      "train_df['param123'].values.tolist()": 3,
      "test_df['param123'].values.tolist()": 3,
      "df.title": 3,
      "df_test['item_description']": 3,
      "test_data['item_description']": 3,
      "Corpus2": 3,
      "train_comments": 3,
      "corpus1": 3,
      "cv_df['Gene']": 3,
      "xtest": 3,
      "tokenized_tweet": 3,
      "train_df['question_text']": 3,
      "clit_df.excerpt": 3,
      "merge['item_description'][nrow_valid:]": 3,
      "X_test.tolist()": 2,
      "x_test_text": 2,
      "df.comment_text": 2,
      "train_tokens": 2,
      "test_tokens": 2,
      "train_corpus": 2,
      "test['item_description'].values.tolist()": 2,
      "test_comment": 2,
      "train['project_subject_categories']": 2,
      "test['project_subject_categories']": 2,
      "train['project_subject_subcategories']": 2,
      "test['project_subject_subcategories']": 2,
      "train['project_title']": 2,
      "test['project_title']": 2,
      "train['project_resource_summary']": 2,
      "test['project_resource_summary']": 2,
      "train['project_essay_1']": 2,
      "test['project_essay_1']": 2,
      "train['project_essay_2']": 2,
      "test['project_essay_2']": 2,
      "train['question_text_final']": 2,
      "test['question_text_final']": 2,
      "test.cleaned_phrase": 2,
      "x1": 2,
      "clean_test_reviews": 2,
      "df['text']": 2,
      "X_test['question_title'].values": 2,
      "X_test['question_body'].values": 2,
      "X_test['answer'].values": 2,
      "X_TXT[:len_train]['Description']": 2,
      "X_TXT[len_train:]['Description']": 2,
      "X_TXT[:len_train]['metadata_annots_top_desc']": 2,
      "X_TXT[len_train:]['metadata_annots_top_desc']": 2,
      "X_TXT[:len_train]['sentiment_entities']": 2,
      "X_TXT[len_train:]['sentiment_entities']": 2,
      "val_texts": 2,
      "(' '.join(i) for i in train_sentences)": 2,
      "(' '.join(i) for i in test_sentences)": 2,
      "test_df2['text']": 2,
      "test_ingredients_text": 2,
      "training_examples['project_subject_categories']": 2,
      "validation_examples['project_subject_categories']": 2,
      "test_examples['project_subject_categories']": 2,
      "training_examples['project_subject_subcategories']": 2,
      "validation_examples['project_subject_subcategories']": 2,
      "test_examples['project_subject_subcategories']": 2,
      "training_examples['project_title']": 2,
      "validation_examples['project_title']": 2,
      "test_examples['project_title']": 2,
      "training_examples['project_resource_summary']": 2,
      "validation_examples['project_resource_summary']": 2,
      "test_examples['project_resource_summary']": 2,
      "training_examples['project_essay_1']": 2,
      "validation_examples['project_essay_1']": 2,
      "test_examples['project_essay_1']": 2,
      "training_examples['project_essay_2']": 2,
      "validation_examples['project_essay_2']": 2,
      "test_examples['project_essay_2']": 2,
      "result_df.caption_1": 2,
      "test_result_df.caption_1": 2,
      "list_sentences_train": 2,
      "list_sentences_test": 2,
      "trainText2": 2,
      "train_data['Description']": 2,
      "test_data['Description']": 2,
      "train_data.comment_text": 2,
      "x_valid['normalized_text']": 2,
      "test['normalized_text']": 2,
      "train_explore_clean['comment_no_stop']": 2,
      "test['comment_no_stop']": 2,
      "trainjoin1": 2,
      "testjoin1": 2,
      "trainjoin2": 2,
      "testjoin2": 2,
      "test_docs": 2,
      "test_data['clean_text']": 2,
      "val[COMMENT]": 2,
      "test_val_lang": 2,
      "test_data['excerpt']": 2,
      "df_train.clean_review": 2,
      "phrase_test": 2,
      "test_df['item_description']": 2,
      "X_pred_ls": 2,
      "test_df[col]": 2,
      "df": 2,
      "Xtest": 2,
      "X_cora_test['lemmatize_question_for_tfidf']": 2,
      "X_cora_test": 2,
      "X_test['lemmatize_text_for_tfidf_test']": 2,
      "train_data['comment']": 2,
      "test_data['comment']": 2,
      "X_train['question_text']": 2,
      "X_test['question_text']": 2,
      "[str(q1)]": 2,
      "[str(q2)]": 2,
      "test['excerpt']": 2,
      "ttextx_test.title": 2,
      "test.normalized": 2,
      "data['text']": 2,
      "train_data['ingredientTextClean']": 2,
      "test_data['ingredientTextClean']": 2,
      "foodTest['ingredientTextClean']": 2,
      "X_cv['item_description']": 2,
      "X_cv['name']": 2,
      "clean_test_data['Phrase']": 2,
      "test['x'].values": 2,
      "train_data": 2,
      "val['question_text']": 2,
      "X_test['question_with_more_wt_title']": 2,
      "train_X": 2,
      "train[col_name]": 2,
      "test[col_name]": 2,
      "docs": 2,
      "test_f['Phrase']": 2,
      "train_data['item_description']": 2,
      "validation_data['item_description']": 2,
      "X_train.values": 2,
      "train_df['item_description'].values.tolist()": 2,
      "test_df['item_description'].values.tolist()": 2,
      "train_df['name'].values.tolist()": 2,
      "test_df['name'].values.tolist()": 2,
      "test['text_clean']": 2,
      "df_test['ingredients']": 2,
      "y['separated_ing_lemma']": 2,
      "train": 2,
      "test_text1": 2,
      "test_text2": 2,
      "test.clean_text": 2,
      "lebeldesc_texts": 2,
      "test_df.text": 2,
      "train['Phrase'].values": 2,
      "test['Phrase'].values": 2,
      "train['Description']": 2,
      "train[c]": 2,
      "test[c]": 2,
      "[document]": 2,
      "[answer]": 2,
      "test.comment_text.values": 2,
      "X_test['comment_text']": 2,
      "df_features.interseq.tolist()": 2,
      "df_features.diffseq.tolist()": 2,
      "x_test['text']": 2,
      "train_data['ciphertext']": 2,
      "test_data['ciphertext']": 2,
      "train['Phrase_Clean']": 2,
      "test['Phrase_Clean']": 2,
      "test_result['comment_text']": 2,
      "np.array([clean])": 2,
      "df['question_text']": 2,
      "valx_preprocess": 2,
      "preprocessed_test": 2,
      "train_df['excerpt']": 2,
      "train.title": 2,
      "[text]": 2,
      "df_test['title']": 2,
      "clean_corpus": 2,
      "article_text": 2,
      "title_text": 2,
      "resource_text": 2,
      "cv_df['comment_text'].values.astype('U')": 2,
      "df_test['comment_text'].values.astype('U')": 2,
      "validation['clean_comment']": 2,
      "submission['clean_comment']": 2,
      "texts_test": 2,
      "cs_df.Desc": 2,
      "df_upsampled['clean_review']": 2,
      "test['clean_review']": 2,
      "df_test['translated']": 2,
      "q": 2,
      "self.train.question_text": 2,
      "self.test.question_text": 2,
      "ts_col": 2,
      "test_examples.question_text.values": 2,
      "Xtest['ciphertext']": 1,
      "test_diff['ciphertext']": 1,
      "df_train['question_text'].values.tolist()": 1,
      "df_test['question_text'].values.tolist()": 1,
      "test_list": 1,
      "test['ingredient_sent']": 1,
      "json_ingredients_cleaned_test": 1,
      "X_valid.question_text": 1,
      "train_x.text": 1,
      "test_x.text": 1,
      "test['question_title']": 1,
      "df_train['joined_ing'].values.tolist()": 1,
      "df_test['joined_ing'].values.tolist()": 1,
      "test['Concatenated']": 1,
      "test_data_without_id['ingredients']": 1,
      "test['ciphertext']": 1,
      "test_df['clean_question_text']": 1,
      "self.ground_truth[self.col]": 1,
      "names_to_match[self.col]": 1,
      "test_texts.question_title": 1,
      "test_texts.question_body": 1,
      "test_texts.answer": 1,
      "x_train_text": 1,
      "clean_text[:len(train)]": 1,
      "clean_text[len(train):]": 1,
      "val_set['text'].values": 1,
      "test_df['text'].values": 1,
      "preprocessed_reviews": 1,
      "list(sentences_test)": 1,
      "questions[c]": 1,
      "feature": 1,
      "df_all[c]": 1,
      "['i hate being hateful']": 1,
      "diff_test1['ciphertext']": 1,
      "diff_test2['ciphertext']": 1,
      "diff_test3['ciphertext']": 1,
      "diff_test4['ciphertext']": 1,
      "test_diff1['ciphertext']": 1,
      "test_diff2['ciphertext']": 1,
      "test_diff3['ciphertext']": 1,
      "test_diff4['ciphertext']": 1,
      "test_data.excerpt": 1,
      "X_submission": 1,
      "test['cleaned']": 1,
      "train_cleaned.sample(1, random_state=1)": 1,
      "test_documents": 1,
      "testxt": 1,
      "train.question_text": 1,
      "features_train.text.values": 1,
      "features_test.text.values": 1,
      "test_file.text.values": 1,
      "test[TEXT]": 1,
      "test_clean": 1,
      "preprocessed_essays_x_train": 1,
      "preprocessed_essays_x_cv": 1,
      "preprocessed_essays_test": 1,
      "preprocessed_title_x_train": 1,
      "preprocessed_title_x_cv": 1,
      "preprocessed_title_test": 1,
      "train_df['question_body']": 1,
      "valid_df['question_body']": 1,
      "test['question_body']": 1,
      "train_df['answer']": 1,
      "valid_df['answer']": 1,
      "test['answer']": 1,
      "train['title']": 1,
      "test['title']": 1,
      "test[test.lang_abv == lan].premise": 1,
      "test[test.lang_abv == lan].hypothesis": 1,
      "X_text[col]": 1,
      "train['question_text'].values.tolist()": 1,
      "test['question_text'].values.tolist()": 1,
      "valid['name'].values": 1,
      "valid['text'].values": 1,
      "test['name'].values": 1,
      "test['text'].values": 1,
      "cv_df['preprocessed_name'].values": 1,
      "test['preprocessed_name'].values": 1,
      "cv_df['preprocessed_description'].values": 1,
      "test['preprocessed_description'].values": 1,
      "X_test.ciphertext": 1,
      "train['seperated_ingredients'].values": 1,
      "test['seperated_ingredients'].values": 1,
      "train_x['question_text'].fillna('na_').values": 1,
      "valid_x['question_text'].fillna('na_').values": 1,
      "test_x['question_text'].fillna('na_').values": 1,
      "test_df[comment]": 1,
      "train.question1[:10]": 1,
      "train.question2[:10]": 1,
      "df_train.text": 1,
      "tx": 1,
      "df_test['text'].values": 1,
      "clean_train_reviews": 1,
      "test['textStemm']": 1,
      "arraytotext(test.ingredients)": 1,
      "b.values": 1,
      "tests": 1,
      "train_orig['question1']": 1,
      "train_orig['question2']": 1,
      "test_orig['question1']": 1,
      "test_orig['question2']": 1,
      "df1['text']": 1,
      "np.array(testx)": 1,
      "train_ingredients_text": 1,
      "crossvalidation": 1,
      "predicting": 1,
      "X_train['comment_text']": 1,
      "X_val['comment_text']": 1,
      "Train['project_subject_categories']": 1,
      "Test['project_subject_categories']": 1,
      "Train['project_subject_subcategories']": 1,
      "Test['project_subject_subcategories']": 1,
      "Train['project_title']": 1,
      "Test['project_title']": 1,
      "Train['project_resource_summary']": 1,
      "Test['project_resource_summary']": 1,
      "Train['project_essay_1']": 1,
      "Test['project_essay_1']": 1,
      "Train['project_essay_2']": 1,
      "Test['project_essay_2']": 1,
      "train_df['clean_comment']": 1,
      "test_df['clean_comment']": 1,
      "result_df.caption_2": 1,
      "result_df.caption_3": 1,
      "result_df.caption_4": 1,
      "test_result_df.caption_2": 1,
      "test_result_df.caption_3": 1,
      "test_result_df.caption_4": 1,
      "final_test": 1,
      "test.excerpt.values": 1,
      "test_processed_text": 1,
      "nlp_items_corpus": 1,
      "nlp_new_item_corpus": 1,
      "X_test['question_with_title']": 1,
      "train_df['text_clean']": 1,
      "test_df['text_clean']": 1,
      "X_test.apply(lambda x: ' '.join(x))": 1,
      "test['text'].apply(lambda x: ' '.join(x))": 1,
      "x_test_b": 1,
      "test['new_text2']": 1,
      "test_sequence": 1,
      "train_data['concat_text']": 1,
      "test_data['concat_text']": 1,
      "data_te['Description'].fillna('null').tolist()": 1,
      "join_data_all[n_tr:]": 1,
      "meta_desc_all[n_tr:].fillna('nan')": 1,
      "identity_hate_only": 1,
      "x_test.astype('U')": 1,
      "dataset['text']": 1,
      "[words_excerpt]": 1,
      "test['text'].tolist()": 1,
      "df['description']": 1,
      "x_val['text']": 1,
      "[submission_texts[i] for i in train.index]": 1,
      "[submission_texts[i] for i in test.index]": 1,
      "train_docs": 1,
      "sample.excerpt": 1,
      "train.excerpt": 1,
      "test['question_text'].values": 1,
      "[tweet]": 1,
      "[tweet_2]": 1,
      "val_df['question_text']": 1,
      "df_test['clean_excerpt']": 1,
      "X_train['essay'].values": 1,
      "X_cv['essay'].values": 1,
      "X_test['essay'].values": 1,
      "train_v[COMMENT]": 1,
      "test_non_val_lang": 1,
      "testing_dataset['question_text']": 1,
      "xcv['Variation']": 1,
      "resulttest['Variation']": 1,
      "xcv['Gene']": 1,
      "resulttest['Gene']": 1,
      "xcv['TEXT']": 1,
      "resulttest['TEXT']": 1,
      "clean_question_test": 1,
      "testv['text']": 1,
      "train['question_text_lemma']": 1,
      "test['question_text_lemma']": 1,
      "train['ingredients']": 1,
      "test.filtered_text": 1,
      "test.iloc[:, 2]": 1,
      "combined_sample['item_description'].values": 1,
      "df_test['text'].tolist()": 1,
      "test_rest['new_name']": 1,
      "test_rest['item_description']": 1,
      "test_rest['category_name']": 1,
      "testrest_cat['name']": 1,
      "testrest_cat['item_description']": 1,
      "train.text": 1,
      "test.excerpt": 1,
      "X_pred": 1,
      "train_df[col]": 1,
      "evalu['clean_text'].astype(str)": 1,
      "test_question_text": 1,
      "test_answer_text": 1,
      "allIngredientsTextInTest": 1,
      "dfX_test.values": 1,
      "preprocessed_data['question_with_more_wt_title']": 1,
      "df_test.overview": 1,
      "df_total.overview": 1,
      "df_test.tagline": 1,
      "df_total.tagline": 1,
      "comment": 1,
      "test_x1": 1,
      "df1['ingredients1'].values": 1,
      "df2['ingredients2'].values": 1,
      "train.project_essay": 1,
      "test.project_essay": 1,
      "X_cora_test_": 1,
      "sub_df['stemming_question_for_tfidf']": 1,
      "test_tweet['text']": 1,
      "full_data[c]": 1,
      "X[:, 1]": 1,
      "X[:, 0]": 1,
      "lst": 1,
      "[QuesBody]": 1,
      "tags": 1,
      "out": 1,
      "clean_text(test.comment_text)": 1,
      "q_AboutMe_text": 1,
      "a_AboutMe_text": 1,
      "test['q_AboutMe'].apply(normalize)": 1,
      "test['a_AboutMe'].apply(normalize)": 1,
      "test1['text']": 1,
      "[ingredients]": 1,
      "test[f]": 1,
      "train_df['Description'].astype('U').values.tolist()": 1,
      "test_df['Description'].astype('U').values.tolist()": 1,
      "test_set['text']": 1,
      "input2['question_text']": 1,
      "[q_p]": 1,
      "data_test": 1,
      "profs['info']": 1,
      "tweets1": 1,
      "test_set.ingredients": 1,
      "test_orig.cast_crew.fillna('')": 1,
      "test_orig.production_companies.fillna('')": 1,
      "test_orig.production_countries.fillna('')": 1,
      "test_orig.belongs_to_collection.fillna('')": 1,
      "test_orig.genres.fillna('')": 1,
      "test_orig.Keywords_tagline_overview.fillna('')": 1,
      "df_test['cleaned_text']": 1,
      "cv_df['comment_text']": 1,
      "['Has the United States become the largest dictatorship in the world']": 1,
      "fulldf['Description']": 1,
      "train['ingredients'].apply(','.join)": 1,
      "test['ingredients'].apply(','.join)": 1,
      "train[key].apply(str)": 1,
      "test[key].apply(str)": 1,
      "X_valid['text']": 1,
      "preds_corpus": 1,
      "corpus_validation": 1,
      "test.ingredients": 1,
      "train_data.url": 1,
      "validation_data.url": 1,
      "test_data.url": 1,
      "df_test['item_description'].astype(str).apply(lambda x: x.replace('No description yet', ''))": 1,
      "t_tweets": 1,
      "test1": 1,
      "X_e.excerpt": 1,
      "test2.excerpt": 1,
      "test_df.text.values": 1,
      "X_crossval": 1,
      "train.question1": 1,
      "train.question2": 1,
      "raw_data.comment_text": 1,
      "X_train['hashtags']": 1,
      "X_val['hashtags']": 1,
      "test['hashtags']": 1,
      "[query_text]": 1,
      "self.words_tr": 1,
      "self.words_tst": 1,
      "testdf['text']": 1,
      "X_test_text": 1,
      "x_j": 1,
      "x_j_sub": 1,
      "test_ingredients_list": 1,
      "x_test_comments_pre": 1,
      "self.get_alphanum_seqs(X)": 1,
      "X_train['item_description']": 1,
      "data_test['item_description']": 1,
      "X_train['name']": 1,
      "data_test['name']": 1,
      "test_features['item_description']": 1,
      "test_resources['subjects']": 1,
      "test_resources['essays']": 1,
      "train_df['clean_text'].values.tolist()": 1,
      "test_df['clean_text'].values.tolist()": 1,
      "train_df['clean_text']": 1,
      "test_df['clean_text']": 1,
      "testX1": 1,
      "test_data_corpus": 1,
      "df.text": 1,
      "df_test.text": 1,
      "test['Text'].values": 1,
      "train_2['geoNetwork.networkDomain']": 1,
      "score_2['geoNetwork.networkDomain']": 1,
      "test_context": 1,
      "desc": 1,
      "train_data_clean": 1,
      "test_data_clean": 1,
      "test_data['ingredients']": 1,
      "test_dataframe['sentence']": 1,
      "train_df['token_text']": 1,
      "test_df['token_text']": 1,
      "test_df['comment_text_stopword_removed']": 1,
      "[' '.join(doc).lower() for doc in test.ingredients]": 1,
      "df_test.excerpt_1": 1,
      "model_new": 1,
      "test.clean_review": 1,
      "df_train['seperated_ingredients'].values": 1,
      "df_test['seperated_ingredients'].values": 1,
      "X_predict": 1,
      "te['excerpt']": 1,
      "reviews": 1,
      "reviewsT": 1,
      "x2": 1,
      "train_keyword": 1,
      "train_location": 1,
      "test_keyword": 1,
      "test_location": 1,
      "X_test['text_lm']": 1,
      "df_sub['text_lm']": 1,
      "test_set_stem": 1,
      "Corpus3": 1,
      "train['labelAnnotations_des'].fillna('NULL')": 1,
      "test['labelAnnotations_des'].fillna('NULL')": 1,
      "X_test['Clean_Text']": 1,
      "X_new['Clean_Text']": 1,
      "train_df['comment_text'].values.tolist()": 1,
      "test_df['comment_text'].values.tolist()": 1,
      "df.text.values": 1,
      "test_data[COMMENT]": 1,
      "test_ingredients": 1,
      "(str(x) for x in x_test)": 1,
      "(str(x) for x in test['comment_text'].values)": 1,
      "train_text[text_column]": 1,
      "test_text[text_column]": 1,
      "train['product_title']": 1,
      "train['search_term']": 1,
      "train['product_description']": 1,
      "test['product_title']": 1,
      "test['search_term']": 1,
      "test['product_description']": 1,
      "test.text.values": 1,
      "x_raw_t": 1,
      "train_v1": 1,
      "test_v1": 1,
      "train_v2": 1,
      "test_v2": 1,
      "test[ESSAY1]": 1,
      "test[ESSAY2]": 1,
      "test[TITLE]": 1,
      "test[RESOURCES]": 1,
      "comments": 1,
      "X_cv['question_text_preprocessed'].values.astype(str)": 1,
      "quora_test['question_text_preprocessed'].values.astype(str)": 1,
      "train_df['text']": 1,
      "submission['excerpt_cleaned']": 1,
      "train_df['questions_title_and_body']": 1,
      "test_df['questions_title_and_body']": 1,
      "X_test_corrected": 1,
      "test_corrected": 1,
      "train_df.cleaned_text.values": 1,
      "list(train_data['prep_text'])": 1,
      "list(test_data['text'])": 1,
      "valid_data": 1,
      "test['Cleaned_text']": 1,
      "test['Address']": 1,
      "df1.text": 1,
      "train.preprocessed_question_text.values": 1,
      "test.preprocessed_question_text.values": 1,
      "train['clean_text']": 1,
      "sentences_test": 1,
      "cleaned_texts": 1,
      "test_data['text'].values": 1,
      "f_train.text": 1,
      "f_val.text": 1,
      "data_clean_test['text_clean']": 1,
      "x_train['text']": 1,
      "x_valid['text']": 1,
      "ingredients_test": 1,
      "datasets[1]['pos_tag_sentence']": 1,
      "df_train.review.values": 1,
      "df_valid.review.values": 1,
      "train_df['comment_text']": 1,
      "train_df[TEXTCOL]": 1,
      "test_df[TEXTCOL]": 1,
      "df.iloc[0:trainlen, :]['Phrase']": 1,
      "df.iloc[trainlen:, :]['Phrase']": 1,
      "train['name_and_breeds']": 1,
      "test['name_and_breeds']": 1,
      "test.Description.fillna('')": 1,
      "test['csen'].values": 1,
      "X_test_subm_words": 1,
      "testing_recipes": 1,
      "fullSent['Phrase']": 1,
      "list(x_train.text)": 1,
      "list(x_val.text)": 1,
      "train['text_cleaned']": 1,
      "test['text_cleaned']": 1,
      "test['text_temp'].values": 1,
      "df_train.question_text": 1,
      "df_test.question_text": 1,
      "test_data.question_text": 1,
      "d_test.comment_text": 1,
      "test['ingredients_tfidf']": 1,
      "merged_training_df['Text'].values": 1,
      "merged_test_df['Text'].values": 1,
      "test_df['description']": 1,
      "train_df['title']": 1,
      "test_df['title']": 1,
      "pd.concat([train_df['description'], test_df['description']])": 1,
      "pd.concat([train_df['title'], test_df['title']])": 1,
      "train[phrase_col_name]": 1,
      "train_text_phrases": 1,
      "test_text_phrases": 1,
      "[input_text]": 1,
      "train_df[TEXT]": 1,
      "test_df[TEXT]": 1,
      "test.excerpt_clean": 1,
      "[''.join(i) for i in test['text']]": 1,
      "train_df['concat_ingredients']": 1,
      "test_df['concat_ingredients']": 1,
      "X_valid['description']": 1,
      "X_test['description']": 1,
      "df_test['name']": 1,
      "tokenized_text": 1,
      "X_ref_test.loc[:, 'text']": 1,
      "working_df_test.loc[:, 'text']": 1,
      "df_feaT.q13g.tolist()": 1,
      "df_feaT.q23g.tolist()": 1,
      "df_feaT.inte.tolist()": 1,
      "df_feaT.diffe.tolist()": 1,
      "df_feaT.q1di.tolist()": 1,
      "df_feaT.q2di.tolist()": 1,
      "pro_title.questions_title": 1,
      "txt.q": 1,
      "df_features.q1d.tolist()": 1,
      "df_features.q2d.tolist()": 1,
      "Corpus": 1,
      "df_test.text.values": 1,
      "train_X.values.tolist()": 1,
      "val_X.values.tolist()": 1,
      "test_X.values.tolist()": 1,
      "train_df['premise'].tolist()": 1,
      "test_df['premise'].tolist()": 1,
      "train_df['hypothesis'].tolist()": 1,
      "test_df['hypothesis'].tolist()": 1,
      "excerpts_val": 1,
      "test_excerpts": 1,
      "test.text_clean": 1,
      "test['question1'].astype(str) + test['question2'].astype(str)": 1,
      "X_train[name].values": 1,
      "X_test[name].values": 1,
      "df['Phrase']": 1,
      "train_features_engineered['project_title']": 1,
      "train_features_engineered['project_essay']": 1,
      "train_features_engineered['item_type']": 1,
      "train_features_engineered['project_cat']": 1,
      "test_features_engineered['project_title']": 1,
      "test_features_engineered['project_essay']": 1,
      "test_features_engineered['item_type']": 1,
      "test_features_engineered['project_cat']": 1,
      "train_data['comment_text']": 1,
      "traindata['ingredients']": 1,
      "pd.Series(testingredientlist)": 1,
      "train['question1']": 1,
      "train['question2']": 1,
      "test['question1']": 1,
      "test['question2']": 1,
      "test['preprocessed_name']": 1,
      "test['preprocessed_description']": 1,
      "corpus_submission": 1,
      "test_tweet": 1,
      "df.name": 1,
      "df1.name": 1,
      "df2.name": 1,
      "df.item_description": 1,
      "df1.item_description": 1,
      "df2.item_description": 1,
      "df1": 1,
      "df2": 1,
      "X_test_lemm": 1,
      "test['ingredients_unrolled_cleaned']": 1,
      "x_test['Title']": 1,
      "test_df.astype('U')": 1,
      "self.training_data['text']": 1,
      "self.test_data['text']": 1,
      "data['description']": 1,
      "data['title']": 1,
      "test['Ingredients']": 1,
      "train1['total_text']": 1,
      "test1['total_text']": 1,
      "q_total": 1,
      "q_query": 1,
      "items_train": 1,
      "items_test": 1,
      "x_tst": 1,
      "df_train['preprocess_text']": 1,
      "df_test['preprocess_text']": 1,
      "sample.values": 1,
      "dtrain['product_title'].fillna('')": 1,
      "dtest['product_title'].fillna('')": 1,
      "dtrain['product_description'].fillna('')": 1,
      "dtest['product_description'].fillna('')": 1,
      "dtrain['search_term'].fillna('')": 1,
      "dtest['search_term'].fillna('')": 1,
      "df_train_key_grpd.keyword": 1,
      "df_test_key_grpd.keyword": 1,
      "text_data": 1,
      "[str(i) for i in features]": 1,
      "[str(i) for i in test_features]": 1,
      "tX": 1,
      "test['processed1']": 1,
      "df_tests['text'].values": 1,
      "df_test['comment_text']": 1,
      "test['lemmatized']": 1,
      "data_clean_ts['text_clean']": 1,
      "df_test['description']": 1,
      "df_test['param_1_copy']": 1,
      "data.question1": 1,
      "data.question2": 1,
      "list(df_test.text.values)": 1,
      "xcvalid": 1,
      "test_data.text": 1,
      "X_test_data": 1,
      "val": 1,
      "my_final_submission.text.values": 1,
      "sub.excerpt": 1,
      "list(pd.DataFrame(train_data.text).append(pd.DataFrame(test_data.text), ignore_index=True).text)[:100]": 1,
      "[x]": 1,
      "[product]": 1,
      "word_test": 1,
      "train_df[textcol].values": 1,
      "test_df[textcol].values": 1,
      "testData.clean_ingredients": 1,
      "x_cv['item_description']": 1,
      "x_cv['name']": 1,
      "test_data['name']": 1,
      "X_TEST_TFIDF": 1,
      "datatrain['Cleaned_tweet']": 1,
      "datatest['Cleaned_tweet']": 1,
      "data['question_text']": 1,
      "test_df['text_cleaned']": 1,
      "test_df['text2']": 1,
      "train['cleaned'].values": 1,
      "test['cleaned'].values": 1,
      "project[c]": 1,
      "df_train[df_train['dataset_title'] == category].json_text.apply(clean_text)": 1,
      "df_train.json_text.apply(clean_text)": 1,
      "df_submission.json_text.apply(clean_text)": 1,
      "test_data['keyword']": 1,
      "test_data['location']": 1,
      "train['token_des'].values.tolist()": 1,
      "test['token_des'].values.tolist()": 1,
      "train['token_name'].values.tolist()": 1,
      "test['token_name'].values.tolist()": 1,
      "validate_x": 1,
      "X_cv_train": 1,
      "X_cv_test": 1,
      "arraytotext(test.ingredients_lem)": 1,
      "train_df['Text'].values": 1,
      "test_df['Text'].values": 1,
      "test['ingredients_str']": 1,
      "test_data['review']": 1,
      "my_data2['review'].values.astype('U')": 1,
      "list(X_test['question1'] + X_test['question2'])": 1,
      "train_df['text_final']": 1,
      "test_df['text_final']": 1,
      "prod_data": 1,
      "query_data": 1,
      "test_data.values": 1,
      "test.review.values": 1,
      "stage2_test_data['Text']": 1,
      "dftest['clean_text']": 1,
      "df_train.question1": 1,
      "df_train.question2": 1,
      "test['final_processed_test']": 1,
      "tweet": 1,
      "valid_question_list": 1,
      "sequence[train_size:]": 1,
      "test.ngrams": 1,
      "prior_ord['product_set']": 1,
      "testset.ingredients": 1,
      "train_mes": 1,
      "valid_mes": 1,
      "testDF.ix[:, 'question1']": 1,
      "testDF.ix[:, 'question2']": 1,
      "X_test['clean_text']": 1,
      "x_valid['ingredients']": 1,
      "[question_text]": 1,
      "data['item_description']": 1,
      "train_0.question_text_cleaned": 1,
      "X_train.question_text_cleaned": 1,
      "X_test.question_text_cleaned": 1,
      "train.question_text_cleaned": 1,
      "test.question_text_cleaned": 1,
      "x_tr['title']": 1,
      "x_cv['title']": 1,
      "x_test['title']": 1,
      "x_tr['essay']": 1,
      "x_cv['essay']": 1,
      "x_test['essay']": 1,
      "x_tr['clean_categories']": 1,
      "x_cv['clean_categories']": 1,
      "x_test['clean_categories']": 1,
      "x_tr['clean_subcategories']": 1,
      "x_cv['clean_subcategories']": 1,
      "x_test['clean_subcategories']": 1,
      "train[INPUT_COLUMN]": 1,
      "test[INPUT_COLUMN]": 1,
      "X_train['features_clean']": 1,
      "X_val['features_clean']": 1,
      "train_df['Text'].values.astype('U')": 1,
      "test_df['Text'].values.astype('U')": 1,
      "test_df['special_char_cleaned_text']": 1,
      "test_df['keyword-text']": 1,
      "X_val['excerpt']": 1,
      "test_n": 1,
      "df_train['title']": 1,
      "arraytotext(test['ingredients'])": 1,
      "X_test.text": 1,
      "[text[0]]": 1,
      "val_X.values": 1,
      "data.loc[(data['TYPE-LABEL'] == 'TRAIN').tolist(), 'ingredients'].values": 1,
      "data.loc[(data['TYPE-LABEL'] == 'TEST').tolist(), 'ingredients'].values": 1,
      "test_df.question_text.values": 1,
      "test['question_text'].values.astype('U')": 1,
      "tokens_colloc_test": 1,
      "joined.comment_text": 1,
      "train_phrases2": 1,
      "test_phrases2": 1,
      "test['clean_question_text']": 1,
      "data_train_cleaned['overview'].fillna('')": 1,
      "data_train_cleaned['tagline'].fillna('')": 1,
      "train['clean_comment_text']": 1,
      "test['clean_comment_text']": 1,
      "test_['text']": 1,
      "resp_tokens": 1,
      "X_list": 1,
      "y_list": 1,
      "[i]": 1,
      "train_df.question_text": 1,
      "val_df.question_text": 1,
      "clean_movie_test['review']": 1,
      "clean_toxic_test['comment_text']": 1,
      "ts_col[:ts_part_data_len]": 1,
      "test_set[0]": 1,
      "documents2": 1,
      "df['comment_text']": 1,
      "valid_all_tokens": 1,
      "comment_df[train_n:]['stemmed_comment']": 1,
      "train_df['lower_case_text'].values": 1,
      "test_df['lower_case_text'].values": 1,
      "test[col].astype(str)": 1,
      "test_df['project_descp']": 1,
      "test_doc": 1,
      "list(X_test)": 1,
      "test_org.question_text.values.tolist()": 1,
      "val['comment_text']": 1
    },
    "sklearn.svm._classes.LinearSVC.fit.X": {
      "X_train": 71,
      "x_train": 17,
      "X": 7,
      "features": 5,
      "X_train_normalized": 5,
      "train_features": 4,
      "xtrain": 4,
      "Xtrain": 3,
      "predictors_tr": 3,
      "train_vect": 2,
      "df_train": 2,
      "train_tf": 2,
      "X_train_tfidf": 2,
      "X_train_tf": 2,
      "train_vectors": 2,
      "x_t": 2,
      "training_features": 2,
      "train": 2,
      "X_train_flatten": 2,
      "tfidf_train": 2,
      "X_train_vec": 2,
      "x_train_final": 2,
      "x_train_counts": 1,
      "X_train_full": 1,
      "cv_train": 1,
      "td_train": 1,
      "x_train_tf": 1,
      "X_training": 1,
      "xtrain_v": 1,
      "xtrain_tfidf_ngram": 1,
      "Stacked": 1,
      "train_vectorized": 1,
      "data_numpy_image": 1,
      "X_train1": 1,
      "tfidf_vectorizer_vectors": 1,
      "train_tfidf": 1,
      "x_traintf": 1,
      "x_traincv": 1,
      "X_train_cv1": 1,
      "matrix_train": 1,
      "mat_trn_pol": 1,
      "ttextdataemx_train": 1,
      "trainfeature": 1,
      "tsiftdatax_train": 1,
      "Xtf_train": 1,
      "tfidf_data": 1,
      "I": 1,
      "x_train_mod": 1,
      "v_X_train": 1,
      "ng_v_X_train": 1,
      "train_data_predictors": 1,
      "X_for_train": 1,
      "X_train_0": 1,
      "trainData": 1,
      "count_train": 1,
      "x_test_v": 1,
      "x_train_v": 1,
      "label_X_train": 1,
      "Xi[i1]": 1,
      "X_tr": 1,
      "bag_train": 1,
      "X_over": 1,
      "numpyMatrix": 1,
      "xtrain_tfv": 1,
      "trainX": 1,
      "X2": 1,
      "xtr": 1,
      "reduced_data": 1,
      "tabel[feat]": 1,
      "train_X": 1,
      "X_train_target": 1,
      "x_trainnew": 1,
      "data_train": 1,
      "xsvm": 1,
      "X_train_pca": 1,
      "train_matrix_tfidf": 1,
      "train_df": 1,
      "train_df[selected_col]": 1,
      "x": 1,
      "games[col].fillna(-1)": 1,
      "messages_tfidf": 1,
      "xtrain_cv": 1,
      "xtrain_tv": 1,
      "train_gene_var_text": 1,
      "X_train_1": 1,
      "X_train_transformed": 1,
      "df_upsampled_vectorized": 1,
      "big_data_matrix": 1,
      "image_preds_all": 1,
      "X_train_vect": 1,
      "df_X": 1,
      "X1_train_train_standard": 1,
      "train_preds": 1
    },
    "sklearn.svm._classes.LinearSVC.fit.y": {
      "y_train": 87,
      "Y_train": 27,
      "y": 19,
      "ytrain": 11,
      "train_df['target']": 6,
      "train_y": 4,
      "training_labels": 4,
      "targets_tr": 3,
      "Y": 3,
      "labels": 2,
      "y_t": 2,
      "target": 2,
      "y_train_full": 1,
      "train['cuisine']": 1,
      "y_train[label_name]": 1,
      "y_training": 1,
      "train2.loc[test_index]['target']": 1,
      "data_numpy_label": 1,
      "y_train1": 1,
      "train_data['cat_cuisine']": 1,
      "y_traintf": 1,
      "y_traincv": 1,
      "df_train.target": 1,
      "trn_polarized.sentiment": 1,
      "train_polarized.sentiment": 1,
      "ttextdataemy_train": 1,
      "ttexty_train": 1,
      "tsiftdatay_train": 1,
      "data['cuisine']": 1,
      "C": 1,
      "train_data_targets": 1,
      "train[category]": 1,
      "y_for_train": 1,
      "Y_train_0": 1,
      "trainLabel": 1,
      "y_test": 1,
      "y[i1]": 1,
      "y_tr": 1,
      "y_over": 1,
      "trainY.values": 1,
      "y2": 1,
      "ytr": 1,
      "Y_Train": 1,
      "label": 1,
      "label_train": 1,
      "ysvm": 1,
      "y_train_pca": 1,
      "train_labels": 1,
      "train_df['isFraud']": 1,
      "games['Pred']": 1,
      "train['sentiment']": 1,
      "classes": 1,
      "train.target": 1,
      "image_labels_all": 1,
      "y_train_vect": 1,
      "df_Y": 1,
      "y_train_tf": 1,
      "train_.label.values": 1
    },
    "sklearn.metrics._classification.accuracy_score.y_true": {
      "y_test": 2176,
      "y_train": 387,
      "y_val": 309,
      "train_predicted": 308,
      "y_valid": 276,
      "y_true": 162,
      "y": 161,
      "y_pred": 152,
      "Y_test": 134,
      "yvalid": 130,
      "test_y": 119,
      "ytest": 60,
      "Y_train": 57,
      "pred": 55,
      "(yv * range(NUM_CLASSES)).sum(axis=1)": 53,
      "val_y": 47,
      "target": 40,
      "targets": 40,
      "self.y_test": 38,
      "valid_y": 32,
      "Titanic_test_y": 32,
      "y_numpy_true": 30,
      "yval": 28,
      "train_y": 26,
      "labels": 26,
      "confidence_valid > 0": 25,
      "test_labels": 25,
      "test_Y_cat": 24,
      "y_validation": 23,
      "y_valid_cv": 23,
      "Yv": 23,
      "ypred": 22,
      "Y_real": 22,
      "Yt": 21,
      "Ytest": 21,
      "predictor": 20,
      "y_cv": 20,
      "predictions": 20,
      "test['Target']": 20,
      "Ytest1": 20,
      "Y_val": 19,
      "ytrain": 19,
      "true_labels": 18,
      "validate_y": 17,
      "preds": 17,
      "list(map(lambda x: np.argmax(x), y_test))": 17,
      "Y_valid": 17,
      "all_df[:train_df.shape[0]][TARGET]": 16,
      "actual": 15,
      "valid_labels": 14,
      "train['Survived']": 14,
      "prediction": 13,
      "va_y": 13,
      "yv": 12,
      "y_Val": 12,
      "y_validation_pred_final.Survived": 12,
      "preds_dig": 11,
      "xgb_up.predict(X_test)": 11,
      "y_pc_imp_train": 11,
      "y_test.argmax(axis=1)": 10,
      "pred_y": 10,
      "Y": 10,
      "train_labels": 10,
      "test_Y": 10,
      "y_pc_imp_test": 10,
      "pred1": 9,
      "y_train_CV": 9,
      "y_valid_CV": 9,
      "TestLabel": 9,
      "y_test_tfidf": 9,
      "y_test_res": 9,
      "predicted": 8,
      "y_validate": 8,
      "df['target']": 8,
      "labels_test": 8,
      "y_mtest": 8,
      "pred_train": 7,
      "labels_for_acc": 7,
      "y_test_val": 7,
      "label": 7,
      "target_test": 7,
      "y_tr": 7,
      "testing_labels": 6,
      "yTest": 6,
      "Y_validation": 6,
      "clf.predict(X_val)": 6,
      "y_pred_train": 6,
      "train_sample['HasDetections'][mask]": 6,
      "oof['label']": 6,
      "valid['target']": 6,
      "y_action_test": 6,
      "true_state": 6,
      "tsiftdatay_test": 6,
      "y_test_new['surface']": 6,
      "y_preds": 6,
      "y_test_new": 6,
      "true": 5,
      "y2": 5,
      "self.y_train": 5,
      "pred_test": 5,
      "true_y": 5,
      "y_true[:, i]": 5,
      "ground_truth": 5,
      "targs.cpu()": 5,
      "ys_test": 5,
      "devlabels": 5,
      "l": 5,
      "y_te": 5,
      "val_true": 5,
      "train.cuisine": 5,
      "cm_correct_labels": 5,
      "heads2['Target']": 5,
      "t_pred": 5,
      "train_df.iloc[valid_idx][target].values": 5,
      "y_test2": 5,
      "test_label": 5,
      "pred.argmax(axis=1)": 5,
      "test_df['author']": 5,
      "pred2": 4,
      "pred3": 4,
      "pred_tag": 4,
      "y1": 4,
      "np.argmax(y_data[test_index], axis=1)": 4,
      "test['author']": 4,
      "y_test_cv": 4,
      "votingC.predict(X_test)": 4,
      "labels_flat": 4,
      "Y_pred": 4,
      "merge_df.label.values": 4,
      "y_predLR": 4,
      "confidence_test > 0": 4,
      "y_predict": 4,
      "final_preds": 4,
      "test_target": 4,
      "val_labels": 4,
      "y_sets[i]": 4,
      "train_df.iloc[val_idx]['target'].values": 4,
      "clf.predict(test_set)": 4,
      "train_Y": 4,
      "pred_val": 4,
      "y_oof": 4,
      "y_val_raw_modf": 4,
      "y_test_count": 4,
      "expected": 4,
      "t": 4,
      "y[test_index]": 4,
      "target['surface']": 4,
      "test['correct']": 4,
      "y_test3": 4,
      "y_test4": 4,
      "ztest": 4,
      "y_test_array": 4,
      "mtrain[veld]": 4,
      "torch.Tensor.cpu(output)": 4,
      "val_data.labels": 4,
      "y_test_b": 4,
      "df_train.loc[:, 'target']": 4,
      "df_valid.loc[:, 'target']": 4,
      "target_train": 3,
      "pd.DataFrame(lr.predict(train_merge4))": 3,
      "pd.DataFrame(rf.predict(train_merge4))": 3,
      "pd.DataFrame(nb.predict(train_merge4))": 3,
      "pd.DataFrame(dt.predict(train_merge4))": 3,
      "pd.DataFrame(svc_ml.predict(train_merge4))": 3,
      "pd.DataFrame(ada.predict(train_merge4))": 3,
      "pd.DataFrame(knn.predict(train_merge4))": 3,
      "pd.DataFrame(gb.predict(train_merge4))": 3,
      "pd.DataFrame(ml.predict(X))": 3,
      "svm.predict(x_val)": 3,
      "validation_label": 3,
      "y_vaild": 3,
      "valdiate_y": 3,
      "data_y": 3,
      "train_data[TARGET]": 3,
      "y_true.flatten()": 3,
      "self.true_targets": 3,
      "predictions_valid": 3,
      "test.target": 3,
      "Y_train['surface']": 3,
      "y_valid['surface']": 3,
      "dtrain[target].values": 3,
      "y_pred_val": 3,
      "pred_RF": 3,
      "yw_test": 3,
      "testy": 3,
      "val_preds": 3,
      "train['Target']": 3,
      "y_hat_test": 3,
      "y_test_data": 3,
      "tmp": 3,
      "train_pred": 3,
      "y_pred_valid": 3,
      "mtrain[veld].astype('int')": 3,
      "predict_svm": 3,
      "np.argmax(valid_y, axis=1)": 3,
      "y_test1": 3,
      "Y_scale_test": 3,
      "y_actuals": 3,
      "y_cvp": 3,
      "classes[np.argmax(Y_test, axis=1)]": 3,
      "y_train_W": 3,
      "y_test_W": 3,
      "val_target": 3,
      "sent_test": 3,
      "y[val_idx]": 3,
      "list(cv_y)": 3,
      "y_train_frq": 3,
      "y_test_frq": 3,
      "y_batch_np": 3,
      "y_eval": 3,
      "test_true": 3,
      "predicted_labels": 3,
      "yp": 3,
      "y_train_pred_final.Survived": 3,
      "target[val]": 3,
      "trueArr": 3,
      "test_y2": 3,
      "flat_y": 3,
      "data.loc['validation']['Sentiment']": 3,
      "validate['target']": 3,
      "s_test": 3,
      "y_test_vect": 3,
      "predict": 3,
      "target_": 2,
      "y_train_label": 2,
      "y_validation_label": 2,
      "y_test_label": 2,
      "ovr.predict(x_val)": 2,
      "clf.predict(x_val)": 2,
      "np.argmax(batch[1].numpy(), axis=1)": 2,
      "pred4": 2,
      "t_test": 2,
      "y_": 2,
      "data[TARGET]": 2,
      "GAMPredict": 2,
      "DTMPredict": 2,
      "RFMPredict": 2,
      "KNCPredict": 2,
      "Y_Test": 2,
      "y_test > 0": 2,
      "model.predict(test_x)": 2,
      "targets.cpu().numpy()": 2,
      "valid_data['target'].values": 2,
      "sample_submission['target']": 2,
      "train['target']": 2,
      "input_data[output_var]": 2,
      "a": 2,
      "y_test73.surface.values": 2,
      "dtrain['target'].values": 2,
      "Y_cv": 2,
      "true_label": 2,
      "Y_dev": 2,
      "classification_model.predict_classes(species_0_test)": 2,
      "classification_model.predict_classes(species_1_test)": 2,
      "classification_model.predict_classes(species_3_test)": 2,
      "classification_model_2.predict_classes(species_0_test)": 2,
      "classification_model_2.predict_classes(species_1_test)": 2,
      "classification_model_2.predict_classes(species_3_test)": 2,
      "train_female['Survived']": 2,
      "train_male['Survived']": 2,
      "actual_train_validate": 2,
      "np.round(avgpreds_val).astype('int')": 2,
      "np.round(avgpreds_train).astype('int')": 2,
      "truth": 2,
      "current_y_val": 2,
      "prediction1": 2,
      "prediction2": 2,
      "prediction3": 2,
      "prediction4": 2,
      "prediction5": 2,
      "prediction6": 2,
      "prediction7": 2,
      "votingC.predict(x_test)": 2,
      "Y_pred_train": 2,
      "Y_pred_val": 2,
      "y_val.argmax(axis=1)": 2,
      "testeLabels": 2,
      "train3['d' + str(k)].values": 2,
      "train3[['d1', 'd2', 'd3', 'd4']].values.reshape(-1)": 2,
      "sub['Survived']": 2,
      "y_val_act": 2,
      "y24": 2,
      "y48": 2,
      "y72": 2,
      "y_loc": 2,
      "valid_targets": 2,
      "dev_targets.long().numpy()": 2,
      "y_holdout": 2,
      "actVal": 2,
      "test_lbls": 2,
      "y_test >= 0": 2,
      "clf.predict(X_test)": 2,
      "new_y": 2,
      "pred > 0.5": 2,
      "df1[output]": 2,
      "torch.squeeze(y_batch, 1).type(torch.LongTensor).cpu().numpy()": 2,
      "y_train_sm": 2,
      "y_valid_sm": 2,
      "y_teste": 2,
      "predict_lr": 2,
      "predict_knn": 2,
      "predict_rfc": 2,
      "predict_dtc": 2,
      "y.values": 2,
      "dtrain['TARGET'].values": 2,
      "y_cora_test": 2,
      "searchCV.predict(X_Singt3gram_vectorizer_test)": 2,
      "train_data['type']": 2,
      "X_train.iloc[val_idx]['target'].values": 2,
      "logistic_model.predict(X_train)": 2,
      "lda_model.predict(X_train)": 2,
      "qda_model.predict(X_train)": 2,
      "lscv_model.predict(X_train)": 2,
      "rfc_model.predict(X_train)": 2,
      "TrueLabels": 2,
      "sst2_y_test": 2,
      "Y[test_index]": 2,
      "y_Test": 2,
      "oof_target": 2,
      "test_gen.classes": 2,
      "val_true.astype('int32')": 2,
      "y_predl": 2,
      "train_ckwe['open_channels'].values": 2,
      "v_vals": 2,
      "t_vals": 2,
      "target_array": 2,
      "res_train": 2,
      "validate['is_attributed'].values": 2,
      "y_train_csv": 2,
      "X_ass_val['floor']": 2,
      "test_labels_mult": 2,
      "hotstar['Sentiment_Manual']": 2,
      "Y_check": 2,
      "valid_lab": 2,
      "target_values[test]": 2,
      "np.array(results)": 2,
      "pred_dig": 2,
      "train_preds": 2,
      "y_validation_pred": 2,
      "y_verify": 2,
      "y_labels": 2,
      "oof_preds_rf[valid_index]": 2,
      "target['surface'][valid_index]": 2,
      "(train.resp > 0).astype(int)": 2,
      "(val.resp > 0).astype(int)": 2,
      "y_for_test": 2,
      "preds_validate": 2,
      "y_train_gini": 2,
      "y_test_gini": 2,
      "model.predict(X_test)": 2,
      "X_valid['label'].values": 2,
      "heads['Target']": 2,
      "y_predDT": 2,
      "y_predsv": 2,
      "y_predAda": 2,
      "dtrain['Disbursed'].values": 2,
      "correct_labels": 2,
      "data['target']": 2,
      "val_pred": 2,
      "final_prediction": 2,
      "y_test['grapheme_root']": 2,
      "y_test['vowel_diacritic']": 2,
      "y_test['consonant_diacritic']": 2,
      "n_b_predictions": 2,
      "pred.detach().cpu().numpy().argmax(-1)": 2,
      "val_targets": 2,
      "y_finalpred": 2,
      "y.iloc[val_idx].values": 2,
      "np.argmax(val_y, axis=1)": 2,
      "train_df['label']": 2,
      "np.argmax(y_val, axis=1)": 2,
      "oof_val_true": 2,
      "trainf2_target": 2,
      "predictions_NB": 2,
      "Y_cls": 2,
      "classifier.predict(x_val)": 2,
      "train[cond]['outlier']": 2,
      "test_predict": 2,
      "y_val_down": 2,
      "mtrain_[:self.lentrain][self.veld]": 2,
      "y_ts": 2,
      "x_label": 2,
      "y1_test": 2,
      "pred_results['actual']": 2,
      "dtrain['logerror'].values": 2,
      "train_numeric_Y['ConfirmedCases']": 2,
      "train_numeric_Y['Fatalities']": 2,
      "np.array(final_targets)": 2,
      "test_df['category'] == 'dog'": 2,
      "test[category]": 2,
      "rounded_labels": 2,
      "FinalTrainLabels": 2,
      "FinalTestLabels": 2,
      "y_pred_lr": 2,
      "y_pred_dtc": 2,
      "y_pred_rfc": 2,
      "predictions.action": 2,
      "D_test.get_label()": 2,
      "trainSet2['Target']": 2,
      "yVal": 2,
      "output.cpu().detach().numpy()": 2,
      "target[val_idx]": 2,
      "yvl": 2,
      "model.predict(X_val)": 2,
      "tfidf_model.predict(X_val)": 2,
      "y_val2": 2,
      "test_batches.labels": 2,
      "validation_labels": 2,
      "Yvalid": 2,
      "y_test9": 2,
      "p": 2,
      "y_train[val_idx]": 2,
      "Ycv": 2,
      "y_testDogs": 2,
      "y_testCats": 2,
      "OOF_PRED['Survived']": 2,
      "cv_y": 2,
      "train.open_channels": 2,
      "np.argmax(y_true, axis=1) if AUG_TYPE is 'CUTMIXUP' else y_true": 2,
      "np.array(vo)": 2,
      "y_test[category]": 2,
      "list1": 2,
      "nb_classifier.predict(X_test)": 2,
      "y_train_stacking": 2,
      "y_val_B": 2,
      "y_train_encode": 1,
      "y_val_encode": 1,
      "eval_table['true_target']": 1,
      "np.append(y_test, (1, 0))": 1,
      "train_df['target']": 1,
      "target[v]": 1,
      "target[t]": 1,
      "varid_y": 1,
      "clf.predict(train.ingredients_new)": 1,
      "dc.predict(X_test)": 1,
      "train['label']": 1,
      "y_vali": 1,
      "rf_pred": 1,
      "rf_pred2": 1,
      "mlpy_pred": 1,
      "mlpy_pred2": 1,
      "y_pred_lstm": 1,
      "y_pred_bilstm": 1,
      "y_pred_gru": 1,
      "y_pred_attention": 1,
      "y_test['AdoptionSpeed']": 1,
      "all_labels.values": 1,
      "label_list": 1,
      "y_train_pred": 1,
      "XG_test_all['sales']": 1,
      "lgb.predict(df.loc[test_index])": 1,
      "trainedModel_B.predict(df_news.loc[test_index])": 1,
      "trainedModel_C.predict(df.loc[test_index])": 1,
      "valid_data[TARGET]": 1,
      "test_t_target": 1,
      "np.array(y_pred > 0.5, dtype='int')": 1,
      "best_model.predict(dtest).astype(np.uint8)": 1,
      "dig_pred": 1,
      "result.values": 1,
      "lrModel.predict(test_x)": 1,
      "stat_model.predict(test_x)": 1,
      "eval(y_te)": 1,
      "test_labels.astype('uint8')": 1,
      "val_df['target']": 1,
      "y_batch_actual_np": 1,
      "test2_df.label": 1,
      "sub['prediction']": 1,
      "df_target": 1,
      "NB_predicted_labels": 1,
      "DT_predicted_labels": 1,
      "DT_impr1_predicted_labels": 1,
      "KNN_predicted_labels": 1,
      "randomforest_predicted_labels": 1,
      "adaboost_predicted_labels": 1,
      "labels_for_accv": 1,
      "testY": 1,
      "outputs": 1,
      "np.argmax(validation_labels, axis=1)": 1,
      "predA": 1,
      "predB": 1,
      "predC": 1,
      "vote": 1,
      "preds_Val": 1,
      "y_test_svm": 1,
      "Y_test_split": 1,
      "np.argmax(Y_val, axis=1)": 1,
      "y[idx_tr]": 1,
      "y[idx_cv]": 1,
      "np.argmax(pred_cv, axis=1)": 1,
      "pred_gcv": 1,
      "tf_test": 1,
      "predM": 1,
      "predRF": 1,
      "Predxgb": 1,
      "logr_predicts": 1,
      "test[:, -1]": 1,
      "y_pred_log": 1,
      "y_pred_lgbm": 1,
      "y_pred_ERT": 1,
      "y_pred_xgb": 1,
      "pred_RF1": 1,
      "pred_RF2": 1,
      "LSTM_y_test": 1,
      "GRU_y_test": 1,
      "sepcnn_y_test": 1,
      "df_preds_train['y']": 1,
      "test_x_y['labels'].to_numpy()": 1,
      "np.argmax(test_Y1, axis=1)": 1,
      "np.argmax(test_Y2, axis=1)": 1,
      "np.argmax(test_Y3, axis=1)": 1,
      "ysp_test": 1,
      "y_test_press": 1,
      "y_test_normal": 1,
      "y_test_soft": 1,
      "K_pred": 1,
      "np.array(y_val)": 1,
      "val_df.label.astype(int)": 1,
      "objetivo": 1,
      "p.argmax(1).long()": 1,
      "y_dig": 1,
      "titanic_predictions": 1,
      "prediccion": 1,
      "train['TARGET'].values": 1,
      "train2['d' + str(k)].values": 1,
      "train2[['d1', 'd2', 'd3', 'd4']].values.reshape(-1)": 1,
      "self.valid_outputs[0]": 1,
      "self.valid_outputs[1]": 1,
      "self.valid_outputs[2]": 1,
      "tr_true": 1,
      "origin_labels": 1,
      "train_data['target']": 1,
      "y_actual": 1,
      "y_vl": 1,
      "df_gmm_train['target_gmm']": 1,
      "val_int.target": 1,
      "pre": 1,
      "df_train_train['diagnosis'].astype('int')": 1,
      "df_train_test['diagnosis'].astype('int')": 1,
      "bert_pred_df.label.values": 1,
      "xlmbase_pred_df.label.values": 1,
      "xlmlarge_pred_df.label.values": 1,
      "validation_set['has_cactus']": 1,
      "yhat": 1,
      "train['AdoptionSpeed']": 1,
      "ylo": 1,
      "yhi": 1,
      "i.predict(train_X)": 1,
      "acc_pred_list": 1,
      "y_train_aug": 1,
      "y_val_f_series": 1,
      "np.array(validation_labels)": 1,
      "np.argmax(oof_preds[idxV, ], axis=1)": 1,
      "ypred_oof": 1,
      "true_value": 1,
      "logreg.predict(x_val)": 1,
      "final_pred": 1,
      "pred_dec": 1,
      "y_pred_word": 1,
      "y_pred_char": 1,
      "oof": 1,
      "clf.predict(X_train)": 1,
      "y_test.ravel()": 1,
      "Y_test_old": 1,
      "output_df['diagnosis'].tolist()": 1,
      "test": 1,
      "combine['Survived']": 1,
      "dog_y_val": 1,
      "dog_y_train": 1,
      "cat_y_val": 1,
      "cat_y_train": 1,
      "catconfidence_test > 0": 1,
      "final_with_ori": 1,
      "final_without_ori": 1,
      "np.argmax(Y, axis=1)": 1,
      "np.array(outputs).reshape(-1, 1)": 1,
      "df.loc[:len(train) - 1, 'prediction']": 1,
      "label_val1": 1,
      "pred_survived": 1,
      "rf.predict(X_val)": 1,
      "rf.predict(X_val_scaled)": 1,
      "data.private": 1,
      "val_tgt": 1,
      "target.values": 1,
      "searchCV.predict(norm.transform(X_Singt3gram_vectorizer_test))": 1,
      "cv_target": 1,
      "train_df['is_duplicate']": 1,
      "target.cpu().numpy()[..., i].flatten()": 1,
      "val_y_rep": 1,
      "level2_df['Survived']": 1,
      "knc_model.predict(X_train)": 1,
      "rnc_model.predict(X_train)": 1,
      "nb_model.predict(X_train)": 1,
      "dtc_model.predict(X_train)": 1,
      "np.argmax(y_pred_prob, axis=1)": 1,
      "np.argmax(y_pred_prob_ensemble, axis=1)": 1,
      "np.where(actual == 1)[1]": 1,
      "revertedy": 1,
      "test_images['label']": 1,
      "nb_preds": 1,
      "knn_preds": 1,
      "rfc_preds": 1,
      "dt_preds": 1,
      "val_df_y": 1,
      "oof_df.loc[oof_df.iloc[val_idx].index]['Survived']": 1,
      "oof_df.Survived": 1,
      "y_test.data": 1,
      "data.iloc[val_idx]['target'].values": 1,
      "y_act": 1,
      "y_va": 1,
      "true_class": 1,
      "y_train[test_idx]": 1,
      "torch.argmax(pred[..., :-1], dim=1).cpu().numpy()": 1,
      "all_y": 1,
      "y_train_x": 1,
      "y_train_v": 1,
      "result['label']": 1,
      "lang_result['label']": 1,
      "target_df": 1,
      "y_test_cat": 1,
      "Y_TEST": 1,
      "result": 1,
      "pred_valid": 1,
      "test['AdoptionSpeed']": 1,
      "val_generator.classes": 1,
      "oof_tar[-1]": 1,
      "submit['diagnosis']": 1,
      "Y_pred_1": 1,
      "Y_pred_xgb": 1,
      "y_dev": 1,
      "y_predd": 1,
      "y_predg": 1,
      "y_predr": 1,
      "val_preds_lgb": 1,
      "clf_rfc.predict(X_val1)": 1,
      "df_train[target]": 1,
      "train.label.values": 1,
      "lgbm_y_test": 1,
      "val_df['is_attributed']": 1,
      "dtrain['is_attributed'].values": 1,
      "np.array(task['test'][p]['output']).reshape(1, -1)[0]": 1,
      "y_tst": 1,
      "y_test['surface']": 1,
      "classes[np.argmax(val_set_output, axis=1)]": 1,
      "YhdbTrain": 1,
      "sample['Sentiment']": 1,
      "y[:train.shape[0]]": 1,
      "self.y_true": 1,
      "oof_labels": 1,
      "Y2_test": 1,
      "Y2_train": 1,
      "survived_data": 1,
      "sample.open_channels": 1,
      "test_set_y": 1,
      "val_y.values": 1,
      "yelp['sentiment']": 1,
      "yy_test": 1,
      "is_artificial": 1,
      "y_pred_xg_train": 1,
      "u": 1,
      "torch.tensor(lst_label)": 1,
      "torch.tensor(lst_val_label)": 1,
      "out_pred": 1,
      "calc_p(preds, a, b, c, d, e, f, g)": 1,
      "viterbi_predictions": 1,
      "data_test[output]": 1,
      "start_labels": 1,
      "end_labels": 1,
      "class_labels": 1,
      "dr_test": 1,
      "ytest[class_name]": 1,
      "train_oof": 1,
      "y_xception_val": 1,
      "y_vgg16_val": 1,
      "y_resnet50_val": 1,
      "actual_labels": 1,
      "matriz_validacao_alvo": 1,
      "y_test_rdf": 1,
      "y_pred_clf": 1,
      "Y_test_clf": 1,
      "y_test_ans": 1,
      "pred_validate": 1,
      "target_array.values": 1,
      "np.argmax(y_test, axis=1)": 1,
      "y_lr": 1,
      "y_xgb": 1,
      "y_pca": 1,
      "y_dt": 1,
      "test_arr": 1,
      "F_test": 1,
      "True_Cuisine": 1,
      "train_cross_target": 1,
      "preds_none": 1,
      "preds_class": 1,
      "preds_gender": 1,
      "preds_class_gender": 1,
      "y_adv": 1,
      "(y_train > 0).astype(int)": 1,
      "(y_test > 0).astype(int)": 1,
      "oof_target_all[num_model]": 1,
      "oof_target_all[0]": 1,
      "oof_preds_gr[valid_index]": 1,
      "Y_valid_base": 1,
      "test_response": 1,
      "pred_flat": 1,
      "train_df.label.values": 1,
      "group_model.predict(X_test)": 1,
      "real": 1,
      "classes": 1,
      "test_labels.cpu()": 1,
      "b['correct']": 1,
      "b2020['correct']": 1,
      "b2019['correct']": 1,
      "prediction.round()": 1,
      "y_hat_RF": 1,
      "y_hat_LSTM_Glove": 1,
      "train_df_all.outliers": 1,
      "oof_predictions_v3.target.values": 1,
      "y_test.tolist()": 1,
      "xv_test_set['surface'].values": 1,
      "Y_test_0": 1,
      "y_cv1": 1,
      "y_cv3": 1,
      "y_cv4": 1,
      "ztest1": 1,
      "x_test['country_destination']": 1,
      "targets_all": 1,
      "pred_nval_y": 1,
      "pred_glove_val_y": 1,
      "y_val_res": 1,
      "valid_preds": 1,
      "vt_clf.predict(X_valid)": 1,
      "val_DV": 1,
      "y_test_fold": 1,
      "oof.label.values": 1,
      "y_batch": 1,
      "ypred_Logreg": 1,
      "ypred_rfc": 1,
      "ypred_naive": 1,
      "prediction_RFC": 1,
      "prediction_lSVC": 1,
      "prediction_DTC": 1,
      "prediction_GNB": 1,
      "prediction_PT": 1,
      "prediction_SGD": 1,
      "prediction_LR": 1,
      "prediction_KNC": 1,
      "yR": 1,
      "f_val.target": 1,
      "target_ind": 1,
      "test['isup_grade']": 1,
      "y_preds_new": 1,
      "bnb": 1,
      "dt": 1,
      "y_train_": 1,
      "dtree_train_y": 1,
      "valid.label": 1,
      "valid0.pred": 1,
      "best_predictions": 1,
      "y_test_dt1": 1,
      "y_test_dt2": 1,
      "y_test_xg1": 1,
      "y_test_xg2": 1,
      "train_df.iloc[val_idx]['label'].values": 1,
      "labelsTest1": 1,
      "np.argmax(model.predict(X_train), axis=1)": 1,
      "acc": 1,
      "train_df2.iloc[val_idx]['target'].values": 1,
      "dtree_pred": 1,
      "rdf_pred": 1,
      "lgbm_pred": 1,
      "product_category": 1,
      "predictions_SVM": 1,
      "ml_val": 1,
      "y_test_": 1,
      "answers": 1,
      "df['diagnosis'].astype('int')": 1,
      "ps": 1,
      "sample_y_val": 1,
      "preds_f": 1,
      "torch.argmax(val_labels, dim=1)": 1,
      "TARGET": 1,
      "train_label_rd": 1,
      "train['action']": 1,
      "valid['action']": 1,
      "np.argmax(y_train[val_idx], axis=1)": 1,
      "dtrain[predlabel].values": 1,
      "nb_y_val": 1,
      "Y_Train.flatten()": 1,
      "Dev_Y.flatten()": 1,
      "encoded_Y": 1,
      "ans1": 1,
      "df_hotstar['Sentiment_Manual']": 1,
      "y_train_true": 1,
      "y_test_true": 1,
      "clf.predict(Xtest)": 1,
      "valid_generator.classes": 1,
      "label_val_split": 1,
      "y_true.T[i]": 1,
      "np.array(targets_reduced.cpu())": 1,
      "np.array(targets_reduced)": 1,
      "y_pred_lgb": 1,
      "img_y": 1,
      "train['open_channels']": 1,
      "oof_proba_list[i].argmax(1)": 1,
      "stack_proba.argmax(1)": 1,
      "y_pred3": 1,
      "y_pred_tuned": 1,
      "gt_labels": 1,
      "output": 1,
      "y_train[::step]": 1,
      "y_test[::step]": 1,
      "Y[test]": 1,
      "label_test": 1,
      "np.array(y_true) > 0": 1,
      "n_y_val": 1,
      "test[target].values": 1,
      "y_test_imba": 1,
      "sam.open_channels": 1,
      "preds_1": 1,
      "df_test_target": 1,
      "labels.cpu()": 1,
      "y[5500:]": 1,
      "pred_test_one_zero": 1,
      "tpY": 1,
      "y_test_x": 1,
      "sub_preds": 1,
      "pred_v1": 1,
      "pred_v2": 1,
      "pred_v3": 1,
      "yteste": 1,
      "y_true.argmax(axis=1)": 1,
      "correct": 1,
      "o": 1,
      "train.label[40000:42000]": 1,
      "validation['Sentiment']": 1,
      "trans_class": 1,
      "up_test": 1,
      "y[valid_idx]": 1,
      "y_train.iloc[train_index]": 1,
      "y_train.iloc[test_index]": 1,
      "target_pre": 1,
      "y_test_under": 1,
      "y_test_over": 1,
      "(Y_test * range(120)).sum(axis=1)": 1,
      "sub['Sentiment']": 1,
      "lightGBM_pred": 1,
      "y_test10": 1,
      "y_test5": 1,
      "y_test6": 1,
      "y_test7": 1,
      "y_test8": 1,
      "tf.argmax(logits, axis=1)": 1,
      "val_predictions": 1,
      "validate_y.values": 1,
      "docs['sentiment']": 1,
      "gender_submission['Survived']": 1,
      "y_test.values": 1,
      "results['y_val']": 1,
      "valid_pred": 1,
      "ground_truth['Label'].values": 1,
      "ANS": 1,
      "lb": 1,
      "Ym_test": 1,
      "np.array(y_test)": 1,
      "y_valid_idx": 1,
      "RandomForest_Predictions": 1,
      "confidence_valid.astype('int')": 1,
      "imdb['sentiment']": 1,
      "val": 1,
      "np.round(targets[:len(toxicity_scores)])": 1,
      "np.round(obscenities[:len(toxicity_scores)])": 1,
      "np.round(severe_toxicities[:len(toxicity_scores)])": 1,
      "np.argmax(valid_Y, -1)": 1,
      "yhat_Train": 1,
      "actual_class": 1,
      "DATA[bin_features[i]]": 1,
      "temp['Survived']": 1,
      "y_pred_inlier": 1,
      "y_pred_outlier": 1,
      "validation_targets": 1,
      "y.detach().cpu().numpy()": 1,
      "val_label": 1,
      "train_label": 1,
      "temp_df.open_channels": 1,
      "true_df": 1,
      "y_test_v": 1,
      "truth_class": 1,
      "final_targets": 1,
      "model.predict(embed_val)": 1,
      "val_pred1.argmax(axis=1)": 1,
      "val_preds.argmax(axis=1)": 1,
      "np.array(train_orig)": 1,
      "knn_pred": 1,
      "svc_predict": 1,
      "gaussian_predict": 1,
      "svc.predict(test_x)": 1,
      "res_y": 1,
      "val['diagnosis']": 1,
      "d_test['label']": 1,
      "validation_y": 1,
      "train_data.target": 1,
      "val_data.target": 1,
      "df_gt_simulated": 1,
      "best_tree.predict(X_test)": 1,
      "best_forest.predict(X_test)": 1,
      "best_lgbm.predict(X_test)": 1,
      "y_pre": 1,
      "y_C_val": 1,
      "label['surface']": 1,
      "xgb.predict(X_test)": 1,
      "catb.predict(X_test)": 1,
      "lr_classifier.predict(X_test)": 1,
      "val_df.sirna": 1,
      "all_preds['y_true']": 1,
      "y_val_speed_convert": 1,
      "y_trn[val]": 1,
      "valid['duration_group']": 1,
      "test_set.sentiment": 1,
      "train_set.sentiment": 1,
      "y_predicted": 1,
      "y_predictt": 1
    },
    "sklearn.metrics._classification.accuracy_score.y_pred": {
      "y_pred": 1067,
      "y": 316,
      "predictions": 312,
      "pred": 311,
      "y_test": 279,
      "preds": 136,
      "y_val": 89,
      "train_predictions": 81,
      "predicted": 79,
      "valid_preds": 71,
      "prediction": 59,
      "y_pred_train": 56,
      "y_valid": 55,
      "Y_pred": 53,
      "y_train": 49,
      "y_pred_test": 46,
      "pred_labels": 41,
      "y_pred_class": 39,
      "test_pred": 35,
      "pred_train": 34,
      "pred_val": 34,
      "target": 33,
      "pred_test": 33,
      "outputs": 32,
      "pred_valid": 32,
      "y_preds": 31,
      "y_pred_val": 30,
      "np.round(y_numpy_pred)": 30,
      "y_test_pred": 29,
      "test_y": 28,
      "y_predict": 28,
      "y_predicted": 26,
      "ypred": 26,
      "predict": 23,
      "y_pred_X": 22,
      "model.predict(X_test)": 22,
      "pred_Y_cat": 22,
      "y_train_pred": 21,
      "pred_trn": 21,
      "train_pred": 20,
      "test_predictions": 20,
      "pred_test1": 20,
      "pred_y": 19,
      "y_pred1": 18,
      "test_Y": 18,
      "y_pre": 17,
      "dtrain_predictions": 16,
      "y_preds_res": 15,
      "result": 14,
      "train_preds": 14,
      "val_pred": 14,
      "y_pred6": 14,
      "y_pred2": 13,
      "up_test": 13,
      "model.predict(X_train)": 13,
      "y_pred_valid.argmax(1)": 13,
      "targets": 13,
      "ytest": 12,
      "pred1": 12,
      "y_pred_lr": 12,
      "y_pred_svm": 12,
      "y_validation_pred_final.Predicted_Survived": 12,
      "oof": 11,
      "y_dig": 11,
      "y_pred_xgb": 11,
      "output": 11,
      "Y_test": 11,
      "rf_pred": 11,
      "train_oof": 11,
      "Clf1.predict(X_test)": 11,
      "Clf2.predict(X_test)": 11,
      "Y_val": 10,
      "clf.predict(X_test)": 10,
      "y_valid_hat > 0.5": 10,
      "y_pred_tr": 10,
      "Y_pred_tra": 10,
      "Y_pred_tes": 10,
      "va_pred": 10,
      "predicted_class": 9,
      "y_hat.argmax(axis=1)": 9,
      "LR_cnt_pred_tr": 9,
      "Y_pred_rand": 9,
      "pred_knn": 9,
      "y_train_hat_mainLearner > 0.5": 9,
      "y_valid_hat_mainLearner > 0.5": 9,
      "Clf1.predict(X)": 9,
      "Clf2.predict(X)": 9,
      "y_pred_knn": 9,
      "y_vid": 9,
      "testY": 9,
      "testLabel": 8,
      "pred_rf": 8,
      "train_y": 8,
      "clf.predict(X_train)": 8,
      "torch.round(val_preds.cpu())": 8,
      "y_pred_rfc": 8,
      "clf.predict(train_data)": 8,
      "y_pred_ts": 8,
      "np.where(pred_train <= 0.5, 0, 1)": 8,
      "np.where(pred_val <= 0.5, 0, 1)": 8,
      "Y_pred_train": 7,
      "y_prediction": 7,
      "validate_y_pred": 7,
      "preds.argmax(1)": 7,
      "knn_pred": 7,
      "test_preds": 7,
      "prediction1": 7,
      "prediction2": 7,
      "predicted_labels": 7,
      "y_pred_rf": 7,
      "pred_nb": 7,
      "temp_oof": 7,
      "preds_test": 7,
      "yhat": 7,
      "y_pred_dt": 7,
      "target_test": 7,
      "pred2": 7,
      "predict_labels": 7,
      "predictions2": 7,
      "best_algo.predict(X_train)": 7,
      "best_algo.predict(X_test)": 7,
      "model_pred": 6,
      "y_pred.round()": 6,
      "pred_class": 6,
      "lgb_clf.predict(X_train)": 6,
      "lgb_clf.predict(X_val)": 6,
      "test_generator.labels": 6,
      "preds_for_acc": 6,
      "y_pred_valid": 6,
      "SVM_cnt_pred_tr": 6,
      "NB_cnt_pred_tr": 6,
      "LR_tfidf_pred_tr": 6,
      "SVM_tfidf_pred_tr": 6,
      "NB_tfidf_pred_tr": 6,
      "pred3": 6,
      "pred4": 6,
      "pred_tr": 6,
      "pred_cv": 6,
      "val_y": 6,
      "y_valid_pred": 6,
      "target_pred": 6,
      "np.where(lgb_oof[oof_idx] > 0.5, 1, 0)": 6,
      "np.where(lgb_oof > 0.5, 1, 0)": 6,
      "valid['prediction']": 6,
      "actions_predicted": 6,
      "y_val_pred": 6,
      "Y_predict": 6,
      "rf.oob_decision_function_[:, 1] >= 0.5": 6,
      "out_class": 6,
      "y_pred_DTC": 6,
      "y_val_preds": 6,
      "np.where(y_oof[valid_index] > 0.5, 1, 0)": 6,
      "ypred_class": 5,
      "val_preds": 5,
      "bin_target.loc[test_index]": 5,
      "(y_pred > 0.5).astype(int)": 5,
      "Y_pred_valid": 5,
      "predictions_train": 5,
      "labels": 5,
      "y_pred[:, i]": 5,
      "y[val_idx]": 5,
      "input.cpu()": 5,
      "y_predLR": 5,
      "y_pred4": 5,
      "np.where(ctb_oof[oof_idx] > 0.5, 1, 0)": 5,
      "np.where(ctb_oof > 0.5, 1, 0)": 5,
      "np.where(dtm_oof[oof_idx] > 0.5, 1, 0)": 5,
      "np.where(dtm_oof > 0.5, 1, 0)": 5,
      "o[:, 1] > 0.5": 5,
      "y_pred_gnb": 5,
      "list(map(lambda x: np.argmax(x), y_hat))": 5,
      "cm_predictions": 5,
      "np.argmax(preds, axis=1)": 5,
      "s": 5,
      "Y_valid_pred": 5,
      "predictcombine": 5,
      "pd.DataFrame(model.predict(preds_val))": 5,
      "valid_pred": 5,
      "oof[valid_idx].round()": 5,
      "lr_pred": 5,
      "y_pred_lstm": 5,
      "y_pred_cnn": 5,
      "flat_y": 5,
      "(predict >= 0.5) * 1": 4,
      "xgb_predicted": 4,
      "predict_val": 4,
      "train_y_pred": 4,
      "train_predict": 4,
      "classifier.predict(X_test)": 4,
      "predictions_test": 4,
      "dt.predict(X_test)": 4,
      "pred_1": 4,
      "y_p1": 4,
      "y_p2": 4,
      "y_p3": 4,
      "np.zeros(len(species_0_test))": 4,
      "np.ones(len(species_1_test))": 4,
      "np.ones(len(species_3_test)) * 2": 4,
      "pred_flat": 4,
      "best_pred": 4,
      "test_labels": 4,
      "yp": 4,
      "oof['pred']": 4,
      "y_pred_tree": 4,
      "y_train_stack_pred": 4,
      "df['label'].values": 4,
      "predict3": 4,
      "predict4": 4,
      "list(map(lambda x: np.argmax(x), y_hat_2))": 4,
      "list(map(lambda x: np.argmax(x), y_hat_3))": 4,
      "y_pred3": 4,
      "valy": 4,
      "test_label": 4,
      "word_clf.predict(x_test_word)": 4,
      "stacked_clf": 4,
      "y_predit_svc": 4,
      "pred_classes": 4,
      "results": 4,
      "[int(pred_prob > 0) for pred_prob in valid_prediction]": 4,
      "np.array(predictions > thr, dtype=np.int)": 4,
      "np.argmax(train_oof, axis=1)": 4,
      "test_pred_rf": 4,
      "test_pred_ab": 4,
      "predict_label": 4,
      "df_train.Survived": 4,
      "predictions1": 4,
      "y_pred_svc": 4,
      "y_pred_test_DTC": 4,
      "y_pred_test_vc": 4,
      "rf_predictions": 4,
      "Valid_pred": 4,
      "y_pred_bidirectional_lstm": 4,
      "y_pred_lstm_cnn": 4,
      "y_pred_bidirectional_lstm_cnn": 4,
      "logReg.predict(X_valid_cv)": 4,
      "kNN.predict(X_valid_cv)": 4,
      "RF.predict(X_valid_cv)": 4,
      "pred_xgb": 4,
      "torch.Tensor.cpu(label)": 4,
      "predicted_y": 4,
      "predIdxs_VGG": 4,
      "np.round(oof).astype(int)": 4,
      "y_pred_b": 4,
      "p > 0.5": 4,
      "y_predi": 4,
      "tf_clf_dnn.predict(X_train)": 3,
      "oof_preds": 3,
      "lr_predicted": 3,
      "svc_predicted": 3,
      "dtree_predicted": 3,
      "lr.predict(X_val)": 3,
      "y_pred_bnb": 3,
      "abc.predict(test[feats])": 3,
      "best_preds": 3,
      "y_pred.flatten()": 3,
      "self.preds": 3,
      "perturbed_preds": 3,
      "valid_tags": 3,
      "test.pred": 3,
      "valid_predictions": 3,
      "pred5": 3,
      "test_predict": 3,
      "classifier.predict(X_train)": 3,
      "clf.predict(val_x)": 3,
      "test": 3,
      "rfc_pred": 3,
      "predictionTrain": 3,
      "b": 3,
      "rndm_preds": 3,
      "sgb_preds": 3,
      "pred_dt": 3,
      "xgb_pred": 3,
      "lr_preds": 3,
      "pred_2": 3,
      "pred_3": 3,
      "pred_4": 3,
      "y_predSVM": 3,
      "pred_KNN": 3,
      "np.round(preds)": 3,
      "clf.predict(x_cv_text)": 3,
      "lr_predict": 3,
      "np.argmax(y_train, axis=1)": 3,
      "y_hat": 3,
      "Y_train": 3,
      "y_pred.argmax(axis=1)": 3,
      "ys_pred": 3,
      "final_pred": 3,
      "casc_pred": 3,
      "pred_svm": 3,
      "predict1": 3,
      "predict2": 3,
      "prediction3": 3,
      "prediction8": 3,
      "np.argmax(val_preds, axis=1)": 3,
      "y_pred5": 3,
      "y_pred7": 3,
      "y_pred8": 3,
      "y_predic": 3,
      "pred_label": 3,
      "y_cora_test": 3,
      "reduce(list.__add__, model.predict(x_train).round().tolist())": 3,
      "rf4.predict(heads2[feats])": 3,
      "np.where(yp_val > 0.5, 1, 0)": 3,
      "[1 if m > thresh else 0 for m in yp_val]": 3,
      "np.where(yp_val > max_accuracy_threshold, 1, 0)": 3,
      "y_trainpred": 3,
      "y_testpred": 3,
      "validate_pred": 3,
      "y_pred_gbc": 3,
      "gs.predict(X_train)": 3,
      "gs.predict(X_test)": 3,
      "mul_lr.predict(X_scale_test)": 3,
      "predict_xgbc": 3,
      "predict_rfc": 3,
      "np.round(pred_val)": 3,
      "y_pred_test_svm": 3,
      "p": 3,
      "predictions_tfidf": 3,
      "np.round(y_pred)": 3,
      "predictionsSVM": 3,
      "np.argmax(val_pred, axis=1)": 3,
      "test_pred_mnb": 3,
      "y_valid.values": 3,
      "np.argmax(pred, axis=1)": 3,
      "predicted_classes": 3,
      "y_pred_test_svc": 3,
      "preds_batch_np": 3,
      "np.argmax(preds_valid, axis=1)": 3,
      "kn_predictions": 3,
      "y_new": 3,
      "trainf2_target": 3,
      "data_label": 3,
      "model.predict(X_valid)": 3,
      "np.argmax(y_pred, axis=1)": 3,
      "yp1": 3,
      "np.round(regr.predict(X))": 3,
      "pred_mode": 3,
      "pred_log": 3,
      "predArr": 3,
      "testPredictions2": 3,
      "y_pred_train.round()": 3,
      "y_pred_test.round()": 3,
      "xgboost_train_preds": 3,
      "rf_train_preds": 3,
      "rf.predict(X)": 3,
      "pred_validate_y": 3,
      "o.argmax(axis=1)": 3,
      "np.where(OOF > 0.5, 1, 0)": 3,
      "y_test_preds": 3,
      "predictions3": 3,
      "predictions4": 3,
      "yp_class": 3,
      "(pred_mean >= 0.5) * 1": 2,
      "preds_train.argmax(axis=1)": 2,
      "y_pred_xgb.round()": 2,
      "ab_pred": 2,
      "gb_pred": 2,
      "clf.predict(xTest)": 2,
      "y_validation_pred": 2,
      "y_real": 2,
      "np.argmax(pred.detach().cpu().numpy(), axis=1)": 2,
      "validation_predictions": 2,
      "predictions_2": 2,
      "g.best_estimator_.predict(x_valid)": 2,
      "vote_clf.predict(x_valid)": 2,
      "my_model.predict(x_valid_mod)": 2,
      "pred_max": 2,
      "baseline_prediction": 2,
      "lgb.predict(x_test)": 2,
      "model.predict(x_test)": 2,
      "final_train_predictions": 2,
      "rf.predict(X_train)": 2,
      "linear_model_sgd_prediction": 2,
      "clf_rf.predict(X_val)": 2,
      "np.argmax(y_pred1, axis=1)": 2,
      "Y_preds_knn": 2,
      "Y_preds_lg": 2,
      "Y_preds_gnb": 2,
      "Y_preds_dt": 2,
      "Y_preds_rfc": 2,
      "confidence > 0": 2,
      "preds.cpu().numpy()": 2,
      "lg_pred": 2,
      "(y_proba_test > my_th).astype(int).argmax(axis=1)": 2,
      "torch.round(valid_preds.cpu())": 2,
      "y_test_predict": 2,
      "y2": 2,
      "predprobs > thr": 2,
      "nb_predict": 2,
      "np.argmax(nnet.predict(X_data[test_index]), axis=1)": 2,
      "np.argmax(xgb_clf.predict_proba(X_data[test_index]), axis=1)": 2,
      "model3.predict(val_x)": 2,
      "to_labels(oof_preds3, t)": 2,
      "gnb_pred": 2,
      "dtc_pred": 2,
      "svc_pred": 2,
      "ann_pred": 2,
      "dtree_train_y": 2,
      "rf.predict(X_test)": 2,
      "test_label == n": 2,
      "grid_predictions": 2,
      "xgb_rndm_preds": 2,
      "vc_preds": 2,
      "logRes": 2,
      "dt_preds": 2,
      "rft_preds": 2,
      "lr.predict(X_test)": 2,
      "lr.predict(X_train)": 2,
      "RandomForestClassifier_yhat_test": 2,
      "SGDClassifier_yhat_test": 2,
      "MultinomialNB_yhat_test": 2,
      "training_preds": 2,
      "predicted_res": 2,
      "y_preds_clf": 2,
      "y_pred_female": 2,
      "y_pred_male": 2,
      "tes": 2,
      "predicted_1": 2,
      "svm_pred": 2,
      "predicted_train_validate": 2,
      "valid_preds_rs": 2,
      "np.argmax(y_val, axis=1)": 2,
      "np.round(p)": 2,
      "current_predictions": 2,
      "y_model": 2,
      "(train3['o' + str(k)].values > 0.5).astype(int)": 2,
      "(train3[['o1', 'o2', 'o3', 'o4']].values > 0.5).astype(int).reshape(-1)": 2,
      "pred_Y_cat[0]": 2,
      "best_pred_smote": 2,
      "y_predicted_r": 2,
      "cat": 2,
      "va_pred > 0.5": 2,
      "train_meta_ints": 2,
      "yp_loctest": 2,
      "oof_tta_predictions": 2,
      "oof_tta['pred']": 2,
      "y_true": 2,
      "y_pred_logreg": 2,
      "lr_tfidf_predict": 2,
      "results_holdout": 2,
      "predVal": 2,
      "predict5": 2,
      "clf.predict(X_valid)": 2,
      "y_pred >= 0": 2,
      "list(map(lambda x: np.argmax(x), y_hat_6))": 2,
      "list(map(lambda x: np.argmax(x), y_hat_5))": 2,
      "prediction4": 2,
      "prediction5": 2,
      "prediction6": 2,
      "Y_pred_lr": 2,
      "shelter_dt.predict(X_train_dm)": 2,
      "dog_y_pred": 2,
      "cat_y_pred": 2,
      "predictions_nb": 2,
      "np.argmax(batch_response.detach().cpu().numpy(), 1)": 2,
      "predict_nb": 2,
      "predict_svm": 2,
      "kmeans.labels_": 2,
      "m.predict(xs)": 2,
      "viterbi_state": 2,
      "clf['best_estimator'].predict(X)": 2,
      "clf.predict(X)": 2,
      "predicted_train": 2,
      "predict_test": 2,
      "predictions_NN_01": 2,
      "pred_val_y": 2,
      "Predictions": 2,
      "list(map(lambda v: v > 0.5, y_hat_4))": 2,
      "model.predict(X_val)": 2,
      "rfc_y_pred": 2,
      "pred.values": 2,
      "model.predict(selected_x_val)": 2,
      "y_train_predict": 2,
      "y_val_predict": 2,
      "y_vad": 2,
      "train_oof_preds": 2,
      "rf.predict(x_test)": 2,
      "np.argmax(probabilities, axis=-1)": 2,
      "np.argmax(oof_prediction, axis=-1)": 2,
      "y_pred_round": 2,
      "pred.argmax(axis=1)": 2,
      "prediction.astype('int32')": 2,
      "test_pred_proba.argmax(1)": 2,
      "log_preds": 2,
      "xgb_preds": 2,
      "rf_preds": 2,
      "Y_prediction_RF": 2,
      "train_ckwe['pred'].values": 2,
      "predicted_label": 2,
      "OG": 2,
      "YOne": 2,
      "y_pred_acc": 2,
      "predknn": 2,
      "predict_gbm": 2,
      "ans_train": 2,
      "label_predict": 2,
      "y_pred_test_forest": 2,
      "rf_predicted": 2,
      "predictions_count": 2,
      "YtestPred": 2,
      "y_predict_lgb": 2,
      "y_pred_LR": 2,
      "logit_val_pred": 2,
      "forest_val_pred": 2,
      "test_prediction_mult": 2,
      "[int(pred_prob > 0) for pred_prob in test_prediction]": 2,
      "[int(pred_prob > 0) for pred_prob in test_prediction2]": 2,
      "vw_pred": 2,
      "test_pred_ada": 2,
      "hotstar['sentiment_vader']": 2,
      "check": 2,
      "predict_train": 2,
      "search.predict(x_train)": 2,
      "search.predict(x_valid)": 2,
      "predicao": 2,
      "y_pred_clf": 2,
      "Y_validation": 2,
      "control_predictions": 2,
      "train_prediction": 2,
      "(oof > 0.5).astype(int)": 2,
      "valid_pred.argmax(axis=1)": 2,
      "y_rf_pred": 2,
      "y_gb_pred": 2,
      "new_predictions": 2,
      "y_pred_with_gaussian": 2,
      "y_pred_with_gaussian_and_deskew": 2,
      "train_actions": 2,
      "val_actions": 2,
      "y_validate": 2,
      "train_labels.label": 2,
      "predictions_fat": 2,
      "val.target": 2,
      "y_prima": 2,
      "v.predict(xtest)": 2,
      "pre": 2,
      "y_val_hat": 2,
      "ada_pred": 2,
      "y_pred_test_lr": 2,
      "Y_val_classes": 2,
      "preds_dict['grapheme_root']": 2,
      "preds_dict['vowel_diacritic']": 2,
      "preds_dict['consonant_diacritic']": 2,
      "y_pred_batch": 2,
      "batch_y.cpu().numpy()": 2,
      "lr.predict(train[features])": 2,
      "val_outputs": 2,
      "label": 2,
      "predictionc": 2,
      "y_validation": 2,
      "y_oof[val_idx].round()": 2,
      "roc_predictions": 2,
      "y_pred_new": 2,
      "rfc_y_pred1": 2,
      "rfc_y_pred2": 2,
      "rfc_y_pred3": 2,
      "oof_train[valid_index]": 2,
      "oof.round()": 2,
      "predictions.round()": 2,
      "train.target": 2,
      "np.argmax(p_valid[-1], axis=1)": 2,
      "Y_pred_cls": 2,
      "gbm.predict(test[feats])": 2,
      "y_pred_gs": 2,
      "y_pred_rs": 2,
      "pred[:self.lentrain]": 2,
      "y_train_pred_final.predicted": 2,
      "test_pred_gb": 2,
      "pred_results['predicted']": 2,
      "prediction_tuned_linear_svc": 2,
      "prediction_tuned_logistic_regression": 2,
      "prediction_tuned_extra_trees": 2,
      "prediction_tuned_random_forest": 2,
      "predicted_x[:, 0]": 2,
      "predicted_x[:, 1]": 2,
      "np.array(final_outputs).argmax(axis=1)": 2,
      "y_pre_LogR": 2,
      "y_pre_KNN": 2,
      "y_pre_RF": 2,
      "val_label_batch": 2,
      "predictions_1": 2,
      "y_pred_bagclf": 2,
      "y_pred_abc": 2,
      "y_pred_xbc": 2,
      "ytrain_pred": 2,
      "y[test_index]": 2,
      "pred_gbm": 2,
      "pred_lgbm": 2,
      "pred_nn": 2,
      "rf_prediction": 2,
      "val_preds_class": 2,
      "NB_pred": 2,
      "y_pred_nb": 2,
      "predx": 2,
      "label.cpu().detach().numpy()": 2,
      "oof[val_idx].round()": 2,
      "ans1": 2,
      "np.where(xg_train_preds <= 0.5, 0, 1)": 2,
      "lgbm_train_preds": 2,
      "np.where(lg_train_preds <= 0.5, 0, 1)": 2,
      "np.where(rf_train_preds <= 0.5, 0, 1)": 2,
      "cb_train_preds": 2,
      "y_pred_gb": 2,
      "y_pred_ab": 2,
      "model.predict(x_train)": 2,
      "prediction['Multinomial']": 2,
      "pred_rdf": 2,
      "lg_pl.predict(data.loc['validation'])": 2,
      "np.round(y_pre)": 2,
      "best_predictions": 2,
      "pred_validation > 0.5": 2,
      "Ypredict": 2,
      "model_xgb.predict(data=X_train)": 2,
      "lgb_measured[val_idx].argmax(1)": 2,
      "dt.predict(X_train)": 2,
      "lr_y_pred": 2,
      "y_pred9": 2,
      "lgb_cv_preds": 2,
      "rf_cv_preds": 2,
      "pred_test_MNB": 2,
      "(oof_preds[val_idx] > 0.5).astype(int)": 2,
      "y_pred_xgboost.round()": 2,
      "labels_test": 2,
      "predictionsDogs": 2,
      "predictionsCats": 2,
      "y_pred_LogReg": 2,
      "y_pred_DTR": 2,
      "yt_pred": 2,
      "y_pred > threshold": 2,
      "y1": 2,
      "model.predict(X_validation)": 2,
      "np.round(preds_one_val)": 2,
      "np.round(preds_two_val)": 2,
      "np.round(preds_one_train)": 2,
      "np.round(preds_two_train)": 2,
      "np.round(preds_one)": 2,
      "np.round(preds_two)": 2,
      "np.round(ensemble)": 2,
      "y_pred > 0.5": 2,
      "ypred1": 2,
      "np.round(val_preds)": 2,
      "fold_pred": 2,
      "cat_pred": 2,
      "np.argmax(val_preds[val_idx, :], axis=1)": 2,
      "cv_p1_y": 2,
      "val_df['label']": 2,
      "np.where(train_preds > 0.5, 1, 0)": 2,
      "np.array(vp)": 2,
      "pred.reshape((762, 1))": 2,
      "y_pred_conf_valid_binary": 2,
      "(df_train.loc[:, 'y_mle_pred'] > 0.5) * 1": 2,
      "(df_train.loc[:, 'y_map_pred'] > 0.5) * 1": 2,
      "(df_valid.loc[:, 'y_mle_pred'] > 0.5) * 1": 2,
      "(df_valid.loc[:, 'y_map_pred'] > 0.5) * 1": 2,
      "y1_predicted": 2,
      "xgb_model.predict(X_train)": 2,
      "xgb_model.predict(X_test)": 2,
      "y_pred_vote": 1,
      "y_pred_gbm": 1,
      "pred > 0.66": 1,
      "predict_svc": 1,
      "mnb_tr_pred_value": 1,
      "mnb_val_pred_value": 1,
      "eval_table['pred_target']": 1,
      "(pred >= 0.5) * 1": 1,
      "(valid_score >= 0.5) * 1": 1,
      "(train_pred['valid'] >= 0.5) * 1": 1,
      "np.append(np.where(prediction < 0.5, 0, 1), (1, 0))": 1,
      "train_df['predictions']": 1,
      "predictor": 1,
      "y_pred_lgbm.round()": 1,
      "predictions_DCmodel_1": 1,
      "predictions_LSTM_model_1": 1,
      "predictions_DCmodel_2": 1,
      "predictions_LSTM_model_2": 1,
      "predictions_DCmodel_3": 1,
      "predictions_LSTM_model_3": 1,
      "np.where(y_pred > 0.56, 1, 0)": 1,
      "knn_predictions": 1,
      "random_predictions": 1,
      "bayes_predictions": 1,
      "nbg.predict(x_test)": 1,
      "dt.predict(x_test)": 1,
      "melb_preds": 1,
      "train.cuisine": 1,
      "lgbc.predict(X_test)": 1,
      "LogisticRegressionModel.predict(train_data)": 1,
      "KNeighborsModeL.predict(train_data)": 1,
      "RandomForestModeL.predict(train_data)": 1,
      "mlp_predict": 1,
      "train_pred_lr": 1,
      "test_pred_lr": 1,
      "my_pipeline.predict(x_train)": 1,
      "my_pipeline.predict(x_valid)": 1,
      "g.best_estimator_.predict(x_train)": 1,
      "vote_clf.predict(x_train)": 1,
      "my_model.predict(x_train_mod)": 1,
      "y_lda_pred": 1,
      "log_pred": 1,
      "dtree_predict": 1,
      "random_forest_predict": 1,
      "xgboost_pred": 1,
      "y_pred_NN": 1,
      "y_pred_max": 1,
      "dtest_Y": 1,
      "rfc.predict(x_test)": 1,
      "xgb.predict(x_test)": 1,
      "lgbm.predict(x_test)": 1,
      "gbc.predict(test[feats])": 1,
      "model3.predict(x_test_val)": 1,
      "y_pred.T": 1,
      "train_pred_labels": 1,
      "test_pred_labels": 1,
      "pred_list": 1,
      "predicted_score": 1,
      "XG_test_all['XG prediction'].round()": 1,
      "(train_pred > 0.5).astype(int)": 1,
      "(val_pred > 0.5).astype(int)": 1,
      "(oof_pred > 0.5).astype(int)": 1,
      "(oof_preds_1 > 0.5).astype(int)": 1,
      "(oof_preds_2 > 0.5).astype(int)": 1,
      "(comb_pred > 0.5).astype(int)": 1,
      "test_t_prediction": 1,
      "knn9_pred": 1,
      "pr": 1,
      "ypredict": 1,
      "dig_labels": 1,
      "rf_predict": 1,
      "NB_predict": 1,
      "ytest.loc[diff_test1.index]": 1,
      "ytest.loc[diff_test2.index]": 1,
      "ytest.loc[diff_test3.index]": 1,
      "ytest.loc[diff_test4.index]": 1,
      "rfg_pred": 1,
      "preds >= 0.5": 1,
      "y_val_test": 1,
      "y_batch_predicted_np": 1,
      "full_predictions_svc": 1,
      "full_predictions": 1,
      "y_train.iloc[indices]": 1,
      "y_pred_changed": 1,
      "y_preds_gnb": 1,
      "y_preds_cat": 1,
      "y_preds_lr": 1,
      "RF_classifier.predict(X_train)": 1,
      "output_for_acc": 1,
      "output_for_accv": 1,
      "pred_xg": 1,
      "PredictedY": 1,
      "np.argmax(validation_outputs, axis=1)": 1,
      "test_target_raw": 1,
      "logreg_pred": 1,
      "tahmin": 1,
      "predictions_rf": 1,
      "random_forest1.predict(X=input_data[input_vars])": 1,
      "nbg.predict(X_test)": 1,
      "xgb.predict(X_test)": 1,
      "np.array(y_pred_valid).argmax(1)": 1,
      "np.round(np.argmax(model.predict(X_valid), axis=1)).astype(int)": 1,
      "RandomForestModel.predict(X_test)": 1,
      "LGBMModel.predict(X_test)": 1,
      "XGBModel.predict(X_test)": 1,
      "AdaBoostModel.predict(X_test)": 1,
      "RandomForestModel2.predict(X_test)": 1,
      "LGBMModel2.predict(X_test)": 1,
      "XGBModel2.predict(X_test)": 1,
      "AdaBoostModel2.predict(X_test)": 1,
      "votingModel.predict(X_test)": 1,
      "BlenderModel.predict(Blend_X)": 1,
      "LogisticRegressionModel.predict(X_test)": 1,
      "DecisionTreeModel.predict(X_test)": 1,
      "KNeighborsClassifierModel.predict(X_test)": 1,
      "GaussianNBModel.predict(X_test)": 1,
      "RandomForestClassifierModel.predict(X_test)": 1,
      "le.inverse_transform(pred_test)": 1,
      "le.inverse_transform(pred_test_kfold)": 1,
      "tf_prediction": 1,
      "Y_prediction": 1,
      "Y_knn_Pred": 1,
      "Y_log_Pred": 1,
      "predictiion": 1,
      "predictions_XG": 1,
      "SVM_cnt_pred_tr_rbf": 1,
      "SVM_cnt_pred_tr_lin": 1,
      "pred_logreg": 1,
      "pred_gnb": 1,
      "pred_linsvc": 1,
      "pred_XGB": 1,
      "pred_BBC": 1,
      "TPre": 1,
      "LPre": 1,
      "NPre": 1,
      "cls_predictions": 1,
      "y_preds2": 1,
      "y_predDT": 1,
      "y_predDT1": 1,
      "y_predDT2": 1,
      "y_predSVM1": 1,
      "y_predSVM2": 1,
      "y_predLR1": 1,
      "y_predLR2": 1,
      "pred_KNN1": 1,
      "pred_KNN2": 1,
      "clf.predict(normalized_test_X)": 1,
      "best_CLF.predict(X_test)": 1,
      "LR_best.predict(X_test)": 1,
      "RF_best.predict(X_test)": 1,
      "KNN_best.predict(X_test)": 1,
      "predictionslsv": 1,
      "predictionslr": 1,
      "LSTM_yhat_test": 1,
      "GRU_yhat_test": 1,
      "RandomForestClassifier_yhat_train": 1,
      "SGDClassifier_yhat_train": 1,
      "MultinomialNB_yhat_train": 1,
      "sepcnn_yhat_test": 1,
      "df_preds_train[c]": 1,
      "np.where(pred_LSTM > 0.5, 1, 0)": 1,
      "np.where(pred_CNN_LSTM > 0.5, 1, 0)": 1,
      "np.where(pred_LSTM_FC > 0.5, 1, 0)": 1,
      "pred_bert": 1,
      "np.argmax(pred_Y1, axis=1)": 1,
      "np.argmax(pred_Y2, axis=1)": 1,
      "np.argmax(pred_Y3, axis=1)": 1,
      "ysp_pred": 1,
      "pred_press": 1,
      "pred_normal": 1,
      "pred_soft": 1,
      "pred > 0.5": 1,
      "y_final": 1,
      "rand_y_pred": 1,
      "kNC_y_predict": 1,
      "dec_predict": 1,
      "valid_preds_rf": 1,
      "valid_preds_xgb_single": 1,
      "valid_preds_best": 1,
      "prediccion": 1,
      "train_y_predicted": 1,
      "model_rf1.predict(x_valid)": 1,
      "model_rf2.predict(x_valid)": 1,
      "model_rf3.predict(x_valid)": 1,
      "model_extra1.predict(x_valid)": 1,
      "model_extra2.predict(x_valid)": 1,
      "model_extra3.predict(x_valid)": 1,
      "model_extra4.predict(x_valid)": 1,
      "model_extra5.predict(x_valid)": 1,
      "model_extra6.predict(x_valid)": 1,
      "y_hat1": 1,
      "Y.argmax(1).long()": 1,
      "sdg": 1,
      "linsvc": 1,
      "predic": 1,
      "onevsall": 1,
      "logreg": 1,
      "final_res": 1,
      "y_pred_model_1": 1,
      "preds_dig": 1,
      "titanic_labels": 1,
      "xgb.predict(train[feats])": 1,
      "abc.predict(train[feats])": 1,
      "previsoes": 1,
      "pred_ens": 1,
      "(train2['o' + str(k)].values > 0.5).astype(int)": 1,
      "(train2[['o1', 'o2', 'o3', 'o4']].values > 0.5).astype(int).reshape(-1)": 1,
      "preds0": 1,
      "preds1": 1,
      "preds2": 1,
      "yvl": 1,
      "gbk_predict": 1,
      "y_predR": 1,
      "tf_clf_dnn.predict(X_test)": 1,
      "y_test1": 1,
      "(tr_pred > best_thresh).astype(int)": 1,
      "pred_results": 1,
      "log_clf.predict(TestData)": 1,
      "lda.predict(TestData)": 1,
      "gnb.predict(TestData)": 1,
      "knn.predict(TestData)": 1,
      "svm.predict(TestData)": 1,
      "dt.predict(TestData)": 1,
      "rf.predict(TestData)": 1,
      "adb.predict(TestData)": 1,
      "gb.predict(TestData)": 1,
      "log_pre": 1,
      "rfcl_pre": 1,
      "gbcl_pre": 1,
      "y_pred_RF_class": 1,
      "predXB": 1,
      "bert_pred_df.pred_label.values": 1,
      "xlmbase_pred_df.pred_label.values": 1,
      "xlmlarge_pred_df.pred_label.values": 1,
      "majority_voting_df.majority.values": 1,
      "weighted_voting_df.majority.values": 1,
      "averaged_prob_df.pred_label.values": 1,
      "weighted_prob_df.pred_label.values": 1,
      "np.round(predictions).astype('int32')": 1,
      "y_val_pre": 1,
      "y_val_pre2": 1,
      "ys": 1,
      "yloh": 1,
      "yhih": 1,
      "best_fit_mod24.predict(X24)": 1,
      "best_fit_mod48.predict(X48)": 1,
      "best_fit_model.predict(X72)": 1,
      "yp24": 1,
      "yp48": 1,
      "yp72": 1,
      "gnb.predict(x)": 1,
      "y_preds_series": 1,
      "sclf.predict(testing_data_final)": 1,
      "train.label.values[idxV]": 1,
      "train.label.values": 1,
      "y_train_pred1": 1,
      "y_train_pred2": 1,
      "y_train_pred3": 1,
      "y_train_pred4": 1,
      "y_train_pred5": 1,
      "y_train_pred6": 1,
      "y_train_maj_vot_pred": 1,
      "test_split.iloc[:, column].values": 1,
      "pred_dtc": 1,
      "pred_rfc": 1,
      "pred_lr": 1,
      "pred_MNB": 1,
      "pred_br": 1,
      "pred_ga": 1,
      "pred_ada": 1,
      "y_val_word": 1,
      "y_val_char": 1,
      "kfold_val_output": 1,
      "tr_preds": 1,
      "pred_bool": 1,
      "y_pred.round(0).astype(int)": 1,
      "prediction7": 1,
      "preds_val": 1,
      "rf_predict_resampled": 1,
      "output_df['prediction'].tolist()": 1,
      "predxg": 1,
      "shelter_dt_3.predict(X_train_dm)": 1,
      "shelter_dt_5.predict(X_train_dm)": 1,
      "shelter_dt_20.predict(X_train_dm)": 1,
      "shelter_dt_1.predict(X_train_dm_1)": 1,
      "y_train_1": 1,
      "y_test_1": 1,
      "np.where(predict > 0.5, 1, 0)": 1,
      "np.where(predict > threshold, 1, 0)": 1,
      "y_test_with_ori": 1,
      "y_test_without_ori": 1,
      "np.where(h_preds_.isFraud > 0.5, 1, 0)": 1,
      "cat.predict(train)": 1,
      "p_pred": 1,
      "prediction_lg": 1,
      "xgdpredictions": 1,
      "testy": 1,
      "np.array(submission['target']).reshape(-1, 1)": 1,
      "random_forest1.predict(X=df1[input])": 1,
      "estimator.predict(X_val)": 1,
      "lr.predict(x_test)": 1,
      "lr.predict(x_train)": 1,
      "lr.predict(df[:len(train)])": 1,
      "rforest_val_pred": 1,
      "lgb_pred": 1,
      "ex_val_pred": 1,
      "predict_dtc": 1,
      "predict_nn_plp": 1,
      "data_submittion": 1,
      "rf.predict(X_valid_sm)": 1,
      "xgb.predict(X_valid_sm)": 1,
      "y_pred_valid.round()": 1,
      "y_predict_nb": 1,
      "y_predict_lr": 1,
      "ad.predict(train_X)": 1,
      "ad.predict(test_X)": 1,
      "char_clf.predict(x_test_char)": 1,
      "combined_predictions": 1,
      "y_predictions_final": 1,
      "predicted_2": 1,
      "predicted_3": 1,
      "vote.predict(X)": 1,
      "y_pred_logistic": 1,
      "y_pred_M": 1,
      "y_pred_B": 1,
      "pred_76": 1,
      "pred_86": 1,
      "pred_56": 1,
      "pred_46": 1,
      "model.predict(X_t3gram_vectorizer_test)": 1,
      "gs.predict(X_t3gram_vectorizer_test)": 1,
      "cv_pred": 1,
      "train_df['predicted_result']": 1,
      "(preds[..., i] > 0.2).byte().cpu().numpy().flatten()": 1,
      "yp_train > 0.5": 1,
      "yp_val > 0.5": 1,
      "yp_test > 0.5": 1,
      "rf.predict(train[feats])": 1,
      "xgb.predict(heads2[feats])": 1,
      "abc.predict(heads2[feats])": 1,
      "y_pred_train_hyper": 1,
      "y_pred_hyper": 1,
      "y_train_predicted": 1,
      "np.where(wt_avg > 0.5, 1, 0)": 1,
      "np.where(yp_val >= 0.5, 1, 0)": 1,
      "logiPred": 1,
      "knnPrediction": 1,
      "DTCPreds": 1,
      "RMPreds": 1,
      "y_preds_rand": 1,
      "viterbi_predictions": 1,
      "pos_dec_predictions": 1,
      "np.argmax(to_np(preds), axis=1)": 1,
      "test_images['predict_labels']": 1,
      "logistic_model.predict(X_train)": 1,
      "svm_model.predict(X_train)": 1,
      "KNN_model.predict(X_train)": 1,
      "logistic_model2.predict(X_train)": 1,
      "svm_model2.predict(X_train)": 1,
      "KNN_model2.predict(X_train)": 1,
      "np.rint(y_pred)": 1,
      "m_pred": 1,
      "oof_df.loc[oof_df.iloc[val_idx].index]['oof']": 1,
      "oof_df.oof": 1,
      "predi": 1,
      "predict_y.data": 1,
      "va_pred_a": 1,
      "ln.predict(X_test)": 1,
      "np.where(oof_proba[:, 1] > 0.5, 1, 0)": 1,
      "np.where(oof[valid_idx] > THRESHOLD, 1, 0)": 1,
      "np.where(oof > THRESHOLD, 1, 0)": 1,
      "oof[valid_idx]": 1,
      "eval_pred_class": 1,
      "model.predict(x_train[test_idx])": 1,
      "y.cpu().numpy()": 1,
      "np.array(all_preds).flatten()": 1,
      "y_vld": 1,
      "model.predict(x_train_x)": 1,
      "model.predict(x_train_v)": 1,
      "result['pred']": 1,
      "lang_result['pred']": 1,
      "clf2.predict(tsiftdatax_test)": 1,
      "kmlp.predict_classes(x_train)": 1,
      "lgb_train_preds": 1,
      "scores": 1,
      "np.argmax(test_pred[0], axis=1)": 1,
      "y_Pred": 1,
      "result_test": 1,
      "df_Predicciones['Resultado_Stacking']": 1,
      "oof_pred[-1]": 1,
      "res": 1,
      "df['diagnosis']": 1,
      "model.predict(X_)": 1,
      "tree_preds": 1,
      "ada_preds": 1,
      "voting_preds": 1,
      "Y_pred_grid": 1,
      "multilabel_model.predict(X_test)": 1,
      "y_val1": 1,
      "df_train_pred[target]": 1,
      "y_predictions": 1,
      "train_pred_output": 1,
      "y_val.sum(axis=1) - 1": 1,
      "y_pred_acctrain": 1,
      "neigh.predict(X_train_)": 1,
      "predTree": 1,
      "predictions_lgbm_valdf": 1,
      "pred_LR": 1,
      "pred_SVC": 1,
      "pred_MultinomialNB": 1,
      "rs_pred_img.reshape(1, -1)[0]": 1,
      "np.round(pred_val_best)": 1,
      "np.round(pred_val_best_tta)": 1,
      "np.round(pred_val_best_avg)": 1,
      "np.round(p_tta)": 1,
      "np.round(pred_val_ens_meta)": 1,
      "np.round(pred_val_ens_avg)": 1,
      "y_pred_test_tree": 1,
      "y_pred_test_knn": 1,
      "RFC_pred_y_bin": 1,
      "LGBM_pred_y_bin": 1,
      "nbpred": 1,
      "knn_predicted": 1,
      "scv_predicted": 1,
      "y_rf": 1,
      "te_predictions": 1,
      "ass_val_floors": 1,
      "X_ass_val['blended_floor_pred']": 1,
      "y_pred_xgb_bal": 1,
      "y_pred_bal": 1,
      "lr_oof[oof_idx, fold // N_SPLITS]": 1,
      "lr_oof[:, fold // N_SPLITS]": 1,
      "self.y_pred": 1,
      "oof_valid_preds": 1,
      "y_pred_oof": 1,
      "Y_test_prediction": 1,
      "Y_train_prediction": 1,
      "model.predict(train_csv_data[columns_with_numbers])": 1,
      "predicts": 1,
      "y_predd": 1,
      "y_preddd": 1,
      "y_pr": 1,
      "lgb_clf.predict(X_valid)": 1,
      "grid_searcher.predict(X_valid)": 1,
      "grid_searcher2.predict(X_valid)": 1,
      "test_pred_wv": 1,
      "yelp['sentiment_vader']": 1,
      "y_predmlp": 1,
      "y_predX": 1,
      "torch.tensor(lst_out)": 1,
      "torch.tensor(lst_val_out)": 1,
      "y_val2": 1,
      "y_train_star": 1,
      "tx_valid_df['content_category']": 1,
      "predict_cv": 1,
      "traget_prediction": 1,
      "np.array(y_valid_hat > 0.5).astype(int)": 1,
      "test_pred_tfid_mnb": 1,
      "open_channels": 1,
      "output_pred": 1,
      "start_preds": 1,
      "end_preds": 1,
      "class_preds": 1,
      "knn.predict(X_train)": 1,
      "nb.predict(X_train)": 1,
      "predics": 1,
      "pred_new": 1,
      "y_pred_PCA": 1,
      "(rf_wrapper.predict_proba(X_valid)[:, 1] > 0.5).astype(int)": 1,
      "(gbc_wrapper.predict_proba(X_valid)[:, 1] > 0.5).astype(int)": 1,
      "(lgbm_wrapper.predict_proba(X_valid)[:, 1] > 0.5).astype(int)": 1,
      "cat_model.predict(X_valid)": 1,
      "np.where(y_tabNet_pred > 0.42, 1, 0)": 1,
      "p_test.argmax(axis=1)": 1,
      "np.argmax(p_test.values, axis=1)": 1,
      "np.argmax(y_pred.values, axis=1)": 1,
      "p_valid.argmax(axis=1)": 1,
      "p_test[:, 1] >= 0.5": 1,
      "oof_predicts": 1,
      "clf2.predict(X_test_vect)": 1,
      "y_xception_pred": 1,
      "y_vgg16_pred": 1,
      "y_resnet50_pred": 1,
      "y_svc_pred": 1,
      "np.array(pred_labels) >= 0.5": 1,
      "Y_test_clf": 1,
      "result_0": 1,
      "new_y_pred": 1,
      "np.argmax(dig_label_transform, axis=1)": 1,
      "dig_label": 1,
      "np.array(validate_labels)": 1,
      "train_df['target']": 1,
      "val['target']": 1,
      "test_y_POS": 1,
      "test_y_NEG": 1,
      "lgbm_pred.round()": 1,
      "previsao_dummy": 1,
      "c.predict(x[test_index])": 1,
      "Pred_Cuisine": 1,
      "(pred_label > 0.5).astype(int)": 1,
      "oof > 0.5": 1,
      "(oof > 0).astype(int)": 1,
      "(preds > 0).astype(int)": 1,
      "(preds > 0.5).astype(int)": 1,
      "y_pred_en": 1,
      "np.argmax(oof_val_all[num_model], axis=-1)": 1,
      "np.argmax(oof_val_all.mean(0), axis=1)": 1,
      "oof_preds_rf0": 1,
      "oof_preds_rf": 1,
      "oof_preds_xgb0": 1,
      "oof_preds_xgb": 1,
      "Y_valid1_int": 1,
      "y_test_split": 1,
      "better_pred": 1,
      "y_gbclf": 1,
      "y_rfclf": 1,
      "y_knclf": 1,
      "y_etclf": 1,
      "y_xgclf": 1,
      "predicted_test_response": 1,
      "h_test": 1,
      "labels_flat": 1,
      "predictions.astype(int)": 1,
      "clf.predict(heads[feats])": 1,
      "cbc.predict(test[feats])": 1,
      "rf.predict(heads[feats])": 1,
      "torch.round(test_pred2)": 1,
      "list(np.round(np.array(model_pipeline.predict(X_valid_filtered)), 0))": 1,
      "nlp_pipeline.predict(X_test)": 1,
      "rf.predict(train_x)": 1,
      "rf.predict(test_x)": 1,
      "b['50%+50%']": 1,
      "b2020['50%+50%']": 1,
      "b2019['50%+50%']": 1,
      "test['Rnxt']": 1,
      "test['Effn']": 1,
      "test['50%+50%']": 1,
      "test['label']": 1,
      "y_pred_1": 1,
      "predicoes1": 1,
      "predicoes2": 1,
      "train_df_all.predict_outliers": 1,
      "evaluate_ensemble(oof_predictions_v3, c)": 1,
      "predictions.tolist()": 1,
      "Y_pred_linear_svc": 1,
      "preddt": 1,
      "lr.predict(X_train_reduced)": 1,
      "lr.predict(X_test_reduced)": 1,
      "clf_nb.predict(X_test)": 1,
      "clf_svm.predict(X_test)": 1,
      "tree.predict(X_test)": 1,
      "SVMperc": 1,
      "a.predict(xtest)": 1,
      "model.predict(xtest1)": 1,
      "model.predict(xtest)": 1,
      "x_test['predicted_country']": 1,
      "np.argmax(outputs_all, axis=1)": 1,
      "lstm_pred": 1,
      "y_pred_RF": 1,
      "ypred_RN": 1,
      "predictions_3": 1,
      "opt_val_predictions": 1,
      "rand_f1.predict(X_val[['var_5']])": 1,
      "rf.predict(X_val)": 1,
      "rf_1.predict(test_all)": 1,
      "rf_2.predict(test_all)": 1,
      "y_pred_test_LR": 1,
      "y_pred_test_gnb": 1,
      "logregpredict": 1,
      "svmpredict": 1,
      "LogisticRegression().fit(X_train, y_train).predict(X_test)": 1,
      "probs": 1,
      "y_predicted_label": 1,
      "(y_val_prob[:, 1] > best_cut['best_prob']).astype(int)": 1,
      "y_full_oof": 1,
      "prediction_": 1,
      "yhat_lr": 1,
      "valid_y": 1,
      "dt_pred": 1,
      "count_nb_pred": 1,
      "count_bnb_pred": 1,
      "count_lsvc_pred": 1,
      "count_svc_pred": 1,
      "count_nusvc_pred": 1,
      "count_sgd_pred": 1,
      "count_lr_pred": 1,
      "dt_prediction": 1,
      "lr_prediction": 1,
      "svc_prediction": 1,
      "bnb_predictions": 1,
      "prediction_mn": 1,
      "svm_predictions": 1,
      "Logreg_predictions": 1,
      "ensemble_predictions": 1,
      "logist_predicted": 1,
      "[round(float(i)) for i in pred_noemb_val_y]": 1,
      "predictedForest": 1,
      "y_preds1": 1,
      "y_preds3": 1,
      "y_preds4": 1,
      "y_preds6": 1,
      "predict_abc": 1,
      "predict_y_gbm": 1,
      "np.argmax(oof[class_cols].values, axis=1)": 1,
      "train_predictions_gbc": 1,
      "test_predictions_gbc": 1,
      "yhat_classes": 1,
      "clf_pred": 1,
      "rf_aug_pred": 1,
      "kn_aug_pred": 1,
      "default_kn": 1,
      "yR_predict": 1,
      "mnb_classifier.predict(train_features)": 1,
      "mnb_prediction": 1,
      "dt.predict(train[features])": 1,
      "lreg_prediction": 1,
      "inp_ind": 1,
      "test['y_pred']": 1,
      "MLP1_preds": 1,
      "MLP2_preds": 1,
      "MLP3_preds": 1,
      "MLP4_preds": 1,
      "pref_y_bin": 1,
      "predictions_LR": 1,
      "predictions_DTC": 1,
      "predictions_SVC": 1,
      "predictions_RFC": 1,
      "predictions_KNC": 1,
      "y_proba >= 0.5": 1,
      "np.array(train_preds_) > tmp[0]": 1,
      "valid0.place_id": 1,
      "y_predoverbag": 1,
      "y_pred_dtr": 1,
      "y_pred_xgb_simple": 1,
      "y_pred_bow": 1,
      "y_pred_bow2": 1,
      "y_pred_tfidf": 1,
      "y_pred_tfidf4": 1,
      "y_pred_stem_dt": 1,
      "y_pred_lemma_dt": 1,
      "pred_stem_xg": 1,
      "pred_lemma_xg": 1,
      "each_predict_result": 1,
      "val_preds.cpu()": 1,
      "pred_RF": 1,
      "clf.predict(xtest)": 1,
      "knn_cls.predict(X_test)": 1,
      "svr_pred": 1,
      "yPredict": 1,
      "label_acc": 1,
      "pred[:, 1] > 0.5": 1,
      "outcome_var": 1,
      "y_pred_": 1,
      "predict_train_gs": 1,
      "predict_test_gs": 1,
      "val_true": 1,
      "labels.detach().cpu().numpy()": 1,
      "pred_RFC": 1,
      "ls": 1,
      "list(prediction)": 1,
      "sample_y_pred": 1,
      "testpred": 1,
      "pred_dichotom": 1,
      "y_m1pred": 1,
      "y_m2pred": 1,
      "y_pred_mbet": 1,
      "y_pred_mbrf": 1,
      "y_pred_mxgB": 1,
      "y_mpred_lgbm": 1,
      "y_valid_preds": 1,
      "nu_train_predictions": 1,
      "rf_train_prediction": 1,
      "nu_test_predict": 1,
      "targs": 1,
      "train_pred_label": 1,
      "TARGET": 1,
      "np.argmax(all_preds, axis=1)": 1,
      "y_pred_down_C_cv": 1,
      "y_pred_down_C_tfidf": 1,
      "log_reg1.predict(X_train)": 1,
      "log_reg1.predict(X_test)": 1,
      "log_reg_sig.predict(X_train)": 1,
      "log_reg_sig.predict(X_test)": 1,
      "final_preds": 1,
      "nb_y_pred": 1,
      "KNN_pred": 1,
      "LR_pred": 1,
      "GNB_pred": 1,
      "DTC_pred": 1,
      "XGB_pred": 1,
      "Y_hat": 1,
      "val_y_pred": 1,
      "temp": 1,
      "temp_D": 1,
      "df_hotstar['Sentiment_Vader']": 1,
      "test_pred_gnb": 1,
      "test_pred_bnb": 1,
      "rf_pred_test": 1,
      "rf_pred_train_2": 1,
      "rf_pred_test_2": 1,
      "rf_pred_train_3": 1,
      "rf_pred_test_3": 1,
      "rf_pred_train_4": 1,
      "rf_pred_test_4": 1,
      "rf_pred_train_5": 1,
      "rf_pred_test_5": 1,
      "rf_pred_train_6": 1,
      "rf_pred_test_6": 1,
      "rf_pred_train_7": 1,
      "rf_pred_test_7": 1,
      "rf_pred_train_8": 1,
      "rf_pred_test_8": 1,
      "rf_pred_train_9": 1,
      "rf_pred_test_9": 1,
      "predict_valid_class": 1,
      "predictions_tuned_linear_svc": 1,
      "predictions_tuned_logistic_regression": 1,
      "predictions_tuned_extra_trees": 1,
      "predictions_tuned_random_forest": 1,
      "pred_tuned_mode": 1,
      "Predicted": 1,
      "Predictedlda": 1,
      "val_predlabels": 1,
      "y_pred.T[i]": 1,
      "np.array(outputs_reduced.cpu()).argmax(axis=1)": 1,
      "np.array(outputs_reduced).argmax(axis=1)": 1,
      "Ypred_lr": 1,
      "Ypred_svc": 1,
      "Ypred_dt": 1,
      "train['signal_tr']": 1,
      "y_pred_sgd_clf": 1,
      "y_pred_sgd_clf_log": 1,
      "y_test_pred_rfc": 1,
      "y_test_pred_svm": 1,
      "y_pred_votclf": 1,
      "nn_predictions": 1,
      "l": 1,
      "XGB_classifier_predict_smote": 1,
      "prediction_train": 1,
      "prediction_train_1": 1,
      "stack_ytrain_pred": 1,
      "predictions.pred_baseline": 1,
      "predictions.lgb_action": 1,
      "pred_glove_train_y > thresh_train": 1,
      "pred_glove_val_y > thresh_valid": 1,
      "pred_caret": 1,
      "test_v['Target_Ensembled_predictions']": 1,
      "pred_sklearn": 1,
      "pred_tpot": 1,
      "pred_hyperopt": 1,
      "pred_keras": 1,
      "pred_keras_": 1,
      "pred_mljar": 1,
      "gluon_pred": 1,
      "h2o_pred_": 1,
      "sele_pred": 1,
      "y_pred_rf_best": 1,
      "y_pred_rf_gsv": 1,
      "prediction_logistic": 1,
      "ab_prediction": 1,
      "SDG_pred": 1,
      "model1.predict(test_x)": 1,
      "model2.predict(test_x)": 1,
      "val_predictions": 1,
      "dev_y": 1,
      "np.array(y_pred) > 0": 1,
      "y_valid_predict": 1,
      "Y_pred_rbf": 1,
      "Y_pred_Fine_tune_HyperParmeters": 1,
      "pred21": 1,
      "pred22": 1,
      "predict_rfd": 1,
      "predict_rfb": 1,
      "predict_cbc": 1,
      "clf.predict(n_x_val)": 1,
      "f_pred": 1,
      "test_nlp[target].values": 1,
      "preds_random": 1,
      "preds_random_imba": 1,
      "y_predx": 1,
      "preds_2": 1,
      "train_labels": 1,
      "validation_df[prediction_column_scaled].values": 1,
      "outputs.cpu()": 1,
      "pred_5": 1,
      "yp2": 1,
      "anser_test_one_zero": 1,
      "np.where(xg_test_preds <= 0.5, 0, 1)": 1,
      "np.where(lg_test_preds <= 0.5, 0, 1)": 1,
      "np.where(rf_test_preds <= 0.5, 0, 1)": 1,
      "np.where(cb_train_preds <= 0.5, 0, 1)": 1,
      "np.where(lvl2_train_preds <= 0.5, 0, 1)": 1,
      "preds_norm": 1,
      "preds_rounded": 1,
      "y_labels_for_random": 1,
      "df_train.label": 1,
      "predictions_count_kmn": 1,
      "predictions_tfidf_kmn": 1,
      "predictions_count_rf": 1,
      "predictions_tfidf_rf": 1,
      "prediction['random_forest']": 1,
      "prediction['adaboost']": 1,
      "final_inference": 1,
      "np.where(y_pred > 0.9, 1, 0)": 1,
      "p[:o.shape[0]]": 1,
      "np.argmax(c, axis=1)": 1,
      "np.argmax(c[:train_df.shape[0]], axis=1)": 1,
      "knn.predict(x[40000:42000])": 1,
      "log_reg_countvec_pl.predict(validation['Phrase'])": 1,
      "lg_stack.predict(np.column_stack((nb_pl.predict_proba(data.loc['validation']), lg_pl.predict_proba(data.loc['validation']), svc_pl.decision_function(data.loc['validation']))))": 1,
      "logisticRegressor_char.predict(X_train_norm)": 1,
      "logisticRegressor_char.predict(X_valid_norm)": 1,
      "logisticRegressor_word.predict(X_train_norm)": 1,
      "logisticRegressor_word.predict(X_valid_norm)": 1,
      "logisticRegressor.predict(X_train)": 1,
      "logisticRegressor.predict(X_valid)": 1,
      "original_ytrain[valid_id]": 1,
      "y_cross_val": 1,
      "r_val > 0": 1,
      "y_blind_guess": 1,
      "classifier.predict(TrainFeat_)": 1,
      "np.argmax(self.oof_preds[valid_idx, :], axis=1)": 1,
      "np.argmax(self.oof_preds, axis=1)": 1,
      "predClipped": 1,
      "ypre": 1,
      "reduced_predictions": 1,
      "y_pred_under": 1,
      "y_pred_over": 1,
      "pred_gr": 1,
      "y_pred_val_tree": 1,
      "y_pred_val_xgb": 1,
      "y_pred_val_lr": 1,
      "y_pred_val_svm": 1,
      "y_pred_val_vc": 1,
      "y_train_pred_final.final_predicted": 1,
      "ovr_prediction": 1,
      "hard_voting__prediction": 1,
      "sub['labels']": 1,
      "lrm.predict(x_train)": 1,
      "lr_tuned_y_pred": 1,
      "rf_y_pred": 1,
      "rf_tuned_y_pred": 1,
      "lgbm_y_pred": 1,
      "lgbm_tuned_y_pred": 1,
      "y_pred10": 1,
      "tf.argmax(Y_test, axis=1)": 1,
      "y_pred_xgb2": 1,
      "y_pred_xgb3": 1,
      "docs['sentiment_vader']": 1,
      "cv_predictions": 1,
      "y_pred_xg": 1,
      "nb_clf.predict(xtest_tf)": 1,
      "rf_clf.predict(xtest_tf)": 1,
      "mlp_clf.predict(xtest_tf)": 1,
      "lreg_clf.predict(xtest_tf)": 1,
      "y_true.iloc[te]": 1,
      "lb_predict_test": 1,
      "tuna_pred_test": 1,
      "prediction_svc": 1,
      "prediction_lr": 1,
      "gender_submission['prediction']": 1,
      "Ycv2": 1,
      "svm_model.predict(X_test)": 1,
      "random_forest.predict(X_test)": 1,
      "gradientB_model.predict(X_test)": 1,
      "results['y_hat']": 1,
      "valid_Ys": 1,
      "train_Y": 1,
      "y_pred_t": 1,
      "submissions['Label'].values": 1,
      "PRED": 1,
      "y_predict1D": 1,
      "op": 1,
      "gs": 1,
      "y_val_predicted": 1,
      "y_val_predicted3": 1,
      "y_val_predicted4": 1,
      "Ym_test_pred": 1,
      "Ycv_pred": 1,
      "Dis_pipeline.predict(X_test)": 1,
      "test_res": 1,
      "forest_y_pred": 1,
      "y_pred_LGB": 1,
      "y_pred_tags": 1,
      "y_pred_list": 1,
      "y_predict_transform": 1,
      "(lgbm_model.predict_proba(x_valid_idx)[:, 1] > 0.5).astype(int)": 1,
      "Predict_Validation_data": 1,
      "logreg.predict(X_test)": 1,
      "dtree.predict(X_test)": 1,
      "dptree.predict(X_test)": 1,
      "rfc_b.predict(X_test)": 1,
      "mlp.predict(X_testS)": 1,
      "rfc_bA.predict(X_testA)": 1,
      "mlpf.predict(X_testS)": 1,
      "y_test.astype('int')": 1,
      "imdb['sentiment_vader']": 1,
      "vote_soft.predict(X_train)": 1,
      "vote_hard.predict(X_tr)": 1,
      "trained_xgb": 1,
      "final_test": 1,
      "best_model.predict(X_validation)": 1,
      "earlystop_model.predict(X_validation)": 1,
      "np.round(toxicity_scores[:len(toxicity_scores)])": 1,
      "np.round(obscenity_scores[:len(toxicity_scores)])": 1,
      "np.round(severe_toxicity_scores[:len(toxicity_scores)])": 1,
      "np.argmax(pred_Y, -1)": 1,
      "yhat_test": 1,
      "Y1": 1,
      "Y2": 1,
      "Y3": 1,
      "DATA[bin_features[j]]": 1,
      "np.round(OOF_PRED['EnsPred'])": 1,
      "OOF_PRED['VotePred']": 1,
      "temp['EnsPred']": 1,
      "np.ones(y_inlier.size)": 1,
      "-np.ones(y_outlier.size)": 1,
      "y_dt": 1,
      "y_nb": 1,
      "y_knn": 1,
      "y_svm": 1,
      "final_predictions": 1,
      "lgbm_pred": 1,
      "pred.softmax(dim=1).argmax(dim=1).detach().cpu().numpy()": 1,
      "y_pred_lr_b": 1,
      "y_pred_lr_b_2": 1,
      "y_pred_kbest_lr_cv": 1,
      "train['OOF']": 1,
      "temp_y": 1,
      "pred_train_y": 1,
      "preds_df": 1,
      "y_preds_result": 1,
      "preds[key].argmax(axis=1)": 1,
      "yv_pred": 1,
      "submission['target']": 1,
      "nn_pred_result": 1,
      "lgb_result": 1,
      "svc_result": 1,
      "test622_result": 1,
      "test433_result": 1,
      "prediction_for_rf": 1,
      "final_outputs": 1,
      "np.array(val_labs)": 1,
      "lr.predict(train[columns])": 1,
      "nb_pred": 1,
      "cnb_pred": 1,
      "vote_pred": 1,
      "knc_y_pred": 1,
      "dtc_y_pred": 1,
      "svm_y_pred": 1,
      "predictions_lr": 1,
      "predictions_lsv": 1,
      "np.array(train_pred)": 1,
      "log_predict": 1,
      "classifier_predict": 1,
      "np.where(preds > 0.5, 1, 0)": 1,
      "ran_pred": 1,
      "pred_tr1": 1,
      "pred_tr2": 1,
      "pred_tr3": 1,
      "pred_tr4": 1,
      "y_res": 1,
      "data_y": 1,
      "X_test.accuracy_group": 1,
      "y_predicted_d": 1,
      "xg_pred": 1,
      "y_preed": 1,
      "reg.predict(X)": 1,
      "l_test": 1,
      "predict_val_bool": 1,
      "nn.predict(dftestx)": 1,
      "train_data.preds": 1,
      "val_data.preds": 1,
      "test_df": 1,
      "xgb.predict(x_train)": 1,
      "gbc.predict(x_test)": 1,
      "gbc.predict(x_train)": 1,
      "classifier1.predict(X_train)": 1,
      "df_pred_simulated": 1,
      "pred_binary": 1,
      "y_valid[label]": 1,
      "predr": 1,
      "rfmodel_colley.predict(X_train)": 1,
      "knnmodel_colley.predict(X_train)": 1,
      "lrmodel_colley.predict(X_train)": 1,
      "rfmodel_all.predict(X_train)": 1,
      "knnmodel_all.predict(X_train)": 1,
      "lrmodel_all.predict(X_train)": 1,
      "model.predict(x_val)": 1,
      "rand.predict(train)": 1,
      "new_result": 1,
      "rf.predict(X_valid)": 1,
      "rf_random_cv.best_estimator_.predict(X)": 1,
      "rf_tunned.predict(X)": 1,
      "target_predicted_knn": 1,
      "lda_pred": 1,
      "XGB.predict(X_val)": 1,
      "RFC.predict(X_test)": 1,
      "ypp": 1,
      "y_pred_rbf": 1,
      "y_pred_forest": 1,
      "val_predictions_flat": 1,
      "all_preds['y_pred_bin']": 1,
      "np.round(scipy.stats.mode(preds[0:i + 1], axis=0)[0][0])": 1,
      "preds_valid > threshold": 1,
      "preds_valid_bi": 1,
      "list(classifier.predict(X_test))": 1,
      "y_train_tf": 1,
      "pred_vote[0]": 1,
      "labelsSampled[validate_idx]": 1,
      "sg_lr.predict(X_test)": 1,
      "sg_rf.predict(X_test)": 1,
      "sg_lr_pca.predict(model_pca_trans_test)": 1,
      "sg_rf_pca.predict(model_pca_trans_test)": 1,
      "sg_lr_sne.predict(X_embedded_test)": 1,
      "sg_rf_sne.predict(X_embedded_test)": 1,
      "rfc.predict(X_train)": 1,
      "rfc.predict(X_test)": 1,
      "rscv.predict(X_train)": 1,
      "rscv.predict(X_test)": 1,
      "pred_logit": 1,
      "svc_linear.predict(X_train)": 1,
      "svc_linear.predict(X_test)": 1,
      "svc.predict(X_train)": 1,
      "svc.predict(X_test)": 1,
      "xg.predict(X_train)": 1,
      "xg.predict(X_test)": 1,
      "y_train_lr": 1,
      "y_train_svc": 1,
      "y_train_rf": 1,
      "y_train_gb": 1,
      "y_train_xgb": 1,
      "y_train_knn": 1
    },
    "sklearn.metrics._classification.f1_score.average": {
      "'binary'": 2046,
      "'macro'": 1416,
      "'weighted'": 395,
      "'micro'": 154,
      "None": 38,
      "'samples'": 17,
      "avg": 10,
      "i": 4,
      "average_method": 3,
      "average": 2,
      "self.average": 1,
      "PARAMS['average']": 1
    },
    "sklearn.preprocessing._label.LabelEncoder.fit.y": {
      "list(train[:, i]) + list(test[:, i])": 231,
      "list(x_train[c].values)": 222,
      "list(x_test[c].values)": 221,
      "list(train[c].values) + list(test[c].values)": 177,
      "list(train_df[f].values) + list(test_df[f].values)": 140,
      "list(train_s[:, i]) + list(test_s[:, i])": 126,
      "m": 116,
      "phone.phone_brand": 113,
      "y": 103,
      "list(properties[c].values)": 98,
      "list(train[f].values) + list(test[f].values)": 95,
      "appevents.app_id": 75,
      "gatrain.group": 74,
      "app_train[col]": 73,
      "applabels.label_id": 71,
      "train.species": 70,
      "FLS['device_id']": 63,
      "list(train_df[col].values.astype('str')) + list(test_df[col].values.astype('str'))": 48,
      "list(x_all[c].values)": 47,
      "list(X_train[f].values) + list(X_test[f].values)": 40,
      "train['species']": 39,
      "gatrain.group.values": 36,
      "list(train[col].values.astype('str')) + list(test[col].values.astype('str'))": 35,
      "np.hstack([train.category_name, test.category_name])": 30,
      "np.hstack([train.brand_name, test.brand_name])": 30,
      "list(X_train[f]) + list(X_test[f])": 29,
      "list(train[col].astype(str).values) + list(test[col].astype(str).values)": 29,
      "list(train[c].values)": 29,
      "train[col]": 28,
      "list(prop[c].values)": 28,
      "list(train[feature].astype(str).values) + list(test[feature].astype(str).values)": 28,
      "list(df_train[f].values) + list(df_test[f].values)": 27,
      "train_df[feature]": 26,
      "list(train_df[f].values)": 25,
      "labels[i]": 24,
      "list(train[col].values) + list(test[col].values)": 23,
      "list(train['Species'].values) + list(test['Species'].values)": 22,
      "df[c].astype(str)": 22,
      "list(all_data[c].values)": 22,
      "list(train['Street'].values) + list(test['Street'].values)": 21,
      "list(train['Trap'].values) + list(test['Trap'].values)": 21,
      "train[feature]": 20,
      "categories": 19,
      "y_train": 19,
      "train[cat_col]": 19,
      "list(test[c].values)": 17,
      "list(train_df[col]) + list(test_df[col])": 16,
      "list(train[f].values)": 15,
      "list(df_train[c].values)": 14,
      "list(train_df[name1].values) + list(test_df[name1].values)": 14,
      "wifi_bssids": 14,
      "list(train[f]) + list(test[f])": 13,
      "train_y": 12,
      "list(df[f].values)": 11,
      "np.unique(train[usecol].unique().tolist() + test[usecol].unique().tolist())": 11,
      "list(train_df[f].values.astype('str')) + list(test_df[f].values.astype('str'))": 10,
      "df[col]": 10,
      "train_vals + test_vals": 10,
      "labels": 10,
      "train_df['word']": 10,
      "teams['Team']": 10,
      "list(trn_df[name1].values) + list(sub_df[name1].values)": 10,
      "data['site_id']": 10,
      "list(train_test[f].values)": 10,
      "list(df[c].values)": 10,
      "list(df_test[c].values)": 9,
      "test_shops": 9,
      "test_items": 9,
      "range(7, 11)": 9,
      "train[i]": 9,
      "df_all[c].astype(str)": 9,
      "train_labels": 9,
      "list(train[col].fillna('')) + list(test[col].fillna(''))": 9,
      "df[c].astype(str).values": 9,
      "list(train_df[c].values)": 9,
      "all_data[col]": 9,
      "list(train['Address']) + list(test['Address'])": 9,
      "X": 8,
      "train_df[column].unique().tolist() + test_df[column].unique().tolist()": 8,
      "train.landmark_id.values": 8,
      "list(df_all[c].values)": 8,
      "list(train_data[f].values) + list(test_data[f].values)": 8,
      "np.unique(questions_df['tags' + str(num)].values)": 8,
      "list(train_data[c].values)": 8,
      "np.unique(list(prudential_df[f].values) + list(test_df[f].values))": 7,
      "trainLabel[0]": 7,
      "list(test_df[c].values)": 7,
      "FLS6['device_id']": 7,
      "np.hstack([tr_cat_col, ts_cat_col])": 7,
      "np.hstack([tr_brand_col, ts_brand_col])": 7,
      "dataset[col]": 6,
      "final[col]": 6,
      "train['Country_Region']": 6,
      "train['Category']": 6,
      "list(train_features[feature].astype(str).values) + list(test_features[feature].astype(str).values)": 6,
      "Y": 6,
      "data[feature]": 6,
      "np.unique(list(airbnb_df[f].values) + list(test_df[f].values))": 6,
      "train_data[col]": 6,
      "application_train[col]": 6,
      "train_df['labels']": 6,
      "list(y_train) + list(y_test)": 6,
      "list(X[col]) + list(P[col])": 6,
      "train['target']": 6,
      "np.unique(train[col_name].unique().tolist() + test[col_name].unique().tolist())": 6,
      "list(df['_collection_name'].fillna(''))": 6,
      "np.unique(list(train[f].values) + list(test[f].values))": 6,
      "traininglabels[0]": 6,
      "list(df['manager_id'].values)": 6,
      "train_df['category_id']": 6,
      "list(test_data[c].values)": 6,
      "list(application_train[col].values.astype('str')) + list(application_test[col].values.astype('str'))": 5,
      "train_data[cf1].unique()": 5,
      "train_test.astype(str)": 5,
      "train_df[col]": 5,
      "train_test_df[col].astype(str)": 5,
      "list(df_train[f].values)": 5,
      "y['surface']": 5,
      "locations_df.cluster": 5,
      "df['Country_Region']": 5,
      "train[feature].append(test[feature]).astype(str)": 5,
      "list(data[c].values)": 5,
      "pd.concat([train['Intersection'], test['Intersection']]).drop_duplicates().values": 5,
      "list(train[f].values) + list(train[f].values)": 5,
      "list(all_data[col].values)": 5,
      "X_train[col]": 5,
      "list(train[field].values)": 5,
      "df_train[col]": 5,
      "train['day_of_week']": 5,
      "train['pd_district']": 5,
      "test['day_of_week']": 5,
      "test['pd_district']": 5,
      "list(test[f].values)": 5,
      "train_raw['Category']": 5,
      "dataset[column]": 5,
      "np.hstack([tr_col, ts_col])": 5,
      "app_events['app_id']": 4,
      "list(all_data[f].values)": 4,
      "train['Province_State']": 4,
      "list(properties16[c].values)": 4,
      "list(properties17[c].values)": 4,
      "list(df['collection_name'].fillna(''))": 4,
      "list(house_data[c].values)": 4,
      "list(x_train[c].values) + list(x_test[c].values)": 4,
      "list(train.iloc[:, i]) + list(test.iloc[:, i])": 4,
      "curData": 4,
      "loadedLabels": 4,
      "list(df_test[f].values)": 4,
      "df_union['Country_Region']": 4,
      "df_union['Province_Norm']": 4,
      "test[i]": 4,
      "np.concatenate([train[col], test[col]])": 4,
      "train_df.landmark_id.values": 4,
      "full_df.brand_name": 4,
      "teams": 4,
      "cats": 4,
      "list(train_df[col].values) + list(test_df[col].values)": 4,
      "y_train_init": 4,
      "list(set(data[li]))": 4,
      "train[c]": 4,
      "df['primary_use']": 4,
      "df['species']": 4,
      "labels['event_name_1']": 4,
      "labels['event_name_2']": 4,
      "list(df_train[col].values.astype('str')) + list(df_test[col].values.astype('str'))": 4,
      "temp[column]": 4,
      "full_train_df['category']": 4,
      "np.unique(list(homesite_df[f].values) + list(test_df[f].values))": 4,
      "list(df[col].values.astype('str'))": 4,
      "df['Province_State']": 4,
      "TYPES": 4,
      "list(train.Product_Info_2_C) + list(test.Product_Info_2_C)": 4,
      "test['Country_Region']": 4,
      "train['brand_name']": 4,
      "train['general_cat']": 4,
      "train['subcat_1']": 4,
      "train['subcat_2']": 4,
      "ga_train['group']": 4,
      "df[col].fillna('PreProcEmpty')": 3,
      "df1[col].fillna('PreProcEmpty')": 3,
      "train_Y[0]": 3,
      "list(dataset[c].values)": 3,
      "X_train[i]": 3,
      "list(df_all.iloc[:, i].values)": 3,
      "unique_values": 3,
      "y_raw": 3,
      "list(train[i].astype('str')) + list(test[i].astype('str'))": 3,
      "data['landmark_id']": 3,
      "pd.concat([train[c], test[c]])": 3,
      "full_df.category_name": 3,
      "train['store_and_fwd_flag']": 3,
      "train['color']": 3,
      "train['type']": 3,
      "train_df[column]": 3,
      "list(df['original_language'].fillna(''))": 3,
      "list(train_temp[:, i]) + list(test_temp[:, i])": 3,
      "df[i]": 3,
      "train_df['author']": 3,
      "list(df.unique())": 3,
      "list(train[f].values.astype('str')) + list(test[f].values.astype('str'))": 3,
      "train['prior_question_had_explanation']": 3,
      "list(train[col]) + list(test[col])": 3,
      "list(train_test[col].values)": 3,
      "list(mergedFilterd[f].values)": 3,
      "train_df[col].values.tolist() + test_df[col].values.tolist()": 3,
      "list(inpX[col].astype(str).values)": 3,
      "train_test_df[col]": 3,
      "X[C]": 3,
      "cat_cat[c]": 3,
      "train[col].astype(str)": 3,
      "all_df[cat]": 3,
      "train_data['species']": 3,
      "vals": 3,
      "list(train_X[f].values) + list(test_df[f].values)": 3,
      "list(train_df[c].values) + list(test_df[c].values)": 3,
      "list(combined_df[c].values)": 3,
      "train_col": 3,
      "building['primary_use']": 3,
      "df_train[c].values": 3,
      "np.hstack(data[label])": 3,
      "X[col]": 3,
      "X0": 3,
      "list(train['cat' + str(i)]) + list(test['cat' + str(i)])": 3,
      "list(d1[v].values) + list(d2[v].values)": 3,
      "hist_data['Q5']": 3,
      "train_features[cat]": 3,
      "np.unique(list(train_df[f].values) + list(test_df[f].values))": 3,
      "list(X[cols].values)": 3,
      "tfeat": 3,
      "data[f].values": 3,
      "['a', 'b', 'c', 'd']": 3,
      "['a', 'b', 'c']": 3,
      "['0', 'a', 'b', 'c']": 3,
      "DF.region": 3,
      "DF.city": 3,
      "DF.category_name": 3,
      "DF.parent_category_name": 3,
      "data_y": 3,
      "levels": 3,
      "device_brand['phone_brand']": 3,
      "app_labels['label_id']": 3,
      "label": 2,
      "pd.concat([data_train[col], data_test[col]], axis=0, sort=False)": 2,
      "train.RescuerID.values.tolist() + test.RescuerID.values.tolist()": 2,
      "self.df[c].values": 2,
      "X_train[f]": 2,
      "labelnames": 2,
      "list(properties2016[c].values)": 2,
      "list(properties2017[c].values)": 2,
      "train_data.species": 2,
      "df.species": 2,
      "X_train_full[col]": 2,
      "df_train[i]": 2,
      "data.values": 2,
      "list(X_test[c].values)": 2,
      "l": 2,
      "list(df[col].values)": 2,
      "data[col]": 2,
      "df_combined[feature]": 2,
      "data_df[f_name]": 2,
      "creature": 2,
      "pd.read_csv(categories_path).category_id": 2,
      "unique_labels": 2,
      "train['matchType']": 2,
      "phone.phone_brand.values": 2,
      "train.author": 2,
      "data['City Group']": 2,
      "data['Type']": 2,
      "data.species": 2,
      "list(data[f].values)": 2,
      "df_label['breed']": 2,
      "list(train_data[f].values)": 2,
      "y_train['surface']": 2,
      "data": 2,
      "list(clean_df[f].values)": 2,
      "list(clean_test[f].values)": 2,
      "train_df['hotel_id']": 2,
      "X_train['category']": 2,
      "pd.concat([X_train['host'], X_test['host']], ignore_index=True)": 2,
      "df[col].unique()": 2,
      "list(X_trn_df[f]) + [-999]": 2,
      "list(train[i].values) + list(test[i].values)": 2,
      "np.unique(list(x_train[f].values) + list(x_test[f].values))": 2,
      "list(X[i].values) + list(test[i].values)": 2,
      "public_train.landmark_id.values": 2,
      "temp.values": 2,
      "df_labels['breed']": 2,
      "list(data[col].values)": 2,
      "list(train_set[f].values)": 2,
      "candidates": 2,
      "data.iloc[:, feature]": 2,
      "list(train[f].unique()) + list(test[f].unique())": 2,
      "train[name]": 2,
      "test[name]": 2,
      "list(df[i].values) + list(test[i].values)": 2,
      "unique_without_nan": 2,
      "list(df_train[column_iter].values.astype('str')) + list(df_test[column_iter].values.astype('str'))": 2,
      "df['ebird_code'].to_numpy()": 2,
      "df_full[col]": 2,
      "X_train[col].append(X_test[col])": 2,
      "train_data[col].append(test_data[col])": 2,
      "np.unique(list(df_train_raw[f].values) + list(df_test_raw[f].values))": 2,
      "train_df[c]": 2,
      "df.title.unique()": 2,
      "train_prepared[col]": 2,
      "train['ebird_code']": 2,
      "['Game', 'Assessment', 'Activity', 'Clip']": 2,
      "['NONE', 'TREETOPCITY', 'MAGMAPEAK', 'CRYSTALCAVES']": 2,
      "np.hstack([train_df[col].values, test_df[col].values])": 2,
      "list(X[f].values) + list(test[f].values)": 2,
      "categories.cat.unique().ravel()": 2,
      "class_list": 2,
      "train_df.species": 2,
      "df.brand_name": 2,
      "train['Sex']": 2,
      "df['landmark_id']": 2,
      "classes": 2,
      "interactions_values": 2,
      "clicks[feature]": 2,
      "train_df.item_id": 2,
      "train_x[c].fillna('NA')": 2,
      "list(train_transaction[f].values) + list(test_transaction[f].values)": 2,
      "list(train_features[train_feat].astype(str).values) + list(test_features[train_feat].astype(str).values)": 2,
      "author_list": 2,
      "labels_train": 2,
      "col_val": 2,
      "list(train[i].values) + list(train[i].values)": 2,
      "target['surface']": 2,
      "list(train_df[c].unique()) + list(test_df[c].unique())": 2,
      "list(y_train_data['surface'])": 2,
      "training_label[0]": 2,
      "fm_values": 2,
      "prep_df['air_store_id']": 2,
      "list(data[col].values.astype('str'))": 2,
      "train_df.labels": 2,
      "train_data['color']": 2,
      "list(df_train[col].astype(str).values) + list(df_test[col].astype(str).values)": 2,
      "pd.concat([df_train['Intersec'], df_test['Intersec']]).drop_duplicates().values": 2,
      "target_column": 2,
      "list(df_macro[f].values)": 2,
      "X0_9": 2,
      "all_paths_df['category']": 2,
      "list(xtrain[col].values.astype('str')) + list(xtest[col].values.astype('str'))": 2,
      "list(train[c].unique()) + list(test[c].unique())": 2,
      "full_col.values.astype('str')": 2,
      "list(train['LastName']) + list(test['LastName'])": 2,
      "list(train_identity[col]) + list(test_identity[col])": 2,
      "xx[x]": 2,
      "Cat_dict[col]": 2,
      "list(train[c].values) + list(test_submit[c].values)": 2,
      "charsDict['all']": 2,
      "cod": 2,
      "df['labels']": 2,
      "list(df_features[f].values)": 2,
      "df['Province_State'].astype(str)": 2,
      "df['Country_Region'].astype(str)": 2,
      "df['Region'].astype(str)": 2,
      "cats_train.Hair": 2,
      "data['Sex']": 2,
      "z": 2,
      "df_as['air_genre_name']": 2,
      "df_as['air_area_name']": 2,
      "df_hs['hpg_genre_name']": 2,
      "df_hs['hpg_area_name']": 2,
      "df_as['air_store_id']": 2,
      "np.hstack([train_df.category_name, test_df.category_name])": 2,
      "np.hstack([train_df.brand_name, test_df.brand_name])": 2,
      "allLabels": 2,
      "total_df[c]": 2,
      "pd.concat([train_df['RescuerID'], test_df['RescuerID']])": 2,
      "df_episode_agents.dropna(subset=['InitialScore'])['SubmissionId']": 2,
      "list(df[col].astype(str).values)": 2,
      "list(df_data['primary_use'].values)": 2,
      "df_cats[col]": 2,
      "['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9']": 2,
      "list(df_train[col].values)": 2,
      "ytrain.surface": 2,
      "list(X_train[i].values) + list(X_test[i].values)": 2,
      "np.unique(list(bnp_df[f].values) + list(test_df[f].values))": 2,
      "Y_train": 2,
      "list(crew[c].values)": 2,
      "train_df[col].to_list() + test_df[col].to_list()": 2,
      "hist_data['Q6']": 2,
      "list(df_train_encoded[col].unique()) + list(df_test_encoded[col].unique())": 2,
      "data_all[c].values": 2,
      "list(train[col].values.astype('str'))": 2,
      "X[col].fillna(value='N/A').values": 2,
      "pd.concat([label_X_train[col], label_X_valid[col]], axis=0, sort=False)": 2,
      "list(train['type'].values) + list(test['type'].values)": 2,
      "data['world'].values": 2,
      "train['Country/Region']": 2,
      "src_train['Country/Region'].astype(str)": 2,
      "dataset.category_name": 2,
      "dataset.brand_name": 2,
      "DF.param_1": 2,
      "DF.param123": 2,
      "pd.concat([train_x, test_x], ignore_index=True)": 2,
      "df.breed.astype(str)": 2,
      "df_calendar['event_type']": 2,
      "df_train[c]": 2,
      "X_train['Province_State']": 2,
      "X_train['Country_Region']": 2,
      "test['Province_State']": 2,
      "list(train_df[i].values) + list(test_df[i].values)": 2,
      "train['Target']": 2,
      "test['Target']": 2,
      "full": 2,
      "df[feature].astype(str)": 2,
      "np.hstack([df.spacegroup, df_val.spacegroup])": 2,
      "np.hstack([df.number_of_total_atoms, df_val.number_of_total_atoms])": 2,
      "list(df[col].values.astype('str')) + list(df1[col].values.astype('str'))": 2,
      "data_x": 2,
      "prop['propertycountylandusecode']": 2,
      "prop['propertyzoningdesc']": 2,
      "list(data[col].astype(str).values)": 2,
      "list(train0[col].astype(str).values)": 2,
      "temp_ds[col]": 2,
      "list(train[col].values)": 2,
      "trainLabel": 2,
      "train_data['Sex']": 2,
      "list(df[col].values) + list(df[col].values)": 2,
      "all_df[col]": 2,
      "cp_time": 2,
      "cp_dose": 2,
      "list(train_copy[col].astype(str).values) + list(test_copy[col].astype(str).values)": 2,
      "data['CentralAir']": 2,
      "data['KitchenQual']": 2,
      "data['GarageType']": 2,
      "data['BsmtCond']": 2,
      "data['Electrical']": 2,
      "all_pacient": 2,
      "df['author']": 2,
      "species": 2,
      "phone_brand_device_model['device_model']": 1,
      "device_id_rows": 1,
      "gender_age_train['group']": 1,
      "list(train[cols].values) + list(test[cols].values)": 1,
      "list(dft2[f].values) + list(dfte2[f].values)": 1,
      "list(x_train[col].values.astype('str')) + list(x_test[col].values.astype('str'))": 1,
      "attr_": 1,
      "dtrain[col]": 1,
      "train_data_df_m['primary_use']": 1,
      "train_app[col]": 1,
      "list(data[c].unique()) + list(test[c].unique())": 1,
      "list(df[col].values) + list(df_test[col].values)": 1,
      "list(train[col].values.astype(str)) + list(test[col].values.astype(str))": 1,
      "list(dftrain[col].values.astype('str')) + list(test_df[col].values.astype('str'))": 1,
      "lectures_df['lecture_id'].values": 1,
      "list(train_df_obj[c].values)": 1,
      "list(prop2017[c].values)": 1,
      "pd.concat([train[col], test[col]], axis=0)": 1,
      "list(x_train_imputed_cat[col].values) + list(x_test_imputed_cat[col].values)": 1,
      "list(train[i].values)": 1,
      "list(test[i].values)": 1,
      "full_data.loc[:, feature].values.tolist()": 1,
      "data_frame[column]": 1,
      "train_label": 1,
      "list(X_train[c].values)": 1,
      "c": 1,
      "leb": 1,
      "labels_encod": 1,
      "train_cat[colName].unique()": 1,
      "test_cat[colName].unique()": 1,
      "X[ca].apply(str)": 1,
      "cuisine": 1,
      "yAll": 1,
      "total.astype(str).values": 1,
      "y_test": 1,
      "loadedLabelsTrain": 1,
      "train_image_df['integer_label']": 1,
      "train['Id']": 1,
      "train['groupId']": 1,
      "train['matchId']": 1,
      "train[col].values": 1,
      "df['target']": 1,
      "mod_train_df[feature]": 1,
      "target_df['surface']": 1,
      "new_merchant_transactions['category_1']": 1,
      "historical_transactions['category_1']": 1,
      "train2['color']": 1,
      "list(df[x].values)": 1,
      "np.concatenate((X_test[:, i], X[:, i]), axis=0)": 1,
      "dropped_df[col]": 1,
      "list(train[c].astype(str)) + list(test[c].astype(str))": 1,
      "list(train[c].astype('str')) + list(test[c].astype('str'))": 1,
      "df[col_name]": 1,
      "consolidated[c]": 1,
      "list(train_new['idhogar'].values) + list(test_new['idhogar'].values)": 1,
      "test_labels": 1,
      "encode_table[i]": 1,
      "list(X_train[c].values) + list(X_test[c].values)": 1,
      "application_test[col]": 1,
      "list(train_transaction[col]) + list(test_transaction[col])": 1,
      "geo.Country_Region": 1,
      "geo.Province_State": 1,
      "df[feature]": 1,
      "train_df['brand_name']": 1,
      "train_df['general_cat']": 1,
      "train_df['subcat_1']": 1,
      "train_df['subcat_2']": 1,
      "train_transaction_full[label_col].append(test_transaction_full[label_col], ignore_index=True).values": 1,
      "train_identity_full[label_col].append(test_identity_full[label_col], ignore_index=True).values": 1,
      "play_cat_classes": 1,
      "player_cat_classes": 1,
      "np.hstack([train_df[col], test_df[col]])": 1,
      "pd.concat([train_cat, test_cat])": 1,
      "data_final['assetCode']": 1,
      "df_acaps_agg['Region']": 1,
      "list(train_df[col].fillna('')) + list(test_df[col].fillna(''))": 1,
      "np.concatenate([x_train['category_name'], x_test['category_name']])": 1,
      "np.concatenate([x_train['brand_name'], x_test['brand_name']])": 1,
      "list(set(data[col].values)) + ['Missing']": 1,
      "dataframe[col]": 1,
      "train_df[feature].append(test_df[feature])": 1,
      "['intraparenchymal', 'intraventricular', 'epidural', 'subarachnoid', 'any', 'subdural']": 1,
      "list(tn[o].values)": 1,
      "list(train['category'].values)": 1,
      "list(test['category'].values)": 1,
      "list(train[col].astype(str).values)": 1,
      "list(test[col].astype(str).values)": 1,
      "X_full[column]": 1,
      "X_full[column].unique().tolist() + X_test[column].unique().tolist()": 1,
      "df_train[columna]": 1,
      "list(X[f].values) + list(X_test[f].values)": 1,
      "df_categories.index.values": 1,
      "np.unique(list(x_train[f].values))": 1,
      "df['loc'].values": 1,
      "df['cat1']": 1,
      "df['cat2']": 1,
      "df['cat3']": 1,
      "test['cat1']": 1,
      "test['cat2']": 1,
      "test['cat3']": 1,
      "df['brand_name']": 1,
      "test['brand_name']": 1,
      "np.hstack([train.category1, test.category1])": 1,
      "np.hstack([train.category2, test.category2])": 1,
      "np.hstack((train.landmark_id.values, valid.landmark_id.values))": 1,
      "list(data['Species'].values)": 1,
      "list(data['Street'].values)": 1,
      "list(data['Trap'].values)": 1,
      "pd.concat([train_data[c], test_data[c]])": 1,
      "list(train_data[col].values) + list(test_data[col].values)": 1,
      "building_combo": 1,
      "manager_combo": 1,
      "loc_combo": 1,
      "list(df_train[column]) + list(df_test[column])": 1,
      "list(full[c].values)": 1,
      "train_df['cuisine'].values": 1,
      "df_combined[feature].astype(str)": 1,
      "['low', 'medium', 'high']": 1,
      "ucats[col]": 1,
      "np.hstack([train_data.project_subject_categories, test_data.project_subject_categories])": 1,
      "np.hstack([train_data.project_subject_subcategories, test_data.project_subject_subcategories])": 1,
      "np.hstack([train_data.project_grade_category, test_data.project_grade_category])": 1,
      "train[c].fillna('NA')": 1,
      "list(test_set[f].values)": 1,
      "train['wheezy-copper-turtle-magic'].tolist() + test['wheezy-copper-turtle-magic'].tolist()": 1,
      "leaf_train + leaf_valid + leaf_test": 1,
      "all_data[cols]": 1,
      "list(df[feature].values)": 1,
      "list(datas[cus_prefix + '_cols_index'].values)": 1,
      "np.hstack([combdata.newCategory])": 1,
      "np.hstack([combdata.Brand])": 1,
      "list(train[c].fillna('').values) + list(test[c].fillna('').values)": 1,
      "l1 + l2": 1,
      "train.labels": 1,
      "train_df.lockdown_type": 1,
      "extract_region(train_df)": 1,
      "np.hstack([train_data.general_cat, test_data.general_cat])": 1,
      "np.hstack([train_data.brand_name, test_data.brand_name])": 1,
      "np.hstack([train_data.subcat_1, test_data.subcat_1])": 1,
      "np.hstack([train_data.subcat_2, test_data.subcat_2])": 1,
      "list(train[i].fillna('')) + list(test[i].fillna(''))": 1,
      "train_df.category_name": 1,
      "train_df.brand_name": 1,
      "X[self.cat]": 1,
      "list(prop[col].values)": 1,
      "list(df_train_model1[column_iter].values.astype('str')) + list(df_test_model1[column_iter].values.astype('str'))": 1,
      "feature": 1,
      "df_train_data.installation_id.unique().tolist()": 1,
      "X_train['class']": 1,
      "list(train_cat[c].values) + list(test_cat[c].values)": 1,
      "np.concatenate([train_df[cat].values, test_df[cat].values])": 1,
      "sf['Category']": 1,
      "list(data_train[i].values)": 1,
      "list(df_test[i].values)": 1,
      "train_test": 1,
      "train['cat9']": 1,
      "self.wifi_bssids": 1,
      "['Never smoked', 'Ex-smoker', 'Currently smokes']": 1,
      "uniq_labels": 1,
      "train.label": 1,
      "sales[col]": 1,
      "cal[col]": 1,
      "pd.concat([train_data[col], test_data[col]])": 1,
      "list(train[col]) + list(test_x[col])": 1,
      "list(allDf[c].values)": 1,
      "labelcat.category": 1,
      "test_df[c]": 1,
      "list(train_df_new[f].values)": 1,
      "list(downsampled[col].astype(str).values) + list(test[col].astype(str).values)": 1,
      "phone['phone_brand']": 1,
      "unique_bssids": 1,
      "list(set(X_train.loc[:, 'building'].values.tolist()))": 1,
      "data.place_id": 1,
      "y_train_split": 1,
      "list(df_tot[c].values)": 1,
      "list(train[index].values.astype(str))": 1,
      "features": 1,
      "df_without_null['NAME_INCOME_TYPE']": 1,
      "word_set": 1,
      "train[target]": 1,
      "new_df.provider.drop_duplicates()": 1,
      "df_categories['category_level1'].values": 1,
      "train.Type": 1,
      "list(X[f].values)": 1,
      "list(X[feature].astype(str).values)": 1,
      "cities": 1,
      "StreetType": 1,
      "df['release_year'].values": 1,
      "df.len_desc": 1,
      "df.category_level1": 1,
      "df.category_level2": 1,
      "df.category_level3": 1,
      "df.item_condition_id": 1,
      "df.version": 1,
      "data['site']": 1,
      "allvalues": 1,
      "df_train['store_and_fwd_flag']": 1,
      "df_train['vendor_id']": 1,
      "np.array(list(X_train[L].values) + list(X_test[L].values)).astype(str)": 1,
      "list(X_train[col].astype(str).values) + list(X_test[col].astype(str).values)": 1,
      "list(X_train[col].astype(str).values) + list(X_test[col].astype(str).values) + list(test[col].astype(str).values)": 1,
      "list(df_all[f].values.astype('str')) + list(df_all[f].values.astype('str'))": 1,
      "train_xgb['cp_type'].astype(str)": 1,
      "train_xgb['cp_dose'].astype(str)": 1,
      "list(train_df[feat].values.astype('str'))": 1,
      "list(dftrain['category_name']) + list(dftest['category_name'])": 1,
      "list(dftrain['brand_name']) + list(dftest['brand_name'])": 1,
      "shop_and_item.shop_and_item": 1,
      "list(all_data['manager_id'].values)": 1,
      "np.concatenate([df_dates['event_type_1'], df_dates['event_type_2']])": 1,
      "train2[col].values.tolist() + test2[col].values.tolist()": 1,
      "np.concatenate([X_train[c], X_test[c]])": 1,
      "all_names": 1,
      "all_l": 1,
      "folds_data['target']": 1,
      "df_trn.word": 1,
      "train_df_categorical[i]": 1,
      "np.unique(list(train[c].values) + list(test[c].values))": 1,
      "train[col].unique().tolist() + test[col].unique().tolist()": 1,
      "return_df[col_name]": 1,
      "train_df[col].astype(str)": 1,
      "list(train.brand_name) + list(test.brand_name)": 1,
      "list(train.general_cat) + list(test.general_cat)": 1,
      "list(train.subcat_1) + list(test.subcat_1)": 1,
      "list(train.subcat_2) + list(test.subcat_2)": 1,
      "pd.concat([train_data[feature], test_data[feature]], axis=0, sort=False)": 1,
      "list(bool_feature_people[i].values)": 1,
      "train.type": 1,
      "df_data[feature]": 1,
      "df[feature_name]": 1,
      "list(df_train[col].values) + list(df_test[col].values)": 1,
      "train['target'].unique()": 1,
      "train['cat8']": 1,
      "list(train_s1[:, i]) + list(test_s1[:, i])": 1,
      "fit_data": 1,
      "pd.concat([train2[c].fillna('NA'), test2[c].fillna('NA')])": 1,
      "train_x[label]": 1,
      "pd.concat(objs=[df_calendar['event_name_1'], df_calendar['event_name_2']], axis=0)": 1,
      "pd.concat(objs=[df_calendar['event_type_1'], df_calendar['event_type_2']], axis=0)": 1,
      "pd.concat(objs=[df_calendar['event_tomorrow_1'], df_calendar['event_tomorrow_2']], axis=0)": 1,
      "pd.concat(objs=[df_calendar['event_type_tomorrow_1'], df_calendar['event_type_tomorrow_2']], axis=0)": 1,
      "train_word": 1,
      "list(train[f].astype(str).values) + list(test[f].astype(str).values)": 1,
      "list(label_columns[col])": 1,
      "matrix[col]": 1,
      "list(train_feat[feature].astype(str).values) + list(test_feat[feature].astype(str).values)": 1,
      "ID_vocab": 1,
      "data['site'].unique()": 1,
      "leaf_classes": 1,
      "train_target_label": 1,
      "train[variable]": 1,
      "full_data[variable]": 1,
      "sample": 1,
      "df['matchType']": 1,
      "data_train[column]": 1,
      "X['day_of_week']": 1,
      "X['air_genre_name']": 1,
      "X['air_area_name']": 1,
      "X['air_store_id']": 1,
      "train[col].append(test[col])": 1,
      "sales[c].unique()": 1,
      "[1, 2, 3]": 1,
      "['Novice', 'Contributor', 'Expert', 'Master', 'Grandmaster']": 1,
      "['Freezing', 'Cold', 'Warm', 'Hot', 'Boiling Hot', 'Lava Hot']": 1,
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o']": 1,
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']": 1,
      "people[col]": 1,
      "act[col]": 1,
      "MTeamConferences[cat]": 1,
      "train_df['species']": 1,
      "cardinal_classes": 1,
      "list(train['P_emaildomain']) + list(test['P_emaildomain'])": 1,
      "list(train['id_30']) + list(test['id_30'])": 1,
      "list(train['id_33']) + list(test['id_33'])": 1,
      "list(train['DeviceInfo']) + list(test['DeviceInfo'])": 1,
      "list(train['card1_card2']) + list(test['card1_card2'])": 1,
      "list(train['card1_addr1']) + list(test['card1_addr1'])": 1,
      "list(train['card2_addr1']) + list(test['card2_addr1'])": 1,
      "train['networkDomain']": 1,
      "train['keyword']": 1,
      "train['referralPath']": 1,
      "train['city']": 1,
      "train['visitNumber']": 1,
      "train['source']": 1,
      "train['region']": 1,
      "train['date']": 1,
      "train['country']": 1,
      "train['metro']": 1,
      "train['browser']": 1,
      "train['adContent']": 1,
      "train['subContinent']": 1,
      "train['operatingSystem']": 1,
      "train['campaign']": 1,
      "test['keyword']": 1,
      "test['referralPath']": 1,
      "test['city']": 1,
      "test['visitNumber']": 1,
      "test['source']": 1,
      "test['region']": 1,
      "test['date']": 1,
      "test['country']": 1,
      "test['metro']": 1,
      "test['browser']": 1,
      "test['networkDomain']": 1,
      "test['adContent']": 1,
      "test['subContinent']": 1,
      "test['operatingSystem']": 1,
      "test['campaign']": 1,
      "list(train_dist[col].values) + list(test_dist[col].values)": 1,
      "data_combined[col]": 1,
      "list(housing[col].values)": 1,
      "list(train[l].values) + list(test[l].values)": 1,
      "train['Agent']": 1,
      "train['Sub_Page']": 1,
      "train['Access']": 1,
      "train[columns]": 1,
      "test[columns]": 1,
      "df['subcat_0']": 1,
      "df['subcat_1']": 1,
      "df['subcat_2']": 1,
      "list(x_train_imputer[c].values)": 1,
      "list(x_test_imputer[c].values)": 1,
      "train.cat0": 1,
      "list(x_train_full[c].values)": 1,
      "df_filtered['sex']": 1,
      "df_filtered['anatom_site_general_challenge']": 1,
      "DATA[x].unique()": 1,
      "X_train[cc].values": 1,
      "full_df.subcat_0": 1,
      "full_df.subcat_1": 1,
      "full_df.subcat_2": 1,
      "list(result_df[c].values)": 1,
      "list(train_macro[f].values)": 1,
      "list(X_train[var].values) + list(X_test[var].values)": 1,
      "test['matchType']": 1,
      "list(X_train2[f].values) + list(X_valid2[f].values)": 1,
      "list(test00[f].values)": 1,
      "list(df_train[c].values) + list(df_test[c].values)": 1,
      "[b'S', b'M', b'I', b'B', b'H', b'E', b'X', b'.', b'(', b')', b'A', b'C', b'G', b'U']": 1,
      "['CVC - Abnormal', 'CVC - Borderline', 'CVC - Normal', 'ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal', 'NGT - Abnormal', 'NGT - Borderline', 'NGT - Incompletely Imaged', 'NGT - Normal', 'Swan Ganz Catheter Present']": 1,
      "['.01', '.02', '.03', '.101', '.102', '.103', '.501', '.502', '.503', '.504', '.911']": 1,
      "category_names['category_id']": 1,
      "np.array(train_whales.Id.values)": 1,
      "genes": 1,
      "variations": 1,
      "np.hstack([train_test.name])": 1,
      "np.hstack([train_test.subcategory_2])": 1,
      "np.hstack([train_test.brand_name])": 1,
      "np.hstack([train_test.subcategory_1])": 1,
      "np.hstack([train_test.general_category])": 1,
      "train_data[column].unique().tolist() + test_data[column].unique().tolist()": 1,
      "x[i]": 1,
      "cuisines": 1,
      "list(df_id[f].values)": 1,
      "list(df[col].values.astype('str')) + list(df[col].values.astype('str'))": 1,
      "turler": 1,
      "df[column].unique().tolist()": 1,
      "df_house[colName].drop_duplicates()": 1,
      "net_state": 1,
      "net_pcd": 1,
      "net_bm": 1,
      "net_md": 1,
      "train_paths['label']": 1,
      "train_data_x['color']": 1,
      "train_data_y": 1,
      "test_data['color']": 1,
      "list(merged_train_data[objectTypeFeature].values)": 1,
      "feature_values": 1,
      "list(all_X[column].values)": 1,
      "classnames": 1,
      "newlist": 1,
      "y_train.values": 1,
      "train['primary_use']": 1,
      "pd.concat([train[col].astype(str), test[col].astype(str)])": 1,
      "column_values": 1,
      "train[feature].values": 1,
      "full_food_df['category'].values": 1,
      "np.concatenate([train_df[x] for x in cat_cols] + [test_df[x] for x in cat_cols])": 1,
      "list(X_train[f].values)": 1,
      "np.hstack([train.name])": 1,
      "np.hstack([train.brand_name])": 1,
      "np.hstack([train.main_cat])": 1,
      "np.hstack([train.subcat1])": 1,
      "np.hstack([train.subcat2])": 1,
      "list(df_train[i].values.astype('str')) + list(df_test[i].values.astype('str'))": 1,
      "trainMasterDf.DayOfWeek": 1,
      "trainMasterDf.PdDistrict": 1,
      "trainMasterDf.Category": 1,
      "np.hstack([train[column], test[column]])": 1,
      "structures_df.atom.values": 1,
      "f_train['target']": 1,
      "df_train[col].append(df_test[col])": 1,
      "pets.Name": 1,
      "pets.RescuerID": 1,
      "pets.PetID": 1,
      "pets2.Name": 1,
      "pets2.RescuerID": 1,
      "pets2.PetID": 1,
      "data.gender": 1,
      "list(train['Embarked'].values)": 1,
      "list(test['Embarked'].values)": 1,
      "df_vals": 1,
      "list(train.X0) + list(test.X0)": 1,
      "list(train.X1) + list(test.X1)": 1,
      "list(train.X2) + list(test.X2)": 1,
      "list(train.X3) + list(test.X3)": 1,
      "list(train.X4) + list(test.X4)": 1,
      "list(train.X5) + list(test.X5)": 1,
      "list(train.X6) + list(test.X6)": 1,
      "list(train.X8) + list(test.X8)": 1,
      "shop_df['city']": 1,
      "category_df['type']": 1,
      "category_df['subtype']": 1,
      "subtraininglabels[0]": 1,
      "alldata[col]": 1,
      "list(df2[col].values.astype('str')) + list(df2[col].values.astype('str'))": 1,
      "test['type']": 1,
      "card_ids": 1,
      "merchants['merchant_id']": 1,
      "transactions['category_3']": 1,
      "list(train_df[col].values.astype('str')) + list(test_df_trimmed[col].values.astype('str')) + list(test_df_dropped[col].values.astype('str'))": 1,
      "list(all_data[col_name].values)": 1,
      "list(data_df[col].astype(str).str.upper().values) + list(submission_df[col].astype(str).str.upper().values)": 1,
      "train['species'].values": 1,
      "species.values": 1,
      "train_df['place_id'].as_matrix()": 1,
      "list(data_v1[col].astype(str).values) + list(test[col].astype(str).values)": 1,
      "Y_Data_Tr": 1,
      "train_total['label']": 1,
      "train_applic[col]": 1,
      "list(train.iloc[:, i].values) + list(test.iloc[:, i].values)": 1,
      "matchType": 1,
      "matchTypeTest": 1,
      "data.author": 1,
      "df_combine[col]": 1,
      "np.ravel(levels.reshape(-1, 1))": 1,
      "list(train[feature].values)": 1,
      "train['Embarked']": 1,
      "all_cat": 1,
      "uid.append(uid_test)": 1,
      "sid.append(sid_test)": 1,
      "train[cat_feature].unique()": 1,
      "np.append(train[c], test[c])": 1,
      "train_df['author'].as_matrix()": 1,
      "list(df[f].values) + list(dft[f].values)": 1,
      "df_le[col]": 1,
      "train_data[column]": 1,
      "leaf_df['species']": 1,
      "list(train_x[f].values)": 1,
      "list(X_train_full[f].values) + list(X_test[f].values)": 1,
      "Y_labels": 1,
      "full_data[col].values": 1,
      "label_df.surface.unique()": 1,
      "df_train['Country/Region']": 1,
      "list(train_dd[f].values) + list(test_dd[f].values)": 1,
      "X[feat]": 1,
      "unique_countries": 1,
      "raw_cat1": 1,
      "raw_cat2": 1,
      "raw_cat3": 1,
      "raw_brand": 1,
      "df['BCG'].astype(str)": 1,
      "train_df['landmark_id']": 1,
      "list(trainData.keys())": 1,
      "train_csv.landmark_id.values": 1,
      "data_train.Race1": 1,
      "data_train.Race2": 1,
      "data_train.Color1": 1,
      "data_train.Color2": 1,
      "data_test.Race1": 1,
      "data_test.Race2": 1,
      "data_test.Color1": 1,
      "data_test.Color2": 1,
      "cats_test.Hair": 1,
      "cats_train.Race1": 1,
      "cats_train.Race2": 1,
      "cats_train.Color1": 1,
      "cats_train.Color2": 1,
      "cats_test.Race1": 1,
      "cats_test.Race2": 1,
      "cats_test.Color1": 1,
      "cats_test.Color2": 1,
      "dogs_train.Race1": 1,
      "dogs_train.Race2": 1,
      "dogs_train.Color1": 1,
      "dogs_train.Color2": 1,
      "dogs_test.Race1": 1,
      "dogs_test.Race2": 1,
      "dogs_test.Color1": 1,
      "dogs_test.Color2": 1,
      "df_to_transf[cols]": 1,
      "list(train['teacher_prefix']) + list(train['teacher_prefix'])": 1,
      "list(train['school_state']) + list(['school_state'])": 1,
      "list(train['project_grade_category']) + list(test['project_grade_category'])": 1,
      "list(train['project_subject_categories']) + list(test['project_subject_categories'])": 1,
      "list(train['project_subject_subcategories']) + list(test['project_subject_subcategories'])": 1,
      "data['Embarked'].astype(str)": 1,
      "data['Cabin'].astype(str)": 1,
      "train_df['keyword']": 1,
      "['Dog', 'Cat']": 1,
      "['Intact Female', 'Intact Male', 'Neutered Male', 'Spayed Female', 'Unknown']": 1,
      "all_breeds": 1,
      "data[:, 'site_id']": 1,
      "data[:, 'path']": 1,
      "np.hstack([train_df.name, test_df.name])": 1,
      "np.hstack([train_df.item_description, test_df.item_description])": 1,
      "np.hstack([train_df.general_cat, test_df.general_cat])": 1,
      "np.hstack([train_df.subcat_1, test_df.subcat_1])": 1,
      "np.hstack([train_df.subcat_2, test_df.subcat_2])": 1,
      "application_data[col]": 1,
      "list(train_test[col].astype(str).values)": 1,
      "data['grid']": 1,
      "train['author']": 1,
      "list(train[feature_name + '_all'].fillna('')) + list(test[feature_name + '_all'].fillna(''))": 1,
      "list(train['original_language'].fillna('')) + list(test['original_language'].fillna(''))": 1,
      "data_train[i]": 1,
      "train['card_id']": 1,
      "train['first_active_month']": 1,
      "test['card_id']": 1,
      "application_train[i]": 1,
      "list(tt[c].values)": 1,
      "data['Province_State'].values": 1,
      "data['Country_Region'].values": 1,
      "x": 1,
      "train_data.sentiment.to_list()": 1,
      "enc[c]": 1,
      "data_all_le_unique[c]": 1,
      "genre_le[c]": 1,
      "area_le[c]": 1,
      "data['target']": 1,
      "train['Address_clean']": 1,
      "submission_pd[ID]": 1,
      "sales[cat]": 1,
      "mixed_dataset[feature]": 1,
      "GameCities[column]": 1,
      "Seasons[column]": 1,
      "list(train_vals) + list(test_vals)": 1,
      "app_train['NAME_CONTRACT_TYPE']": 1,
      "list(train_data[i].values) + list(test_transaction_all[i].values)": 1,
      "np.unique(traindf[usecol].unique().tolist())": 1,
      "list(df['_genres_name'].fillna(''))": 1,
      "pd.concat([train[col], test[col]], axis=0, sort=False)": 1,
      "species_label": 1,
      "list(X_train[col])": 1,
      "list(df1[col])": 1,
      "y_raw['surface']": 1,
      "tmp": 1,
      "pd.concat([train[col], test_x[col]]).astype('str')": 1,
      "pd.concat([train_labeled[c], test_labeled[c]])": 1,
      "X1": 1,
      "X2": 1,
      "X3": 1,
      "X4": 1,
      "X5": 1,
      "X6": 1,
      "X8": 1,
      "list(df_test[col].values)": 1,
      "insurance.sex.drop_duplicates()": 1,
      "train_y.surface": 1,
      "list(application_train[i].unique())": 1,
      "train_df.surface": 1,
      "list(data['matchType'].values)": 1,
      "list(test_data['matchType'].values)": 1,
      "final_df[col]": 1,
      "data['country_destination']": 1,
      "data_train[col]": 1,
      "list(merge_df[col].values)": 1,
      "labellist[i]": 1,
      "data['Cabin']": 1,
      "data['Embarked']": 1,
      "list(non_cor_train_df[f].values) + list(non_cor_test_df[f].values)": 1,
      "train_df['landmark_id'].values": 1,
      "np.hstack([train_df.category_name, dev_df.category_name, test_df.category_name])": 1,
      "np.hstack([train_df.brand_name, dev_df.brand_name, test_df.brand_name])": 1,
      "tr_df[elt]": 1,
      "list(m_train[l].values)": 1,
      "list(m_test[l].values)": 1,
      "list(xtrain[col].fillna('')) + list(xtest[col].fillna(''))": 1,
      "list(homesite_df[f].values) + list(test_df[f].values)": 1,
      "train_df[cf1].unique()": 1,
      "test_df[cf1].unique()": 1,
      "train[cf].unique()": 1,
      "list(all_labels)": 1,
      "recipeRaw['cuisine'].values": 1,
      "df_cat[col]": 1,
      "pd.concat([train_df[cols], test_df[cols]], axis=0, sort=False)": 1,
      "TRANS_tr_new[la]": 1,
      "TRANS_te_new[la]": 1,
      "C.ind_empleado.unique()": 1,
      "C.pais_residencia.unique()": 1,
      "C.sexo.unique()": 1,
      "C.tiprel_1mes.unique()": 1,
      "C.indresi.unique()": 1,
      "C.indext.unique()": 1,
      "C.canal_entrada.unique()": 1,
      "C.segmento.unique()": 1,
      "list(set(train_df[column].apply(list).sum()))": 1,
      "list(y_train_str.values())": 1,
      "list(data[feat].values)": 1,
      "train_df['cuisine']": 1,
      "list(train_df3[col].values.astype('str'))": 1,
      "all_data[le]": 1,
      "X_train[col] + X_valid[col] + X_test[col]": 1,
      "list(X_train[col].values.astype('str')) + list(X_valid[col].values.astype('str')) + list(X_test[col].values.astype('str'))": 1,
      "prev_train_df.landmark_id.values": 1,
      "np.unique(list(train_df[feat].values) + list(test_df[feat].values))": 1,
      "X_train[feat]": 1,
      "new[0].unique()": 1,
      "new[1].unique()": 1,
      "train_features['cp_type'].values": 1,
      "train_features['cp_dose'].values": 1,
      "list(df[column_name].values)": 1,
      "list(x_tota[c].values)": 1,
      "list(pilot[c].values)": 1,
      "np.round(np.log(ds['trip_duration']) * 10)": 1,
      "list(set(X_train[f].unique()).union(set(X_test[f].unique())))": 1,
      "df_enc[i].astype(str)": 1,
      "list(X[f].values) + list(test_X[f].values)": 1,
      "train.OutcomeType": 1,
      "train.country_destination": 1,
      "list(train['manager_id'].values)": 1,
      "list(train_data[col].dropna().values) + list(test_data[col].dropna().values)": 1,
      "Y.values.tolist()": 1,
      "pd.concat([train_df[feature], test_df[feature]], ignore_index=True)": 1,
      "train_set[feat]": 1,
      "pd.concat([train_set[feat], test_set[feat]], axis=0)": 1,
      "list(train_data[c].values) + list(test_data[c].values)": 1,
      "list(train_X[f].values) + list(val_X[f].values) + list(test_df[f].values)": 1,
      "X['sub_area'].astype(str)": 1,
      "X['product_type'].astype(str)": 1,
      "df.label": 1,
      "['squad-fpp', 'duo', 'solo-fpp', 'squad', 'duo-fpp', 'solo', 'normal-squad-fpp', 'crashfpp', 'flaretpp', 'normal-solo-fpp', 'flarefpp', 'normal-duo-fpp', 'normal-duo', 'crashtpp', 'normal-squad', 'normal-solo']": 1,
      "list(yy1.values)": 1,
      "list(d1[v].values)": 1,
      "textlabels": 1,
      "outcomes": 1,
      "train['source'].values": 1,
      "df_full[column]": 1,
      "data.Q1.loc[data.Q4 != 'Master\u2019s degree']": 1,
      "data.Q1.loc[data.Q4 == 'Master\u2019s degree']": 1,
      "data.Q5.loc[data.Q4 != 'Master\u2019s degree'].dropna()": 1,
      "data.Q5.loc[data.Q4 == 'Master\u2019s degree'].dropna()": 1,
      "hist_data['Q1']": 1,
      "df[col].unique().tolist() + extra_keys": 1,
      "list(train['Id'].values)": 1,
      "list(train['idhogar'].values)": 1,
      "list(test['Id'].values)": 1,
      "list(test['idhogar'].values)": 1,
      "total_data[i].unique()": 1,
      "train.Age.unique()": 1,
      "train.Fare.unique()": 1,
      "test.Age.unique()": 1,
      "test.Fare.unique()": 1,
      "cat_names[0:num_classes]": 1,
      "list(all_country_codes)": 1,
      "cntntns": 1,
      "pd.concat([train_df[col], test_x[col]]).astype('str')": 1,
      "list(bureau.columns) + list(bureau_balance.columns)": 1,
      "list(test[col].values.astype('str'))": 1,
      "list(total_data[c].values)": 1,
      "list(x_train[f].values)": 1,
      "data[i]": 1,
      "list(g_train_df[col].values.astype('str')) + list(g_test_df[col].values.astype('str'))": 1,
      "t_data['species']": 1,
      "gt": 1,
      "list(train['type'].values) + list(train['type'].values)": 1,
      "yTrain['surface']": 1,
      "list(original_train[f].values)": 1,
      "list(missingValues[f].values)": 1,
      "a_train[col]": 1,
      "df[cate]": 1,
      "fit_by": 1,
      "list(train_dataset[i].values) + list(test_dataset[i].values)": 1,
      "train_set[col].unique().astype('str')": 1,
      "trx_data[cat_col_name].unique().astype('str')": 1,
      "np.unique(list(dt[cols].values) + list(dt_test[cols].values))": 1,
      "train_in_bin_2.place_id.values": 1,
      "df_train['gender']": 1,
      "df_train['signup_method']": 1,
      "df_train['language']": 1,
      "df_train['affiliate_channel']": 1,
      "df_train['affiliate_provider']": 1,
      "df_train['first_affiliate_tracked']": 1,
      "df_train['signup_app']": 1,
      "df_train['first_device_type']": 1,
      "df_train['first_browser']": 1,
      "X[:, i]": 1,
      "list(train_test[f].values) + list(train_test[f].values)": 1,
      "data['title_y'].values": 1,
      "data['title'].values": 1,
      "df_test['experiment']": 1,
      "df_train['event']": 1,
      "df_train['experiment']": 1,
      "train_X[columns]": 1,
      "test_X[columns]": 1,
      "train['Province/State'].unique()": 1,
      "targets_df['target_concat']": 1,
      "rf_combined['original_language']": 1,
      "rf_combined['status']": 1,
      "rf_combined['collection_name']": 1,
      "data['Province/State']": 1,
      "data['Country/Region']": 1,
      "full_var_data": 1,
      "list(train_df[f].values.astype('str')) + list(df_test[f].values.astype('str'))": 1,
      "all_dates": 1,
      "train['PdDistrict']": 1,
      "pd.concat((trainLabel, validLabel))": 1,
      "image_breed_label_list": 1,
      "df.Sex": 1,
      "train_df['primary_use']": 1,
      "list(application_train[c].values.astype('str')) + list(application_test[c].values.astype('str'))": 1,
      "enhanced_train_df['event']": 1,
      "df[col].values": 1,
      "DF.image_code": 1,
      "traindf['species']": 1,
      "new_train[col]": 1,
      "list_title": 1,
      "list_atitle": 1,
      "list_event_code": 1,
      "ID": 1,
      "list(weather[column].values)": 1,
      "list(train[column].values) + list(test[column].values)": 1,
      "list(train_df[col].values)": 1,
      "list(trainData['color'].values)": 1,
      "list(trainData['type'].values)": 1,
      "list(testData['color'].values)": 1,
      "self.data['OffenseFormation']": 1,
      "ord_dict[col]": 1,
      "dataset.ix[:, feat]": 1,
      "train['Province/State']": 1,
      "merged['sentiment'].values": 1,
      "train_tags": 1,
      "merge_df['ProductCD']": 1,
      "merge_df['card4']": 1,
      "merge_df['card6']": 1,
      "list(feature.brand_name)": 1,
      "list(feature.category_name)": 1,
      "list(df_train[column_iter].values.astype('str')) + list(df_eval[column_iter].values.astype('str')) + list(df_actual_test[column_iter].values.astype('str'))": 1,
      "y_true": 1,
      "df_train.brand_name.values.tolist() + df_test.brand_name.values.tolist()": 1,
      "df_train.cat1.values.tolist() + df_test.cat1.values.tolist()": 1,
      "df_train.cat2.values.tolist() + df_test.cat2.values.tolist()": 1,
      "df_train.cat3.values.tolist() + df_test.cat3.values.tolist()": 1,
      "train_data[target_attribute]": 1,
      "list(prox[c].values)": 1,
      "province['Country_Region'].astype(str)": 1,
      "province['Province_State'].astype(str)": 1,
      "Country_exp['Country_Region'].astype(str)": 1,
      "Country_exp['Province_State'].astype(str)": 1,
      "test[c]": 1,
      "list(X_train[col].values.astype('str')) + list(X_test[col].values.astype('str'))": 1,
      "Y_grid": 1,
      "data[c]": 1,
      "list(X['display_address']) + list(X_test['display_address'])": 1,
      "train['label']": 1,
      "tr_y": 1,
      "df_train['Sex']": 1,
      "train_bench[iter]": 1,
      "data[iter]": 1,
      "df['wheezy-copper-turtle-magic']": 1,
      "np.hstack((train_df.loc[:, column].values, test_df.loc[:, column].values))": 1,
      "train['country_destination']": 1,
      "list(train['color']) + list(test['color'])": 1,
      "traindata['species']": 1,
      "list(train_full[f].values)": 1,
      "word_label": 1,
      "df[c]": 1,
      "X[column]": 1,
      "list(new_train[col].astype(str).values) + list(new_test[col].astype(str).values)": 1,
      "X['store_and_fwd_flag']": 1,
      "datas['Country/Region']": 1,
      "full_data.brand_name": 1,
      "full_data.subcat_0": 1,
      "full_data.subcat_1": 1,
      "full_data.subcat_2": 1,
      "full_data[nominal_list[i]]": 1,
      "temp[i]": 1,
      "list(dataa[c].values)": 1,
      "self.df[cat].values": 1,
      "train_add['target']": 1,
      "base_preco2[colName].drop_duplicates()": 1,
      "x[colName].drop_duplicates()": 1,
      "X_teste[colName].drop_duplicates()": 1,
      "fe['cp_type']": 1,
      "fe['cp_dose']": 1,
      "df_train.target": 1,
      "df_stve[col]": 1,
      "df_cal[col]": 1,
      "df_price[col]": 1,
      "test[col].append(train[col]).to_frame()": 1,
      "train_user_combine['date_account_created_day']": 1,
      "train_user_combine['country_destination']": 1,
      "locations": 1,
      "self.classes": 1,
      "df_train['keyword']": 1,
      "df_test['keyword']": 1,
      "X.fillna(self.missing_value_replacement)": 1,
      "list(features[cols].values)": 1,
      "building_meta.primary_use": 1,
      "list(train_df[x].astype(str).values) + list(test_df[x].astype(str).values)": 1,
      "np.unique(y_train)": 1,
      "list(train['Field6'].values) + list(test['Field6'].values)": 1,
      "pd.concat([train, test])[col]": 1,
      "lectures['type_of']": 1,
      "np.unique(list(train_users[f].values) + list(test_users[f].values))": 1,
      "data['RescuerID']": 1,
      "train['State']": 1,
      "test['State']": 1,
      "train['category']": 1,
      "Types": 1,
      "Holidays": 1,
      "trainCopy['NAME_CONTRACT_TYPE']": 1,
      "trainCopy['CODE_GENDER']": 1,
      "trainCopy['FLAG_OWN_CAR']": 1,
      "trainCopy['FLAG_OWN_REALTY']": 1,
      "trainCopy['NAME_TYPE_SUITE']": 1,
      "trainCopy['NAME_INCOME_TYPE']": 1,
      "trainCopy['NAME_EDUCATION_TYPE']": 1,
      "trainCopy['NAME_FAMILY_STATUS']": 1,
      "trainCopy['NAME_HOUSING_TYPE']": 1,
      "trainCopy['OCCUPATION_TYPE']": 1,
      "trainCopy['ORGANIZATION_TYPE']": 1,
      "trainCopy['WEEKDAY_APPR_PROCESS_START']": 1,
      "trainCopy['FONDKAPREMONT_MODE']": 1,
      "trainCopy['HOUSETYPE_MODE']": 1,
      "trainCopy['WALLSMATERIAL_MODE']": 1,
      "trainCopy['EMERGENCYSTATE_MODE']": 1,
      "previous_applicationEncoding['NAME_CONTRACT_TYPE']": 1,
      "previous_applicationEncoding['FLAG_LAST_APPL_PER_CONTRACT']": 1,
      "previous_applicationEncoding['WEEKDAY_APPR_PROCESS_START']": 1,
      "previous_applicationEncoding['NAME_CASH_LOAN_PURPOSE']": 1,
      "previous_applicationEncoding['NAME_CONTRACT_STATUS']": 1,
      "previous_applicationEncoding['NAME_PAYMENT_TYPE']": 1,
      "previous_applicationEncoding['CODE_REJECT_REASON']": 1,
      "previous_applicationEncoding['NAME_TYPE_SUITE']": 1,
      "previous_applicationEncoding['NAME_CLIENT_TYPE']": 1,
      "previous_applicationEncoding['NAME_GOODS_CATEGORY']": 1,
      "previous_applicationEncoding['NAME_PORTFOLIO']": 1,
      "previous_applicationEncoding['NAME_PRODUCT_TYPE']": 1,
      "previous_applicationEncoding['CHANNEL_TYPE']": 1,
      "previous_applicationEncoding['NAME_YIELD_GROUP']": 1,
      "previous_applicationEncoding['PRODUCT_COMBINATION']": 1,
      "previous_applicationEncoding['NAME_SELLER_INDUSTRY']": 1,
      "traintestCopy['NAME_CONTRACT_TYPE']": 1,
      "traintestCopy['CODE_GENDER']": 1,
      "traintestCopy['FLAG_OWN_CAR']": 1,
      "traintestCopy['FLAG_OWN_REALTY']": 1,
      "traintestCopy['NAME_TYPE_SUITE']": 1,
      "traintestCopy['NAME_INCOME_TYPE']": 1,
      "traintestCopy['NAME_EDUCATION_TYPE']": 1,
      "traintestCopy['NAME_FAMILY_STATUS']": 1,
      "traintestCopy['NAME_HOUSING_TYPE']": 1,
      "traintestCopy['OCCUPATION_TYPE']": 1,
      "traintestCopy['ORGANIZATION_TYPE']": 1,
      "traintestCopy['WEEKDAY_APPR_PROCESS_START']": 1,
      "traintestCopy['FONDKAPREMONT_MODE']": 1,
      "traintestCopy['HOUSETYPE_MODE']": 1,
      "traintestCopy['WALLSMATERIAL_MODE']": 1,
      "traintestCopy['EMERGENCYSTATE_MODE']": 1,
      "list(np.append(x_train[c].values, x_test[c].values))": 1,
      "merged_collection": 1,
      "merged_language": 1,
      "train_test.sex": 1,
      "train_test.anatom_site_general_challenge": 1,
      "df['building_id']": 1,
      "list(train[cat].values.astype('str')) + list(test[cat].values.astype('str'))": 1,
      "df.sentiment.tolist()": 1,
      "X[text]": 1,
      "dataframe[i]": 1,
      "df[cf1].unique()": 1,
      "target_train.surface.values.reshape(-1, 1)": 1,
      "X_train[cf].unique()": 1,
      "X_test[cf].unique()": 1,
      "df_items['family']": 1,
      "train_df[features]": 1,
      "pd.concat([df_train['Intersection'], df_test['Intersection']]).drop_duplicates().values": 1,
      "list(all_data[col].values.astype('str'))": 1,
      "list(train_flat[col].values.astype('str')) + list(test_flat[col].values.astype('str'))": 1,
      "productCategory_df['category_id']": 1,
      "raw_train_data['primary_use']": 1,
      "train_data['Embarked']": 1,
      "list(train_new[f].values)": 1,
      "gender_age_train['gender']": 1,
      "df.meta_category": 1,
      "df.town": 1,
      "train_data['SmokingStatus']": 1,
      "train_data.author": 1,
      "list(train_ds[val].values)": 1,
      "list(df_train['manager_id'].values)": 1,
      "list(df_test['manager_id'].values)": 1,
      "list(df[f].values) + list(df[f].values)": 1,
      "list(properties['A-propertyzoning'].values)": 1,
      "list(properties['A-country-code'].values)": 1,
      "list(properties['A-city-code'].values)": 1,
      "list(properties['A-town-code'].values)": 1,
      "list(properties[feature].values)": 1,
      "np.concatenate([train['category_name'], test['category_name']])": 1,
      "np.concatenate([train['brand_name'], test['brand_name']])": 1,
      "list(X_le[f].values)": 1,
      "list(X_be[f].values)": 1,
      "train[colum]": 1,
      "np.hstack([df_train.category_name, df_test.category_name])": 1,
      "np.hstack([df_train.brand_name, df_test.brand_name])": 1,
      "list(train_mac[f].values.astype('str')) + list(test_mac[f].values.astype('str'))": 1,
      "list(train_clean_rob[f].values) + list(test_clean_rob[f].values)": 1,
      "col": 1,
      "train2['statusCode'].values.reshape((-1, 1))": 1,
      "X_train[feature].append(X_test[feature]).astype(str)": 1,
      "label_status": 1,
      "gatrain.gender": 1,
      "age_train.group.values": 1,
      "phone_brand['phone_brand']": 1,
      "dataset[feature]": 1,
      "np.hstack([train_df[col_name], test_df[col_name]])": 1,
      "list(train_df[f].values + test_df[f].values)": 1,
      "train.ebird_code.values": 1,
      "df.phone_brand": 1,
      "df.device_model": 1,
      "df.group": 1,
      "['Adoption', 'Died', 'Euthanasia', 'Return_to_owner', 'Transfer']": 1,
      "all_aug.source_system_tab": 1,
      "all_aug.source_screen_name": 1,
      "all_aug.source_type": 1,
      "all_aug.genre_ids": 1,
      "all_aug.artist_name": 1,
      "all_aug.composer": 1,
      "all_aug.lyricist": 1,
      "all_aug.name": 1,
      "all_aug.isrc": 1,
      "all_aug.gender": 1,
      "list(df_train[feature].astype(str).values) + list(df_test[feature].astype(str).values)": 1,
      "list(dataframe[c].values)": 1,
      "tmp.values": 1,
      "cp_type": 1,
      "np.unique(list(train_val[f].values) + list(test_val[f].values))": 1,
      "RF_train_X[label]": 1,
      "list(_df_train[col]) + list(_df_test[col])": 1,
      "df[i].values.astype('str')": 1,
      "all_df[i]": 1,
      "['True', 'False']": 1,
      "train['patient_id'].unique()": 1,
      "train['sex'].unique()": 1,
      "train['anatom_site_general_challenge'].unique()": 1,
      "test['patient_id'].unique()": 1,
      "DATA_TRAIN['prior_question_had_explanation'].unique()": 1,
      "dataframe['patient_id'].unique()": 1,
      "dataframe['sex'].unique()": 1,
      "dataframe['anatom_site_general_challenge'].unique()": 1,
      "os.listdir('../input/train')": 1,
      "applabelCategories.label_id": 1,
      "applabelCategories.category": 1,
      "data_raw['type']": 1,
      "labels_all": 1,
      "Y_train_label": 1,
      "Y_test_label": 1,
      "list(df_all[f].values.astype('str'))": 1,
      "test_data[cf1].unique()": 1
    },
    "sklearn.preprocessing._label.LabelEncoder.transform.y": {
      "train[:, i]": 231,
      "test[:, i]": 231,
      "list(x_test[c].values)": 226,
      "list(x_train[c].values)": 225,
      "list(train[c].values)": 173,
      "list(train_df[f].values)": 168,
      "list(test_df[f].values)": 167,
      "list(test[c].values)": 160,
      "list(train[f].values)": 135,
      "list(test[f].values)": 127,
      "train_s[:, i]": 126,
      "test_s[:, i]": 126,
      "m": 116,
      "y": 103,
      "list(properties[c].values)": 98,
      "test[col]": 80,
      "phone['phone_brand']": 78,
      "app_test[col]": 75,
      "appevents.app_id": 75,
      "app_train[col]": 74,
      "gatrain.group": 73,
      "applabels.app_id": 72,
      "applabels.label_id": 71,
      "train.species": 70,
      "train['device_id']": 70,
      "test['device_id']": 70,
      "np.array(test_features[col].astype(str)).reshape((-1, ))": 63,
      "FLS['device_id']": 63,
      "train[col]": 56,
      "list(train_df[col].values.astype('str'))": 48,
      "list(test_df[col].values.astype('str'))": 48,
      "list(x_all[c].values)": 47,
      "list(X_test[f].values)": 42,
      "list(X_train[f].values)": 41,
      "train[c].values": 39,
      "test[c].values": 39,
      "train['species']": 39,
      "list(train[col].values.astype('str'))": 37,
      "gatrain.group.values": 36,
      "phone.phone_brand": 36,
      "list(test[col].values.astype('str'))": 36,
      "train.brand_name": 32,
      "test.brand_name": 31,
      "list(df_train[f].values)": 31,
      "y_train": 30,
      "test_df[col]": 30,
      "train.category_name": 30,
      "test.category_name": 30,
      "list(df_test[f].values)": 30,
      "train_df[feature]": 30,
      "X_train[f].ravel()": 29,
      "X_test[f].ravel()": 29,
      "list(train[col].astype(str).values)": 29,
      "list(test[col].astype(str).values)": 29,
      "list(prop[c].values)": 28,
      "train_df[col]": 28,
      "list(train[feature].astype(str).values)": 28,
      "list(test[feature].astype(str).values)": 28,
      "test['Country_Region']": 24,
      "test[c]": 23,
      "test_df['prior_question_had_explanation']": 23,
      "train['Species'].values": 22,
      "test['Species'].values": 22,
      "df[c].astype(str)": 22,
      "le.classes_": 22,
      "list(all_data[c].values)": 22,
      "train['Street'].values": 21,
      "test['Street'].values": 21,
      "train['Trap'].values": 21,
      "test['Trap'].values": 21,
      "test['primary_use']": 20,
      "train[cat_col]": 19,
      "test['PdDistrict']": 19,
      "train[feature]": 18,
      "test_df['Country_Region']": 17,
      "list(train[col].values)": 17,
      "test['Province_State']": 17,
      "list(df_train[c].values)": 16,
      "df[col]": 16,
      "authorHistoryDF": 16,
      "list(test[col].values)": 15,
      "list(train_df[name1].values)": 14,
      "list(test_df[name1].values)": 14,
      "train_y": 13,
      "list(df[f].values)": 13,
      "test[c].astype(str)": 12,
      "test[i]": 12,
      "X[col]": 12,
      "y_test": 12,
      "test_data['Country_Region']": 12,
      "train_data[col]": 12,
      "test_data[col]": 12,
      "df_test[col]": 12,
      "data.loc[:, i]": 12,
      "test[feature]": 12,
      "list(df_test[c].values)": 11,
      "list(train_df[f].values.astype('str'))": 11,
      "[x]": 11,
      "train_cat[col]": 11,
      "test_cat[col]": 11,
      "label_encoder.classes_": 11,
      "train_df[column]": 11,
      "test_df[column]": 11,
      "dataset.iloc[:, i]": 11,
      "train.landmark_id": 11,
      "train[c].astype(str)": 11,
      "train[c]": 11,
      "train[usecol]": 11,
      "test[usecol]": 11,
      "train[col].astype(str)": 11,
      "list(train_test[f].values)": 11,
      "list(test_df[f].values.astype('str'))": 10,
      "X_test[col]": 10,
      "train[i]": 10,
      "Y": 10,
      "dataset_test.iloc[:, i]": 10,
      "list(train_data[f].values)": 10,
      "in_df['word'].values": 10,
      "list(trn_df[name1].values)": 10,
      "list(sub_df[name1].values)": 10,
      "data.loc[:, 'site_id']": 10,
      "test_data.loc[:, i]": 10,
      "list(train_df[c].values)": 10,
      "[nextChar]": 10,
      "df[c].values": 10,
      "test_shops": 9,
      "test_items": 9,
      "range(7, 11)": 9,
      "X_train[col]": 9,
      "train_labels": 9,
      "train[col].fillna('').astype(str)": 9,
      "test[col].fillna('').astype(str)": 9,
      "seasonGames['WTeamID']": 9,
      "seasonGames['LTeamID']": 9,
      "valid_set['word'].values": 9,
      "test['air_store_id']": 9,
      "list(test_data[f].values)": 9,
      "test_data.loc[:, 'site_id']": 9,
      "list(train_data[c].values)": 9,
      "train['Address']": 9,
      "test['Address']": 9,
      "X": 8,
      "labels": 8,
      "test_data['Province_State']": 8,
      "application_test[col]": 8,
      "list(test_df[c].values)": 8,
      "list(df_all[c].values)": 8,
      "test[col].astype(str)": 8,
      "list(df[col].values.astype('str'))": 8,
      "[ch for ch in histChars]": 8,
      "list(prudential_df[f].values)": 7,
      "trainLabel[0]": 7,
      "df_test['Country_Region']": 7,
      "test_labels": 7,
      "FLS6['device_id']": 7,
      "df_train[col]": 7,
      "train['target']": 7,
      "list(test_data[c].values)": 7,
      "tr_cat_col": 7,
      "ts_cat_col": 7,
      "tr_brand_col": 7,
      "ts_brand_col": 7,
      "df1[col].fillna('PreProcEmpty')": 6,
      "final[col]": 6,
      "train['Category']": 6,
      "list(train_features[feature].astype(str).values)": 6,
      "list(test_features[feature].astype(str).values)": 6,
      "data[feature]": 6,
      "train_df[col].astype(str)": 6,
      "list(airbnb_df[f].values)": 6,
      "val_labels": 6,
      "application_train[col]": 6,
      "train_df['labels']": 6,
      "test['brand_name']": 6,
      "test[e]": 6,
      "P[col]": 6,
      "test['Sex']": 6,
      "train[col_name]": 6,
      "test[col_name]": 6,
      "df['_collection_name'].fillna('').astype(str)": 6,
      "test['day_of_week']": 6,
      "traininglabels[0]": 6,
      "[ch for ch in history]": 6,
      "list(df['manager_id'].values)": 6,
      "X_test['Province']": 6,
      "train_df['category_id']": 6,
      "train_vals": 6,
      "test_vals": 6,
      "dataset['region']": 6,
      "dataset['city']": 6,
      "dataset['category_name']": 6,
      "dataset['parent_category_name']": 6,
      "public_training_dates": 6,
      "list(application_train[col].values.astype('str'))": 5,
      "list(application_test[col].values.astype('str'))": 5,
      "train_data[cf1]": 5,
      "testing_data['Country_Region']": 5,
      "train[column].astype(str)": 5,
      "y_raw": 5,
      "test_df[col].astype(str)": 5,
      "y['surface']": 5,
      "locations_df.cluster": 5,
      "lbl": 5,
      "df['word'].values": 5,
      "df['Country_Region']": 5,
      "train[feature].astype(str)": 5,
      "test[feature].astype(str)": 5,
      "list(test[i].values)": 5,
      "list(X[f].values)": 5,
      "test['Target']": 5,
      "train['Intersection']": 5,
      "test['Intersection']": 5,
      "list(all_data[col].values)": 5,
      "train[field].values": 5,
      "test[field].values": 5,
      "X_test[c]": 5,
      "test[col].values": 5,
      "test_df['cp']": 5,
      "train['day_of_week']": 5,
      "train['pd_district']": 5,
      "test['pd_district']": 5,
      "test['Embarked']": 5,
      "list(homesite_df[f].values)": 5,
      "train_raw['Category']": 5,
      "test['Country/Region']": 5,
      "train['brand_name']": 5,
      "train_df[target_col]": 5,
      "dataset[column]": 5,
      "tr_col": 5,
      "ts_col": 5,
      "list(all_data[f].values)": 4,
      "x['Country_Region']": 4,
      "x['Province_State']": 4,
      "test_x['Country_Region']": 4,
      "test_x['Province_State']": 4,
      "test[column].astype(str)": 4,
      "list(properties16[c].values)": 4,
      "list(properties17[c].values)": 4,
      "df['collection_name'].fillna('').astype(str)": 4,
      "list(house_data[c].values)": 4,
      "df_test[i]": 4,
      "list(df[col].values)": 4,
      "train.iloc[:, i]": 4,
      "test.iloc[:, i]": 4,
      "df_test['Province_State']": 4,
      "train_data.loc[:, i_cat]": 4,
      "test_data.loc[:, i_cat]": 4,
      "loadedLabels": 4,
      "df_union['Country_Region']": 4,
      "df_union['Province_Norm']": 4,
      "hadi['shot_zone_area']": 4,
      "train_df.landmark_id": 4,
      "test.State.astype('str') + ':' + test.Country.astype('str')": 4,
      "test_days[-1]['item_id']": 4,
      "test_days[-1]['store_id']": 4,
      "full_df.brand_name": 4,
      "test['store_and_fwd_flag']": 4,
      "list(x_train[f].values)": 4,
      "list(data[c].values)": 4,
      "list(train_df[col].values)": 4,
      "list(test_df[col].values)": 4,
      "X_test_categorical[feature]": 4,
      "train[c].round(n)": 4,
      "test[c].round(n)": 4,
      "y_train_init": 4,
      "data[li]": 4,
      "df['primary_use']": 4,
      "df['species']": 4,
      "labels['event_name_1']": 4,
      "labels['event_name_2']": 4,
      "list(df_train[col].values.astype('str'))": 4,
      "list(df_test[col].values.astype('str'))": 4,
      "list(train_X[f].values)": 4,
      "df_train[c].values": 4,
      "temp[column]": 4,
      "x": 4,
      "[firstChar]": 4,
      "[ch for ch in generatedSentence[-historyLength:]]": 4,
      "cats_train.Hair": 4,
      "df['Province_State']": 4,
      "list(d1[v].values)": 4,
      "train.Product_Info_2_C": 4,
      "test.Product_Info_2_C": 4,
      "dataset['param_1']": 4,
      "dataset['param123']": 4,
      "train_x": 4,
      "public_test_dates": 4,
      "private_test_dates": 4,
      "train['general_cat']": 4,
      "train['subcat_1']": 4,
      "train['subcat_2']": 4,
      "dev['brand_name']": 4,
      "dev['general_cat']": 4,
      "dev['subcat_1']": 4,
      "dev['subcat_2']": 4,
      "test['general_cat']": 4,
      "test['subcat_1']": 4,
      "test['subcat_2']": 4,
      "data['Sex'].values": 4,
      "data['SmokingStatus'].values": 4,
      "dataset[col]": 3,
      "y_val": 3,
      "df2[col].fillna('PreProcEmpty')": 3,
      "data_train[col]": 3,
      "data_test[col]": 3,
      "train_Y[0]": 3,
      "list(dataset[c].values)": 3,
      "train[i].values": 3,
      "test[i].values": 3,
      "X_train[i]": 3,
      "X_val[i]": 3,
      "list(df_all.iloc[:, i].values)": 3,
      "list(X_test[c].values)": 3,
      "data": 3,
      "data[col]": 3,
      "application_train[col].astype(str)": 3,
      "application_test[col].astype(str)": 3,
      "test.sex.astype('str')": 3,
      "test.anatom_site_general_challenge.astype('str')": 3,
      "test_df[feature]": 3,
      "hadi['season']": 3,
      "hadi['opponent']": 3,
      "hadi['shot_zone_range']": 3,
      "test.sex": 3,
      "test.anatom_site_general_challenge": 3,
      "list(train[i].astype('str'))": 3,
      "test[i].astype('str')": 3,
      "test.country_province": 3,
      "test_features['cp_type']": 3,
      "test_features['cp_dose']": 3,
      "test_df.sex.astype('str')": 3,
      "test_df.anatom_site_general_challenge.astype('str')": 3,
      "full_df.category_name": 3,
      "train['store_and_fwd_flag']": 3,
      "train['color']": 3,
      "train['type']": 3,
      "list(train[i].values)": 3,
      "df_regular['HomeTeam']": 3,
      "df_regular['AwayTeam']": 3,
      "df_tourney.WTeamID": 3,
      "df_tourney.LTeamID": 3,
      "test_x[c].fillna('NA')": 3,
      "df['original_language'].fillna('').astype(str)": 3,
      "full_categories": 3,
      "test[name]": 3,
      "train_temp[:, i]": 3,
      "test_temp[:, i]": 3,
      "list(df_train[column_iter].values.astype('str'))": 3,
      "train_df['author']": 3,
      "val_X.type": 3,
      "list(train[f].values.astype('str'))": 3,
      "list(test[f].values.astype('str'))": 3,
      "train['prior_question_had_explanation']": 3,
      "validation['prior_question_had_explanation']": 3,
      "list(train_test[col].values)": 3,
      "encoder.classes_": 3,
      "list(mergedFilterd[f].values)": 3,
      "train_df[col].values": 3,
      "test_df[col].values": 3,
      "test_features[col]": 3,
      "list(inpX[col].astype(str).values)": 3,
      "X[C]": 3,
      "X_train_cat[c]": 3,
      "X_test_cat[c]": 3,
      "all_df[cat]": 3,
      "train_data['species']": 3,
      "all_data[col]": 3,
      "df_test[c]": 3,
      "full_train_df['category']": 3,
      "df['camera']": 3,
      "test[column]": 3,
      "test['Ticket']": 3,
      "list(combined_df[c].values)": 3,
      "building['primary_use']": 3,
      "species": 3,
      "data[label]": 3,
      "train_df.category_name": 3,
      "test_df.category_name": 3,
      "train_df.brand_name": 3,
      "test_df.brand_name": 3,
      "train['author']": 3,
      "label_X_valid[col]": 3,
      "X_test['Province_State']": 3,
      "X_test['Country_Region']": 3,
      "X0": 3,
      "test['Cabin']": 3,
      "train['cat' + str(i)]": 3,
      "test['cat' + str(i)]": 3,
      "test_features[l]": 3,
      "Y_train": 3,
      "list(d2[v].values)": 3,
      "hist_data['Q5']": 3,
      "train_features[cat]": 3,
      "test_features[cat]": 3,
      "list(train['type'].values)": 3,
      "list(test['type'].values)": 3,
      "list(X[cols].values)": 3,
      "data[f].values": 3,
      "test['Province/State']": 3,
      "train.StoreType": 3,
      "test.StoreType": 3,
      "train.Assortment": 3,
      "test.Assortment": 3,
      "train_holiday_in_str": 3,
      "test_holiday_in_str": 3,
      "trainLabel": 3,
      "data_y": 3,
      "levels": 3,
      "device_brand['phone_brand']": 3,
      "app_events['app_id']": 3,
      "app_labels['app_id']": 3,
      "app_labels['label_id']": 3,
      "dataframe['patient_id']": 3,
      "dataframe['sex']": 3,
      "dataframe['anatom_site_general_challenge']": 3,
      "label": 2,
      "train.RescuerID.values": 2,
      "test.RescuerID.values": 2,
      "test_df['Province_State']": 2,
      "self.df[c].values": 2,
      "X_train[f]": 2,
      "df[col].values": 2,
      "list(properties2016[c].values)": 2,
      "list(properties2017[c].values)": 2,
      "train_data.species": 2,
      "df.species": 2,
      "X_train_full[col]": 2,
      "df_train[i]": 2,
      "list(X_train[c].values)": 2,
      "train[x]": 2,
      "test[x]": 2,
      "cuisine_encoder.classes_": 2,
      "ingredient_encoder.classes_": 2,
      "df[feature]": 2,
      "data_df[f_name]": 2,
      "creature": 2,
      "original": 2,
      "test.age_approx.astype('str')": 2,
      "train['matchType']": 2,
      "phone.phone_brand.values": 2,
      "X[:, i]": 2,
      "train['FirstName']": 2,
      "train['SecondName']": 2,
      "test['FirstName']": 2,
      "test['SecondName']": 2,
      "train['Name']": 2,
      "test['Name']": 2,
      "data['City Group']": 2,
      "data['Type']": 2,
      "data.species": 2,
      "list(data[f].values)": 2,
      "df_label['breed']": 2,
      "data_test['Product_Info_2']": 2,
      "list(clean_df[f].values)": 2,
      "list(clean_test[f].values)": 2,
      "train_df['hotel_id']": 2,
      "test_df['age_approx'].astype('str')": 2,
      "X_train['category']": 2,
      "X_test['category']": 2,
      "X_train['host']": 2,
      "X_test['host']": 2,
      "test['color']": 2,
      "list(x_test[f].values)": 2,
      "list(X[i].values)": 2,
      "X[category].values": 2,
      "X_test[category].values": 2,
      "df_labels['breed']": 2,
      "df_train[column]": 2,
      "df_test[column]": 2,
      "list(data[col].values)": 2,
      "list(train_set[f].values)": 2,
      "data.iloc[:, feature]": 2,
      "X_valid[col]": 2,
      "train[name]": 2,
      "list(df[i].values)": 2,
      "X[self.cat]": 2,
      "list(df_test[column_iter].values.astype('str'))": 2,
      "[bird]": 2,
      "df[i]": 2,
      "events['device_id']": 2,
      "df_full[col]": 2,
      "list(df_train_raw[f].values)": 2,
      "list(df_test_raw[f].values)": 2,
      "train_df[c]": 2,
      "test_df[c]": 2,
      "df['seed_letterTeam2']": 2,
      "df.title": 2,
      "train_prepared[col]": 2,
      "test_prepared[col]": 2,
      "evalu['author'].astype(str)": 2,
      "class_list[:5]": 2,
      "[word]": 2,
      "train_df.species": 2,
      "df.brand_name": 2,
      "data.loc[:, 'site']": 2,
      "list(X_train[col].astype(str).values)": 2,
      "list(X_test[col].astype(str).values)": 2,
      "list(df_all[f].values.astype('str'))": 2,
      "label_enc.classes_": 2,
      "['FOODS_3_827']": 2,
      "[item_id]": 2,
      "valid[col].values": 2,
      "train_x[c].fillna('NA')": 2,
      "list(train_transaction[f].values)": 2,
      "list(test_transaction[f].values)": 2,
      "list(train_features[train_feat].astype(str).values)": 2,
      "list(test_features[train_feat].astype(str).values)": 2,
      "author_list": 2,
      "train[variable]": 2,
      "test[variable]": 2,
      "labels_train": 2,
      "test['ord_3']": 2,
      "test['ord_4']": 2,
      "target['surface']": 2,
      "train['Agent']": 2,
      "train['Sub_Page']": 2,
      "train['Access']": 2,
      "train_df[c].astype(str)": 2,
      "test_df[c].astype(str)": 2,
      "test.cat0": 2,
      "test.cat1": 2,
      "test.cat2": 2,
      "df_filtered['sex']": 2,
      "df_filtered['anatom_site_general_challenge']": 2,
      "list(y_train_data['surface'])": 2,
      "training_label[0]": 2,
      "fm_data[c]": 2,
      "prep_df['air_store_id']": 2,
      "predict_data['air_store_id']": 2,
      "list(data[col].values.astype('str'))": 2,
      "train_df[c].values": 2,
      "test_df[c].values": 2,
      "train_df.labels": 2,
      "train_data['color']": 2,
      "train_data[column]": 2,
      "test_data[column]": 2,
      "list(df_train[col].astype(str).values)": 2,
      "list(df_test[col].astype(str).values)": 2,
      "df_train['Intersec']": 2,
      "df_test['Intersec']": 2,
      "target_column": 2,
      "list(df_macro[f].values)": 2,
      "X0_9": 2,
      "list(xtrain[col].values.astype('str'))": 2,
      "list(xtest[col].values.astype('str'))": 2,
      "train[column]": 2,
      "train[col_name].values.astype('str')": 2,
      "test[col_name].values.astype('str')": 2,
      "train['LastName']": 2,
      "test['LastName']": 2,
      "train_identity[col]": 2,
      "test_identity[col]": 2,
      "data[x]": 2,
      "data_sub[x]": 2,
      "train_col": 2,
      "list(test_submit[c].values)": 2,
      "charsDict['EAP']": 2,
      "charsDict['HPL']": 2,
      "charsDict['MWS']": 2,
      "[history]": 2,
      "[histChar]": 2,
      "[generatedSentence[-1]]": 2,
      "[ch for ch in generatedSentence[-2:]]": 2,
      "[secondChar]": 2,
      "test[i].fillna('NA')": 2,
      "df['labels']": 2,
      "list(df_features[f].values)": 2,
      "df_train.brand_name": 2,
      "df_test.brand_name": 2,
      "X_train[feature]": 2,
      "X_test[feature]": 2,
      "df['Province_State'].astype(str)": 2,
      "df['Country_Region'].astype(str)": 2,
      "df['Region'].astype(str)": 2,
      "train_df['label']": 2,
      "data_train.Race1": 2,
      "data_train.Race2": 2,
      "data_train.Color1": 2,
      "data_train.Color2": 2,
      "data_test.Race1": 2,
      "data_test.Race2": 2,
      "data_test.Color1": 2,
      "data_test.Color2": 2,
      "cats_test.Hair": 2,
      "cats_train.Race1": 2,
      "cats_train.Race2": 2,
      "cats_train.Color1": 2,
      "cats_train.Color2": 2,
      "cats_test.Race1": 2,
      "cats_test.Race2": 2,
      "cats_test.Color1": 2,
      "cats_test.Color2": 2,
      "dogs_train.Race1": 2,
      "dogs_train.Race2": 2,
      "dogs_train.Color1": 2,
      "dogs_train.Color2": 2,
      "dogs_test.Race1": 2,
      "dogs_test.Race2": 2,
      "dogs_test.Color1": 2,
      "dogs_test.Color2": 2,
      "test_data['GeoSubregion']": 2,
      "test_data['Income Group']": 2,
      "data_site[:, i]": 2,
      "test_data_site[:, i]": 2,
      "z": 2,
      "df_ar['air_store_id']": 2,
      "df_as['air_store_id']": 2,
      "df_av['air_store_id']": 2,
      "df_hr['air_store_id']": 2,
      "df_hs['air_store_id']": 2,
      "df_test['air_store_id']": 2,
      "training_samples[:, colIndex]": 2,
      "test_samples[:, colIndex]": 2,
      "total_df[c]": 2,
      "train_df['RescuerID']": 2,
      "df['SubmissionId']": 2,
      "df1[col]": 2,
      "train_x[col].astype('str')": 2,
      "test_x[col].astype('str')": 2,
      "list(df_data['primary_use'].values)": 2,
      "dataframe.iloc[:, 94]": 2,
      "list(df_train[col].values)": 2,
      "ytrain.surface": 2,
      "test_csv.iloc[:, 5]": 2,
      "test_csv.iloc[:, 6]": 2,
      "test.iloc[:, 5]": 2,
      "test.iloc[:, 6]": 2,
      "list(X_train[i].values)": 2,
      "list(X_test[i].values)": 2,
      "list(bnp_df[f].values)": 2,
      "valid.loc[:, cat_feat].values.reshape(-1, 1)": 2,
      "Y_val": 2,
      "list(X_train[col].values.astype('str'))": 2,
      "list(X_test[col].values.astype('str'))": 2,
      "list(crew[c].values)": 2,
      "train_set[feat]": 2,
      "test_set[feat]": 2,
      "test_data['anatom_site_general_challenge'].astype('str')": 2,
      "hist_data['Q6']": 2,
      "df_train_encoded[col]": 2,
      "df_test_encoded[col]": 2,
      "X_test['primary_use']": 2,
      "test_features[f]": 2,
      "label_X_train[col]": 2,
      "test['cp_dose']": 2,
      "data['world'].values": 2,
      "train['Province/State']": 2,
      "train['Country/Region']": 2,
      "one_pilot_train_df['event']": 2,
      "src_train['Country/Region']": 2,
      "src_test['Country/Region']": 2,
      "dataset['image_code']": 2,
      "[session['title'].values[0]]": 2,
      "df_calendar['event_type']": 2,
      "df_train[c]": 2,
      "X_train['Province_State']": 2,
      "X_train['Country_Region']": 2,
      "train_df[i].values": 2,
      "test_df[i].values": 2,
      "t_df[col]": 2,
      "train['Country_Region']": 2,
      "train['Target']": 2,
      "df[feature].astype(str)": 2,
      "df.spacegroup": 2,
      "df_val.spacegroup": 2,
      "df.number_of_total_atoms": 2,
      "df_val.number_of_total_atoms": 2,
      "list(df1[col].values.astype('str'))": 2,
      "data_x": 2,
      "[image_name]": 2,
      "prop['propertycountylandusecode']": 2,
      "prop['propertyzoningdesc']": 2,
      "list(data[col].astype(str).values)": 2,
      "list(train0[col].astype(str).values)": 2,
      "temp_ds[col]": 2,
      "train_data['Sex']": 2,
      "test_data['Sex']": 2,
      "train_data.author": 2,
      "ga_train['group']": 2,
      "all_df[col]": 2,
      "yuanlai": 2,
      "cp_time": 2,
      "cp_dose": 2,
      "list(train_copy[col].astype(str).values)": 2,
      "list(test_copy[col].astype(str).values)": 2,
      "data['CentralAir']": 2,
      "data['KitchenQual']": 2,
      "data['GarageType']": 2,
      "data['BsmtCond']": 2,
      "data['Electrical']": 2,
      "dataframe['Patient']": 2,
      "df['author']": 2,
      "device_id_rows": 1,
      "app_id_cols": 1,
      "list(m)": 1,
      "y_valid": 1,
      "X_test['color']": 1,
      "train[cols].values": 1,
      "test[cols].values": 1,
      "list(dft2[f].values)": 1,
      "list(dfte2[f].values)": 1,
      "list(x_train[col].values.astype('str'))": 1,
      "list(x_test[col].values.astype('str'))": 1,
      "attr_": 1,
      "dtrain[col]": 1,
      "dtest[col]": 1,
      "train_data_df_m['primary_use']": 1,
      "train_app[col]": 1,
      "test_app[col]": 1,
      "data[c].astype(str)": 1,
      "df_test[col].values": 1,
      "self.test[e]": 1,
      "list(train[col].astype(str))": 1,
      "list(test[col].astype(str))": 1,
      "list(dftrain[col].values.astype('str'))": 1,
      "test_df['type'].values": 1,
      "[labelname]": 1,
      "list(train_df_obj[c].values)": 1,
      "test2016[column].astype(str)": 1,
      "test2017[column].astype(str)": 1,
      "list(prop2017[c].values)": 1,
      "x_train_imputed_cat[col]": 1,
      "x_test_imputed_cat[col]": 1,
      "full_data.loc[:, feature].values.tolist()": 1,
      "test['AnimalType']": 1,
      "data_frame[column]": 1,
      "train_label": 1,
      "data2": 1,
      "lebels.breed": 1,
      "leb": 1,
      "train_cat[colName]": 1,
      "test_cat[colName]": 1,
      "test.store_and_fwd_flag": 1,
      "X_test['Type']": 1,
      "train['cuisine']": 1,
      "yAll": 1,
      "test.cp_dose": 1,
      "train[i].astype(str)": 1,
      "test[i].astype(str)": 1,
      "unique_labels": 1,
      "loadedLabelsTrain": 1,
      "df_events['device_id'].values": 1,
      "df_gender_age_train['device_id'].values": 1,
      "df_app_events['app_id'].values": 1,
      "df_app_labels['app_id'].values": 1,
      "df_all[c].astype(str)": 1,
      "train_image_df['integer_label']": 1,
      "train['Id']": 1,
      "train['groupId']": 1,
      "train['matchId']": 1,
      "df['target']": 1,
      "mod_train_df[feature]": 1,
      "mod_test_df[feature]": 1,
      "target_df['surface']": 1,
      "new_merchant_transactions['category_1']": 1,
      "historical_transactions['category_1']": 1,
      "df_test['type']": 1,
      "hadi['combined_shot_type']": 1,
      "test['title']": 1,
      "train2['color']": 1,
      "list(df[x].values)": 1,
      "all_tsdf['country']": 1,
      "all_tsdf['state']": 1,
      "dataframe[cat]": 1,
      "X_test[:, i]": 1,
      "train.author": 1,
      "dropped_df[col]": 1,
      "list(train[c].astype(str))": 1,
      "list(test[c].astype(str))": 1,
      "x_train[c].astype(str)": 1,
      "x_cv[c].astype(str)": 1,
      "test_data[c].astype(str)": 1,
      "train['idhogar']": 1,
      "train_new['idhogar']": 1,
      "test['idhogar']": 1,
      "test_new['idhogar']": 1,
      "testData['Sex']": 1,
      "testData['SmokingStatus']": 1,
      "test['Alley']": 1,
      "test['LandSlope']": 1,
      "test['YearBuilt']": 1,
      "test['WoodDeckSF']": 1,
      "y_train.surface.values": 1,
      "[surf]": 1,
      "encode_table[i]": 1,
      "test.province": 1,
      "train_transaction[col]": 1,
      "test_transaction[col]": 1,
      "train.author.values": 1,
      "train.Country_Region": 1,
      "train.Province_State": 1,
      "test.Country_Region": 1,
      "test.Province_State": 1,
      "train_df['brand_name']": 1,
      "train_df['general_cat']": 1,
      "train_df['subcat_1']": 1,
      "train_df['subcat_2']": 1,
      "dev_df['brand_name']": 1,
      "dev_df['general_cat']": 1,
      "dev_df['subcat_1']": 1,
      "dev_df['subcat_2']": 1,
      "test_df['brand_name']": 1,
      "test_df['general_cat']": 1,
      "test_df['subcat_1']": 1,
      "test_df['subcat_2']": 1,
      "sell_prices['item_id']": 1,
      "test['sex'].astype(str)": 1,
      "test['anatom_site_general_challenge'].astype(str)": 1,
      "seasonGames['Winner']": 1,
      "seasonGames['Loser']": 1,
      "train_transaction_full[label_col]": 1,
      "test_transaction_full[label_col]": 1,
      "train_identity_full[label_col]": 1,
      "test_identity_full[label_col]": 1,
      "['unknown_play_cat']": 1,
      "['unknown_player_cat']": 1,
      "train_cat.iloc[trn_]": 1,
      "train_cat.iloc[val_]": 1,
      "test_cat": 1,
      "df_acaps_agg['Region']": 1,
      "train_df[col].fillna('').astype(str)": 1,
      "test_df[col].fillna('').astype(str)": 1,
      "x_train['category_name']": 1,
      "x_test['category_name']": 1,
      "x_train['brand_name']": 1,
      "x_test['brand_name']": 1,
      "dataframe[col]": 1,
      "df_val[col]": 1,
      "df_train[feature]": 1,
      "df_test[feature]": 1,
      "X_test_full[col]": 1,
      "train_tv_y": 1,
      "val_tv_y": 1,
      "test.license.values": 1,
      "list(tn[o].values)": 1,
      "list(train['category'].values)": 1,
      "list(test['category'].values)": 1,
      "list(X_trn_df[f])": 1,
      "list(X_test[f])": 1,
      "X_full[column]": 1,
      "X_test[column]": 1,
      "pred_template['Patient']": 1,
      "df_train[columna]": 1,
      "df_test[columna]": 1,
      "df_regular_2017['HomeTeam']": 1,
      "df_regular_2017['AwayTeam']": 1,
      "df_tourney_2017.WTeamID": 1,
      "df_tourney_2017.LTeamID": 1,
      "df['cat1']": 1,
      "df['cat2']": 1,
      "df['cat3']": 1,
      "test['cat1']": 1,
      "test['cat2']": 1,
      "test['cat3']": 1,
      "df['brand_name']": 1,
      "new_test[cols]": 1,
      "test_feature['cp_type']": 1,
      "test_feature['cp_time']": 1,
      "test_feature['cp_dose']": 1,
      "train.category1": 1,
      "test.category1": 1,
      "train.category2": 1,
      "test.category2": 1,
      "valid.landmark_id": 1,
      "data['Species'].values": 1,
      "data['Street'].values": 1,
      "data['Trap'].values": 1,
      "train_data[c]": 1,
      "test_data[c]": 1,
      "train_df['building_id']": 1,
      "test_df['building_id']": 1,
      "train_df['manager_id']": 1,
      "test_df['manager_id']": 1,
      "train_df['loc']": 1,
      "test_df['loc']": 1,
      "object_test[col]": 1,
      "list(full[c].values)": 1,
      "train_df['cuisine'].values": 1,
      "test_df['cuisine'].values": 1,
      "df_train[feature].astype(str)": 1,
      "df_test[feature].astype(str)": 1,
      "df[col].astype('str')": 1,
      "train_data.project_subject_categories": 1,
      "test_data.project_subject_categories": 1,
      "train_data.project_subject_subcategories": 1,
      "test_data.project_subject_subcategories": 1,
      "train_data.project_grade_category": 1,
      "test_data.project_grade_category": 1,
      "train[c].fillna('NA')": 1,
      "list(test_set[f].values)": 1,
      "df_test1['Country_Region']": 1,
      "train['wheezy-copper-turtle-magic']": 1,
      "test['wheezy-copper-turtle-magic']": 1,
      "leaf_train": 1,
      "leaf_valid": 1,
      "leaf_test": 1,
      "all_data[cols]": 1,
      "list(df[feature].values)": 1,
      "list(datas[cus_prefix + '_cols_index'].values)": 1,
      "pred_user_raw.loc[:, 'title']": 1,
      "pred_user_raw.loc[:, 'type']": 1,
      "pred_user_raw.loc[:, 'world']": 1,
      "pred_user_raw.loc[:, 'dayofweek']": 1,
      "combdata.newCategory": 1,
      "combdata.Brand": 1,
      "list(train[c].fillna('').values)": 1,
      "list(test[c].fillna('').values)": 1,
      "df_test['matchType']": 1,
      "train.labels": 1,
      "train_df.lockdown_type": 1,
      "extract_region(train_df)": 1,
      "extract_region(test_df)": 1,
      "extract_region(region_metadata)": 1,
      "train_data.general_cat": 1,
      "test_data.general_cat": 1,
      "train_data.brand_name": 1,
      "test_data.brand_name": 1,
      "train_data.subcat_1": 1,
      "test_data.subcat_1": 1,
      "train_data.subcat_2": 1,
      "test_data.subcat_2": 1,
      "train[i].fillna('').astype(str)": 1,
      "test[i].fillna('').astype(str)": 1,
      "x.category_name": 1,
      "test_category": 1,
      "x.brand_name": 1,
      "test_brand": 1,
      "list(prop[col].values)": 1,
      "list(df_train_model1[column_iter].values.astype('str'))": 1,
      "list(df_test_model1[column_iter].values.astype('str'))": 1,
      "feature": 1,
      "df_train_data.installation_id.values": 1,
      "X_train['class']": 1,
      "y_valid['class']": 1,
      "train_cat[c].values": 1,
      "test_cat[c].values": 1,
      "train_df[cat]": 1,
      "test_df[cat]": 1,
      "list(train[col].astype('str').values)": 1,
      "list(test[col].astype('str').values)": 1,
      "data_train[i].values": 1,
      "df_test[i].values": 1,
      "train_test": 1,
      "train.index": 1,
      "test.index": 1,
      "pbd['device_id']": 1,
      "data[bssid_feat]": 1,
      "df_full['SmokingStatus']": 1,
      "temp": 1,
      "train.label": 1,
      "sales[col]": 1,
      "cal[col]": 1,
      "test_x[col]": 1,
      "list(allDf[c].values)": 1,
      "labelcat.category": 1,
      "new_brands": 1,
      "new_categories": 1,
      "list(train_df_new[f].values)": 1,
      "list(downsampled[col].astype(str).values)": 1,
      "X_train.loc[:, i]": 1,
      "X_test.loc[:, i]": 1,
      "X_train.loc[:, 'building']": 1,
      "X_test.loc[:, 'building']": 1,
      "data.place_id": 1,
      "y_train_split": 1,
      "y_valid_split": 1,
      "list(df_tot[c].values)": 1,
      "train_val": 1,
      "shops.shop_name0": 1,
      "shops.shop_name1": 1,
      "shops.shop_name2": 1,
      "categories.item_category_name0": 1,
      "categories.item_category_name1": 1,
      "categories.item_category_name2": 1,
      "items.item_name0": 1,
      "items.item_name1": 1,
      "items.item_name2": 1,
      "train_with_specs['type']": 1,
      "train_with_specs['world']": 1,
      "test_with_specs['type']": 1,
      "test_with_specs['world']": 1,
      "list(X[feature].values)": 1,
      "df_without_null['NAME_INCOME_TYPE']": 1,
      "LabelEncoder.classes_": 1,
      "label_set": 1,
      "train[target]": 1,
      "trainData[i]['ingredients']": 1,
      "testData[i]['ingredients']": 1,
      "new_df.provider": 1,
      "Y_new": 1,
      "[category]": 1,
      "train.Type": 1,
      "list(X[feature].astype(str).values)": 1,
      "test['dayofweek']": 1,
      "_df_train['City']": 1,
      "_df_test['City']": 1,
      "_df_train['EntryStreetType']": 1,
      "_df_train['ExitStreetType']": 1,
      "_df_test['EntryStreetType']": 1,
      "_df_test['ExitStreetType']": 1,
      "df['release_year'].values": 1,
      "df.len_desc": 1,
      "df.category_level1": 1,
      "df.category_level2": 1,
      "df.category_level3": 1,
      "df.item_condition_id": 1,
      "df.version": 1,
      "test_data.loc[:, 'site']": 1,
      "train['Sex']": 1,
      "d[c].values": 1,
      "df_train['store_and_fwd_flag']": 1,
      "df_test['store_and_fwd_flag']": 1,
      "df_train['vendor_id']": 1,
      "df_test['vendor_id']": 1,
      "list(X_train[L].values.astype(str))": 1,
      "list(X_test[L].values.astype(str))": 1,
      "train_xgb['cp_type'].astype(str)": 1,
      "train_xgb['cp_dose'].astype(str)": 1,
      "test_xgb['cp_type'].astype(str)": 1,
      "test_xgb['cp_dose'].astype(str)": 1,
      "all_data[col][len(train):]": 1,
      "test_X['PdDistrict']": 1,
      "test[cat]": 1,
      "list(train_df[feat].values.astype('str'))": 1,
      "classes": 1,
      "OS_X_valid_clean['Product_Info_2']": 1,
      "dftrain['category_name']": 1,
      "dftest['category_name']": 1,
      "dftrain['brand_name']": 1,
      "dftest['brand_name']": 1,
      "test['license']": 1,
      "shop_and_item.shop_and_item": 1,
      "train.shop_and_item": 1,
      "grid.shop_and_item": 1,
      "list(all_data['manager_id'].values)": 1,
      "df_dates['event_type_1']": 1,
      "df_dates['event_type_2']": 1,
      "train2[col].values": 1,
      "test2[col].values": 1,
      "X_train[c]": 1,
      "folds_data['target']": 1,
      "df_trn.word": 1,
      "df_val.word": 1,
      "train_df_categorical[i]": 1,
      "test_dataset['Sex']": 1,
      "test_dataset['Embarked']": 1,
      "return_df[col_name]": 1,
      "train.general_cat": 1,
      "test.general_cat": 1,
      "train.subcat_1": 1,
      "test.subcat_1": 1,
      "train.subcat_2": 1,
      "test.subcat_2": 1,
      "train_data[feature]": 1,
      "test_data[feature]": 1,
      "list(bool_feature_people[i].values)": 1,
      "test['City Group']": 1,
      "train['Type']": 1,
      "df_data[feature]": 1,
      "df.loc[:, feature_name]": 1,
      "df_train[col].astype(str)": 1,
      "df_test[col].astype(str)": 1,
      "['A']": 1,
      "['Z']": 1,
      "train_s1[:, i]": 1,
      "test_s1[:, i]": 1,
      "train2[c].fillna('NA')": 1,
      "test2[c].fillna('NA')": 1,
      "self.valid['session_title']": 1,
      "self.valid['world']": 1,
      "self.test['session_title']": 1,
      "self.test['world']": 1,
      "data_tes1['enco_day']": 1,
      "train_x[label]": 1,
      "df_calendar['event_name_1']": 1,
      "df_calendar['event_name_2']": 1,
      "df_calendar['event_type_1']": 1,
      "df_calendar['event_type_2']": 1,
      "df_calendar['event_tomorrow_1']": 1,
      "df_calendar['event_tomorrow_2']": 1,
      "df_calendar['event_type_tomorrow_1']": 1,
      "df_calendar['event_type_tomorrow_2']": 1,
      "d.cell_type": 1,
      "train_word.values": 1,
      "valid_word.values": 1,
      "train_test_word.values": 1,
      "list(train[f].astype(str).values)": 1,
      "list(test[f].astype(str).values)": 1,
      "list(train_feat[feature].astype(str).values)": 1,
      "list(test_feat[feature].astype(str).values)": 1,
      "train_target_label": 1,
      "titanic_data.Cabin.values": 1,
      "test.Cabin.values": 1,
      "col_val_train": 1,
      "col_val_test": 1,
      "X['day_of_week']": 1,
      "X_test['day_of_week']": 1,
      "X['air_genre_name']": 1,
      "X_test['air_genre_name']": 1,
      "X['air_area_name']": 1,
      "X_test['air_area_name']": 1,
      "X['air_store_id']": 1,
      "X_test['air_store_id']": 1,
      "sales[c].astype(str)": 1,
      "train['ord_0']": 1,
      "test['ord_0']": 1,
      "train['ord_1']": 1,
      "test['ord_1']": 1,
      "train['ord_2']": 1,
      "test['ord_2']": 1,
      "train['ord_3']": 1,
      "train['ord_4']": 1,
      "test['age_approx'].astype('str')": 1,
      "people[col]": 1,
      "act[col]": 1,
      "train_df.ip": 1,
      "train_df.os": 1,
      "train_df.device": 1,
      "train_df.channel": 1,
      "train_df.app": 1,
      "test_df.ip": 1,
      "test_df.os": 1,
      "test_df.device": 1,
      "test_df.channel": 1,
      "test_df.app": 1,
      "MTeamConferences[cat]": 1,
      "train_df['species']": 1,
      "np.squeeze(batch_a_target)": 1,
      "train['P_emaildomain']": 1,
      "train['id_30']": 1,
      "train['id_33']": 1,
      "train['DeviceInfo']": 1,
      "test['P_emaildomain']": 1,
      "test['id_30']": 1,
      "test['id_33']": 1,
      "test['DeviceInfo']": 1,
      "train['card1_card2']": 1,
      "train['card1_addr1']": 1,
      "train['card2_addr1']": 1,
      "test['card1_card2']": 1,
      "test['card1_addr1']": 1,
      "test['card2_addr1']": 1,
      "train['networkDomain']": 1,
      "train['keyword']": 1,
      "train['referralPath']": 1,
      "train['city']": 1,
      "train['visitNumber']": 1,
      "train['source']": 1,
      "train['region']": 1,
      "train['date']": 1,
      "train['country']": 1,
      "train['metro']": 1,
      "train['browser']": 1,
      "train['adContent']": 1,
      "train['subContinent']": 1,
      "train['operatingSystem']": 1,
      "train['campaign']": 1,
      "test['networkDomain']": 1,
      "test['keyword']": 1,
      "test['referralPath']": 1,
      "test['city']": 1,
      "test['visitNumber']": 1,
      "test['source']": 1,
      "test['region']": 1,
      "test['date']": 1,
      "test['country']": 1,
      "test['metro']": 1,
      "test['browser']": 1,
      "test['adContent']": 1,
      "test['subContinent']": 1,
      "test['operatingSystem']": 1,
      "test['campaign']": 1,
      "ts_set[:, i]": 1,
      "list(train_dist[col].values)": 1,
      "list(test_dist[col].values)": 1,
      "data_combined[col]": 1,
      "list(housing[col].values)": 1,
      "list(train[l].values)": 1,
      "list(test[l].values)": 1,
      "train[columns]": 1,
      "test[columns]": 1,
      "df['subcat_0']": 1,
      "df['subcat_1']": 1,
      "df['subcat_2']": 1,
      "list(x_train_imputer[c].values)": 1,
      "list(x_test_imputer[c].values)": 1,
      "train.cat0": 1,
      "train.cat1": 1,
      "train.cat2": 1,
      "list(x_train_full[c].values)": 1,
      "df_train['patient_id']": 1,
      "df_test['patient_id']": 1,
      "DATA[x]": 1,
      "X_train[cc].values": 1,
      "full_df.subcat_0": 1,
      "full_df.subcat_1": 1,
      "full_df.subcat_2": 1,
      "list(result_df[c].values)": 1,
      "list(train_macro[f].values)": 1,
      "list(X_train[var].values)": 1,
      "list(X_test[var].values)": 1,
      "test['matchType']": 1,
      "df_test.loc[:, i]": 1,
      "df_test.loc[:, 'site_id']": 1,
      "list(X_train2[f].values)": 1,
      "list(X_valid2[f].values)": 1,
      "list(test00[f].values)": 1,
      "df_test[c].values": 1,
      "np.array(code, 'c')": 1,
      "df_annotations.label": 1,
      "[1000010653]": 1,
      "[target]": 1,
      "[category_id]": 1,
      "np.array(positive_labels)": 1,
      "np.array(negative_labels)": 1,
      "genes": 1,
      "variations": 1,
      "testdf.iloc[:, 1]": 1,
      "testdf.iloc[:, 5]": 1,
      "train_test.name": 1,
      "train_test.subcategory_2": 1,
      "train_test.brand_name": 1,
      "train_test.subcategory_1": 1,
      "train_test.general_category": 1,
      "x[i]": 1,
      "list(df_id[f].values)": 1,
      "y_train['surface']": 1,
      "turler": 1,
      "df[column]": 1,
      "df_house[colName]": 1,
      "X_six.state": 1,
      "X_test.state": 1,
      "X_six.fiProductClassDesc": 1,
      "X_test.fiProductClassDesc": 1,
      "X_six.fiBaseModel": 1,
      "X_test.fiBaseModel": 1,
      "X_six.fiModelDesc": 1,
      "X_test.fiModelDesc": 1,
      "train_paths['label']": 1,
      "train_df[col].values.astype('str')": 1,
      "test_df[col].values.astype('str')": 1,
      "train_data_x['color']": 1,
      "train_data_y": 1,
      "test_data['color']": 1,
      "list(merged_train_data[objectTypeFeature].values)": 1,
      "list(all_X[column].values)": 1,
      "final_test[col]": 1,
      "y_train.values": 1,
      "train['primary_use']": 1,
      "class_0_values": 1,
      "class_1_values": 1,
      "class_t_values": 1,
      "column_values": 1,
      "out_df[c_name].values": 1,
      "train.name": 1,
      "train.main_cat": 1,
      "train.subcat1": 1,
      "train.subcat2": 1,
      "xtest[cols]": 1,
      "list(data1[c].values)": 1,
      "list(df_train[i].values.astype('str'))": 1,
      "list(df_test[i].values.astype('str'))": 1,
      "trainMasterDf.DayOfWeek": 1,
      "testMasterDf.DayOfWeek": 1,
      "trainMasterDf.PdDistrict": 1,
      "testMasterDf.PdDistrict": 1,
      "trainMasterDf.Category": 1,
      "f_train['target']": 1,
      "testData['Country_Region']": 1,
      "df_train_curated['label0']": 1,
      "df_train_noisy['label0']": 1,
      "pets.Name": 1,
      "pets.RescuerID": 1,
      "pets.PetID": 1,
      "pets2.Name": 1,
      "pets2.RescuerID": 1,
      "pets2.PetID": 1,
      "data.gender": 1,
      "list(train['Embarked'].values)": 1,
      "list(test['Embarked'].values)": 1,
      "train.X0": 1,
      "test.X0": 1,
      "train.X1": 1,
      "test.X1": 1,
      "train.X2": 1,
      "test.X2": 1,
      "train.X3": 1,
      "test.X3": 1,
      "train.X4": 1,
      "test.X4": 1,
      "train.X5": 1,
      "test.X5": 1,
      "train.X6": 1,
      "test.X6": 1,
      "train.X8": 1,
      "test.X8": 1,
      "shop_df['city']": 1,
      "category_df['type']": 1,
      "category_df['subtype']": 1,
      "subtraininglabels[0]": 1,
      "alldata[col]": 1,
      "list(df2[col].values.astype('str'))": 1,
      "submission['J_type']": 1,
      "test[:6956]['type']": 1,
      "df['card_id']": 1,
      "df.loc[~df['merchant_id'].isnull(), 'merchant_id']": 1,
      "transactions['category_3']": 1,
      "list(test_df_trimmed[col].values.astype('str'))": 1,
      "list(test_df_dropped[col].values.astype('str'))": 1,
      "list(all_data[col_name].values)": 1,
      "cat_train.iloc[:, i]": 1,
      "cat_test.iloc[:, i]": 1,
      "list(data_df[col].astype(str).str.upper().values)": 1,
      "list(submission_df[col].astype(str).str.upper().values)": 1,
      "train_df['place_id'].as_matrix()": 1,
      "list(data_v1[col].astype(str).values)": 1,
      "Y_Data_Tr": 1,
      "train_total['label']": 1,
      "train_applic[col]": 1,
      "test_applic[col]": 1,
      "list(train.iloc[:, i].values)": 1,
      "list(test.iloc[:, i].values)": 1,
      "matchType": 1,
      "matchTypeTest": 1,
      "data.author": 1,
      "X[hc].astype(str).fillna('NAN').values": 1,
      "Xt[hc].astype(str).fillna('NAN').values": 1,
      "self.train[cat]": 1,
      "self.valid[cat]": 1,
      "self.test[cat]": 1,
      "uid": 1,
      "uid_test": 1,
      "sid": 1,
      "sid_test": 1,
      "train[cat_feature]": 1,
      "[author]": 1,
      "list(dft[f].values)": 1,
      "df_le[col]": 1,
      "leaf_df['species']": 1,
      "list(train_x[f].values)": 1,
      "list(test_x[f].values)": 1,
      "list(X_train_full[f].values)": 1,
      "Y_labels": 1,
      "label_df.surface": 1,
      "df_train['Country/Region']": 1,
      "df_test['Country/Region']": 1,
      "list(train_dd[f].values)": 1,
      "list(test_dd[f].values)": 1,
      "X[feat]": 1,
      "lbl.classes_": 1,
      "validation_X.countrycode": 1,
      "df_train.cat1": 1,
      "df_train.cat2": 1,
      "df_train.cat3": 1,
      "df_test.cat1": 1,
      "df_test.cat2": 1,
      "df_test.cat3": 1,
      "val[c]": 1,
      "df['BCG'].astype(str)": 1,
      "train_csv.landmark_id": 1,
      "df_to_transf[cols]": 1,
      "train['teacher_prefix']": 1,
      "train['school_state']": 1,
      "train['project_grade_category']": 1,
      "train['project_subject_categories']": 1,
      "train['project_subject_subcategories']": 1,
      "test['teacher_prefix']": 1,
      "test['school_state']": 1,
      "test['project_grade_category']": 1,
      "test['project_subject_categories']": 1,
      "test['project_subject_subcategories']": 1,
      "test_data[feat].fillna('-1')": 1,
      "testDataset['Sex']": 1,
      "trainDataset['Sex']": 1,
      "testDataset['Embarked'].astype(str)": 1,
      "trainDataset['Embarked'].astype(str)": 1,
      "testDataset['Cabin'].astype(str)": 1,
      "trainDataset['Cabin'].astype(str)": 1,
      "train_df['keyword']": 1,
      "test_df['keyword']": 1,
      "test_data['County']": 1,
      "test_data['Target']": 1,
      "train.AnimalType": 1,
      "train.SexuponOutcome": 1,
      "breeds_train": 1,
      "test.AnimalType": 1,
      "test.SexuponOutcome": 1,
      "breeds_test": 1,
      "val[col]": 1,
      "data[:, 'site_id']": 1,
      "data[:, 'path']": 1,
      "data[:, i]": 1,
      "X_test['Country']": 1,
      "['Position__OLB']": 1,
      "['Position__ILB']": 1,
      "['Position__DE']": 1,
      "['Position__DT']": 1,
      "train_df.name": 1,
      "test_df.name": 1,
      "train_df.item_description": 1,
      "test_df.item_description": 1,
      "train_df.general_cat": 1,
      "test_df.general_cat": 1,
      "train_df.subcat_1": 1,
      "test_df.subcat_1": 1,
      "train_df.subcat_2": 1,
      "test_df.subcat_2": 1,
      "application_data[col]": 1,
      "list(train_test[col].astype(str).values)": 1,
      "data['grid']": 1,
      "train[feature_name + '_all'].fillna('').astype(str)": 1,
      "test[feature_name + '_all'].fillna('').astype(str)": 1,
      "train['original_language'].fillna('').astype(str)": 1,
      "test['original_language'].fillna('').astype(str)": 1,
      "submission['Sex']": 1,
      "data_train[i]": 1,
      "data_test[i]": 1,
      "train['card_id']": 1,
      "train['first_active_month']": 1,
      "test['card_id']": 1,
      "df_test['toxic?']": 1,
      "application_train[i]": 1,
      "application_test[i]": 1,
      "list(tt[c].values)": 1,
      "val_y": 1,
      "x_test[col]": 1,
      "train_data.sentiment.to_list()": 1,
      "test_data.sentiment.to_list()": 1,
      "enc[c]": 1,
      "data_all_le_unique[c]": 1,
      "genre_le[c]": 1,
      "area_le[c]": 1,
      "data['target']": 1,
      "train['Address_clean']": 1,
      "test['Address_clean']": 1,
      "submission_pd[ID]": 1,
      "sales[cat]": 1,
      "mixed_dataset[feature]": 1,
      "GameCities[column]": 1,
      "Seasons[column]": 1,
      "list(train_vals)": 1,
      "list(test_vals)": 1,
      "app_train['NAME_CONTRACT_TYPE']": 1,
      "list(train_data[i].values)": 1,
      "list(test_transaction_all[i].values)": 1,
      "traindf[usecol]": 1,
      "test['c_p']": 1,
      "df['_genres_name'].fillna('').astype(str)": 1,
      "pd.concat([train_df['RescuerID'], test_df['RescuerID']])": 1,
      "species_label": 1,
      "test['type'].map(lambda x: str(x)[i])": 1,
      "y_raw['surface']": 1,
      "train_labeled[c]": 1,
      "test_labeled[c]": 1,
      "X1": 1,
      "X2": 1,
      "X3": 1,
      "X4": 1,
      "X5": 1,
      "X6": 1,
      "X8": 1,
      "list(df_test[col].values)": 1,
      "insurance.sex": 1,
      "Y_test": 1,
      "train_y.surface": 1,
      "list(application_train[i].values)": 1,
      "train_df.surface": 1,
      "list(data['matchType'].values)": 1,
      "list(test_data['matchType'].values)": 1,
      "final_df[col]": 1,
      "data['country_destination']": 1,
      "list(merge_df[col].values)": 1,
      "DF.iloc[:, i]": 1,
      "data['Sex']": 1,
      "data['Cabin']": 1,
      "data['Embarked']": 1,
      "list(non_cor_train_df[f].values)": 1,
      "list(non_cor_test_df[f].values)": 1,
      "train_df['landmark_id']": 1,
      "dev_df.category_name": 1,
      "dev_df.brand_name": 1,
      "holiday_df['visit_date'].dt.date": 1,
      "enc.classes_": 1,
      "list(m_train[l].values)": 1,
      "list(m_test[l].values)": 1,
      "X_test['pickup_borough']": 1,
      "X_train['dropoff_borough']": 1,
      "X_test['dropoff_borough']": 1,
      "xtrain[col].fillna('').astype(str)": 1,
      "xtest[col].fillna('').astype(str)": 1,
      "train_df[cf1]": 1,
      "test_df[cf1]": 1,
      "train[cf]": 1,
      "train[cat]": 1,
      "val_X[col]": 1,
      "recipeRaw['cuisine'].values": 1,
      "df_cat[col]": 1,
      "list(df_train[f])": 1,
      "list(df_test[f])": 1,
      "train_df[[cols]]": 1,
      "test_df[[cols]]": 1,
      "TRANS_tr_new[la]": 1,
      "TRANS_te_new[la]": 1,
      "C.ind_empleado": 1,
      "C.pais_residencia": 1,
      "C.sexo": 1,
      "C.tiprel_1mes": 1,
      "C.indresi": 1,
      "C.indext": 1,
      "C.canal_entrada": 1,
      "C.segmento": 1,
      "Y.astype(str)": 1,
      "[y_train_str[eid]]": 1,
      "list(data[feat].values)": 1,
      "train_df['cuisine']": 1,
      "list(train_df3[col].values.astype('str'))": 1,
      "all_data[le]": 1,
      "list(X_valid[col].values.astype('str'))": 1,
      "[y]": 1,
      "prev_label_encoder.inverse_transform(saved_idx)": 1,
      "list(train_df[feat].values)": 1,
      "list(test_df[feat].values)": 1,
      "X_train[feat]": 1,
      "X_test[feat]": 1,
      "new[0]": 1,
      "new[1]": 1,
      "train_features['cp_type']": 1,
      "train_features['cp_dose']": 1,
      "list(df[column_name].values)": 1,
      "list(x_tota[c].values)": 1,
      "list(pilot[c].values)": 1,
      "list(trainSD[c].values)": 1,
      "np.round(np.log(ds['trip_duration']) * 10)": 1,
      "X_train[f].values": 1,
      "X_test[f].values": 1,
      "df_enc[i].astype(str)": 1,
      "list(test_X[f].values)": 1,
      "train.OutcomeType": 1,
      "train.country_destination": 1,
      "list(train['manager_id'].values)": 1,
      "y[y >= 0.0]": 1,
      "list(train_data.loc[train_index, col].values)": 1,
      "list(test_data.loc[test_index, col].values)": 1,
      "Test[feature]": 1,
      "list(val_X[f].values)": 1,
      "X['sub_area'].astype(str)": 1,
      "X['product_type'].astype(str)": 1,
      "df.label": 1,
      "df['matchType']": 1,
      "list(yy1.values)": 1,
      "df2[c]": 1,
      "df2['OutcomeType']": 1,
      "data.Q1.loc[data.Q4 != 'Master\u2019s degree']": 1,
      "data.Q1.loc[data.Q4 == 'Master\u2019s degree']": 1,
      "data.Q5.loc[data.Q4 != 'Master\u2019s degree'].dropna()": 1,
      "data.Q5.loc[data.Q4 == 'Master\u2019s degree'].dropna()": 1,
      "hist_data['Q1']": 1,
      "list(train['Id'].values)": 1,
      "list(train['idhogar'].values)": 1,
      "list(test['Id'].values)": 1,
      "list(test['idhogar'].values)": 1,
      "total_data[i]": 1,
      "train['Age']": 1,
      "train['Fare']": 1,
      "test['Age']": 1,
      "test['Fare']": 1,
      "_all_labels": 1,
      "_countries": 1,
      "_continents": 1,
      "bureau.columns": 1,
      "bureau_balance.columns.values.astype('str')": 1,
      "df_test_building_left['primary_use']": 1,
      "list(total_data[c].values)": 1,
      "public_test_features[cat]": 1,
      "data[i]": 1,
      "final_test[i]": 1,
      "test_data.sex.astype('str')": 1,
      "test_data.anatom_site_general_challenge.astype('str')": 1,
      "list(g_train_df[col].values.astype('str'))": 1,
      "list(g_test_df[col].values.astype('str'))": 1,
      "train[col].values": 1,
      "t_data['species']": 1,
      "covid_test['Province_State']": 1,
      "covid_test['Country_Region']": 1,
      "gt": 1,
      "test['Type']": 1,
      "test['IsHoliday']": 1,
      "test_df['Sex']": 1,
      "test_df['SmokingStatus']": 1,
      "yTrain['surface']": 1,
      "yTest['surface']": 1,
      "list(original_train[f].values)": 1,
      "col_val": 1,
      "list(missingValues[f].values)": 1,
      "a_train[col]": 1,
      "a_test[col]": 1,
      "df[cate]": 1,
      "list(train_dataset[i].values)": 1,
      "list(test_dataset[i].values)": 1,
      "train_set[col].astype('str')": 1,
      "test_set[col].astype('str')": 1,
      "trx_data[cat_col_name].astype('str')": 1,
      "list(dt[cols].values)": 1,
      "list(dt_test[cols].values)": 1,
      "train_in_bin_2.place_id.values": 1,
      "test['ord_5']": 1,
      "df_train['gender']": 1,
      "df_test['gender']": 1,
      "df_train['signup_method']": 1,
      "df_test['signup_method']": 1,
      "df_train['language']": 1,
      "df_test['language']": 1,
      "df_train['affiliate_channel']": 1,
      "df_test['affiliate_channel']": 1,
      "df_train['affiliate_provider']": 1,
      "df_test['affiliate_provider']": 1,
      "df_train['first_affiliate_tracked']": 1,
      "df_test['first_affiliate_tracked']": 1,
      "df_train['signup_app']": 1,
      "df_test['signup_app']": 1,
      "df_train['first_device_type']": 1,
      "df_test['first_device_type']": 1,
      "df_train['first_browser']": 1,
      "df_test['first_browser']": 1,
      "test['cp_type']": 1,
      "train['Position']": 1,
      "data['title_y'].values": 1,
      "data['title'].values": 1,
      "train_X[columns]": 1,
      "test_X[columns]": 1,
      "targets_df['target_concat']": 1,
      "rf_train['original_language']": 1,
      "rf_test['original_language']": 1,
      "rf_train['status']": 1,
      "rf_test['status']": 1,
      "rf_train['collection_name']": 1,
      "rf_test['collection_name']": 1,
      "data['Province/State']": 1,
      "data['Country/Region']": 1,
      "train_1[var].astype('str')": 1,
      "test_1[var].astype('str')": 1,
      "list(df_test[f].values.astype('str'))": 1,
      "lockdown_geo[['Date']].astype(str)": 1,
      "[test_df.Date.min()]": 1,
      "test_df['Date']": 1,
      "list(train_df[col])": 1,
      "list(test_df[col])": 1,
      "train[f].values": 1,
      "test[f].values": 1,
      "train[f].ravel()": 1,
      "test[f].ravel()": 1,
      "train['PdDistrict']": 1,
      "validLabel": 1,
      "curr_batch_lables_list": 1,
      "df.Sex": 1,
      "train_df['primary_use']": 1,
      "test_df['primary_use']": 1,
      "test_new[e]": 1,
      "list(application_train[c].values.astype('str'))": 1,
      "list(application_test[c].values.astype('str'))": 1,
      "temp_train_df['event']": 1,
      "temp_val_df['event']": 1,
      "train[e]": 1,
      "traindf['species']": 1,
      "train_df.breed.astype(str)": 1,
      "test_df.breed.astype(str)": 1,
      "new_train[col]": 1,
      "new_test[col]": 1,
      "train['event_code']": 1,
      "train['title']": 1,
      "ID": 1,
      "weather[column].values": 1,
      "train[column].values": 1,
      "test[column].values": 1,
      "list(trainData['color'].values)": 1,
      "list(trainData['type'].values)": 1,
      "list(testData['color'].values)": 1,
      "dataset.ix[:, feat]": 1,
      "X_test_[col]": 1,
      "test_df['matchTypeReduced']": 1,
      "test_df['matchType']": 1,
      "merged['sentiment'].values": 1,
      "train_tags": 1,
      "test_tags": 1,
      "merge_df['ProductCD']": 1,
      "merge_df_test['ProductCD']": 1,
      "merge_df['card4']": 1,
      "merge_df_test['card4']": 1,
      "merge_df['card6']": 1,
      "merge_df_test['card6']": 1,
      "test['X']": 1,
      "test['Y']": 1,
      "list(feature.brand_name)": 1,
      "list(feature.category_name)": 1,
      "list(feature_test.brand_name)": 1,
      "list(feature_test.category_name)": 1,
      "list(df_eval[column_iter].values.astype('str'))": 1,
      "list(df_actual_test[column_iter].values.astype('str'))": 1,
      "y_true": 1,
      "df_train.brand_name.values.tolist()": 1,
      "df_test.brand_name.values.tolist()": 1,
      "df_train.cat1.values.tolist()": 1,
      "df_train.cat2.values.tolist()": 1,
      "df_train.cat3.values.tolist()": 1,
      "train_data[target_attribute]": 1,
      "list(prox[c].values)": 1,
      "Y_grid": 1,
      "data[c].values": 1,
      "valid[col]": 1,
      "train['label']": 1,
      "tr_y": 1,
      "va_y": 1,
      "te_y": 1,
      "df_train['Sex']": 1,
      "train_bench[iter]": 1,
      "test_all_feat[iter]": 1,
      "data[iter]": 1,
      "df['wheezy-copper-turtle-magic']": 1,
      "train_df.loc[:, column].values": 1,
      "test_df.loc[:, column].values": 1,
      "list(train['color'])": 1,
      "list(test['color'])": 1,
      "test['cp_time']": 1,
      "test_features[col].astype(str)": 1,
      "list(train_full[f].values)": 1,
      "df[c]": 1,
      "X[column]": 1,
      "list(new_train[col].astype(str).values)": 1,
      "list(new_test[col].astype(str).values)": 1,
      "X['store_and_fwd_flag']": 1,
      "X_test['store_and_fwd_flag']": 1,
      "datas['Country/Region']": 1,
      "full_data.brand_name": 1,
      "full_data.subcat_0": 1,
      "full_data.subcat_1": 1,
      "full_data.subcat_2": 1,
      "full_data[nominal_list[i]]": 1,
      "val_df['Country_Region']": 1,
      "X[i]": 1,
      "features_test[i]": 1,
      "list(dataa[c].values)": 1,
      "X_test.Country_Region": 1,
      "X_test.Target": 1,
      "base_preco2[colName]": 1,
      "x[colName]": 1,
      "X_teste[colName]": 1,
      "fe['cp_type']": 1,
      "fe['cp_dose']": 1,
      "df_train.target": 1,
      "test[col].to_frame()": 1,
      "train[col].to_frame()": 1,
      "train_user_combine['date_account_created_day']": 1,
      "train_user_combine['country_destination']": 1,
      "test_feat[col]": 1,
      "self.labels": 1,
      "df_train['keyword']": 1,
      "df_test['keyword']": 1,
      "X_copy.loc[~X_copy.isin(unseen_labels_lst)]": 1,
      "list(features[cols].values)": 1,
      "building_meta.primary_use": 1,
      "list(train_df[x].astype(str).values)": 1,
      "list(test_df[x].astype(str).values)": 1,
      "clf.predict(X)": 1,
      "X_test.title": 1,
      "X_target.title": 1,
      "lectures['type_of']": 1,
      "list(train_users[f].values)": 1,
      "list(test_users[f].values)": 1,
      "data['RescuerID']": 1,
      "train['State']": 1,
      "test['State']": 1,
      "training_data['Type']": 1,
      "test_data['Type']": 1,
      "training_data['IsHoliday']": 1,
      "test_data['IsHoliday']": 1,
      "trainCopy['NAME_CONTRACT_TYPE']": 1,
      "trainCopy['CODE_GENDER']": 1,
      "trainCopy['FLAG_OWN_CAR']": 1,
      "trainCopy['FLAG_OWN_REALTY']": 1,
      "trainCopy['NAME_TYPE_SUITE']": 1,
      "trainCopy['NAME_INCOME_TYPE']": 1,
      "trainCopy['NAME_EDUCATION_TYPE']": 1,
      "trainCopy['NAME_FAMILY_STATUS']": 1,
      "trainCopy['NAME_HOUSING_TYPE']": 1,
      "trainCopy['OCCUPATION_TYPE']": 1,
      "trainCopy['ORGANIZATION_TYPE']": 1,
      "trainCopy['WEEKDAY_APPR_PROCESS_START']": 1,
      "trainCopy['FONDKAPREMONT_MODE']": 1,
      "trainCopy['HOUSETYPE_MODE']": 1,
      "trainCopy['WALLSMATERIAL_MODE']": 1,
      "trainCopy['EMERGENCYSTATE_MODE']": 1,
      "previous_applicationEncoding['NAME_CONTRACT_TYPE']": 1,
      "previous_applicationEncoding['FLAG_LAST_APPL_PER_CONTRACT']": 1,
      "previous_applicationEncoding['WEEKDAY_APPR_PROCESS_START']": 1,
      "previous_applicationEncoding['NAME_CASH_LOAN_PURPOSE']": 1,
      "previous_applicationEncoding['NAME_CONTRACT_STATUS']": 1,
      "previous_applicationEncoding['NAME_PAYMENT_TYPE']": 1,
      "previous_applicationEncoding['CODE_REJECT_REASON']": 1,
      "previous_applicationEncoding['NAME_TYPE_SUITE']": 1,
      "previous_applicationEncoding['NAME_CLIENT_TYPE']": 1,
      "previous_applicationEncoding['NAME_GOODS_CATEGORY']": 1,
      "previous_applicationEncoding['NAME_PORTFOLIO']": 1,
      "previous_applicationEncoding['NAME_PRODUCT_TYPE']": 1,
      "previous_applicationEncoding['CHANNEL_TYPE']": 1,
      "previous_applicationEncoding['NAME_YIELD_GROUP']": 1,
      "previous_applicationEncoding['PRODUCT_COMBINATION']": 1,
      "previous_applicationEncoding['NAME_SELLER_INDUSTRY']": 1,
      "testCopy['NAME_CONTRACT_TYPE']": 1,
      "testCopy['CODE_GENDER']": 1,
      "testCopy['FLAG_OWN_CAR']": 1,
      "testCopy['FLAG_OWN_REALTY']": 1,
      "testCopy['NAME_TYPE_SUITE']": 1,
      "testCopy['NAME_INCOME_TYPE']": 1,
      "testCopy['NAME_EDUCATION_TYPE']": 1,
      "testCopy['NAME_FAMILY_STATUS']": 1,
      "testCopy['NAME_HOUSING_TYPE']": 1,
      "testCopy['OCCUPATION_TYPE']": 1,
      "testCopy['ORGANIZATION_TYPE']": 1,
      "testCopy['WEEKDAY_APPR_PROCESS_START']": 1,
      "testCopy['FONDKAPREMONT_MODE']": 1,
      "testCopy['HOUSETYPE_MODE']": 1,
      "testCopy['WALLSMATERIAL_MODE']": 1,
      "testCopy['EMERGENCYSTATE_MODE']": 1,
      "X_test_enc[cols]": 1,
      "train_collection": 1,
      "test_collection": 1,
      "train_language": 1,
      "test_language": 1,
      "train.sex": 1,
      "train.anatom_site_general_challenge": 1,
      "list(train[cat].values.astype('str'))": 1,
      "list(test[cat].values.astype('str'))": 1,
      "list(train[col])": 1,
      "list(test[col])": 1,
      "val['species']": 1,
      "df.sentiment.tolist()": 1,
      "test_df.sentiment.tolist()": 1,
      "dataframe[i]": 1,
      "df[cf1]": 1,
      "target_train.surface.values.reshape(-1, 1)": 1,
      "X_train[cf]": 1,
      "X_test[cf]": 1,
      "df_items['family']": 1,
      "test[obj_test]": 1,
      "train_df[features]": 1,
      "df_train['Intersection']": 1,
      "df_test['Intersection']": 1,
      "test_features.cp_time": 1,
      "list(all_data[col].values.astype('str'))": 1,
      "list(train_flat[col].values.astype('str'))": 1,
      "list(test_flat[col].values.astype('str'))": 1,
      "test_data[enc]": 1,
      "raw_train_data['primary_use']": 1,
      "raw_test_data['primary_use']": 1,
      "train_data['Embarked']": 1,
      "test_data['Embarked']": 1,
      "list(train_new[f].values)": 1,
      "gender_age_train['gender']": 1,
      "df2[col]": 1,
      "df.meta_category": 1,
      "df.town": 1,
      "test4.meta_category": 1,
      "test4.town": 1,
      "test.air_store_id": 1,
      "test.day_of_week": 1,
      "test.air_genre_name": 1,
      "test.air_area_name": 1,
      "train_data['SmokingStatus']": 1,
      "test_data['SmokingStatus']": 1,
      "list(train_ds[val].values)": 1,
      "list(df_train['manager_id'].values)": 1,
      "list(df_test['manager_id'].values)": 1,
      "list(properties['A-propertyzoning'].values)": 1,
      "list(properties['A-country-code'].values)": 1,
      "list(properties['A-city-code'].values)": 1,
      "list(properties['A-town-code'].values)": 1,
      "list(properties[feature].values)": 1,
      "train['category_name']": 1,
      "test['category_name']": 1,
      "list(X_le[f].values)": 1,
      "list(X_be[f].values)": 1,
      "x[colum]": 1,
      "test[colum]": 1,
      "label['surface']": 1,
      "df_train.category_name": 1,
      "df_test.category_name": 1,
      "list(train_mac[f].values.astype('str'))": 1,
      "list(test_mac[f].values.astype('str'))": 1,
      "list(train_clean_rob[f].values)": 1,
      "list(test_clean_rob[f].values)": 1,
      "train2['statusCode'].values.reshape((-1, 1))": 1,
      "df['statusCode'].values.reshape(-1, 1)": 1,
      "X_train[feature].astype(str)": 1,
      "X_test[feature].astype(str)": 1,
      "label_status": 1,
      "[cl]": 1,
      "train_cat[c]": 1,
      "test_cat[c]": 1,
      "gatrain.gender": 1,
      "test_full['primary_use']": 1,
      "age_train.group.values": 1,
      "phone_brand['phone_brand']": 1,
      "dataset[feature]": 1,
      "train_df[col_name]": 1,
      "test_df[col_name]": 1,
      "X_xTest.Country": 1,
      "X_xTest['State']": 1,
      "df.phone_brand": 1,
      "df.device_model": 1,
      "df.group": 1,
      "target": 1,
      "all_aug.source_system_tab": 1,
      "all_aug.source_screen_name": 1,
      "all_aug.source_type": 1,
      "all_aug.genre_ids": 1,
      "all_aug.artist_name": 1,
      "all_aug.composer": 1,
      "all_aug.lyricist": 1,
      "all_aug.name": 1,
      "all_aug.isrc": 1,
      "all_aug.gender": 1,
      "list(df_train[feature].astype(str).values)": 1,
      "list(df_test[feature].astype(str).values)": 1,
      "train_data_set.iloc[:, i + 1]": 1,
      "tempTe[col]": 1,
      "list(dataframe[c].values)": 1,
      "cp_type": 1,
      "list(train_val[f].values)": 1,
      "list(test_val[f].values)": 1,
      "RF_train_X[label]": 1,
      "_df_train[col]": 1,
      "_df_test[col]": 1,
      "list(df[i].values.astype('str'))": 1,
      "['carpet', 'concrete', 'fine_concrete', 'hard_tiles', 'hard_tiles_large_space', 'soft_pvc', 'soft_tiles', 'tiled', 'wood']": 1,
      "X_run['surface']": 1,
      "all_df[i]": 1,
      "val.landmark_id": 1,
      "data['prior_question_had_explanation']": 1,
      "df['prior_question_had_explanation']": 1,
      "os.listdir('../input/train')": 1,
      "os.listdir(TRAIN)": 1,
      "sample_df['air_store_id']": 1,
      "applabelCategories.app_id": 1,
      "applabelCategories.label_id": 1,
      "applabelCategories.category": 1,
      "data_raw['type']": 1,
      "labels.values.flatten()": 1,
      "Y_train_label": 1,
      "Y_test_label": 1,
      "test_x.loc[:, col]": 1,
      "app_test[x]": 1,
      "test_data[cf1]": 1
    },
    "sklearn.preprocessing._data.StandardScaler.fit.X": {
      "train_copied[['Age', 'Fare']]": 303,
      "X": 199,
      "X_train": 197,
      "x_train": 79,
      "data": 63,
      "test": 51,
      "X_test": 35,
      "np.vstack((features, test_features))": 32,
      "train_X": 27,
      "X_tr": 25,
      "train": 24,
      "x_test": 23,
      "df": 21,
      "train_x": 18,
      "xtrain_svd": 17,
      "finData": 16,
      "pd.concat([train[features], test[features]])": 14,
      "features": 11,
      "df_train": 11,
      "x": 9,
      "tr_x": 9,
      "train[features]": 8,
      "pd.concat([train, test])": 7,
      "np.vstack((TRAIN, TEST))": 7,
      "train.item_price.as_matrix().reshape(-1, 1)": 7,
      "train.item_cnt_day.as_matrix().reshape(-1, 1)": 7,
      "data.loc[:, RSSI_FEATS]": 7,
      "np.concatenate([train_df[column].values.reshape(-1, 1), test_df[column].values.reshape(-1, 1)])": 6,
      "pd.concat([train_X, test_X])": 6,
      "data_ref.reshape(-1, 1)": 6,
      "train[col].values.reshape(-1, 1)": 6,
      "y_train_.reshape(-1, 1)": 6,
      "np.vstack((train_features, test_features))": 5,
      "pd.concat([xtrain[features], test[features]])": 5,
      "np.vstack((leaks, test_leaks))": 5,
      "train_df": 5,
      "trainDF[['X', 'Y']]": 5,
      "X_train_flatten": 5,
      "test_X": 4,
      "feature_df": 4,
      "train.values": 4,
      "[[y] for y in y_train]": 4,
      "Xtrain": 4,
      "X_train_init": 4,
      "X_test_init": 4,
      "test_data": 4,
      "stationary_train_sales.T": 4,
      "y_train": 4,
      "x_train_store": 4,
      "train_df[features]": 4,
      "pd.concat([X, X_test])": 4,
      "raw_val_df": 3,
      "X1": 3,
      "X_cleaned": 3,
      "Standard_features": 3,
      "im_features": 3,
      "X.loc[:, cols]": 3,
      "X_all_num": 3,
      "data[tmpFEATS].values.reshape(-1, 1)": 3,
      "np.tile(data[tmpFEATS].values.reshape(-1, 1), (1, 3))": 3,
      "features_train": 3,
      "np.float64(train_set[feature]).reshape((len(train_set[feature]), 1))": 3,
      "train_df[all_features].values": 3,
      "transf": 3,
      "X_train[base].values.reshape(-1, 1)": 3,
      "alldata": 3,
      "aux[features]": 3,
      "aux[target].values.reshape(-1, 1)": 3,
      "Correlation_df[num_col]": 2,
      "Titanic_train_x[num_col]": 2,
      "Titanic_predict_x[num_col]": 2,
      "X_train_full[numerical_cols]": 2,
      "c_df": 2,
      "v_df": 2,
      "numeric_data": 2,
      "train_data[['X', 'Y', 'time']]": 2,
      "test_data[['X', 'Y', 'time']]": 2,
      "train_df[features].values": 2,
      "data[num_cols_to_scale]": 2,
      "data[num_col]": 2,
      "x_train1": 2,
      "market_train_df[self.numeric_cols + self.time_cols]": 2,
      "news_train_df": 2,
      "data.loc[:, RSSI_FEATS + ['floor']]": 2,
      "train_prepared": 2,
      "train_data": 2,
      "Y_train_orig": 2,
      "features.values": 2,
      "xtr": 2,
      "train_gc": 2,
      "X_train[cols]": 2,
      "data_train": 2,
      "y_train.reshape(-1, 1)": 2,
      "x_data": 2,
      "df_train[col].values.reshape(-1, 1)": 2,
      "X_train.reshape(-1, 1)": 2,
      "x_test_store": 2,
      "X_all": 2,
      "X_train_svd": 2,
      "X_transformed_max": 2,
      "data[DELTA_FEATS]": 2,
      "pd.DataFrame(all_rssis)": 2,
      "train_continuous_columns_df.values": 2,
      "X[:10158]": 2,
      "train_targ_columns.values": 2,
      "X_train.values": 2,
      "xtrain": 2,
      "data_site[:, rx]": 2,
      "x_train_kf.values": 2,
      "X_test.drop(cat_col, axis=1)": 2,
      "test_df": 2,
      "X_tra": 2,
      "X_full": 2,
      "y_train.values.reshape(-1, 1)": 2,
      "X_train.fillna(0)": 2,
      "X_train_p": 2,
      "train_df[scaled_labels].to_numpy()": 2,
      "frame": 2,
      "Data": 2,
      "np.vstack((train, test))": 2,
      "dataset[[feature]]": 2,
      "all_data[features]": 2,
      "arr": 2,
      "all_data": 2,
      "self.numerical_data": 2,
      "self.num_test_data": 2,
      "meta_data": 1,
      "train.item_price.to_numpy().reshape(-1, 1)": 1,
      "train.item_cnt_day.to_numpy().reshape(-1, 1)": 1,
      "x_temp": 1,
      "xtrain_tfv_svd": 1,
      "X_train[numeric]": 1,
      "train_data[features]": 1,
      "final_train": 1,
      "final_test": 1,
      "df[['Age', 'Fare']]": 1,
      "X[num]": 1,
      "df[cols]": 1,
      "trainImage": 1,
      "testImage": 1,
      "trainRows": 1,
      "one_hot_vec": 1,
      "df[cols_normalize]": 1,
      "train + test": 1,
      "features.to_numpy()": 1,
      "train.to_numpy()": 1,
      "df[o_cols].sample(sample_size, random_state=7)": 1,
      "X_train.iloc[:, 1:]": 1,
      "X.iloc[:, 1:]": 1,
      "test.iloc[:, 1:]": 1,
      "y": 1,
      "df[['vendor_id', 'passenger_count', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'store_and_fwd_flag', 'travel_distance_km', 'hour_pickup', 'day_pickup']]": 1,
      "test[['vendor_id', 'passenger_count', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'store_and_fwd_flag', 'travel_distance_km', 'hour_pickup', 'day_pickup']]": 1,
      "train_p[[c]].values": 1,
      "X_train_flat": 1,
      "X_test_flat": 1,
      "x_t": 1,
      "market_float_data": 1,
      "train_x[num_features]": 1,
      "pd.DataFrame(munged_train_df['parts'])": 1,
      "train2": 1,
      "pd.concat([X, T])": 1,
      "train_preprocessed['Size'].values.reshape(-1, 1)": 1,
      "df_bin": 1,
      "data[i].values.reshape(-1, 1).astype(np.float32)": 1,
      "pd.concat([trn_x, val_x, test[feature]])": 1,
      "X_train.values.reshape(-1, 1)": 1,
      "X_test.values.reshape(-1, 1)": 1,
      "test.values.reshape(-1, 1)": 1,
      "X_train_with_ctl.iloc[:, 4:]": 1,
      "latitudes": 1,
      "longitudes": 1,
      "data_all[col_list]": 1,
      "df_combined": 1,
      "Train[col].values.reshape(-1, 1)": 1,
      "train_df[feature].append(test_df[feature]).astype(np.float64).values[:, np.newaxis]": 1,
      "X['Population'].values.reshape(-1, 1)": 1,
      "training[features]": 1,
      "X_train_feature.values.reshape(-1, 1)": 1,
      "full_df[num_vars].values": 1,
      "pd.DataFrame(y_log_transformed)": 1,
      "pd.DataFrame(X_log_transformed)": 1,
      "stats_data": 1,
      "train[cols_to_scale]": 1,
      "X_train_pos.T": 1,
      "X_train_neg.T": 1,
      "data_x": 1,
      "X_train[int_vars]": 1,
      "df_test": 1,
      "data[reg_columns]": 1,
      "project_data['price'].values.reshape(-1, 1)": 1,
      "knn_data": 1,
      "train_x.values": 1,
      "vt.transform(train2[cols])": 1,
      "X_train[cont_cols]": 1,
      "train_data[cont_cols]": 1,
      "np.vstack([features, test_features])": 1,
      "data.values": 1,
      "std_train_features.loc[:, preprocess_columns]": 1,
      "test[features]": 1,
      "test.values": 1,
      "df[numerics]": 1,
      "self.train_data[self.rssi_feats]": 1,
      "df_train[updated_numericals]": 1,
      "pd.concat([train_df[[col]].fillna(0), test_df[[col]].fillna(0)])": 1,
      "train_new[new_features]": 1,
      "pd.concat([train[features], test[features]], axis=0)": 1,
      "Y_tr": 1,
      "train_x[continueList]": 1,
      "test_x[continueList]": 1,
      "for_pred_x[continueList]": 1,
      "train.loc[:, features].values": 1,
      "X_train[features]": 1,
      "_df_train": 1,
      "x_train.values[:, 0:10]": 1,
      "df_blended_data[num_x]": 1,
      "train[mol_features]": 1,
      "train[nn_mol_features]": 1,
      "data7": 1,
      "pd.concat([X_train.loc[:, scale_features], df_test.loc[:, scale_features]], axis=0)": 1,
      "x_rf_train": 1,
      "train_xp": 1,
      "train_xn": 1,
      "compute_features(df_train, one_hot_encoder, scaler=None)": 1,
      "Train_data": 1,
      "Test_data": 1,
      "dataset_val": 1,
      "xtst": 1,
      "X_test_new": 1,
      "train.drop(['Id', 'groupId', 'matchId', 'winPlacePerc'], axis=1)": 1,
      "train_feat": 1,
      "np.tile(data[tmpFEATS].values.reshape(-1, 1), (1, 2))": 1,
      "np.tile(data[tmpFEATS].values.reshape(-1, 1), (1, 6))": 1,
      "np.tile(data[DELTA_FEATS].values.reshape(-1, 1), (1, 4))": 1,
      "x_cleaned": 1,
      "sample_train_data_pca[featstr[1:]]": 1,
      "train_data_pca[featstr[1:]]": 1,
      "df_train[features]": 1,
      "data_test": 1,
      "train_data[['Age']]": 1,
      "train_data[scaler_columns]": 1,
      "my_team_train1": 1,
      "opp_team_train1": 1,
      "my_team_train2": 1,
      "opp_team_train2": 1,
      "other_train1": 1,
      "other_train2": 1,
      "data_features.values": 1,
      "numeric": 1,
      "numeric_test": 1,
      "x_train_feat": 1,
      "train[['day_of_week_encoded', 'pd_district_encoded', 'x', 'y', 'hour']]": 1,
      "numVar": 1,
      "scaled_feat": 1,
      "test_set_rf_cont": 1,
      "test_cont_feat": 1,
      "pd.concat([df[feature_cols], df_tst[feature_cols]], axis=0).fillna(0).values": 1,
      "price_list": 1,
      "pubg_x": 1,
      "train[feature].append(test[feature]).astype(np.float64).values[:, np.newaxis]": 1,
      "train_features[GENES + CELLS].append(test_features[GENES + CELLS])": 1,
      "data_train['returnsOpenNextMktres10'].values.reshape((-1, 1))": 1,
      "self.df.loc[:, num_list]": 1,
      "Y_train.values.reshape(-1, 1)": 1,
      "train[to_normalize]": 1,
      "test[to_normalize]": 1,
      "train_data[['Patient', 'Age']].drop_duplicates()['Age'].values.reshape(-1, 1)": 1,
      "train_data[['Patient', 'Weeks']].drop_duplicates()['Weeks'].values.reshape(-1, 1)": 1,
      "train_data['Percent'].values.reshape(-1, 1)": 1,
      "train_data['FVC'].values.reshape(-1, 1)": 1,
      "filter_X_train": 1,
      "filter_X_train_sm": 1,
      "n_df": 1,
      "dataset[num_vars]": 1,
      "x_train.fillna(0)": 1,
      "pd.concat([_X_train[cols], _X_test[cols]])": 1,
      "x0": 1,
      "features_train.values": 1,
      "features_test.values": 1,
      "np.array(train_df[col].tolist() + submission[col].tolist()).reshape(-1, 1)": 1,
      "train[test.columns]": 1,
      "train[columns]": 1,
      "train_df[[col]].fillna(0)": 1,
      "train_input": 1,
      "y_test": 1,
      "new_train_features": 1,
      "useful_train_feature": 1,
      "useless_train_feature": 1,
      "X_train[:, :len(numerical)]": 1,
      "np.array(full_data[features_to_scale])": 1,
      "X_train_base": 1,
      "X_submission": 1,
      "np.array(df_all_data[col]).reshape(-1, 1)": 1,
      "train_gd": 1,
      "y_.reshape(-1, 1)": 1,
      "df_train[colunas]": 1,
      "df_test[colunas]": 1,
      "ylog.reshape(-1, 1)": 1,
      "mtrain[self.num_cols + self.time_cols].astype(float)": 1,
      "news_train_agg": 1,
      "Xt": 1,
      "xts": 1,
      "data_train[predictors]": 1,
      "np.concatenate([train[column].values.reshape(-1, 1), test[column].values.reshape(-1, 1)])": 1,
      "np.array(train.Age).reshape(-1, 1)": 1,
      "np.array(train.Fare).reshape(-1, 1)": 1,
      "df[featstr[1:]]": 1,
      "select_features": 1,
      "df_train[['latitude', 'longitude', 'month']].astype(float).to_numpy()": 1,
      "feature_train_df": 1,
      "all_df.drop([TARGET], axis=1)": 1,
      "X_all[features_to_scale_flatten]": 1,
      "text_len.values.reshape(-1, 1)": 1,
      "train_df.loc[:, d_i].values.reshape(-1, 1)": 1,
      "res[features]": 1,
      "raw_distance": 1,
      "inputs": 1,
      "test_unscale": 1,
      "x_data_2": 1,
      "train_df[[cols]]": 1,
      "train_copy[[cols]]": 1,
      "trainX + testX": 1,
      "data[col].to_numpy().reshape(-1, 1)": 1,
      "train[['shape2', 'shape3', 'shape1', 'margin16']]": 1,
      "X_train_encoded": 1,
      "X_train.astype(float)": 1,
      "df[[x]]": 1,
      "df1[[x]]": 1,
      "matrix": 1,
      "Data['X']": 1,
      "Data['Time']": 1,
      "taxi_trip_data[features]": 1,
      "final_X_train": 1,
      "application_train[col].values.reshape(-1, 1)": 1,
      "train[col]": 1,
      "general_data": 1,
      "dataset[['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp', 'humidity', 'windspeed', 'year', 'month', 'day', 'hour']]": 1,
      "test_dataset[['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp', 'humidity', 'windspeed', 'year', 'month', 'day', 'hour']]": 1,
      "X_val": 1,
      "X_out.astype(float)": 1,
      "df_numeric": 1,
      "xTrain": 1,
      "X_train[numerics]": 1,
      "x_train2[[x]]": 1,
      "x_test2[[x]]": 1,
      "np.swapaxes(data, 0, 1)": 1,
      "df[columns].values": 1,
      "data_x_test": 1,
      "self.df_train[['age_approx']]": 1,
      "df_train[['age_approx']]": 1,
      "x_train[num_col]": 1,
      "test_x": 1,
      "num_imputed_highVar": 1,
      "x[num_cols]": 1,
      "pd.concat([pd.DataFrame(train[GENES]), pd.DataFrame(test[GENES])])": 1,
      "pd.concat([pd.DataFrame(train[CELLS]), pd.DataFrame(test[CELLS])])": 1,
      "pd.concat([train[actualcolumns], test[actualcolumns]])": 1,
      "alldata[alldata.columns]": 1,
      "pd.concat([X[feats], X_test[feats]])": 1,
      "pd.concat([X[X.columns], test_df[X.columns]], sort=False)": 1,
      "np.vstack([X_train, X_test])": 1,
      "scipy.sparse.vstack((X_train_char, X_valid_char, X_test_char))": 1,
      "scipy.sparse.vstack((X_train_word, X_valid_word, X_test_word))": 1,
      "scipy.sparse.vstack((X_train, X_valid, X_test))": 1,
      "pd.concat([X_train, X_val, X_test])": 1,
      "enc_df": 1,
      "validation_set": 1,
      "df_train[features].values": 1,
      "X_train_orig": 1,
      "train_df['Comment_Len'].values.reshape(-1, 1)": 1,
      "cv_df['Comment_Len'].values.reshape(-1, 1)": 1,
      "df_test['Comment_Len'].values.reshape(-1, 1)": 1,
      "train_df['Topic-1'].values.reshape(-1, 1)": 1,
      "cv_df['Topic-1'].values.reshape(-1, 1)": 1,
      "df_test['Topic-1'].values.reshape(-1, 1)": 1,
      "train_df['Topic-2'].values.reshape(-1, 1)": 1,
      "cv_df['Topic-2'].values.reshape(-1, 1)": 1,
      "df_test['Topic-2'].values.reshape(-1, 1)": 1,
      "train_df['Topic-3'].values.reshape(-1, 1)": 1,
      "cv_df['Topic-3'].values.reshape(-1, 1)": 1,
      "df_test['Topic-3'].values.reshape(-1, 1)": 1,
      "train_df['Topic-4'].values.reshape(-1, 1)": 1,
      "cv_df['Topic-4'].values.reshape(-1, 1)": 1,
      "df_test['Topic-4'].values.reshape(-1, 1)": 1,
      "train_df['Topic-5'].values.reshape(-1, 1)": 1,
      "cv_df['Topic-5'].values.reshape(-1, 1)": 1,
      "df_test['Topic-5'].values.reshape(-1, 1)": 1,
      "points": 1,
      "train[cont_feat]": 1,
      "pd.DataFrame(train_0[col])": 1,
      "X_ds_train": 1,
      "X_solo_train": 1,
      "df_train_0_x": 1,
      "x_tr": 1,
      "cover_new": 1,
      "cont_train[cont_vars]": 1,
      "X_imp": 1,
      "X_trainA": 1,
      "train[feature_names]": 1,
      "raw_vec": 1,
      "train[std_cols]": 1,
      "sentence_feature_mat": 1,
      "df['Age'].values.reshape(-1, 1)": 1,
      "df['Fare'].values.reshape(-1, 1)": 1,
      "df2['Age'].values.reshape(-1, 1)": 1,
      "df2['Fare'].values.reshape(-1, 1)": 1,
      "successes": 1,
      "fails": 1,
      "data_features": 1,
      "train_mod": 1,
      "pd.concat([X_train, final_X_test])": 1,
      "np.vstack((features_train, features_test))": 1,
      "all_x": 1,
      "all_y": 1,
      "train_y": 1,
      "train[feats]": 1,
      "df[features_names]": 1,
      "training_data[features_without_holiday]": 1,
      "s_data": 1,
      "x_tr['price'].values.reshape(-1, 1)": 1,
      "x_cv['price'].values.reshape(-1, 1)": 1,
      "x_test['price'].values.reshape(-1, 1)": 1,
      "train_X.values": 1,
      "df[feature_scale]": 1,
      "margin": 1,
      "shape": 1,
      "texture": 1,
      "testMargin": 1,
      "testShape": 1,
      "testTexture": 1,
      "pd.concat([X, X1])": 1,
      "X_train[scaling_list].values": 1,
      "train[numerical_features]": 1,
      "data[numerical_features]": 1,
      "X_train['description_len'].values.reshape(-1, 1)": 1,
      "tr[feature].values.reshape(-1, 1)": 1,
      "F_train": 1,
      "train.drop('Survived', axis=1)": 1,
      "X_le_pca": 1,
      "train_features": 1,
      "train_wo_mc": 1,
      "X_train_high_corr": 1,
      "train[resp_group]": 1,
      "df_train['SalePrice'][:, np.newaxis]": 1,
      "pd.concat([trainP, validP, testP])": 1,
      "pd.concat([trainN, validN, testN])": 1,
      "x_train_full": 1,
      "y_train.values.reshape(y_train.shape[0], 1)": 1,
      "df_test_1": 1,
      "x_localtrain.values": 1,
      "train_onehot": 1,
      "X_num": 1,
      "np.vstack((train_feat, test_feat))": 1,
      "X_train_transformed": 1,
      "df_train.drop('Cover_Type', axis=1).values": 1,
      "feature_selected": 1,
      "featuresEncoded": 1
    },
    "sklearn.preprocessing._data.StandardScaler.transform.X": {
      "X_test": 582,
      "test_copied[['Age', 'Fare']]": 318,
      "train_copied[['Age', 'Fare']]": 303,
      "X_train": 213,
      "test": 201,
      "X": 149,
      "x_test": 136,
      "x_train": 78,
      "X_val": 61,
      "data": 58,
      "test_df": 57,
      "test_features": 53,
      "features": 43,
      "test[features]": 40,
      "test_X": 39,
      "train": 32,
      "train_X": 32,
      "df": 26,
      "X_tr": 25,
      "train[features]": 20,
      "market_obs_df[num_cols]": 20,
      "test_data": 19,
      "X_valid": 19,
      "x": 18,
      "xtrain_svd": 17,
      "xvalid_svd": 17,
      "test_df[['answered_correctly_user_mean', 'answered_correctly_content_mean', 'sum_correct', 'count', 'prior_question_elapsed_time', 'prior_question_had_explanation_enc']]": 17,
      "train_x": 16,
      "finData": 16,
      "finDatat": 16,
      "df_test": 15,
      "test_x": 15,
      "basetable": 15,
      "xvalid_glove": 13,
      "test.values": 13,
      "X0_test_iter": 13,
      "test[col].values.reshape(-1, 1)": 13,
      "data.loc[:, RSSI_FEATS]": 12,
      "test_data.loc[:, RSSI_FEATS]": 12,
      "x_val": 11,
      "tr_x": 10,
      "X_test[X_train.columns[:-1]]": 10,
      "df_train": 10,
      "xvalid": 9,
      "test[num_features]": 8,
      "xtest": 8,
      "X_sub": 8,
      "train_features": 7,
      "TRAIN": 7,
      "TEST": 7,
      "test_set": 7,
      "train.item_price.as_matrix().reshape(-1, 1)": 7,
      "train.item_cnt_day.as_matrix().reshape(-1, 1)": 7,
      "x_tt": 7,
      "train_df[column].values.reshape(-1, 1)": 6,
      "test_df[column].values.reshape(-1, 1)": 6,
      "y_test": 6,
      "market_obs[num_columns]": 6,
      "train[col].values.reshape(-1, 1)": 6,
      "raw_val_df": 6,
      "test[features].values": 6,
      "y_train_.reshape(-1, 1)": 6,
      "x_train_store": 6,
      "x_test_store": 6,
      "test[col]": 5,
      "xtrain[features]": 5,
      "test_X[train_columns]": 5,
      "X_eval": 5,
      "leaks": 5,
      "test_leaks": 5,
      "valid_x": 5,
      "trainDF[['X', 'Y']]": 5,
      "np.concatenate([X, X_play_col], axis=1)": 5,
      "test_features.values": 5,
      "fillna_npwhere(test_df[features].values, train_median[features].values)": 5,
      "data[DELTA_FEATS]": 5,
      "X_test_flatten": 5,
      "X_train_flatten": 5,
      "data_test": 5,
      "y_train": 5,
      "check_df['ConfirmedCases'].values.reshape(len(check_df['ConfirmedCases'].values), 1)": 5,
      "check_df['Fatalities'].values.reshape(len(check_df['Fatalities'].values), 1)": 5,
      "xval": 5,
      "scaledtest[features]": 5,
      "basetable[num]": 4,
      "val_x": 4,
      "X_validation": 4,
      "feature_df": 4,
      "train.values": 4,
      "full_test[full_train.columns]": 4,
      "X1": 4,
      "test_temp_X": 4,
      "num_data": 4,
      "train_df": 4,
      "X_final": 4,
      "test[[c]]": 4,
      "[[y] for y in y_train]": 4,
      "testX": 4,
      "test_inputs_count": 4,
      "df_test[col].values.reshape(-1, 1)": 4,
      "data.loc[:, RSSI_FEATS + ['floor']]": 4,
      "test_data.loc[:, RSSI_FEATS + ['floor']]": 4,
      "Xtrain": 4,
      "X_train_init": 4,
      "X_test_init": 4,
      "xtst": 4,
      "data[tmpFEATS]": 4,
      "features_train": 4,
      "features_test": 4,
      "stationary_train_sales.T": 4,
      "X_prep_low[:, i]": 4,
      "train_df[features]": 4,
      "test_df[features]": 4,
      "X_test[:, 2:]": 4,
      "x_test_solo": 4,
      "x_test_duo": 4,
      "x_test_squad": 4,
      "x_test_solo_fpp": 4,
      "x_test_duo_fpp": 4,
      "x_test_squad_fpp": 4,
      "x_test_flarefpp": 4,
      "x_test_flaretpp": 4,
      "x_test_crashfpp": 4,
      "x_test_crashtpp": 4,
      "final_test": 3,
      "X[num]": 3,
      "test.iloc[:, 1:]": 3,
      "numeric_test": 3,
      "test[feature_columns]": 3,
      "test2": 3,
      "X_num": 3,
      "val_tv_X": 3,
      "test[num_col]": 3,
      "train_data": 3,
      "X_test[features]": 3,
      "testDF[['X', 'Y']]": 3,
      "features_sub[collist]": 3,
      "test_df[cols]": 3,
      "X_cleaned": 3,
      "X_cleaned_test": 3,
      "val_X": 3,
      "Standard_features": 3,
      "im_features": 3,
      "Xtest": 3,
      "X_train.values": 3,
      "X.loc[train, cols]": 3,
      "X.loc[val, cols]": 3,
      "X_test.loc[:, cols]": 3,
      "X.loc[:, cols]": 3,
      "X_train_num": 3,
      "X_test_num": 3,
      "X_test['num_words'].values.reshape(-1, 1)": 3,
      "X_val['num_words'].values.reshape(-1, 1)": 3,
      "X_test['num_unique_words'].values.reshape(-1, 1)": 3,
      "X_val['num_unique_words'].values.reshape(-1, 1)": 3,
      "X_test['num_char'].values.reshape(-1, 1)": 3,
      "X_val['num_char'].values.reshape(-1, 1)": 3,
      "X_test['num_stopwords'].values.reshape(-1, 1)": 3,
      "X_val['num_stopwords'].values.reshape(-1, 1)": 3,
      "X_cv": 3,
      "test_flatten": 3,
      "data_train": 3,
      "test_encoded": 3,
      "train[['day_of_week_encoded', 'pd_district_encoded', 'x', 'y', 'hour']]": 3,
      "train_df[all_features].values": 3,
      "test_df[all_features].values": 3,
      "X_test.reshape(-1, 1)": 3,
      "x_test[simple_features]": 3,
      "transf": 3,
      "X_submission": 3,
      "X_train[base].values.reshape(-1, 1)": 3,
      "test[cols]": 3,
      "scaledtrain[features]": 3,
      "out_np[:, 0:sindex]": 3,
      "aux[features]": 3,
      "Correlation_df[num_col]": 2,
      "Titanic_train_x[num_col]": 2,
      "Titanic_predict_x[num_col]": 2,
      "test[test.columns]": 2,
      "val[col]": 2,
      "X_train_full[numerical_cols]": 2,
      "X_test[numerical_cols]": 2,
      "train.iloc[:][features].values": 2,
      "test.iloc[:][features].values": 2,
      "t": 2,
      "train.LConfirmedCases[train.serd > 70].values.reshape(-1, 1)": 2,
      "train.LFatalities[train.serd > 70].values.reshape(-1, 1)": 2,
      "trainpred.loc[trainpred.serd == serd, ['LConfirmedCases', 'LARIMApred']]": 2,
      "trainpred.loc[trainpred.serd == serd, ['LConfirmedCases', 'LARIMApred', 'LFatalities', 'LFARIMApred', 'LDConfirmedCases', 'LDFatalities']]": 2,
      "tda": 2,
      "df_Test": 2,
      "c_df": 2,
      "v_df": 2,
      "x2": 2,
      "numeric_data": 2,
      "train_data[['X', 'Y', 'time']]": 2,
      "test_data[['X', 'Y', 'time']]": 2,
      "df_features_test.values": 2,
      "data[['x', 'y', 'z']]": 2,
      "T": 2,
      "train_df[features].values": 2,
      "test_df[features].values": 2,
      "X_val_scaling": 2,
      "X_test_scaling": 2,
      "test_num_feature": 2,
      "X_play": 2,
      "data[num_cols_to_scale]": 2,
      "sub[num_cols_to_scale]": 2,
      "test.as_matrix()": 2,
      "test_data[features]": 2,
      "test[[col]]": 2,
      "X_submit": 2,
      "x_train1": 2,
      "x_test1": 2,
      "test_result_x": 2,
      "df[self.numeric_cols + self.time_cols].astype(float)": 2,
      "news_df[self.news_cols_numeric]": 2,
      "df2[feature_cols]": 2,
      "train_df[[col]].fillna(0)": 2,
      "test_df[[col]].fillna(0)": 2,
      "X_test_file": 2,
      "train_prepared_scaled": 2,
      "test_prepared_scaled": 2,
      "X_test_out.select_dtypes(exclude=['object'])": 2,
      "Xval": 2,
      "validation": 2,
      "Xvalid": 2,
      "Y_train_orig": 2,
      "X_test_encoded": 2,
      "X_test[scale_cols]": 2,
      "features.values": 2,
      "xtr": 2,
      "train_gc": 2,
      "X_train[cols]": 2,
      "X_test[cols]": 2,
      "train_feat": 2,
      "x_test['price'].values.reshape(-1, 1)": 2,
      "df_test[features]": 2,
      "y_train.reshape(-1, 1)": 2,
      "x_test_201610": 2,
      "x_test_201611": 2,
      "x_test_201612": 2,
      "x_test_201710": 2,
      "x_test_201711": 2,
      "x_test_201712": 2,
      "imp.transform(X_test_1)": 2,
      "pubg_x": 2,
      "x_data": 2,
      "test_df[feature_columns]": 2,
      "df_train[col].values.reshape(-1, 1)": 2,
      "X_train.reshape(-1, 1)": 2,
      "np.array(split[1]['modi']).reshape(-1, 1)": 2,
      "testDataset": 2,
      "trainDataset": 2,
      "X_all": 2,
      "X_train_svd": 2,
      "X_test_svd": 2,
      "X_transformed_max": 2,
      "X_test_transformed_max": 2,
      "pd.DataFrame(data.loc[:, i])": 2,
      "pd.DataFrame(test_data.loc[:, i])": 2,
      "train_continuous_columns_df.values": 2,
      "val_continuous_columns_df.values": 2,
      "test_continuous_columns_df.values": 2,
      "basetable_play[play_train_num_cols]": 2,
      "train_targ_columns.values": 2,
      "val_targ_columns.values": 2,
      "test_targ_columns.values": 2,
      "xtrain": 2,
      "data_site[:, rx]": 2,
      "test_data_site[:, rx]": 2,
      "test.loc[:, numerical_features]": 2,
      "test[column].values.reshape(-1, 1)": 2,
      "X_tst": 2,
      "X_test_firep": 2,
      "x_train_kf.values": 2,
      "x_val_kf.values": 2,
      "x_test.values": 2,
      "trial": 2,
      "X.drop(cat_col, axis=1)": 2,
      "X_test.drop(cat_col, axis=1)": 2,
      "reduce_test[features]": 2,
      "X_test_lr": 2,
      "df_test_feature.iloc[:, 0:10]": 2,
      "feature_test": 2,
      "inputs": 2,
      "df_test.drop(['ID_code'], axis=1)": 2,
      "xTest": 2,
      "X_tra": 2,
      "y_train.values.reshape(-1, 1)": 2,
      "data[columns_std]": 2,
      "X_test[:, 0:]": 2,
      "df_test.drop('id', axis=1)": 2,
      "o.features[col]": 2,
      "X_train.fillna(0)": 2,
      "val_df[features]": 2,
      "test_df_1[features]": 2,
      "test_df_2[features]": 2,
      "final_X_test": 2,
      "X_train_p": 2,
      "X_test_p": 2,
      "X_t": 2,
      "frame": 2,
      "Data": 2,
      "test[numeric_features].fillna(0)": 2,
      "num_imputed_highVar": 2,
      "alldata.loc[:, features]": 2,
      "test[test.columns[3:]]": 2,
      "X_test.to_pandas()": 2,
      "all_data[features]": 2,
      "X_ds_test": 2,
      "X_solo_test": 2,
      "arr": 2,
      "cv_X": 2,
      "data[numerical_features]": 2,
      "test_num": 2,
      "self.numerical_data": 2,
      "self.num_test_data": 2,
      "test[all_feat_cols]": 1,
      "fillna_npwhere(df_test[features].values, f_median[features].values)": 1,
      "train.item_price.to_numpy().reshape(-1, 1)": 1,
      "train.item_cnt_day.to_numpy().reshape(-1, 1)": 1,
      "X_test[X_test.columns]": 1,
      "test_df_ltd.fillna(-1)": 1,
      "x_temp": 1,
      "test_data_to_pred": 1,
      "[[2, 2]]": 1,
      "Xtest_vals": 1,
      "xtrain_tfv_svd": 1,
      "xvalid_tfv_svd": 1,
      "testData": 1,
      "X_for_pred": 1,
      "X_train[numeric]": 1,
      "X_test[numeric]": 1,
      "train_data[features]": 1,
      "final_train": 1,
      "df[['Age', 'Fare']]": 1,
      "test[['Age', 'Fare']]": 1,
      "df[cols]": 1,
      "trainImage": 1,
      "testImage": 1,
      "XTest": 1,
      "test_df[feature_cols]": 1,
      "trainRows": 1,
      "one_hot_vec": 1,
      "features.to_numpy()": 1,
      "train.to_numpy()": 1,
      "df[o_cols]": 1,
      "o.features[o_cols]": 1,
      "f": 1,
      "X_cross": 1,
      "test[continous_cols]": 1,
      "X_train.iloc[:, 1:]": 1,
      "X_test.iloc[:, 1:]": 1,
      "X.iloc[:, 1:]": 1,
      "y": 1,
      "test_df_processed": 1,
      "X_test[:, :]": 1,
      "df[['vendor_id', 'passenger_count', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'store_and_fwd_flag', 'travel_distance_km', 'hour_pickup', 'day_pickup']]": 1,
      "test[['vendor_id', 'passenger_count', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'store_and_fwd_flag', 'travel_distance_km', 'hour_pickup', 'day_pickup']]": 1,
      "x_val_": 1,
      "test_df.drop('id', axis=1)": 1,
      "train_p[[c]].values": 1,
      "test_p[[c]].values": 1,
      "train_signal": 1,
      "validation_signal": 1,
      "test[nums]": 1,
      "Xtst": 1,
      "voxel_mat": 1,
      "data[scale_vars]": 1,
      "x_t": 1,
      "X_test1[['WScore_1', 'LScore_1', 'LScore_2', 'WScore_2']]": 1,
      "X_test[numerical_feats]": 1,
      "X_test[img_feats]": 1,
      "X_test[text_feats]": 1,
      "np.log1p(valid_price)": 1,
      "test_sc": 1,
      "test['LotArea'].values.reshape(-1, 1)": 1,
      "test['MasVnrArea'].values.reshape(-1, 1)": 1,
      "test.drop('PassengerId', axis=1)": 1,
      "ts_X": 1,
      "X_test_1": 1,
      "market_float_data": 1,
      "train_x[num_features]": 1,
      "test_x[num_features]": 1,
      "X_test_filtered": 1,
      "data_test.drop(['id'], axis=1)": 1,
      "pd.DataFrame(munged_train_df['parts'])": 1,
      "pd.DataFrame(munged_test_df['parts'])": 1,
      "tt.iloc[:, 0:2]": 1,
      "test_raw": 1,
      "test_raw.drop('id', axis=1)": 1,
      "train2": 1,
      "Xmod1test": 1,
      "X_train['Size'].values.reshape(-1, 1)": 1,
      "X_test['Size'].values.reshape(-1, 1)": 1,
      "df[total_numeric]": 1,
      "df[compound]": 1,
      "df_bin": 1,
      "df_test_final": 1,
      "test.iloc[:, 1:21]": 1,
      "data[i].values.reshape(-1, 1).astype(np.float32)": 1,
      "trn_x": 1,
      "test[feature]": 1,
      "X_test.loc[:, test_num_cols]": 1,
      "X_train_with_ctl.iloc[:, 4:]": 1,
      "X_test.iloc[:, 4:]": 1,
      "test_features.iloc[:, 4:]": 1,
      "d_test_X[col_list]": 1,
      "d_train_X2[col_list]": 1,
      "d_test_X2[col_list]": 1,
      "d_train_3[col_list]": 1,
      "X_train[num_col].fillna(-1).clip(0.0001, 0.99999)": 1,
      "X_val[num_col].fillna(-1).clip(0.0001, 0.99999)": 1,
      "self.test_data.loc[:, genes]": 1,
      "df_train[select_features]": 1,
      "df_test[select_features]": 1,
      "test_1": 1,
      "Train[col].values.reshape(-1, 1)": 1,
      "Test[col].values.reshape(-1, 1)": 1,
      "test_df.values": 1,
      "train_df[feature].astype(np.float64).values[:, np.newaxis]": 1,
      "test_df[feature].astype(np.float64).values[:, np.newaxis]": 1,
      "X_val_num": 1,
      "test[cont_cols]": 1,
      "X['Population'].values.reshape(-1, 1)": 1,
      "X_test['Population'].values.reshape(-1, 1)": 1,
      "X_train_feature.values.reshape(-1, 1)": 1,
      "X_data_submission": 1,
      "cv_test": 1,
      "cv_test_": 1,
      "test[num_feature]": 1,
      "train_data[num_col]": 1,
      "test_data[num_col]": 1,
      "train[num_col]": 1,
      "lr_fea_te[lr_base_fea_cols[1:35]]": 1,
      "train_df[num_vars].values": 1,
      "test_df[num_vars].values": 1,
      "test_df[col].values.reshape(-1, 1)": 1,
      "pd.DataFrame(y_log_transformed)": 1,
      "pd.DataFrame(X_log_transformed)": 1,
      "X_valid[columns_to_scale]": 1,
      "X_test[columns_to_scale]": 1,
      "stats_data": 1,
      "train[cols_to_scale]": 1,
      "X_train_pos.T": 1,
      "X_train_neg.T": 1,
      "Test_imputed": 1,
      "basetable[features]": 1,
      "test[[ft]]": 1,
      "x_cv": 1,
      "X_num_test": 1,
      "fillna_npwhere(test_df[features].values, train_df_median[features].values)": 1,
      "X_train[int_vars]": 1,
      "X_test[int_vars]": 1,
      "project_data['price'].values.reshape(-1, 1)": 1,
      "knn_data": 1,
      "validation.iloc[:, ~validation.columns.isin(validation.iloc[:, validation.columns != 'target'].columns[indexes].tolist()[-44:] + ['target'])]": 1,
      "train_x.values": 1,
      "val_x.values": 1,
      "vt.transform(train2_pse[cols])": 1,
      "vt.transform(train2[cols])": 1,
      "vt.transform(test2[cols])": 1,
      "X_valid[num_features]": 1,
      "X_new": 1,
      "X_train[cont_cols]": 1,
      "X_test[cont_cols]": 1,
      "train_data[cont_cols]": 1,
      "test_data[cont_cols]": 1,
      "test[continuous_cols]": 1,
      "test_p": 1,
      "data.values": 1,
      "X_result": 1,
      "df[numerics]": 1,
      "test[numerics]": 1,
      "data[self.rssi_feats]": 1,
      "df_train[updated_numericals]": 1,
      "df_test[updated_numericals]": 1,
      "X_test_submission": 1,
      "test_X_df": 1,
      "train_new[new_features]": 1,
      "test_new[new_features]": 1,
      "val_train_features": 1,
      "test_stats": 1,
      "train_X[train_X.columns]": 1,
      "val_X[val_X.columns]": 1,
      "test_data[test_numerical]": 1,
      "Y_tr": 1,
      "train_x[continueList]": 1,
      "test_x[continueList]": 1,
      "for_pred_x[continueList]": 1,
      "test[independent_feat]": 1,
      "train.loc[:, features].values": 1,
      "X_train[features]": 1,
      "_df_train": 1,
      "_df_test": 1,
      "x_train.values[:, 0:10]": 1,
      "x_test.values[:, 0:10]": 1,
      "xT.values[:, 0:10]": 1,
      "df_blended_data[num_x]": 1,
      "df_changed_data[num_x]": 1,
      "X_val.values": 1,
      "test_full[nn_mol_features].values": 1,
      "test['fnlwgt'].values.reshape(-1, 1)": 1,
      "test['age'].values.reshape(-1, 1)": 1,
      "data7": 1,
      "test_rows": 1,
      "new_test": 1,
      "test_df[feat_cols_list]": 1,
      "train3": 1,
      "test3": 1,
      "train4": 1,
      "test4": 1,
      "train5": 1,
      "test5": 1,
      "test_features.values[:, top_feats]": 1,
      "df_test.loc[:, 'margin1':'margin64']": 1,
      "df_val.loc[:, 'margin1':'margin64']": 1,
      "df_test.loc[:, 'shape1':'shape64']": 1,
      "df_val.loc[:, 'shape1':'shape64']": 1,
      "df_test.loc[:, 'texture1':'texture64']": 1,
      "df_val.loc[:, 'texture1':'texture64']": 1,
      "test_data_final": 1,
      "X2_test": 1,
      "np.vstack(df_test['item_description'].astype(str).apply(extract_counts).values)": 1,
      "merge_with_cat_stats(df_test)": 1,
      "X_train.loc[:, scale_features]": 1,
      "df_test.loc[:, scale_features]": 1,
      "x_rf_train": 1,
      "train_xp": 1,
      "train_xn": 1,
      "valid_xp": 1,
      "valid_xn": 1,
      "fillna_npwhere(test_df[features].values, train_median_p[features].values)": 1,
      "fillna_npwhere(test_df[features].values, train_median_n[features].values)": 1,
      "Train_data": 1,
      "Test_data": 1,
      "X_rtest": 1,
      "test_df[num_cols_test]": 1,
      "X_test_new": 1,
      "part_B_x[numerical_cols].astype('float32')": 1,
      "part_C_x[numerical_cols].astype('float32')": 1,
      "test[numerical_cols].astype('float32')": 1,
      "df_test_X": 1,
      "train_red.drop(['Id', 'groupId', 'matchId', 'winPlacePerc'], axis=1)": 1,
      "x_test_final": 1,
      "x_cleaned": 1,
      "house_ts_cpy": 1,
      "sample_train_data_pca[featstr[1:]]": 1,
      "train_data_pca[featstr[1:]]": 1,
      "testingData": 1,
      "test['price'].values.reshape(-1, 1)": 1,
      "x_test['teacher_number_of_previously_posted_projects'].values.reshape(-1, 1)": 1,
      "test['teacher_number_of_previously_posted_projects'].values.reshape(-1, 1)": 1,
      "x_test['quantity'].values.reshape(-1, 1)": 1,
      "test['quantity'].values.reshape(-1, 1)": 1,
      "df_train[features]": 1,
      "train_data[['Age']]": 1,
      "test_data[['Age']]": 1,
      "np.array(X_val_1_simple, dtype='float64')": 1,
      "np.array(X_val_2_simple, dtype='float64')": 1,
      "pred_arr": 1,
      "my_team_train1": 1,
      "opp_team_train1": 1,
      "my_team_train2": 1,
      "opp_team_train2": 1,
      "my_team_test1": 1,
      "opp_team_test1": 1,
      "my_team_test2": 1,
      "opp_team_test2": 1,
      "other_train1": 1,
      "other_train2": 1,
      "other_test1": 1,
      "other_test2": 1,
      "np.array([id1_df[my_team_cols].tolist()])": 1,
      "np.array([id1_df[opp_team_cols].tolist()])": 1,
      "np.array([id1_df[other_cols].tolist()])": 1,
      "np.array([id2_df[my_team_cols].tolist()])": 1,
      "np.array([id2_df[opp_team_cols].tolist()])": 1,
      "np.array([id2_df[other_cols].tolist()])": 1,
      "X_e[[i for i in X_e.columns if i != 'excerpt']]": 1,
      "test2[[i for i in test2.columns if i != 'excerpt' and i != 'id']]": 1,
      "X_dev": 1,
      "fillna_npwhere(test_df[cols].values, train_median[cols].values)": 1,
      "ts_set": 1,
      "ts_features": 1,
      "test_chunk_values": 1,
      "data_features.values": 1,
      "test_data_features.values": 1,
      "numeric": 1,
      "x_train_feat": 1,
      "x_test_feat": 1,
      "test[['day_of_week_encoded', 'pd_district_encoded', 'x', 'y', 'hour']]": 1,
      "df_submit": 1,
      "numVar": 1,
      "scaled_feat": 1,
      "test_set_rf_cont": 1,
      "test_cont_feat": 1,
      "df[feature_cols].fillna(0).values": 1,
      "df_tst[feature_cols].fillna(0).values": 1,
      "X_test[numerical_vars]": 1,
      "price_list": 1,
      "yte": 1,
      "test_te": 1,
      "t1": 1,
      "test1": 1,
      "test_resources[label].astype(np.float64).values.reshape(-1, 1)": 1,
      "train[feature].astype(np.float64).values[:, np.newaxis]": 1,
      "test[feature].astype(np.float64).values[:, np.newaxis]": 1,
      "train_features[GENES + CELLS]": 1,
      "test_features[GENES + CELLS]": 1,
      "TestData_X": 1,
      "self.df.loc[:, num_list]": 1,
      "X_test.values.reshape(len(X_test), 784)": 1,
      "Y_train.values.reshape(-1, 1)": 1,
      "val_x_2": 1,
      "scr_x_2": 1,
      "nrm.transform(df_test)": 1,
      "x_test_data.drop(['row_id', 'series_id', 'measurement_number'], axis=1)": 1,
      "train[to_normalize]": 1,
      "test[to_normalize]": 1,
      "n_df": 1,
      "x_train.fillna(0)": 1,
      "_X_train[cols]": 1,
      "_X_test[cols]": 1,
      "test_data[DELTA_FEATS]": 1,
      "x0": 1,
      "x1": 1,
      "features_train.values": 1,
      "features_test.values": 1,
      "train_df[col].values.reshape(-1, 1)": 1,
      "submission[col].values.reshape(-1, 1)": 1,
      "train[test.columns]": 1,
      "train[columns]": 1,
      "test_df[columns]": 1,
      "train_input": 1,
      "test_input": 1,
      "test_new[num_features]": 1,
      "new_train_features": 1,
      "test[numeric.columns].fillna(numeric_fill)": 1,
      "X_testset[train_columns]": 1,
      "useful_train_feature": 1,
      "useless_train_feature": 1,
      "useful_test_feature": 1,
      "useless_test_feature": 1,
      "X_train[:, :len(numerical)]": 1,
      "X_test[:, :len(numerical)]": 1,
      "np.array(full_data[features_to_scale])": 1,
      "np.array(sub_full_data[features_to_scale])": 1,
      "F": 1,
      "test_smooth": 1,
      "X_test[:, :3]": 1,
      "Xt[selection].fillna(X[selection].median())": 1,
      "base_test": 1,
      "X_train_base": 1,
      "X_valid_base": 1,
      "X_test_base": 1,
      "X_test_": 1,
      "X_test[all_stats]": 1,
      "X_new[all_stats]": 1,
      "x_test_sel": 1,
      "X_test2": 1,
      "np.array(df_all_data[col]).reshape(-1, 1)": 1,
      "validation.groupby(['stock_id', 'time_id'])['target'].first().values.reshape(-1, 1)": 1,
      "train_gd": 1,
      "test_gd": 1,
      "np.log(x_valid.price.reshape(-1, 1) + 1)": 1,
      "y_.reshape(-1, 1)": 1,
      "df_train[colunas]": 1,
      "df_test[colunas]": 1,
      "X_test_glove": 1,
      "X_test_submit": 1,
      "val_ds": 1,
      "X_val[col].values.reshape(-1, 1)": 1,
      "X_pretest1": 1,
      "test.drop(['Id'], axis=1)": 1,
      "mtrain[self.num_cols + self.time_cols].astype(float)": 1,
      "news_df_numeric": 1,
      "Xt": 1,
      "xts": 1,
      "data_train[predictors]": 1,
      "data_test[predictors]": 1,
      "test.values.reshape(-1, 1)": 1,
      "orig_test['signal'].values.reshape(-1, 1)": 1,
      "e_stack.reshape((-1, 16))": 1,
      "X_valid_seq.reshape(-1, 10)": 1,
      "X_test_seq.reshape(-1, 10)": 1,
      "y_valid": 1,
      "X_valid_feat.reshape(-1, 10)": 1,
      "X_test_feat.reshape(-1, 10)": 1,
      "Z_test.values": 1,
      "X_test_a": 1,
      "train[column].values.reshape(-1, 1)": 1,
      "np.array(train.Age).reshape(-1, 1)": 1,
      "np.array(train.Fare).reshape(-1, 1)": 1,
      "df[featstr[1:]]": 1,
      "select_features": 1,
      "np.array([row['Latitude'], row['Longitude'], row['month']]).astype(float).reshape(1, 3)": 1,
      "x_valid": 1,
      "x_test.iloc[:, 2:11]": 1,
      "x_test.iloc[:, 8:15]": 1,
      "feature_train_df": 1,
      "feature_test_df": 1,
      "all_df_scaled": 1,
      "row[train_columns].values.reshape(1, -1)": 1,
      "row[train_feature_columns].values.reshape(1, -1)": 1,
      "X_all[features_to_scale_flatten]": 1,
      "X_fake[features_to_scale_flatten]": 1,
      "test[col_StandardScale]": 1,
      "test_final": 1,
      "X_test.loc[:, X_test.columns[3:]]": 1,
      "train_df.loc[:, d_i].values.reshape(-1, 1)": 1,
      "test_df.loc[:, d_i].values.reshape(-1, 1)": 1,
      "X_testing": 1,
      "X_test_rf": 1,
      "sub[['Weeks', 'Age', 'base_week', 'count_from_base_week', 'base_fvc', 'base_fev1', 'base_week_percent', 'base fev1/base fvc', 'base_height', 'base_weight', 'base_bmi']]": 1,
      "l_test": 1,
      "test_unscale": 1,
      "test[cont]": 1,
      "X_test.loc[:, numerical_features]": 1,
      "xtest_lr_elif": 1,
      "xtest_lr_perm": 1,
      "X_test_pca": 1,
      "mtestData": 1,
      "last_test": 1,
      "x_data_2": 1,
      "add_data_last": 1,
      "val_X[cont_columns]": 1,
      "pubg_test": 1,
      "result3_test[lister_4]": 1,
      "train_df[[cols]]": 1,
      "test_df[[cols]]": 1,
      "observation.features.iloc[:, 2:].values": 1,
      "trainX": 1,
      "X1_test": 1,
      "test[g_columns]": 1,
      "df[df['merchant_id'].isnull()][clmns].values": 1,
      "data[col].to_numpy().reshape(-1, 1)": 1,
      "test[num_cols]": 1,
      "train[['shape2', 'shape3', 'shape1', 'margin16']]": 1,
      "X_train_encoded": 1,
      "X_test_Auser": 1,
      "X_f_test": 1,
      "X_train.astype(float)": 1,
      "X_test.astype(float)": 1,
      "xTestNum": 1,
      "xTestNumClip": 1,
      "xvalid_tfv": 1,
      "test_df[['answered_correctly_user', 'explanation_mean_user', 'quest_pct', 'avg_questions_seen', 'prior_question_elapsed_time', 'prior_question_had_explanation_enc', 'part']]": 1,
      "df[[x]]": 1,
      "df1[[x]]": 1,
      "TestDF_Input": 1,
      "Check_0[features]": 1,
      "Check_1[features]": 1,
      "check_corr_1[features]": 1,
      "train_evaluation[features]": 1,
      "df_F_test_M[features]": 1,
      "matrix": 1,
      "taxi_trip_data[features]": 1,
      "final_X_train": 1,
      "application_train[col].values.reshape(-1, 1)": 1,
      "application_test[col].values.reshape(-1, 1)": 1,
      "train[col]": 1,
      "test_dataset": 1,
      "test_features.drop('cp_type', axis=1).iloc[:, :2]": 1,
      "A_test": 1,
      "df_test3": 1,
      "general_data": 1,
      "dataset[['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp', 'humidity', 'windspeed', 'year', 'month', 'day', 'hour']]": 1,
      "test_dataset[['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp', 'humidity', 'windspeed', 'year', 'month', 'day', 'hour']]": 1,
      "X_Test_CS": 1,
      "x_test_pf": 1,
      "testdf": 1,
      "X_test[numeric_columns]": 1,
      "X_out.astype(float)": 1,
      "market_obs_df[INPUT_COLS]": 1,
      "df_numeric": 1,
      "xTrain": 1,
      "df_test[fet_num_list]": 1,
      "df_test[ordinal_cols]": 1,
      "mlp.predict(vl_x).reshape(-1, 1)": 1,
      "X_train[numerics]": 1,
      "X_test[numerics]": 1,
      "reduce_test.loc[:, best_features['Feature']]": 1,
      "x_train2[[x]]": 1,
      "x_test2[[x]]": 1,
      "test[feat_name].values.reshape(-1, 1)": 1,
      "np.swapaxes(data, 0, 1)": 1,
      "test.values[:, top_feats]": 1,
      "X_sample": 1,
      "dataframe": 1,
      "X_test[col].values.reshape(-1, 1)": 1,
      "y_test['Hazard'].values.reshape(-1, 1)": 1,
      "X_df_test[col].values.reshape(-1, 1)": 1,
      "df[columns].values": 1,
      "data_x_test": 1,
      "Xx": 1,
      "test.fillna(fill_val)": 1,
      "df[['age_approx']]": 1,
      "[generate_hist_vec(img) for img in unseen_img_sample]": 1,
      "x_train[num_col]": 1,
      "x_val[num_col]": 1,
      "testx": 1,
      "test_pca": 1,
      "y_test.values.reshape(-1, 1)": 1,
      "x[num_cols]": 1,
      "train[GENES]": 1,
      "test[GENES]": 1,
      "train[CELLS]": 1,
      "test[CELLS]": 1,
      "test_df[test_df.columns]": 1,
      "train[actualcolumns]": 1,
      "test[actualcolumns]": 1,
      "full_data.loc[:, features]": 1,
      "gptrain[gptrain.columns]": 1,
      "gptest[gptest.columns]": 1,
      "X[feats]": 1,
      "X_test[feats]": 1,
      "X[X.columns]": 1,
      "test_df[X.columns]": 1,
      "train[train.columns]": 1,
      "train_X[features]": 1,
      "test_X[features]": 1,
      "test_df[feats]": 1,
      "X_imputed": 1,
      "X_train_char": 1,
      "X_valid_char": 1,
      "X_test_char": 1,
      "X_train_word": 1,
      "X_valid_word": 1,
      "X_test_word": 1,
      "t4p[feat]": 1,
      "val_features": 1,
      "X_": 1,
      "test_fe": 1,
      "z": 1,
      "enc_df": 1,
      "test_enc_df": 1,
      "test.signal.values.reshape(-1, 1)": 1,
      "X_val[scale_vars]": 1,
      "titanic_test[scale_vars]": 1,
      "X[scale_vars]": 1,
      "validation_set": 1,
      "test[column_names]": 1,
      "df_train[features].values": 1,
      "df_test[features].values": 1,
      "hand_crafted_cv": 1,
      "hand_crafted_test": 1,
      "test_hand_craft.values": 1,
      "df[numeric_cols]": 1,
      "merge_df_test": 1,
      "X_train_orig": 1,
      "X_valid_orig": 1,
      "X_test_orig": 1,
      "train_df['Comment_Len'].values.reshape(-1, 1)": 1,
      "cv_df['Comment_Len'].values.reshape(-1, 1)": 1,
      "df_test['Comment_Len'].values.reshape(-1, 1)": 1,
      "train_df['Topic-1'].values.reshape(-1, 1)": 1,
      "cv_df['Topic-1'].values.reshape(-1, 1)": 1,
      "df_test['Topic-1'].values.reshape(-1, 1)": 1,
      "train_df['Topic-2'].values.reshape(-1, 1)": 1,
      "cv_df['Topic-2'].values.reshape(-1, 1)": 1,
      "df_test['Topic-2'].values.reshape(-1, 1)": 1,
      "train_df['Topic-3'].values.reshape(-1, 1)": 1,
      "cv_df['Topic-3'].values.reshape(-1, 1)": 1,
      "df_test['Topic-3'].values.reshape(-1, 1)": 1,
      "train_df['Topic-4'].values.reshape(-1, 1)": 1,
      "cv_df['Topic-4'].values.reshape(-1, 1)": 1,
      "df_test['Topic-4'].values.reshape(-1, 1)": 1,
      "train_df['Topic-5'].values.reshape(-1, 1)": 1,
      "cv_df['Topic-5'].values.reshape(-1, 1)": 1,
      "df_test['Topic-5'].values.reshape(-1, 1)": 1,
      "points": 1,
      "test_new": 1,
      "X_test0": 1,
      "Q": 1,
      "train[cont_feat]": 1,
      "test[cont_feat]": 1,
      "pd.DataFrame(train_0[col])": 1,
      "pd.DataFrame(valid_0[col])": 1,
      "pd.DataFrame(test_0[col])": 1,
      "X_ds_train": 1,
      "X_solo_train": 1,
      "X_final_ds": 1,
      "X_final_solo": 1,
      "df_train_0_x": 1,
      "df_valid_0_x": 1,
      "df_valid.drop(['isFraud'], axis=1)": 1,
      "new_val_X": 1,
      "new_test_X": 1,
      "np.reshape(mydata[val_indices], (len(val_indices) * 3780, len(num_cols)))": 1,
      "history[num_cols]": 1,
      "my_final_test": 1,
      "splits[split_][features]": 1,
      "train_s": 1,
      "data_test[features].T": 1,
      "x_tr": 1,
      "cover_new": 1,
      "cont_train[cont_vars]": 1,
      "test_data[cont_vars]": 1,
      "X_imp": 1,
      "test_imp": 1,
      "X_trainA": 1,
      "X_testA": 1,
      "train[feature_names]": 1,
      "test[feature_names]": 1,
      "raw_vec": 1,
      "test[col].values.reshape(vec_len_test, 1)": 1,
      "data[std_cols]": 1,
      "xx_test": 1,
      "sentence_feature_mat": 1,
      "testg": 1,
      "va_x": 1,
      "df_test[df_train_col]": 1,
      "data_features": 1,
      "train_mod": 1,
      "test_add": 1,
      "test[col].to_frame()": 1,
      "X_train_final": 1,
      "tmp[features_to_be_scaled_lst]": 1,
      "batch_x": 1,
      "batch_y": 1,
      "old_row": 1,
      "train_y": 1,
      "row_x": 1,
      "to_float(X_val)": 1,
      "Xb": 1,
      "test.drop(columns=to_drop)": 1,
      "train[feats]": 1,
      "test[feats]": 1,
      "df[features_names]": 1,
      "test_df.drop('id', axis=1).values": 1,
      "X[features_without_holiday]": 1,
      "test_data[features_without_holiday]": 1,
      "s_data": 1,
      "t_data": 1,
      "x_tr['price'].values.reshape(-1, 1)": 1,
      "x_cv['price'].values.reshape(-1, 1)": 1,
      "val_X_prep": 1,
      "test_X_prep": 1,
      "df[feature_scale]": 1,
      "margin": 1,
      "shape": 1,
      "texture": 1,
      "testMargin": 1,
      "testShape": 1,
      "testTexture": 1,
      "test.iloc[:, 4:]": 1,
      "test_y_reshape": 1,
      "X_train[scaling_list].values": 1,
      "X_test[scaling_list]": 1,
      "testing[testing.columns[1:]]": 1,
      "X_test_arr.reshape(-1, 1)": 1,
      "vlX[num_cols].values": 1,
      "X_test2_concat": 1,
      "X_test[train_columns]": 1,
      "val_X_svd": 1,
      "val_X_svd_tfv": 1,
      "XT": 1,
      "Predictions_2014": 1,
      "Predictions_2015": 1,
      "Predictions_2016": 1,
      "Predictions_2017": 1,
      "Predictions_2014.iloc[:, 1:3]": 1,
      "Predictions_2014.iloc[:, 12:13]": 1,
      "Predictions_2014.iloc[:, 3:12]": 1,
      "Predictions_2014.iloc[:, 0:1]": 1,
      "Predictions_2015.iloc[:, 1:3]": 1,
      "Predictions_2015.iloc[:, 12:13]": 1,
      "Predictions_2015.iloc[:, 3:12]": 1,
      "Predictions_2015.iloc[:, 0:1]": 1,
      "Predictions_2016.iloc[:, 1:3]": 1,
      "Predictions_2016.iloc[:, 12:13]": 1,
      "Predictions_2016.iloc[:, 3:12]": 1,
      "Predictions_2016.iloc[:, 0:1]": 1,
      "Predictions_2017.iloc[:, 1:3]": 1,
      "Predictions_2017.iloc[:, 12:13]": 1,
      "Predictions_2017.iloc[:, 3:12]": 1,
      "Predictions_2017.iloc[:, 0:1]": 1,
      "Predictions_2018": 1,
      "X_train['description_len'].values.reshape(-1, 1)": 1,
      "X_test['description_len'].values.reshape(-1, 1)": 1,
      "tr[feature].values.reshape(-1, 1)": 1,
      "ts[feature].values.reshape(-1, 1)": 1,
      "dataframe['description_len'].values.reshape(-1, 1)": 1,
      "test_prepared": 1,
      "F_train": 1,
      "F_test": 1,
      "X_test_all_pow": 1,
      "train.drop('Survived', axis=1)": 1,
      "test_ds[train_columns]": 1,
      "pca.transform(test2p[cols])": 1,
      "test_": 1,
      "np_val_features": 1,
      "X_gtest": 1,
      "X_le_pca": 1,
      "train_wo_mc": 1,
      "test_wo_mc": 1,
      "Z": 1,
      "X_train_high_corr": 1,
      "X_test_high_corr": 1,
      "train[resp_group]": 1,
      "X.toarray()": 1,
      "X_test.toarray()": 1,
      "all_data.iloc[:n_trains]": 1,
      "all_data.iloc[n_trains:]": 1,
      "transform_data(test)": 1,
      "trainP": 1,
      "validP": 1,
      "testP": 1,
      "trainN": 1,
      "validN": 1,
      "testN": 1,
      "x_train_full": 1,
      "x_test_full": 1,
      "x_sub_full": 1,
      "y_train.values.reshape(y_train.shape[0], 1)": 1,
      "df_test_1": 1,
      "test_df.iloc[:, 2:]": 1,
      "test_X_np": 1,
      "Xp": 1,
      "x_localtrain": 1,
      "x_localval": 1,
      "df_test_": 1,
      "data_T": 1,
      "test_X[cols]": 1,
      "test_y": 1,
      "train_onehot": 1,
      "test_df['z'].values.reshape(-1, 1)": 1,
      "test_feat": 1,
      "train.loc[:, features]": 1,
      "X_train_transformed": 1,
      "X_val_transformed": 1,
      "X_test_transformed": 1,
      "df_train.drop('Cover_Type', axis=1).values": 1,
      "df_validate.drop('Cover_Type', axis=1).values": 1,
      "X_test.values": 1,
      "feature_selected": 1,
      "data_test.drop(['id'] + to_drop, axis=1)": 1,
      "featuresEncoded": 1,
      "encodeFeatures(data_test.drop(['id'], axis=1))": 1,
      "featuresExtended": 1,
      "np.array(df_test['Age']).reshape(-1, 1)": 1
    },
    "sklearn.preprocessing._encoders.OneHotEncoder.__init__.handle_unknown": {
      "'error'": 1125,
      "'ignore'": 381
    },
    "sklearn.preprocessing._encoders.OneHotEncoder.fit_transform.X": {
      "integer_encoded": 65,
      "train_df[[cat]]": 54,
      "country_ids_base": 34,
      "feature": 26,
      "geo_ids_base": 21,
      "y.values.reshape(-1, 1)": 16,
      "X": 13,
      "category_df": 11,
      "y_train": 10,
      "image_bbox_df['class_idx'].values.reshape(-1, 1)": 9,
      "continents_ids_base": 7,
      "X_cat": 7,
      "np.vstack((trn.values, sub.values))": 6,
      "y": 6,
      "y_train.reshape(-1, 1)": 5,
      "df": 5,
      "y_train.values.reshape(-1, 1)": 5,
      "features.reshape(-1, 1)": 5,
      "x_train[ohe_features]": 4,
      "X_train_1": 4,
      "X_test_1": 4,
      "X_sub": 4,
      "y.reshape(-1, 1)": 4,
      "df_train": 4,
      "y_validation": 4,
      "numpy.array(train_store[col]).reshape((len(train_store[col]), 1))": 4,
      "sales['dept_id'].values.reshape(-1, 1)": 4,
      "sales['cat_id'].values.reshape(-1, 1)": 4,
      "sales['state_id'].values.reshape(-1, 1)": 4,
      "imputed_calendar": 4,
      "tmp_data": 4,
      "train": 3,
      "train_cats": 3,
      "df[feature].values.reshape(-1, 1)": 3,
      "X_train[low_cardinality_cols]": 3,
      "x": 3,
      "nom_0_9_matrix": 3,
      "x_test": 3,
      "categorical": 3,
      "grid_df[['state_id']]": 3,
      "np.array(df_copy['original_language']).reshape(-1, 1)": 2,
      "dataset.loc[:, ohe_features]": 2,
      "y[:, np.newaxis]": 2,
      "cat_train": 2,
      "categorical_features": 2,
      "all_df[onehot_cols].values": 2,
      "numpy.array(train[col]).reshape((len(train[col]), 1))": 2,
      "df_work[nomvar]": 2,
      "df_work[dmvar]": 2,
      "train['cp_time'].to_numpy().reshape(-1, 1)": 2,
      "train[col4train]": 2,
      "X[cat_cols]": 2,
      "X_train": 2,
      "train_categorical": 2,
      "Y_train": 2,
      "x_train": 2,
      "data": 2,
      "X_train[object_cols]": 2,
      "labels": 2,
      "df[categorical_columns]": 2,
      "pd.DataFrame(X_cats, columns=[X_cats_names])[nominal_features]": 2,
      "color_encode.reshape((color_encode.size, 1))": 2,
      "values.reshape(values.shape[0], 1)": 2,
      "X[[col]]": 2,
      "X_train_norm": 2,
      "cat_train_features": 2,
      "cat": 2,
      "SH_int": 2,
      "pd.DataFrame(train_data.target)": 2,
      "label_X_train[object_cols]": 2,
      "stack": 2,
      "df[col].values.reshape(-1, 1)": 2,
      "pd.cut(alldata[c], cuts, labels=False).values.reshape(-1, 1)": 2,
      "X_test": 2,
      "data[['Type']]": 2,
      "X[categorielles]": 2,
      "test[categorielles]": 2,
      "y_true.reshape(-1, 1)": 2,
      "target.reshape(-1, 1)": 2,
      "z_df[obj_cols]": 2,
      "train_categorical_values": 2,
      "np.array(label_names).reshape(-1, 1)": 2,
      "np.array(df_copy['Director']).reshape(-1, 1)": 1,
      "np.array(df_copy['Lead']).reshape(-1, 1)": 1,
      "X_combined_clean": 1,
      "data[['netloc', 'category']]": 1,
      "train_y.reshape(-1, 1)": 1,
      "val_y.reshape(-1, 1)": 1,
      "df[['Sex']]": 1,
      "df[['Embarked']]": 1,
      "y_train.reshape(y_train.shape[0], 1)": 1,
      "my_geoloc_ids_base": 1,
      "df_train[['item_condition_id', 'shipping']].values": 1,
      "all_data[object_cols]": 1,
      "df[[column]]": 1,
      "data['type'].values.reshape(len(data), 1)": 1,
      "imputed_X_train[categorical_cols]": 1,
      "X_train[obj_columns]": 1,
      "X_train[categor_col]": 1,
      "int_encoded": 1,
      "train_cat": 1,
      "dataset[cat_variables]": 1,
      "train_df[['sex', 'anatom_site_general_challenge']]": 1,
      "test_df[['sex', 'anatom_site_general_challenge']]": 1,
      "train_features[categorical_features]": 1,
      "cat_train_data": 1,
      "cat_test_x": 1,
      "np.array(y_train).reshape(-1, 1)": 1,
      "np.array(y_validation).reshape(-1, 1)": 1,
      "labels.reshape((-1, 1))": 1,
      "df1[['bin_4']]": 1,
      "df[['cp_type', 'cp_time', 'cp_dose']]": 1,
      "data[cat_vars]": 1,
      "df_train[feature].values.reshape(-1, 1)": 1,
      "df_test[feature].values.reshape(-1, 1)": 1,
      "train['shipping'].values.reshape(-1, 1)": 1,
      "train['item_condition_id'].values.reshape(-1, 1)": 1,
      "train_data['matchType'].values.reshape(-1, 1)": 1,
      "test_data['matchType'].values.reshape(-1, 1)": 1,
      "train[feature].values.reshape(-1, 1)": 1,
      "test[feature].values.reshape(-1, 1)": 1,
      "np.array(train_labels_healthy).reshape(-1, 1)": 1,
      "np.array(train_labels_multiple_diseases).reshape(-1, 1)": 1,
      "np.array(train_labels_rust).reshape(-1, 1)": 1,
      "np.array(train_labels_scab).reshape(-1, 1)": 1,
      "trainLabel": 1,
      "train_tv_X": 1,
      "X_balanced_dropna_cat": 1,
      "df_imputed_cat": 1,
      "y.values.reshape(X.shape[0], 1)": 1,
      "df_train[cat_columns]": 1,
      "df_train[cat_columns_reduce]": 1,
      "df2[['Category']]": 1,
      "taxi_cat": 1,
      "df_test": 1,
      "y.to_frame().values": 1,
      "labeled_dummies.reshape(-1, 1)": 1,
      "X[X_catCols]": 1,
      "train[['fault_severity']].as_matrix()": 1,
      "all_data[feature_name].as_matrix()": 1,
      "train_df[['diagnosis']]": 1,
      "le_ajustado": 1,
      "train_data[train_object_cols]": 1,
      "store_data[store_object_cols]": 1,
      "y_test": 1,
      "dataset.values": 1,
      "x[['Sex', 'SmokingStatus']]": 1,
      "train_test_phone.apply(lambda col: LabelEncoder().fit_transform(col))": 1,
      "X2_train_dnn": 1,
      "labels.reshape([-1, 1])": 1,
      "train_data[strings]": 1,
      "bureau_cat": 1,
      "categorical_ftrs": 1,
      "te_categorical_ftrs": 1,
      "score_categorical_ftrs": 1,
      "train_df['floor'].values.reshape(-1, 1)": 1,
      "train_data[['label']]": 1,
      "y_original": 1,
      "Canadate": 1,
      "yl.reshape(-1, 1)": 1,
      "condition.values.reshape(-1, 1)": 1,
      "lb.fit_transform(cat_1.values.reshape(-1, 1)).reshape(-1, 1)": 1,
      "lb.fit_transform(cat_2.values.reshape(-1, 1)).reshape(-1, 1)": 1,
      "lb.fit_transform(cat_3.values.reshape(-1, 1)).reshape(-1, 1)": 1,
      "df[['country']]": 1,
      "Ints[['bin_3_Cat']]": 1,
      "Ints[['bin_4_Cat']]": 1,
      "Ints[['nom_0_Cat']]": 1,
      "Ints[['nom_1_Cat']]": 1,
      "Ints[['nom_2_Cat']]": 1,
      "Ints[['nom_3_Cat']]": 1,
      "Ints[['nom_4_Cat']]": 1,
      "Ints[['ord_1_Cat']]": 1,
      "Ints[['ord_2_Cat']]": 1,
      "Ints[['ord_0']]": 1,
      "reshape_arr_train": 1,
      "train['workclass'].values.reshape(-1, 1)": 1,
      "label_encoded[:, np.newaxis]": 1,
      "test_df['diagnosis'].values.reshape(-1, 1)": 1,
      "onehot_label": 1,
      "tr_te.drop(['id', 'target'], axis=1).copy()": 1,
      "val_Y.reshape(-1, 1)": 1,
      "X_train[['seat']]": 1,
      "X_train[['crew']]": 1,
      "X_test[['seat']]": 1,
      "X_test[['crew']]": 1,
      "ylabel": 1,
      "cat_df": 1,
      "df[[col]]": 1,
      "sent_train": 1,
      "sent_test": 1,
      "exam.reshape(-1, 1)": 1,
      "X[[feature]]": 1,
      "train[ohe_columns]": 1,
      "np.array(le_out).reshape(-1, 1)": 1,
      "df[col_name].values.reshape(-1, 1)": 1,
      "x_train.iloc[:, 3].values.reshape(-1, 1)": 1,
      "df_train[oh_cols]": 1,
      "train_seqpos[['predicted_loop_type', 'sequence']]": 1,
      "df_full_linear['DayOfWeek'].values.reshape(-1, 1)": 1,
      "df_full_linear['StoreType'].values.reshape(-1, 1)": 1,
      "df_full_linear['Assortment'].values.reshape(-1, 1)": 1,
      "df_linear_test['DayOfWeek'].values.reshape(-1, 1)": 1,
      "df_linear_test['StoreType'].values.reshape(-1, 1)": 1,
      "df_linear_test['Assortment'].values.reshape(-1, 1)": 1,
      "train_ann[['isup_grade']]": 1,
      "train_features": 1,
      "np.array(y_train['time_to_failure']).reshape(-1, 1)": 1,
      "cur_train": 1,
      "y_val.values.reshape(-1, 1)": 1,
      "day_one_hot": 1,
      "X_train_cat": 1,
      "trn[cat_cols]": 1,
      "tt_combine[['main_cat_le', 'subcat1_le', 'subcat2_le', 'subcat3_le', 'subcat4_le']]": 1,
      "train['target'].values.reshape(-1, 1)": 1,
      "train_data_cat_full2": 1,
      "housing_processed": 1,
      "train_data_x": 1,
      "df[[col_name]]": 1,
      "TargetHot": 1,
      "feature_train[cat_cols]": 1,
      "nr_y_train.reshape(-1, 1)": 1,
      "X_OH": 1,
      "merge[features_to_encode]": 1,
      "train_df[['isup_grade']]": 1,
      "ord_data": 1,
      "new_data": 1,
      "train_features[['cp_type', 'cp_dose']]": 1,
      "train_df[features]": 1,
      "f": 1,
      "train_df[low_cardinality_nom_cols]": 1,
      "forOneHot": 1,
      "train[categoric_cols]": 1,
      "data[categoric]": 1,
      "x.dataset[['Neighborhood']]": 1,
      "train[['brand_name', 'category_name_1', 'category_name_2', 'shipping', 'item_condition_id']].values": 1,
      "train[cat_cols]": 1,
      "df[[c]]": 1,
      "x_train_k[c].values.reshape(-1, 1)": 1,
      "x_test_k[c].values.reshape(-1, 1)": 1,
      "df[feature].to_numpy().reshape(-1, 1)": 1,
      "labels.values.reshape(-1, 1)": 1,
      "table[['Sex', 'SmokingStatus']]": 1,
      "y_train.values.reshape(X.shape[0], 1)": 1,
      "target_values": 1,
      "selected[key_attributes].apply(lambda x: x.cat.codes)": 1,
      "y_true": 1,
      "np.array(tmp).reshape(-1, 1)": 1,
      "np.array(X).transpose()": 1,
      "[train['status']]": 1,
      "[test['status']]": 1,
      "int_enc": 1,
      "X_train[cat_cols]": 1,
      "X_cats_full": 1,
      "_df['Condition1'].to_numpy().reshape(-1, 1)": 1,
      "train_X[cat_col]": 1,
      "df_train[categorical_feats]": 1,
      "mydf[['store', 'item']]": 1,
      "train_csv[['SmokingStatus']]": 1,
      "train_data[feature].values.reshape(-1, 1)": 1,
      "test_data[feature].values.reshape(-1, 1)": 1,
      "data_df[features_to_encode]": 1,
      "train[['Target']]": 1,
      "test[['Target']]": 1,
      "trn[['fact_' + self.name]].replace(-1, 999)": 1,
      "categorical_data": 1,
      "categorical_data_test": 1,
      "train_X[oh_cols]": 1,
      "data_train_11[['Sex', 'Embarked']]": 1,
      "table.loc[:, ['weather']]": 1,
      "table.loc[:, ['dow']]": 1,
      "Y_.reshape(-1, 1)": 1,
      "temp": 1,
      "traintest[ohe_1_features]": 1,
      "traintest[ohe_2_features]": 1,
      "traintest[ohe_3_features]": 1,
      "dataset1": 1,
      "df[cat_features]": 1,
      "cat_t": 1,
      "X_int": 1,
      "df_train.DayOfWeek.values.reshape(-1, 1)": 1,
      "df_test.DayOfWeek.values.astype(str).reshape(-1, 1)": 1,
      "train[target].values.reshape(-1, 1)": 1,
      "train_info['label'].values.reshape(-1, 1)": 1,
      "Y1": 1,
      "train_data[['keyword']]": 1,
      "imputed_train[object_cols]": 1,
      "np.array(df_c).reshape(-1, 1)": 1,
      "train[col].values.reshape(-1, 1)": 1,
      "label_x_train": 1,
      "data_df[['diagnosis', 'sex']]": 1,
      "x_data_df[catColumns]": 1,
      "reduce_train[categoricals]": 1,
      "reduce_test[categoricals]": 1,
      "X_train[low_cardinal]": 1,
      "all_train[cat_features].fillna('0')": 1,
      "train[cat_features].fillna('0')": 1,
      "test_c[:, 11].reshape(-1, 1)": 1,
      "data_train[objlist]": 1,
      "test": 1,
      "ctri[one_hot]": 1,
      "X_all[:, :10]": 1,
      "y.reshape(len(y), 1)": 1,
      "alldata[c].values.reshape(1, -1).T": 1,
      "np.expand_dims(y, axis=1)": 1,
      "cat_data": 1,
      "y_test.reshape(-1, 1)": 1,
      "train_X[['cp_type', 'cp_dose', 'cp_time']]": 1,
      "test_categorical": 1,
      "data['train_data'][['SmokingStatus']]": 1,
      "Age_D": 1,
      "Title_df.values": 1,
      "col": 1,
      "df.target.values.reshape(-1, 1)": 1,
      "training_labels": 1,
      "train_y_encoded": 1,
      "y_train_input.values.reshape(-1, 1)": 1,
      "labelencodedv.reshape(-1, 1)": 1,
      "labelencodedo.reshape(-1, 1)": 1,
      "dataset[cat_col]": 1,
      "data[['City Group']]": 1,
      "test[['City Group']]": 1,
      "test[['Type']]": 1,
      "y_raw.reshape(-1, 1)": 1,
      "X[low_cardinality_cols]": 1,
      "self.feature": 1,
      "descritize_each_column(self.feature, self.bins)": 1,
      "df[object_cols]": 1,
      "df_combined[object_cols]": 1,
      "b": 1,
      "b11": 1,
      "cat_X": 1,
      "X2": 1,
      "train[feat_group['fea_cat']]": 1,
      "data[['Gender']]": 1,
      "data[['Color1']]": 1,
      "data[['Color2']]": 1,
      "data[['MaturitySize']]": 1,
      "data[['FurLength']]": 1,
      "data[['Vaccinated']]": 1,
      "data[['Dewormed']]": 1,
      "data[['Sterilized']]": 1,
      "data[['Health']]": 1,
      "train_df[cat_FEATURES]": 1,
      "traindf.select_dtypes('object')": 1,
      "label_X_train[new_OH]": 1,
      "label_X_valid[new_OH]": 1,
      "df[Cat_columns]": 1,
      "np.reshape(Y_train, (Y_train.shape[0], 1))": 1,
      "np.reshape(Y, (Y.shape[0], 1))": 1,
      "inteiros": 1,
      "data[column_name].values.reshape(-1, 1)": 1,
      "train_df['town'].values.reshape(-1, 1)": 1,
      "train_df['meta_category'].values.reshape(-1, 1)": 1,
      "all_data_t": 1,
      "list(train_y.reshape(-1, 1))": 1,
      "list(test_y.reshape(-1, 1))": 1,
      "X_cat[cat].values.reshape(len(X_cat), 1)": 1,
      "merged[toEncode]": 1,
      "df_train3[categorical_train]": 1,
      "df_test3[categorical_test]": 1,
      "all_data[nom_cols]": 1,
      "all_data[date_cols]": 1,
      "all_data[cat_features]": 1,
      "trainraw[['cp_type', 'cp_dose']]": 1,
      "train_X": 1,
      "X.nom_2.values.reshape(-1, 1)": 1,
      "X.nom_3.values.reshape(-1, 1)": 1,
      "X.nom_4.values.reshape(-1, 1)": 1,
      "X.day.values.reshape(-1, 1)": 1,
      "X.month.values.reshape(-1, 1)": 1,
      "train_data_v8[hot_columns]": 1,
      "train_df['coverage_class'].values.reshape(-1, 1)": 1,
      "semant_kmeans": 1,
      "tmp_tr": 1,
      "df.to_numpy().reshape(-1, 1)": 1,
      "train_x.loc[:, col].values.reshape(-1, 1)": 1,
      "np.array(list(train_df[f].values) + list(test_df[f].values)).reshape(-1, 1)": 1,
      "np.array([df['item_condition_id'].tolist(), df['shipping'].tolist()]).T": 1
    },
    "sklearn.linear_model._ridge.Ridge.__init__.alpha": {
      "1.0": 584,
      "alpha": 111,
      "1": 48,
      "0.5": 38,
      "0.1": 28,
      "3": 27,
      "100": 26,
      "10": 23,
      "0.4": 17,
      "20": 16,
      "5": 14,
      "0.05": 12,
      "3.3": 12,
      "0.01": 11,
      "50": 11,
      "3.1": 11,
      "i": 10,
      "30": 7,
      "0.75": 7,
      "0.001": 6,
      "10.0": 5,
      "50.0": 5,
      "2": 5,
      "5.0": 5,
      "a": 4,
      "220": 4,
      "0.0001": 4,
      "0.9": 4,
      "330": 4,
      "200": 4,
      "0.025": 4,
      "0.6": 4,
      "1 / 2 * C": 4,
      "alpha_best": 3,
      "alpha_val": 3,
      "81.01": 3,
      "38": 3,
      "0.7": 3,
      "ridgecv.alpha_": 3,
      "0.3": 3,
      "0.8": 3,
      "1000": 3,
      "4.75": 3,
      "4.5": 3,
      "60": 3,
      "20.0": 2,
      "40": 2,
      "8": 2,
      "best_Alpha": 2,
      "7": 2,
      "0.0065": 2,
      "75.0": 2,
      "best_alpha": 2,
      "2.651347536470113": 2,
      "3.5": 2,
      "1.5": 2,
      "ridge_best_Lambda": 2,
      "4": 2,
      "5.3": 2,
      "0.95": 2,
      "1500": 2,
      "2.5": 2,
      "parameter[0]": 2,
      "2.0": 2,
      "0.005": 2,
      "18": 2,
      "best_ridge_alpha": 2,
      "0.03": 2,
      "0.015269": 1,
      "ridge_regressor.best_params_['alpha']": 1,
      "3.0": 1,
      "alpha[best_alpha]": 1,
      "C": 1,
      "3.8000000000000003": 1,
      "al": 1,
      "500.0": 1,
      "params['alpha']": 1,
      "3.0656": 1,
      "2 * ridgecv.alpha_": 1,
      "lamb": 1,
      "model.alpha_": 1,
      "0.9999894695819446": 1,
      "0.45": 1,
      "5.2": 1,
      "clf_cv.best_params_['alpha']": 1,
      "lmda": 1,
      "_alpha": 1,
      "7.491061624529043": 1,
      "631.1412445239156": 1,
      "0.04": 1,
      "1e-05": 1,
      "23": 1,
      "30.0": 1,
      "100000.0": 1,
      "35": 1,
      "805.0291812295973": 1,
      "final_alpha": 1,
      "trial.suggest_float('alpha', 0.001, 1)": 1,
      "0.0": 1,
      "10**(-i)": 1,
      "9": 1,
      "9.325573593386588": 1,
      "tuning_parameter": 1,
      "12.0": 1,
      "1250": 1,
      "optpars['sbm+funcdeweighted_win_ridge'][target]": 1,
      "optpars['sbm+funcdeweighted_win_ridgebag'][target]": 1,
      "optpars['sbm+sbm_win_ridge_alpha'][target]": 1,
      "optpars['sbm+sbm_win_ridge_alphabag'][target]": 1,
      "optpars['fnc_extended_ridge'][target]": 1,
      "optpars['fnc_extended_ridgebag'][target]": 1,
      "optpars['fnc_simple_ridge'][target]": 1,
      "optpars['spatial_maps_gmmax_wm_csf'][target]": 1,
      "optpars['fnc_graph_ridge_alpha'][target]": 1,
      "optpars['gm_all_ridge_alpha'][target]": 1,
      "optpars['sbm_PNI_ridge_alpha'][target]": 1,
      "3000": 1,
      "0.0005": 1,
      "12.773681311355642": 1,
      "16.66": 1,
      "500": 1,
      "m": 1,
      "l2_penalty": 1,
      "10000": 1,
      "trial.suggest_loguniform('alpha', 0.1, 5)": 1,
      "1.9510706324753746": 1,
      "16.8": 1,
      "5000": 1,
      "self.alpha": 1,
      "52": 1,
      "58": 1,
      "300": 1,
      "0.925": 1,
      "ridge_cv.alpha_": 1,
      "11.91946435680328": 1,
      "alpha_i": 1
    },
    "sklearn.linear_model._ridge.Ridge.__init__.normalize": {
      "False": 1175,
      "True": 47,
      "ridge_regressor.best_params_['normalize']": 1,
      "use_all_feats": 1,
      "trial.suggest_categorical('normalize', [True, False])": 1
    },
    "sklearn.linear_model._ridge.Ridge.fit.X": {
      "X_train": 220,
      "X": 81,
      "x_train": 45,
      "trn_data": 12,
      "train_X": 12,
      "train": 11,
      "X_train[:, i_cols_list]": 10,
      "x": 10,
      "X_train_scaled": 9,
      "x0": 9,
      "X_tr": 7,
      "X_train_1": 7,
      "X_train_2": 7,
      "Xtrain": 6,
      "np.array(train.loc[y_is_within_cut, cols_to_use].values)": 6,
      "x1": 6,
      "train_x": 5,
      "X_death": 5,
      "X_case": 5,
      "features": 4,
      "dtrain": 4,
      "RX1": 4,
      "train_features": 3,
      "X_train2": 3,
      "train_feature[tr]": 3,
      "train.loc[index1, ['fundamental_11']].values": 3,
      "train.loc[index2, ['technical_30', 'fundamental_11']].values": 3,
      "train.loc[index3, ['technical_20', 'fundamental_11']].values": 3,
      "train.loc[index4, ['technical_30', 'technical_20', 'fundamental_11']].values": 3,
      "trn_x": 3,
      "x_train_train": 2,
      "X2": 2,
      "np.log(data[['id']])": 2,
      "X_train_stacked": 2,
      "trnX": 2,
      "X_xTrain_CS": 2,
      "df.date.dt.dayofyear.values.reshape(-1, 1)": 2,
      "Xs_train_a": 2,
      "X_train_transformed": 2,
      "X_train_ohe": 2,
      "X_train_rfe": 2,
      "time": 2,
      "new_c": 2,
      "z[tr_idx]": 2,
      "train.loc[y_is_within_cut, cols_lr0]": 2,
      "train.loc[y_is_within_cut, cols_lr1]": 2,
      "train.loc[y_is_within_cut, cols_lr2]": 2,
      "df_train": 2,
      "X_train_kneigboards[X_train_kneigboards.columns.tolist()[:-11]]": 2,
      "train_cv": 1,
      "train_df.loc[:, features[:-1]]": 1,
      "train_df.loc[train_df['log_budget'] <= np.log(10000), features[:-1]]": 1,
      "train_df.loc[train_df['log_budget'] > np.log(10000), features[:-1]]": 1,
      "X_train_tfv": 1,
      "X_train[rfe_selected]": 1,
      "np.array(train[names[2:-1]])": 1,
      "train[features]": 1,
      "train[['store_nbr', 'item_nbr']]": 1,
      "X_train_pca": 1,
      "X_scaled": 1,
      "train[l].values": 1,
      "fold_tr_fea": 1,
      "df_data[x_cols][mask_base].values": 1,
      "last": 1,
      "trs[tr_idx, :]": 1,
      "X_val": 1,
      "train_x_norm": 1,
      "encoder.predict(xtrain)": 1,
      "train_cp": 1,
      "X_toxic": 1,
      "X_attack": 1,
      "X_aggression": 1,
      "x_tr": 1,
      "training_data": 1,
      "X_train_onehot": 1,
      "fit_data": 1,
      "part_b_meta": 1,
      "meta_df[meta_features]": 1,
      "weeks.reshape([-1, 1])": 1,
      "X_trn": 1,
      "Xs_train": 1,
      "xtsc": 1,
      "sxtr": 1,
      "train_x[tr_idx]": 1,
      "train_meta": 1,
      "numerical_input_A": 1,
      "oof_df.iloc[train_idx]": 1,
      "X_train_4": 1,
      "X_linear": 1,
      "data_transformed": 1,
      "train_work": 1,
      "x_train_imputer": 1,
      "train_set['X']": 1,
      "train_trans": 1,
      "X[mask_tr]": 1,
      "X[:train_num][mask_tr]": 1,
      "data_tr_x": 1,
      "X_description_train_wb": 1,
      "X_name_train_wb": 1,
      "sparse_merge_train_1": 1,
      "X_train_vectorized": 1,
      "data_X": 1,
      "all_x": 1,
      "np.array(train.loc[y_is_within_cut, col].values).reshape(-1, 1)": 1,
      "X[tr_idx]": 1,
      "vectorized_data_train": 1,
      "train.iloc[:, :-1]": 1,
      "xtrain[features]": 1,
      "oobpredictions": 1,
      "train_feat": 1,
      "train_data": 1,
      "train.ix[train_idxs]": 1,
      "X_2": 1,
      "X_c": 1,
      "x_": 1,
      "X_train.loc[train_indices]": 1,
      "X_trainS": 1,
      "X[train_idx]": 1,
      "descr_train": 1,
      "title_train": 1,
      "onehot_train": 1,
      "blend_train": 1,
      "train_inputs[numeric_cols + encoded_cols]": 1,
      "X_train_rb": 1,
      "X_train_rb[variables]": 1,
      "xTrain": 1,
      "np.array(oof_models).T": 1,
      "train[not_resp].values": 1,
      "self.common_vecs": 1,
      "train_transform": 1,
      "transformed_text": 1,
      "X_train_final": 1,
      "prediction.reshape(-1, 1)": 1,
      "train_processed": 1,
      "tr_x": 1,
      "lr_X_train": 1,
      "train.ix[indextrain]": 1,
      "data": 1,
      "train[feature_columns]": 1,
      "valid_df": 1,
      "pred_train": 1,
      "train_features[best_feature]": 1,
      "valid_data_pred_df['pred'].to_numpy().reshape(-1, 1)": 1,
      "X_train_sc": 1,
      "df_X": 1,
      "train_X_reduced": 1,
      "train.loc[y_is_within_cut, feat].values": 1,
      "X_train_pf": 1,
      "tr[features].values": 1,
      "pca_training_set": 1,
      "X_ss": 1,
      "X_train[store_id]": 1,
      "pca.transform(train_X)": 1
    },
    "sklearn.linear_model._ridge.Ridge.fit.y": {
      "y_train": 276,
      "y": 79,
      "Y_train": 36,
      "train_y": 15,
      "Y": 11,
      "trn_y": 10,
      "y0": 9,
      "target": 8,
      "y_tr": 8,
      "ytrain": 7,
      "y_train_1": 7,
      "y_train_2": 7,
      "train_target": 6,
      "train.loc[y_is_within_cut, 'y']": 6,
      "y_train_scaled": 5,
      "y_death": 5,
      "y_case": 5,
      "y1": 5,
      "dtrain_y": 4,
      "Ry1": 4,
      "train.loc[y_is_within_cut, target_var]": 4,
      "score[tr]": 3,
      "target_1": 3,
      "target_2": 3,
      "target_3": 3,
      "y[tr_idx]": 3,
      "train_Y": 3,
      "train.loc[index1].y": 3,
      "train.loc[index2].y": 3,
      "train.loc[index3].y": 3,
      "train.loc[index4].y": 3,
      "y_train[class_name]": 2,
      "y_train_train": 2,
      "ytr": 2,
      "y[mask_tr]": 2,
      "trnY": 2,
      "y1_xTrain_CS": 2,
      "train.loc[y_is_within_cut, target]": 2,
      "signedExp(y1 + 1.0)": 2,
      "train_targets": 2,
      "nr_adopted": 2,
      "train_label": 1,
      "train_df.loc[:, 'log_revenue']": 1,
      "train_df.loc[train_df['log_budget'] <= np.log(10000), 'log_revenue']": 1,
      "train_df.loc[train_df['log_budget'] > np.log(10000), 'log_revenue']": 1,
      "np.array(train['y'])": 1,
      "train[label]": 1,
      "train['unit_sales']": 1,
      "train.y": 1,
      "fold_tr_label": 1,
      "df_data[target][mask_base].values": 1,
      "train[target].iloc[tr_idx]": 1,
      "y_val": 1,
      "train_target_cp": 1,
      "prices_train": 1,
      "y_train_log": 1,
      "y_toxic": 1,
      "y_attack": 1,
      "y_aggression": 1,
      "data['ConfirmedCases']": 1,
      "data['Fatalities']": 1,
      "confirmed_cases": 1,
      "fatalities": 1,
      "training_prices": 1,
      "fit_labels": 1,
      "part_b_y": 1,
      "np.hstack([part_b_y, validation_y])": 1,
      "fvc": 1,
      "y_trn": 1,
      "trn_labels": 1,
      "train_y[tr_idx]": 1,
      "part_A_y": 1,
      "train_df['target'].to_numpy()[train_idx]": 1,
      "y_linear": 1,
      "train_data['ConfirmedCases']": 1,
      "y_train_array": 1,
      "train_set['y']": 1,
      "train_2_Num['Hazard']": 1,
      "y_label_log": 1,
      "data_tr_y.values.ravel()": 1,
      "all_y": 1,
      "labels": 1,
      "train.iloc[:, -1]": 1,
      "df.competitors": 1,
      "df.teams": 1,
      "y_train.values.ravel()": 1,
      "target_carbon_monoxide": 1,
      "target_nitrogen_oxides": 1,
      "target_benzene": 1,
      "y[col]": 1,
      "ytrain[target]": 1,
      "targets": 1,
      "ooby['y1']": 1,
      "xtrain['target']": 1,
      "log_train_prices": 1,
      "y.ix[train_idxs]": 1,
      "train.loc[y_is_within_cut, TARGET]": 1,
      "y_c": 1,
      "y_train_cos": 1,
      "y_": 1,
      "np.log(y.loc[train_indices])": 1,
      "y_cdf": 1,
      "Y[train_idx]": 1,
      "y_valid": 1,
      "train_lower_50['y'].values": 1,
      "y_tr_pred[i]": 1,
      "y_test_pred[i].reshape(-1, 1)": 1,
      "yTrain": 1,
      "train[resp].values": 1,
      "df_train['target']": 1,
      "real_Y": 1,
      "train['revenue']": 1,
      "tr_y": 1,
      "y.ix[indextrain]": 1,
      "train['FVC']": 1,
      "Y_valid": 1,
      "valid_labels": 1,
      "valid_data_pred_df['target'].to_numpy().reshape(-1, 1)": 1,
      "df_Y": 1,
      "train.loc[y_is_within_cut, 'y'].values": 1,
      "target_cc": 1,
      "target_ft": 1,
      "tr.target": 1,
      "frac_training_label": 1,
      "y_train[store_id]": 1
    },
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.tokenizer": {
      "None": 2920,
      "tokenize": 109,
      "tokenizer.tokenize": 30,
      "lambda x: x": 17,
      "lambda x: x.split()": 14,
      "normalize": 12,
      "tokenizer": 11,
      "char_analyzer": 10,
      "lambda x: regex.findall('[^\\\\p{P}\\\\W]+', x)": 10,
      "word_tokenize": 9,
      "lambda x: x.split(' ')": 8,
      "lambda x: re.findall('[^\\\\p{P}\\\\W]+', x)": 7,
      "LemmaTokenizer()": 4,
      "lemmatizer": 4,
      "spacy_tokenizer": 4,
      "lambda x: [i.strip() for i in x.split(',')]": 4,
      "TweetTokenizer().tokenize": 3,
      "tokenize_and_stem": 3,
      "lambda x: x.split(',')": 3,
      "sklearn_tokenizer": 2,
      "identity_tokenizer": 2,
      "Tokenizer": 2,
      "tokenize_text": 2,
      "nltk.word_tokenize": 2,
      "TreebankWordTokenizer().tokenize": 2,
      "lambda doc: doc": 1,
      "tt.tokenize": 1,
      "tokenizeANDstem": 1,
      "tokenize_only": 1,
      "token_r": 1,
      "wp_tokenizer.tokenize": 1,
      "token": 1,
      "tweet_preprocessor": 1,
      "lemmatize": 1,
      "text_cleaning": 1,
      "getwords": 1,
      "as_it_is": 1,
      "n_gram": 1,
      "tweet_tokenizer.tokenize": 1,
      "my_tokenizer": 1,
      "self.preproc": 1,
      "tokenizer_porter": 1,
      "get_lemmas": 1,
      "IngredientTokenizer()": 1,
      "lambda x: str(x).split()": 1,
      "custom_tokenizer": 1
    },
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.stop_words": {
      "None": 1737,
      "'english'": 1221,
      "ML_STOP_WORDS": 53,
      "stop_words": 46,
      "russian_stop": 33,
      "stop": 18,
      "stopWords": 14,
      "STOP_WORDS": 13,
      "stopwords.words('english')": 13,
      "stopwords.words('russian')": 9,
      "[stopwords, string.punctuation]": 8,
      "set(stopwords.words('english'))": 7,
      "stopwords": 6,
      "nltk.corpus.stopwords.words('english')": 6,
      "Stopwords": 4,
      "sw": 4,
      "stopwords_list": 2,
      "{'english'}": 2,
      "lists": 2,
      "stopWords_ru": 2,
      "stops": 2,
      "st_wd": 1,
      "self.stop_words": 1,
      "new_stopwords": 1,
      "stopwords.words('english') + list(string.punctuation)": 1,
      "stopwords_list_rev": 1,
      "('english', 'russian')": 1,
      "stop_words_lst": 1,
      "master_stopwords_list": 1,
      "merknamen": 1,
      "ENGLISH_STOP_WORDS": 1,
      "stop_words1": 1,
      "stopset": 1,
      "self.tfidf_stop_words": 1
    },
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.norm": {
      "'l2'": 3194,
      "'l1'": 12,
      "None": 8,
      "'max'": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.alpha": {
      "0.0001": 325,
      "alpha[best_alpha]": 254,
      "i": 151,
      "0.001": 39,
      "1e-05": 20,
      "1": 16,
      "best_alpha": 15,
      "0.1": 4,
      "0.01": 4,
      "alpha": 2,
      "0.0002": 2,
      "100": 1,
      "10**(-4)": 1,
      "0.004": 1,
      "0.0005": 1,
      "1e-06": 1,
      "l_alpha": 1,
      "10**(-6)": 1,
      "10**(-5)": 1,
      "sgdc_optimal_alpha": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.epsilon": {
      "DEFAULT_EPSILON": 825,
      "0.1": 16
    },
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.eta0": {
      "0.0": 829,
      "1": 7,
      "0.002": 2,
      "100": 2,
      "2": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.l1_ratio": {
      "0.15": 835,
      "0.1": 1,
      "0.3": 1,
      "0.7": 1,
      "0.25": 1,
      "1": 1,
      "0.0": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.learning_rate": {
      "'optimal'": 838,
      "'adaptive'": 2,
      "'constant'": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.loss": {
      "'log'": 468,
      "'hinge'": 335,
      "'modified_huber'": 30,
      "'squared_hinge'": 2,
      "l": 2,
      "'squared_loss'": 1,
      "loss_sgd": 1,
      "res.x[4]": 1,
      "loss": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.penalty": {
      "'l2'": 795,
      "'l1'": 21,
      "'elasticnet'": 15,
      "penalty": 3,
      "p": 2,
      "'L2'": 2,
      "best_penalty": 1,
      "penalty_sgd": 1,
      "res.x[3]": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.class_weight": {
      "None": 612,
      "'balanced'": 223,
      "{1: 0.7, 0: 0.3}": 2,
      "{0: 1, 1: 11}": 2,
      "{1: 20, 0: 1}": 1,
      "{0: 1, 1: 9}": 1
    },
    "sklearn.pipeline.Pipeline.__init__.steps": {
      "[('s1', cust_txt_col(key='search_term')), ('tfidf1', tfidf), ('tsvd1', tsvd)]": 99,
      "[('s2', cust_txt_col(key='product_title')), ('tfidf2', tfidf), ('tsvd2', tsvd)]": 99,
      "[('s4', cust_txt_col(key='brand')), ('tfidf4', tfidf), ('tsvd4', tsvd)]": 96,
      "[('s3', cust_txt_col(key='product_description')), ('tfidf3', tfidf), ('tsvd3', tsvd)]": 90,
      "[('union', FeatureUnion(transformer_list=[('cst', cust_regression_vals()), ('txt1', pipeline.Pipeline([('s1', cust_txt_col(key='search_term')), ('tfidf1', tfidf), ('tsvd1', tsvd)])), ('txt2', pipeline.Pipeline([('s2', cust_txt_col(key='product_title')), ('tfidf2', tfidf), ('tsvd2', tsvd)])), ('txt3', pipeline.Pipeline([('s3', cust_txt_col(key='product_description')), ('tfidf3', tfidf), ('tsvd3', tsvd)])), ('txt4', pipeline.Pipeline([('s4', cust_txt_col(key='brand')), ('tfidf4', tfidf), ('tsvd4', tsvd)]))], transformer_weights={'cst': 1.0, 'txt1': 0.5, 'txt2': 0.25, 'txt3': 0.0, 'txt4': 0.5}, n_jobs=-1)), ('rfr', rfr)]": 69,
      "[('poly', PolynomialFeatures(degree=2)), ('linear', LinearRegression(fit_intercept=False))]": 64,
      "[('vt', VarianceThreshold(threshold=2)), ('scaler', StandardScaler())]": 50,
      "[('rfr', rfr)]": 45,
      "[('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore'))]": 39,
      "steps": 36,
      "[('svd', svd), ('scl', scl), ('svm', svm_model)]": 32,
      "[('preprocessor', preprocessor), ('model', model)]": 27,
      "pipeline_transformers + [('model', model)]": 25,
      "[('UnionInput', FeatureUnion([('svd', svd), ('dense_features', FeatureInserter())])), ('scl', scl), ('svm', svm_model)]": 23,
      "[('v', TfidfVectorizer(min_df=5, max_df=500, max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 2), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words='english')), ('svd', TruncatedSVD(n_components=200, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=10.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None))]": 22,
      "[('imputer', Imputer(strategy='median')), ('scaler', MinMaxScaler())]": 20,
      "[('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())]": 19,
      "[('imputer', SimpleImputer(strategy='constant', fill_value='missing')), ('onehot', OneHotEncoder(handle_unknown='ignore'))]": 18,
      "estimators": 17,
      "[('svd', svd), ('scl', scl), ('lr', lr_model)]": 16,
      "[('nb', nb_model)]": 15,
      "[('union', FeatureUnion(transformer_list=[('cst', cust_img_features())], transformer_weights={'cst': 1.0}, n_jobs=-1)), ('ovr', ovr)]": 15,
      "[('encode', CountEncoder(cols=[0, 2])), ('classify', classifier)]": 14,
      "[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())]": 14,
      "[('scaler', StandardScaler())]": 14,
      "[('std_scaler', StandardScaler())]": 13,
      "[('scaler2', StandardScaler()), ('RandomForestRegressor: ', RandomForestRegressor())]": 12,
      "[('Classifier', c)]": 12,
      "[('vect', CountVectorizer()), ('clf', LogisticRegression(C=1, random_state=0, max_iter=2000))]": 11,
      "[('imp_mean', CustomImputer(strategy='median', cols=median_columns)), ('imp_mode', CustomImputer(strategy='most_frequent', cols=mode_columns)), ('imp_zero', CustomImputer(strategy='constant', fill_value=0, cols=zero_columns)), ('imp_none', CustomImputer(strategy='constant', fill_value='None', cols=none_columns)), ('imp_typ', CustomImputer(strategy='constant', fill_value='Typ', cols=typ_columns)), ('skewed', TransformerSkewed(cols=skewed_feats)), ('transformer', TransformerColumnsData()), ('encoder', encoder)]": 11,
      "[('imputer', SimpleImputer(strategy='median')), ('std_scaler', StandardScaler())]": 10,
      "(('standard_scaler', StandardScaler()), ('lin_reg', LinearRegression()))": 10,
      "[('v', TfidfVectorizer(max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 6), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words=ML_STOP_WORDS)), ('svd', TruncatedSVD(n_components=100)), ('scl', StandardScaler()), ('svm', SVC(C=10))]": 9,
      "[('v', TfidfVectorizer(max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 6), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words=ML_STOP_WORDS)), ('sdg', SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15, learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1, penalty='l2', power_t=0.5, random_state=None, shuffle=True, verbose=0, warm_start=False))]": 8,
      "[('imputer', SimpleImputer(strategy='most_frequent')), ('encoder', OneHotEncoder(handle_unknown='ignore'))]": 7,
      "[('model', ensemble.GradientBoostingRegressor())]": 7,
      "[('vect', CountVectorizer()), ('clf', MultinomialNB())]": 7,
      "[('pca', pca), ('logistic', logistic)]": 7,
      "[('v', TfidfVectorizer(max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 6), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words=ML_STOP_WORDS)), ('dtc', DecisionTreeClassifier(random_state=0))]": 7,
      "[('model', xgb.XGBRegressor())]": 7,
      "[('select', ItemSelector('brand_name', start_time=start_time)), ('transform', CountVectorizer(token_pattern='.+', min_df=2, lowercase=False))]": 7,
      "[('select', ItemSelector('gencat_cond', start_time=start_time)), ('transform', CountVectorizer(token_pattern='.+', min_df=2, lowercase=False))]": 7,
      "[('select', ItemSelector('subcat_1_cond', start_time=start_time)), ('transform', CountVectorizer(token_pattern='.+', min_df=2, lowercase=False))]": 7,
      "[('select', ItemSelector('subcat_2_cond', start_time=start_time)), ('transform', CountVectorizer(token_pattern='.+', min_df=2, lowercase=False))]": 7,
      "[('select', ItemSelector('has_brand', start_time=start_time)), ('ohe', OneHotEncoder())]": 7,
      "[('select', ItemSelector('shipping', start_time=start_time)), ('ohe', OneHotEncoder())]": 7,
      "[('select', ItemSelector('item_condition_id', start_time=start_time)), ('ohe', OneHotEncoder())]": 7,
      "[('select', ItemSelector('item_description', start_time=start_time)), ('hash', HashingVectorizer(ngram_range=(1, 3), n_features=2**27, dtype=np.float32, norm='l2', lowercase=False, stop_words=stopwords)), ('drop_cols', DropColumnsByDf(min_df=2))]": 7,
      "[('scaler', MinMaxScaler())]": 7,
      "[('imputer_median', SimpleImputer(strategy='median')), ('polynomial_pipe', PolynomialFeatures(degree=3))]": 7,
      "[('scaler', StandardScaler()), ('knn', KNeighborsClassifier(n_neighbors=k_Optimal, weights=weights))]": 7,
      "[('std', StandardScaler()), ('clf1', clf1)]": 7,
      "[('std', StandardScaler()), ('clf3', clf3)]": 7,
      "[('std', StandardScaler()), ('clf4', clf4)]": 7,
      "[('std', StandardScaler()), ('clf5', clf5)]": 7,
      "[('vect', vect), ('clf', clf)]": 6,
      "[('vect', CountVectorizer()), ('clf', LogisticRegression(random_state=0, max_iter=2000))]": 6,
      "[('vect', CountVectorizer()), ('clf', LinearSVC(max_iter=3000))]": 6,
      "[('tfidf', TfidfVectorizer(sublinear_tf=True, min_df=5, max_df=0.25, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')), ('clf', LogisticRegression(random_state=0, max_iter=2000))]": 6,
      "[('tfidf', TfidfVectorizer(sublinear_tf=True, min_df=5, max_df=0.25, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')), ('clf', LinearSVC(max_iter=2000))]": 6,
      "[('tfidf', TfidfVectorizer(sublinear_tf=True, min_df=5, max_df=0.25, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')), ('clf', MultinomialNB())]": 6,
      "[('low_variance_filter', VarianceThreshold()), ('model', model)]": 6,
      "[('union', FeatureUnion(transformer_list=[('cst', cust_regression_vals()), ('txt1', pipeline.Pipeline([('s1', cust_txt_col(key='search_term')), ('tfidf1', tfidf), ('tsvd1', tsvd)])), ('txt2', pipeline.Pipeline([('s2', cust_txt_col(key='product_title')), ('tfidf2', tfidf), ('tsvd2', tsvd)])), ('txt3', pipeline.Pipeline([('s3', cust_txt_col(key='product_description')), ('tfidf3', tfidf), ('tsvd3', tsvd)])), ('txt4', pipeline.Pipeline([('s4', cust_txt_col(key='brand')), ('tfidf4', tfidf), ('tsvd4', tsvd)]))], transformer_weights={'cst': 1.0, 'txt1': 0.5, 'txt2': 0.25, 'txt3': 0.0, 'txt4': 0.5})), ('rfr', rfr)]": 6,
      "[('std_scalar', StandardScaler())]": 6,
      "[('min_max_scaler', MinMaxScaler()), ('knn', KNeighborsClassifier())]": 6,
      "pipeline_6_transformers + [('model', model)]": 6,
      "[('v', TfidfVectorizer(max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 6), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words=ML_STOP_WORDS)), ('kn', KNeighborsClassifier(n_neighbors=3))]": 6,
      "[('feature_processing', pipeline.FeatureUnion(transformer_list=transformer_list)), ('model_fitting', regressor)]": 6,
      "[('onehot', OneHotEncoder(handle_unknown='ignore'))]": 6,
      "[('tfidf', TfidfVectorizer(lowercase=False, max_df=0.3, min_df=1, binary=False, use_idf=True, smooth_idf=False, ngram_range=(1, 2), stop_words='english', token_pattern='(?u)\\\\b\\\\w+\\\\b', max_features=limit_word))]": 6,
      "[('tfidf2', TfidfVectorizer(sublinear_tf=True, strip_accents='unicode', analyzer='char', stop_words='english', ngram_range=(1, 4), max_features=limit_char))]": 6,
      "[('one_hot_encoder', OneHotEncoder())]": 6,
      "[('label_encoder', OrdinalEncoder())]": 6,
      "[('standard_scaler', StandardScaler())]": 6,
      "[('tfidf', tfidf), ('tsvd', tsvd), ('scl', scl), ('class', classifier)]": 6,
      "[('scaler', StandardScaler()), ('estimator', SVR())]": 6,
      "[('Scaler', StandardScaler()), ('LR', LogisticRegression())]": 5,
      "[('Scaler', StandardScaler()), ('LDA', LinearDiscriminantAnalysis())]": 5,
      "[('tfidf', TfidfVectorizer()), ('clf', LinearSVC())]": 5,
      "[('union', FeatureUnion(transformer_list=[('cst', cust_regression_vals()), ('txt1', pipeline.Pipeline([('s1', cust_txt_col(key='search_term')), ('tfidf1', tfidf), ('tsvd1', tsvd)])), ('txt2', pipeline.Pipeline([('s2', cust_txt_col(key='product_title')), ('tfidf2', tfidf), ('tsvd2', tsvd)])), ('txt4', pipeline.Pipeline([('s4', cust_txt_col(key='brand')), ('tfidf4', tfidf), ('tsvd4', tsvd)]))], transformer_weights={'cst': 1.0, 'txt1': 0.5, 'txt2': 0.25, 'txt4': 0.5}, n_jobs=-1)), ('rfr', rfr)]": 5,
      "[('Scaler', StandardScaler()), (name, model)]": 5,
      "[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', svm.LinearSVC())]": 5,
      "[('v', TfidfVectorizer(min_df=5, max_df=500, max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 3), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words='english')), ('svd', TruncatedSVD(n_components=200, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=10.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None))]": 5,
      "[('classifier', RandomForestClassifier())]": 5,
      "[('imputer', Imputer(strategy='median')), ('pca', PCA())]": 5,
      "[('preprocessor', SimpleImputer()), ('model', DecisionTreeRegressor(random_state=0))]": 5,
      "[('bow', CountVectorizer(analyzer=text_process)), ('tfidf', TfidfTransformer()), ('classifier', MultinomialNB())]": 5,
      "[('select', ItemSelector('name', start_time=start_time)), ('transform', HashingVectorizer(ngram_range=(1, 2), n_features=2**27, norm='l2', lowercase=False, stop_words=stopwords)), ('drop_cols', DropColumnsByDf(min_df=2))]": 5,
      "[('select', ItemSelector('category_name', start_time=start_time)), ('transform', HashingVectorizer(ngram_range=(1, 1), token_pattern='.+', tokenizer=split_cat, n_features=2**27, norm='l2', lowercase=False)), ('drop_cols', DropColumnsByDf(min_df=2))]": 5,
      "(('lin_reg', LinearRegression()), )": 4,
      "[('imputer', SimpleImputer(missing_values=np.nan, strategy='mean')), ('scaler', StandardScaler()), ('clf', clf)]": 4,
      "[('transformer', transformer), ('lr', LinearRegression())]": 4,
      "[('union', FeatureUnion(transformer_list=[('numeric_features', Pipeline([('selector', get_numeric_data)])), ('text_features', Pipeline([('selector', get_text_data), ('vectorizer', TfidfVectorizer(stop_words='english', strip_accents='unicode', token_pattern='\\\\w{2,}', analyzer='word', ngram_range=(1, 1), min_df=5))]))])), ('clf', OneVsRestClassifier(LogisticRegression()))]": 4,
      "[('selector', get_numeric_data)]": 4,
      "[('selector', get_text_data), ('vectorizer', TfidfVectorizer(stop_words='english', strip_accents='unicode', token_pattern='\\\\w{2,}', analyzer='word', ngram_range=(1, 1), min_df=5))]": 4,
      "[('poly', PolynomialFeatures(degree=2, include_bias=False)), ('linear', LinearRegression())]": 4,
      "[('URL-transformer', FunctionTransformer(transform_url, validate=False)), ('URL-OHE', OneHotEncoder(drop_invariant=True))]": 4,
      "[('tfidf', TfidfVectorizer())]": 4,
      "[('impute', SimpleImputer(strategy='constant', fill_value=0)), ('scale', PowerTransformer(method='yeo-johnson'))]": 4,
      "[('impute', SimpleImputer(strategy='constant', fill_value='')), ('encode', OneHotEncoder(handle_unknown='ignore'))]": 4,
      "[('classify', classifier)]": 4,
      "[('imputer', SimpleImputer(strategy='median')), ('scaler', MinMaxScaler())]": 4,
      "[('extract_features', features), ('classify', RandomForestClassifier(n_estimators=200, n_jobs=1, min_samples_split=2, random_state=1))]": 4,
      "[('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))]": 4,
      "[('imputer', SimpleImputer()), ('scaler', StandardScaler())]": 4,
      "[('count_vectorizer', count_vectorizer), ('model', model)]": 4,
      "[('union', FeatureUnion(transformer_list=[('cst', cust_regression_vals()), ('txt1', pipeline.Pipeline([('s1', cust_txt_col(key='search_term')), ('tfidf1', tfidf), ('tsvd1', tsvd)])), ('txt2', pipeline.Pipeline([('s2', cust_txt_col(key='product_title')), ('tfidf2', tfidf), ('tsvd2', tsvd)])), ('txt3', pipeline.Pipeline([('s3', cust_txt_col(key='product_description')), ('tfidf3', tfidf), ('tsvd3', tsvd)])), ('txt4', pipeline.Pipeline([('s4', cust_txt_col(key='brand')), ('tfidf4', tfidf), ('tsvd4', tsvd)]))], transformer_weights={'cst': 1.0, 'txt1': 0.5, 'txt2': 0.28, 'txt3': 0.0, 'txt4': 0.6}, n_jobs=-1)), ('rfr', rfr)]": 4,
      "[('scaler2', StandardScaler()), ('RandomForestRegressor: ', model)]": 4,
      "preprocessing_steps": 4,
      "[('preprocessor', SimpleImputer()), ('gbm', GradientBoostingRegressor(n_estimators=300, learning_rate=0.01, alpha=0.9, random_state=0))]": 4,
      "[('anova', anova_filter), ('svc', clf)]": 4,
      "[('Feature Selection', selector), ('Classification', clf())]": 4,
      "[('imputer', imputer), ('scaler', scaler)]": 4,
      "[('preprocess', preprocess), ('lr', lr)]": 4,
      "[('imputer', SimpleImputer(strategy='constant')), ('onehot', OneHotEncoder(handle_unknown='ignore'))]": 4,
      "[('imputer', SimpleImputer(strategy='mean'))]": 4,
      "[('fs', tml.DtypeSel('numeric')), ('imp', tml.DfImputer('mean'))]": 4,
      "[('fs', tml.DtypeSel('category')), ('imp', tml.DfImputer('most_frequent')), ('dummify', tml.Dummify(drop_first=True))]": 4,
      "[('imputer', imp_mean), ('scaler', scaler), ('logistic', logistic)]": 4,
      "[('imputer', imp_mean), ('scaler', scaler), ('xgb', clf)]": 4,
      "[('imputer', SimpleImputer(strategy='median'))]": 4,
      "[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('model', LogisticRegression())]": 4,
      "[('bow', CountVectorizer(analyzer=clean_text)), ('tfidf', TfidfTransformer()), ('classifier', LogisticRegression(random_state=101))]": 4,
      "[('preprocessor', Preprocessor(**preproc_params)), ('nan_imputer', NanImputer(('fillna', -1)))]": 4,
      "[('scaling', StandardScaler()), ('pca', PCA(n_components=40, whiten=True))]": 4,
      "[('selector', get_text_data), ('vectorizer', CountVectorizer(analyzer='word', ngram_range=[1, 3], stop_words=nltk.corpus.stopwords.words('english')))]": 4,
      "[('scaler', StandardScaler()), ('knn', KNeighborsClassifier(n_neighbors=n_neighborss, weights=weights))]": 4,
      "[('discrete_imputer', SimpleImputer(strategy='constant', fill_value='NaN')), ('encoder', OneHotEncoder(handle_unknown='ignore'))]": 4,
      "[('select_data', DataFrameSelector(X_train.columns)), ('Std_Scaler', StandardScaler())]": 3,
      "[('select_data', DataFrameSelector(X_val.columns)), ('Std_Scaler', StandardScaler())]": 3,
      "[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=0.001, random_state=42, max_iter=5, tol=None))]": 3,
      "[('imputer', SimpleImputer(strategy='mean')), ('scaler', PowerTransformer())]": 3,
      "[('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='error'))]": 3,
      "[('Scaler', StandardScaler()), ('CART', DecisionTreeClassifier())]": 3,
      "[('Scaler', StandardScaler()), ('NB', GaussianNB())]": 3,
      "[('features', features), ('clf', clf)]": 3,
      "[('selector', FunctionTransformer(lambda x: x['ciphertext'], validate=False)), ('vectorizer', vectorizer), ('tfidf', TfidfTransformer()), ('estimator', estimator)]": 3,
      "[('vectorizer', vectorizer), ('classifier', classifier)]": 3,
      "[('imputer', SimpleImputer(strategy='median')), ('robustScaler', RobustScaler())]": 3,
      "[('vectorizer', vectorizer), ('svd', svd)]": 3,
      "[('union', FeatureUnion(transformer_list=[('cst', cust_regression_vals()), ('txt1', pipeline.Pipeline([('s1', cust_txt_col(key='search_term')), ('tfidf1', tfidf), ('tsvd1', tsvd)])), ('txt2', pipeline.Pipeline([('s2', cust_txt_col(key='product_title')), ('tfidf2', tfidf), ('tsvd2', tsvd)])), ('txt3', pipeline.Pipeline([('s3', cust_txt_col(key='product_description')), ('tfidf3', tfidf), ('tsvd3', tsvd)])), ('txt4', pipeline.Pipeline([('s4', cust_txt_col(key='brand')), ('tfidf4', tfidf), ('tsvd4', tsvd)]))], transformer_weights={'cst': 1.0, 'txt1': 0.5, 'txt2': 0.25, 'txt3': 0.0, 'txt4': 0.5}, n_jobs=-1))]": 3,
      "[('clf', clf)]": 3,
      "[('vect', CountVectorizer()), ('clf', SVC(C=0.1, kernel='linear'))]": 3,
      "[('scaler', StandardScaler()), ('clf', LogisticRegression(solver='lbfgs', verbose=1, n_jobs=1, random_state=42))]": 3,
      "[('preprocessor', preprocessor)]": 3,
      "[('count_vector', CountVectorizer()), ('clf', LogisticRegression())]": 3,
      "[('BOW', CountVectorizer(analyzer=own_analyser)), ('tfidf', TfidfTransformer()), ('classifier', MultinomialNB())]": 3,
      "[('preprocessor', preprocessor), ('regressor', RandomForestRegressor())]": 3,
      "[('feature_selector', FeatureSelector()), ('linreg', Ridge())]": 3,
      "[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())]": 3,
      "[('feats', feats)]": 3,
      "Input": 3,
      "[('CVec', CountVectorizer(stop_words='english')), ('Tfidf', TfidfTransformer())]": 3,
      "[('pca', pca), ('linear regression', lin_reg)]": 3,
      "[('separator', DTypeSelector(key='datetime'))]": 3,
      "[('separator', DTypeSelector(key='object')), ('encoder', FeatureHasher(input_type='string'))]": 3,
      "[('separator', DTypeSelector(key='number'))]": 3,
      "[('vect', vectorizer)]": 3,
      "[('union', FeatureUnion(transformer_list=[('cst', cust_regression_vals()), ('txt1', pipeline.Pipeline([('s1', cust_txt_col(key='search_term')), ('tfidf1', tfidf), ('tsvd1', tsvd)])), ('txt2', pipeline.Pipeline([('s2', cust_txt_col(key='product_title')), ('tfidf2', tfidf), ('tsvd2', tsvd)]))], transformer_weights={'cst': 1.0, 'txt1': 1.0, 'txt2': 1.0})), ('rfr', rfr)]": 3,
      "[('union', FeatureUnion(transformer_list=[('cst', cust_regression_vals()), ('txt1', pipeline.Pipeline([('s1', cust_txt_col(key='xdescription')), ('tfidf1', tfidf), ('tsvd1', tsvd)])), ('txt2', pipeline.Pipeline([('s2', cust_txt_col(key='ydescription')), ('tfidf2', tfidf), ('tsvd2', tsvd)]))], transformer_weights={'cst': 1.0, 'txt1': 1.0, 'txt2': 1.0}, n_jobs=-1))]": 3,
      "[('s1', cust_txt_col(key='xdescription')), ('tfidf1', tfidf), ('tsvd1', tsvd)]": 3,
      "[('s2', cust_txt_col(key='ydescription')), ('tfidf2', tfidf), ('tsvd2', tsvd)]": 3,
      "[('union', ColumnTransformer([('scale', RobustScaler(), loading_features)])), ('dummy_regressor', regressor)]": 3,
      "pipeline_6_transformers + [('model', rf_clf)]": 3,
      "pipeline_6_transformers + [('model', xgb_clf)]": 3,
      "pipeline_6_transformers + [('model', lgbm_clf)]": 3,
      "[('imputer', SimpleImputer(strategy='mean')), ('scaler', MinMaxScaler())]": 3,
      "[('imputer', SimpleImputer(strategy='mean')), ('scaler', StandardScaler())]": 3,
      "[('preprocessor', SimpleImputer()), ('model', model)]": 3,
      "steps_xg": 3,
      "[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('model', LinearSVC())]": 3,
      "[('encoder', encoder), ('rfe', rfe)]": 3,
      "[('pca', pca), ('svm', svm0)]": 3,
      "[('classifier', KNeighborsClassifier())]": 3,
      "[('selecting', preprocessing.FunctionTransformer(lambda data: data[:, numeric_data_indices])), ('scaling', preprocessing.StandardScaler(with_mean=0))]": 3,
      "[('selecting', preprocessing.FunctionTransformer(lambda data: data[:, categorical_data_indices])), ('hot_encoding', preprocessing.OneHotEncoder(handle_unknown='ignore'))]": 3,
      "[('scaler', StandardScaler()), ('model', estimator)]": 3,
      "[('selector', ItemSelector(['item_condition_id'])), ('transformer', FillNa(9999)), ('ohe', OneHotEncoder(handle_unknown='ignore')), ('log', LoggingTransformer('End of item_condition_id'))]": 3,
      "[('selector', ItemSelector('category_name')), ('transformer', FillNa('Unknown')), ('vectorizer', CountVectorizer(token_pattern='[^/]+', min_df=3, binary=True, analyzer='word', ngram_range=(1, 5), strip_accents='ascii')), ('log', LoggingTransformer('End of category_name'))]": 3,
      "[('selector', ItemSelector('category_name')), ('transformer', FillNa('Unknown')), ('vectorizer', CountVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b', min_df=3, binary=True, analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of category_name 2'))]": 3,
      "[('selector', ItemSelector('brand_name')), ('transformer', FillNa('Unknown')), ('vectorizer', CountVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b', min_df=3, binary=True, analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of brand 2'))]": 3,
      "[('imputer', SimpleImputer(strategy='most_frequent')), ('ordinal', OrdinalEncoder(handle_unknown='ignore'))]": 3,
      "[('inpute', imp_1), ('pca', pca), ('vts', VarianceThreshold(threshold=0.8 * (1 - 0.8))), ('lr', LogisticRegression(solver='lbfgs'))]": 3,
      "[('tfidf', tfidf), ('svc', svc)]": 3,
      "[('scale', scaler), ('lr', lr)]": 3,
      "[('cv', CountVectorizer()), ('mnb', MultinomialNB())]": 3,
      "[('Scaler', scaler), ('NB', GaussianNB())]": 3,
      "[('imputer', SimpleImputer(strategy='most_frequent')), ('cat_enc', OneHotEncoder(handle_unknown='ignore'))]": 3,
      "[('union', FeatureUnion(transformer_list=[('cst', cust_regression_vals()), ('txt1', pipeline.Pipeline([('s1', cust_txt_col(key='search_term')), ('tfidf1', tfidf), ('tsvd1', tsvd)])), ('txt2', pipeline.Pipeline([('s2', cust_txt_col(key='product_title')), ('tfidf2', tfidf), ('tsvd2', tsvd)])), ('txt3', pipeline.Pipeline([('s3', cust_txt_col(key='product_description')), ('tfidf3', tfidf), ('tsvd3', tsvd)])), ('txt4', pipeline.Pipeline([('s4', cust_txt_col(key='brand')), ('tfidf4', tfidf), ('tsvd4', tsvd)]))], transformer_weights={'cst': 1.0, 'txt1': 0.5, 'txt2': 0.25, 'txt3': 0.01, 'txt4': 0.5})), ('rfr', rfr)]": 3,
      "[('Text-TF-IDF', TfidfVectorizer(ngram_range=(1, 3))), ('Text-SVD', TruncatedSVD(n_components=100))]": 3,
      "[('preprocessor', Preprocessor(**preproc_params)), ('nan_imputer', NanImputer(('ohe', -1)))]": 3,
      "[('poly', PolynomialFeatures(degree=2, include_bias=False)), ('Ridge', Ridge())]": 3,
      "[('scaler', StandardScaler()), ('estimator', KNeighborsClassifier(n_jobs=4))]": 3,
      "[('text', CountVectorizer()), ('mnb', MultinomialNB())]": 3,
      "[('selector', get_text_data), ('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=[1, 3], stop_words=nltk.corpus.stopwords.words('english')))]": 3,
      "[('selector', get_text_data), ('vectorizer', TfidfVectorizer(analyzer='char', ngram_range=[3, 5], stop_words=nltk.corpus.stopwords.words('english')))]": 3,
      "[('vt', VarianceThreshold(threshold=1.5)), ('scaler', RobustScaler(quantile_range=(35, 65)))]": 3,
      "[('constant', DropConstantFeatures(tol=0.998)), ('duplicated', DropDuplicateFeatures())]": 3,
      "[('vec', vec), ('clf', clf)]": 3,
      "[('do_nothing', PassthroughTransformer())]": 3,
      "[('discrete_imputer', SimpleImputer(strategy='constant', fill_value='NaN')), ('encoder', OrdinalEncoder(handle_unknown='ignore'))]": 3,
      "[('encode', CountEncoder(cols=[0, 2])), ('classify', MultiOutputClassifier(XGBClassifier(tree_method='gpu_hist')))]": 2,
      "[('Cat_Encoder', cat_encoder), ('pca', pca), ('lgbm', lgb_reg)]": 2,
      "[('catboost', cat)]": 2,
      "[('USE_question_title', UniversalSentenceEncoderEncoder('question_title', use_model)), ('USE_question_body', UniversalSentenceEncoderEncoder('question_body', use_model)), ('USE_answer', UniversalSentenceEncoderEncoder('answer', use_model)), ('distance_use_question_title-question_body', DistanceEngineerer('question_title_use', 'question_body_use')), ('distance_use_question_title-answer', DistanceEngineerer('question_title_use', 'answer_use')), ('distance_use_question_body-answer', DistanceEngineerer('question_body_use', 'answer_use')), ('onehost_encode_and_drop_columns', Pipeline(steps=[('extrace_sld', ColumnTransformer({'host': SecondLevelDomainExtracter()})), ('onehot_encode_host', WrappedOneHotEncoder('host')), ('onehot_encode_category', WrappedOneHotEncoder('category'))]).fit(features_train)), ('drop_columns', ColumnDropper(['qa_id', 'category', 'host', 'question_title', 'question_body', 'question_user_name', 'question_user_page', 'answer', 'answer_user_name', 'answer_user_page', 'url']))]": 2,
      "[('extrace_sld', ColumnTransformer({'host': SecondLevelDomainExtracter()})), ('onehot_encode_host', WrappedOneHotEncoder('host')), ('onehot_encode_category', WrappedOneHotEncoder('category'))]": 2,
      "[('preprocess', use_preprocess), ('estimate', DenseECV())]": 2,
      "[('preprocess', use_preprocess), ('estimate', ElasticNetECV())]": 2,
      "[('scaler', StandardScaler()), ('clf', LogisticRegression(random_state=42))]": 2,
      "[('clf', DecisionTreeClassifier(splitter='random', class_weight='balanced'))]": 2,
      "[('dataprep', data_transform(num_cols, cat_cols, is_cat=0)), ('imputer', SimpleImputer(strategy='mean')), ('scaler', PowerTransformer())]": 2,
      "[('dataprep', data_transform(num_cols, cat_cols, is_cat=1)), ('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='error'))]": 2,
      "[('transformer', transformer), ('stack', stack)]": 2,
      "[('vectorizer', vectorizer), ('classifier', c)]": 2,
      "[('vectorizer', vectorizer), ('classifier', LogisticRegression())]": 2,
      "[('scaler', StandardScaler()), ('qda', QuadraticDiscriminantAnalysis(reg_param=0.111))]": 2,
      "[('scaler', scaler1), ('reg', reg1)]": 2,
      "[('scaler', scaler2), ('reg', reg2)]": 2,
      "[('scaler', scaler3), ('reg', reg3)]": 2,
      "[('scaler', scaler4), ('reg', reg4)]": 2,
      "[('scaler', scaler5), ('reg', reg5)]": 2,
      "[('scaler', scaler6), ('reg', reg6)]": 2,
      "[('scale', std_scale), ('clf', log_reg)]": 2,
      "(('standard_scaler', StandardScaler()), ('poly_features', PolynomialFeatures(degree=2)), ('ridge', Ridge()))": 2,
      "[('sc', sc), ('logistic', logistic)]": 2,
      "[('cleantext', ColumnExtractor(cols='clean_text')), ('vect', vect)]": 2,
      "[('Counters-transformer', FunctionTransformer(counts, validate=False)), ('Counters-std', StandardScaler())]": 2,
      "[('tfidf', TfidfVectorizer()), ('clf', LogisticRegression())]": 2,
      "[('imputer', SimpleImputer(strategy='median')), ('robust_scaler', RobustScaler())]": 2,
      "[('vectorizer_23', vectorizer_23), ('svd_9c', svd_9c)]": 2,
      "[('tfidf', tfidf), ('lr', lr)]": 2,
      "[('selecting', preprocessing.FunctionTransformer(lambda data: data.iloc[:, get_ind(numeric_col)])), ('scaling', preprocessing.StandardScaler(with_mean=0.0))]": 2,
      "[('ss', StandardScaler()), ('ridge', RidgeCV())]": 2,
      "[('scaler', StandardScaler()), ('knn', KNeighborsClassifier(n_jobs=-1))]": 2,
      "[['ord_encoder', ct], ['rfe', RFE(estimator=xgb.XGBRegressor(tree_method='gpu_hist', random_state=11, n_jobs=-1), n_features_to_select=20)], ['regressor', xgb.XGBRegressor(tree_method='gpu_hist', random_state=11, n_jobs=-1, max_depth=4, n_estimators=200, reg_lambda=100)]]": 2,
      "[('bow', CountVectorizer()), ('tfid', TfidfTransformer()), ('model', xgb.XGBClassifier(use_label_encoder=False, eval_metric='auc'))]": 2,
      "[('bow', CountVectorizer()), ('tfid', TfidfTransformer()), ('model', MultinomialNB())]": 2,
      "[('preprocessor', preprocessor), ('model', RandomForestClassifier(random_state=0, n_estimators=500, max_depth=5))]": 2,
      "[('tfidf', TfidfVectorizer(ngram_range=(1, 10), max_features=10000, lowercase=True, use_idf=True, smooth_idf=True, sublinear_tf=False, tokenizer=TweetTokenizer().tokenize, stop_words='english')), ('clf', LogisticRegression(random_state=17, C=1.8))]": 2,
      "[('union', FeatureUnion(transformer_list=[('cst', cust_regression_vals()), ('txt1', pipeline.Pipeline([('s1', cust_txt_col(key='search_term')), ('tfidf1', tfidf), ('tsvd1', tsvd)])), ('txt2', pipeline.Pipeline([('s2', cust_txt_col(key='product_title')), ('tfidf2', tfidf), ('tsvd2', tsvd)])), ('txt3', pipeline.Pipeline([('s3', cust_txt_col(key='product_description')), ('tfidf3', tfidf), ('tsvd3', tsvd)])), ('txt4', pipeline.Pipeline([('s4', cust_txt_col(key='brand')), ('tfidf4', tfidf), ('tsvd4', tsvd)]))], transformer_weights={'cst': 1.0, 'txt1': 0.5, 'txt2': 0.25, 'txt3': 0.0, 'txt4': 0.5})), ('xgb_model', xgb_model)]": 2,
      "[('preprocessor', preprocessor), ('model', rf_classifier)]": 2,
      "[('preprocessor', SimpleImputer()), ('model', RandomForestRegressor(n_estimators, random_state=0))]": 2,
      "[('selector', TextSelector(key='processed')), ('tfidf', TfidfVectorizer(stop_words='english'))]": 2,
      "[('selector', NumberSelector(key='length')), ('standard', StandardScaler())]": 2,
      "[('selector', NumberSelector(key='words')), ('standard', StandardScaler())]": 2,
      "[('selector', NumberSelector(key='words_not_stopword')), ('standard', StandardScaler())]": 2,
      "[('selector', NumberSelector(key='avg_word_length')), ('standard', StandardScaler())]": 2,
      "[('selector', NumberSelector(key='commas')), ('standard', StandardScaler())]": 2,
      "[('features', feats), ('classifier', RandomForestClassifier(random_state=42))]": 2,
      "[('classifier', DecisionTreeClassifier())]": 2,
      "[('preprocess', full_processor), ('model', lasso)]": 2,
      "[('vectorizer', tfvec), ('lr', lr)]": 2,
      "[('select', ItemSelector('name')), ('transform', HashingVectorizer(ngram_range=(1, 2), n_features=2**27, norm='l2', lowercase=False, stop_words=stopwords)), ('drop_cols', DropColumnsByDf(min_df=2))]": 2,
      "[('select', ItemSelector('category_name')), ('transform', HashingVectorizer(ngram_range=(1, 1), token_pattern='.+', tokenizer=split_cat, n_features=2**27, norm='l2', lowercase=False)), ('drop_cols', DropColumnsByDf(min_df=2))]": 2,
      "[('select', ItemSelector('brand_name')), ('transform', CountVectorizer(token_pattern='.+', min_df=2, lowercase=False))]": 2,
      "[('select', ItemSelector('gencat_cond')), ('transform', CountVectorizer(token_pattern='.+', min_df=2, lowercase=False))]": 2,
      "[('select', ItemSelector('subcat_1_cond')), ('transform', CountVectorizer(token_pattern='.+', min_df=2, lowercase=False))]": 2,
      "[('select', ItemSelector('subcat_2_cond')), ('transform', CountVectorizer(token_pattern='.+', min_df=2, lowercase=False))]": 2,
      "[('select', ItemSelector('has_brand')), ('ohe', OneHotEncoder())]": 2,
      "[('select', ItemSelector('shipping')), ('ohe', OneHotEncoder())]": 2,
      "[('select', ItemSelector('item_condition_id')), ('ohe', OneHotEncoder())]": 2,
      "[('select', ItemSelector('item_description')), ('hash', HashingVectorizer(ngram_range=(1, 3), n_features=2**27, dtype=np.float32, norm='l2', lowercase=False, stop_words=stopwords)), ('drop_cols', DropColumnsByDf(min_df=2))]": 2,
      "[('impute', IterativeImputer(max_iter=4)), ('model', model)]": 2,
      "[('model', model)]": 2,
      "[('cv', TfidfVectorizer(ngram_range=(1, 2), use_idf=1, smooth_idf=1, sublinear_tf=1)), ('dim_reduce', TruncatedSVD(n_components=5, random_state=10, algorithm='arpack'))]": 2,
      "[('imputer', SimpleImputer(strategy='most_frequent', fill_value='missing')), ('onehot', OneHotEncoder(handle_unknown='ignore'))]": 2,
      "[('union', ColumnTransformer([('scale', RobustScaler(), loading_features)]))]": 2,
      "pipeline_1_transformers + [('model', model)]": 2,
      "pipeline_2_transformers + [('model', model)]": 2,
      "pipeline_3_transformers + [('model', model)]": 2,
      "pipeline_4_transformers + [('model', model)]": 2,
      "pipeline_5_transformers + [('model', model)]": 2,
      "pipeline_transformers": 2,
      "[('mapper', mapper(population, weight, day)), ('linear_regression', LinearRegression())]": 2,
      "[('scale', map_scale()), ('regressor', RandomForestRegressor(n_estimators=10, verbose=1, n_jobs=-1))]": 2,
      "[('tfidf', TfidfVectorizer(ngram_range=(1, 3), analyzer='word', binary=False)), ('svd', TruncatedSVD(n_components=150))]": 2,
      "[('tfidf', TfidfVectorizer(ngram_range=(1, 3), analyzer='word', binary=False)), ('svd', TruncatedSVD(n_components=150)), ('norm', Normalizer())]": 2,
      "[('tfidf', TfidfVectorizer(stop_words='english', ngram_range=(1, 2))), ('lr_model', OneVsRestClassifier(LogisticRegression(C=10), n_jobs=-1))]": 2,
      "[('SFromModel', SelectKBest(score_func=f_regression)), ('Model', LinearRegression())]": 2,
      "[('imputer', SimpleImputer(strategy='mean')), ('std_scaler', StandardScaler())]": 2,
      "[('imputer', SimpleImputer(strategy='constant', fill_value='NA')), ('onehot', OneHotEncoder(handle_unknown='ignore'))]": 2,
      "[('select', ItemSelector('name', start_time=start_time)), ('transform', HashingVectorizer(ngram_range=(1, 2), n_features=2**28, norm='l2', lowercase=False, stop_words=stopwords)), ('drop_cols', DropColumnsByDf(min_df=2))]": 2,
      "[('select', ItemSelector('category_name', start_time=start_time)), ('transform', HashingVectorizer(ngram_range=(1, 1), token_pattern='.+', tokenizer=split_cat, n_features=2**28, norm='l2', lowercase=False)), ('drop_cols', DropColumnsByDf(min_df=2))]": 2,
      "steps_exclimp": 2,
      "steps_inclimp": 2,
      "[('v', TfidfVectorizer(min_df=5, max_df=500, max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 2), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words='english')), ('svd', TruncatedSVD(n_components=560, algorithm='randomized', n_iter=6, random_state=None, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=11.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None))]": 2,
      "[('preprocessor', preprocessor), ('classifier', RandomForestRegressor())]": 2,
      "[('scaler', StandardScaler()), ('preprocessor', SimpleImputer()), ('model', RandomForestRegressor(n_estimators=100, max_depth=2, random_state=0))]": 2,
      "_name_estimators([AddColumns(transform_=PCA(n_components=10)), AddColumns(transform_=FastICA(n_components=10, max_iter=500)), xgb_model])": 2,
      "[('vectorizer', tfvec), ('svd', svd)]": 2,
      "[('imp_mean', CustomImputer(strategy='median', cols=median_columns)), ('imp_mode', CustomImputer(strategy='most_frequent', cols=mode_columns)), ('imp_zero', CustomImputer(strategy='constant', fill_value=0, cols=zero_columns)), ('imp_none', CustomImputer(strategy='constant', fill_value='None', cols=none_columns)), ('imp_typ', CustomImputer(strategy='constant', fill_value='Typ', cols=typ_columns)), ('transformer', TransformerColumnsData()), ('encoder', encoder)]": 2,
      "[('ss', ss), ('fs', fs), ('model', model)]": 2,
      "[('preprocessor', SimpleImputer()), ('model', model0)]": 2,
      "[('preprocessor', SimpleImputer()), ('model', model1)]": 2,
      "[('Scaler', StandardScaler()), ('LR', LinearRegression())]": 2,
      "[('encoder', encoder), ('scaler', StandardScaler()), ('clf', RandomForestRegressor(n_jobs=-1))]": 2,
      "[('imputation', SimpleImputerCorrected(strategy='most_frequent')), ('scalling', StandardScaler())]": 2,
      "[('imputation', SimpleImputerCorrected(strategy='most_frequent')), ('encoding', OneHotEncoder(sparse=False))]": 2,
      "[('Scaler', std_sca), ('Estimator', model)]": 2,
      "[('svd', TruncatedSVD(n_components=200, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=10.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None))]": 2,
      "[('vec', vec), ('scale', MaxAbsScaler()), ('classifier', classifier)]": 2,
      "[('svd', svd), ('gbm', gbm)]": 2,
      "[('scl', scl), ('svm', svm_model)]": 2,
      "[('scaler', StandardScaler()), ('model', LogisticRegression())]": 2,
      "[('ohe', OneHotEncoder(categories=categories, dtype='int')), ('model', LogisticRegression(max_iter=150, C=C))]": 2,
      "[('ct_ohe', ct_ohe), ('scaler', StandardScaler()), ('model', LogisticRegression(max_iter=100, C=C))]": 2,
      "[('pca', pca), ('logreg', logreg)]": 2,
      "[('vt', VarianceThreshold(threshold=1.5)), ('scaler', StandardScaler())]": 2,
      "[('vt', VarianceThreshold(threshold=1.5))]": 2,
      "[('tfidf_vectorizer', feature_extraction.text.TfidfVectorizer(lowercase=True)), ('clf', LinearSVC(random_state=0))]": 2,
      "[('bow', CountVectorizer(analyzer=text_process)), ('tfidf', TfidfTransformer()), ('classifier', RandomForestClassifier())]": 2,
      "[('bow', CountVectorizer(analyzer=text_process)), ('tfidf', TfidfTransformer()), ('classifier', SVC())]": 2,
      "[('selector', ItemSelector('name')), ('transformer', FillNa('null')), ('lowalphanum', LowAlphaNum()), ('vectorizer', TfidfVectorizer(use_idf=False, min_df=3, analyzer='char', ngram_range=(2, 6), strip_accents='ascii')), ('log', LoggingTransformer('End of name char')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log2', LoggingTransformer('End of name char vt'))]": 2,
      "[('selector', ItemSelector(['item_condition_id'])), ('log', LoggingTransformer('End of item_condition_id_2'))]": 2,
      "[('selector', ItemSelector(['shipping'])), ('log', LoggingTransformer('End of shipping'))]": 2,
      "[('selector', ItemSelector('brand_name')), ('transformer', FillNa('Unknown')), ('vectorizer', CountVectorizer(token_pattern='.+', min_df=3, binary=True, analyzer='word', ngram_range=(1, 1), strip_accents='ascii')), ('log', LoggingTransformer('End of brand'))]": 2,
      "[('scaler', RobustScaler())]": 2,
      "[('Prepo', Pipe), ('Clf', RandomForestRegressor())]": 2,
      "[('scaler', StandardScaler()), ('logit', logit)]": 2,
      "[('Encoder', encoder), ('Estimator', lr_est)]": 2,
      "[('Scaler', StandardScaler()), ('Votings', VotingRegressor([('XGBoostR', XGBR_grid.best_estimator_), ('AdaBoostR', AdaBoostR_grid.best_estimator_)]))]": 2,
      "[('preprocessor', preprocessor), ('estimator', Ridge(random_state=RANDOM_STATE))]": 2,
      "[('fillna', SimpleImputer(missing_values=np.nan, strategy='mean')), ('scaler', StandardScaler())]": 2,
      "[('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False)), ('scaler', StandardScaler())]": 2,
      "[('pclass_enc', OrdinalEncoder(categories=[[1, 2, 3]])), ('scaler', StandardScaler())]": 2,
      "[('extract_features', ColumnExtractor(polynomial_features)), ('fillna', numeric_transformer), ('polynomial_features', PolynomialFeatures(degree=2, interaction_only=True))]": 2,
      "[('features', features), ('lr', LogisticRegression(max_iter=10000, n_jobs=-1, verbose=False, random_state=RANDOM_SEED))]": 2,
      "[('vectorizer', vectorizer), ('lreg', lreg)]": 2,
      "[('v', TfidfVectorizer(min_df=5, max_df=500, max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 3), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words='english')), ('svd', TruncatedSVD(n_components=300, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=10.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None))]": 2,
      "[('tfidf', tfidf), ('svd', svd)]": 2,
      "[('preprocessor', preprocessor), ('model', rf_clf)]": 2,
      "[('cv', CountVectorizer(analyzer='word', ngram_range=(1, 4), max_df=0.9)), ('clf', LogisticRegression(solver='saga', class_weight='balanced', C=0.45, max_iter=250, verbose=1, n_jobs=-1))]": 2,
      "[('scl', tml.DfScaler()), ('ridge', Ridge())]": 2,
      "[('scl', tml.DfScaler()), ('logit', LogisticRegression(solver='lbfgs', multi_class='auto'))]": 2,
      "[('count_vectorizer', count_vectorizer), ('logit', model)]": 2,
      "[('tfidf_vectorizer', tfidf_ngrams_converter), ('logit', model)]": 2,
      "[('poly', PolynomialFeatures(degree=3)), ('linear', LinearRegression(fit_intercept=False))]": 2,
      "[('scale', scaler), ('rfecv', rfecv)]": 2,
      "[('scale', scaler), ('gridsearch', lr_cv)]": 2,
      "[('preprocessing', preprocessing_step), ('model', model)]": 2,
      "[('classifier', ExtraTreesClassifier(n_estimators=500, random_state=0, criterion='entropy'))]": 2,
      "[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', LogisticRegression())]": 2,
      "[('preprocessing', preprocessing), ('scaler', StandardScaler()), ('pca', PCA(n_components=6))]": 2,
      "[('impute', SimpleImputer(strategy='most_frequent')), ('encode', OneHotEncoder(handle_unknown='ignore'))]": 2,
      "[('cv', CountVectorizer()), ('tfidf', TfidfTransformer()), ('tfidf_logit', ClassifierWrapper(LogisticRegression()))]": 2,
      "[('pos', PosTagMatrix(tokenizer=nltk.word_tokenize)), ('pos_logit', ClassifierWrapper(LogisticRegression()))]": 2,
      "[('preprocessor', preprocessor), ('classifier', classifier)]": 2,
      "[('poly', PolynomialFeatures(degree=i)), ('linear', LinearRegression())]": 2,
      "[('tfidf', TfidfVectorizer(strip_accents='unicode', analyzer='char', preprocessor=stripString)), ('feat', SelectPercentile(chi2)), ('model', LogisticRegression())]": 2,
      "[('preprocessor', preprocessor), ('model', i)]": 2,
      "[('imputation', imputation), ('scaler', scaler), ('log_fare', transformation), ('encoding', ohe), ('poly', poly), ('model', model)]": 2,
      "[('age_imputation', ColumnTransformer([('impute_age', SimpleImputer(strategy='mean'), [0])], remainder='passthrough')), ('fare_imputation', ColumnTransformer([('impute_fare', SimpleImputer(strategy='median'), [1])], remainder='passthrough')), ('scaler', ColumnTransformer([('mmscaler', MinMaxScaler(), [0, 1, 2, 3, 4])], remainder='passthrough'))]": 2,
      "[('scaler', StandardScaler()), ('lr', LogisticRegression(C=10, solver='newton-cg', multi_class='multinomial', max_iter=500))]": 2,
      "[('scaler', StandardScaler()), ('svm', SVC(C=10, gamma=0.1, probability=True))]": 2,
      "[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('nb', SGDClassifier())]": 2,
      "[('pre_process', pre_process), ('catboost_clf', catboost_clf)]": 2,
      "[('imputer', SimpleImputer(strategy='median')), ('scaler', PowerTransformer())]": 2,
      "[('pre_process', pre_process), ('voting_reg', voting_reg)]": 2,
      "[('zeroes', SimpleImputer(strategy='constant', fill_value=0)), ('scl1', StandardScaler())]": 2,
      "[('zeroes', SimpleImputer(strategy='median')), ('scl2', StandardScaler())]": 2,
      "[('preprocessor', preprocessor), ('lr', model)]": 2,
      "[('tfidf', TfidfVectorizer()), ('classifier', DecisionTreeClassifier(random_state=100, class_weight={0: 1, 1: pos_weights}))]": 2,
      "[('vect', word_char_vectorizer), ('clf', classifier)]": 2,
      "[('imputer', SimpleImputer(strategy='constant')), ('scale', StandardScaler())]": 2,
      "[('imputer', SimpleImputer(strategy='constant')), ('onehot', OneHotEncoder(dtype=np.int8, handle_unknown='ignore'))]": 2,
      "[('onehot', OneHotEncoder(handle_unknown='ignore', dtype=np.int))]": 2,
      "[('pca', PCA()), ('xgb', XGBClassifier())]": 2,
      "[('cleaner', predictors()), ('vectorizer', bow_vector), ('classifier', classifier)]": 2,
      "[('linear', LinearRegression())]": 2,
      "[('cv', CountVectorizer(analyzer='word', ngram_range=(1, 2), max_df=0.9)), ('clf', LogisticRegression(solver='saga', class_weight='balanced', C=i, max_iter=10000, verbose=1, n_jobs=-1))]": 2,
      "[('WordCounter-transformer', FunctionTransformer(count_words, validate=False)), ('WordCounter-std', StandardScaler())]": 2,
      "[('scaler', StandardScaler()), ('lr', LinearRegression())]": 2,
      "[('count_vectorizer', count_vectorizer), ('model', model4)]": 2,
      "[('feature_processing', pipeline.FeatureUnion(transformer_list=transformer_list)), ('model_fitting', gbr)]": 2,
      "[('one_hot', OneHotEncoder())]": 2,
      "[('preprocessor', preprocessor), ('regression_model', model)]": 2,
      "[('Scaler', StandardScaler()), ('GBM', GradientBoostingRegressor())]": 2,
      "[('Scaler', StandardScaler()), ('RF', RandomForestRegressor())]": 2,
      "[('Scaler', StandardScaler()), ('ET', ExtraTreesRegressor())]": 2,
      "[('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1))]": 2,
      "[('preprocessor', preprocessor), ('model', RandomForestRegressor(n_estimators=100, random_state=0))]": 2,
      "[('uni', UnigramPredictions()), ('nlp', PartOfSpeechFeatures()), ('clean', DropStringColumns()), ('clf', LogisticRegression())]": 2,
      "[('Scaler', scaler), ('LDA', LinearDiscriminantAnalysis())]": 2,
      "[('Scaler', scaler), ('KNN', KNeighborsClassifier())]": 2,
      "[('Scaler', scaler), ('AB', AdaBoostClassifier())]": 2,
      "[('Scaler', scaler), ('GMB', GradientBoostingClassifier())]": 2,
      "[('preprocessor', preprocessor), ('classifier', LogisticRegression())]": 2,
      "[('featurize', mapper), ('clf', LGBMClassifier(random_state=seed_train))]": 2,
      "[('Scaler', StandardScaler()), ('Votings', VotingRegressor([('GBRegressor', GradientBoostingRegressor()), ('XGBR', XGBRegressor())]))]": 2,
      "[('imputer', SimpleImputer(strategy='mean')), ('standard', StandardScaler())]": 2,
      "[('Scaler', StandardScaler()), ('RC', RidgeClassifier())]": 2,
      "[('imputer', SimpleImputer(missing_values=np.nan, strategy='mean'))]": 2,
      "[('scaler', StandardScaler()), ('rf', RandomForestClassifier())]": 2,
      "[('imputer', SimpleImputer(fill_value=0, strategy='constant')), ('scaler', StandardScaler())]": 2,
      "[('imputer', SimpleImputer(fill_value=0, strategy='constant')), ('log_scale', FunctionTransformer(np.log1p)), ('scaler', StandardScaler())]": 2,
      "[('preprocess', feature_pipe), ('clf', OrdinalRegressor(VotingRegressor, estimators=[('xgb', xgb.XGBRegressor(**xgb_params)), ('mlp', KerasRegressor_v2(build_model, **mlp_params))], weights=(0.7, 0.3)))]": 2,
      "[('tfidf', TfidfVectorizer()), ('rgr', m)]": 2,
      "[('columntransformer', ColumnTransformer([('countvectorizer', vect, 'text')], remainder='drop')), ('multinomialnb', nb)]": 2,
      "[('encoder', DummiesEncoding(dummy_na=True))]": 2,
      "[('contiouous_imputer', SimpleImputer(strategy='median')), ('scaler', PowerTransformer())]": 2,
      "[('contiouous_imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())]": 2,
      "[('missing_ind', SimpleImputer(strategy='constant')), ('cat-onehot', OneHotEncoder(handle_unknown='ignore'))]": 2,
      "[('tfid', TfidfTransformer())]": 2,
      "[('vectorizer', cvec), ('mnb', mnb)]": 2,
      "[('scaler', scaler), ('xgb', clf)]": 2,
      "[(model, model_dict[model])]": 2,
      "[('Imputr', simpImp), ('Scalr', sdScaler)]": 2,
      "[('tfidf', TfidfVectorizer(sublinear_tf=True)), ('svc', LinearSVC(loss='hinge'))]": 1,
      "[('Cat_Encoder', cat_encoder), ('Quantile transformer', qt), ('Scaling', rs), ('Elastic Net', en)]": 1,
      "[('Cat_Encoder', cat_encoder), ('Quantile transformer', qt), ('Scaling', rs)]": 1,
      "[('poly_features', poly), ('linear reg', en)]": 1,
      "[('scaler', StandardScaler()), ('forest', RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=6))]": 1,
      "[('tokenize', QATokenizer(albert_tokenizer)), ('estimate', AlbertFineTuningECV(albert_model))]": 1,
      "[('xgb', xgb_model)]": 1,
      "[('imputer', SimpleImputer(strategy='most_frequent')), ('scaler', MinMaxScaler())]": 1,
      "[('imputer', SimpleImputer(strategy='most_frequent')), ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))]": 1,
      "[('imputer', SimpleImputer(strategy='most_frequent')), ('scaler', StandardScaler())]": 1,
      "[('imputer', SimpleImputer(strategy='most_frequent')), ('ohe', OneHotEncoder(handle_unknown='ignore'))]": 1,
      "[('preprocess', pre_processor), ('model', my_model)]": 1,
      "[('countV', CountVectorizer()), ('tf', TfidfTransformer()), ('lg', LogisticRegression())]": 1,
      "[('minmaxScaler', MinMaxScaler())]": 1,
      "[('StanderScaler', StandardScaler())]": 1,
      "[('initial_preprocessor', InitialPreprocessing()), ('quant_features_generator', AddingQuantFeatures()), ('data_imputer', MissingValuesImputer()), ('asset_encoder', AssetcodeEncoder()), ('lgb', LGBClassifierCV(cv=5, perform_random_search=False, use_train_test_split=False, use_full_data=True, use_kfold_split=False))]": 1,
      "[('na_imputer', MissingValuesImputer(impute_zero_columns=['v18q1', 'v2a1', 'rez_esc'])), ('cat_transformer', CategoricalVariableTransformer()), ('unnecessary_columns_remover_transformer', UnnecessaryColumnsRemoverTransformer()), ('feature_engineering_transformer', FeatureEngineeringTransformer()), ('lgb', LGBClassifierCV(lgb_params=lgb_params, fit_params=lgb_fit_params, cv=5, perform_random_search=False, perform_bayes_search=True, use_train_test_split=True, use_kfold_split=False))]": 1,
      "[('pca', pca), ('linear', lr_pca)]": 1,
      "[('pca', pca), ('linear', lr_ridge)]": 1,
      "[('extract_features', features), ('classify', RandomForestClassifier(n_estimators=50, n_jobs=-1, min_samples_split=2, max_features=None, random_state=1))]": 1,
      "[('Scaler', StandardScaler()), ('KNN', KNeighborsClassifier())]": 1,
      "[('Scaler', StandardScaler()), ('SVM', SVC())]": 1,
      "(('standard_scaler', StandardScaler()), ('linear_reg', LinearRegression()))": 1,
      "[('vectorizer', SkipGramVectorizer(ngram_range=(1, 3), k=1, stop_words=stop_words, tokenizer=tokenizer)), ('clf', LinearRegression())]": 1,
      "[('Text-TF-IDF', TfidfVectorizer(ngram_range=(1, 3))), ('Text-SVD', TruncatedSVD(n_components=300))]": 1,
      "[('imputer', Imputer(strategy='median')), ('scaler', StandardScaler())]": 1,
      "[('preprocessing', preprocessor), ('clf', clf)]": 1,
      "[('Preprocessing', preprocessor), ('estimate', clf)]": 1,
      "[('preprocessor', self.features_union), ('classifier', SVC)]": 1,
      "[('preprocessor', preprocessor), ('estimator', LinearSVR())]": 1,
      "[('svd', svd), ('scl', scl), ('model', lr_model)]": 1,
      "[('model', nb_model)]": 1,
      "[('svd', svd), ('scl', scl), ('model', xg_model)]": 1,
      "[('lr_clf', LogisticRegression(solver='lbfgs', max_iter=1000))]": 1,
      "[('NB_clf', ComplementNB())]": 1,
      "[('scalar1', StandardScaler()), ('pca1', PCA(n_components=2)), ('lr_classifier', LogisticRegression(random_state=0))]": 1,
      "[('scalar3', StandardScaler()), ('pca3', PCA(n_components=2)), ('rf_classifier', RandomForestClassifier())]": 1,
      "[('scalar3', StandardScaler()), ('lgbm_classifier', LGBMClassifier(n_jobs=-1))]": 1,
      "[('bow', CountVectorizer(analyzer=cleaner)), ('tfidf', TfidfTransformer()), ('classifier', MultinomialNB())]": 1,
      "[('imputer', SimpleImputer(strategy='median')), ('minmaxscaler', MinMaxScaler())]": 1,
      "[('imputer', MostFrequentImputer()), ('cat_encoder', OrdinalEncoder())]": 1,
      "[('vectorizer_22', vectorizer_22), ('svd_10c', svd_10c)]": 1,
      "[('separator', DTypeSelector(key='datetime')), ('filter', SelectPercentile(f_classif, percentile=14))]": 1,
      "[('separator', DTypeSelector(key='object')), ('encoder', FeatureHasher(input_type='string')), ('filter', VarianceThreshold(threshold=2))]": 1,
      "[('separator', DTypeSelector(key='number')), ('filter', SelectFpr(f_classif, alpha=0.02))]": 1,
      "[('feature_processing', pipeline.FeatureUnion(transformer_list=[('binary_variables_processing', preprocessing.FunctionTransformer(lambda data: data.iloc[:, get_ind(binary_col)])), ('numeric_variables_processing', pipeline.Pipeline(steps=[('selecting', preprocessing.FunctionTransformer(lambda data: data.iloc[:, get_ind(numeric_col)])), ('scaling', preprocessing.StandardScaler(with_mean=0.0))])), ('categorical_variables_processing', pipeline.Pipeline(steps=[('selecting', preprocessing.FunctionTransformer(lambda data: data.iloc[:, get_ind(categor_col)])), ('hot_encoding', preprocessing.OneHotEncoder(handle_unknown='ignore'))]))])), ('model_fitting', sgd_reg)]": 1,
      "[('selecting', preprocessing.FunctionTransformer(lambda data: data.iloc[:, get_ind(categor_col)])), ('hot_encoding', preprocessing.OneHotEncoder(handle_unknown='ignore'))]": 1,
      "[('feature_processing', pipeline.FeatureUnion(transformer_list=[('binary_variables_processing', preprocessing.FunctionTransformer(lambda data: data.iloc[:, get_ind(binary_col)])), ('numeric_variables_processing', pipeline.Pipeline(steps=[('selecting', preprocessing.FunctionTransformer(lambda data: data.iloc[:, get_ind(numeric_col)])), ('scaling', preprocessing.StandardScaler(with_mean=0.0))])), ('categorical_variables_processing', pipeline.Pipeline(steps=[('selecting', preprocessing.FunctionTransformer(lambda data: data.iloc[:, get_ind(categor_col)])), ('hot_encoding', preprocessing.OneHotEncoder(handle_unknown='ignore', sparse=False))]))])), ('model_fitting', rf_reg)]": 1,
      "[('selecting', preprocessing.FunctionTransformer(lambda data: data.iloc[:, get_ind(categor_col)])), ('hot_encoding', preprocessing.OneHotEncoder(handle_unknown='ignore', sparse=False))]": 1,
      "[('scaler', StandardScaler()), ('rfr', RandomForestRegressor())]": 1,
      "[('preprocessing', None), ('classifier', SVC())]": 1,
      "[('tfidf', TfidfVectorizer()), ('MNB', MultinomialNB())]": 1,
      "[('imputer', SimpleImputer(strategy='constant', fill_value='missing')), ('target_encoder', TargetEncoder()), ('scaler', StandardScaler())]": 1,
      "[('imputer', IterativeImputer(max_iter=10)), ('scaler', StandardScaler())]": 1,
      "[('vect', CountVectorizer(tokenizer=lambda x: x.split())), ('clf', LogisticRegression(max_iter=1000, random_state=RANDOM_STATE))]": 1,
      "[('chi', SelectKBest(chi2, k=400)), ('multilabel', OneVsRestClassifier(NbSvmClassifier()))]": 1,
      "[('store_item_lag_1d', Lag_Featurizer(index_col=['store', 'item'], time_col='date', value_col='sales', output_col='sales_1d', output_time_index=True, shift=1)), ('store_item_lag_2d', Lag_Featurizer(index_col=['store', 'item'], time_col='date', value_col='sales', output_col='sales_2d', output_time_index=True, shift=2)), ('store_item_lag_3d', Lag_Featurizer(index_col=['store', 'item'], time_col='date', value_col='sales', output_col='sales_3d', output_time_index=True, shift=3)), ('store_item_lag_4d', Lag_Featurizer(index_col=['store', 'item'], time_col='date', value_col='sales', output_col='sales_4d', output_time_index=True, shift=4)), ('store_item_lag_1w', Lag_Featurizer(index_col=['store', 'item'], time_col='date', value_col='sales', output_col='sales_1w', output_time_index=True, shift=7)), ('store_item_lag_2w', Lag_Featurizer(index_col=['store', 'item'], time_col='date', value_col='sales', output_col='sales_2w', output_time_index=True, shift=14)), ('store_item_lag_4w', Lag_Featurizer(index_col=['store', 'item'], time_col='date', value_col='sales', output_col='sales_4w', output_time_index=True, shift=28)), ('store_item_lag_3m', Lag_Featurizer(index_col=['store', 'item'], time_col='date', value_col='sales', output_col='sales_3m', output_time_index=True, shift=84)), ('store_item_lag_6m', Lag_Featurizer(index_col=['store', 'item'], time_col='date', value_col='sales', output_col='sales_6m', output_time_index=True, shift=168)), ('store_item_lag_1y', Lag_Featurizer(index_col=['store', 'item'], time_col='date', value_col='sales', output_col='sales_1y', output_time_index=True, shift=336)), ('store_lag_1d', Lag_Featurizer(index_col=['store'], time_col='date', value_col='sales', output_col='store_sales_1d', output_time_index=True, shift=1)), ('store_lag_2d', Lag_Featurizer(index_col=['store'], time_col='date', value_col='sales', output_col='store_sales_2d', output_time_index=True, shift=2)), ('store_lag_3d', Lag_Featurizer(index_col=['store'], time_col='date', value_col='sales', output_col='store_sales_3d', output_time_index=True, shift=3)), ('store_lag_4d', Lag_Featurizer(index_col=['store'], time_col='date', value_col='sales', output_col='store_sales_4d', output_time_index=True, shift=4)), ('store_lag_1w', Lag_Featurizer(index_col=['store'], time_col='date', value_col='sales', output_col='store_sales_1w', output_time_index=True, shift=7)), ('store_lag_2w', Lag_Featurizer(index_col=['store'], time_col='date', value_col='sales', output_col='store_sales_2w', output_time_index=True, shift=14)), ('store_lag_4w', Lag_Featurizer(index_col=['store'], time_col='date', value_col='sales', output_col='store_sales_4w', output_time_index=True, shift=28)), ('store_lag_3m', Lag_Featurizer(index_col=['store'], time_col='date', value_col='sales', output_col='store_sales_3m', output_time_index=True, shift=84)), ('store_lag_6m', Lag_Featurizer(index_col=['store'], time_col='date', value_col='sales', output_col='store_sales_6m', output_time_index=True, shift=168)), ('store_lag_1y', Lag_Featurizer(index_col=['store'], time_col='date', value_col='sales', output_col='store_sales_1y', output_time_index=True, shift=336)), ('item_lag_1d', Lag_Featurizer(index_col=['item'], time_col='date', value_col='sales', output_col='item_sales_1d', output_time_index=True, shift=1)), ('item_lag_2d', Lag_Featurizer(index_col=['item'], time_col='date', value_col='sales', output_col='item_sales_2d', output_time_index=True, shift=2)), ('item_lag_3d', Lag_Featurizer(index_col=['item'], time_col='date', value_col='sales', output_col='item_sales_3d', output_time_index=True, shift=3)), ('item_lag_4d', Lag_Featurizer(index_col=['item'], time_col='date', value_col='sales', output_col='item_sales_4d', output_time_index=True, shift=4)), ('item_lag_1w', Lag_Featurizer(index_col=['item'], time_col='date', value_col='sales', output_col='item_sales_1w', output_time_index=True, shift=7)), ('item_lag_2w', Lag_Featurizer(index_col=['item'], time_col='date', value_col='sales', output_col='item_sales_2w', output_time_index=True, shift=14)), ('item_lag_4w', Lag_Featurizer(index_col=['item'], time_col='date', value_col='sales', output_col='item_sales_4w', output_time_index=True, shift=28)), ('item_lag_3m', Lag_Featurizer(index_col=['item'], time_col='date', value_col='sales', output_col='item_sales_3m', output_time_index=True, shift=84)), ('item_lag_6m', Lag_Featurizer(index_col=['item'], time_col='date', value_col='sales', output_col='item_sales_6m', output_time_index=True, shift=168)), ('item_lag_1y', Lag_Featurizer(index_col=['item'], time_col='date', value_col='sales', output_col='item_sales_1y', output_time_index=True, shift=336))]": 1,
      "[('imputer', SimpleImputer(strategy='constant', fill_value=0)), ('onehot', preprocessing.OneHotEncoder(handle_unknown='ignore'))]": 1,
      "[('preprocessor', preprocessor), ('classifier', model)]": 1,
      "[('v', TfidfVectorizer(max_features=None, ngram_range=(1, 6), use_idf=False, smooth_idf=False, sublinear_tf=False, stop_words=ML_STOP_WORDS)), ('sdg', SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15, learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1, penalty='l2', power_t=0.5, random_state=None, shuffle=True, verbose=0, warm_start=False))]": 1,
      "[('v', TfidfVectorizer(max_features=None, ngram_range=(1, 6), use_idf=False, smooth_idf=False, sublinear_tf=False, stop_words=ML_STOP_WORDS)), ('dtc', DecisionTreeClassifier(random_state=0))]": 1,
      "[('v', TfidfVectorizer(max_features=None, ngram_range=(1, 6), use_idf=False, smooth_idf=False, sublinear_tf=False, stop_words=ML_STOP_WORDS)), ('kn', KNeighborsClassifier(n_neighbors=3))]": 1,
      "[('tfidf', TfidfVectorizer()), ('functiontransform', FunctionTransformer(lambda x: x.astype('float32'), validate=False))]": 1,
      "[('scl', StandardScaler()), ('clf', LogisticRegression(random_state=1))]": 1,
      "[('knn', KNeighborsClassifier(n_jobs=-1))]": 1,
      "[('scaler', scaler_lasso), ('reg', tt_lasso)]": 1,
      "[('scaler', scaler_svr), ('reg', tt_svr)]": 1,
      "[('vectorizer', sktext.CountVectorizer(lowercase=True, ngram_range=(1, 2))), ('tfidf', sktext.TfidfTransformer()), ('clf', KNeighborsClassifier(n_neighbors=1))]": 1,
      "[('pca', pca), ('model', rf_model)]": 1,
      "[('map', mapper), ('reg', Ridge(alpha=3.0))]": 1,
      "[('tfid', TfidfVectorizer(ngram_range=(1, 2))), ('model', xgb.XGBRegressor(learning_rate=0.1, max_depth=7, n_estimators=80, use_label_encoder=False, eval_metric='rmse'))]": 1,
      "[('bow', CountVectorizer()), ('tfid', TfidfTransformer()), ('model', xgb.XGBClassifier(learning_rate=0.1, max_depth=7, n_estimators=80, use_label_encoder=False, eval_metric='auc'))]": 1,
      "[('selector', df_cols_selector(['GrLivArea', 'OverallQual', 'GarageCars'])), ('scaler', StandardScaler()), ('lm', LinearRegression())]": 1,
      "[('selector', df_cols_selector(NUM_FEATURES)), ('imputer', KNNImputer(n_neighbors=20)), ('scaler', StandardScaler()), ('lm', LinearRegression())]": 1,
      "[('selector', df_cols_selector(num_features)), ('imputer', KNNImputer(n_neighbors=20)), ('scaler', StandardScaler())]": 1,
      "[('selector', df_cols_selector(text_features)), ('imputer', SimpleImputer(strategy='most_frequent')), ('oh', OneHotEncoder(handle_unknown='ignore'))]": 1,
      "[('feature_union', feature_union), ('estimator', estimator)]": 1,
      "[('selector', df_cols_selector(['text_len'])), ('scaler', StandardScaler())]": 1,
      "[('selector', df_cols_selector('text')), ('tfidf', TfidfVectorizer(tokenizer=wp_tokenizer.tokenize, ngram_range=(1, 2), lowercase=True))]": 1,
      "[('feature_union', feature_union), ('logreg', LogisticRegression(C=5, max_iter=300))]": 1,
      "[('scaler', MaxAbsScaler(copy=False)), ('clf', LogisticRegression(solver='lbfgs', multi_class='multinomial', verbose=2, n_jobs=-1))]": 1,
      "[('mutual_info_classif', SelectKBest(chi2, k=6500)), ('classifier', SVC(kernel='rbf', random_state=0, verbose=True, gamma=1, C=1, degree=6, shrinking=True, probability=False, cache_size=5))]": 1,
      "[('clf', SVC(kernel='rbf', gamma=0.01, C=100))]": 1,
      "[('imputer', IterativeImputer(random_state=42)), ('robust', RobustScaler(quantile_range=(10.0, 90.0))), ('minmax', MinMaxScaler())]": 1,
      "[('imputer', IterativeImputer(random_state=42))]": 1,
      "[('preprocessor', preprocessor), ('rfecv', RFECV(RandomForestRegressor(random_state=42), step=1, cv=2)), ('model', StackingRegressor(estimators=estimators, final_estimator=RandomForestRegressor(n_estimators=100, random_state=42)))]": 1,
      "[('selector', NumColumnSelector(key='num_words')), ('scaler', StandardScaler())]": 1,
      "[('selector', NumColumnSelector(key='non_stopwords')), ('scaler', StandardScaler())]": 1,
      "[('selector', NumColumnSelector(key='avg_word_len')), ('scaler', StandardScaler())]": 1,
      "[('selecor', TextColumnSelector(key='processed_text')), ('tfidf', TfidfVectorizer())]": 1,
      "[('selector', NumColumnSelector(key='length')), ('scaler', StandardScaler())]": 1,
      "[('selector', TextColumnSelector(key='keyword')), ('counter', CountVectorizer())]": 1,
      "[('feature_union', feature_union), ('clf', RandomForestClassifier())]": 1,
      "[('idf_vect', IDFVectorizer()), ('pre_processing', pre_process), ('svr', SVR(C=0.01, kernel='linear'))]": 1,
      "[('get_new_columns', FeatureGenerator())]": 1,
      "[('zerocount', ZeroCount()), ('robustscaler', RobustScaler()), ('mlpclassifier', MLPClassifier(alpha=0.1, learning_rate_init=0.01, random_state=2))]": 1,
      "[('poly', PolynomialFeatures(degree=7)), ('linear', LinearRegression(fit_intercept=False))]": 1,
      "[('poly', PolynomialFeatures(degree=5)), ('linear', LinearRegression(fit_intercept=False))]": 1,
      "[('imputer', SimpleImputer(strategy='constant', fill_value='missing')), ('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))]": 1,
      "[('imputer', SimpleImputer(strategy='median')), ('st_scaler', StandardScaler())]": 1,
      "[('preprocessor', preprocessor), ('xgb_model', XGBRegressor())]": 1,
      "[('xgb', xgb)]": 1,
      "[('bow', CountVectorizer(analyzer=text_preprocess)), ('Classifier', MultinomialNB())]": 1,
      "[('feature', ColumnTransformer([('k', TfidfVectorizer(stop_words=STOP_WORDS), 'keyword'), ('t', TfidfVectorizer(stop_words=STOP_WORDS), 'text')])), ('svc', GridSearchCV(LinearSVC(), param_grid={'C': np.logspace(0.01, 2, 10)}, cv=5))]": 1,
      "[('feature', ColumnTransformer([('k', TfidfVectorizer(stop_words=STOP_WORDS, tokenizer=lemmatizer), 'keyword'), ('t', TfidfVectorizer(stop_words=STOP_WORDS, tokenizer=lemmatizer), 'text')])), ('svc', GridSearchCV(LinearSVC(), param_grid={'C': np.logspace(0.01, 1, 10)}, cv=5))]": 1,
      "[('model', rf)]": 1,
      "[('model', rf_classifier)]": 1,
      "[('clf', OneVsRestClassifier(LinearSVC()))]": 1,
      "[('Standarise', StandardScaler()), ('MinMax', MinMaxScaler())]": 1,
      "[('vectorizer', CountVectorizer(max_df=0.5, ngram_range=(1, 2))), ('tfidf', TfidfTransformer()), ('clf', OneVsRestClassifier(LinearSVC()))]": 1,
      "[('scaler', args['scaler']()), ('selection', feature_selector['selection_algo'](**feature_selector['selection_params'])), ('clf', args['clf'](**args['clf_params']))]": 1,
      "[('preprocessor', preprocessor), ('regressor', KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=5, verbose=1))]": 1,
      "[('vect', TfidfVectorizer(strip_accents='unicode', stop_words='english', analyzer='word', ngram_range=(1, 2))), ('chi', SelectKBest(chi2, k=50000)), ('clf', SVC(max_iter=3000, probability=True))]": 1,
      "[('vect', TfidfVectorizer(strip_accents='unicode', stop_words='english', analyzer='word', ngram_range=(1, 2))), ('chi', SelectKBest(chi2, k=15000)), ('clf', LogisticRegression(max_iter=5000))]": 1,
      "[('imputer', SimpleImputer(strategy='constant', fill_value='NA')), ('encoder', OneHotEncoder(handle_unknown='ignore'))]": 1,
      "[('preprocessor', preprocessor), ('regressor', LinearRegression())]": 1,
      "[['scaler', MinMaxScaler(feature_range=(0, 1))], ['lr', LogisticRegression()]]": 1,
      "[['scaler', MinMaxScaler(feature_range=(0, 1))], ['xgb', xgb.XGBClassifier()]]": 1,
      "[('selector', DataFrameSelector(ord_cat_attribs)), ('ord_encoder', CategoricalEncoder(encoding='ordinal')), ('std_scaler', StandardScaler())]": 1,
      "[('selector', DataFrameSelector(onehot_cat_attribs)), ('onehot_encoder', CategoricalEncoder(encoding='onehot-dense'))]": 1,
      "[('selector', DataFrameSelector(num_attribs)), ('imputer', Imputer(strategy='mean')), ('std_scaler', StandardScaler())]": 1,
      "[('cv', CountVectorizer(analyzer=process_text)), ('tfidf', TfidfTransformer()), ('regressor', search)]": 1,
      "[('cv', CountVectorizer(analyzer=process_text)), ('tfidf', TfidfTransformer()), ('classifier', LogisticRegression())]": 1,
      "[('cv', CountVectorizer(analyzer=process_text)), ('tfidf', TfidfTransformer()), ('classifier', SVC())]": 1,
      "[('cv', CountVectorizer(analyzer=process_text)), ('tfidf', TfidfTransformer()), ('classifier', RandomForestClassifier(n_estimators=600))]": 1,
      "[('tfidf', TfidfVectorizer(tokenizer=Tokenizer, max_df=0.3, min_df=0.001, max_features=100000)), ('clf', XGBClassifier(objective='multi:softmax', n_estimators=500, num_class=20, learning_rate=0.075, colsample_bytree=0.7, subsample=0.8, eval_metric='merror'))]": 1,
      "[('scale', MinMaxScaler()), ('m', models[i])]": 1,
      "[('vect', CountVectorizer()), ('clf', SVC(C=10, gamma=0.01, kernel='rbf', max_iter=2000))]": 1,
      "(('scaler', StandardScaler()), ('svm_clf', SVC(kernel='poly', degree=3, coef0=1, C=5)))": 1,
      "[('vectorizer', TfidfVectorizer(max_features=10000, ngram_range=(1, 2))), ('classifier', OneVsRestClassifier(LogisticRegression(), n_jobs=4))]": 1,
      "[('text_to_word_count', TextToWordCounterTransformer()), ('word_count_to_vector', WordCounterToVectorTransformer(vocabulary_size=14000))]": 1,
      "[('scale', MinMaxScaler(feature_range=(1e-05, 1))), ('power_transform', PowerTransformer(method='box-cox'))]": 1,
      "[('feature_engineering', FeatureEngineering()), ('linreg', Ridge())]": 1,
      "[('vect', CountVectorizer(stop_words=st_wd, lowercase=1)), ('clf', MLPClassifier(hidden_layer_sizes=10, solver='sgd', max_iter=50, random_state=20, verbose=10, learning_rate_init=0.07))]": 1,
      "[('selector', DataFrameSelector(num_attributes)), ('imputer', Imputer(strategy='median'))]": 1,
      "[('selector', DataFrameSelector(cat_attributes)), ('binarizer', NewLabelBinarizer())]": 1,
      "[('tfidf', TfidfVectorizer()), ('lr', LogisticRegression())]": 1,
      "[('selector', ItemSelector(key='name')), ('tfidf', TfidfVectorizer(ngram_range=(1, 3), strip_accents='unicode', stop_words='english', min_df=20, max_df=0.9, max_features=MAX_FEATURES_NAME))]": 1,
      "[('item_description', Pipeline([('selector', ItemSelector(key='item_description')), ('tfidf', TfidfVectorizer(ngram_range=(1, 3), stop_words='english', min_df=20, max_df=0.9, max_features=MAX_FEATURES_DESC))]))]": 1,
      "[('selector', ItemSelector(key='item_description')), ('tfidf', TfidfVectorizer(ngram_range=(1, 3), stop_words='english', min_df=20, max_df=0.9, max_features=MAX_FEATURES_DESC))]": 1,
      "[('vestas_imputer', VestasImputer(vestas_columns)), ('vestas_scaler', VestasScaler(vestas_columns)), ('vestas_pca', VestasPCATransformer(vestas_columns))]": 1,
      "[('imputer', SimpleImputer(strategy='most_frequent')), ('oneHotEncoder', OneHotEncoder())]": 1,
      "[('date_transformer', DateTransformer()), ('feature_weekend_transformer', FeatureWeekendTransformer()), ('feature_peak_hour_transformer', FeaturePeakHourTransformer()), ('feature_is_2011_transformer', FeatureIs2011Transformer()), ('one_hot_encoder_transformer', OneHotEncoderTransformer(one_hot_cols)), ('label_remover', LabelRemover(['iso_datetime', 'datetime']))]": 1,
      "[('feature_creator', FeatureCreator()), ('scaler', StandardScaler())]": 1,
      "[('vect', CountVectorizer(tokenizer=tokenize, analyzer='word', ngram_range=(1, 2), min_df=min_df, lowercase=False)), ('tfidf', TfidfTransformer(sublinear_tf=True)), ('clf', MultinomialNB())]": 1,
      "[('vect', CountVectorizer(tokenizer=tokenize, analyzer='word', ngram_range=(1, 2), min_df=min_df, lowercase=False)), ('tfidf', TfidfTransformer(sublinear_tf=True)), ('clf-svm', LinearSVC(loss='hinge', penalty='l2', max_iter=5))]": 1,
      "[('vect', CountVectorizer(tokenizer=tokenize, analyzer='word', ngram_range=(1, 2), min_df=min_df, lowercase=False)), ('tfidf', TfidfTransformer(sublinear_tf=True)), ('clf-svm', SGDClassifier(loss='hinge', penalty='l2', alpha=0.001, max_iter=5))]": 1,
      "[('imputer', SimpleImputer(strategy='median')), ('minmax_scaler', MinMaxScaler())]": 1,
      "[('imputer', SimpleImputer(strategy='most_frequent')), ('cat_encoder', OneHotEncoder())]": 1,
      "[('cleaner', predictors()), ('vectorizer', vectorizer), ('classifier', classifier)]": 1,
      "[('tfidf', TfidfVectorizer(decode_error='ignore', stop_words='english', ngram_range=(1, 2))), ('clf', clf)]": 1,
      "[('tfidf', TfidfVectorizer(decode_error='ignore')), ('clf', MultinomialNB())]": 1,
      "[('tfidf', TfidfVectorizer(decode_error='ignore')), ('clf', SVC(kernel='linear', probability=True))]": 1,
      "[('tfidf', TfidfVectorizer(decode_error='ignore', stop_words='english')), ('clf', SVC(kernel='linear', probability=True))]": 1,
      "[('impute', SimpleImputer(strategy='mean')), ('scale', MinMaxScaler())]": 1,
      "[('impute', SimpleImputer(strategy='most_frequent')), ('one-hot', OneHotEncoder(handle_unknown='ignore', sparse=False))]": 1,
      "[('cv', CountVectorizer(analyzer='word', ngram_range=(1, 4), max_df=0.9)), ('clf', LogisticRegression(solver='saga', class_weight='balanced', C=0.45, max_iter=250, verbose=1))]": 1,
      "[('vectorizer', tfvec), ('rf', rf)]": 1,
      "[('scale', ss)]": 1,
      "[('onehot', oh)]": 1,
      "[('ct', ct), ('model', LogisticRegression(max_iter=10000, penalty='l2'))]": 1,
      "[('s1', scaler), ('p', power), ('s2', scaler2)]": 1,
      "[('dtr', dtr), ('ada', ada)]": 1,
      "[('union', FeatureUnion(transformer_list=[('cst', cust_regression_vals()), ('txt1', pipeline.Pipeline([('s1', cust_txt_col(key='search_term')), ('tfidf1', tfidf), ('tsvd1', tsvd)])), ('txt2', pipeline.Pipeline([('s2', cust_txt_col(key='product_title')), ('tfidf2', tfidf), ('tsvd2', tsvd)])), ('txt4', pipeline.Pipeline([('s4', cust_txt_col(key='brand')), ('tfidf4', tfidf), ('tsvd4', tsvd)]))], transformer_weights={'cst': 1.0, 'txt1': 1.0, 'txt2': 1.0, 'txt4': 1.0})), ('rfr', rfr)]": 1,
      "[('impute', KNNImputer(n_neighbors=6)), ('encode', StandardScaler()), ('model', GradientBoostingClassifier())]": 1,
      "[('impute', SimpleImputer(strategy='most_frequent')), ('s', PowerTransformer(method='yeo-johnson')), ('m', GradientBoostingRegressor())]": 1,
      "[('impute', KNNImputer(n_neighbors=6)), ('d', StandardScaler())]": 1,
      "[('i', KNNImputer(n_neighbors=9)), ('rfe', RFECV(estimator=GradientBoostingClassifier())), ('model', GradientBoostingClassifier())]": 1,
      "[('impute', IterativeImputer(max_iter=9, imputation_order='arabic')), ('d', SelectKBest(score_func=f_regression, k=55)), ('e', SelectKBest(score_func=f_classif, k=52)), ('model', model)]": 1,
      "[('i', KNNImputer(n_neighbors=27)), ('s', SelectKBest(score_func=mutual_info_regression, k=69)), ('normalize', StandardScaler()), ('model', xg.XGBRegressor(objective='reg:linear', n_estimators=10, seed=123))]": 1,
      "[('impute', KNNImputer(n_neighbors=23)), ('mo', SelectKBest(score_func=f_classif, k=32))]": 1,
      "[('impute', KNNImputer(n_neighbors=23)), ('scale', StandardScaler()), ('ss', SelectKBest(score_func=f_regression, k=31))]": 1,
      "[('rfe', SelectKBest(score_func=chi2, k=13)), ('encode', StandardScaler()), ('model', GradientBoostingClassifier())]": 1,
      "[('impute', KNNImputer(n_neighbors=9)), ('model', GradientBoostingClassifier())]": 1,
      "[('cv', TfidfVectorizer(min_df=2, strip_accents='unicode', analyzer='word', stop_words='english', token_pattern='[\\\\w@]{1,}', ngram_range=(1, 3), use_idf=1, smooth_idf=1, sublinear_tf=1))]": 1,
      "[('cv', TfidfVectorizer(min_df=3, max_features=10000, strip_accents='unicode', analyzer='word', token_pattern='[\\\\w@]{1,}', ngram_range=(1, 3), use_idf=1, smooth_idf=1, sublinear_tf=1)), ('svd', TruncatedSVD(n_components=120, algorithm='arpack', random_state=10))]": 1,
      "[('cv', TfidfVectorizer(min_df=3, max_features=10000, strip_accents='unicode', analyzer='word', token_pattern='[\\\\w@]{1,}', ngram_range=(1, 3), use_idf=1, smooth_idf=1, sublinear_tf=1)), ('svd', TruncatedSVD(n_components=10, algorithm='arpack', random_state=10))]": 1,
      "[('scaler', StandardScaler()), ('model', RandomForestRegressor(random_state=42))]": 1,
      "(('standard_scaler', StandardScaler()), ('kneighborsregressor', KNeighborsRegressor()))": 1,
      "[('transforms', LambdaTransformer(transforms)), ('join_imbd', JoinTransformer(imdb_df, 'imdb_id', 'imdb_id')), ('null_encoder', NullEncoder(null_encode_cols, delete_old=True)), ('date_encoder', DateEncoder(date_cols)), ('json_encoder', JsonEncoder(json_fields)), ('nhot_encoder', NhotEncoder(nhot_cols, top_n=10)), ('add_features', LambdaFeatures(new_features)), ('targ_encoder', MultiTargetEncoderLOO(te_cols, bayesian_c=bayesian_c)), ('bert_encoder', BertEncoder(bert_cols, n_pc=n_pc)), ('scaler', Scaler()), ('imputer', Imputer())]": 1,
      "[('preprocessing', preprocessing), ('regressor', CatBoostRegressor(verbose=False))]": 1,
      "[('preprocessing', preprocessing), ('col_filter', KeepOnlyCols(cols_to_keep))]": 1,
      "[('target_encoder', TargetEncoderCV(cols=cat_cols)), ('scaler', RobustScaler()), ('imputer', SimpleImputer(strategy='median')), ('classifier', XGBClassifier())]": 1,
      "[('target_encoder', TargetEncoderCV(cols=cat_cols)), ('scaler', RobustScaler()), ('imputer', SimpleImputer(strategy='median')), ('regressor', CatBoostRegressor(loss_function='RMSE', verbose=False))]": 1,
      "[('targ_enc', TargetEncoderCV(cols=cat_cols)), ('scaler', RobustScaler()), ('imputer', SimpleImputer(strategy='median')), ('classifier', XGBClassifier())]": 1,
      "[('targ_enc', TargetEncoderCV(cols=cat_cols)), ('scaler', RobustScaler()), ('imputer', SimpleImputer(strategy='median')), ('regressor', CatBoostRegressor())]": 1,
      "[('targ_enc', TargetEncoderCV(cols=cat_cols)), ('scaler', RobustScaler()), ('imputer', SimpleImputer(strategy='median')), ('regressor', BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06))]": 1,
      "[('targ_enc', TargetEncoderCV(cols=cat_cols)), ('scaler', RobustScaler()), ('imputer', SimpleImputer(strategy='mean')), ('regressor', BayesianRidge(alpha_1=3e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-05))]": 1,
      "[('targ_enc', TargetEncoderCV(cols=cat_cols)), ('scaler', RobustScaler()), ('imputer', SimpleImputer(strategy='median')), ('regressor', XGBRegressor(max_depth=5, learning_rate=0.07, n_estimators=150, n_jobs=2))]": 1,
      "[('targ_enc', TargetEncoderCV(cols=cat_cols)), ('scaler', RobustScaler()), ('imputer', SimpleImputer(strategy='mean')), ('regressor', LGBMRegressor(num_leaves=30, max_depth=6, learning_rate=0.05, n_estimators=160))]": 1,
      "[('targ_enc', TargetEncoderCV(cols=cat_cols)), ('scaler', RobustScaler()), ('imputer', SimpleImputer(strategy='median')), ('regressor', CatBoostRegressor(verbose=False, depth=7, learning_rate=0.02, iterations=1000, l2_leaf_reg=2.0))]": 1,
      "[('scaler', RobustScaler()), ('imputer', SimpleImputer(strategy='median')), ('classifier', XGBClassifier())]": 1,
      "[('scaler', RobustScaler()), ('imputer', SimpleImputer(strategy='median')), ('classifier', CalibratedClassifierCV(base_estimator=XGBClassifier(), method='isotonic'))]": 1,
      "[('scaler', RobustScaler()), ('imputer', SimpleImputer(strategy='median')), ('classifier', CalibratedClassifierCV(base_estimator=XGBClassifier(), method='sigmoid'))]": 1,
      "[('scaler', RobustScaler()), ('imputer', SimpleImputer(strategy='median'))]": 1,
      "[('vect', TfidfVectorizer(lowercase=True, stop_words='english', encoding='utf-8')), ('tfidf', TfidfTransformer()), ('clf', i)]": 1,
      "[('vect', TfidfVectorizer()), ('tfidf', TfidfTransformer()), ('clf', svm.LinearSVC())]": 1,
      "[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', rfc)]": 1,
      "[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', xgbc)]": 1,
      "[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', lgbmc)]": 1,
      "[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', mnb)]": 1,
      "[('pca', pca), ('linear', regr)]": 1,
      "[('scale', StandardScaler()), ('model', model)]": 1,
      "[('fs', feature_selection), ('ridge', ridge)]": 1,
      "[('vectorizador', CountVectorizer()), ('clf', RidgeClassifier())]": 1,
      "[('vectorizador', TfidfVectorizer()), ('clf', RidgeClassifier())]": 1,
      "[('preprocessor', preprocessor), ('model', ExtraTreesClassifier(n_estimators=100, max_depth=8, random_state=0))]": 1,
      "[('preprocessor', preprocessor), ('model', LGBMClassifier(boosting_type='goss', n_estimators=100, max_depth=5, random_state=0))]": 1,
      "[('preprocessor', preprocessor), ('model', AdaBoostClassifier(n_estimators=100, random_state=0))]": 1,
      "[('preprocessor', preprocessor), ('model', LogisticRegression(max_iter=100, solver='sag', random_state=0))]": 1,
      "[('preprocessor', preprocessor), ('model', NuSVC(random_state=0))]": 1,
      "[('preprocessor', preprocessor), ('model', KNeighborsClassifier(n_neighbors=5, leaf_size=30))]": 1,
      "[('preprocessor', preprocessor), ('model', BaggingClassifier(n_estimators=10, random_state=0))]": 1,
      "[('preprocessor', preprocessor), ('model', XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10, min_child_weight=1, missing=None, n_estimators=100, nthread=-1, objective='binary:logistic', reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0, subsample=1))]": 1,
      "[('preprocessor', preprocessor), ('model', LabelPropagation(n_neighbors=7, max_iter=1000))]": 1,
      "[('preprocessor', preprocessor), ('model', QuadraticDiscriminantAnalysis())]": 1,
      "[('classifier', classifier)]": 1,
      "[('poly', PolynomialFeatures(degree=2, include_bias=False)), ('linear', Ridge())]": 1,
      "[('fe', ColumnTransformer([('prev', PolynomialFeatures(degree=1, include_bias=False), features), ('loc', Pipeline([('label', lb_encoder), ('onehot', oh_encoder)]), 'loc')])), ('linear', Ridge())]": 1,
      "[('label', lb_encoder), ('onehot', oh_encoder)]": 1,
      "[('bow', CountVectorizer()), ('tfidf', TfidfTransformer()), ('model', MultinomialNB())]": 1,
      "[('std', StandardScaler()), ('classifier', RandomForestRegressor())]": 1,
      "[('imputer', bin_imputer), ('Bin', KBinsDiscretizer(n_bins=5, encode=bin_encode_strategy, strategy=bin_strategy))]": 1,
      "[('preprocessor', ct1), ('classifier', model)]": 1,
      "[('preprocessor', ct1)]": 1,
      "[('imputer', SimpleImputer()), ('onehot', OneHotEncoder(handle_unknown='ignore'))]": 1,
      "[('imputer', SimpleImputer()), ('log_transform', LogTransform()), ('scaler', 'passthrough'), ('reduce_dim', PCA())]": 1,
      "[('data_transformer', data_transformer_simple), ('model', rf)]": 1,
      "[('data_transformer', data_transformer_pca), ('model', rf)]": 1,
      "[('selector_cat', FeatureSelector(cat_attribs)), ('cat_trans', OneHotEncoder())]": 1,
      "[('clip_trip_duration', ClipOutliers('trip_duration', lower_limit=None, upper_limit=6000)), ('clip_passenger_count', ClipOutliers('passenger_count', lower_limit=0, upper_limit=None)), ('clip_pickup_longitude', ClipOutliers('pickup_longitude', lower_limit=-90, upper_limit=None)), ('clip_pickup_latitude', ClipOutliers('pickup_latitude', lower_limit=None, upper_limit=50)), ('dist_trans', DistanceAttribsAdder()), ('clip_distance', ClipOutliers('distance', lower_limit=None, upper_limit=400))]": 1,
      "[('selector_num', DataFrameSelector(num_attribs)), ('date_tranform', DateAttribsAdder('pickup_datetime')), ('feature_dropper', DropFeature('trip_duration'))]": 1,
      "[('clip_trip_duration', ClipOutliers('trip_duration', lower_limit=None, upper_limit=6000)), ('trip_log_transformer', LogTransformer('trip_duration')), ('feature_selector', FeatureSelector('trip_duration'))]": 1,
      "[('imputer', SimpleImputer()), ('scaler', RobustScaler())]": 1,
      "[('preprocessor', preprocessor), ('classifier', LinearRegression())]": 1,
      "[('vect', CountVectorizer()), ('mnclf', MultinomialNB(alpha=alphas[k]))]": 1,
      "[('vect', CountVectorizer()), ('lgclf', LogisticRegression(C=0.5))]": 1,
      "[('vect', CountVectorizer()), ('lgclf', LogisticRegression(C=C[k]))]": 1,
      "[(PREPROCESSING_STAGE_NAME, ColumnTransformer([('down_scale_fnc', FunctionTransformer(down_scale), fnc_features), ('scale_others', 'passthrough', loading_features)]))]": 1,
      "[(PREPROCESSING_STAGE_NAME, ColumnTransformer([('top_k', SelectKBest(f_regression, k=k), fnc_features), ('others', 'passthrough', loading_features)])), ('scaling', StandardScaler())]": 1,
      "[(PREPROCESSING_STAGE_NAME, ColumnTransformer([('top_k', PCA(n_components=k), fnc_features), ('others', 'passthrough', loading_features)])), ('scaling', StandardScaler())]": 1,
      "[(PREPROCESSING_STAGE_NAME, ColumnTransformer([('top_k', Pipeline([('PCA', PCA(n_components=k)), ('scale', FunctionTransformer(down_scale))]), fnc_features), ('others', 'passthrough', loading_features)]))]": 1,
      "[('PCA', PCA(n_components=k)), ('scale', FunctionTransformer(down_scale))]": 1,
      "[('imp', SimpleImputer(strategy='constant', fill_value='MISSING')), ('hot', OneHotEncoder(handle_unknown='ignore', sparse=False))]": 1,
      "[('imp', SimpleImputer(strategy='most_frequent')), ('std', StandardScaler())]": 1,
      "[('clean', TeamAbbrCleaner()), ('features', FeaturePreprocessor()), ('play', PerPlayDatasetTransformer())]": 1,
      "[('pre', PosPreprocessor()), ('predictor', RandomForestClassifier(n_estimators=100))]": 1,
      "[('pre', PosPreprocessor()), ('rnn', RnnClassifier(batch_size=64))]": 1,
      "[('pre', PosPreprocessor()), ('rnn', RnnClassifier(batch_size=64, rnn_type='gru', hidden_layer=[64]))]": 1,
      "[('imputer', SimpleImputer(strategy='constant')), ('scaler', StandardScaler())]": 1,
      "[('ns', NameSplitter()), ('imputer', SimpleImputer(strategy='most_frequent')), ('scaler', OrdinalEncoder())]": 1,
      "[('col_t', column_trans), ('sfs', sfs), ('mlp', mlp)]": 1,
      "[('classifier', LogisticRegression(random_state=42))]": 1,
      "[('classifier', SVC())]": 1,
      "[('classifier', MLPClassifier())]": 1,
      "[('scaler', scaler), ('pca', pca), ('moc', MultiOutputClassifier(logistic, n_jobs=-1))]": 1,
      "[('tfidf', TfidfVectorizer(decode_error='ignore')), ('clf', SVC(random_state=2020))]": 1,
      "[('vect', new_vect), ('clf', new_clf)]": 1,
      "steps1": 1,
      "steps2": 1,
      "[('rescale', RobustScaler(quantile_range=(5.0, 95.0)))]": 1,
      "[('prep', column_trans), ('dt', dt)]": 1,
      "[('skb', SelectKBest(f_classif)), ('clf', lgbm.LGBMClassifier(boosting_type='goss', n_jobs=4, objective='binary'))]": 1,
      "[('ss', StandardScaler()), ('pca', PCA()), ('clf', LogisticRegression(random_state=0, n_jobs=-1, solver='lbfgs', class_weight='balanced'))]": 1,
      "[('rescale', MinMaxScaler()), ('modelo', lightgbm.LGBMRegressor(num_leaves=100, max_depth=14, learning_rate=0.2396915023230759, n_estimators=482, min_split_gain=0.17147656915295872, min_child_samples=12))]": 1,
      "[('xgb', xgb.XGBRegressor(silent=True))]": 1,
      "[('standardizer', norm), ('decom', pca), ('alg', svm)]": 1,
      "[('scaler', StandardScaler()), ('randomforestregressor: ', RandomForestRegressor())]": 1,
      "[('SCALE', MinMaxScaler()), ('CLASS', CLASS)]": 1,
      "[('imputer', SimpleImputer(strategy='most_frequent')), ('lanelencoder', LabelEncoder())]": 1,
      "[('imputer', SimpleImputer()), ('log', FunctionTransformer(np.log1p)), ('scaler', StandardScaler())]": 1,
      "[('preprocessor', preprocessor), ('variance_drop', VarianceThreshold(threshold=0.95 * (1 - 0.95))), ('voting', 'passthrough')]": 1,
      "pipeline_1_transformers": 1,
      "pipeline_2_transformers": 1,
      "pipeline_3_transformers": 1,
      "pipeline_4_transformers": 1,
      "final_pipeline_transformers + [('model', xgb_clf)]": 1,
      "final_pipeline_transformers + [('model', rf_reg)]": 1,
      "final_pipeline_transformers + [('model', xgb_reg)]": 1,
      "final_pipeline_transformers + [('model', lgbm_reg)]": 1,
      "[('preprocessor', preprocessor), ('model', linear_model)]": 1,
      "[('preprocessor', preprocessor), ('model', forest_model)]": 1,
      "[('preprocessor', preprocessor), ('model', xgb_model)]": 1,
      "[('v', TfidfVectorizer(min_df=5, max_df=500, max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 2), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words='english')), ('svd', TruncatedSVD(n_components=150, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=10.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=True, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None))]": 1,
      "[('label_enc', toLabeEncoderTransformer(cat='assetCode')), ('fillSrcNa', fillNASrcDscTransformer(_list_src=column_raw, _list_dst=column_market)), ('fillNa', fillNATransformer(_list=num_cols_fna, _value=0.0)), ('openclose', OpenCloseTransformer(open_col_name='open', close_col_name='close', new_col='op'))]": 1,
      "[('selector', dataSelector(cat_list=num_cols, isRetDataFrame=True)), ('std_scaler', StandardScaler())]": 1,
      "[('selector', dataSelector(cat_list=cat_cols_sel, isRetDataFrame=True))]": 1,
      "[('prep', data_prep_pipeline), ('comb', comb_pipeline)]": 1,
      "[('tdfidf', TfidfVectorizer()), ('lr', LogisticRegression())]": 1,
      "[('tdfidf', TfidfVectorizer()), ('lr', MultinomialNB())]": 1,
      "[('tdfidf', TfidfVectorizer()), ('clf', LinearSVC())]": 1,
      "[('tdfidf', TfidfVectorizer()), ('rfc', RandomForestClassifier(criterion='gini', max_depth=15))]": 1,
      "[('tdfidf', TfidfVectorizer()), ('dtc', DecisionTreeClassifier())]": 1,
      "[('tdfidf', TfidfVectorizer()), ('knn', KNeighborsClassifier())]": 1,
      "[('scaler', StandardScaler()), ('dim_reduct', PCA()), ('clf', RandomForestClassifier())]": 1,
      "[('union', pipeline.FeatureUnion(transformer_list=[('standard', cust_regression_vals()), ('pip1', pipeline.Pipeline([('newText', cust_txt_col('newText')), ('counts', cvec), ('tsvdCountText', tsvdCount)])), ('pip2', pipeline.Pipeline([('nmf_Text', cust_txt_col('newText')), ('tfidf_Text', tfidf), ('nmfText', nmf)])), ('pip3', pipeline.Pipeline([('lda_Text', cust_txt_col('newText')), ('tfidf_Text', tfidf), ('ldaText', lda)])), ('pip4', pipeline.Pipeline([('newText', cust_txt_col('newText')), ('tfidf_Text', tfidf), ('tsvdText', tsvdText)]))]))]": 1,
      "[('newText', cust_txt_col('newText')), ('counts', cvec), ('tsvdCountText', tsvdCount)]": 1,
      "[('nmf_Text', cust_txt_col('newText')), ('tfidf_Text', tfidf), ('nmfText', nmf)]": 1,
      "[('lda_Text', cust_txt_col('newText')), ('tfidf_Text', tfidf), ('ldaText', lda)]": 1,
      "[('newText', cust_txt_col('newText')), ('tfidf_Text', tfidf), ('tsvdText', tsvdText)]": 1,
      "[('tfidf', TfidfVectorizer()), ('clf', XGBClassifier())]": 1,
      "[('cvt', cvt), ('tfi', tfi), ('clf', clf)]": 1,
      "[('cvt', cvt), ('tfi', tfi)]": 1,
      "[('tfidf', TfidfVectorizer(stop_words='english')), ('nb_model', OneVsRestClassifier(MultinomialNB(), n_jobs=-1))]": 1,
      "[('tfidf', TfidfVectorizer(stop_words='english')), ('lr_model', OneVsRestClassifier(LogisticRegression(), n_jobs=-1))]": 1,
      "[('tfidf', TfidfVectorizer(stop_words='english')), ('svm_model', OneVsRestClassifier(LinearSVC(), n_jobs=-1))]": 1,
      "[('custom', NonLinearTransformer()), ('scaling', StandardScaler()), ('regression', xgb.XGBRegressor(**xgb_parameters))]": 1,
      "[('custom', NonLinearTransformer()), ('scaling', StandardScaler()), ('regression', lgb.LGBMRegressor(**lgb_parameters))]": 1,
      "[('correlation', CorrelationSelector(threshold=0.85)), ('scaler', MinMaxScaler()), ('xgboost', XGBRegressor(objective='reg:squarederror', n_estimators=1000, **parameters))]": 1,
      "[('features', combined_features), ('rfr', rfr)]": 1,
      "[('vect', CountVectorizer(stop_words='english', tokenizer=LemmaTokenizer())), ('tfidf', TfidfTransformer())]": 1,
      "[('pre', pre_process_pl), ('clf', OneVsRestClassifier(LogisticRegression()))]": 1,
      "[('Tfidf', TfidfVectorizer()), ('Svm', LinearSVC())]": 1,
      "[('Tfidf', TfidfVectorizer()), ('logisticregression', LogisticRegression(penalty='l2', solver='saga'))]": 1,
      "[('Tfidf', TfidfVectorizer()), ('naivebayes', MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None))]": 1,
      "[('Tfidf', TfidfVectorizer()), ('SGD', SGDClassifier(loss='hinge', penalty='l2', random_state=0))]": 1,
      "[('Tfidf', TfidfVectorizer()), ('RFC', RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=4))]": 1,
      "[('selector', DataFrameSelector(num_attribs)), ('imputer', Imputer(strategy='median')), ('std_scaler', StandardScaler()), ('KBest', SelectKBest(k=10)), ('pca', PCA(n_components=5)), ('reg', RandomForestRegressor(random_state=42))]": 1,
      "[('encoder', OneHotEncoder(handle_unknown='ignore'))]": 1,
      "[('preprocessor', preprocessor), ('classifier', SGDClassifier(loss='log', alpha=0.001, n_jobs=-1, random_state=14))]": 1,
      "[('union', FeatureUnion(transformer_list=[('cst', cust_regression_vals()), ('txt1', pipeline.Pipeline([('s1', cust_txt_col(key='search_term')), ('tfidf1', tfidf), ('tsvd1', tsvd)])), ('txt2', pipeline.Pipeline([('s2', cust_txt_col(key='product_title')), ('tfidf2', tfidf), ('tsvd2', tsvd)])), ('txt3', pipeline.Pipeline([('s3', cust_txt_col(key='product_description')), ('tfidf3', tfidf), ('tsvd3', tsvd)])), ('txt4', pipeline.Pipeline([('s4', cust_txt_col(key='brand')), ('tfidf4', tfidf), ('tsvd4', tsvd)]))], transformer_weights={'cst': 0.9, 'txt1': 0.5, 'txt2': 0.25, 'txt3': 0.0, 'txt4': 0.5}, n_jobs=-1)), ('rfr', rfr)]": 1,
      "[('SFromModel', SelectKBest(score_func=f_regression, k=best_params['SFromModel__k'])), ('Model', LinearRegression())]": 1,
      "[('poly', PolynomialFeatures(degree=2)), ('pca', PCA(n_components=10)), ('lr', LinearRegression())]": 1,
      "[('vt', VarianceThreshold()), ('skb', SelectKBest(f_classif, k=15)), ('pca', PCA()), ('xgb_clf', XGBClassifier())]": 1,
      "[('xy_is', xy_is), ('xy_scaler', xy_scaler), ('pca', pca)]": 1,
      "[('date_is', date_is), ('date_fun', dateFun)]": 1,
      "[('address_cat_is', address_cat_is), ('count_feat_fun', count_feat_fun)]": 1,
      "[('cocrimeFun', cocrimeFun), ('reshaper', reshaper)]": 1,
      "dummy_steps": 1,
      "random_forest_steps": 1,
      "random_forest_scaled_steps": 1,
      "random_forest_hyper_steps": 1,
      "random_forest_month_steps": 1,
      "support_vector_reg_steps": 1,
      "svr_normalized_steps": 1,
      "svr_hyper_steps": 1,
      "svr_hyper_month_steps": 1,
      "xgboost_steps": 1,
      "xgboost_month_steps": 1,
      "[('imputer', SimpleImputer(strategy='most_frequent')), ('one_hot', OneHotEncoder(handle_unknown='ignore'))]": 1,
      "[('label_encoder', ModifiedLabelEncoder())]": 1,
      "[('imputer', SimpleImputer(strategy='constant', fill_value='missing')), ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=True))]": 1,
      "[('v', TfidfVectorizer(min_df=4, max_df=500, max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 3), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words='english')), ('svd', TruncatedSVD(n_components=350, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=10.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None))]": 1,
      "[('v', TfidfVectorizer(max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 5), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words=ML_STOP_WORDS)), ('sdg', SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15, learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1, penalty='l2', power_t=0.5, random_state=None, shuffle=True, verbose=0, warm_start=False))]": 1,
      "[('v', TfidfVectorizer(max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 5), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words=ML_STOP_WORDS)), ('svd', TruncatedSVD(n_components=100)), ('scl', StandardScaler()), ('svm', SVC(C=10))]": 1,
      "[('v', TfidfVectorizer(max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 5), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words=ML_STOP_WORDS)), ('dtc', DecisionTreeClassifier(random_state=0))]": 1,
      "[('v', TfidfVectorizer(max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 5), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words=ML_STOP_WORDS)), ('kn', KNeighborsClassifier(n_neighbors=3))]": 1,
      "[('cvec', CountVectorizer()), ('lr', LogisticRegression())]": 1,
      "[('preprocessor', preprocessor), ('f_selection', SelectPercentile(percentile=75)), ('model', model)]": 1,
      "[('v', TfidfVectorizer(min_df=5, max_df=500, max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 2), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words='english')), ('svd', TruncatedSVD(n_components=200, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('rf', RandomForestClassifier())]": 1,
      "[('col_select', ColumnSelector('name')), ('tf_idf', TfidfVectorizer(stop_words='english', sublinear_tf=True))]": 1,
      "[('col_select', ColumnSelector('item_description')), ('tf_idf', TfidfVectorizer(stop_words='english', sublinear_tf=True))]": 1,
      "[('col_select', ColumnSelector('category_name')), ('tf_idf', TfidfVectorizer(stop_words='english', sublinear_tf=True))]": 1,
      "[('col_select', ColumnSelector('brand_name')), ('tf_idf', TfidfVectorizer(stop_words='english', sublinear_tf=True))]": 1,
      "[('col_select', ColumnSelector('item_condition_id', is_ordinal=True)), ('one_binary', CountVectorizer(lowercase=False, binary=True))]": 1,
      "[('vect', CountVectorizer(analyzer='word')), ('clf', clfs)]": 1,
      "[('union', FeatureUnion(n_jobs=-1, transformer_list=[('standard', cust_regression_vals()), ('pi1', Pipeline([('Gene', cust_txt_col('Gene')), ('vect_Gene', CountVectorizer(analyzer='char', max_df=0.5, ngram_range=(1, 2), max_features=None)), ('tsvd1', TruncatedSVD(n_iter=25, random_state=12, n_components=10))]))]))]": 1,
      "[('Gene', cust_txt_col('Gene')), ('vect_Gene', CountVectorizer(analyzer='char', max_df=0.5, ngram_range=(1, 2), max_features=None)), ('tsvd1', TruncatedSVD(n_iter=25, random_state=12, n_components=10))]": 1,
      "[('encode', CountEncoder(cols=[0, 2])), ('classify', mof)]": 1,
      "[('svd', svd), ('scl', scl)]": 1,
      "[('feature_set', FeatureUnion([('f_poly', Pipeline([('poly', PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)), ('scaler', StandardScaler())])), ('f_kpca', Pipeline([('scaler', StandardScaler()), ('kpca', KernelPCA(n_components=15, kernel='rbf', fit_inverse_transform=True, gamma=1))]))])), ('rfe', RFE(estimator=SVC(kernel='linear', C=1), n_features_to_select=10, step=1))]": 1,
      "[('poly', PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)), ('scaler', StandardScaler())]": 1,
      "[('scaler', StandardScaler()), ('kpca', KernelPCA(n_components=15, kernel='rbf', fit_inverse_transform=True, gamma=1))]": 1,
      "[('features', combined_features), (name, clf)]": 1,
      "[('preprocessor', feature_preprocessor), ('model', model)]": 1,
      "[('std', StandardScaler()), ('clf', KNeighborsClassifier())]": 1,
      "[('std', StandardScaler()), ('clf', LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced'))]": 1,
      "[('sel', SelectKBest()), ('clf', LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced', C=0.1))]": 1,
      "[('sel', SelectKBest()), ('clf', LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced', C=0.05))]": 1,
      "[('sel', SelectKBest()), ('clf', LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced', C=0.04))]": 1,
      "[('std', StandardScaler()), ('clf', SGDClassifier(loss='modified_huber', max_iter=1000, tol=0.001))]": 1,
      "[('vectorizer', tfvec), ('rf', mb)]": 1,
      "[('vectorizer', tfvec), ('mb', mb)]": 1,
      "[('feature_selector', FeatureSelector()), ('linreg', elastic_net())]": 1,
      "[('feature_selector', FeatureSelector()), ('Scaler', RobustScaler()), ('Ridge', RidgeCV(alphas=alphas_alt, cv=kfolds))]": 1,
      "[('feature_selector', FeatureSelector()), ('Scaler', RobustScaler()), ('Lasso', LassoCV(max_iter=10000000.0, alphas=alphas2, random_state=42, cv=kfolds))]": 1,
      "[('feature_selector', FeatureSelector()), ('Scaler', RobustScaler()), ('Elastic', ElasticNetCV(max_iter=10000000.0, alphas=e_alphas, cv=kfolds, l1_ratio=e_l1ratio))]": 1,
      "[('feature_selector', FeatureSelector()), ('Scaler', RobustScaler()), ('SVR', SVR(C=20, epsilon=0.008, gamma=0.0003))]": 1,
      "[('imp', Imputer(missing_values='NaN', strategy='median', axis=0)), ('feat_select', SelectKBest(k=5)), ('lgbm', LGBMRegressor())]": 1,
      "[('imp', Imputer(missing_values='NaN', axis=0)), ('feat_select', SelectKBest()), ('lgbm', LGBMRegressor())]": 1,
      "[('tax_dimension', ColumnSelector(taxVars)), ('imp', Imputer(missing_values='NaN', axis=0)), ('column_purge', SelectKBest()), ('lgbm', LGBMRegressor())]": 1,
      "[('unity', FeatureUnion(transformer_list=[('cont_portal', Pipeline([('selector', PortalToColDimension(contVars)), ('cont_imp', Imputer(missing_values='NaN', strategy='median', axis=0)), ('scaler', StandardScaler())])), ('tax_portal', Pipeline([('selector', PortalToColDimension(taxVars)), ('tax_imp', Imputer(missing_values='NaN', strategy='most_frequent', axis=0)), ('scaler', MinMaxScaler(copy=True, feature_range=(0, 3)))]))])), ('column_purge', SelectKBest(k=5)), ('lgbm', LGBMRegressor())]": 1,
      "[('selector', PortalToColDimension(contVars)), ('cont_imp', Imputer(missing_values='NaN', strategy='median', axis=0)), ('scaler', StandardScaler())]": 1,
      "[('selector', PortalToColDimension(taxVars)), ('tax_imp', Imputer(missing_values='NaN', strategy='most_frequent', axis=0)), ('scaler', MinMaxScaler(copy=True, feature_range=(0, 3)))]": 1,
      "[ohe_step]": 1,
      "[catboost_enc_step]": 1,
      "[ord_auto_step]": 1,
      "[ord_list_step]": 1,
      "[adjust_day, ord_auto_step]": 1,
      "[('transform', col_transformer), ('lr', LogisticRegression())]": 1,
      "[('vt', VarianceThreshold(threshold=0.0)), ('ut', UniqueTransformer()), ('fu', FeatureUnion([('pca', PCA(n_components=100)), ('ct-2', ClassifierTransformer(get_rfc(), n_classes=2, cv=5)), ('ct-3', ClassifierTransformer(get_rfc(), n_classes=3, cv=5)), ('ct-4', ClassifierTransformer(get_rfc(), n_classes=4, cv=5)), ('ct-5', ClassifierTransformer(get_rfc(), n_classes=5, cv=5)), ('st', StatsTransformer(stat_funs=get_stat_funs()))])), ('xgb-cv', XGBRegressorCV(xgb_params=xgb_params, fit_params=fit_params, cv=10))]": 1,
      "[('preprocess', CountVectorizer(analyzer=data_preprocess)), ('Tfidf', TfidfTransformer()), ('classify', LogisticRegression())]": 1,
      "[('select', DataFrameSelector(numbers_attrs)), ('p_imputer', PercentImputer(percent=0.9)), ('s_imputer', SimpleImputer(strategy='mean')), ('to_dataFrame', ToDataFrame(columns=numbers_cols)), ('drop_dt_fraud', DataFrameDropper(drop_attrs=['isFraud'])), ('normalize', NormalizeByLog('TransactionAmt')), ('categorize', CategorizeCs()), ('dropVs', DropExtraVs()), ('drop1', DataFrameDropper(drop_attrs=to_drop_numbers)), ('drop2', DataFrameDropper(drop_attrs=id_to_drop)), ('std_scale', StandardScaler())]": 1,
      "[('select', DataFrameSelector(label_atrrs)), ('p_imputer', PercentImputer(percent=0.9)), ('l_imputer', LabelImputer(dummy=True)), ('change_debit', ChangeToDebit()), ('melt', MeltMatchStatus()), ('encode', ModifiedLabelEncoder()), ('std_scale', StandardScaler())]": 1,
      "[('imputer', Imputer()), ('corr', CorrelationSelector()), ('knn', KNeighborsClassifier())]": 1,
      "[('imputer', Imputer()), ('corr', CorrelationSelector(min_corr=min_corr, max_pval=max_pval)), ('knn', KNeighborsClassifier(n_neighbors=k, p=p))]": 1,
      "[('denoise', RMTDenoising(sample=0.8)), ('clf', XGBClassifier(**params))]": 1,
      "pipeline_list": 1,
      "[('SimpleImputer', SimpleImputer()), ('normalize', StandardScaler()), ('pca', PCA(n_components=n_pc))]": 1,
      "[('preprocessor', SimpleImputer()), ('model', RandomForestRegressor(n_estimators=n_est, random_state=0))]": 1,
      "[('scaler', StandardScaler()), ('preprocessor', SimpleImputer()), ('model', RandomForestRegressor(n_estimators=100, random_state=0))]": 1,
      "[('preprocessor', SimpleImputer()), ('model', RandomForestRegressor(n_estimators=n_estimators, random_state=0))]": 1,
      "[('tfidf', TfidfVectorizer()), ('mnb', MultinomialNB())]": 1,
      "[('poly', PolynomialFeatures()), ('Scaler', StandardScaler()), ('LASSO', Lasso(random_state=42))]": 1,
      "[('poly', PolynomialFeatures()), ('Scaler', StandardScaler()), ('RID', Ridge(random_state=42))]": 1,
      "[('poly', PolynomialFeatures()), ('Scaler', StandardScaler()), ('KNN', KNeighborsRegressor(n_neighbors=2))]": 1,
      "[('poly', PolynomialFeatures()), ('Scaler', StandardScaler()), ('CART', DecisionTreeRegressor(random_state=42))]": 1,
      "[('poly', PolynomialFeatures()), ('Scaler', StandardScaler()), ('GBM', GradientBoostingRegressor(random_state=42))]": 1,
      "[('poly', PolynomialFeatures()), ('Scaler', StandardScaler()), ('RFR', RandomForestRegressor(random_state=42))]": 1,
      "[('poly', PolynomialFeatures()), ('Scaler', StandardScaler()), ('SVR', SVR(kernel='linear'))]": 1,
      "[('poly', PolynomialFeatures()), ('Scaler', StandardScaler()), ('XGBR', XGBRegressor(random_state=42))]": 1,
      "[('poly', PolynomialFeatures()), ('StandardScaler', standardscaler), ('XGBR', model)]": 1,
      "[('imputer', CustomImputer(['Sex', 'Pclass'])), ('attribs_adder', AttributeAdder()), ('std_scaler', StandardScaler())]": 1,
      "[('cat_imputer', SimpleImputer(strategy='most_frequent')), ('encoder', OneHotEncoder(handle_unknown='ignore'))]": 1,
      "[('imputer', SimpleImputer(strategy='median')), ('attribs_adder', AttributesAdder()), ('std_scaler', StandardScaler())]": 1,
      "[('norm', StandardScaler()), ('knn', classifier)]": 1,
      "[('Feature Selection', selector), ('Classification', clf(kernel='poly'))]": 1,
      "[('Feature Selection', SelectPercentile(f_classif, percentile=70)), ('Classification', MLPClassifier(random_state=random_state, activation=str(space_eval(space, best)['activation']), solver=str(space_eval(space, best)['solver']), alpha=int(best['alpha']), hidden_layer_sizes=tuple(space_eval(space, best)['hidden_layer_sizes']), learning_rate=str(space_eval(space, best)['learning_rate'])))]": 1,
      "[('ss', StandardScaler()), ('classifier', ovr_class)]": 1,
      "[('features', FeatureUnion([('assetCodeEncoder', Pipeline([('selector', FunctionTransformer(lambda X: X['assetCode'], validate=False)), ('label', LabelBinarizerPipelineFriendly(sparse_output=True)), ('t-svd', TruncatedSVD(10)), ('repeater', Repeater())])), ('numericFeatures', Pipeline([('selector', FunctionTransformer(lambda X: X[market_numeric_features], validate=False)), ('fillNa', FunctionTransformer(lambda X: X.fillna(0), validate=False)), ('scale', StandardScaler()), ('repeater', Repeater())]))])), ('classifier', XGBClassifier(n_estimators=50, tree_kind='hist'))]": 1,
      "[('selector', FunctionTransformer(lambda X: X['assetCode'], validate=False)), ('label', LabelBinarizerPipelineFriendly(sparse_output=True)), ('t-svd', TruncatedSVD(10)), ('repeater', Repeater())]": 1,
      "[('selector', FunctionTransformer(lambda X: X[market_numeric_features], validate=False)), ('fillNa', FunctionTransformer(lambda X: X.fillna(0), validate=False)), ('scale', StandardScaler()), ('repeater', Repeater())]": 1,
      "[('hist_D1', LagWeatherFeatureCalculator(frequency='D', shift=1, attributes=attributes)), ('hist_W1', LagWeatherFeatureCalculator(frequency='W', shift=1, attributes=attributes))]": 1,
      "[('selector', DataFrameSelector(cat_features)), ('imputer', CategoricalImputer()), ('encoder', OrdinalEncoder())]": 1,
      "[('selector', DataFrameSelector(date_attributes)), ('extractor', TimeInfoExtractor()), ('encoder', OrdinalEncoder())]": 1,
      "[('selector', DataFrameSelector(num_features)), ('imputer', SimpleImputer(strategy='mean')), ('transformer', LogModulusTransformer()), ('scaler', StandardScaler())]": 1,
      "[('scaler', StandardScaler()), ('pca', PCA(n_components=0.95))]": 1,
      "[('tweet', tweet), ('cat', fill)]": 1,
      "[('encoder', encoder), ('scaler', StandardScaler()), ('kbest', SelectKBest(f_regression)), ('clf', RandomForestRegressor(n_jobs=-1))]": 1,
      "[('encoder', encoder), ('polynomial', PolynomialFeatures()), ('scaler', StandardScaler()), ('kbest', SelectKBest(f_regression)), ('clf', Lasso())]": 1,
      "[('encoder', encoder), ('polynomial', PolynomialFeatures()), ('scaler', StandardScaler()), ('clf', Lasso())]": 1,
      "[('encoder', encoder), ('scaler', StandardScaler()), ('kbest', SelectKBest(f_regression, k=k)), ('clf', lgb.LGBMRegressor(n_jobs=-1))]": 1,
      "[('encoder', JamesSteinEncoder()), ('scaler', StandardScaler()), ('clf', lgb.LGBMRegressor(n_jobs=-1))]": 1,
      "[('pca', PCA(n_components=154, random_state=RANDOM_SEED)), ('classifier', SVC(kernel='rbf', gamma=0.06))]": 1,
      "[('bow', CountVectorizer(ngram_range=(1, 3), stop_words='english')), ('tfidf', TfidfTransformer()), ('classifier', Ridge(alpha=0.5))]": 1,
      "[('preprocessor', preprocessor), ('classifier', clf)]": 1,
      "[('encoder', encoder), ('rfe', rfe), ('clf', clf1)]": 1,
      "[('extractfeatures', FeatureExtractor()), ('union', FeatureUnion([('name_trigram', Pipeline([('selector', ItemSelector(key='name')), ('preprocessor', DataPreprocessor()), ('normalizer', DataNormalizer()), ('tfidf', TfidfVectorizer(ngram_range=(1, 3), max_features=75000, lowercase=False, min_df=2))])), ('name_bigram_hash', Pipeline([('selector', ItemSelector(key='name')), ('preprocessor', DataPreprocessor()), ('normalizer', DataNormalizer()), ('hv', HashingVectorizer(ngram_range=(1, 2), lowercase=False, stop_words='english', norm='l2'))])), ('name_stats', Pipeline([('selector', ItemSelector(key='name')), ('stats', TextStats()), ('vect', DictVectorizer())])), ('category_name', Pipeline([('selector', ItemSelector(key='category_name')), ('preprocessor', DataPreprocessor()), ('cv', CountVectorizer(token_pattern='.+'))])), ('general_cat', Pipeline([('selector', ItemSelector(key='general_cat')), ('preprocessor', DataPreprocessor()), ('cv', CountVectorizer(token_pattern='.+', min_df=2))])), ('subcat_1', Pipeline([('selector', ItemSelector(key='subcat_1')), ('preprocessor', DataPreprocessor()), ('cv', CountVectorizer(token_pattern='.+', min_df=2))])), ('subcat_2', Pipeline([('selector', ItemSelector(key='subcat_2')), ('preprocessor', DataPreprocessor()), ('cv', CountVectorizer(token_pattern='.+', min_df=2))])), ('brand_name', Pipeline([('selector', ItemSelector(key='brand_name')), ('preprocessor', DataPreprocessor()), ('cv', CountVectorizer(token_pattern='.+', min_df=2))])), ('shipping', Pipeline([('selector', ItemSelector(key='shipping')), ('preprocessor', DataPreprocessor()), ('cv', CountVectorizer(token_pattern='\\\\d+'))])), ('item_condition_id', Pipeline([('selector', ItemSelector(key='item_condition_id')), ('preprocessor', DataPreprocessor()), ('cv', CountVectorizer(token_pattern='\\\\d+'))])), ('item_description_trigram', Pipeline([('selector', ItemSelector(key='item_description')), ('preprocessor', DataPreprocessor()), ('normalizer', DataNormalizer()), ('tfidf', TfidfVectorizer(ngram_range=(1, 3), max_features=100000, lowercase=False))])), ('item_description_bigram_hash', Pipeline([('selector', ItemSelector(key='item_description')), ('preprocessor', DataPreprocessor()), ('normalizer', DataNormalizer()), ('hv', HashingVectorizer(ngram_range=(1, 2), lowercase=False, stop_words='english', norm='l2'))])), ('item_description_stats', Pipeline([('selector', ItemSelector(key='item_description')), ('stats', TextStats()), ('vect', DictVectorizer())]))]))]": 1,
      "[('selector', ItemSelector(key='name')), ('preprocessor', DataPreprocessor()), ('normalizer', DataNormalizer()), ('tfidf', TfidfVectorizer(ngram_range=(1, 3), max_features=75000, lowercase=False, min_df=2))]": 1,
      "[('selector', ItemSelector(key='name')), ('preprocessor', DataPreprocessor()), ('normalizer', DataNormalizer()), ('hv', HashingVectorizer(ngram_range=(1, 2), lowercase=False, stop_words='english', norm='l2'))]": 1,
      "[('selector', ItemSelector(key='name')), ('stats', TextStats()), ('vect', DictVectorizer())]": 1,
      "[('selector', ItemSelector(key='category_name')), ('preprocessor', DataPreprocessor()), ('cv', CountVectorizer(token_pattern='.+'))]": 1,
      "[('selector', ItemSelector(key='general_cat')), ('preprocessor', DataPreprocessor()), ('cv', CountVectorizer(token_pattern='.+', min_df=2))]": 1,
      "[('selector', ItemSelector(key='subcat_1')), ('preprocessor', DataPreprocessor()), ('cv', CountVectorizer(token_pattern='.+', min_df=2))]": 1,
      "[('selector', ItemSelector(key='subcat_2')), ('preprocessor', DataPreprocessor()), ('cv', CountVectorizer(token_pattern='.+', min_df=2))]": 1,
      "[('selector', ItemSelector(key='brand_name')), ('preprocessor', DataPreprocessor()), ('cv', CountVectorizer(token_pattern='.+', min_df=2))]": 1,
      "[('selector', ItemSelector(key='shipping')), ('preprocessor', DataPreprocessor()), ('cv', CountVectorizer(token_pattern='\\\\d+'))]": 1,
      "[('selector', ItemSelector(key='item_condition_id')), ('preprocessor', DataPreprocessor()), ('cv', CountVectorizer(token_pattern='\\\\d+'))]": 1,
      "[('selector', ItemSelector(key='item_description')), ('preprocessor', DataPreprocessor()), ('normalizer', DataNormalizer()), ('tfidf', TfidfVectorizer(ngram_range=(1, 3), max_features=100000, lowercase=False))]": 1,
      "[('selector', ItemSelector(key='item_description')), ('preprocessor', DataPreprocessor()), ('normalizer', DataNormalizer()), ('hv', HashingVectorizer(ngram_range=(1, 2), lowercase=False, stop_words='english', norm='l2'))]": 1,
      "[('selector', ItemSelector(key='item_description')), ('stats', TextStats()), ('vect', DictVectorizer())]": 1,
      "[('selector', DataFrameSelector(str_feature)), ('tfidf', TfidfVectorizer(stop_words='english'))]": 1,
      "[('selector', DataFrameSelector(num_features_list)), ('standard', StandardScaler())]": 1,
      "[('vect', CountVectorizer(min_df=10, max_df=0.9, stop_words='english')), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())]": 1,
      "[('lr_clf', LogisticRegression(solver='lbfgs', max_iter=1500, C=10))]": 1,
      "[('add_features', FunctionTransformer(add_features, validate=False, kw_args={'split_aspect': True, 'aspect_slope': True, 'drop_aspects': True, 'elev_asp_slope': True, 'asp_slope_factor': 10}))]": 1,
      "[('add_features', FunctionTransformer(add_features, validate=False, kw_args={'split_aspect': True, 'aspect_slope': True, 'drop_aspects': True, 'elev_asp_slope': True, 'asp_slope_factor': 10})), ('random_forest', RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini', max_depth=100, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=2, min_samples_split=5, min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None, oob_score=False, random_state=None, verbose=0, warm_start=False))]": 1,
      "[('add_features', FunctionTransformer(add_features, validate=False, kw_args={'split_aspect': True, 'aspect_slope': True, 'drop_aspects': True, 'elev_asp_slope': True, 'asp_slope_factor': 10})), ('bin_onehot', FunctionTransformer(bin_onehot, validate=False, kw_args={'perf_bin_onehot': True})), ('random_forest', RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini', max_depth=100, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=2, min_samples_split=5, min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None, oob_score=False, random_state=None, verbose=0, warm_start=False))]": 1,
      "[('column', column_transformer), ('scaler', scaler)]": 1,
      "[('preprocessing', preprocessing), ('regressor', XGBRegressor(n_estimators=100, max_depth=2, objective='reg:squarederror', tree_method='gpu_hist'))]": 1,
      "[('preprocessing', preprocessing), ('regressor', stacked)]": 1,
      "[('preprocessing', preprocessing), ('regressor', nn_model)]": 1,
      "[('clean', XLambda(transforms=[(lambda x: 0 if x == 'no' else 1 if x == 'yes' else float(x), ['edjefe', 'edjefa', 'dependency']), (lambda x: np.log(1 + x), lr_log_vars)])), ('feats', FeatureUnion(transformer_list=[('scaled', XScaler(select_columns=lr_num_vars, transformer=StandardScaler(), return_is_none_vars=False)), ('binary', XVarSelector(lr_bin_vars))])), ('clf', FoldsEstimator(LogisticRegression(C=0.1, penalty='l2', class_weight='balanced', random_state=25), predict_mode='mean'))]": 1,
      "[('clean', XLambda(transforms=[(lambda x: 0 if x == 'no' else 1 if x == 'yes' else float(x), ['edjefe', 'edjefa', 'dependency']), (lambda x: np.log(1 + x), [])])), ('feats', FeatureUnion(transformer_list=[('scaled', XScaler(select_columns=gb_num_vars, transformer=MinMaxScaler(), none_value=-100, return_is_none_vars=False)), ('nominal', XVarSelector(gb_cat_vars))])), ('clf', FoldsEstimator(LGBMClassifier(learning_rate=0.05, n_estimators=200, num_leaves=20, max_depth=15, class_weight='balanced', objective='multinominal', boosting='dart'), cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=39), predict_mode='mean'))]": 1,
      "[('encoder', OrdinalEncoder(categories=labels))]": 1,
      "[('preprocessor', preprocessor), ('model', XGBClassifier(n_estimators=500, booster='gbtree', use_label_encoder=False, learning_rate=0.02, eval_metric='auc', n_jobs=-1, random_state=42))]": 1,
      "[('v', TfidfVectorizer(min_df=5, max_df=500, max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 2), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words='english')), ('svd', TruncatedSVD(n_components=500, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=13.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None))]": 1,
      "[('model', LogisticRegression())]": 1,
      "[('imputation', SimpleImputerCorrected(strategy='most_frequent')), ('encoding', TargetEncoder()), ('scalling', StandardScaler())]": 1,
      "[('imputation', SimpleImputerCorrected(strategy='most_frequent')), ('encoding', TargetEncoder(smoothing=te_smoothing)), ('scalling', StandardScaler())]": 1,
      "[('encoder', encoder), ('pca', PCA(n_components=pca_threshold))]": 1,
      "[('encoder', encoder)]": 1,
      "[('encode', CountEncoder(cols=['cp_dose', 'cp_time'])), ('classify', classifier)]": 1,
      "[('cleaning', DataCleaning()), ('Date and time extraction', date_time_extraction()), ('Pick up or drop off in an airport', Airport_data()), ('usefull distances', distance()), ('Normalization', Normalization())]": 1,
      "[('sscaler2', StandardScaler()), ('rf', RandomForestRegressor())]": 1,
      "[('classifier', LogisticRegression(solver='lbfgs', penalty='none'))]": 1,
      "[('classifier', RandomForestClassifier(n_estimators=100))]": 1,
      "[('bow', CountVectorizer(analyzer=preprocess)), ('tfidf', TfidfTransformer()), ('classifier', clf)]": 1,
      "[('bow', CountVectorizer(analyzer=preprocess)), ('tfidf', TfidfTransformer()), ('classifier', MultinomialNB())]": 1,
      "[('bow', CountVectorizer(analyzer=preprocess)), ('tfidf', TfidfTransformer()), ('classifier', KNeighborsClassifier())]": 1,
      "[('bow', CountVectorizer(analyzer=preprocess)), ('tfidf', TfidfTransformer()), ('classifier', RandomForestClassifier())]": 1,
      "[('bow', CountVectorizer(analyzer=preprocess)), ('tfidf', TfidfTransformer()), ('classifier', DecisionTreeClassifier())]": 1,
      "[('union', FeatureUnion(transformer_list=[('cst', Pipeline([('cst1', cust_regression_vals())])), ('txt1', Pipeline([('s1', cust_txt_col(key='question1')), ('tfidf1', tfidf)])), ('txt2', Pipeline([('s2', cust_txt_col(key='question2')), ('tfidf2', tfidf)]))], transformer_weights={'cst': 1.0, 'txt1': 1.0, 'txt2': 1.0}, n_jobs=-1))]": 1,
      "[('cst1', cust_regression_vals())]": 1,
      "[('s1', cust_txt_col(key='question1')), ('tfidf1', tfidf)]": 1,
      "[('s2', cust_txt_col(key='question2')), ('tfidf2', tfidf)]": 1,
      "[('scaler2', StandardScaler()), ('RandomForestRegressor: ', RandomForestRegressor(n_jobs=-1, random_state=0))]": 1,
      "[('preprocess', data_process), ('model_rfr', model)]": 1,
      "[('vectorizer', TfidfVectorizer(max_df=0.85, norm='l2')), ('ligreg', linear_model.LinearRegression())]": 1,
      "[('vectorizer', TfidfVectorizer(max_df=0.85, norm='l2')), ('to_dense', DenseTransformer()), ('basreg', linear_model.BayesianRidge())]": 1,
      "[('vectorizer', TfidfVectorizer(max_df=0.85, norm='l2')), ('LinearSvr', svm.LinearSVR())]": 1,
      "[('vectorizer', TfidfVectorizer(max_df=0.85, norm='l2')), ('KNN', neighbors.KNeighborsRegressor())]": 1,
      "[('vectorizer', TfidfVectorizer(max_df=0.85, norm='l2')), ('DTR', tree.DecisionTreeRegressor())]": 1,
      "[('feature-engineering', FunctionTransformer(pre_process)), ('data-prep', ct), ('robust-scaler', RobustScaler()), ('model', model)]": 1,
      "[('pca', PCA(n_components=256)), ('reg', LinearRegressionTransformer()), ('cal', Calibrator())]": 1,
      "p.steps[:-1]": 1,
      "pipeline_list_1": 1,
      "pipeline_list_2": 1,
      "pipeline_list_3": 1,
      "pipeline_list_4": 1,
      "pipeline_list_5": 1,
      "pipeline_list_1 + pipe_list_1_rf": 1,
      "pipeline_list_2 + pipe_list_2_rf": 1,
      "[('Scaler', std_sca), (first_model_names[n], first_models[n])]": 1,
      "[('categorical_transform', ct), ('one hot', OneHotTransform())]": 1,
      "[('trans', CategoricalTransform(cat_cols)), ('lgbm', LGBMClassifier(n_jobs=-2))]": 1,
      "[('trans', IntegerCategoricalTransform(cat_cols=cat_cols)), ('xgboost', xgb)]": 1,
      "[('trans', CategoricalTransform(cat_cols=cat_cols)), ('oht', OneHotTransform()), ('xgboost', xgb)]": 1,
      "[('trans', IntegerCategoricalTransform(cat_cols=cat_cols)), ('rf', rf)]": 1,
      "[('trans', CategoricalTransform(cat_cols=cat_cols)), ('oht', OneHotTransform()), ('rf', rf)]": 1,
      "[('trans', NonNegativeIntegerCategoricalTransform(cat_cols=cat_cols)), ('catnb', catnb)]": 1,
      "[('trans', CategoricalTransform(cat_cols=cat_cols)), ('oht', OneHotTransform()), ('lr', LogisticRegression(n_jobs=-2))]": 1,
      "[('cat_trans', CategoricalTransform(cat_cols)), ('lgbm', LGBMRegressor(n_jobs=-2))]": 1,
      "[('cat_trans', IntegerCategoricalTransform(cat_cols)), ('cb', CatBoostRegressor(iterations=50, thread_count=3, cat_features=cat_cols))]": 1,
      "[('cat_trans', CategoricalTransform(cat_cols)), ('oh_trans', OneHotTransform())]": 1,
      "[('oh_trans', oh_pipe), ('rf', RandomForestRegressor(n_jobs=-2))]": 1,
      "[('scaler', None), ('reduce_dim', PCA()), ('regressor', None)]": 1,
      "[('scaler', None), ('reduce_dim', PCA()), ('regressor', SVR())]": 1,
      "[('scaler', StandardScaler()), ('reduce_dim', PCA(n_components=25)), ('regressor', SVR(C=8.0, kernel='linear'))]": 1,
      "[('delete_inessential_columns', DeleteInessentialColumns())]": 1,
      "[('data_cleaning', data_cleaning_pipeline), ('categorical', one_hot_columns), ('imputer', SimpleImputer(strategy='median')), ('scale', StandardScaler())]": 1,
      "[('LogisticRegression pipline', full_pipline_LR), ('LogisticRegression', log_reg)]": 1,
      "[('BernoulliNB pipeline', full_pipline_BNB), ('BernoulliNB', bernoulli_nb)]": 1,
      "[('DecisionTree pipline', full_pipline_DT), ('DecisionTree', DT_clf)]": 1,
      "[('LinearSVC pipline', full_pipline_SVC), ('LinearSVC', svc_clf)]": 1,
      "[('scl', StandardScaler()), ('est', KNeighborsClassifier())]": 1,
      "[('scl', StandardScaler()), ('est', DecisionTreeClassifier(random_state=1))]": 1,
      "[('scl', StandardScaler()), ('est', RandomForestClassifier(random_state=1))]": 1,
      "[('scl', StandardScaler()), ('est', lgb.LGBMClassifier())]": 1,
      "[('inf_extor', InfoExtractor(field=TEXT_FIELDS, replace=True)), ('txt_encoder', TextEncoder(replace=True))]": 1,
      "[('num_filter', NumberFilter()), ('imputer', SimpleImputer(strategy='median')), ('mm_scaler', MinMaxScaler(feature_range=(-1, 1)))]": 1,
      "[('cat_filter', CategoryFilter()), ('imputer', SimpleImputer(strategy='constant', fill_value='Missing'))]": 1,
      "[('preprocessor', preprocessor), ('model', my_model)]": 1,
      "[('UnionInput', FeatureUnion([('svd', svd), ('dense_features', FeatureInserter())])), ('scl', scl), ('svm', logistic_model)]": 1,
      "[('UnionInput', FeatureUnion([('svd', svd), ('dense_features', FeatureInserter())])), ('scl', scl), ('logreg', LogisticRegression(C=10))]": 1,
      "[('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))]": 1,
      "[('pclass_enc', OrdinalEncoder(categories=[[1, 2, 3]]))]": 1,
      "[('fillna', SimpleImputer(missing_values=np.nan, strategy='mean'))]": 1,
      "[('feature_engineer', features), ('scaler', StandardScaler()), ('model', LogisticRegression())]": 1,
      "[('forest', RandomForestClassifier(n_estimators=n_estimators, random_state=random_state, n_jobs=n_jobs))]": 1,
      "[('onehotencoder', OneHotEncoder(handle_unknown='ignore'))]": 1,
      "[('cleaner', predictors()), ('vectorizer', CountVectorizer(tokenizer=spacy_tokenizer, ngram_range=(1, 3))), ('classifier', SVC())]": 1,
      "[('cleaner', predictors()), ('vectorizer', CountVectorizer(tokenizer=spacy_tokenizer, ngram_range=(1, 3))), ('clf', MultinomialNB())]": 1,
      "[('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())]": 1,
      "[('vect', stemmed_count_vect), ('tfidf', TfidfTransformer()), ('mnb', MultinomialNB(fit_prior=False))]": 1,
      "[('Encoding', CustomEncoder()), ('scaler', CustomScaler())]": 1,
      "[('scaler', StandardScaler()), ('linear_svc', LinearSVC(C=10, loss='hinge'))]": 1,
      "[('s', rfe_lgb), ('m', LGBMRegressor(**parms))]": 1,
      "[('s', rfe_estimator), ('m', XGBRegressor(**params))]": 1,
      "[('preprocess', preprocessing), ('classifier', RandomForestClassifier())]": 1,
      "[('preprocess', preprocessing), ('classifier', xgb.XGBClassifier())]": 1,
      "[('preprocess', preprocessing), ('sc', sc), ('classifier', LogisticRegression(penalty='l2'))]": 1,
      "[('vec', CountVectorizer()), ('clf', LogisticRegression())]": 1,
      "[('scaler', scaler), ('linear_svc', svm_clf)]": 1,
      "[('std_scaler', StandardScaler()), ('kmeans', KMeans(n_clusters=5))]": 1,
      "[('std_scaler', StandardScaler()), ('grid_converter', GridConverter()), ('knn', KNeighborsClassifier(n_neighbors=5))]": 1,
      "[('imputer', imputer()), ('add_features', addFeatures()), ('drop_features', dropFeatures(['object_id', 'hostgal_specz'])), ('customModel', customModel())]": 1,
      "[('pre', None), ('feature_selection', None), ('clf', LogisticRegression(solver='liblinear'))]": 1,
      "[('imputer', imputer), ('consolidator', Consolidator(idx=idx_imputed)), ('feature_creator', FeatureCreator(idx=idx_imputed)), ('binary_creator', BinaryCreator(idx=idx_imputed))]": 1,
      "[('drop', ColumnDropper(drop_idx)), ('encode', one_hot_encoder), ('selector', FeatureSelector())]": 1,
      "[('feature_engineering', feat_eng_pipeline), ('feature_selection', feat_sel_pipeline)]": 1,
      "[('preprocessing', preprocessing_pipeline), ('regressor', regressor)]": 1,
      "[('vect', CountVectorizer(min_df=157, ngram_range=(1, 3), stop_words='english')), ('tfidf', TfidfTransformer()), ('clf', SGDRegressor(loss='squared_loss', penalty='l2', alpha=0.001, random_state=42, max_iter=40, tol=None, shuffle=True))]": 1,
      "[('tfidf', TfidfVectorizer(tokenizer=text_cleaning)), ('clf', LinearSVC())]": 1,
      "[('svd', svd), ('calibrated_rf', calibrated_rf)]": 1,
      "[('tfidf', TfidfVectorizer(stop_words=stop_words, ngram_range=(1, 3))), ('classifier', LogisticRegression())]": 1,
      "[('selector', NumberSelector(key='num_unique_words')), ('standard', StandardScaler())]": 1,
      "[('selector', NumberSelector(key='num_chars')), ('standard', StandardScaler())]": 1,
      "[('selector', NumberSelector(key='num_words_upper')), ('standard', StandardScaler())]": 1,
      "[('selector', NumberSelector(key='num_words_title')), ('standard', StandardScaler())]": 1,
      "[('rfr', RandomForestRegressor(random_state=2017))]": 1,
      "[('classifier', RandomForestClassifier(random_state=42))]": 1,
      "[('model2', model2)]": 1,
      "[('vect', vect), ('model', model)]": 1,
      "[('union', FeatureUnion(transformer_list=[('cst', cust_regression_vals()), ('txt1', pipeline.Pipeline([('s1', cust_txt_col(key='search_term')), ('tfidf1', tfidf), ('tsvd1', tsvd)])), ('txt2', pipeline.Pipeline([('s2', cust_txt_col(key='product_title')), ('tfidf2', tfidf), ('tsvd2', tsvd)])), ('txt3', pipeline.Pipeline([('s3', cust_txt_col(key='product_description')), ('tfidf3', tfidf), ('tsvd3', tsvd)])), ('txt4', pipeline.Pipeline([('s4', cust_txt_col(key='brand')), ('tfidf4', tfidf), ('tsvd4', tsvd)])), ('txt5', pipeline.Pipeline([('s5', cust_txt_col(key='material')), ('tfidf5', tfidf), ('tsvd5', tsvd)])), ('txt6', pipeline.Pipeline([('s6', cust_txt_col(key='color')), ('tfidf6', tfidf), ('tsvd6', tsvd)]))], transformer_weights={'cst': 1.0, 'txt1': 0.5, 'txt2': 0.25, 'txt3': 0.0, 'txt4': 0.5, 'txt5': 0.5, 'txt6': 0.5}, n_jobs=1)), ('rfr', rfr)]": 1,
      "[('s5', cust_txt_col(key='material')), ('tfidf5', tfidf), ('tsvd5', tsvd)]": 1,
      "[('s6', cust_txt_col(key='color')), ('tfidf6', tfidf), ('tsvd6', tsvd)]": 1,
      "[('union', FeatureUnion(transformer_list=[('transform_text', Pipeline([('select_column', ColumnSelector(key='Text')), ('tfidf', TfidfVectorizer(analyzer='word', max_df=0.9, stop_words='english', norm='l2', sublinear_tf=True, use_idf=True)), ('svd', TruncatedSVD(algorithm='randomized', n_components=100))])), \"\\n            ('transform_categories',\\n             Pipeline([\\n                 ('select_columns', ColumnSelector(key=['Gene', 'Variation'])),\\n                 ('dummy_mca', DummyMCA(n_factors=207)),\\n             ]),\\n             ),\\n             \"('transform_categories', Pipeline([('select_columns', ColumnSelector(key=['Gene', 'Variation'])), ('get_dummy', GetDummies())]))])), ('xgb', XGBClassifier(learning_rate=0.13, n_estimators=55, max_depth=5, min_child_weight=8, gamma=0, subsample=0.9, colsample_bytree=0.6, objective='multi:softprob', nthread=4, scale_pos_weight=1, reg_alpha=0.0001, seed=7))]": 1,
      "[('select_column', ColumnSelector(key='Text')), ('tfidf', TfidfVectorizer(analyzer='word', max_df=0.9, stop_words='english', norm='l2', sublinear_tf=True, use_idf=True)), ('svd', TruncatedSVD(algorithm='randomized', n_components=100))]": 1,
      "[('select_columns', ColumnSelector(key=['Gene', 'Variation'])), ('get_dummy', GetDummies())]": 1,
      "[('preprocessor', preprocessor), ('model', RandomForestClassifier(n_estimators=50, random_state=1, max_depth=3))]": 1,
      "[('preprocessor', preprocessor), ('model', RandomForestClassifier(random_state=1))]": 1,
      "[('preprocessor', preprocessor), ('model', XGBClassifier(random_state=1, n_estimators=1000, learning_rate=0.01, early_stopping_rounds=5, eval_metric='logloss', subsample=0.8, max_depth=5))]": 1,
      "[('count', countVectorizer), ('tfid', TfidfTransformer())]": 1,
      "[('email_to_wordcount', MessageToWordCounterTransform()), ('wordcount_to_vector', WordCounterToVectorTransformer())]": 1,
      "[('scaler', StandardScaler()), ('poly_fs', PolynomialFeatures(degree=3)), ('pca', PCA(n_components=3))]": 1,
      "[('imputer', SimpleImputer(strategy='constant', fill_value='-1')), ('ordinal_encoder', OrdinalEncoder())]": 1,
      "[('preprocessor', preprocessor), ('clf', LinearSVC(loss='hinge'))]": 1,
      "[('polynomial_features', PolynomialFeatures(degree=2)), ('linear_regression', linear_model.Ridge())]": 1,
      "[('bow', CountVectorizer(analyzer=text_process)), ('tfidf', TfidfTransformer()), ('Classifier', MultinomialNB())]": 1,
      "[('feat_eng', feature_engineer), ('na_imputer', na_imputer), ('drop_cols', column_dropper), ('cat_enc', cat_encoder), ('num_sca', num_scaler)]": 1,
      "[('tfidf', TfidfVectorizer()), ('clf', SGDClassifier())]": 1,
      "[('vec', feature_extraction.text.TfidfVectorizer()), ('clf', svm_clf)]": 1,
      "[('vec', feature_extraction.text.TfidfVectorizer(tokenizer=tokenizer)), ('clf', svm_clf)]": 1,
      "[('vec', feature_extraction.text.TfidfVectorizer(stop_words=stop_words)), ('clf', svm_clf)]": 1,
      "[('log', LoggingTransformer('Starting transformer/classification pipeline')), ('preprocess', Preprocess()), ('first_union', FeatureUnion([('name', Pipeline([('selector', ItemSelector('name')), ('transformer', FillNa('Unknown')), ('vectorizer', TfidfVectorizer(use_idf=False, min_df=3, token_pattern='(?u)\\\\b\\\\w+\\\\b', analyzer='word', ngram_range=(1, 3), strip_accents='ascii', stop_words=stopwords.words('english'))), ('log', LoggingTransformer('End of name')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log2', LoggingTransformer('End of name vt'))])), ('name2', Pipeline([('selector', ItemSelector('name')), ('transformer', FillNa('null')), ('lowalphanum', LowAlphaNum()), ('vectorizer', TfidfVectorizer(use_idf=False, min_df=3, analyzer='char', ngram_range=(2, 6), strip_accents='ascii')), ('log', LoggingTransformer('End of name char')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log2', LoggingTransformer('End of name char vt'))])), ('item_description', Pipeline([('selector', ItemSelector('item_description')), ('transformer', FillNa('No description yet')), ('vectorizer', TfidfVectorizer(use_idf=False, min_df=3, token_pattern='(?u)\\\\b\\\\w+\\\\b', analyzer='word', ngram_range=(1, 3), strip_accents='ascii', stop_words=stopwords.words('english'))), ('log', LoggingTransformer('End of item_description')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log2', LoggingTransformer('End of item_description vt'))])), ('item_condition_id', Pipeline([('selector', ItemSelector(['item_condition_id'])), ('transformer', FillNa(9999)), ('ohe', OneHotEncoder(handle_unknown='ignore')), ('log', LoggingTransformer('End of item_condition_id'))])), ('item_condition_id_2', Pipeline([('selector', ItemSelector(['item_condition_id'])), ('log', LoggingTransformer('End of item_condition_id_2'))])), ('category_name', Pipeline([('selector', ItemSelector('category_name')), ('transformer', FillNa('Unknown')), ('vectorizer', CountVectorizer(token_pattern='[^/]+', min_df=3, binary=True, analyzer='word', ngram_range=(1, 5), strip_accents='ascii')), ('log', LoggingTransformer('End of category_name'))])), ('category_name_2', Pipeline([('selector', ItemSelector('category_name')), ('transformer', FillNa('Unknown')), ('vectorizer', CountVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b', min_df=3, binary=True, analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of category_name 2'))])), ('brand_name', Pipeline([('be', BrandExtractor()), ('vectorizer', CountVectorizer(token_pattern='.+', min_df=3, binary=True, analyzer='word', ngram_range=(1, 1), strip_accents='ascii')), ('log', LoggingTransformer('End of brand'))])), ('brand_name_2', Pipeline([('selector', ItemSelector('brand_name')), ('transformer', FillNa('Unknown')), ('vectorizer', CountVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b', min_df=3, binary=True, analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of brand 2'))])), ('shipping', Pipeline([('selector', ItemSelector(['shipping'])), ('log', LoggingTransformer('End of shipping'))]))], n_jobs=1)), ('log2', LoggingTransformer('End of first union')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log3', LoggingTransformer('Variance eliminated, end of pipeline'))]": 1,
      "[('selector', ItemSelector('name')), ('transformer', FillNa('Unknown')), ('vectorizer', TfidfVectorizer(use_idf=False, min_df=3, token_pattern='(?u)\\\\b\\\\w+\\\\b', analyzer='word', ngram_range=(1, 3), strip_accents='ascii', stop_words=stopwords.words('english'))), ('log', LoggingTransformer('End of name')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log2', LoggingTransformer('End of name vt'))]": 1,
      "[('selector', ItemSelector('item_description')), ('transformer', FillNa('No description yet')), ('vectorizer', TfidfVectorizer(use_idf=False, min_df=3, token_pattern='(?u)\\\\b\\\\w+\\\\b', analyzer='word', ngram_range=(1, 3), strip_accents='ascii', stop_words=stopwords.words('english'))), ('log', LoggingTransformer('End of item_description')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log2', LoggingTransformer('End of item_description vt'))]": 1,
      "[('be', BrandExtractor()), ('vectorizer', CountVectorizer(token_pattern='.+', min_df=3, binary=True, analyzer='word', ngram_range=(1, 1), strip_accents='ascii')), ('log', LoggingTransformer('End of brand'))]": 1,
      "[('log', LoggingTransformer('Starting feature extraction pipeline')), ('first_union', FeatureUnion([('name', Pipeline([('selector', ItemSelector('name')), ('transformer', FillNa('Unknown')), ('vectorizer', TfidfVectorizer(use_idf=False, min_df=10, token_pattern='(?u)\\\\b\\\\w+\\\\b', analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of name')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log2', LoggingTransformer('End of name vt'))])), ('name2', Pipeline([('selector', ItemSelector('name')), ('transformer', FillNa('Unknown')), ('vectorizer', MixedTfidfVectorizer(use_idf=False, min_df=10, token_pattern='(?u)\\\\b\\\\w+\\\\b', analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of name2')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log2', LoggingTransformer('End of name2 vt'))])), ('item_description', Pipeline([('selector', ItemSelector('item_description')), ('transformer', FillNa('No description yet')), ('vectorizer', TfidfVectorizer(use_idf=False, min_df=10, token_pattern='(?u)\\\\b\\\\w+\\\\b', analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of item_description')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log2', LoggingTransformer('End of item_description vt'))])), ('item_condition_id', Pipeline([('selector', ItemSelector(['item_condition_id'])), ('transformer', FillNa(9999)), ('ohe', OneHotEncoder(handle_unknown='ignore')), ('log', LoggingTransformer('End of item_condition_id'))])), ('item_condition_id_2', Pipeline([('selector', ItemSelector(['item_condition_id'])), ('log', LoggingTransformer('End of item_condition_id_2'))])), ('category_name', Pipeline([('selector', ItemSelector('category_name')), ('transformer', FillNa('Unknown')), ('vectorizer', CountVectorizer(token_pattern='[^/]+', min_df=3, binary=True, analyzer='word', ngram_range=(1, 5), strip_accents='ascii')), ('log', LoggingTransformer('End of category_name'))])), ('category_name_2', Pipeline([('selector', ItemSelector('category_name')), ('transformer', FillNa('Unknown')), ('vectorizer', CountVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b', min_df=3, binary=True, analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of category_name 2'))])), ('brand_name', Pipeline([('selector', ItemSelector('brand_name')), ('transformer', FillNa('Unknown')), ('vectorizer', CountVectorizer(token_pattern='.+', min_df=3, binary=True, analyzer='word', ngram_range=(1, 1), strip_accents='ascii')), ('log', LoggingTransformer('End of brand'))])), ('brand_name_2', Pipeline([('selector', ItemSelector('brand_name')), ('transformer', FillNa('Unknown')), ('vectorizer', CountVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b', min_df=3, binary=True, analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of brand 2'))])), ('shipping', Pipeline([('selector', ItemSelector(['shipping'])), ('log', LoggingTransformer('End of shipping'))]))], n_jobs=-1)), ('log2', LoggingTransformer('End of first union')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('var', TopVariance(3000000)), ('log3', LoggingTransformer('Variance eliminated, end of pipeline'))]": 1,
      "[('selector', ItemSelector('name')), ('transformer', FillNa('Unknown')), ('vectorizer', TfidfVectorizer(use_idf=False, min_df=10, token_pattern='(?u)\\\\b\\\\w+\\\\b', analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of name')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log2', LoggingTransformer('End of name vt'))]": 1,
      "[('selector', ItemSelector('name')), ('transformer', FillNa('Unknown')), ('vectorizer', MixedTfidfVectorizer(use_idf=False, min_df=10, token_pattern='(?u)\\\\b\\\\w+\\\\b', analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of name2')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log2', LoggingTransformer('End of name2 vt'))]": 1,
      "[('selector', ItemSelector('item_description')), ('transformer', FillNa('No description yet')), ('vectorizer', TfidfVectorizer(use_idf=False, min_df=10, token_pattern='(?u)\\\\b\\\\w+\\\\b', analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of item_description')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log2', LoggingTransformer('End of item_description vt'))]": 1,
      "[('log', LoggingTransformer('Starting transformer/classification pipeline')), ('first_union', FeatureUnion([('name', Pipeline([('selector', ItemSelector('name')), ('transformer', FillNa('Unknown')), ('vectorizer', TfidfVectorizer(use_idf=False, min_df=3, token_pattern='(?u)\\\\b\\\\w+\\\\b', analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of name')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log2', LoggingTransformer('End of name vt'))])), ('name2', Pipeline([('selector', ItemSelector('name')), ('transformer', FillNa('null')), ('lowalphanum', LowAlphaNum()), ('vectorizer', TfidfVectorizer(use_idf=False, min_df=3, analyzer='char', ngram_range=(2, 6), strip_accents='ascii')), ('log', LoggingTransformer('End of name char')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log2', LoggingTransformer('End of name char vt'))])), ('item_description', Pipeline([('selector', ItemSelector('item_description')), ('transformer', FillNa('No description yet')), ('vectorizer', TfidfVectorizer(use_idf=False, min_df=3, token_pattern='(?u)\\\\b\\\\w+\\\\b', analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of item_description')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log2', LoggingTransformer('End of item_description vt'))])), ('item_condition_id', Pipeline([('selector', ItemSelector(['item_condition_id'])), ('transformer', FillNa(9999)), ('ohe', OneHotEncoder(handle_unknown='ignore')), ('log', LoggingTransformer('End of item_condition_id'))])), ('item_condition_id_2', Pipeline([('selector', ItemSelector(['item_condition_id'])), ('imputer', Imputer()), ('log', LoggingTransformer('End of item_condition_id_2'))])), ('category_name', Pipeline([('selector', ItemSelector('category_name')), ('transformer', FillNa('Unknown')), ('vectorizer', CountVectorizer(token_pattern='[^/]+', min_df=3, binary=True, analyzer='word', ngram_range=(1, 5), strip_accents='ascii')), ('log', LoggingTransformer('End of category_name'))])), ('category_name_2', Pipeline([('selector', ItemSelector('category_name')), ('transformer', FillNa('Unknown')), ('vectorizer', CountVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b', min_df=3, binary=True, analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of category_name 2'))])), ('brand_name', Pipeline([('selector', ItemSelector('brand_name')), ('transformer', FillNa('Unknown')), ('vectorizer', CountVectorizer(token_pattern='.+', min_df=3, binary=True, analyzer='word', ngram_range=(1, 1), strip_accents='ascii')), ('log', LoggingTransformer('End of brand'))])), ('brand_name_2', Pipeline([('selector', ItemSelector('brand_name')), ('transformer', FillNa('Unknown')), ('vectorizer', CountVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b', min_df=3, binary=True, analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of brand 2'))])), ('shipping', Pipeline([('selector', ItemSelector(['shipping'])), ('imputer', Imputer()), ('log', LoggingTransformer('End of shipping'))]))], n_jobs=1)), ('log2', LoggingTransformer('End of first union')), ('log3', LoggingTransformer('Variance eliminated, end of pipeline'))]": 1,
      "[('selector', ItemSelector('name')), ('transformer', FillNa('Unknown')), ('vectorizer', TfidfVectorizer(use_idf=False, min_df=3, token_pattern='(?u)\\\\b\\\\w+\\\\b', analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of name')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log2', LoggingTransformer('End of name vt'))]": 1,
      "[('selector', ItemSelector('item_description')), ('transformer', FillNa('No description yet')), ('vectorizer', TfidfVectorizer(use_idf=False, min_df=3, token_pattern='(?u)\\\\b\\\\w+\\\\b', analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of item_description')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log2', LoggingTransformer('End of item_description vt'))]": 1,
      "[('selector', ItemSelector(['item_condition_id'])), ('imputer', Imputer()), ('log', LoggingTransformer('End of item_condition_id_2'))]": 1,
      "[('selector', ItemSelector(['shipping'])), ('imputer', Imputer()), ('log', LoggingTransformer('End of shipping'))]": 1,
      "[('const_imputer', SimpleImputer(strategy='constant', fill_value='Abs')), ('cat_encoder', OneHotEncoder(handle_unknown='ignore'))]": 1,
      "[('const_imputer', SimpleImputer(strategy='constant', fill_value='Abs')), ('ord_encoder', OrdinalEncoder(handle_unknown='ignore'))]": 1,
      "[('preprocessor', preprocessor), ('PCA', PCA(n_components=23)), ('regressor', RandomForestRegressor())]": 1,
      "[('Vec', CountVectorizer(tokenizer=lambda x: x.split())), ('Clf', SGDClassifier(max_iter=1000, random_state=0))]": 1,
      "[('wordVectz', AverageEmbeddingVectorizer(WordVectorz)), ('multilabel', OneVsRestClassifier(LinearSVC(random_state=0)))]": 1,
      "[('TFidf', TfidfVectorizer()), ('multilabel', OneVsRestClassifier(LinearSVC(random_state=0)))]": 1,
      "[('Scaler', StandardScaler()), ('LogReg', LogisticRegression())]": 1,
      "[('Scaler', StandardScaler()), ('RidgeClassifier', RidgeClassifier())]": 1,
      "[('Scaler', StandardScaler()), ('BaggingClassifier', BaggingClassifier())]": 1,
      "[('preprocessor', preprocessor), ('model', model_1)]": 1,
      "[('id_select', SelectColumnsTransfomer(['train_id']))]": 1,
      "[('name_select', SelectColumnsTransfomer(['name'])), ('To1DArrayTransfomer', To1DArrayTransfomer()), ('TfidfVectorizer', TfidfVectorizer(stop_words='english')), ('TruncatedSVD', TruncatedSVD(n_components=n_comp_name, algorithm='arpack'))]": 1,
      "[('item_descriptione_select', SelectColumnsTransfomer(['item_description'])), ('rvm_nans', removeNull('No decription')), ('To1DArrayTransfomer', To1DArrayTransfomer()), ('TfidfVectorizer', TfidfVectorizer(stop_words='english')), ('TruncatedSVD', TruncatedSVD(n_components=n_comp_description, algorithm='arpack'))]": 1,
      "[('category_name_select', SelectColumnsTransfomer(['category_name'])), ('category_spliting', CategorySplitingTransformer())]": 1,
      "[('category_spliting_pipeline', category_spliting_pipeline), ('select_col', select_col(n=0)), ('to_labels', LabelBinarizer_new())]": 1,
      "[('category_spliting_pipeline', category_spliting_pipeline), ('select_col', select_col(n=1)), ('to_labels', LabelBinarizer_new())]": 1,
      "[('category_spliting_pipeline', category_spliting_pipeline), ('select_col', select_col(n=2)), ('to_labels', LabelBinarizer_new())]": 1,
      "[('item_condition_id_select', SelectColumnsTransfomer(['item_condition_id'])), ('to_labels', LabelBinarizer_new())]": 1,
      "[('brand_name_select', SelectColumnsTransfomer(['brand_name'])), ('rvm_nans', removeNull('No brand')), ('to_labels', LabelBinarizer_new())]": 1,
      "[('shipping_select', SelectColumnsTransfomer(['shipping']))]": 1,
      "[('all_feature_pipeline', all_feature_pipeline), ('RandomForestRegressor', RandomForestRegressor(n_jobs=-1, min_samples_leaf=3, n_estimators=200))]": 1,
      "[('cat_selector', FeatureSelector(categorical_features)), ('onehot_encoder', ce.OneHotEncoder())]": 1,
      "[('numeric_selector', FeatureSelector(numerical_features)), ('ordinal_encoder', ce.OrdinalEncoder())]": 1,
      "[('features', preprocessing_pipeline), ('scaler', StandardScaler()), ('log_reg_model', ClassifierChainEnsemble(base_classifier=lgbm))]": 1,
      "[('countVector', CountVectorizer()), ('tfidf', TfidfTransformer()), ('modelo', SGDClassifier())]": 1,
      "[('transformer', NumberTransformer(key='propn_count')), ('standard_scalar', StandardScaler())]": 1,
      "[('transformer', TextTransformer(key='no_stop')), ('vectorizer', TfidfVectorizer(ngram_range=(1, 3)))]": 1,
      "[('scaler', PCA(n_components=91, whiten=True)), ('clf', Ridge(alpha=5))]": 1,
      "[('clf', LGBMRegressor(num_leaves=30, learning_rate=0.05, n_estimators=900, subsample=0.8, colsample_bytree=1, random_state=42, min_child_samples=10, n_jobs=-1))]": 1,
      "[('scaler', PCA(n_components=25, whiten=True)), ('clf', MLPRegressor(hidden_layer_sizes=(50, 20, 15), early_stopping=True))]": 1,
      "[('selector', DataFrameSelector(numeric_features))]": 1,
      "[('numeric_pipeline', numeric_pipeline), ('estimator', SGDRegressor(max_iter=100, verbose=1, shuffle=True, early_stopping=True, alpha=0.0003, learning_rate='invscaling', penalty='l2'))]": 1,
      "[('pca', PCA(n_components=4)), ('GBR', GradientBoostingClassifier())]": 1,
      "[('selection', VarianceThreshold(threshold=1.3))]": 1,
      "[('imputer', SimpleImputer(strategy='constant'))]": 1,
      "[('cp', CustomProcessor()), ('preprocessor', preprocessor), ('model', xg_model_)]": 1,
      "[('cp', CustomProcessor()), ('preprocessor', preprocessor), ('model', xg_model)]": 1,
      "[('preprocess', CustomPreprocessor()), ('model', ex_model)]": 1,
      "[('preprocess', CustomPreprocessor()), ('model', xg_model)]": 1,
      "[('scaler2', StandardScaler()), ('RandomForestRegressor:', RandomForestRegressor())]": 1,
      "[('Encoder', TargetEncoder(cols=cols, smoothing=0.1, min_samples_leaf=100)), ('Estimator', LogisticRegression(solver='liblinear'))]": 1,
      "(('pca', PCA(n_components=70)), ('classifier', SVC(kernel='rbf')))": 1,
      "(('pca', PCA(n_components=80)), ('classifier', RandomForestClassifier()))": 1,
      "(('pca', PCA(n_components=40)), ('classifier', DecisionTreeClassifier(max_depth=10)))": 1,
      "[('Scaler', StandardScaler()), ('Votings', VotingRegressor([('XGBoostR', XGBR_grid.best_estimator_), ('AdaBoostR', AdaBoostR_grid.best_estimator_), ('Ridge', ridge_grid.best_estimator_)]))]": 1,
      "[('Scaler', StandardScaler()), ('Votings', VotingRegressor([('XGBoostR', XGBR_grid.best_estimator_), ('Ridge', ridge_grid.best_estimator_)]))]": 1,
      "[('Scaler', StandardScaler()), ('Votings', VotingRegressor([('AdaBoostR', AdaBoostR_grid.best_estimator_), ('Ridge', ridge_grid.best_estimator_)]))]": 1,
      "[('bow', TfidfVectorizer(analyzer=text_process, ngram_range=(1, 2))), ('tfidf', TfidfTransformer()), ('classifier', MultinomialNB())]": 1,
      "[('bow', TfidfVectorizer(analyzer=text_process, ngram_range=(1, 2), max_df=0.8)), ('tfidf', TfidfTransformer()), ('classifier', SGDClassifier(loss='hinge', penalty='l2', alpha=0.001, random_state=42, max_iter=5, tol=None))]": 1,
      "estimator_1": 1,
      "[('preprocessor', preprocessor), ('minmaxscaler', MinMaxScaler()), ('stdscaler', StandardScaler()), ('regressor', DecisionTreeRegressor(random_state=0, criterion='mse'))]": 1,
      "[('preprocessor', preprocessor), ('minmaxscaler', MinMaxScaler()), ('stdscaler', StandardScaler()), ('regressor', DecisionTreeRegressor(random_state=0, criterion='mse', max_depth=max_depth))]": 1,
      "[('preprocessor', preprocessor), ('minmaxscaler', MinMaxScaler()), ('stdscaler', StandardScaler()), ('regressor', decision_tree_regressor)]": 1,
      "[('tdfidf', TfidfVectorizer(analyzer='word', binary=False, ngram_range=(1, 4), stop_words='english')), ('svd', TruncatedSVD(algorithm='randomized', n_components=20, n_iter=10, random_state=None, tol=0.0))]": 1,
      "[('classify', RandomForestClassifier(random_state=10, max_features='sqrt'))]": 1,
      "[('scl', StandardScaler()), ('est', LGBMClassifier())]": 1,
      "[('quantile', QuantileTransformer(**params_quantile)), ('logreg', LogisticRegression(**params_logreg))]": 1,
      "[('encode', CountEncoder(cols=['cp_type', 'cp_dose'])), ('classify', classifier)]": 1,
      "[('ohe', OneHotEncoder(categories='auto', handle_unknown='ignore')), ('classifier', classifier)]": 1,
      "[('features', ColumnTransformer([('k', TfidfVectorizer(stop_words=STOP_WORDS), 'keyword'), ('t', TfidfVectorizer(stop_words=STOP_WORDS), 'text')])), ('svc', GridSearchCV(LinearSVC(), param_grid={'C': np.logspace(0.01, 1, 10)}, cv=5))]": 1,
      "[('features', ColumnTransformer([('k', TfidfVectorizer(stop_words=STOP_WORDS, tokenizer=lemmatizer), 'keyword'), ('t', TfidfVectorizer(stop_words=STOP_WORDS, tokenizer=lemmatizer), 'text')])), ('svc', GridSearchCV(LinearSVC(), param_grid={'C': np.logspace(0.01, 1, 10)}, cv=5))]": 1,
      "[('add_has_name', has_field_transformer(column_name='Name', new_column_name='hasName')), ('add_is_free', value_matches_transformer(column_name='Fee', new_column_name='isFree', matches=lambda value: value < 1)), ('map_type_to_species', map_categories(column_name='Type', mapping_dict={1: 'dog', 2: 'cat'})), ('map_gender_to_names', map_categories(column_name='Gender', mapping_dict={1: 'male', 2: 'female', 3: 'mixed'})), ('truncate_breed1', truncate_categorical(column_name='Breed1', n_values_to_keep=10)), ('truncate_breed2', truncate_categorical(column_name='Breed2', n_values_to_keep=10)), ('truncate_state', truncate_categorical(column_name='State', n_values_to_keep=10)), ('truncate_rescuer_id', truncate_categorical(column_name='RescuerID', n_values_to_keep=10)), ('onehot_encode', CategoricalToOneHotEncoder(columns=ONEHOT_ENCODED_COLUMNS)), ('drop_unused_columns', DataFrameColumnDropper(column_names=['PetID', 'Description', 'Type_dog'])), ('pick_columns_by_importance', ColumnByFeatureImportancePicker(n_features=None))]": 1,
      "[('to_numpy', DataFrameToValuesTransformer()), ('scaler', StandardScaler())]": 1,
      "[('preprocessing', preprocessing_pipeline), ('preparation', preparation_pipeline), ('classifier', classifier)]": 1,
      "[('impute_sentiment_magnitude', ColumnImputer(column_name='SentimentMagnitude', imputer=SimpleImputer(strategy='constant', fill_value=0.0))), ('impute_sentiment_score', ColumnImputer(column_name='SentimentScore', imputer=SimpleImputer(strategy='constant', fill_value=0.0))), ('drop_unused_columns', DataFrameColumnDropper(column_names=['PetID', 'Description', 'RescuerID']))]": 1,
      "[('preprocessing', preprocessing_pipeline), ('classifier', CatBoostPandasClassifier(verbose=0, loss_function='MultiClass', allow_writing_files=False, task_type=task_type))]": 1,
      "[['ord_encoder', ct], ['rfe', RFE(estimator=xgb.XGBRegressor(tree_method='gpu_hist', random_state=11, n_jobs=-1), n_features_to_select=22)], ['regressor', xgb.XGBRegressor(tree_method='gpu_hist', random_state=11, n_jobs=-1, max_depth=4, n_estimators=200, reg_lambda=100)]]": 1,
      "[['rfe', RFE(estimator=xgb_classifier)], ['classifier', xgb_classifier]]": 1,
      "[['rfe', RFE(n_features_to_select=41, estimator=xgb.XGBClassifier(random_state=11, eval_metric='auc', tree_method='gpu_hist', n_jobs=-1, use_label_encoder=False, scale_pos_weight=2.8))], ['classifier', xgb_classifier]]": 1,
      "[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('lgr', LogisticRegression(solver='sag'))]": 1,
      "[('features', FeatureUnion([('category', Pipeline([('selector', get_category_data)])), ('numeric', Pipeline([('selector', get_numeric_data), ('scale', MinMaxScaler())])), ('text', Pipeline([('selector', get_text_data), ('vect', CountVectorizer(tokenizer=tokenize)), ('tfidf', TfidfTransformer())]))])), ('clf', MultinomialNB())]": 1,
      "[('selector', get_category_data)]": 1,
      "[('selector', get_numeric_data), ('scale', MinMaxScaler())]": 1,
      "[('selector', get_text_data), ('vect', CountVectorizer(tokenizer=tokenize)), ('tfidf', TfidfTransformer())]": 1,
      "[('vect', vectorizer), ('tfidf', TfidfTransformer(smooth_idf=False))]": 1,
      "[('preprocessor', preprocessor), ('estimator', LinearRegression())]": 1,
      "[('extract', ColumnExtractor(columns='comment_text')), ('vec', TfidfVectorizerPlus()), ('nb_features', NBTransformer()), ('clf', LinearSVC())]": 1,
      "[('converting_datetime', DatetimeConverter()), ('create_binary_columns', BinaryEncoder()), ('drop_columns', drop_col), ('random_forest_regressor', RandomForestRegressor(n_estimators=300, bootstrap=True, max_depth=50, min_samples_leaf=2, min_samples_split=2, max_features='auto'))]": 1,
      "[('v', TfidfVectorizer(min_df=5, max_df=500, max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 2), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words='english')), ('svd', TruncatedSVD(n_components=350, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=9.0, kernel='rbf', gamma=0.0, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None))]": 1,
      "[('count', TfidfVectorizer(max_features=1000)), ('rfc', OneVsRestClassifier(RandomForestClassifier(n_estimators=200, random_state=11, class_weight='balanced')))]": 1,
      "[('scaler', StandardScaler()), ('nusvc', NuSVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=4, nu=0.6, coef0=0.08))]": 1,
      "[('v', TfidfVectorizer(min_df=5, max_df=500, max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 2), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words='english')), ('svd', TruncatedSVD(n_components=210, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=10.1, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None))]": 1,
      "[('select_numeric', DataFrameSelector(numerical_features)), ('imputer', SimpleImputer(strategy='median'))]": 1,
      "[('select_cat', DataFrameSelector(categorical_features)), ('imputer', MostFrequentImputer()), ('cat_encoder', OneHotEncoder(sparse=False))]": 1,
      "[('vect', CountVectorizer()), ('tsvd', TruncatedSVD()), ('clf', RidgeClassifier())]": 1,
      "pipe_input": 1,
      "[('preprocessor', preprocessor), ('Linear', LinearRegression())]": 1,
      "[('preprocessor', preprocessor), ('Ridge', Ridge(random_state=5))]": 1,
      "[('preprocessor', preprocessor), ('Lasso', Lasso(random_state=5))]": 1,
      "[('preprocessor', preprocessor), ('ElaNet', ElasticNet(random_state=5))]": 1,
      "[('preprocessor', preprocessor), ('BayesRidge', BayesianRidge(n_iter=500, compute_score=True))]": 1,
      "[('preprocessor', preprocessor), ('GBR', GradientBoostingRegressor(random_state=5))]": 1,
      "[('preprocessor', preprocessor), ('XGB', XGBRegressor(objective='reg:squarederror', metric='rmse', random_state=5, nthread=-1))]": 1,
      "[('preprocessor', preprocessor), ('LGBM', LGBMRegressor(objective='regression', metric='rmse', random_state=5))]": 1,
      "[('preprocessor', preprocessor), ('ADA', AdaBoostRegressor(DecisionTreeRegressor(), random_state=5, loss='exponential'))]": 1,
      "[('rbf', RBFSampler(random_state=0)), ('sgd', SGDClassifier(loss='log'))]": 1,
      "[('scaler', StandardScaler()), ('clf', estimator)]": 1,
      "[('inpute', imp_1), ('KNN1', KNN_1)]": 1,
      "[('inpute', imp_1), ('kbest', kbest), ('lr', LogisticRegression(solver='lbfgs'))]": 1,
      "[('inpute', imp_1), ('pca', pca), ('dst', DecisionTreeClassifier())]": 1,
      "[('preprocessor', preprocessor), ('GBR', GradientBoostingRegressor())]": 1,
      "[('preprocessor', preprocessor), ('XGB', XGBRegressor(objective='reg:squarederror'))]": 1,
      "[('preprocessor', preprocessor), ('LGBM', LGBMRegressor(objective='regression'))]": 1,
      "[('vectorizer', CountVectorizer(stop_words='english')), ('svm', SVC())]": 1,
      "[('nb_vectorizer', CountVectorizer(stop_words='english')), ('nb', MultinomialNB())]": 1,
      "[('poly', PolynomialFeatures(degree=2, include_bias=False)), ('linear', Ridge(random_state=0))]": 1,
      "[('v', TfidfVectorizer(min_df=5, max_df=500, max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 2), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words='english')), ('svd', TruncatedSVD(n_components=200, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=12.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None))]": 1,
      "[('transformer', ct), ('predictor', LinearRegression())]": 1,
      "[('transformer', ct), ('predictor', RidgeCV(alphas=np.logspace(-6, 6, 13)))]": 1,
      "[('transformer', ct), ('predictor', LassoCV(alphas=np.logspace(-6, 6, 13)))]": 1,
      "[('transformer', ct), ('predictor', RandomForestRegressor())]": 1,
      "[('transformer', ct), ('poly', PolynomialFeatures(2)), ('predictor', Lasso())]": 1,
      "(('standard_scaler', StandardScaler()), ('rf_tree', RandomForestRegressor()))": 1,
      "[('cv', CountVectorizer(analyzer='word', ngram_range=(1, 4), max_df=0.9)), ('clf', LogisticRegression(solver='saga', class_weight='balanced', C=0.45, max_iter=600, verbose=1, n_jobs=-1))]": 1,
      "[('cv', CountVectorizer(analyzer='word', ngram_range=(1, 4), max_df=0.9)), ('clf', LogisticRegression(solver='saga', class_weight='balanced', C=0.45, max_iter=300, verbose=1, n_jobs=-1))]": 1,
      "[('scaler', tml.DfScaler()), model]": 1,
      "[('scaler', tml.DfScaler()), ('Lgb', lgb.LGBMClassifier(n_estimators=200, learning_rate=0.05, reg_alpha=0.3, reg_lambda=1, subsample=0.7, n_jobs=-1))]": 1,
      "[('scl', df_p.df_scaler())] + [('forest', RandomForestClassifier(n_estimators=500, min_samples_split=40, min_samples_leaf=20, max_features='sqrt', n_jobs=4))]": 1,
      "[('fs', tml.DtypeSel('numeric')), ('imp', tml.DfImputer(strategy='median'))]": 1,
      "[('fs', tml.DtypeSel('category')), ('imp', tml.DfImputer(strategy='most_frequent')), ('dum', tml.Dummify(drop_first=True))]": 1,
      "[('proc', proc_pipe), ('model', xgb.XGBClassifier(n_estimators=10000, subsample=0.7, random_state=10, n_jobs=-1))]": 1,
      "[('pca', tml.DfPCA(n_components=0.95, random_state=24)), ('tree', DecisionTreeClassifier(random_state=34))]": 1,
      "[('pca', tml.DfPCA(n_components=0.95)), ('forest', forest)]": 1,
      "[('pca', tml.DfPCA(n_components=0.95)), ('xgb', boost)]": 1,
      "[('pca', tml.DfPCA(n_components=0.95, compress=True)), ('tree', DecisionTreeClassifier(random_state=34))]": 1,
      "[('proc', union_pipe), ('scl', tml.DfScaler())]": 1,
      "[('proc', union_pipe), ('scl', tml.DfScaler()), ('pca', tml.DfPCA(n_components=100))]": 1,
      "[('proc', union_pipe), ('scl', tml.DfScaler()), ('pca', tml.DfPCA(n_components=100, compress=True))]": 1,
      "[('proc', union_pipe), ('scl', tml.DfScaler()), ('pca', tml.DfPCA(n_components=100)), ('tree', DecisionTreeRegressor(max_depth=5, random_state=32))]": 1,
      "[('proc', union_pipe), ('scl', tml.DfScaler()), ('pca', tml.DfPCA(n_components=100, compress=False)), ('tree', DecisionTreeRegressor(max_depth=5, random_state=32))]": 1,
      "[('feature_selector', SelectPercentile(f_regression, percentile=70)), ('lr', LinearRegression(n_jobs=-1))]": 1,
      "[('feature_selector', SelectPercentile(f_regression, percentile=50)), ('scaler', StandardScaler()), ('clf', knn)]": 1,
      "[('scaler', MinMaxScaler()), ('pca', PCA())]": 1,
      "[('scaler', MinMaxScaler()), ('pca', PCA(n_components=0.95))]": 1,
      "[('selector', SelectKBest(f_regression)), ('model', RandomForestRegressor(random_state=42))]": 1,
      "[('selector', SelectKBest(f_regression)), ('model', DecisionTreeRegressor(random_state=42))]": 1,
      "[('selector', SelectKBest(f_regression)), ('model', xgb.XGBRegressor(random_state=42))]": 1,
      "[('selector', SelectKBest(f_regression)), ('model', lgb.LGBMRegressor(random_state=42, objective='regression', bagging_fraction=0.8, bagging_freq=5, feature_fraction=0.2319, feature_fraction_seed=9, bagging_seed=9, min_data_in_leaf=6, min_sum_hessian_in_leaf=11))]": 1,
      "stages": 1,
      "[('scaler', StandardScaler()), ('NN', neural_model)]": 1,
      "[('preprocessor', basic_transformer), ('scaler', StandardScaler(with_mean=False)), ('model', LogisticRegression())]": 1,
      "[('preprocessor', advanced_transformer), ('scaler', StandardScaler()), ('model', LogisticRegression())]": 1,
      "[('feature_union', numerical_categorical_union), ('clf', RandomForestClassifier(max_depth=3, class_weight='balanced'))]": 1,
      "[('feature_union', numerical_categorical_union), ('cl', xgb.XGBClassifier(max_depth=3))]": 1,
      "[('feature_union', numerical_categorical_union), ('scaleing', MaxAbsScaler), ('logs', LogisticRegression(C=100, class_weight='balanced'))]": 1,
      "[('preproc', ColumnTransformer([('bin_0_2', 'passthrough', ['bin_0', 'bin_1', 'bin_2']), ('bin_3_4', FunctionTransformer(func=lambda X: X.replace({'F': 0, 'T': 1, 'N': 0, 'Y': 1}), validate=False), ['bin_3', 'bin_4']), ('nom_0_4', OneHotEncoder(sparse=True, handle_unknown='ignore'), ['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4', 'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']), ('ord', Pipeline(steps=[('replace', ColumnTransformer([('encoder', OrdinalEncoder(categories=[['Novice', 'Contributor', 'Expert', 'Master', 'Grandmaster'], ['Freezing', 'Cold', 'Warm', 'Hot', 'Boiling Hot', 'Lava Hot'], np.sort(train_df['ord_3'].unique()), np.sort(train_df['ord_4'].unique()), np.sort(train_df['ord_5'].unique())]), ['ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5'])], remainder='passthrough')), ('mm_scaler', MinMaxScaler())]), ['ord_0', 'ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5', 'day', 'month'])])), ('est', estimator)]": 1,
      "[('replace', ColumnTransformer([('encoder', OrdinalEncoder(categories=[['Novice', 'Contributor', 'Expert', 'Master', 'Grandmaster'], ['Freezing', 'Cold', 'Warm', 'Hot', 'Boiling Hot', 'Lava Hot'], np.sort(train_df['ord_3'].unique()), np.sort(train_df['ord_4'].unique()), np.sort(train_df['ord_5'].unique())]), ['ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5'])], remainder='passthrough')), ('mm_scaler', MinMaxScaler())]": 1,
      "[('encode', CountEncoder(cols=categ_columns)), ('classify', classifier)]": 1,
      "[('imputer', SimpleImputer(strategy='constant')), ('scale', RobustScaler(quantile_range=[5, 95])), ('quantile', QuantileTransformer(n_quantiles=300, output_distribution='normal', random_state=0)), ('cutoff', CutOff()), ('norm', Normalizer(norm='l2'))]": 1,
      "[('imputer', SimpleImputer(strategy='constant')), ('pca', PCA(whiten=True, random_state=0)), ('bins', KBinsDiscretizer(n_bins=100, encode='onehot', strategy='quantile')), ('norm', Normalizer(norm='l2'))]": 1,
      "[('imputer', SimpleImputer(strategy='constant')), ('bins', KBinsDiscretizer(n_bins=100, encode='ordinal', strategy='quantile')), ('norm', Normalizer(norm='l2'))]": 1,
      "[('quantile', QuantileTransformer(n_quantiles=300, output_distribution='normal', random_state=0))]": 1,
      "[('preprocessor', preprocessor_X), ('multioutreg', multi_out_reg)]": 1,
      "[('vectorizer', tvec), ('classifier', lr)]": 1,
      "[('onehot_scaling', column_transformer), ('xlassifier', xgb_cool)]": 1,
      "[('scaler', StandardScaler()), ('lgbm', LGBMRegressor(n_estimators=1000, max_depth=14, num_leaves=45, learning_rate=0.1, min_child_samples=20, subsample=0.9, colsample_bytree=0.9, random_state=42, eval_metric='rmse'))]": 1,
      "[('scaler', MaxAbsScaler()), ('sgd', SGDClassifier(loss='log', random_state=42))]": 1,
      "[('scaler', MaxAbsScaler()), ('sgd', SGDClassifier(loss='log', penalty=penalty, max_iter=max_iter, alpha=alpha, random_state=42))]": 1,
      "[('scaler', MaxAbsScaler()), ('gb', XGBClassifier(random_state=42))]": 1,
      "[('scaler', MaxAbsScaler()), ('gb', XGBClassifier(random_state=42, learning_rate=learning_rate, max_depth=max_depth, subsample=subsample, colsample_bytree=colsample_bytree, max_leaves=max_leaves, min_child_weight=min_child_weight))]": 1,
      "[('scaler', MaxAbsScaler()), ('lgbm', LGBMClassifier(random_state=42))]": 1,
      "[('scaler', MaxAbsScaler()), ('lgbm', LGBMClassifier(random_state=42, learning_rate=learning_rate, n_estimators=n_estimators, num_leaves=num_leaves, min_child_samples=min_child_samples, subsample=subsample, colsample_bytree=colsample_bytree))]": 1,
      "[('preprocessor', ColumnTransformer(transformers=[('num', SimpleImputer(strategy='most_frequent'), numeric_columns + ordinal_columns), ('one_hot', OneHotEncoder(), one_hot_columns)])), ('std_scaler', StandardScaler())]": 1,
      "[('model', XGBRegressor(random_state=SEED, n_jobs=4, verbosity=0, tree_method='gpu_hist', **best_params))]": 1,
      "[('imputer_cat', imputer_cat), ('imputer_num', imputer_num), ('dummy_encoder', dummy_encoder), ('constant', constant), ('duplicated', duplicated), ('correlated', correlated)]": 1,
      "[('imputer', imp_mean), ('scaler', scaler), ('lr', lr)]": 1,
      "[('tfidf', TfidfVectorizer(min_df=3, max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 3), use_idf=1, smooth_idf=1, sublinear_tf=1, stop_words='english')), ('mnb', MultinomialNB())]": 1,
      "[('cv', CountVectorizer(ngram_range=(1, 2))), ('mnb', MultinomialNB())]": 1,
      "[('voting', VotingClassifier(classifiers, voting='soft'))]": 1,
      "[('le', OrdinalEncoder())]": 1,
      "[('preprocess', preprocessor)]": 1,
      "[('svd', TruncatedSVD(n_components=400)), ('scl', StandardScaler()), ('svm', SVC(C=10))]": 1,
      "[('imputer', cat_imputer), ('encoder', ohe)]": 1,
      "[('preprocessor', preprocessor), ('classifier', rf)]": 1,
      "[('imputer', cat_imputer), ('combiner', combiner), ('encoder', ohe)]": 1,
      "[('imputer', cat_imputer), ('encoder', CustomLabelEncoder())]": 1,
      "[('imputer', cat_imputer), ('encoder', TargetEncoder())]": 1,
      "[('preprocessor', preprocessor), ('model', ExtraTreesClassifier(n_estimators=10, max_depth=None, min_samples_split=10, random_state=0))]": 1,
      "[('cleaning', Clean()), ('brand_encoding', OneHotEncoder('brand_name')), ('item_condition_scaling', MinMaxScaler('item_condition_id')), ('change_format', ToDict()), ('category_encoding', OneHotMultipleEncoder('category_name')), ('item_description_tfidf', TfidfVectorizer('item_description', lower_case=False, stop_words='english')), ('name_tfidf', TfidfVectorizer('name')), ('hstack_arrays', ToArray()), ('imputer', SimpleImputer(strategy='median')), ('estimator', SVR())]": 1,
      "[('means', FunctionTransformer(lambda X: X.mean(axis=1, keepdims=True))), ('tree', DecisionTreeRegressor(max_depth=10))]": 1,
      "[('nb', nb)]": 1,
      "[('week_label', KMeansTransformerWeek(5)), ('dept_label', KMeansTransformerDepts(12))]": 1,
      "[('KMeansTransform', transformers['clustering']), ('dataprep', transformers['dataprep']), ('model', model)]": 1,
      "[('preprocessing', preprocessing), ('scaler', StandardScaler()), ('pca', PCA(n_components=6)), ('model', model)]": 1,
      "[('impute', SimpleImputer(strategy='median')), ('scale', StandardScaler())]": 1,
      "[('transformer', ct), ('predictor', AdaBoostRegressor())]": 1,
      "[('imputer', SimpleImputer(strategy='constant', fill_value='missing')), ('encoder', OneHotEncoder(handle_unknown='ignore'))]": 1,
      "[('preprocessor', Transformer), ('predictor', XGBRegressor(n_jobs=-1, random_state=RANDOM_STATE))]": 1,
      "[('extract_features', features), ('classify', ExtraTreesClassifier(n_estimators=50, max_depth=None, min_samples_split=1, random_state=0))]": 1,
      "[('union', pipeline.FeatureUnion(n_jobs=-1, transformer_list=[('standard', cust_regression_vals()), ('pi1', pipeline.Pipeline([('Gene', cust_txt_col('Gene')), ('count_Gene', feature_extraction.text.CountVectorizer(analyzer='char', ngram_range=(1, 8))), ('tsvd1', decomposition.TruncatedSVD(n_components=20, n_iter=25, random_state=12))])), ('pi2', pipeline.Pipeline([('Variation', cust_txt_col('Variation')), ('count_Variation', feature_extraction.text.CountVectorizer(analyzer='char', ngram_range=(1, 8))), ('tsvd2', decomposition.TruncatedSVD(n_components=20, n_iter=25, random_state=12))]))]))]": 1,
      "[('Gene', cust_txt_col('Gene')), ('count_Gene', feature_extraction.text.CountVectorizer(analyzer='char', ngram_range=(1, 8))), ('tsvd1', decomposition.TruncatedSVD(n_components=20, n_iter=25, random_state=12))]": 1,
      "[('Variation', cust_txt_col('Variation')), ('count_Variation', feature_extraction.text.CountVectorizer(analyzer='char', ngram_range=(1, 8))), ('tsvd2', decomposition.TruncatedSVD(n_components=20, n_iter=25, random_state=12))]": 1,
      "[('preprocessor', preprocessor), ('model', xgbreg)]": 1,
      "[('cv', CountVectorizer()), ('tfidf', TfidfTransformer()), ('logit', LogisticRegression())]": 1,
      "[('cv', CountVectorizer()), ('tfidf', TfidfTransformer()), ('bnb', BernoulliNB())]": 1,
      "[('u1', FeatureUnion([('tfdif_features', Pipeline([('cv', CountVectorizer()), ('tfidf', TfidfTransformer())])), ('pos_features', Pipeline([('pos', PosTagMatrix(tokenizer=nltk.word_tokenize))]))])), ('logit', LogisticRegression())]": 1,
      "[('cv', CountVectorizer()), ('tfidf', TfidfTransformer())]": 1,
      "[('pos', PosTagMatrix(tokenizer=nltk.word_tokenize))]": 1,
      "[('cv', CountVectorizerPlus(fit_add=test['text'])), ('tfidf', TfidfTransformer()), ('bnb', BernoulliNB())]": 1,
      "[('u1', FeatureUnion([('tfdif_features', Pipeline([('cv', CountVectorizer()), ('tfidf', TfidfTransformer()), ('tfidf_logit', ClassifierWrapper(LogisticRegression()))])), ('pos_features', Pipeline([('pos', PosTagMatrix(tokenizer=nltk.word_tokenize)), ('pos_logit', ClassifierWrapper(LogisticRegression()))]))])), ('xgb', XGBClassifier(**xgb_params))]": 1,
      "[('u1', FeatureUnion([('tfdif_features', Pipeline([('cv', CountVectorizer()), ('tfidf', TfidfTransformer()), ('tfidf_logit', ClassifierWrapper(LogisticRegression()))], memory='/tmp')), ('pos_features', Pipeline([('pos', PosTagMatrix(tokenizer=nltk.word_tokenize)), ('pos_logit', ClassifierWrapper(LogisticRegression()))], memory='/tmp'))])), ('xgb', XGBClassifier(**xgb_params))]": 1,
      "[('vectorizer', bow_vector), ('classifier', classifier)]": 1,
      "[('tfidf', tfidf_vector), ('clf', svc)]": 1,
      "[('preprocessor', col_trans), ('model', model_xgboost)]": 1,
      "[('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler()), ('interactions', PolynomialFeatures(2))]": 1,
      "[('preprocessor', preprocessor), ('regressor', transformed_ridge)]": 1,
      "[('median_imputer', SimpleImputer(strategy='median')), ('log_scaler', FunctionTransformer(np.log1p)), ('std_scaler', StandardScaler())]": 1,
      "[('median_imputer', SimpleImputer(strategy='median')), ('std_scaler', StandardScaler())]": 1,
      "[('categorize', OneHotEncoder(drop=None, sparse=False))]": 1,
      "[('v', TfidfVectorizer(min_df=2, max_df=200, max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 3), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words='english')), ('svd', TruncatedSVD(n_components=350, algorithm='randomized', n_iter=6, random_state=12345, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=10.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False, tol=0.002, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None))]": 1,
      "[('scaler', None), ('estimator', estimator)]": 1,
      "[('estimator', estimator)]": 1,
      "[('select', ItemSelector('comment_text', start_time=start_time)), ('transform', TfidfVectorizer(sublinear_tf=True, strip_accents='unicode', analyzer='word', stop_words='english', token_pattern='\\\\w{1,}', ngram_range=(1, 1), max_features=15000)), ('drop_cols', DropColumnsByDf(min_df=2))]": 1,
      "[('select', ItemSelector('comment_text', start_time=start_time)), ('transform', TfidfVectorizer(sublinear_tf=True, strip_accents='unicode', analyzer='char', stop_words='english', ngram_range=(2, 6), max_features=20000)), ('drop_cols', DropColumnsByDf(min_df=2))]": 1,
      "[('select', ItemSelector('abuse_list', start_time=start_time)), ('ohe', MyLabelEncoder())]": 1,
      "[('select', ItemSelector('num_abuses', start_time=start_time)), ('ohe', OneHotEncoder())]": 1,
      "[('tfidf', TfidfVectorizer()), ('model', LinearSVC())]": 1,
      "[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('model', BernoulliNB())]": 1,
      "[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('model', GradientBoostingClassifier(loss='deviance', learning_rate=0.01, n_estimators=5, max_depth=500, random_state=55))]": 1,
      "[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('model', DecisionTreeClassifier(max_depth=150))]": 1,
      "[('preprocessor', SimpleImputer()), ('model', RandomForestRegressor(n_estimators=500, random_state=0))]": 1,
      "[('selector', OldDataFrameSelector(num_attr)), ('scaler', StandardScaler())]": 1,
      "[('selector', OldDataFrameSelector(cat_attr)), ('cat_encoder', OneHotEncoder(sparse=False))]": 1,
      "[('selector', OldDataFrameSelector(skewed_feats_index)), ('scalermm', MinMaxScaler()), ('PCA', PCA(n_components=200)), ('skew_scaler', Skewness_numericalSelector())]": 1,
      "[('cursor', SliceSelector(slices)), ('scaler', StandardScaler()), ('PCA', PCA(n_components=pca_coef))]": 1,
      "[('col_remover', col_remover), ('feature_gen', feature_gen), ('col_trans', col_trans), ('xgbreg', xgbreg)]": 1,
      "[('vec', CountVectorizer()), ('clf', RandomForestClassifier())]": 1,
      "[('rfc', RandomForestClassifier(n_estimators=10, n_jobs=-1))]": 1,
      "[('preprocessor', baseline_preprocessor), ('model', LinearRegression())]": 1,
      "[('imputer', SimpleImputer(strategy='constant', fill_value='MISSING'))]": 1,
      "[('preprocessor', full_preprocessor), ('ohe', OneHotEncoder()), ('model', LinearRegression())]": 1,
      "[('feature_engineering', FeatureEngineering()), ('preprocessor', full_preprocessor), ('ohe', OneHotEncoder()), ('model', LinearRegression())]": 1,
      "[('feature_engineering', FeatureEngineering()), ('preprocessor', full_preprocessor), ('ohe', OneHotEncoder()), ('selector', feature_selector), ('model', LinearRegression())]": 1,
      "[('bow', CountVectorizer(analyzer='word')), ('classifier', MultinomialNB())]": 1,
      "[('RobustScaler', sc_rs), ('MinMax', sc_mm)]": 1,
      "[('tfidf', TfidfVectorizer(preprocessor=None, lowercase=False)), ('classifier', OneVsRestClassifier(LogisticRegression(solver='saga', max_iter=500, random_state=42)))]": 1,
      "[('modelC', modelC)]": 1,
      "[('Scaler', minmax_scaler), ('Feature_selection', Feature_selection2), ('clf', log_reg_clf2)]": 1,
      "[('Scaler', minmax_scaler), ('Feature_extraction', PCA_features), ('clf', log_reg_clf2)]": 1,
      "[('Scaler', minmax_scaler), ('clf', log_reg_clf2)]": 1,
      "[('Scaler', minmax_scaler), ('Feature_selection', Feature_selection2), ('clf', RF_clf)]": 1,
      "[('Scaler', minmax_scaler), ('Feature_selection', Feature_selection4), ('clf', log_reg_clf4)]": 1,
      "[('Scaler', minmax_scaler), ('Feature_extraction', PCA_features), ('clf', log_reg_clf4)]": 1,
      "[('Scaler', minmax_scaler), ('clf', log_reg_clf4)]": 1,
      "[('Scaler', minmax_scaler), ('Feature_selection', Feature_selection4), ('clf', RF_clf)]": 1,
      "[('Scaler', minmax_scaler), ('Feature_extraction', PCA_features), ('clf', RF_clf)]": 1,
      "[('Scaler', minmax_scaler), ('clf', RF_clf)]": 1,
      "[('scaler', scaler), ('embedding', embedding_instance)]": 1,
      "[('scaler', StandardScaler()), ('kmeans', KMeans(n_clusters=57, random_state=42))]": 1,
      "[('preprocess', column_transform), ('model', StackingRegressor([('ridge', Ridge(alpha=0.8, solver='sag', max_iter=2000)), ('xgb', XGBRegressor()), ('lgbm', LGBMRegressor()), ('catboost', CatBoostRegressor())]))]": 1,
      "[('Scaler', scaler), ('XGB', XGBClassifier())]": 1,
      "[('Scaler', scaler), ('LGB', LGBMClassifier())]": 1,
      "[('vectorizer', CountVectorizer(binary=False, stop_words='english', ngram_range=(1, 2))), ('tfidf', TfidfTransformer(use_idf=True)), ('clf', lr)]": 1,
      "[('poly', PolynomialFeatures(degree=d)), ('linear', LinearRegression(fit_intercept=True))]": 1,
      "[('poly', PolynomialFeatures(degree=d)), ('ridge', Ridge(alpha=10.0, copy_X=True, fit_intercept=True))]": 1,
      "[('poly', PolynomialFeatures(degree=2)), ('ridge', Ridge(alpha=10.0, copy_X=True, fit_intercept=False))]": 1,
      "[('sc', StandardScaler()), ('classifier', LogisticRegression())]": 1,
      "[('sc', StandardScaler()), ('classifier', KNeighborsClassifier())]": 1,
      "[('decisiontree', DecisionTreeClassifier())]": 1,
      "[('pre_process', pre_process), ('logistic_reg', logistic_reg)]": 1,
      "[('pre_process', pre_process), ('forest_clf', forest_clf)]": 1,
      "[('pre_process', pre_process), ('xgb_clf', xgb_clf)]": 1,
      "[('pre_process', cat_boost_pre_process), ('catboost_clf', catboost_clf)]": 1,
      "[('pre_process', cat_boost_pre_process), ('catboost', catboost_clf)]": 1,
      "[('StandardScaler', StandardScaler()), ('XGBRegressor:', XGBRegressor())]": 1,
      "[('ord', ordinal.OrdinalEncoder(verbose=1, cols=ordinals, mapping=ordinal_mappings, handle_unknown='value', handle_missing='value'))]": 1,
      "[('cat', one_hot.OneHotEncoder(verbose=1, cols=categoricals, use_cat_names=True, handle_unknown='value', handle_missing='value'))]": 1,
      "[('extra_feat', CreateExtraFeatures())]": 1,
      "[('categorical_encoder', OneHotEncoder(sparse=False))]": 1,
      "[('scl', StandardScaler()), ('DecisionTreeRegressor', DecisionTreeRegressor())]": 1,
      "[('scl', StandardScaler()), ('RandomForestRegressor', RandomForestRegressor())]": 1,
      "[('feature_transformer', NonparametricTransformer(feature_eda, keepcols=keep_raw_features)), ('fare_encoder', ParametricTransformer(KBinsDiscretizer(n_bins=3, encode='ordinal'), usecols=['Fare'])), ('string_converter', NonparametricTransformer(lambda df: df.astype(str))), ('feature_combiner', NonparametricTransformer(combine_feature, keepcols=keep_combined_features))]": 1,
      "[('preprocessor', preprocessor), ('woe_encoder', woe_encoder), ('scaler', StandardScaler())]": 1,
      "[('preprocessor', preprocessor), ('woe_encoder', woe_encoder), ('classifier', LogisticRegression(max_iter=10000, n_jobs=-1, verbose=False, random_state=RANDOM_SEED))]": 1,
      "[(DR_name, DR), ('xtree', ExtraTreesRegressor())]": 1,
      "[('imp', SimpleImputer(strategy='constant', fill_value='NA')), ('one_hot', OneHotEncoder()), ('std_scaler', StandardScaler(with_mean=False))]": 1,
      "[('dict_processor', DictProcessor(custom_dic)), ('std_scaler', StandardScaler())]": 1,
      "[('other', OtherEncoder()), ('std_scaler', StandardScaler())]": 1,
      "[('encoder', OrdinalEncoder(handle_unknown='ignore'))]": 1,
      "[('scaler', scaler), ('rfc', rfc)]": 1,
      "[('selector', selector), ('rfc', rfc)]": 1,
      "[('scaler', StandardScaler()), ('lgbm', lgbm)]": 1,
      "[('boolean_transformer', BooleanTransformer(boolean_features)), ('one_hot_transformer', OneHotTransformer(one_hot_objects, one_hot_top_values)), ('date_transformer', DateTransformer()), ('cast_transformer', CastTransformer(top_values(engineered_data, 'cast', 'name'), top_values(engineered_data, 'cast', 'character'))), ('crew_transformer', CrewTransformer(top_values(engineered_data, 'crew', 'name'), top_values(engineered_data, 'crew', 'job'), top_values(engineered_data, 'crew', 'department'))), ('fix_revenue_transformer', FixRevenueTransformer()), ('drop_features_transformers', DropFeaturesTransformer(drop_features))]": 1,
      "[('v', TfidfVectorizer(min_df=3, max_df=500, max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 1), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words='english')), ('svd', TruncatedSVD(n_components=200, algorithm='randomized', n_iter=5, random_state=1, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=10.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=1))]": 1,
      "[('v', TfidfVectorizer(min_df=3, max_df=600, max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 3), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words='english')), ('svd', TruncatedSVD(n_components=200, algorithm='randomized', n_iter=5, random_state=1, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=10.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=True, max_iter=-1, random_state=1))]": 1,
      "[('svd', svd), ('scl', scl), ('rf', rf_model)]": 1,
      "[('v', TfidfVectorizer(min_df=2, max_df=500, max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 3), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words='english')), ('svd', TruncatedSVD(n_components=200, algorithm='randomized', n_iter=5, random_state=1, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=10.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=1))]": 1,
      "[('vect', CountVectorizer(ngram_range=(1, 2))), ('tfidf', TfidfTransformer()), ('clf', BernoulliNB())]": 1,
      "[('bow', CountVectorizer(analyzer=clean_text)), ('tfidf', TfidfTransformer()), ('classifier', MultinomialNB())]": 1,
      "[('bow', CountVectorizer(analyzer=clean_text)), ('tfidf', TfidfTransformer()), ('classifier', RandomForestClassifier(n_estimators=500))]": 1,
      "[('preprcessor', preprocessor), ('model', model)]": 1,
      "[('extract_features', features), ('classify', RandomForestClassifier(n_estimators=100, n_jobs=1, min_samples_split=50, random_state=1))]": 1,
      "[('cleanText', CleanTextTransformer()), ('vectorizer', vectorizer), ('clf', clf)]": 1,
      "[('cleanText', CleanTextTransformer()), ('vectorizer', vectorizer)]": 1,
      "[('pca', pca), ('bagging_svm', bagging_svm)]": 1,
      "[('scaler', scaler), ('regression', ridge)]": 1,
      "[('scaler', RobustScaler()), ('rfr', RandomForestRegressor(random_state=0))]": 1,
      "[('ohe', OneHotEncoder(sparse=False)), ('LDA', LinearDiscriminantAnalysis())]": 1,
      "[('sc', StandardScaler()), ('pca', PCA(n_components=3)), ('rfr', RandomForestClassifier())]": 1,
      "[('scaler', StandardScaler()), ('gs_rfr', gs)]": 1,
      "[('col_trasf', col_transformer), ('rfc', rfc)]": 1,
      "[('poly_feat', PolynomialFeatures(degree=3)), ('scaler', StandardScaler()), ('linear_reg', LinearRegression())]": 1,
      "[('scaler', StandardScaler()), ('linear_svr', LinearSVR())]": 1,
      "[('tfidf', vec), ('logreg', LogisticRegression(penalty='elasticnet'))]": 1,
      "[('v', TfidfVectorizer(min_df=5, max_df=500, max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 3), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words='english')), ('svd', TruncatedSVD(n_components=200, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=10.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=True, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None))]": 1,
      "(('intcat', CategoricalIntegerTransformer(categoricals)), ('onehot', sklearn.preprocessing.OneHotEncoder(categorical_features=categoricals)), ('dense', DenseTransformer()), ('interaction', InteractionTransformer()), ('model', sklearn.ensemble.RandomForestRegressor(n_estimators=100)))": 1,
      "(('detrender', Detrender()), )": 1,
      "[('scalar1', StandardScaler()), ('pca1', PCA(n_components=10)), ('lr_classifier', LogisticRegression(random_state=0))]": 1,
      "[('scalar2', StandardScaler()), ('pca2', PCA(n_components=10)), ('dt_classifier', DecisionTreeClassifier())]": 1,
      "[('scalar3', StandardScaler()), ('pca3', PCA(n_components=10)), ('rf_classifier', RandomForestClassifier())]": 1,
      "[('scalar4', StandardScaler()), ('pca4', PCA(n_components=10)), ('gn_classifier', GaussianNB())]": 1,
      "[('imputer', SimpleImputer(strategy='mean')), ('standard_scaler', StandardScaler())]": 1,
      "[('imputer', SimpleImputer(strategy='most_frequent')), ('hot_encoder', OneHotEncoder())]": 1,
      "[('transformer', transformer), ('model', GradientBoostingRegressor())]": 1,
      "[('preprocessor', preprocessor), ('model', RandomForestRegressor(n_estimators=5, n_jobs=-1, min_samples_split=6, random_state=0))]": 1,
      "[('imputer', SimpleImputer())]": 1,
      "[('feature_eng', FunctionTransformer(_custom_eng, check_inverse=False)), ('trnsfrmer', PowerTransformer(method='yeo-johnson')), ('scaler', StandardScaler()), ('pca', PCA())]": 1,
      "[('cat_selector', FeatureSelector(categorical_features)), ('cat_transformer', CategoricalTransformer()), ('imputer', SimpleImputer(strategy='most_frequent')), ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))]": 1,
      "[('num_selector', FeatureSelector(numerical_features)), ('num_transformer', NumericalTransformer()), ('imputer', SimpleImputer(strategy='median')), ('std_scaler', MinMaxScaler()), ('power_transform', PowerTransformer(method='yeo-johnson'))]": 1,
      "[('imputer', SimpleImputer(strategy='constant', fill_value=0)), ('scaler', StandardScaler())]": 1,
      "[('one_hot', OneHotEncoder(handle_unknown='ignore'))]": 1,
      "[('preprocessor', linear_preprocessor), ('estimator', linear_estimator)]": 1,
      "[('dropper', Num_Dropper(num_att_to_drop)), ('atts_adder', CombinedAtts(duration_no_remodeling=True)), ('imputer', SimpleImputer(strategy='median')), ('std_scaler', StandardScaler())]": 1,
      "[('cat_dropper', Cat_Dropper(cat_att_to_drop)), ('eliminate_null', Eliminate_null_values()), ('one_hot', OrdinalEncoder())]": 1,
      "[('v', TfidfVectorizer(min_df=5, max_df=500, max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 3), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words='english')), ('svd', TruncatedSVD(n_components=200, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=20.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None))]": 1,
      "[('imputer', SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)), ('scaler', StandardScaler())]": 1,
      "[('imputer', SimpleImputer(strategy='constant', fill_value='missing')), ('one_hot', OneHotEncoder(handle_unknown='ignore'))]": 1,
      "(('clf', RandomForestRegressor(max_depth=500, max_features=None)), )": 1,
      "(('clf', LogisticRegression(class_weight='balanced', penalty='l2', solver='saga', max_iter=100)), )": 1,
      "(('clf', MLPRegressor()), )": 1,
      "(('clf', DecisionTreeRegressor(splitter='random')), )": 1,
      "[('quantile', QuantileTransformer(n_quantiles=n_quantiles, random_state=0)), ('logreg', LogisticRegression(C=C2))]": 1,
      "[('scaler', StandardScaler()), ('nn', MLPRegressor(hidden_layer_sizes=(100, 50), batch_size=100, max_iter=20, verbose=True))]": 1,
      "[('date_processor', DatePreprocessor()), ('drop_cols', DropColumns(columns=drop_cols))]": 1,
      "[('n', KNNImputer(n_neighbors=int(s))), ('m', model)]": 1,
      "[('preprocessor', preprocessor), ('logit', LogisticRegression())]": 1,
      "[('tfidf', TfidfVectorizer(stop_words='english', analyzer='word', min_df=3, max_df=0.9, strip_accents='unicode', sublinear_tf=1)), ('clf', MultinomialNB())]": 1,
      "[('tfidf', TfidfVectorizer(stop_words='english', analyzer='word', min_df=3, max_df=0.9, strip_accents='unicode', sublinear_tf=1)), ('clf', SGDClassifier())]": 1,
      "[('preprocessor', preprocessor), ('classifier', KNeighborsClassifier())]": 1,
      "[('preprocessor', preprocessor), ('ensemble', ensemble)]": 1,
      "[('preprocessor', preprocessor), ('ensemble', RandomForestClassifier())]": 1,
      "[('scaler', scaler), ('xgb', clf0)]": 1,
      "[('pre', preprocessor), ('poly', PolynomialFeatures(2)), ('selection', SelectFromModel(estimator=RandomForestRegressor(n_estimators=300, random_state=1))), ('xg', xg)]": 1,
      "[('pre', preprocessor), ('lg', lg)]": 1,
      "[('pre', preprocessor), ('stack', stack_reg)]": 1,
      "[('pre', preprocessor), ('poly', PolynomialFeatures(2)), ('selection', SelectFromModel(estimator=RandomForestRegressor(n_estimators=300, random_state=1))), ('a', xg)]": 1,
      "[('pre', preprocessor), ('a', lg)]": 1,
      "[('pre', preprocessor), ('a', stack_reg)]": 1,
      "[('pre', preprocessor), ('a', GradientBoostingClassifier(random_state=42))]": 1,
      "[('pre', preprocessor), ('a', LogisticRegression(random_state=42))]": 1,
      "[('sc', StandardScaler())]": 1,
      "[('forest', RandomForestRegressor())]": 1,
      "[('svr', SVR(kernel='rbf', gamma='scale'))]": 1,
      "[('forest', RandomForestClassifier(criterion='entropy'))]": 1,
      "[('preprocessor', preprocessor), ('model', model_lr)]": 1,
      "[('preprocessor', preprocessor), ('model', model_rf)]": 1,
      "[('scaler', RobustScaler()), ('regressor', model)]": 1,
      "[('inputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore'))]": 1,
      "[('preproc', preprocessor), ('model', xgboost)]": 1,
      "[('cat_imputer', SimpleImputer(strategy='most_frequent')), ('ord', OneHotEncoder(handle_unknown='ignore'))]": 1,
      "[('preproc', my_tranf), ('model', xgboost)]": 1,
      "[('scaler', QuantileTransformer(n_quantiles=1000, random_state=np.random.randint(10000), output_distribution='normal'))]": 1,
      "[('scaler', RobustScaler(quantile_range=(25.0, 75.0)))]": 1,
      "[('tfidf_vectorizer', tfidf_vectorizer), ('model', model)]": 1,
      "[('count_vectorizer', count_vectorizer), ('model1', model1)]": 1,
      "[('count_vectorizer', tfidf_vectorizer), ('model1', model1)]": 1,
      "[('count_vectorizer', count_vectorizer), ('model2', model2)]": 1,
      "[('cv', CountVectorizer(analyzer='word', ngram_range=(1, 2), max_df=0.9)), ('clf', LogisticRegression(solver='saga', class_weight={0: 0.0619, 1: 0.9381}, max_iter=10000, verbose=1, n_jobs=-1))]": 1,
      "[('cv', CountVectorizer(analyzer='word', ngram_range=(1, 2), max_df=0.9)), ('clf', LogisticRegression(solver='saga', class_weight='balanced', max_iter=10000, verbose=1, n_jobs=-1))]": 1,
      "[('cv', CountVectorizer(analyzer='word', ngram_range=(1, 2), max_df=0.9)), ('clf', LogisticRegression(solver='saga', class_weight='balanced', C=0.45, max_iter=10000, verbose=1, n_jobs=-1))]": 1,
      "[('tfidf', TfidfVectorizer(analyzer='word', ngram_range=(1, 2), max_df=0.9)), ('clf', LogisticRegression(solver='saga', class_weight={0: 0.0619, 1: 0.9381}, max_iter=10000, verbose=1, n_jobs=-1))]": 1,
      "[('tfidf', TfidfVectorizer(analyzer='word', ngram_range=(1, 2), max_df=0.9)), ('clf', LogisticRegression(solver='saga', class_weight='balanced', max_iter=10000, verbose=1, n_jobs=-1))]": 1,
      "[('cv', CountVectorizer(analyzer='word', ngram_range=(1, 2), max_df=0.9)), ('clf', LogisticRegression(solver='saga', class_weight='balanced', C=0.5, max_iter=10000, verbose=1, n_jobs=-1))]": 1,
      "[('count_vectorizer', CountVectorizer(analyzer=lambda x: x)), ('multinomial nb', OneVsRestClassifier(MultinomialNB()))]": 1,
      "[('count_vectorizer', CountVectorizer(analyzer=lambda x: x)), ('bernoulli nb', BernoulliNB())]": 1,
      "[('tfidf_vectorizer', TfidfVectorizer(analyzer=lambda x: x)), ('multinomial nb', MultinomialNB())]": 1,
      "[('tfidf_vectorizer', TfidfVectorizer(analyzer=lambda x: x)), ('bernoulli nb', BernoulliNB())]": 1,
      "[('tfidf_vectorizer', TfidfVectorizer(analyzer=lambda x: x, sublinear_tf=True)), ('knn', OneVsRestClassifier(KNeighborsClassifier()))]": 1,
      "[('count_vectorizer', CountVectorizer(analyzer=lambda x: x)), ('linear svc', SVC(kernel='rbf'))]": 1,
      "[('tfidf_vectorizer', TfidfVectorizer(analyzer=lambda x: x)), ('linear svc', OneVsRestClassifier(SVC(kernel='rbf')))]": 1,
      "[('tfidf_vectorizer', TfidfVectorizer(analyzer=lambda x: x)), ('linear svc', OneVsRestClassifier(SVC(kernel='linear')))]": 1,
      "[('count_vectorizer', CountVectorizer(analyzer=lambda x: x)), ('linear svc', OneVsRestClassifier(SVC(kernel='linear')))]": 1,
      "[('count_vectorizer', CountVectorizer(analyzer=lambda x: x)), ('svc_ovr', OneVsRestClassifier(SVC()))]": 1,
      "[('tfidf', TfidfVectorizer(max_df=0.95, min_df=2, ngram_range=(1, 2))), ('Naive Bayes', MultinomialNB())]": 1,
      "[('vetorizador', vect), ('classificador', clf)]": 1,
      "[('scale', StandardScaler()), ('impute', SimpleImputer(strategy='median'))]": 1,
      "[('v', TfidfVectorizer(min_df=3, max_df=500, max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 2), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words='english')), ('svd', TruncatedSVD(n_components=200, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=10.0, kernel='rbf', degree=3, gamma=0.01, coef0=0.01, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None))]": 1,
      "[('numerical_imputer', SimpleImputer(strategy='median')), ('quantile', QuantileTransformer(n_quantiles=100, output_distribution='normal')), ('robust', RobustScaler((5, 95)))]": 1,
      "[('categorical_imputer', SimpleImputer(fill_value='NA', strategy='constant')), ('onehot_encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))]": 1,
      "estimators_svc": 1,
      "[('cat', OneHotEncoder(handle_unknown='ignore'))]": 1,
      "[('robust', RobustScaler())]": 1,
      "[('pre', preprocessing), ('reg', RandomForestRegressor(n_estimators=80, random_state=42421))]": 1,
      "[('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), ('clf-svm', SGDClassifier(loss='modified_huber'))]": 1,
      "[('pca', pca), ('svc', svc)]": 1,
      "[('standardize', scl), ('logarithm', transformer), ('pca', pca), ('logistic', logistic)]": 1,
      "[('preprocessor', preprocessor), ('model', ridge_randomized)]": 1,
      "[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', RandomForestClassifier())]": 1,
      "[('scaler', MinMaxScaler()), algorithm]": 1,
      "[('scaler', MinMaxScaler()), ('XGBRegressor', XGBRegressor())]": 1,
      "[('vect', CountVectorizer(tokenizer=tokenize)), ('tfidf', TfidfTransformer()), ('clf', RandomForestRegressor(random_state=42))]": 1,
      "[('scaler2', StandardScaler()), ('XGBRegressor: ', model)]": 1,
      "[('tfidf', TfidfVectorizer(stop_words=stop_words)), ('clf', OneVsRestClassifier(MultinomialNB(fit_prior=True, class_prior=None)))]": 1,
      "[('bow', ft), ('clf', LogisticRegression(solver='saga', class_weight='balanced', C=0.45, max_iter=250, verbose=1))]": 1,
      "[('imputer', SimpleImputer(strategy='constant', fill_value='S')), ('onehot', OneHotEncoder(handle_unknown='ignore'))]": 1,
      "[('preprocessor', preprocessor), ('model', RandomForestClassifier())]": 1,
      "[('Scaler', StandardScaler()), ('AB', AdaBoostRegressor())]": 1,
      "[('preprocessor', preprocessor_xgb), ('rcv_xgb', xgb.XGBRegressor(objective=huber_approx_obj, feval=huber_loss, max_depth=5, n_estimators=30))]": 1,
      "[('poly', pf), ('scaler', s), ('linear', lr)]": 1,
      "[('poly', pf), ('scaler', s), ('Lass', Lasso(alpha=alpha))]": 1,
      "[('poly', pf), ('scaler', s), ('Ridge', Ridge(alpha=alpha))]": 1,
      "[('poly', PolynomialFeatures(include_bias=False)), ('scaler', StandardScaler()), ('Ridge', Ridge())]": 1,
      "[('poly', PolynomialFeatures(degree=3, include_bias=False)), ('scaler', StandardScaler()), ('Ridge', Ridge(alpha=12.0))]": 1,
      "[('one_hot_encoder', OneHotEncoder()), ('median', SimpleImputer(strategy='most_frequent'))]": 1,
      "[('label_encoder', OrdinalEncoder()), ('median', SimpleImputer(strategy='most_frequent'))]": 1,
      "[('standard_scaler', StandardScaler()), ('median', SimpleImputer(strategy='median'))]": 1,
      "[('v', TfidfVectorizer(min_df=5, max_df=500, max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 2), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words='english')), ('svd', TruncatedSVD(n_components=200, algorithm='randomized', n_iter=10, random_state=None, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=10.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None))]": 1,
      "[('scaler', MaxAbsScaler())]": 1,
      "[('preprocessor', preprocessor), ('model', RandomForestRegressor(n_estimators=n_estimators, random_state=42))]": 1,
      "[('preprocessor', preprocessor), ('model', XGBRegressor(n_estimators=n_estimators, learning_rate=learning_rate, n_jobs=n_jobs, random_state=42))]": 1,
      "[('preprocessing', FunctionTransformer(remove_extra, validate=False)), ('regressor', RandomForestRegressor())]": 1,
      "[('v', TfidfVectorizer(min_df=5, max_df=500, max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 3), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words=stop_words1)), ('svd', TruncatedSVD(n_components=200, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=10.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False, tol=0.0001, cache_size=300, class_weight=None, verbose=False, max_iter=-1, random_state=None))]": 1,
      "[('imputer', Imputer(missing_values='NaN', strategy='mean', axis=1)), ('feature', RandomizedLasso()), ('model', LogisticRegression())]": 1,
      "[('imputer', Imputer(missing_values='NaN', strategy='mean', axis=1)), ('feature', RandomizedLasso()), ('model', GradientBoostingClassifier())]": 1,
      "[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('model', DecisionTreeClassifier(criterion='entropy', max_depth=10, splitter='best', random_state=2020))]": 1,
      "[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('model', RandomForestClassifier())]": 1,
      "[('imp', SimpleImputer(strategy='most_frequent')), ('cat_encoder', OrdinalEncoder())]": 1,
      "[('preprocessor', SimpleImputer()), ('model', RandomForestRegressor(n_estimators=50, random_state=0))]": 1,
      "[('Scaler', scaler), ('LR', LogisticRegression())]": 1,
      "[('Scaler', scaler), ('CART', DecisionTreeClassifier())]": 1,
      "[('Scaler', scaler), ('SVM', SVC())]": 1,
      "[('Scaler', scaler), ('RF', RandomForestClassifier())]": 1,
      "[('Scaler', scaler), ('ET', ExtraTreesClassifier())]": 1,
      "[('Scaler', scaler), ('LR', LogisticRegression(class_weight='balanced'))]": 1,
      "[('Scaler', scaler), ('CART', DecisionTreeClassifier(class_weight='balanced'))]": 1,
      "[('Scaler', scaler), ('SVM', SVC(class_weight='balanced'))]": 1,
      "[('Scaler', scaler), ('RF', RandomForestClassifier(class_weight='balanced'))]": 1,
      "[('Scaler', scaler), ('ET', ExtraTreesClassifier(class_weight='balanced'))]": 1,
      "[('columns', ColumnTransformer([('sbm', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_loading_features), ('fnc', FunctionTransformer(down_scale, kw_args={'factor': 1 / 600}, validate=True), col_fnc_features), ('internal_conn', FunctionTransformer(down_scale, kw_args={'factor': 1 / 600}, validate=True), col_internalconn_features), ('external_conn', FunctionTransformer(down_scale, kw_args={'factor': 1 / 600}, validate=True), col_externalconn_features), ('intmultext', FunctionTransformer(down_scale, kw_args={'factor': 1 / 600}, validate=True), col_intmultext_features)], remainder='drop')), ('win', FunctionTransformer(winsorize, kw_args={'l': 0.0001, 'h': 0.0001}, validate=True)), ('e', Ridge(alpha=optpars['sbm+funcdeweighted_win_ridge'][target]))]": 1,
      "[('columns', ColumnTransformer([('sbm', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_loading_features), ('fnc', FunctionTransformer(down_scale, kw_args={'factor': 1 / 600}, validate=True), col_fnc_features), ('gm', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_gm_features), ('gm2', FunctionTransformer(square, validate=True), col_gm_features), ('wm', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_wm_features), ('wm2', FunctionTransformer(square, validate=True), col_wm_features), ('csf', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_csf_features), ('csf2', FunctionTransformer(square, validate=True), col_csf_features)], remainder='drop')), ('win', FunctionTransformer(winsorize, kw_args={'l': 0.0001, 'h': 0.0001}, validate=True)), ('e', BaggingRegressor(Ridge(alpha=optpars['sbm+funcdeweighted_win_ridgebag'][target]), n_estimators=20, random_state=42, max_samples=0.8, max_features=0.8))]": 1,
      "[('columns', ColumnTransformer([('sbm', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_loading_features), ('sbm2', FunctionTransformer(square, validate=True), col_loading_features)], remainder='drop')), ('win', FunctionTransformer(winsorize, kw_args={'l': 0.0001, 'h': 0.0001}, validate=True)), ('e', Ridge(alpha=optpars['sbm+sbm_win_ridge_alpha'][target]))]": 1,
      "[('columns', ColumnTransformer([('sbm', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_loading_features), ('sbm2', FunctionTransformer(square, validate=True), col_loading_features)], remainder='drop')), ('win', FunctionTransformer(winsorize, kw_args={'l': 0.0001, 'h': 0.0001}, validate=True)), ('e', BaggingRegressor(Ridge(alpha=optpars['sbm+sbm_win_ridge_alphabag'][target]), n_estimators=20, random_state=42, max_samples=0.8, max_features=0.8))]": 1,
      "[('columns', ColumnTransformer([('fnc', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_fnc_features), ('internal_conn', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_internalconn_features), ('external_conn', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_externalconn_features), ('intmultext', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_intmultext_features), ('netmat', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_netmat_features), ('netmat2', FunctionTransformer(square, validate=True), col_netmat_features)], remainder='drop')), ('win', FunctionTransformer(winsorize, validate=True)), ('e', Ridge(alpha=optpars['fnc_extended_ridge'][target]))]": 1,
      "[('columns', ColumnTransformer([('fnc', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_fnc_features), ('internal_conn', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_internalconn_features), ('external_conn', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_externalconn_features), ('intmultext', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_intmultext_features), ('netmat', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_netmat_features), ('netmat2', FunctionTransformer(square, validate=True), col_netmat_features)], remainder='drop')), ('win', FunctionTransformer(winsorize, validate=True)), ('e', BaggingRegressor(Ridge(alpha=optpars['fnc_extended_ridgebag'][target]), n_estimators=20, random_state=42, max_samples=0.8, max_features=0.8))]": 1,
      "[('columns', ColumnTransformer([('internal_conn', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_internalconn_features), ('external_conn', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_externalconn_features), ('netmat', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_netmat_features)], remainder='drop')), ('win', FunctionTransformer(winsorize, validate=True)), ('poly', PolynomialFeatures()), ('e', Ridge(alpha=optpars['fnc_simple_ridge'][target]))]": 1,
      "[('columns', ColumnTransformer([('gm', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_gm_features), ('gm2', FunctionTransformer(square, validate=True), col_gm_features), ('wm', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_wm_features), ('wm2', FunctionTransformer(square, validate=True), col_wm_features), ('csf', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_csf_features), ('csf2', FunctionTransformer(square, validate=True), col_csf_features)], remainder='drop')), ('win', FunctionTransformer(winsorize, validate=True)), ('e', Ridge(alpha=optpars['spatial_maps_gmmax_wm_csf'][target]))]": 1,
      "[('columns', ColumnTransformer([('sbm', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_loading_features), ('fnc', FunctionTransformer(down_scale, kw_args={'factor': 1 / 600}, validate=True), col_fnc_features), ('internal_conn', FunctionTransformer(down_scale, kw_args={'factor': 1 / 600}, validate=True), col_internalconn_features), ('external_conn', FunctionTransformer(down_scale, kw_args={'factor': 1 / 600}, validate=True), col_externalconn_features), ('intmultext', FunctionTransformer(down_scale, kw_args={'factor': 1 / 600}, validate=True), col_intmultext_features)], remainder='drop')), ('win', FunctionTransformer(winsorize, kw_args={'l': 0.0001, 'h': 0.0001}, validate=True)), ('e', SVR(C=optpars['sbm+funcdeweighted_win_svr'][target], cache_size=1000, gamma='scale'))]": 1,
      "[('columns', ColumnTransformer([('sbm', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_loading_features), ('fnc', FunctionTransformer(down_scale, kw_args={'factor': 1 / 600}, validate=True), col_fnc_features), ('degree', FunctionTransformer(down_scale, kw_args={'factor': optpars['fnc_graph_ridge_degree_scale'][target]}, validate=True), col_degree_features), ('clustering_r', FunctionTransformer(down_scale, kw_args={'factor': optpars['fnc_graph_ridge_clustering_r_scale'][target]}, validate=True), col_clustering_r_features), ('clustering_i', FunctionTransformer(down_scale, kw_args={'factor': optpars['fnc_graph_ridge_clustering_i_scale'][target]}, validate=True), col_clustering_i_features), ('betweenness', FunctionTransformer(down_scale, kw_args={'factor': optpars['fnc_graph_ridge_betweenness_scale'][target]}, validate=True), col_betweenness_centrality_features), ('eigenvec', FunctionTransformer(down_scale, kw_args={'factor': optpars['fnc_graph_ridge_eigenvec_scale'][target]}, validate=True), col_eigenvector_centrality_features), ('gm', FunctionTransformer(down_scale, kw_args={'factor': optpars['fnc_graph_ridge_gm_scale'][target]}, validate=True), col_gm_features), ('csf', FunctionTransformer(down_scale, kw_args={'factor': optpars['fnc_graph_ridge_csf_scale'][target]}, validate=True), col_csf_features)], remainder='drop')), ('var', VarianceThreshold(0)), ('e', Ridge(alpha=optpars['fnc_graph_ridge_alpha'][target]))]": 1,
      "[('columns', ColumnTransformer([('wm', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_wm_features), ('wm2', FunctionTransformer(square, validate=True), col_wm_features), ('csf', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_csf_features), ('csf2', FunctionTransformer(square, validate=True), col_csf_features), ('gm_all', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_gm_all)], remainder='drop')), ('win', FunctionTransformer(winsorize, validate=True)), ('e', Ridge(alpha=optpars['gm_all_ridge_alpha'][target]))]": 1,
      "[('columns', ColumnTransformer([('sbm', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_loading_features), ('PNI', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_pni)], remainder='drop')), ('e', Ridge(alpha=optpars['sbm_PNI_ridge_alpha'][target]))]": 1,
      "[('pca', pca), ('linear', linear)]": 1,
      "[('clf', LGBMClassifier(random_state=seed_train, n_jobs=1))]": 1,
      "[('prep', PrepPipeline(notes='with cat encode', cat_encode=True)), ('clf', LGBMClassifier(random_state=seed_train, n_jobs=1, learning_rate=0.3, n_estimators=n_estimators))]": 1,
      "[('Scaler', StandardScaler()), ('GBRegressor', GradientBoostingRegressor())]": 1,
      "[('Scaler', StandardScaler()), ('Votings', VotingRegressor([('GBRegressor', GradientBoostingRegressor()), ('XGBR', XGBRegressor()), ('RFR', RandomForestRegressor(random_state=seed))]))]": 1,
      "[('Scaler', StandardScaler()), ('Votings', VotingRegressor([('GBRegressor', GradientBoostingRegressor()), ('RFR', RandomForestRegressor(random_state=seed))]))]": 1,
      "[('Scaler', StandardScaler()), ('Votings', VotingRegressor([('XGBR', XGBRegressor()), ('RFR', RandomForestRegressor(random_state=seed))]))]": 1,
      "[('t', scaler), ('q', qa), ('m', NB)]": 1,
      "[('imputer', SimpleImputer(strategy='constant', fill_value=-10)), ('biner', KBinsDiscretizer(n_bins=9, encode='onehot-dense', strategy='uniform'))]": 1,
      "[('preprocessor', preprocessor), ('model', models['Logistic Regression'])]": 1,
      "[('scaler', StandardScaler()), ('clf', nn)]": 1,
      "[('scaler', StandardScaler()), ('clf', dnn)]": 1,
      "[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('lr', LogisticRegression())]": 1,
      "[('cat_feature_selector', feature_selector(cat_features_index)), ('imputer', SimpleImputer(strategy='most_frequent')), ('encoder', OneHotEncoder(sparse=False, categories='auto'))]": 1,
      "[('num_feature_selector', feature_selector(num_features_index)), ('num_transformer', num_transformer()), ('Imputer', SimpleImputer(strategy='median')), ('Scalar', StandardScaler())]": 1,
      "[('count', CountVectorizer()), ('tfid', TfidfTransformer())]": 1,
      "[('simple_imputer', SimpleImputer(strategy='median')), ('std_scaler', StandardScaler())]": 1,
      "[('preprocessor', preprocessor), ('model', best_model)]": 1,
      "[('imputer', SimpleImputer(missing_values=np.nan, strategy='mean')), ('stndard', StandardScaler())]": 1,
      "PIPE.steps + [('eda', edat)]": 1,
      "[('imputer', SimpleImputer(missing_values=np.nan, strategy='mean')), ('x_x2', FeatureUnion([('x', IdentityTransformer()), ('x2_interactions', ColumnTransformer([('top10_interactions', PolynomialFeatures(2, interaction_only=True, include_bias=False), [44, 45, 41, 42, 43, 62, 5, 60, 63, 6])]))]))]": 1,
      "pipeline": 1,
      "[('vect', CountVectorizer(tokenizer=lambda x: [i.strip() for i in x.split(',')], lowercase=False)), ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=0.001, random_state=42, max_iter=5, tol=None))]": 1,
      "[('vect', CountVectorizer(tokenizer=lambda x: [i.strip() for i in x.split(',')], lowercase=False)), ('tfidf', TfidfTransformer()), ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=0.001, random_state=42, max_iter=5, tol=None))]": 1,
      "[('svd', svd), ('scl', scl), ('lr_model', lr_model)]": 1,
      "[('vect', CountVectorizer(ngram_range=(1, 1))), ('tfidf', TfidfTransformer()), ('clf', SGDClassifier(loss='modified_huber', penalty='l2', alpha=0.0001, random_state=42, tol=None))]": 1,
      "[('vec', count_vect), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())]": 1,
      "[('transformations', transformer), ('rf', model)]": 1,
      "[('scaling', preprocessing.RobustScaler()), ('lasso', Lasso(alpha=0.0004225349823414949, max_iter=10000000.0, tol=0.001, random_state=random_state))]": 1,
      "[('scaling', preprocessing.RobustScaler()), ('elastic_net', ElasticNet(alpha=0.0005033042674715873, l1_ratio=0.8201479505715717, positive=True, precompute=False, selection='random', max_iter=10000000.0, tol=0.001, random_state=random_state))]": 1,
      "[('scaling', preprocessing.RobustScaler()), ('ridge', Ridge(alpha=12.773681311355642, random_state=random_state))]": 1,
      "[('scaling', preprocessing.RobustScaler()), ('svr', svm.SVR(C=46, epsilon=0.009019504329938493, gamma=0.0003434802243340735))]": 1,
      "[('gl', GalaxyClassifier(lgb_params=lgb_params, cv=5)), ('al', RealClassifier(lgb_params=al_lgb_params, cv=5))]": 1,
      "[('vt', VarianceThreshold(threshold=0.0)), ('ut', UniqueTransformer()), ('fu', FeatureUnion([('pca', PCA(n_components=100)), ('ct-2', ClassifierTransformer(get_rfc(), n_classes=2, cv=5)), ('ct-3', ClassifierTransformer(get_rfc(), n_classes=3, cv=5)), ('ct-4', ClassifierTransformer(get_rfc(), n_classes=4, cv=5)), ('ct-5', ClassifierTransformer(get_rfc(), n_classes=5, cv=5)), ('st', StatsTransformer(stat_funs=get_stat_funs(), verbose=2))])), ('ln', LnTransformer())]": 1,
      "[('qt', QuantileTransformer(output_distribution='normal')), ('pca', PCA(n_components=N))]": 1,
      "[('qt', QuantileTransformer(output_distribution='normal')), ('pca', PCA(n_components=n))]": 1,
      "[('qt', QuantileTransformer(output_distribution='normal')), ('pca', PCA(n_components=d_GENE))]": 1,
      "[('union', gene_union), ('var', VarianceThreshold(0.8))]": 1,
      "[('qt', QuantileTransformer(output_distribution='normal')), ('pca', PCA(n_components=d_CELL))]": 1,
      "[('union', cell_union), ('var', VarianceThreshold(0.8))]": 1,
      "[('ohc', OneHotEncoder())]": 1,
      "[('vectorizer', CountVectorizer(analyzer='word', ngram_range=[1, 3], stop_words=nltk.corpus.stopwords.words('english'))), ('clf', LogisticRegression())]": 1,
      "[('union', FeatureUnion(transformer_list=[('text_features', Pipeline([('selector', get_text_data), ('vectorizer', CountVectorizer(analyzer='word', ngram_range=[1, 3], stop_words=nltk.corpus.stopwords.words('english')))]))])), ('clf', LogisticRegression(penalty='l1'))]": 1,
      "[('union', FeatureUnion(transformer_list=[('text_features', Pipeline([('selector', get_text_data), ('vectorizer', CountVectorizer(analyzer='word', ngram_range=[1, 3], stop_words=nltk.corpus.stopwords.words('english')))])), ('tfidf', Pipeline([('selector', get_text_data), ('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=[1, 3], stop_words=nltk.corpus.stopwords.words('english')))])), ('char_features', Pipeline([('selector', get_text_data), ('vectorizer', TfidfVectorizer(analyzer='char', ngram_range=[3, 5], stop_words=nltk.corpus.stopwords.words('english')))]))])), ('clf', LogisticRegression(penalty='l1'))]": 1,
      "[('union', FeatureUnion(transformer_list=[('text_features', Pipeline([('selector', get_text_data), ('vectorizer', CountVectorizer(analyzer='word', ngram_range=[1, 3], stop_words=nltk.corpus.stopwords.words('english')))])), ('tfidf', Pipeline([('selector', get_text_data), ('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=[1, 3], stop_words=nltk.corpus.stopwords.words('english')))])), ('char_features', Pipeline([('selector', get_text_data), ('vectorizer', TfidfVectorizer(analyzer='char', ngram_range=[3, 5], stop_words=nltk.corpus.stopwords.words('english')))]))])), ('clf', MultinomialNB())]": 1,
      "[('union', FeatureUnion(transformer_list=[('text_features', Pipeline([('selector', get_text_data), ('vectorizer', CountVectorizer(analyzer='word', ngram_range=[1, 3], stop_words=nltk.corpus.stopwords.words('english')))])), ('tfidf', Pipeline([('selector', get_text_data), ('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=[1, 3], stop_words=nltk.corpus.stopwords.words('english')))])), ('char_features', Pipeline([('selector', get_text_data), ('vectorizer', TfidfVectorizer(analyzer='char', ngram_range=[3, 5], stop_words=nltk.corpus.stopwords.words('english')))]))])), ('clf', LinearSVC())]": 1,
      "[('extract_features', features), (name, classifier)]": 1,
      "[('vect', TfidfVectorizer(min_df=3)), ('logreg', LinearRegression())]": 1,
      "[('vect', TfidfVectorizer(min_df=3, ngram_range=(1, 2))), ('logreg', LinearRegression())]": 1,
      "[('vect', TfidfVectorizer(min_df=3)), ('ridgereg', Ridge())]": 1,
      "[('vect', TfidfVectorizer(min_df=3)), ('ridgereg', AdaBoostRegressor(Ridge()))]": 1,
      "[('vect', TfidfVectorizer(min_df=3)), ('ridgereg', Ridge(alpha=0.95))]": 1,
      "[('vect', TfidfVectorizer(min_df=3)), ('randomforest', RandomForestRegressor())]": 1,
      "[('vect', TfidfVectorizer(min_df=3)), ('XGBRegressor', XGBRegressor(n_estimators=500, learning_rate=0.05))]": 1,
      "[('impute', SimpleImputer(strategy='mean')), ('scale', StandardScaler())]": 1,
      "[('nca', nca), ('knn', model)]": 1,
      "[('tfidf', tfidf), ('nb', nb), ('lr', lr)]": 1,
      "[('lm', lm), ('tfidf', tfidf), ('nb', nb), ('lr', lr)]": 1,
      "[('lm', lm), ('wc_tfidfs', FeatureUnion([('tfidf_w', tfidf_w), ('tfidf_c', tfidf_c)])), ('nb', nb), ('lr', lr)]": 1,
      "[('vt', VarianceThreshold(threshold=0.0)), ('ut', UniqueTransformer()), ('fu', FeatureUnion([('pca', PCA(n_components=100)), ('ct-2', ClassifierTransformer(get_rfc(), n_classes=2, cv=5)), ('ct-3', ClassifierTransformer(get_rfc(), n_classes=3, cv=5)), ('ct-5', ClassifierTransformer(get_rfc(), n_classes=5, cv=5)), ('ct-auto', ClassifierTransformer(get_rfc(), n_classes='auto', cv=5)), ('st', StatsTransformer(stat_funs=get_stat_funs(), verbose=2))])), ('xgb-cv', XGBRegressorCV(xgb_params=xgb_params, fit_params=fit_params, cv=10))]": 1,
      "[('rob_scale', RobustScaler())]": 1,
      "[('scaling', StandardScaler()), ('LR', LogisticRegression())]": 1,
      "[('scaling', StandardScaler()), ('Adb', AdaBoostRegressor(base_estimator=dt_stump, random_state=123))]": 1,
      "[('scaling', StandardScaler()), ('Bgr', BaggingRegressor(base_estimator=dt_stump, random_state=123))]": 1,
      "[('scaling', StandardScaler()), ('grad_boost', GradientBoostingRegressor(random_state=123))]": 1,
      "[('encoder', CountEncoder(cols=[0, 2])), ('classify', classifier)]": 1,
      "[('sc', sc), ('SVM', svm)]": 1,
      "[('selecting', FunctionTransformer(lambda data: data.iloc[:, numeric_data_indices])), ('scaling', StandardScaler(with_mean=True))]": 1,
      "[('selecting', FunctionTransformer(lambda data: data.iloc[:, numeric_data_indices_log])), ('scaling', PowerTransformer(standardize=True))]": 1,
      "[('selecting', FunctionTransformer(lambda data: data.iloc[:, categorical_data_indices])), ('hot_encoding', OneHotEncoder(handle_unknown='ignore'))]": 1,
      "[('feature_processing', combined_features), ('classifier', tree_class)]": 1,
      "[('feature_processing', combined_features), ('classifier', xgb_class)]": 1,
      "[('feature_processing', combined_features), ('classifier', logreg)]": 1,
      "[('feature_processing', combined_features), ('classifier', svm)]": 1,
      "[('scaler2', StandardScaler()), ('MLPRegressor: ', model1)]": 1,
      "[('kbest', kbest), ('lr', LogisticRegression())]": 1,
      "[('tfidf', TfidfVectorizer()), ('clf', lgbm.LGBMClassifier())]": 1,
      "[('lr_clf', LogisticRegression(solver='lbfgs', max_iter=10000))]": 1,
      "input": 1,
      "[('vectorizer', CountVectorizer(analyzer=text_process)), ('tfidf_transformer', TfidfTransformer())]": 1,
      "[('imp_num', SimpleImputer(strategy='median')), ('scaler', RobustScaler())]": 1,
      "[('imp_cat', SimpleImputer(strategy='most_frequent')), ('ohe', OneHotEncoder(handle_unknown='ignore'))]": 1,
      "[sc, ('LinearRegression', LinearRegression())]": 1,
      "[sc, ('Ridge', Ridge())]": 1,
      "[sc, ('Lasso', Lasso())]": 1,
      "[sc, ('BayesianRidge', BayesianRidge())]": 1,
      "[sc, ('Elastic', ElasticNet())]": 1,
      "[sc, ('SGD', SGDRegressor())]": 1,
      "[sc, ('Huber', HuberRegressor())]": 1,
      "[sc, ('RANSAC', RANSACRegressor())]": 1,
      "[sc, ('GradientBoosting', GradientBoostingRegressor())]": 1,
      "[sc, ('AdaBoost', AdaBoostRegressor())]": 1,
      "[sc, ('ExtraTrees', ExtraTreesRegressor())]": 1,
      "[sc, ('RandomForest', RandomForestRegressor())]": 1,
      "[sc, ('Bagging', BaggingRegressor())]": 1,
      "[sc, ('KNeighbors', KNeighborsRegressor())]": 1,
      "[sc, ('DecisionTree', DecisionTreeRegressor())]": 1,
      "[sc, ('XGB', XGBRegressor())]": 1,
      "[('LinearRegression', LinearRegression())]": 1,
      "[('Ridge', Ridge())]": 1,
      "[('Lasso', Lasso())]": 1,
      "[('BayesianRidge', BayesianRidge())]": 1,
      "[('Elastic', ElasticNet())]": 1,
      "[('SGD', SGDRegressor())]": 1,
      "[('Huber', HuberRegressor())]": 1,
      "[('RANSAC', RANSACRegressor())]": 1,
      "[('GradientBoosting', GradientBoostingRegressor())]": 1,
      "[('AdaBoost', AdaBoostRegressor())]": 1,
      "[('ExtraTrees', ExtraTreesRegressor())]": 1,
      "[('RandomForest', RandomForestRegressor())]": 1,
      "[('Bagging', BaggingRegressor())]": 1,
      "[('KNeighbors', KNeighborsRegressor())]": 1,
      "[('DecisionTree', DecisionTreeRegressor())]": 1,
      "[('XGB', XGBRegressor())]": 1,
      "[('LR', LogisticRegression())]": 1,
      "[('BNB', BernoulliNB())]": 1,
      "[('MNB', MultinomialNB())]": 1,
      "[('LNB', LinearSVC())]": 1,
      "[('scalar', StandardScaler()), ('log', LogisticRegression())]": 1,
      "[('scalar', StandardScaler()), ('ada', AdaBoostClassifier())]": 1,
      "[('scalar', StandardScaler()), ('xgb', XGBClassifier())]": 1,
      "[('scalar', StandardScaler()), ('lgm', LGBMClassifier())]": 1,
      "[('scaler', StandardScaler()), ('log_reg', LogisticRegression())]": 1,
      "[('scaler', StandardScaler()), ('lgbm', LGBMClassifier())]": 1,
      "[('cat', CatBoostClassifier(classes_count=4))]": 1,
      "[('scale', StandardScaler()), ('gnb', GaussianNB())]": 1,
      "[('scale', StandardScaler()), ('bnb', BernoulliNB())]": 1,
      "[('scale', StandardScaler()), ('lr', LogisticRegression(solver='sag', multi_class='multinomial'))]": 1,
      "[('scale', StandardScaler()), ('rf', RandomForestClassifier())]": 1,
      "[('scale', StandardScaler()), ('lgbm', LGBMClassifier())]": 1,
      "[('scale', StandardScaler()), ('xgb', XGBClassifier())]": 1,
      "[('scale', StandardScaler()), ('knn', KNeighborsClassifier())]": 1,
      "[('scale', StandardScaler()), ('bnb', BernoulliNB(alpha=4.0))]": 1,
      "[('scale', StandardScaler()), ('lgbm', LGBMClassifier(boosting_type='gbdt', num_leaves=35, learning_rat=0.1, objective='multiclass'))]": 1,
      "[('scaler', StandardScaler()), ('lr', LogisticRegression(multi_class='multinomial', n_jobs=-1))]": 1,
      "[('scaler', StandardScaler()), ('cat', CatBoostClassifier(loss_function='MultiClass', eval_metric='MultiClass', verbose=False))]": 1,
      "[('scaler', StandardScaler()), ('sgd', SGDClassifier(alpha=0.001, early_stopping=True, n_jobs=-1))]": 1,
      "[('scaler', StandardScaler()), ('lgbm', LGBMClassifier(n_estimators=150, num_leaves=35, objective='multiclass'))]": 1,
      "[('scaler', StandardScaler()), ('bnb', BernoulliNB(alpha=7.0))]": 1,
      "[('scaler', StandardScaler()), ('xgb', XGBClassifier())]": 1,
      "[('prep', preprocessor), ('RandomForest', rfc)]": 1,
      "[('kmeans', KMeans()), ('kneighbors', KNeighborsClassifier())]": 1,
      "[('tfidf', TfidfVectorizer()), ('nbayes', MultinomialNB())]": 1,
      "[('tfidf', TfidfVectorizer()), ('svm', SGDClassifier())]": 1,
      "[('tfidf', TfidfVectorizer()), ('dtree', DecisionTreeClassifier())]": 1,
      "[('tfidf', TfidfVectorizer()), ('gboost', GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=3, random_state=0))]": 1,
      "[('w2v mean vectorizer', MeanEmbeddingVectorizer(w2v)), ('extra trees', ExtraTreesClassifier(n_estimators=25))]": 1,
      "[('w2v tfidf vectorizer', TfidfEmbeddingVectorizer(w2v)), ('extra trees', ExtraTreesClassifier(n_estimators=25))]": 1,
      "[('w2v mean vectorizer', MeanEmbeddingVectorizer(w2v)), ('SVM', LinearSVC(random_state=0, tol=0.0001))]": 1,
      "[('word2vec vectorizer', TfidfEmbeddingVectorizer(w2v)), ('SVM', LinearSVC(random_state=0, tol=0.0001))]": 1,
      "[('w2v mean vectorizer', MeanEmbeddingVectorizer(w2v)), ('MLP', MLPClassifier(solver='lbfgs', alpha=1e-05, hidden_layer_sizes=(20, 10, 2), random_state=1))]": 1,
      "[('word2vec vectorizer', TfidfEmbeddingVectorizer(w2v)), ('MLP', MLPClassifier(solver='lbfgs', alpha=1e-05, hidden_layer_sizes=(20, 10, 2), random_state=1))]": 1,
      "[('glov mean vectorizer', MeanEmbeddingVectorizer(glov)), ('Guassian NB', GaussianNB())]": 1,
      "[('glov tfidf vectorizer', TfidfVectorizer(glov)), ('transform', TfidfTransformer()), ('Guassian NB', MultinomialNB())]": 1,
      "[('glov mean vectorizer', MeanEmbeddingVectorizer(glov)), ('extra trees', ExtraTreesClassifier(n_estimators=25))]": 1,
      "[('glov tfidf vectorizer', TfidfVectorizer(glov)), ('transform', TfidfTransformer()), ('extra trees', ExtraTreesClassifier(n_estimators=25))]": 1,
      "[('glov mean vectorizer', MeanEmbeddingVectorizer(glov)), ('SVM', LinearSVC(random_state=42, tol=1e-05))]": 1,
      "[('glov tfidf vectorizer', TfidfVectorizer(glov)), ('transform', TfidfTransformer()), ('SVM', LinearSVC(random_state=0, tol=1e-05))]": 1,
      "[('glov mean vectorizer', MeanEmbeddingVectorizer(glov)), ('MLP', MLPClassifier(solver='lbfgs', alpha=1e-05, hidden_layer_sizes=(20, 10, 2), random_state=42))]": 1,
      "[('glov tfidf vectorizer', TfidfVectorizer(glov)), ('transform', TfidfTransformer()), ('MLP', MLPClassifier(solver='lbfgs', alpha=1e-05, hidden_layer_sizes=(20, 10, 2), random_state=42))]": 1,
      "[('glov mean vectorizer', MeanEmbeddingVectorizer(glov)), ('LREG', LogisticRegression(solver='lbfgs', multi_class='multinomial', random_state=42))]": 1,
      "[('glov tfidf vectorizer', TfidfVectorizer(glov)), ('transform', TfidfTransformer()), ('LREG', LogisticRegression(solver='lbfgs', multi_class='multinomial', random_state=42))]": 1,
      "[('program mean vectorizer', MeanEmbeddingVectorizer(program)), ('Guassian NB', GaussianNB())]": 1,
      "[('program tfidf vectorizer', TfidfVectorizer(program)), ('transform', TfidfTransformer()), ('Guassian NB', MultinomialNB())]": 1,
      "[('program mean vectorizer', MeanEmbeddingVectorizer(program)), ('extra trees', ExtraTreesClassifier(n_estimators=20))]": 1,
      "[('program tfidf vectorizer', TfidfEmbeddingVectorizer(program)), ('extra trees', ExtraTreesClassifier(n_estimators=20))]": 1,
      "[('program mean vectorizer', MeanEmbeddingVectorizer(program)), ('SVM', LinearSVC(random_state=0, tol=1e-05))]": 1,
      "[('word2vec vectorizer', TfidfEmbeddingVectorizer(program)), ('SVM', LinearSVC(random_state=0, tol=1e-05))]": 1,
      "[('program mean vectorizer', MeanEmbeddingVectorizer(program)), ('MLP', MLPClassifier(solver='lbfgs', alpha=1e-05, hidden_layer_sizes=(20, 10, 2), random_state=42))]": 1,
      "[('word2vec vectorizer', TfidfEmbeddingVectorizer(program)), ('MLP', MLPClassifier(solver='lbfgs', alpha=1e-05, hidden_layer_sizes=(20, 10, 2), random_state=42))]": 1,
      "[('program mean vectorizer', MeanEmbeddingVectorizer(program)), ('LREG', LogisticRegression(solver='lbfgs', multi_class='multinomial', random_state=42))]": 1,
      "[('program tfidf vectorizer', TfidfVectorizer(program)), ('transform', TfidfTransformer()), ('LREG', LogisticRegression(solver='lbfgs', multi_class='multinomial', random_state=42))]": 1,
      "[('google mean vectorizer', MeanEmbeddingVectorizer(google)), ('Guassian NB', GaussianNB())]": 1,
      "[('google tfidf vectorizer', TfidfVectorizer(google)), ('transform', TfidfTransformer()), ('Guassian NB', MultinomialNB())]": 1,
      "[('google mean vectorizer', MeanEmbeddingVectorizer(google)), ('extra trees', ExtraTreesClassifier(n_estimators=20))]": 1,
      "[('google tfidf vectorizer', TfidfEmbeddingVectorizer(google)), ('extra trees', ExtraTreesClassifier(n_estimators=20))]": 1,
      "[('google mean vectorizer', MeanEmbeddingVectorizer(google)), ('SVM', LinearSVC(random_state=0, tol=1e-05))]": 1,
      "[('word2vec vectorizer', TfidfEmbeddingVectorizer(google)), ('SVM', LinearSVC(random_state=0, tol=1e-05))]": 1,
      "[('google mean vectorizer', MeanEmbeddingVectorizer(google)), ('MLP', MLPClassifier(solver='lbfgs', alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1))]": 1,
      "[('word2vec vectorizer', TfidfEmbeddingVectorizer(google)), ('MLP', MLPClassifier(solver='lbfgs', alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1))]": 1,
      "[('google mean vectorizer', MeanEmbeddingVectorizer(google)), ('LREG', LogisticRegression(solver='lbfgs', multi_class='multinomial', random_state=42))]": 1,
      "[('google tfidf vectorizer', TfidfVectorizer(google)), ('transform', TfidfTransformer()), ('LREG', LogisticRegression(solver='lbfgs', multi_class='multinomial', random_state=42))]": 1,
      "[('wiki mean vectorizer', MeanEmbeddingVectorizer(wiki)), ('Guassian NB', GaussianNB())]": 1,
      "[('wiki tfidf vectorizer', TfidfVectorizer(wiki)), ('transform', TfidfTransformer()), ('Guassian NB', MultinomialNB())]": 1,
      "[('wiki mean vectorizer', MeanEmbeddingVectorizer(wiki)), ('extra trees', ExtraTreesClassifier(n_estimators=20))]": 1,
      "[('wiki tfidf vectorizer', TfidfVectorizer(wiki)), ('transform', TfidfTransformer()), ('extra trees', ExtraTreesClassifier(n_estimators=20))]": 1,
      "[('wiki mean vectorizer', MeanEmbeddingVectorizer(wiki)), ('SVM', LinearSVC(random_state=0, tol=1e-05))]": 1,
      "[('wiki tfidf vectorizer', TfidfVectorizer(wiki)), ('transform', TfidfTransformer()), ('SVM', LinearSVC(random_state=0, tol=1e-05))]": 1,
      "[('wiki mean vectorizer', MeanEmbeddingVectorizer(wiki)), ('MLP', MLPClassifier(solver='lbfgs', alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1))]": 1,
      "[('wiki tfidf vectorizer', TfidfVectorizer(wiki)), ('transform', TfidfTransformer()), ('MLP', MLPClassifier(solver='lbfgs', alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1))]": 1,
      "[('wiki mean vectorizer', MeanEmbeddingVectorizer(wiki)), ('LREG', LogisticRegression(solver='lbfgs', multi_class='multinomial', random_state=42))]": 1,
      "[('wiki tfidf vectorizer', TfidfVectorizer(wiki)), ('transform', TfidfTransformer()), ('LREG', LogisticRegression(solver='lbfgs', multi_class='multinomial', random_state=42))]": 1,
      "[('selector', ItemSelector(fields=['len_name', 'len_desc', 'max_word_desc', 'nsents_desc', 'fstartcaps_desc', 'fcaps_name', 'fstartcaps_name'])), ('minmaxscaler', MinMaxScaler())]": 1,
      "[('selector', ItemSelector(fields='name')), ('cv', MPCountVectorizer(ngram_weight=[1.5, 1.0], seq_l=20, analyzer=analyzer, min_df=4))]": 1,
      "[('selector', ItemSelector(fields='item_description')), ('cv', MPCountVectorizer(ngram_weight=[1.0, 1.0], seq_l=75, analyzer=analyzer, min_df=9)), ('tfidf', TfidfTransformer(sublinear_tf=True))]": 1,
      "[('interaction_remover', FeatureRemover(np.array([0, 1, 9]))), ('feature_filter', FeatureFilter(100)), ('lgbm', LGBMWrapper(params={'learning_rate': 0.6, 'application': 'regression', 'max_depth': 3, 'num_leaves': 60, 'verbosity': -1, 'metric': 'RMSE', 'data_random_seed': 1, 'bagging_fraction': 0.5, 'nthread': 4, 'min_data_in_leaf': 200, 'max_bin': 30}, num_boost_round=5000, early_stopping_rounds=250, verbose_eval=1000, categorical_feature=list(range(6))))]": 1,
      "[('ohe', SparseOneHotEncoder(categorical_features=np.arange(8))), ('feature_filter', FeatureFilter(2)), ('linear_regressors', FeatureUnion([('fm_ftrl', FM_FTRLWrapper(alpha=0.015123039358983292, beta=0.003696159595914427, L1=0.0001071848083393167, L2=0.15063815187520505, alpha_fm=0.009424503125353001, L2_fm=0.0, init_fm=0.01, D_fm=157, e_noise=0.00011964508569471388, iters=18, inv_link='identity', threads=4))]))]": 1,
      "(*sklearn_pipeline_steps(categorical_columns, verbose=verbose), ('xgb', xgb.XGBClassifier(n_estimators=1000, seed=42, objective='multi:softprob', subsample=0.8, colsample_bytree=0.8)))": 1,
      "[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('model', KNeighborsClassifier(n_neighbors=10, weights='distance', algorithm='brute'))]": 1,
      "[('Prepo', Transformer), ('Clf', RandomForestRegressor(n_jobs=-1, random_state=RANDOM_STATE))]": 1,
      "[('elapsed_time', creation.CombineWithReferenceFeature(variables_to_combine=['YrSold'], reference_variables=['YearBuilt', 'YearRemodAdd', 'GarageYrBlt'], operations=['sub'])), ('elapsed_time2', creation.CombineWithReferenceFeature(variables_to_combine=['YearRemodAdd', 'GarageYrBlt'], reference_variables=['YearBuilt'], operations=['sub'])), ('total_surface', creation.MathematicalCombination(variables_to_combine=['TotRmsAbvGrd', 'FullBath', 'HalfBath', 'KitchenAbvGr'], math_operations=['sum'], new_variables_names=['Total_Surface'])), ('surface_room', creation.CombineWithReferenceFeature(variables_to_combine=['GrLivArea'], reference_variables=['Total_Surface'], operations=['div'])), ('qual_sf', creation.MathematicalCombination(variables_to_combine=['1stFlrSF', '2ndFlrSF'], math_operations=['sum'], new_variables_names=['HighQualSF'])), ('drop_features', sel.DropFeatures(features_to_drop=['YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'YrSold'])), ('missing_ind', imp.AddMissingIndicator(missing_only=True, variables=numerical_arbitrary + categorical_mode + new_vars)), ('arbitrary_number', imp.EndTailImputer(imputation_method='iqr', tail='right', fold=3, variables=numerical_arbitrary)), ('median', imp.MeanMedianImputer(imputation_method='median', variables=numerical_median + new_vars)), ('frequent', imp.CategoricalImputer(imputation_method='frequent', variables=categorical_mode, return_object=True)), ('missing', imp.CategoricalImputer(imputation_method='missing', variables=categorical_missing, return_object=True)), ('transformation', tf.YeoJohnsonTransformer(variables=discretize)), ('encoder', enc.OneHotEncoder(top_categories=10)), ('scaler', StandardScaler())]": 1,
      "[('elapsed_time', creation.CombineWithReferenceFeature(variables_to_combine=['YrSold'], reference_variables=['YearBuilt', 'YearRemodAdd', 'GarageYrBlt'], operations=['sub'])), ('elapsed_time2', creation.CombineWithReferenceFeature(variables_to_combine=['YearRemodAdd', 'GarageYrBlt'], reference_variables=['YearBuilt'], operations=['sub'])), ('total_surface', creation.MathematicalCombination(variables_to_combine=['TotRmsAbvGrd', 'FullBath', 'HalfBath', 'KitchenAbvGr'], math_operations=['sum'], new_variables_names=['Total_Surface'])), ('surface_room', creation.CombineWithReferenceFeature(variables_to_combine=['GrLivArea'], reference_variables=['Total_Surface'], operations=['div'])), ('qual_sf', creation.MathematicalCombination(variables_to_combine=['1stFlrSF', '2ndFlrSF'], math_operations=['sum'], new_variables_names=['HighQualSF'])), ('drop_features', sel.DropFeatures(features_to_drop=['YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'YrSold'])), ('missing_ind', imp.AddMissingIndicator(missing_only=True, variables=numerical_arbitrary + categorical_mode + new_vars)), ('arbitrary_number', imp.EndTailImputer(imputation_method='iqr', tail='right', fold=3, variables=numerical_arbitrary)), ('median', imp.MeanMedianImputer(imputation_method='median', variables=numerical_median + new_vars)), ('frequent', imp.CategoricalImputer(imputation_method='frequent', variables=categorical_mode, return_object=True)), ('missing', imp.CategoricalImputer(imputation_method='missing', variables=categorical_missing, return_object=True)), ('rare_grouping', enc.RareLabelEncoder(tol=0.1, n_categories=1)), ('discretizer', disc.EqualWidthDiscretiser(bins=3, variables=discretize, return_object=True)), ('encoder', enc.OrdinalEncoder(encoding_method='ordered')), ('scaler', StandardScaler())]": 1,
      "[('elapsed_time', creation.CombineWithReferenceFeature(variables_to_combine=['YrSold'], reference_variables=['YearBuilt', 'YearRemodAdd', 'GarageYrBlt'], operations=['sub'])), ('elapsed_time2', creation.CombineWithReferenceFeature(variables_to_combine=['YearRemodAdd', 'GarageYrBlt'], reference_variables=['YearBuilt'], operations=['sub'])), ('total_surface', creation.MathematicalCombination(variables_to_combine=['TotRmsAbvGrd', 'FullBath', 'HalfBath', 'KitchenAbvGr'], math_operations=['sum'], new_variables_names=['Total_Surface'])), ('surface_room', creation.CombineWithReferenceFeature(variables_to_combine=['GrLivArea'], reference_variables=['Total_Surface'], operations=['div'])), ('qual_sf', creation.MathematicalCombination(variables_to_combine=['1stFlrSF', '2ndFlrSF'], math_operations=['sum'], new_variables_names=['HighQualSF'])), ('drop_features', sel.DropFeatures(features_to_drop=['YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'YrSold'])), ('missing_ind', imp.AddMissingIndicator(missing_only=True, variables=numerical_arbitrary + categorical_mode + new_vars)), ('arbitrary_number', imp.EndTailImputer(imputation_method='iqr', tail='right', fold=3, variables=numerical_arbitrary)), ('median', imp.MeanMedianImputer(imputation_method='median', variables=numerical_median + new_vars)), ('frequent', imp.CategoricalImputer(imputation_method='frequent', variables=categorical_mode, return_object=True)), ('missing', imp.CategoricalImputer(imputation_method='missing', variables=categorical_missing, return_object=True)), ('rare_grouping', enc.RareLabelEncoder(tol=0.1, n_categories=1)), ('discretizer', disc.DecisionTreeDiscretiser(cv=3, scoring='neg_mean_squared_error', variables=discretize, regression=True, random_state=0)), ('encoder', enc.DecisionTreeEncoder(encoding_method='arbitrary', cv=3, scoring='neg_mean_squared_error', regression=True, random_state=0)), ('scaler', StandardScaler())]": 1,
      "[('constant', DropConstantFeatures(tol=0.998)), ('duplicated', DropDuplicateFeatures()), ('correlation', SmartCorrelatedSelection(threshold=0.8, selection_method='model_performance', estimator=RandomForestClassifier(n_estimators=10, random_state=1)))]": 1,
      "[('constant', DropConstantFeatures(tol=0.998)), ('duplicated', DropDuplicateFeatures()), ('shuffle', SelectByShuffling(estimator=RandomForestClassifier(n_estimators=10, max_depth=2, random_state=1), scoring='roc_auc', cv=3)), ('random_forest', RandomForestClassifier(n_estimators=10, max_depth=2, random_state=1))]": 1,
      "pipeline_steps": 1,
      "[('scaler', StandardScaler()), (model_name, model)]": 1,
      "[('scaler', StandardScaler()), ('lineardiscriminantanalysis', LogisticRegression(random_state=1, solver='lbfgs', multi_class='multinomial', C=100, penalty='l2', max_iter=100))]": 1,
      "[('tfidf', tfidf), ('tsvd', tsvd), ('scl', scl), ('class', RandomForestClassifier())]": 1,
      "[('scaler', StandardScaler()), ('classifier', LogisticRegression())]": 1,
      "[('scaler', StandardScaler()), ('classifier', KNeighborsClassifier())]": 1,
      "[('scaler', MinMaxScaler()), ('classifier', LogisticRegression(solver='lbfgs', n_jobs=-1))]": 1,
      "[('classifier', ExtraTreesClassifier(n_estimators=500, random_state=0))]": 1,
      "[('classifier', RandomForestClassifier(n_estimators=500, random_state=0))]": 1,
      "[('classifier', XGBClassifier(n_estimators=50, subsample=0.5))]": 1,
      "[('imputer', company_imputer), ('trans', CompanyTransformer()), ('vect', CountVectorizer(max_features=10))]": 1,
      "[('imputer', country_imputer), ('trans', CountryTransformer()), ('vect', CountVectorizer(min_df=300))]": 1,
      "[('imputer', date_imputer), ('trans', DateTransformer())]": 1,
      "[('imputer', genre_imputer), ('trans', GenreTransformer()), ('vect', CountVectorizer())]": 1,
      "[('imputer', keyword_imputer), ('trans', KeywordTransformer()), ('vect', TfidfVectorizer(min_df=150))]": 1,
      "[('trans', LanguageTransformer()), ('vect', OneHotEncoder(handle_unknown='ignore'))]": 1,
      "[('imputer', spoken_language_imputer), ('trans', SpokenLanguageTransformer()), ('vect', CountVectorizer(min_df=75))]": 1,
      "[('union', column_transformer), ('selector', feature_selector), ('regressor', transformed_regressor)]": 1,
      "[('tfidf', TfidfVectorizer()), ('tsvd', TruncatedSVD(algorithm='arpack')), ('pa', PassiveAggressiveClassifier(max_iter=1000, average=True, early_stopping=True, validation_fraction=0.1, n_jobs=-1, n_iter_no_change=20, random_state=0))]": 1,
      "[('vectorizer', vectorizer), ('classifier', classifier_svm)]": 1,
      "[('vectorizer', vectorizer), ('lsa', lsa), ('classifier', classifier_xgboost)]": 1,
      "[('model', RandomForestClassifier(max_depth=11, n_jobs=-1, random_state=1))]": 1,
      "[('ctv', CountVectorizer(tokenizer=word_tokenize, ngram_range=(3, 3))), ('vot', ensemble.VotingClassifier(estimators=[('lr', linear_model.LogisticRegression(random_state=101, C=0.04)), ('rf', ensemble.RandomForestClassifier(max_depth=10)), ('nb', naive_bayes.MultinomialNB())], voting='soft'))]": 1,
      "[('label_encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-99)), ('mutual_gbm', mutual_gbm)]": 1,
      "[('label_encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-99)), ('RFE_gbm', RFE_gbm)]": 1,
      "[('column_preprocessor', column_preprocessor), ('svm', svm.SVC(kernel='rbf', C=1.2, gamma=0.2))]": 1,
      "Input1": 1,
      "[('select_numeric', DataFrameSelector(['Age', 'Fare', 'Family'])), ('imputer', SimpleImputer(strategy='median')), ('std_scaler', StandardScaler())]": 1,
      "[('select_cat', DataFrameSelector(['Pclass', 'Embarked'])), ('imputer', MostFrequentImputer()), ('cat_encoder', OneHotEncoder(sparse=False))]": 1,
      "[('Scaler', StandardScaler()), ('LASSO', Lasso())]": 1,
      "[('Scaler', StandardScaler()), ('Ridge', Ridge())]": 1,
      "[('Scaler', StandardScaler()), ('EN', ElasticNet())]": 1,
      "[('Scaler', StandardScaler()), ('KNN', KNeighborsRegressor())]": 1,
      "[('Scaler', StandardScaler()), ('CART', DecisionTreeRegressor())]": 1,
      "[('Scaler', StandardScaler()), ('Ada', AdaBoostRegressor())]": 1,
      "[('Scaler', StandardScaler()), ('XGB', XGBRegressor())]": 1,
      "[('Scaler', StandardScaler()), ('MLP', MLPRegressor())]": 1,
      "[('fill', Imputer(strategy='mean')), ('kbest', SelectKBest(f_regression, k=1))]": 1,
      "[('preprocessor', PreProcessor(thresh_feats, threshs)), ('feature_generator', FeatureGeneratorApplication()), ('col_tf', col_tf)]": 1,
      "[('v', TfidfVectorizer(min_df=5, max_df=500, max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 2), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words='english')), ('svd', TruncatedSVD(n_components=300, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('ada', AdaBoostClassifier(n_estimators=100))]": 1,
      "[('scaler', MinMaxScaler()), ('imputer', SimpleImputer())]": 1,
      "[('preprocessor', preprocessor), ('model', SVC(class_weight=None, random_state=0))]": 1,
      "[('preprocessor', preprocessor), ('model', RandomForestClassifier(class_weight=None, random_state=0))]": 1,
      "[('preprocessor', preprocessor), ('model', xgb.XGBClassifier(use_label_encoder=False, objective='binary:logistic', eval_metric='logloss'))]": 1,
      "[('cv', CountVectorizer()), ('lr', LogisticRegression())]": 1,
      "[('cv', CountVectorizer()), ('nb', MultinomialNB())]": 1,
      "[('cv', CountVectorizer()), ('review', LinearSVC())]": 1,
      "[('tfidf', TfidfVectorizer()), ('review', LogisticRegression())]": 1,
      "[('tfidf', TfidfVectorizer()), ('review', MultinomialNB())]": 1,
      "[('tfidf', TfidfVectorizer()), ('review', LinearSVC())]": 1,
      "[('vec', CountVectorizer(token_pattern=tks)), ('clf', OneVsRestClassifier(LogisticRegression()))]": 1,
      "[('scaler', None), ('knn', KNeighborsClassifier(n_jobs=-1))]": 1,
      "[('scaler', StandardScaler()), ('knn', KNeighborsClassifier(n_neighbors=k_Optimal))]": 1,
      "[('vect', vectorizer), ('chi', SelectKBest(chi2, k='all')), ('clf', RandomForestClassifier())]": 1,
      "[('scale', StandardScaler()), ('model ', model)]": 1,
      "[('scale', StandardScaler()), ('model ', RandomForestRegressor(n_jobs=-1))]": 1,
      "[('rfe', RFE(estimator=RandomForestClassifier(), verbose=1)), ('model', SVR())]": 1,
      "[('columntransformer', ColumnTransformer([('countvectorizer', vect, 'text')], remainder='drop'))]": 1,
      "[('preprocessor', preprocessor), ('classifier', nb)]": 1,
      "[('columntransformer', ColumnTransformer([('countvectorizer', vect, 'text')], remainder='drop')), ('clf', clf1)]": 1,
      "[('columntransformer', ColumnTransformer([('countvectorizer', vect, 'text')], remainder='drop')), ('clf', clf2)]": 1,
      "[('columntransformer', ColumnTransformer([('countvectorizer', vect, 'text')], remainder='drop')), ('functransformer', FunctionTransformer(lambda x: x.todense(), accept_sparse=True)), ('clf', clf3)]": 1,
      "[('kbest', SelectKBest(f_regression, k=15)), ('scaller', StandardScaler())]": 1,
      "[('createFeatures', CreateFeatures()), ('fillNaValues', FillNaValues()), ('featureSelector', FeatureSelector()), ('scaler', StandardScaler())]": 1,
      "[('createFeatures', CreateFeatures()), ('featureSelector', FeatureSelector1())]": 1,
      "[('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(sparse=False, handle_unknown='ignore'))]": 1,
      "[('numerical_imputer', SimpleImputer(strategy='median')), ('numerical_scaler', StandardScaler()), ('numerical_selector', SelectKBest(k=10))]": 1,
      "[('low_card_imputer', SimpleImputer(strategy='most_frequent')), ('low_card_selector', SelectKBest(chi2, k=10))]": 1,
      "[('categorical_imputer', SimpleImputer(strategy='most_frequent')), ('categorical_encoder', OneHotEncoder()), ('categorical_selector', SelectKBest(chi2, k=10))]": 1,
      "[('preprocessor', preprocessor), ('classifier', SGDClassifier(loss='log', random_state=0))]": 1,
      "[('normalizer', StandardScaler()), ('poli-features', PolynomialFeatures()), ('linear-model', LinearRegression())]": 1,
      "[('cat3_agrup', cat3_agrup), ('cat5_agrup', cat5_agrup), ('cat8_agrup', cat8_agrup)]": 1,
      "[('selector', ColumnSelection(features=INITIAL_FEATURES)), ('cat_agrup', Pipeline([('cat3_agrup', CategoricalLimitter(features=CAT3_FEATURES, n_cat=3, other_tag=OTHER_TAG)), ('cat5_agrup', CategoricalLimitter(features=CAT5_FEATURES, n_cat=5, other_tag=OTHER_TAG)), ('cat8_agrup', CategoricalLimitter(features=CAT8_FEATURES, n_cat=8, other_tag=OTHER_TAG))])), ('splitter', DataSplitter(target=TARGET))]": 1,
      "[('cat3_agrup', CategoricalLimitter(features=CAT3_FEATURES, n_cat=3, other_tag=OTHER_TAG)), ('cat5_agrup', CategoricalLimitter(features=CAT5_FEATURES, n_cat=5, other_tag=OTHER_TAG)), ('cat8_agrup', CategoricalLimitter(features=CAT8_FEATURES, n_cat=8, other_tag=OTHER_TAG))]": 1,
      "[('selector', ColumnSelection(features=INITIAL_FEATURES)), ('cat_agrup', CategoricalMapper(cat_dict=high_cat_dict, other_tag=OTHER_TAG)), ('splitter', DataSplitter(target=TARGET))]": 1,
      "[('imputer', SimpleImputer(strategy='median')), ('log', DynamicLogTransformation(num_features=num_features, cols_to_log=cols_to_log)), ('scaler', DynamicScaler(scaler_type='Standard'))]": 1,
      "[('col_filter', ColumnSelection(features=INITIAL_FEATURES)), ('cat_agrup', CategoricalMapper(cat_dict=CAT_GROUP_DICT, other_tag=OTHER_TAG)), ('log_target', LogTransformation(cols_to_log=TARGET))]": 1,
      "[('imputer', SimpleImputer(strategy='median')), ('log', DynamicLogTransformation(num_features=NUM_FEATURES, cols_to_log=COLS_TO_LOG)), ('scaler', DynamicScaler(scaler_type=None))]": 1,
      "[('selector', FeatureSelection(feature_importance=feat_imp, k=len(MODEL_FEATURES))), ('model', model)]": 1,
      "[('col_filter', ColumnSelection(features=[col for col in INITIAL_FEATURES if col != TARGET])), ('cat_agrup', CategoricalMapper(cat_dict=CAT_GROUP_DICT, other_tag=OTHER_TAG))]": 1,
      "[('initial', initial_pred_pipeline), ('prep', prep_pipeline)]": 1,
      "[('selector', ColumnSelection(features=INITIAL_FEATURES)), ('target_encoder', TargetExtractor()), ('splitter', DataSplitter(target=TARGET))]": 1,
      "[('selector', ColumnSelection(features=TEST_FEATURES))]": 1,
      "[('selector', FeatureSelection(feature_importance, k=len(TEST_FEATURES))), ('model', best_model)]": 1,
      "[('Scale', StandardScaler()), ('model', LinearRegression())]": 1,
      "[('Scale', StandardScaler()), ('model', DecisionTreeRegressor())]": 1,
      "[('Scale', StandardScaler()), ('model', RandomForestRegressor())]": 1,
      "[('one_hot', preprocessing.OneHotEncoder(sparse=False, handle_unknown='ignore')), ('rescale', preprocessing.StandardScaler()), ('pca', decomposition.TruncatedSVD(n_components=30)), ('ridge', linear_model.Ridge())]": 1,
      "[('PreprocessingStep', PreprocessingStep()), ('CategoricalFeaturesEncoder', CategoricalFeaturesEncoder(categorical_columns_to_be_encoded_lst, categorical_encoders_lst)), ('SparseTextEncoder', SparseTextEncoder(text_columns_to_be_encoded_lst, text_encoders_lst, output_format='pandas')), ('DuplicatedFeaturesRemover', DuplicatedFeaturesRemover()), ('BlendedLightGBM', BlendedLGBMClassifier(lgb_params, early_stopping_rounds=150, eval_size=0.2, eval_split_type='random', verbose_eval=100, nrounds=10000))]": 1,
      "[('vect', CountVectorizer(lowercase=False)), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())]": 1,
      "[('union', FeatureUnion(transformer_list=[('description_tdfidf', Pipeline([('selector', ItemSelector(key='item_description')), ('tfidf', TfidfVectorizer(max_df=0.95, min_df=2, max_features=5000, stop_words='english', ngram_range=(1, 3))), ('svd', TruncatedSVD(n_components=100))])), ('the_rest_of_the_data_frame', Pipeline([('selector_2', ItemSelector(['item_condition_id', 'cat0', 'cat1', 'cat2', 'brand_name', 'shipping'])), ('encode_cat', DataFrameLabelEncoder(['cat0', 'cat1', 'cat2', 'brand_name'])), ('onehot_encode', OneHotEncoder(categorical_features=[1, 2, 3, 4]))]))]))]": 1,
      "[('selector', ItemSelector(key='item_description')), ('tfidf', TfidfVectorizer(max_df=0.95, min_df=2, max_features=5000, stop_words='english', ngram_range=(1, 3))), ('svd', TruncatedSVD(n_components=100))]": 1,
      "[('selector_2', ItemSelector(['item_condition_id', 'cat0', 'cat1', 'cat2', 'brand_name', 'shipping'])), ('encode_cat', DataFrameLabelEncoder(['cat0', 'cat1', 'cat2', 'brand_name'])), ('onehot_encode', OneHotEncoder(categorical_features=[1, 2, 3, 4]))]": 1,
      "[('tfidf', TfidfTransformer()), ('clf', MultinomialNB())]": 1,
      "[('vectorizer', None), ('model', None)]": 1,
      "[('clean', FunctionTransformer(clean_tweets)), ('vectorizer', None), ('model', None)]": 1,
      "[('killVamp', KillVampires('DAYS_EMPLOYED')), ('killLiar', KillLiars('AMT_INCOME_TOTAL')), ('scaler', StandardScaler()), ('imputer', SimpleImputer(strategy='mean'))]": 1,
      "[('imputer', SimpleImputer(strategy='constant', fill_value='missing')), ('label_encoder', OrdinalEncoder())]": 1,
      "[('imputer', SimpleImputer(strategy='constant', fill_value='missing')), ('onehot_encoder', OneHotEncoder(handle_unknown='ignore'))]": 1,
      "[('v', TfidfVectorizer(min_df=5, max_df=505, max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 2), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words='english')), ('svd', TruncatedSVD(n_components=201, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=10.5, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None))]": 1,
      "[('features', FeatureUnion([('text_length', LengthTransformer()), ('word_count', WordCountTransformer()), ('mean_length', MeanLengthTransformer()), ('punctuation_count', PunctuationCountTransformer()), ('stop_words_count', StopWordsCountTransformer()), ('count_vect', CountVectorizer(lowercase=False)), ('tf_idf', TfidfVectorizer())])), ('classifier', XGBClassifier(objective='multi:softprob', random_state=12, eval_metric='mlogloss'))]": 1,
      "[('separator', DTypeSelector(key='datetime')), ('encoder', FeatureHasher(input_type='string')), ('filter', VarianceThreshold())]": 1,
      "[('separator', DTypeSelector(key='object')), ('encoder', FeatureHasher(input_type='string')), ('filter', VarianceThreshold())]": 1,
      "[('separator', DTypeSelector(key='number')), ('encoder', FeatureHasher(input_type='string')), ('filter', VarianceThreshold())]": 1,
      "[('separator', DTypeSelector(key='semi-number')), ('encoder', FeatureHasher(input_type='string')), ('filter', VarianceThreshold(threshold=0))]": 1,
      "[('a', StandardScaler()), ('pca', TruncatedSVD(n_components=10)), ('b', LinearDiscriminantAnalysis())]": 1,
      "[('kbest', kbest), ('lr', lr)]": 1,
      "[('scl', RobustScaler()), ('lightgbm', LGBMRegressor(objective='regression', n_estimators=450, learning_rate=0.01))]": 1,
      "[('num_colsplitter', num_colsplitter), ('logtransform', logtransform), ('scaler', scaler)]": 1,
      "[('dummy_colsplitter', dummy_colsplitter)]": 1,
      "[('text_colsplitter', text_colsplitter), ('tf_idf', tf_idf)]": 1,
      "[('union', FeatureUnion(transformer_list=[('numerical_pipe', numerical_pipe), ('categorical_pipe', categorical_pipe), ('text_pipe', text_pipe)])), ('estimator', estimator)]": 1,
      "[('preprocessor', preprocessor), ('regressor', Ridge(random_state=random_state))]": 1,
      "[('preprocessor', preprocessor), ('regressor', RANSACRegressor(random_state=random_state))]": 1,
      "[('preprocessor', preprocessor), ('regressor', SVR())]": 1,
      "[('preprocessor', preprocessor), ('regressor', KNeighborsRegressor(n_jobs=n_jobs))]": 1,
      "[('preprocessor', preprocessor), ('regressor', reg)]": 1,
      "[('preprocessor', preprocessor), ('regressor', XGBRegressor(n_jobs=n_jobs, random_state=random_state))]": 1,
      "[('preprocessor', preprocessor), ('regressor', LGBMRegressor(n_jobs=n_jobs, random_state=random_state, importance_type='gain'))]": 1,
      "[('column_transformer', transformer), ('robust_scaler', robust_scaler), ('classifier', random_forest_regressor)]": 1,
      "[('imputer', SimpleImputer(strategy='constant', fill_value='-1')), ('OneHotEncoder', OneHotEncoder())]": 1,
      "[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', LinearSVC(class_weight='balanced', C=0.5))]": 1,
      "[('unk_imputing', simpleImputer(strategy='constant', fill_value='unk')), ('text_lowering', TextLowerer(columns=['url_legal', 'license', 'excerpt'])), ('feature_processing', featureUnion(transformer_list=[('text_spliting', TextSpliter(columns=['url_legal', 'license'], spliters=[':', '/', '_', '-'])), ('pass_through', PassThroughExcept(col_except_func=lambda X: [c for c in X.columns if c in ['url_legal', 'license']]))])), ('combine_text', TextCombinator()), ('vect', CountVectorizer(ngram_range=(1, 1), max_df=0.9, max_features=None)), ('tfidf', TfidfTransformer()), ('clf', SVR(kernel='rbf', gamma='scale', C=2))]": 1,
      "[('tfidf_vectorizer', feature_extraction.text.TfidfVectorizer(lowercase=True)), ('rf_classifier', ensemble.RandomForestClassifier(n_estimators=500, verbose=1, n_jobs=-1))]": 1,
      "[('scaler2', StandardScaler()), ('ExtraTreesRegressor: ', ExtraTreesRegressor(n_estimators=500))]": 1,
      "[('imputer', sklearn.impute.SimpleImputer(strategy='most_frequent')), ('onehot', sklearn.preprocessing.OneHotEncoder(handle_unknown='ignore'))]": 1,
      "[('preprocessor', preprocessor), ('model', baseline)]": 1,
      "[('preprocessor', preprocessor), ('model', rf_model)]": 1,
      "[('imputer', SimpleImputer(add_indicator=True, strategy='median')), ('scaler', QuantileTransformer(output_distribution='normal')), ('clip_extremes', FunctionTransformer(lambda x, cap: np.clip(x, -cap, cap))), ('feature_creator', create_features), ('scale_min_max', MinMaxScaler())]": 1,
      "[('Preprocessor', preprocessor), ('Regressors', ElasticNet())]": 1,
      "[('imputer', SimpleImputer(add_indicator=True, strategy='median')), ('scaler', QuantileTransformer(output_distribution='normal')), ('feature_creator', create_features), ('scale_min_max', MinMaxScaler())]": 1,
      "[('Preprocessor', preprocessor), ('Regression', TweedieRegressor(max_iter=100000, warm_start=True))]": 1,
      "[('imputer_num', SimpleImputer(strategy='median')), ('scaler_num', StandardScaler())]": 1,
      "[('imputer', SimpleImputer(strategy='constant')), ('onehot', OneHotEncoder(handle_unknown='ignore')), ('scaler', StandardScaler())]": 1,
      "[('vect', CountVectorizer()), ('tfidf', TfidfTransformer())]": 1,
      "[('features', text_features), ('clf', MultinomialNB())]": 1,
      "[('vect', CountVectorizer(max_features=10000, ngram_range=(1, 2))), ('tfidf', TfidfTransformer(use_idf=False)), ('clf', ComplementNB(alpha=0.01))]": 1,
      "[('vect', CountVectorizer(max_features=10000)), ('tfidf', TfidfTransformer(use_idf=False)), ('clf', RandomForestClassifier(n_estimators=50))]": 1,
      "[('vect', CountVectorizer(max_features=10000)), ('tfidf', TfidfTransformer(use_idf=False)), ('clf', SGDClassifier(loss='log', penalty='l2'))]": 1,
      "[('vect', CountVectorizer(max_features=10000)), ('tfidf', TfidfTransformer(use_idf=False)), ('clf', ada)]": 1,
      "[('vect', CountVectorizer(max_features=10000, ngram_range=(1, 2))), ('tfidf', TfidfTransformer(use_idf=False))]": 1,
      "[('bow', CountVectorizer(analyzer=text_process)), ('tfidf', TfidfTransformer()), ('classifier', ExtraTreesClassifier())]": 1,
      "[('tfidf', TfidfVectorizer()), ('clf', LinearSVC(loss='hinge', fit_intercept=False))]": 1,
      "[('v', TfidfVectorizer(min_df=5, max_df=500, max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 2), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words='english')), ('svd', TruncatedSVD(n_components=200, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=9.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None))]": 1,
      "[('impute', SimpleImputer(strategy='most_frequent')), ('one-hot', OneHotEncoder())]": 1,
      "[('impute', SimpleImputer(strategy='median')), ('std', StandardScaler())]": 1,
      "[('transformations', Pipeline([('scaling', StandardScaler())])), ('feature_reduction', FeatureUnion([('kbest', MajorityVotingSelectKBest(k=40)), ('pca', PCAModifier(n_components=10))]))]": 1,
      "[('scaling', StandardScaler())]": 1,
      "[('LGBMClassifier', clf1)]": 1,
      "[('LogisticRegression', clf2)]": 1,
      "[('XGBRegressor', clf3)]": 1,
      "[('GaussianNB', clf4)]": 1,
      "[('RandomForestClassifier', clf5)]": 1,
      "[('KNeighborsRegressor', clf9)]": 1,
      "[('DecisionTreeRegressor', clf10)]": 1,
      "[('GradientBoostingRegressor', clf11)]": 1,
      "[('StackingClassifier', SCF)]": 1,
      "[('scaler2', StandardScaler()), ('ExtraTreesRegressor: ', ExtraTreesRegressor(n_estimators=5))]": 1,
      "[('scaler', StandardScaler()), ('reg', reg)]": 1,
      "[('time_features_create', TimeFeaturesEncoder('pickup_datetime')), ('time_features_ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))]": 1,
      "[('dist_and_time', preprocessor), ('scaler', MinMaxScaler())]": 1,
      "[('preprocessor', pipe_prepro), ('model', RandomForestRegressor())]": 1,
      "[('v', TfidfVectorizer(min_df=5, max_df=500, max_features=None, strip_accents='unicode', analyzer='word', token_pattern='\\\\w{1,}', ngram_range=(1, 2), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words='english')), ('svd', TruncatedSVD(n_components=200, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('rf', RandomForestClassifier(n_estimators=300))]": 1,
      "[('logistic', LR())]": 1,
      "[('vectorizer', 'passthrough'), ('regressor', 'passthrough')]": 1,
      "[('vectorizer', 'passthrough'), ('svd', 'passthrough'), ('regressor', 'passthrough')]": 1,
      "[('choose_cols', ColumnChooser(['temp', 'rh', 'wdsp', 'Elapsed'])), ('fill_na', SimpleImputer(strategy='median')), ('scaler', StandardScaler())]": 1,
      "[('impute', SimpleImputer(strategy='most_frequent')), ('encode', OrdinalEncoder())]": 1,
      "[('impute', SimpleImputer(strategy='median'))]": 1,
      "[('impute_nums', CustomImputer(strategy='constant', cols=cols_to_impute_w_null)), ('impute_cats', CustomImputer(strategy='mode', cols='NAME_TYPE_SUITE')), ('get_ext_source_integrity', ExtSourceIntegrity(ext_source_cols)), ('impute_occupations', OccupationsImputer(occu_gr_cols)), ('normalize_days_employed', DaysEmployedZscore(exp_gr_cols)), ('discretizing_zscore', ZscoreQuantileDiscretizer()), ('get_apart_desc_integrity', SimpleColumnsAdder(apartments_cols, cols_to_drop)), ('oh_encoding', CustomOHEncoder()), ('xgb_model', xgb_model)]": 1,
      "[('feature_selection', SelectFromModel(LinearSVC(penalty='l1', dual=False, tol=0.001))), ('classification', LinearSVC(penalty='l2'))]": 1,
      "[('sc', StandardScaler(with_mean=True, with_std=True)), ('logistic_regression', LogisticRegression(solver='liblinear', max_iter=100, random_state=42))]": 1,
      "[('sc', StandardScaler(with_mean=True, with_std=True)), ('pca', PCA()), ('logistic_regression', LogisticRegression(solver='liblinear', max_iter=1000))]": 1,
      "[('sc', StandardScaler(with_mean=True, with_std=True)), ('lda', LinearDiscriminantAnalysis()), ('logistic_regression', LogisticRegression(solver='liblinear', max_iter=1000))]": 1,
      "[('svc', SVC(kernel='linear', gamma='auto', probability=True))]": 1,
      "[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', LogisticRegression(C=1000.0))]": 1,
      "[('tfidf', TfidfVectorizer()), ('clf', OneVsRestClassifier(MultinomialNB(fit_prior=True, class_prior=None)))]": 1,
      "[('tfidf', TfidfVectorizer()), ('clf', OneVsRestClassifier(LinearSVC(), n_jobs=1))]": 1,
      "[('tfidf', TfidfVectorizer()), ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=1))]": 1,
      "[('tfidf', TfidfVectorizer()), ('clf', OneVsRestClassifier(XGBClassifier(), n_jobs=1))]": 1,
      "[('tfidf', TfidfVectorizer()), ('clf', OneVsRestClassifier(DecisionTreeClassifier()))]": 1,
      "[('encode', CountEncoder(cols=[0, 2])), ('classify', model)]": 1,
      "[('tfidf', TfidfVectorizer(max_df=0.5, min_df=20, stop_words='english')), ('clf', model1(batch_size=512, epochs=5, validation_data=(X_test, y_test), verbose=1))]": 1,
      "[('impeter', SimpleImputer(strategy='mean')), ('scaler', MinMaxScaler())]": 1,
      "[('tvec', tvec), ('svd', svd)]": 1,
      "[('vectorizer', cvec), ('lr', lr)]": 1,
      "[('transform_columns', transform_columns), ('model', best_model)]": 1,
      "[('transform_columns', transform_columns), ('model', model)]": 1,
      "[('union', FeatureUnion([('tf_idf', Pipeline([('extract_field', description_selector), ('tfidf', tf_idf), ('lda', lda)])), ('no_tfidf', nodescription_selector)])), ('classifier', lgbm)]": 1,
      "[('extract_field', description_selector), ('tfidf', tf_idf), ('lda', lda)]": 1,
      "[('extract_features', features), ('classify', GradientBoostingClassifier(n_estimators=400, learning_rate=0.06, max_depth=4, verbose=2, subsample=0.3, min_samples_split=2, random_state=1))]": 1,
      "[('shape1', FunctionTransformer(_print_shape, validate=False)), ('feats', FeatureUnion(transformer_list=[('categories', Pipeline([('filter', FunctionTransformer(lambda X: X[:, [0]], validate=False)), ('binarizer', OneHotEncoder()), ('shape1', FunctionTransformer(_print_shape, validate=False))])), ('parentCategories', Pipeline([('filter', FunctionTransformer(lambda X: X[:, [1]], validate=False)), ('binarizer', OneHotEncoder()), ('shape1', FunctionTransformer(_print_shape, validate=False))])), ('titles', Pipeline([('filter', FunctionTransformer(lambda X: X[:, [2, 3]], validate=False)), ('titleswitch', TextTransformer(CountVectorizer(binary=True))), ('logreg', SupervisedTransformer(LogisticRegression(C=0.01), 'predict_proba')), ('selector', FunctionTransformer(lambda X: X[:, [1]])), ('shape1', FunctionTransformer(_print_shape, validate=False))])), ('locationID', Pipeline([('filter', FunctionTransformer(lambda X: X[:, [4, 5]].astype(int), validate=False)), ('binarizer', EqNotEqBinarizer()), ('threshold', VarianceThreshold(0.0001)), ('shape1', FunctionTransformer(_print_shape, validate=False))])), ('regionID', Pipeline([('filter', FunctionTransformer(lambda X: X[:, [6, 7]].astype(int), validate=False)), ('binarizer', EqNotEqBinarizer()), ('threshold', VarianceThreshold(0.0001)), ('shape1', FunctionTransformer(_print_shape, validate=False))])), ('metroID', Pipeline([('filter', FunctionTransformer(lambda X: X[:, [8, 9]].astype(int), validate=False)), ('binarizer', EqNotEqBinarizer()), ('threshold', VarianceThreshold(0.0001)), ('shape1', FunctionTransformer(_print_shape, validate=False))]))])), ('shape2', FunctionTransformer(_print_shape, validate=False)), ('est', XGBClassifier())]": 1,
      "[('filter', FunctionTransformer(lambda X: X[:, [0]], validate=False)), ('binarizer', OneHotEncoder()), ('shape1', FunctionTransformer(_print_shape, validate=False))]": 1,
      "[('filter', FunctionTransformer(lambda X: X[:, [1]], validate=False)), ('binarizer', OneHotEncoder()), ('shape1', FunctionTransformer(_print_shape, validate=False))]": 1,
      "[('filter', FunctionTransformer(lambda X: X[:, [2, 3]], validate=False)), ('titleswitch', TextTransformer(CountVectorizer(binary=True))), ('logreg', SupervisedTransformer(LogisticRegression(C=0.01), 'predict_proba')), ('selector', FunctionTransformer(lambda X: X[:, [1]])), ('shape1', FunctionTransformer(_print_shape, validate=False))]": 1,
      "[('filter', FunctionTransformer(lambda X: X[:, [4, 5]].astype(int), validate=False)), ('binarizer', EqNotEqBinarizer()), ('threshold', VarianceThreshold(0.0001)), ('shape1', FunctionTransformer(_print_shape, validate=False))]": 1,
      "[('filter', FunctionTransformer(lambda X: X[:, [6, 7]].astype(int), validate=False)), ('binarizer', EqNotEqBinarizer()), ('threshold', VarianceThreshold(0.0001)), ('shape1', FunctionTransformer(_print_shape, validate=False))]": 1,
      "[('filter', FunctionTransformer(lambda X: X[:, [8, 9]].astype(int), validate=False)), ('binarizer', EqNotEqBinarizer()), ('threshold', VarianceThreshold(0.0001)), ('shape1', FunctionTransformer(_print_shape, validate=False))]": 1,
      "[FastICA(n_components=4), KernelPCA(n_components=2)]": 1,
      "[('cleantext', ColumnExtractor(cols='clean_text')), ('vect', CountVectorizer(max_df=0.5, min_df=1, ngram_range=(1, 2)))]": 1,
      "[('features', features), ('clf', LogisticRegression(C=1.0, penalty='l2'))]": 1,
      "[('time_transformer', DatetimeTransformer())]": 1,
      "[('hot_columns', ItemSelector(key=['datetime_year'])), ('label_encoder', OneHotEncoder())]": 1,
      "[('weather_columns', ItemSelector(key=['weather'])), ('label_encoder', DummyEncoder(categories=[[1, 2, 3, 4]]))]": 1,
      "[('season_columns', ItemSelector(key=['season'])), ('label_encoder', DummyEncoder(categories=[[1, 2, 3, 4]]))]": 1,
      "[('min_max_columns', ItemSelector(key=['datetime_hour', 'datetime_day', 'datetime_weak', 'datetime_month', 'datetime_timestape', 'humidity', 'workingday', 'holiday'])), ('minMaxScaler', MinMaxScaler())]": 1,
      "[('temp_columns', ItemSelector(key=['temp', 'atemp'])), ('pca', PCA(n_components=1)), ('min_max', MinMaxScaler())]": 1,
      "[('windspeed_columns', ItemSelector(key=['windspeed'])), ('kbins', KBinsDiscretizer(n_bins=4, encode='ordinal', strategy='uniform')), ('min_max', MinMaxScaler())]": 1,
      "[('preper_data', preper_data_pipeline), ('feature_union', feature_union)]": 1,
      "[('time_transformer', PickupTransformer()), ('center_location_transformer', CenterLocationTransformer()), ('airport_location_transormer', AirportLocationTransformer())]": 1,
      "[('hot_columns', ItemSelector(key=['pickup_year'])), ('oneHowEncoder', one_hot)]": 1,
      "[('min_max_columns', ItemSelector(key=['distance_from_dropoff_to_center', 'distance_from_pickup_to_center', 'y_pickup_week', 'x_pickup_week', 'y_pickup_day', 'x_pickup_day', 'y_pickup_month', 'x_pickup_month', 'passenger_count', 'dropoff_latitude', 'jfk_distance', 'ewr_distance', 'lga_distance', 'dropoff_longitude', 'pickup_latitude', 'pickup_longitude', 'distance_from_pickup_to_dropoff'])), ('minMaxScaler', min_max)]": 1,
      "[('preper_data', preper_data_pipeline), ('one_hot_min_max_feature_union', one_hot_min_max_feature_union)]": 1,
      "[('preprocessor', preprocessor), ('model', cls)]": 1,
      "[('count_vectorizer', count_vectorizer), ('model', model1)]": 1,
      "[('count_vectorizer', count_vectorizer), ('model', model2)]": 1,
      "[('count_vectorizer', count_vectorizer), ('model', model3)]": 1,
      "[('tokenize', QATokenizer(bert_tokenizer)), ('estimate', BertFineTuningECV('../input/transformers/bert-base-uncased'))]": 1,
      "[('tfv', tfv), ('svd', svd), ('scl', scl), ('sminmax', sminmax), ('svm', svm_model)]": 1,
      "[('tfv', tfv), ('svd', svd), ('scl', scl), ('sminmax', sminmax)]": 1,
      "[('selector', DataFrameSelector(num_attr)), ('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())]": 1,
      "[('selector', DataFrameSelector(cat_attr)), ('imputer', SimpleImputer(strategy='most_frequent'))]": 1,
      "[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', SGDClassifier(loss='hinge', penalty='l2', random_state=42))]": 1,
      "[('Text-TF-IDF', TfidfVectorizer(ngram_range=(1, 1))), ('Text-SVD', TruncatedSVD(n_components=100))]": 1,
      "[('scaling', preprocessing.RobustScaler()), ('ridge', Ridge(alpha=alpha, random_state=random_state))]": 1,
      "[('scaling', preprocessing.RobustScaler()), ('ridge', Ridge(alpha=11.91946435680328, random_state=random_state))]": 1,
      "[('scaling', preprocessing.RobustScaler()), ('lasso', Lasso(alpha=alpha, random_state=random_state))]": 1,
      "[('scaling', preprocessing.RobustScaler()), ('lasso', Lasso(alpha=0.011262757057466669, random_state=random_state))]": 1,
      "[('scaling', preprocessing.RobustScaler()), ('svr', svm.SVR(C=C, epsilon=epsilon, gamma=gamma))]": 1,
      "[('scaling', preprocessing.RobustScaler()), ('svr', svm.SVR(C=70.8461395955645, epsilon=0.023807407289868687, gamma=0.0024348987081239675))]": 1,
      "[('reduce_dim', PCA(random_state=16446054)), ('classify', my_knn_agent.uniform_knn)]": 1,
      "[('reduce_dim', PCA(random_state=166446054)), ('classify', SVC(random_state=16446054, class_weight='balanced'))]": 1,
      "[('reduce_dim', PCA(random_state=166446054)), ('classify', AdaBoostClassifier(random_state=16446054))]": 1,
      "[('scaling', scaler), ('baggingregressor', clf)]": 1,
      "[('vect', vect), ('tfidf', tfidf)]": 1,
      "[('vectorizer', cvz), ('tfid', tfid)]": 1,
      "[('scl', StandardScaler()), ('pca', PCA(n_components=10)), ('clf', LogisticRegression(random_state=1))]": 1,
      "[('scaler', StandardScaler()), ('estimator', LinearRegression())]": 1,
      "[('scale', StandardScaler()), ('pca', PCA(n_components=2))]": 1,
      "[('Vect', CountVectorizer(stop_words=None, token_pattern='.+', tokenizer=lambda x: x.split('|'), max_df=0.9, min_df=1)), ('Classif', LinearSVC())]": 1,
      "[('Vect', CountVectorizer(stop_words=None, token_pattern='.+', tokenizer=lambda x: x.split('|'), max_df=1.0, min_df=1)), ('Classif', LinearSVC())]": 1,
      "[('scaler', StandardScaler()), ('estimator', KerasRegressor(build_fn=build_model, epochs=3, batch_size=128))]": 1,
      "[('OneHot', onehotEncoder)]": 1,
      "[('targetEnc', targetEncoder)]": 1
    },
    "sklearn.pipeline.Pipeline.fit.X": {
      "X_train": 616,
      "X": 210,
      "x_train": 134,
      "x": 80,
      "s_data": 50,
      "adjusted_X_train": 42,
      "train": 37,
      "df1_s[1]": 37,
      "train_X": 28,
      "train_x": 22,
      "np.array(features)": 22,
      "xs": 18,
      "finaltrainset": 17,
      "train_data": 13,
      "train_numeric_X": 13,
      "xtrain": 11,
      "t_X": 10,
      "train.values": 10,
      "x_train_Stem": 9,
      "x_train_Lemm": 9,
      "feature_2": 8,
      "features_train": 6,
      "df['comment_text']": 6,
      "Xt": 6,
      "X_train2": 6,
      "X.iloc[train]": 6,
      "traindata": 6,
      "train_df": 5,
      "X_Train": 5,
      "all_text": 5,
      "data_train.copy()": 5,
      "X_train_part": 5,
      "reduced_X_train['item_description']": 5,
      "data.loc['train']": 5,
      "datatrain['comment_text']": 5,
      "preds_with_consistency": 4,
      "dev_df[features]": 4,
      "Xshort": 4,
      "train.ingredients": 4,
      "dftemp": 4,
      "tweet_train": 4,
      "sxtr": 4,
      "x_train_L1": 4,
      "x_train_pca": 4,
      "X_train_down": 4,
      "Xhetero": 3,
      "phrase_train": 3,
      "X_train.values": 3,
      "X_train_clean": 3,
      "XE": 3,
      "X[train]": 3,
      "x_train_selected": 3,
      "X_trainvalid": 3,
      "X_train.reshape(-1, 1)": 3,
      "X_train_fold": 3,
      "X_fit": 3,
      "X_train[best_variables]": 3,
      "train2[cols]": 3,
      "trn_x": 2,
      "train_encoded": 2,
      "train_text": 2,
      "train_features": 2,
      "trainX": 2,
      "X_training": 2,
      "X_train_block": 2,
      "X_train1": 2,
      "bag_of_words": 2,
      "data_to_train": 2,
      "part_a": 2,
      "features": 2,
      "df_train.iloc[:, 1:-2]": 2,
      "X_train_full": 2,
      "data_X": 2,
      "X_train_final": 2,
      "train_data['comment_text']": 2,
      "X_Scaler_train": 2,
      "x_train_c": 2,
      "X_train[train_idx, :]": 2,
      "train_data.query('date > 100')[train_data.columns[train_data.columns.str.contains('feature')]].values": 2,
      "prior_df[['ConfirmedCases', 'Fatalities', 'Days']].shift(periods=2).dropna()": 2,
      "prior_df[['ConfirmedCases', 'Fatalities', 'Days']].diff(periods=1).dropna()": 2,
      "new_train": 2,
      "train['comment_text'].values": 2,
      "train['review']": 2,
      "public_train_build[features]": 2,
      "private_train_build[features]": 2,
      "training_features": 2,
      "msg_train": 2,
      "train_df['ingredients']": 2,
      "TrainingFeatures": 2,
      "feats[sorted(feats.columns)]": 2,
      "train_df.text": 2,
      "X_fea_2_tr_equid": 2,
      "X_fea_2_tr_balan": 2,
      "train_df.iloc[:, :-1]": 2,
      "X_train_base": 2,
      "df.question_text.to_numpy()": 1,
      "en_df": 1,
      "train['ingredients_new']": 1,
      "X_1": 1,
      "[market_train]": 1,
      "x_train.copy()": 1,
      "xh": 1,
      "abs(trn_x)": 1,
      "train[['text', 'keyword', 'location']].values": 1,
      "a": 1,
      "X[important_cols]": 1,
      "final_train": 1,
      "train_df[train_df.columns.drop('SalePrice')]": 1,
      "df": 1,
      "train_text1": 1,
      "train_data['text']": 1,
      "X_train.ciphertext": 1,
      "data['Phrase']": 1,
      "train_transaction_full": 1,
      "Z": 1,
      "Z2": 1,
      "X_train[i_train]": 1,
      "train.drop('SalePrice', axis=1)": 1,
      "train.drop('Survived', axis=1)": 1,
      "cat": 1,
      "reg": 1,
      "original_train": 1,
      "X_tr": 1,
      "X_nonoutlier": 1,
      "train_df[features + ['loc']]": 1,
      "X[['offense_formation']]": 1,
      "X[['defenders_in_the_box']]": 1,
      "dataset['text'][:test_split]": 1,
      "df_train_X": 1,
      "train_df.preprocessed": 1,
      "train10": 1,
      "dog_x_training": 1,
      "cat_x_training": 1,
      "dog_x": 1,
      "cat_x": 1,
      "X_train_sss": 1,
      "quora_train.question_text.values": 1,
      "np.array(x_train_cas)": 1,
      "X_treino_pipe": 1,
      "x.drop('Patient', 1)": 1,
      "data_train": 1,
      "X_transformed_train": 1,
      "data.drop(columns=['target'])": 1,
      "X_train_dm_1": 1,
      "kf_x": 1,
      "X_train_tk": 1,
      "X_train_pr": 1,
      "x_train_cont": 1,
      "train.Phrase": 1,
      "train[['C' + str(i + 1) for i in range(14)]]": 1,
      "X_cleaned": 1,
      "X_t3gram_vectorizer_train": 1,
      "X_f": 1,
      "X_m": 1,
      "trn_aug_x": 1,
      "train[features]": 1,
      "X_trn": 1,
      "X_v1": 1,
      "x_train.head(10000)": 1,
      "X_data": 1,
      "x_train[list_features].as_matrix()[train]": 1,
      "X_train.item_description": 1,
      "xvalid": 1,
      "clean_train_reviews": 1,
      "df_train[cols]": 1,
      "np.arange(x_train_m.size).reshape(-1, 1)": 1,
      "train.description": 1,
      "X_test_pca": 1,
      "X_train_pca": 1,
      "this_X": 1,
      "feature_train": 1,
      "X_train_1": 1,
      "t['X_train']": 1,
      "np.array(train.loc[y_is_within_cut, cols_to_use].values)": 1,
      "dataset.text": 1,
      "train_sentences": 1,
      "traindf_X": 1,
      "train3": 1,
      "df_train.text": 1,
      "data_downsample['questions_text']": 1,
      "doc_df": 1,
      "train_df1['text'].as_matrix()": 1,
      "x_train_sgd": 1,
      "x_train_xgb": 1,
      "x_train_lgbm": 1,
      "X_train_filtered": 1,
      "train['comment_text']": 1,
      "train['text']": 1,
      "train_df[features_list]": 1,
      "X_train.post": 1,
      "trainx": 1,
      "train_data_1": 1,
      "x_k": 1,
      "df.text": 1,
      "train1": 1,
      "X_new": 1,
      "X_train[features]": 1,
      "X_train[new_features]": 1,
      "df_train[features]": 1,
      "np.concatenate([X_train[GENES], X_test[GENES]], axis=0)": 1,
      "np.concatenate([X_train[CELLS], X_test[CELLS]], axis=0)": 1,
      "train[kolom]": 1,
      "xtrain.comment_text": 1,
      "train_tfidf": 1,
      "train_df['clean_ques'].values": 1,
      "df_kaggle_train": 1,
      "x_base[:15000]": 1,
      "train_df['excerpt']": 1,
      "List_of_tweets(train)": 1,
      "train_data.loc[:, cluster_1_features]": 1,
      "train_data.loc[:, cluster_2_features]": 1,
      "train_data.loc[:, cluster_3_features]": 1,
      "train_data.loc[:, cluster_4_features]": 1,
      "train_data.loc[:, cluster_5_features]": 1,
      "feature[0]": 1,
      "train['Phrase']": 1,
      "independent_variables": 1,
      "df['comment_text'].values": 1,
      "train_pivot": 1,
      "y_train_pred": 1,
      "xTrain": 1,
      "fnc_train.iloc[tr, :].values": 1,
      "loading_train.iloc[tr, :].values": 1,
      "fnc_train": 1,
      "loading_train": 1,
      "xTr[:, binsOfInterest]": 1,
      "xTr[:, selected_binsOfInterest]": 1,
      "Xtrain[:, binsOfInterest]": 1,
      "Xtrain[:, selected_binsOfInterest]": 1,
      "ingredients": 1,
      "self.data['Customers'].values.reshape(-1, 1)": 1,
      "_inp(df_train)": 1,
      "df.stem.values": 1,
      "df.question_text.values": 1,
      "df.lemm.values": 1,
      "training_data_df": 1,
      "df_train": 1,
      "coo_train": 1,
      "X_train_split": 1,
      "data_train.drop(columns=['target', 'standard_error'])": 1,
      "df_train['strIngredient']": 1,
      "X_test": 1,
      "train_set": 1,
      "pr.drop('isDuplicate', axis=1).values": 1,
      "df_model.drop('Opportunity_Concern', axis=1)": 1,
      "df.iloc[train_idx, 0].values": 1,
      "featuresSampled[train_idx]": 1,
      "df['ingredients']": 1
    },
    "sklearn.pipeline.Pipeline.fit.y": {
      "y_train": 765,
      "y": 243,
      "None": 73,
      "s_labels": 50,
      "train_y": 46,
      "df1_s[2]": 37,
      "target": 31,
      "adjusted_y_train_confirmed": 21,
      "adjusted_y_train_fatalities": 21,
      "y_fat": 20,
      "ys": 19,
      "train_labels": 19,
      "Y_train": 18,
      "np.log1p(y)": 10,
      "ytrain": 10,
      "t_Y": 10,
      "train['median_relevance']": 9,
      "y_train_Stem": 9,
      "y_train_Lemm": 9,
      "train_Y": 7,
      "Y": 6,
      "y_train_f": 6,
      "y_train_c": 6,
      "Yt": 6,
      "y.iloc[train]": 6,
      "train_numeric_Y": 6,
      "train.cuisine": 5,
      "labels_train.copy()": 5,
      "target_train": 5,
      "y_train_part": 5,
      "reduced_y_train": 5,
      "data.loc['train']['Sentiment']": 5,
      "datatrain[classes]": 5,
      "y_train > 0": 4,
      "dev_df[TARGETS]": 4,
      "y_Train": 4,
      "ytr": 4,
      "y_train_L1": 4,
      "y_train_down": 4,
      "y_equidistant": 4,
      "y_balanced": 4,
      "np.ravel(y)": 3,
      "targets_train": 3,
      "trn_y": 3,
      "sentiment_train": 3,
      "y2": 3,
      "trainlabels": 3,
      "y_train_log": 3,
      "y1": 3,
      "labels": 3,
      "ye": 3,
      "label_train": 3,
      "y[train]": 3,
      "y_train.reshape(-1, 1)": 3,
      "y_train.target": 3,
      "train_numeric_Y.values[:, 0]": 3,
      "train_numeric_Y.values[:, 1]": 3,
      "y_fit": 3,
      "train['Sentiment']": 3,
      "df.target.values": 3,
      "train_df['target']": 2,
      "train_data['target']": 2,
      "y_train_block": 2,
      "y_train1": 2,
      "labels_to_use": 2,
      "part_a_y": 2,
      "y_v1": 2,
      "y_labels[train_idx]": 2,
      "(train_data.query('date > 100')['resp'] > 0).astype(int).values": 2,
      "Z_train": 2,
      "Z_trainvalid": 2,
      "trainy": 2,
      "train_target": 2,
      "train['sentiment']": 2,
      "y_train[label].values.ravel()": 2,
      "y3": 2,
      "y4": 2,
      "y5": 2,
      "y6": 2,
      "public_train_build[TARGETS]": 2,
      "private_train_build[TARGETS]": 2,
      "y_train.ravel()": 2,
      "train[category]": 2,
      "train_df.target": 2,
      "training_target": 2,
      "train_df['cuisine']": 2,
      "labels.accuracy_group": 2,
      "scores.iloc[tr][targets]": 2,
      "scores[targets]": 2,
      "y_fea_2_tr_equid": 2,
      "y_fea_2_tr_balan": 2,
      "train_df.iloc[:, -1]": 2,
      "train['cuisine']": 1,
      "np.log(train_y)": 1,
      "train_yt": 1,
      "y_1": 1,
      "y_train.copy()": 1,
      "df['toxic']": 1,
      "df['severe_toxic']": 1,
      "df['obscene']": 1,
      "df['threat']": 1,
      "df['insult']": 1,
      "df['identity_hate']": 1,
      "train['target']": 1,
      "logy": 1,
      "b": 1,
      "y_training": 1,
      "np.log(train_df['SalePrice'])": 1,
      "df['target']": 1,
      "train[column]": 1,
      "trainY": 1,
      "targets": 1,
      "data['Sentiment']": 1,
      "y_train[i_train]": 1,
      "np.log(train['SalePrice'])": 1,
      "train['Survived']": 1,
      "y1_training": 1,
      "y2_training": 1,
      "outliers": 1,
      "y_nonoutlier": 1,
      "train_df[TARGETS]": 1,
      "train_df[label]": 1,
      "dataset['author'][:test_split]": 1,
      "df_train_y": 1,
      "train_df.cleaned_label": 1,
      "dog_y_training": 1,
      "cat_y_training": 1,
      "dog_y": 1,
      "cat_y": 1,
      "y_train_sss": 1,
      "quora_train.target.values": 1,
      "fatalities": 1,
      "y_treino_pipe": 1,
      "y_train['Survived']": 1,
      "labels_train": 1,
      "data['target']": 1,
      "y_train_1": 1,
      "kf_y": 1,
      "train.Sentiment": 1,
      "y_pred2": 1,
      "y1_pred2": 1,
      "y_cora_train": 1,
      "np.squeeze(y_train)": 1,
      "y_f": 1,
      "y_m": 1,
      "trn_aug_y": 1,
      "y_trn": 1,
      "y_train.head(10000)": 1,
      "y_train.as_matrix()[train]": 1,
      "boxcox(train_labels, lmbda)": 1,
      "boxcox(train_labels, best_lambda)": 1,
      "y_train_cc": 1,
      "y_train_ft": 1,
      "y_train.tolist()": 1,
      "X_train.price": 1,
      "data_y": 1,
      "yvalid": 1,
      "df_train['SalePrice']": 1,
      "y_train_m": 1,
      "train.interest_level": 1,
      "y_train_final": 1,
      "y_train_pca": 1,
      "this_y": 1,
      "t['y_train']": 1,
      "train.loc[y_is_within_cut, target]": 1,
      "train_df['class']": 1,
      "traindf_y.values.ravel()": 1,
      "train2['target']": 1,
      "train_y_POS": 1,
      "y1_train_c": 1,
      "y2_train_c": 1,
      "data_downsample['target']": 1,
      "df.target": 1,
      "train_df1['label'].as_matrix()": 1,
      "y_v2": 1,
      "Y_trainvalid": 1,
      "train['toxic']": 1,
      "yy": 1,
      "lb.transform(train['author'])": 1,
      "train_df['TargetValue']": 1,
      "prior_df[['ConfirmedCases']].shift(periods=-2).dropna().values.reshape(-1)": 1,
      "prior_df[['Fatalities']].shift(periods=-2).dropna().values.reshape(-1)": 1,
      "prior_df[['ConfirmedCases']].diff(periods=-1).dropna().values.reshape(-1)": 1,
      "prior_df[['Fatalities']].diff(periods=-1).dropna().values.reshape(-1)": 1,
      "y_train.tags": 1,
      "y_k": 1,
      "df.is_train": 1,
      "labelsTrain1": 1,
      "y_new": 1,
      "df_train[label].values.ravel()": 1,
      "train['y_pred']": 1,
      "y_train2": 1,
      "y_train.values": 1,
      "y_base[:15000]": 1,
      "dependent_variable": 1,
      "df['toxic'].values": 1,
      "train.open_channels": 1,
      "target['group_id']": 1,
      "yTrain": 1,
      "train_df.author": 1,
      "ytrain_lat": 1,
      "ytrain_lng": 1,
      "yTr[:, 0]": 1,
      "yTr[:, n + 1]": 1,
      "Ytrain[:, 0]": 1,
      "Ytrain[:, n + 1]": 1,
      "Countries": 1,
      "self.data['Sales'].values.reshape(-1, 1)": 1,
      "_out(df_train)": 1,
      "target_sr": 1,
      "target.values": 1,
      "y_train_split": 1,
      "train_labels_log": 1,
      "data_train.target": 1,
      "df_train['cuisine']": 1,
      "y_train[category]": 1,
      "pr['isDuplicate'].values": 1,
      "Labels": 1,
      "df_model.Opportunity_Concern": 1,
      "df.iloc[train_idx, 1].values": 1,
      "labelsSampled[train_idx]": 1
    },
    "sklearn.pipeline.Pipeline.predict.X": {
      "X_test": 405,
      "X_train": 101,
      "x_test": 86,
      "test": 79,
      "X": 78,
      "predict_x": 56,
      "X_val": 50,
      "t_data": 48,
      "X_valid": 43,
      "adjusted_X_pred": 42,
      "df2_s[1]": 37,
      "valid_x": 36,
      "test_data": 27,
      "finaltrainset": 22,
      "finaltestset": 18,
      "np.array(Xtest)": 18,
      "test_X": 17,
      "df_test": 15,
      "test.values": 14,
      "testX": 14,
      "x_train": 11,
      "x_val": 11,
      "X_submission": 10,
      "xtest": 10,
      "train_numeric_X": 10,
      "test_text": 9,
      "x": 9,
      "test_df": 9,
      "test_pwr": 9,
      "v_X": 9,
      "test_numeric_X": 9,
      "test_x": 7,
      "train_data": 7,
      "new_test": 7,
      "features_test": 6,
      "test_df.loc[test_df['Date'] == first_day][features]": 6,
      "y_pred": 6,
      "features['test']": 6,
      "Xv": 6,
      "XTEST": 6,
      "X_pred": 6,
      "testdata": 6,
      "test['text']": 5,
      "x_valid": 5,
      "X_Train": 5,
      "datatest['comment_text']": 5,
      "dev_df[features]": 4,
      "df": 4,
      "test.text": 4,
      "X_Test": 4,
      "xvalid": 4,
      "X_train.values": 4,
      "tweet_test": 4,
      "xtsc": 4,
      "test_processed": 4,
      "np.array(features)": 4,
      "X_val_down": 4,
      "dat_test": 4,
      "np.c_[xx.ravel(), yy.ravel()]": 4,
      "X_new": 3,
      "features": 3,
      "train_X": 3,
      "lol": 3,
      "test_features": 3,
      "test_data['text']": 3,
      "phrase_test": 3,
      "test_data['Phrase']": 3,
      "X_test_final": 3,
      "df_test['question_text_cleaned']": 3,
      "dev_data": 3,
      "test_df['excerpt_preprocessed']": 3,
      "validation_x": 3,
      "train": 3,
      "X_test_clean": 3,
      "test.drop(columns=['id'])": 3,
      "test_new_cats.drop(columns=['id'])": 3,
      "test_std": 3,
      "test_df['text']": 3,
      "test.ingredients": 3,
      "df[XE.columns.tolist()]": 3,
      "test_df['preprocessed']": 3,
      "X_test.reshape(-1, 1)": 3,
      "sub_df[features]": 2,
      "test_encoded": 2,
      "sub_test": 2,
      "test['excerpt']": 2,
      "test['Phrase']": 2,
      "data_test": 2,
      "test_data.iloc[[i]]": 2,
      "X_test.values": 2,
      "X_test_block.values": 2,
      "X_valid1": 2,
      "bag_of_words": 2,
      "test_bag": 2,
      "x_val.drop('Patient', 1)": 2,
      "test_df.text": 2,
      "part_b": 2,
      "val_X": 2,
      "X_test2": 2,
      "val": 2,
      "test_data['comment_text']": 2,
      "X_Scaler_test": 2,
      "X_Scaler_train": 2,
      "x_test_c": 2,
      "X_final": 2,
      "X_train[valid_idx, :]": 2,
      "test_df.loc[:, feature_names].values": 2,
      "prior_df[['ConfirmedCases', 'Fatalities', 'Days']]": 2,
      "prior_df[['ConfirmedCases', 'Fatalities', 'Days']].diff(1).dropna()": 2,
      "pd.Series(['this is so sad', 'This is good bro!', 'can you help me?'])": 2,
      "submission_test_clean": 2,
      "test['review']": 2,
      "public_train_build[features]": 2,
      "real_test_data": 2,
      "covid_test[X_features]": 2,
      "testing_features": 2,
      "msg_test": 2,
      "X_test[best_variables]": 2,
      "train_df['ingredients']": 2,
      "data.loc['validation']": 2,
      "test_X[sorted(feats.columns)]": 2,
      "testdata_x": 2,
      "X_fea_2_te_equid": 2,
      "X_fea_2_te_balan": 2,
      "feature_2": 2,
      "c_df.iloc[-7:, :][['Average Word Length', '# Of Sentences', '# Of Different People Mentioned']]": 2,
      "test_df.iloc[:, :-1]": 2,
      "test_df.question_text.to_numpy()": 1,
      "en_df": 1,
      "test_file_names": 1,
      "train.ingredients_new": 1,
      "test['ing_new']": 1,
      "X_1": 1,
      "X_2": 1,
      "[market_obs_df]": 1,
      "x_test.copy()": 1,
      "test_data['excerpt']": 1,
      "test[['text', 'keyword', 'location']].values": 1,
      "train_features": 1,
      "X_test[important_cols]": 1,
      "final_valid": 1,
      "val_df": 1,
      "testing": 1,
      "TestVector": 1,
      "X_test.ciphertext": 1,
      "X1": 1,
      "Z": 1,
      "Z2": 1,
      "df1['text']": 1,
      "original_test": 1,
      "X_te": 1,
      "test_": 1,
      "train_df[features + ['loc']]": 1,
      "test_df.loc[test_df['Date'] == first_day][features + ['loc']]": 1,
      "test_df.loc[test_df['Date'] == date][features + ['loc']]": 1,
      "Xt": 1,
      "X_valid[train_cols]": 1,
      "df_test_X": 1,
      "to_be_predicted": 1,
      "dog_x_training": 1,
      "dog_x_testing": 1,
      "cat_x_training": 1,
      "cat_x_testing": 1,
      "df_test1_scaled": 1,
      "np.array(x_test_cas)": 1,
      "test[model_cols]": 1,
      "X_train1": 1,
      "[features]": 1,
      "new_feature": 1,
      "df_predict.drop(columns='segment')": 1,
      "x.drop('Patient', 1)": 1,
      "X_transformed_test": 1,
      "X_train_dm_1": 1,
      "X_test_dm_1": 1,
      "X_test[my_cols]": 1,
      "X[my_cols]": 1,
      "X_valid_tk": 1,
      "X_valid_pr": 1,
      "X_test_pr": 1,
      "x_valid_cont": 1,
      "x_tt": 1,
      "x_train_test": 1,
      "sub_test.drop(['Id'], axis=1)": 1,
      "X_t3gram_vect_sub_test": 1,
      "arreglo_prueba": 1,
      "df_test['excerpt']": 1,
      "predict_test": 1,
      "eval_df['excerpt']": 1,
      "clean_tweets": 1,
      "d_test": 1,
      "test['processed_excerpt']": 1,
      "X_eval.values": 1,
      "X_v1": 1,
      "x_test[list_features]": 1,
      "test.drop('id', axis=1)": 1,
      "X2": 1,
      "X_valid_full": 1,
      "test_df['seperated_ingredients']": 1,
      "holdout_df": 1,
      "chunk": 1,
      "X_val.item_description": 1,
      "test.item_description": 1,
      "test_df[numerical_features]": 1,
      "(df_test['name'] + ' ' + df_test['item_description']).values": 1,
      "disaster_test": 1,
      "df_test[cols]": 1,
      "np.arange(x_train_m.size).reshape(-1, 1)": 1,
      "np.arange(x_predict.size).reshape(-1, 1)": 1,
      "X_valid_final": 1,
      "X_test_full": 1,
      "X_test_full_final": 1,
      "X_valid_pca": 1,
      "x_plot[:, np.newaxis]": 1,
      "feature_valid": 1,
      "X_valid_1": 1,
      "t['X_test']": 1,
      "df_test.set_index('id')": 1,
      "df_test['excerpt_clean']": 1,
      "val_sentences": 1,
      "testdf": 1,
      "test_data['question_text']": 1,
      "doc_df_test": 1,
      "data_test.Phrase": 1,
      "test_prep": 1,
      "stats_test_df.drop(columns=['segment_id'])": 1,
      "x_test_sgd": 1,
      "x_val_sgd": 1,
      "x_test_xgb": 1,
      "x_val_xgb": 1,
      "x_test_lgbm": 1,
      "x_val_lgbm": 1,
      "X_valid_filtered": 1,
      "test_df_filtered": 1,
      "df[X_train.columns.tolist()]": 1,
      "df_X": 1,
      "X_realtest": 1,
      "test_df[features_list]": 1,
      "sodata['post']": 1,
      "df_final_test": 1,
      "xt": 1,
      "testx": 1,
      "test_data_1": 1,
      "test_data_pred": 1,
      "df.text": 1,
      "test1": 1,
      "loading_df.iloc[:, 1:]": 1,
      "test_transformed": 1,
      "df_test['str_processed']": 1,
      "housing_test_data": 1,
      "X_test[new_features]": 1,
      "df_test[features]": 1,
      "test_df['preprocessing']": 1,
      "test_df['question_text_cleaned']": 1,
      "train[kolom]": 1,
      "test[kolom]": 1,
      "test_vector": 1,
      "xtest.comment_text": 1,
      "X_valid2": 1,
      "test_excerpts": 1,
      "test_df['clean_ques'].values": 1,
      "test_df_": 1,
      "s_data": 1,
      "to_predict": 1,
      "testmessages['Phrase']": 1,
      "x_validation": 1,
      "test_df['excerpt']": 1,
      "pred_history": 1,
      "submission_test_clean['text_clean']": 1,
      "feature[1]": 1,
      "feature[2]": 1,
      "mod_test_data[best_variables]": 1,
      "test_df['ingredients']": 1,
      "validation['Phrase']": 1,
      "validation_data": 1,
      "test_pivot": 1,
      "y_valid_pred": 1,
      "y_train_pred": 1,
      "y_test_pred": 1,
      "X_validate": 1,
      "df_test['question_text']": 1,
      "TestingFeatures": 1,
      "X_eval": 1,
      "fnc_train.iloc[te, :]": 1,
      "loading_train.iloc[te, :]": 1,
      "fnc_test": 1,
      "loading_test": 1,
      "X_sub": 1,
      "X_val_final": 1,
      "test_head": 1,
      "testData": 1,
      "self.data['Customers'].values.reshape(-1, 1)": 1,
      "self.test_data['Customers'].values.reshape(-1, 1)": 1,
      "test.drop(columns=['Id', 'Date']).astype('float64')": 1,
      "testing_data_df": 1,
      "data_train.drop(columns=['target', 'standard_error'])": 1,
      "df_test['Phrase']": 1,
      "submission": 1,
      "df_test['strIngredient']": 1,
      "test_df[num_features]": 1,
      "X_test.iloc[:, 1:]": 1,
      "test_df['question_text']": 1,
      "xtrain": 1,
      "test_set": 1,
      "df_model_pos": 1,
      "df_model_neg": 1,
      "test_data_transaction_cpy": 1,
      "dftest": 1,
      "test['question_text_cleaned']": 1,
      "test_drop": 1,
      "featuresSampled[validate_idx]": 1,
      "testDf['ingredients']": 1
    },
    "sklearn.feature_selection._variance_threshold.VarianceThreshold.fit.X": {
      "train2[cols]": 65,
      "train2p[cols]": 26,
      "train.drop(['id', 'target'], axis=1)": 18,
      "X_train": 16,
      "X": 11,
      "train_features.iloc[:, 4:]": 9,
      "data": 9,
      "X_dummy": 6,
      "data_frame": 5,
      "df_train2.iloc[:, 1:-1]": 4,
      "x_train_2.loc[train_indices]": 4,
      "data[cols]": 4,
      "data.iloc[:, 4:]": 3,
      "train_X": 3,
      "train": 3,
      "data.iloc[:, 4:][:train_features.shape[0]]": 3,
      "features_np[:, 3:]": 2,
      "train1[cont_names]": 2,
      "total": 2,
      "x_train": 2,
      "local_X_train": 2,
      "x[cols]": 2,
      "ptrain[cols]": 2,
      "train_set": 2,
      "all_features": 2,
      "Data": 2,
      "data.drop('LogSalePrice', axis=1)": 1,
      "X_train1": 1,
      "np.concatenate([X, test])[:, 4:]": 1,
      "train2[attribs]": 1,
      "temp": 1,
      "train3p[cols]": 1,
      "columns": 1,
      "train[train_num]": 1,
      "df_train": 1,
      "concatenated_df": 1,
      "traintest[dates <= 33]": 1,
      "train_features.loc[train_indices]": 1,
      "test_features.loc[test_indices]": 1,
      "X[selector_cols]": 1,
      "train_features": 1,
      "mini_train[col_train]": 1,
      "features_no_output": 1,
      "X_train2_unsup2": 1,
      "df": 1,
      "train1[cols]": 1,
      "X_train_clean": 1,
      "train_df2[cols]": 1,
      "train.drop(['Id', 'ConfirmedCases', 'Fatalities', 'Date'], axis=1)": 1,
      "A": 1,
      "santander_treino_limpo": 1,
      "dfprep[num_col]": 1,
      "df_combined_final": 1,
      "num / num.mean()": 1,
      "X_train_scaled": 1,
      "train_df.drop(['id', 'target'], axis=1)": 1,
      "df[b]": 1,
      "df1.iloc[:, 4:]": 1,
      "train_c[valid_features]": 1,
      "train[cols]": 1
    },
    "sklearn.feature_selection._variance_threshold.VarianceThreshold.__init__.threshold": {
      "1.5": 152,
      "2": 98,
      "0.8": 75,
      "0.0": 56,
      "0.01": 34,
      "0": 18,
      "VarianceThreshold_for_FS": 18,
      "0.5": 17,
      "0.85": 16,
      "0.8 * (1 - 0.8)": 12,
      "threshold": 11,
      "VARIANCE_THRESHOLD": 11,
      "0.9": 9,
      "0.4": 9,
      "0.7": 6,
      "0.05": 5,
      "0.0001": 4,
      "0.001": 4,
      "0.95 * (1 - 0.95)": 3,
      "1": 3,
      "params['var_thresh']": 2,
      "0.9 * (1 - 0.9)": 2,
      "0.02": 2,
      "0.98 * (1 - 0.98)": 2,
      "0.95": 2,
      "2.0": 2,
      "3": 2,
      "variance_t": 2,
      "0.2": 2,
      "num": 2,
      "t": 2,
      "bestthreshold": 2,
      "0.03": 2,
      "var": 1,
      "2.3": 1,
      "0.82": 1,
      "0.85 * (1 - 0.85)": 1,
      "thr": 1,
      "0.845": 1,
      "0.99": 1,
      "n": 1,
      "1.3": 1,
      "1.6": 1,
      "20.0": 1,
      "0.1": 1,
      "0.65": 1,
      "0.008": 1,
      "variance_threshold": 1,
      "threshold_n * (1 - threshold_n)": 1,
      "thresh * (1 - thresh)": 1,
      "tr": 1
    },
    "sklearn.feature_selection._base.SelectorMixin.transform.X": {
      "X_train": 95,
      "train2[cols]": 91,
      "test2[cols]": 88,
      "X_test": 84,
      "X": 44,
      "test": 43,
      "train2p[cols]": 26,
      "X_val": 17,
      "x_test": 16,
      "train_sp": 12,
      "test_sp": 12,
      "train": 10,
      "x_train": 9,
      "train_set": 8,
      "test_set": 8,
      "train_features.iloc[:, 4:]": 6,
      "test_features.iloc[:, 4:]": 6,
      "vectorizer.transform(sentences).toarray()": 6,
      "test2": 6,
      "X_dummy": 6,
      "test_features": 5,
      "val_X": 5,
      "train_X": 4,
      "df_train2.iloc[:, 1:-1]": 4,
      "df_test2.iloc[:, 1:]": 4,
      "pred_test1": 4,
      "test_X": 4,
      "x_train_2.loc[train_indices]": 4,
      "x_test_2.loc[test_indices]": 4,
      "test_data[feature_cols]": 4,
      "df_test": 4,
      "trn": 4,
      "tst": 4,
      "x_val": 4,
      "tabel[feat]": 4,
      "X_eval": 3,
      "test_df": 3,
      "train_features": 3,
      "train_data[feature_cols]": 3,
      "data[cols]": 3,
      "data.iloc[:, 4:]": 3,
      "normX": 2,
      "clean_test.fillna(0)": 2,
      "train_for_fs_no_target": 2,
      "test_data": 2,
      "X_train1": 2,
      "X_train2": 2,
      "X_test1": 2,
      "X_test2": 2,
      "submission_test": 2,
      "test_df.iloc[:, 1:]": 2,
      "train1[cont_names]": 2,
      "test1[cont_names]": 2,
      "train2": 2,
      "test.loc[:, mask]": 2,
      "X1": 2,
      "X1_test": 2,
      "local_X_train": 2,
      "local_X_test": 2,
      "x[cols]": 2,
      "x_test[cols]": 2,
      "val_X.values": 2,
      "ptrain[cols]": 2,
      "ptrain_add[cols]": 2,
      "ptest[cols]": 2,
      "ptrain_add_pos[cols]": 2,
      "ptrain_add_neg[cols]": 2,
      "Xtrain": 2,
      "Xtest": 2,
      "count_test": 2,
      "X_train_scaled": 2,
      "X_test_scaled": 2,
      "new_feature1": 2,
      "rfe_feature": 2,
      "rfe_feature2": 2,
      "rfe_feature3": 2,
      "numpyMatrix": 2,
      "train[self._feature_cols]": 2,
      "test[self._feature_cols]": 2,
      "X_valid": 2,
      "X_tests": 2,
      "binary_log_test[feature_test]": 2,
      "binary_log_test_NO[feature_test]": 2,
      "binary_log_test_NO_TNO[feature_test]": 2,
      "binary_num_test[feature_test]": 2,
      "binary_num_test_NO[feature_test]": 2,
      "binary_num_test_NO_TNO[feature_test]": 2,
      "ordinal_num_test[feature_test]": 2,
      "ordinal_num_test_NO[feature_test]": 2,
      "ordinal_num_test_NO_TNO[feature_test]": 2,
      "ordinal_log_test[feature_test]": 2,
      "ordinal_log_test_NO[feature_test]": 2,
      "ordinal_log_test_NO_TNO[feature_test]": 2,
      "freq_num_test[feature_test]": 2,
      "freq_num_test_NO[feature_test]": 2,
      "freq_num_test_NO_TNO[feature_test]": 2,
      "freq_log_test[feature_test]": 2,
      "freq_log_test_NO[feature_test]": 2,
      "freq_log_test_NO_TNO[feature_test]": 2,
      "Data": 2,
      "X_train.fillna(0)": 2,
      "df_train": 2,
      "df_test.copy()": 2,
      "X_knn": 2,
      "dfe": 2,
      "X_test_vec": 2,
      "data.drop('LogSalePrice', axis=1)": 1,
      "train_data.drop('LogSalePrice', axis=1)": 1,
      "hadi": 1,
      "train.drop(['target'], axis=1)": 1,
      "train2[attribs]": 1,
      "test2[attribs]": 1,
      "train3p[cols]": 1,
      "train_df": 1,
      "B.iloc[:, :-1]": 1,
      "A_test2": 1,
      "train_merge": 1,
      "test_merge": 1,
      "stage_2[objs]": 1,
      "to_pred[objs]": 1,
      "x_values": 1,
      "train2_pse[cols]": 1,
      "X[self.num_columns]": 1,
      "X[self.cat_columns]": 1,
      "X1_transformed": 1,
      "X1_test_transformed": 1,
      "tfidf_results": 1,
      "tfidf_results_cl": 1,
      "test_bow": 1,
      "train_noTarget": 1,
      "test_noID": 1,
      "tr": 1,
      "test.copy()": 1,
      "trf[:, 0:trf.shape[1] - 1]": 1,
      "tes": 1,
      "XVec": 1,
      "dev_X.values": 1,
      "feature_df.iloc[test_idx].values": 1,
      "mini_train[col_train]": 1,
      "mini_test[col_test]": 1,
      "x_test_final": 1,
      "test.iloc[:, 4:]": 1,
      "test_df[['answered_correctly_user', 'explanation_mean_user', 'quest_pct', 'avg_questions_seen', 'prior_question_elapsed_time', 'prior_question_had_explanation_enc', 'part', 'part_1', 'part_2', 'part_3', 'part_4', 'part_5', 'part_6', 'part_7', 'type_of_concept', 'type_of_intention', 'type_of_solving_question', 'type_of_starter', 'part_1_boolean', 'part_2_boolean', 'part_3_boolean', 'part_4_boolean', 'part_5_boolean', 'part_6_boolean', 'part_7_boolean', 'type_of_concept_boolean', 'type_of_intention_boolean', 'type_of_solving_question_boolean', 'type_of_starter_boolean']]": 1,
      "train_df[features]": 1,
      "test_df[features]": 1,
      "housing_best_poly": 1,
      "trans_x": 1,
      "trans_test": 1,
      "raw_test_df.iloc[:, 1:]": 1,
      "X_val_test": 1,
      "train_no_y": 1,
      "X_train_vectorized": 1,
      "X_predict_vectorized": 1,
      "df_submit_cleaned": 1,
      "train_x": 1,
      "test_x": 1,
      "X_to_select": 1,
      "dataset_val.values": 1,
      "X_test_data": 1,
      "rfe_test": 1,
      "rfe_test2": 1,
      "rfe_test3": 1,
      "training_features": 1,
      "testing_features": 1,
      "xtrain": 1,
      "xtest": 1,
      "train1[cols]": 1,
      "x": 1,
      "train_df2[cols]": 1,
      "test_df2[cols]": 1,
      "e_[:len(mtrain)]": 1,
      "e_[-len(mtest):]": 1,
      "A": 1,
      "xTestCat": 1,
      "xTestNum": 1,
      "df[var_cols]": 1,
      "X_test.fillna(0)": 1,
      "X_validation": 1,
      "np.array(X_train)": 1,
      "X_t": 1,
      "train_data": 1,
      "features_test": 1,
      "train_data[train_data.columns[4:]]": 1,
      "df1.iloc[:, 4:]": 1,
      "df2.iloc[:, 4:]": 1,
      "test_word_features": 1,
      "test_df[['answered_correctly_user', 'explanation_mean_user', 'quest_pct', 'avg_question_seen', 'prior_question_elapsed_time', 'prior_question_had_explanation_enc', 'part', 'part_1', 'part_2', 'part_3', 'part_4', 'part_5', 'part_6', 'part_7', 'type_of_concept', 'type_of_intention', 'type_of_solving_question', 'type_of_starter', 'part_1_boolean', 'part_2_boolean', 'part_3_boolean', 'part_4_boolean', 'part_5_boolean', 'part_6_boolean', 'part_7_boolean', 'type_of_concept_boolean', 'type_of_intention_boolean', 'type_of_solving_question_boolean', 'type_of_starter_boolean']]": 1,
      "xTest": 1,
      "m": 1,
      "test.loc[te_idx, cols]": 1,
      "X_test.iloc[:, 2:]": 1,
      "train_c[valid_features]": 1,
      "test_c[valid_features]": 1,
      "add_stat_feat(chunk.drop('ID', axis=1))": 1,
      "dev_bow": 1,
      "valid_bow": 1,
      "train_x_std_scalled": 1,
      "val_x_std_scalled": 1
    },
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.n_components": {
      "2": 63,
      "3": 31,
      "6": 27,
      "n_components": 22,
      "4": 16,
      "n": 9,
      "5": 8,
      "n_clusters": 7,
      "numGaussians": 6,
      "1": 6,
      "NK": 6,
      "components": 5,
      "k": 4,
      "n_comp": 4,
      "8": 4,
      "num_gaussians": 4,
      "11": 3,
      "self.n_components": 3,
      "n_cluster": 3,
      "n_neg_clusters + n_pos_clusters": 3,
      "compo_cnt": 2,
      "n_component_mapping[i]": 2,
      "10": 2,
      "k_pos + k_neg": 2,
      "i": 2,
      "n_components[j]": 2,
      "25": 2,
      "2 * n_clusters_per_class": 2,
      "18": 1,
      "num_clusters": 1,
      "m": 1,
      "best_component": 1,
      "2**5": 1,
      "len(init)": 1,
      "train_df.label.nunique()": 1,
      "9": 1,
      "N_CLUSTERS": 1,
      "150": 1,
      "peak_count[i]": 1,
      "i + 1": 1,
      "n_clusters * 2": 1,
      "n_classes": 1,
      "350": 1,
      "36": 1
    },
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.init_params": {
      "'kmeans'": 208,
      "'random'": 55,
      "init_params": 2,
      "CLUSTERING_GMM_INIT_PARAMS": 1
    },
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.covariance_type": {
      "'full'": 211,
      "'diag'": 28,
      "cv_type": 15,
      "covariance_matrix_type": 4,
      "'tied'": 3,
      "covariance_type[i]": 2,
      "'spherical'": 1,
      "cov_type": 1,
      "cov": 1
    },
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.max_iter": {
      "100": 214,
      "1000": 16,
      "5000": 8,
      "10000": 7,
      "100000": 3,
      "55": 3,
      "500": 3,
      "50": 2,
      "n_iter": 2,
      "max_iter": 2,
      "30": 1,
      "200": 1,
      "r": 1,
      "bestreg": 1,
      "150": 1,
      "2000": 1
    },
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.tol": {
      "0.001": 246,
      "1e-06": 9,
      "1e-10": 3,
      "tol": 2,
      "1e-05": 2,
      "0.01": 2,
      "0.0001": 1,
      "0.1": 1
    },
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.reg_covar": {
      "1e-06": 192,
      "0.001": 48,
      "covariance_matrix_regularization": 6,
      "0.075": 6,
      "reg_covar": 3,
      "0.01": 3,
      "0.0001": 2,
      "0.1": 2,
      "1": 2,
      "0.03": 1,
      "self.reg_covar": 1
    },
    "sklearn.model_selection._split.GroupKFold.__init__.n_splits": {
      "5": 212,
      "n_splits": 95,
      "10": 44,
      "n_fold": 39,
      "N_FOLD": 31,
      "N_SPLITS": 22,
      "6": 22,
      "4": 20,
      "NFOLDS": 17,
      "3": 17,
      "NUM_FOLDS": 16,
      "n_folds": 14,
      "FOLD_N": 13,
      "FOLDS": 13,
      "folds": 12,
      "nfolds": 10,
      "CFG.n_fold": 8,
      "self.n_splits": 7,
      "NFOLD": 7,
      "num_folds": 5,
      "kfold": 5,
      "k": 4,
      "SPLITS": 4,
      "N_FOLDS": 4,
      "PARAMETER.n_fold": 3,
      "config.k": 3,
      "7": 3,
      "config.num_folds": 3,
      "CFG.N_FOLDS": 3,
      "CFG.num_kfolds": 2,
      "num_split": 2,
      "K": 2,
      "K_FOLDS": 2,
      "cv": 2,
      "15": 2,
      "n_bag": 1,
      "self.n_folds": 1,
      "CFG['fold_num']": 1,
      "args['folds']": 1,
      "args['n_splits']": 1,
      "cv_folds": 1,
      "8": 1,
      "params.n_folds": 1,
      "self.config.N_FOLDS": 1,
      "params['n_splits']": 1,
      "nfold": 1,
      "kf": 1,
      "N_SPLIT": 1,
      "N_FILES": 1,
      "11": 1,
      "SPLIT_NUM": 1,
      "CFG.n_splits": 1,
      "cfg.kfold": 1,
      "20": 1,
      "2": 1,
      "conf_num_fold": 1
    },
    "sklearn.preprocessing._data.QuantileTransformer.__init__.n_quantiles": {
      "100": 232,
      "1000": 101,
      "n_quantiles": 4,
      "20": 4,
      "300": 4,
      "250": 3,
      "1500": 2,
      "q": 2,
      "500": 2,
      "len(X_train)": 2,
      "QuantileTransformer_n_quantiles": 1,
      "206": 1,
      "50": 1,
      "4": 1,
      "ParamConfig.n_quantiles": 1,
      "params['n_quantiles']": 1,
      "params['n_quantiles_first']": 1,
      "params['n_quantiles_second']": 1,
      "params['n_quantiles_final']": 1,
      "125": 1,
      "10": 1,
      "200": 1
    },
    "sklearn.preprocessing._data.QuantileTransformer.__init__.random_state": {
      "0": 204,
      "None": 92,
      "42": 47,
      "123": 4,
      "seed": 3,
      "SEED": 2,
      "self.seed": 2,
      "46": 2,
      "rng": 2,
      "12": 2,
      "10": 1,
      "321": 1,
      "2021": 1,
      "random_state": 1,
      "33": 1,
      "35": 1,
      "1068": 1,
      "np.random.randint(10000)": 1
    },
    "sklearn.preprocessing._data.QuantileTransformer.__init__.output_distribution": {
      "'normal'": 313,
      "'uniform'": 53,
      "transform_type": 1,
      "ouput_distribution": 1
    },
    "sklearn.preprocessing._data.QuantileTransformer.fit.X": {
      "raw_vec": 154,
      "pd.concat([pd.DataFrame(train[GENES + CELLS]), pd.DataFrame(test[GENES + CELLS])])": 7,
      "df[self.label_cols]": 3,
      "df[self.numeric_cols + self.time_cols]": 3,
      "df[:train.shape[0]][col].values.reshape(-1, 1)": 3,
      "pd.DataFrame(train_features[GENES + CELLS])": 3,
      "x_train": 2,
      "to.train[self.cont_names]": 2,
      "X_train.drop(cols, axis=1)": 2,
      "X_train": 2,
      "data.iloc[:, 5:]": 2,
      "X": 2,
      "data[col].to_numpy().reshape(-1, 1)": 2,
      "data_features[col].values.reshape(vec_len, 1)": 1,
      "train_df[cont_features]": 1,
      "train_features[G_COLS + C_COLS].values": 1,
      "train_features[col].values.reshape(-1, 1)": 1,
      "pd.concat([_X_train[cols], _X_test[cols]])": 1,
      "raw_vec_elapsed_time": 1,
      "raw_vec_lag_time": 1,
      "x_train[c].reshape(-1, 1)": 1,
      "df_cp[gene_cols + cell_cols]": 1,
      "X[genes + cells]": 1,
      "train[[c]]": 1,
      "Xt": 1,
      "vec": 1
    },
    "sklearn.decomposition._pca.PCA.__init__.n_components": {
      "n_comp": 375,
      "None": 356,
      "2": 341,
      "3": 144,
      "n_components": 88,
      "10": 70,
      "0.95": 68,
      "5": 63,
      "ncompo_genes": 54,
      "ncompo_cells": 54,
      "100": 47,
      "20": 44,
      "50": 43,
      "0.98": 40,
      "40": 34,
      "1": 32,
      "0.9": 30,
      "0.8": 25,
      "4": 22,
      "n_comp_CELLS": 20,
      "0.99": 19,
      "200": 19,
      "'mle'": 18,
      "n_comp_GENES": 18,
      "i": 18,
      "n": 18,
      "n_cs": 18,
      "n_gs": 18,
      "train_scaled.shape[1]": 16,
      "6": 15,
      "N_COMP": 13,
      "60": 13,
      "12": 12,
      "145": 12,
      "70": 11,
      "25": 10,
      "30": 8,
      "150": 8,
      "35": 8,
      "n_comp_genes": 8,
      "n_comp_cells": 8,
      "7": 8,
      "0.7": 8,
      "125": 7,
      "80": 7,
      "8": 7,
      "300": 7,
      "pca_num_components": 6,
      "1000": 6,
      "cat_dict[k]": 6,
      "500": 6,
      "components": 6,
      "COMPONENTS": 6,
      "0.85": 5,
      "k": 5,
      "15": 5,
      "CLUSTER_DIM": 5,
      "32": 4,
      "comp": 4,
      "11": 4,
      "numBasisFunctions": 4,
      "n_comps": 4,
      "154": 4,
      "nof_comp": 4,
      "27": 4,
      "120": 4,
      "self.n_components": 4,
      "int(round(n_components))": 4,
      "frac": 4,
      "component": 3,
      "0.97": 3,
      "400": 3,
      "180": 3,
      "pca_components": 3,
      "14": 3,
      "9": 3,
      "N_COMPONENTS": 3,
      "0.75": 3,
      "900": 3,
      "23": 3,
      "160": 3,
      "0.5": 3,
      "47": 3,
      "n_col": 3,
      "13": 3,
      "64": 3,
      "800": 3,
      "45": 3,
      "260": 2,
      "345": 2,
      "28": 2,
      "0.975": 2,
      "x": 2,
      "comp_num": 2,
      "num_comp": 2,
      "0.999": 2,
      "2000": 2,
      "16": 2,
      "COMPONENT_NUM": 2,
      "51": 2,
      "n_gene": 2,
      "n_c": 2,
      "256": 2,
      "0.93": 2,
      "d": 2,
      "512": 2,
      "29": 2,
      "n_eigens": 2,
      "npca": 2,
      "0.25": 2,
      "350": 2,
      "0.6": 2,
      "numComponents": 2,
      "75": 2,
      "self.ncomp": 2,
      "comps": 2,
      "c": 2,
      "min(7, mol.natoms)": 2,
      "90": 2,
      "num_components_for_kmeans": 2,
      "num_components": 2,
      "n_compute": 2,
      "110": 2,
      "num_feature_dimensions": 2,
      "1197": 2,
      "33": 2,
      "LENGTH": 1,
      "0.91": 1,
      "1139": 1,
      "784": 1,
      "c1": 1,
      "c2": 1,
      "73": 1,
      "53": 1,
      "65": 1,
      "1600": 1,
      "450": 1,
      "len(X_train_sc.columns)": 1,
      "len(trx_colnames_C)": 1,
      "250": 1,
      "g_comp": 1,
      "c_comp": 1,
      "reduced_comp": 1,
      "57": 1,
      "dim**2": 1,
      "18**2": 1,
      "381": 1,
      "44": 1,
      "42": 1,
      "nf": 1,
      "3000": 1,
      "2100": 1,
      "700": 1,
      "n_com": 1,
      "n_comp_PCA": 1,
      "g_n_components": 1,
      "c_n_components": 1,
      "n_pc": 1,
      "n_comps + 1": 1,
      "0.86": 1,
      "n_pca": 1,
      "n_cell": 1,
      "random_pca_dimension_genes": 1,
      "random_pca_dimension_cells": 1,
      "pca_threshold": 1,
      "embed_size": 1,
      "141": 1,
      "len(g_list)": 1,
      "len(c_list)": 1,
      "CFG['n_components'][n_model]": 1,
      "CFG['n_components']": 1,
      "int(num_seq / 4)": 1,
      "int(num_spar / 4)": 1,
      "N_COMP_G": 1,
      "N_COMP_C": 1,
      "cat_dict[i]": 1,
      "feature_cutoff": 1,
      "143": 1,
      "91": 1,
      "179": 1,
      "NUMBER_OF_COMPONENTS": 1,
      "155": 1,
      "n_dims": 1,
      "0.78": 1,
      "0.56": 1,
      "243": 1,
      "1527": 1,
      "108": 1,
      "31": 1,
      "experiment_config['min_variance']": 1,
      "38": 1,
      "best_k": 1,
      "len(db_variables.columns)": 1,
      "445": 1,
      "220": 1,
      "keeped_variance": 1,
      "pca_coef": 1,
      "settings['pca']": 1,
      "embedding_comps": 1,
      "54": 1,
      "N_COMPONENTS_C": 1,
      "N_COMPONENTS_G": 1,
      "43": 1,
      "X_filt_scale.shape[1]": 1,
      "650": 1,
      "83": 1,
      "g_n_comp": 1,
      "c_n_comp": 1,
      "explained_variance": 1,
      "0.15": 1,
      "train_trans.shape[1]": 1,
      "xi / 100": 1,
      "pc": 1,
      "189": 1,
      "pcan": 1,
      "86": 1,
      "275": 1,
      "n_comp1": 1,
      "n_comp2": 1,
      "n_clusters": 1,
      "nc": 1,
      "152": 1,
      "208": 1,
      "min(NUM_PCA_COMPONENTS, natoms)": 1,
      "N": 1,
      "d_GENE": 1,
      "d_CELL": 1,
      "COMP": 1,
      "len(gene_features)": 1,
      "len(cell_features)": 1,
      "ncFeatures": 1,
      "ngFeatures": 1,
      "pca_dim": 1,
      "j": 1,
      "pca_min_var": 1,
      "N_PCA": 1,
      "n_cfeatures": 1,
      "n_gfeatures": 1,
      "n_co": 1,
      "n_cells": 1,
      "r": 1,
      "num_decompose": 1,
      "72": 1,
      "0.94": 1,
      "nComponents": 1,
      "0.65": 1,
      "117": 1,
      "int(n_components)": 1,
      "750": 1,
      "515": 1,
      "num_pca": 1,
      "num_numeric": 1,
      "features_num": 1,
      "component_number": 1,
      "int(round(xgBO.max['params']['n_components']))": 1,
      "n_features": 1,
      "num_ft": 1,
      "f": 1,
      "n_g": 1,
      "pct": 1
    },
    "sklearn.decomposition._pca.PCA.__init__.random_state": {
      "None": 1891,
      "42": 359,
      "seed": 96,
      "420": 57,
      "rand_seed": 23,
      "SEED_VALUE": 21,
      "SEED": 20,
      "4": 17,
      "1903": 17,
      "0": 16,
      "base_seed": 16,
      "17": 11,
      "random_state": 11,
      "1234": 9,
      "self.random_state": 6,
      "1": 6,
      "DEFAULT_SEED": 6,
      "321": 6,
      "1001": 5,
      "2020": 4,
      "RANDOM_SEED": 4,
      "5": 4,
      "10": 3,
      "random_seed": 3,
      "166446054": 3,
      "self.cfg.seed": 2,
      "55": 2,
      "CFG['seed']": 2,
      "234": 2,
      "11": 2,
      "123": 2,
      "7": 2,
      "1068": 2,
      "seed_val": 2,
      "44": 2,
      "16446054": 2,
      "228": 1,
      "8188": 1,
      "RANDOM_STATE": 1,
      "15": 1,
      "421": 1,
      "20180425": 1,
      "2019": 1,
      "33": 1,
      "1984": 1,
      "23": 1,
      "rstate": 1,
      "40": 1,
      "56": 1,
      "77": 1,
      "rs": 1,
      "98": 1,
      "101": 1
    },
    "sklearn.decomposition._pca.PCA.fit.X": {
      "X": 92,
      "X_train": 50,
      "coords": 36,
      "train_scaled": 17,
      "data[GENES]": 17,
      "data[CELLS]": 17,
      "set144[0].matrix": 15,
      "x": 14,
      "df": 12,
      "X_scaled": 12,
      "x_train": 12,
      "train": 10,
      "train_features[GENES]": 9,
      "train_features[CELLS]": 9,
      "train_x_norm": 9,
      "df[[i for i in df.columns if i != 'answered_correctly']]": 9,
      "train2p[cols]": 7,
      "X_train_scaled": 7,
      "train[GENES]": 7,
      "train[CELLS]": 7,
      "features": 6,
      "only_stations": 6,
      "data": 6,
      "dataset": 6,
      "train_X": 6,
      "train_test_g_concat": 5,
      "train_test_c_concat": 5,
      "scaled_data": 4,
      "train_feat.iloc[:, 1:]": 4,
      "cust_prod": 4,
      "x_norm": 4,
      "train_rbst": 4,
      "ip": 4,
      "train_features.iloc[:, 776:876]": 4,
      "temp_df_wide": 4,
      "all_data[COLS]": 3,
      "X_std": 3,
      "tf": 3,
      "data_rescaled": 3,
      "PCA_features": 3,
      "train_data": 3,
      "df_train": 3,
      "df_pca": 3,
      "X_stand": 3,
      "standardized_train.set_index(['ID_code', 'target'])": 3,
      "self.proc_df": 3,
      "features_train_scaled": 3,
      "train_d[features]": 3,
      "train_data[features]": 3,
      "matrix": 3,
      "data[:train2.shape[0]]": 3,
      "data[GENES][:train_features.shape[0]]": 3,
      "data[CELLS][:train_features.shape[0]]": 3,
      "X_cv": 3,
      "norm_feat": 3,
      "data_all[GENES]": 2,
      "data_all[CELLS]": 2,
      "cat_features": 2,
      "pca_input_features": 2,
      "train_numerical_feat_df.iloc[:, 0:10]": 2,
      "trainImage": 2,
      "df_materials": 2,
      "df_living": 2,
      "df_assets": 2,
      "x_train.todense()": 2,
      "standardized_data": 2,
      "total_data": 2,
      "ingredients": 2,
      "sub": 2,
      "df[:len(target)]": 2,
      "model.wv.syn0": 2,
      "pca_data[len(train_df):]": 2,
      "train_df[sc_test_group]": 2,
      "actor": 2,
      "Xt": 2,
      "pca_train": 2,
      "scaled_gene_data": 2,
      "scaled_cell_data": 2,
      "df_type": 2,
      "X_train_sc": 2,
      "sclr.fit_transform(train_df[train_df.columns[1:-1]])": 2,
      "train.values": 2,
      "scaled": 2,
      "cells": 2,
      "genes": 2,
      "all_data[numcols]": 2,
      "x.iloc[:, 0:9]": 2,
      "pca_df[pca_columns]": 2,
      "features_scaled": 2,
      "CP": 2,
      "GENES": 2,
      "CELLS": 2,
      "X_tr": 2,
      "data_train": 2,
      "train_df.drop(['label'], axis=1)[::5]": 2,
      "x_raw": 2,
      "train[num_id_colmns]": 2,
      "X_test_scl": 2,
      "source_df[self.columns].values": 2,
      "xtrain": 2,
      "X_tra": 2,
      "X_full": 2,
      "x_train_sub_onehot": 2,
      "StandardScaler().fit_transform(train.loc[:, cols_pca])": 2,
      "train_trn[vcols].fillna(-1)": 2,
      "train[numcols]": 2,
      "X_subset": 2,
      "df[genes]": 2,
      "df[cells]": 2,
      "pca_x": 2,
      "ae_latent_rep_table": 2,
      "X_rep_autoencoder": 2,
      "train_df": 2,
      "X_smote": 2,
      "x_hold_test": 2,
      "feature_list": 2,
      "total_text": 2,
      "total_text_list": 2,
      "train_test.values": 2,
      "ind": 2,
      "combined": 2,
      "train_data.drop('label', axis=1)": 2,
      "scaledTrain": 2,
      "data_features[GENES]": 1,
      "data_features[CELLS]": 1,
      "xlines": 1,
      "dft2": 1,
      "x_train_norm": 1,
      "learn.model[0].encoder.weight.data": 1,
      "scaled_data.T": 1,
      "full_data": 1,
      "train2": 1,
      "cont_features": 1,
      "cont_test_features": 1,
      "cat_test_features": 1,
      "np.array(pd.concat((train_OHE, test_OHE), axis=0))": 1,
      "X_train / 255": 1,
      "df[selected_colums_for_pca]": 1,
      "df[d_cols].sample(sample_size, random_state=7)": 1,
      "df[d_cols]": 1,
      "train[cols]": 1,
      "X[genes]": 1,
      "X[cells]": 1,
      "image_set": 1,
      "test": 1,
      "X[self._vestas_features]": 1,
      "X_resampled": 1,
      "X_train_scaled[:, 0:-100]": 1,
      "X_train_scaled[:, -100:]": 1,
      "dataset.values": 1,
      "train_img_feat.values": 1,
      "df.iloc[trn_idx, :]": 1,
      "stats_scaled": 1,
      "np.concatenate([train_x_image_array, test_x_image_array], axis=0)": 1,
      "all_data[['temp', 'atemp']]": 1,
      "stage_1": 1,
      "columns": 1,
      "X_train.values": 1,
      "train_xs_df": 1,
      "train_data[train_data.columns[1:-1]]": 1,
      "train_data[train_data.columns[2:]]": 1,
      "num_data": 1,
      "train_and_test_genes_features": 1,
      "train_and_test_cell_features": 1,
      "positive_samples.flatten().reshape(positive_samples.shape[0], 96 * 96 * 3)": 1,
      "negative_samples.flatten().reshape(negative_samples.shape[0], 96 * 96 * 3)": 1,
      "x_num_data": 1,
      "train.loc[:, features]": 1,
      "X_flat": 1,
      "X_normalized": 1,
      "df_train_scaled": 1,
      "x1_train": 1,
      "train.drop(['y'], axis=1).dropna(how='any')": 1,
      "Xx.iloc[:, 0:14]": 1,
      "Xtrain": 1,
      "L0_one_hot.iloc[:, 2:]": 1,
      "train_x": 1,
      "train_image_df": 1,
      "coord": 1,
      "dummy_tr_df.drop(['num_target', 'kfold'], axis=1)": 1,
      "new.toarray()": 1,
      "train_xp_norm": 1,
      "train_xn_norm": 1,
      "vector": 1,
      "embedding_matrix": 1,
      "df_train_features[c_col]": 1,
      "all_purchases": 1,
      "train[g_list]": 1,
      "train[c_list]": 1,
      "train_feature": 1,
      "np.squeeze(s)": 1,
      "df_trainx": 1,
      "totalGenome - Encoder.predict(totalGenome)": 1,
      "totalViability - VEncoder.predict(totalViability)": 1,
      "totalViability": 1,
      "corr_feat_df": 1,
      "kmeans.cluster_centers_": 1,
      "categoricas_dummies.drop('SK_ID_PREV', axis=1)": 1,
      "x_train_flat": 1,
      "user_ai": 1,
      "comp_df[p_name]": 1,
      "numeric_sc": 1,
      "new_trans_x": 1,
      "Stand_df": 1,
      "train[all_features]": 1,
      "np.vstack((train3, test3))": 1,
      "Xtrain_r": 1,
      "img_embeds": 1,
      "nan_features": 1,
      "weight": 1,
      "scaledums": 1,
      "df_full[p_name]": 1,
      "DATAFRAME": 1,
      "pd.concat([_X_train.loc[:, decomp_cols], _X_test.loc[:, decomp_cols]])": 1,
      "data.loc[:, RSSI_FEATS]": 1,
      "xtr": 1,
      "data_train.drop('target', axis=1)": 1,
      "temp_df": 1,
      "train.drop(['weight'], axis=1).values": 1,
      "normalized_train_features": 1,
      "train_transform": 1,
      "useless_train_feature": 1,
      "train_tran": 1,
      "scaled_train_cont": 1,
      "scaled_test_cont": 1,
      "train.drop('target', axis=1)": 1,
      "XC": 1,
      "X_train_": 1,
      "payment": 1,
      "StandardScaler().fit_transform(train_df.iloc[:, 7:-1].dropna())": 1,
      "StandardScaler().fit_transform(example_test.iloc[:, 2:-1].dropna())": 1,
      "X1": 1,
      "X_train_d": 1,
      "X_test_d": 1,
      "returnsClosePrevRaw1": 1,
      "db_variables": 1,
      "np.asarray(img_set_reds)": 1,
      "vec": 1,
      "x_train_s": 1,
      "xscaled": 1,
      "filteredTrainFrame": 1,
      "data[['X', 'Y']]": 1,
      "train_features_number[skewed_feats_index]": 1,
      "X_pre": 1,
      "df[['temp', 'atemp']]": 1,
      "train.loc[:, 'V1':'V321']": 1,
      "train[feature_col].dropna()": 1,
      "numpyMatrix": 1,
      "X.fillna(0).values": 1,
      "train_num_norm": 1,
      "df.loc[train_idx, cell_cols].loc[:, cell_mask]": 1,
      "train_features.loc[train_idx, gene_cols].loc[:, gene_mask]": 1,
      "data_rescaled_g": 1,
      "data_rescaled_c": 1,
      "fnc": 1,
      "train_df[feature_columns]": 1,
      "vectors.squeeze()": 1,
      "X_train_pca": 1,
      "x_data": 1,
      "x_data_2": 1,
      "df_encoded": 1,
      "noisy": 1,
      "train2[cols]": 1,
      "all_features": 1,
      "train_for_decomposition_no_y": 1,
      "pd.concat([train_df, test_df])": 1,
      "train_x_scaled": 1,
      "X_pc_imp_train": 1,
      "res": 1,
      "non_moa_train[:, cs]": 1,
      "non_moa_train[:, gs]": 1,
      "cells_train": 1,
      "genes_train": 1,
      "test_dataset": 1,
      "df_C": 1,
      "df_V": 1,
      "X_sm_train": 1,
      "sales_train_sum": 1,
      "data_all[GENES][:train.shape[0]]": 1,
      "data_all[CELLS][:train.shape[0]]": 1,
      "train[features].as_matrix()": 1,
      "clean": 1,
      "unmissed.drop('survived', axis=1)": 1,
      "unmissed": 1,
      "X_test_cv": 1,
      "train[train.columns[2:]]": 1,
      "xdat[y == 1]": 1,
      "box_point_cloud[:, :2]": 1,
      "point_cloud[:, :2]": 1,
      "x_test": 1,
      "cell_data.values": 1,
      "data[g_cols]": 1,
      "data[c_cols]": 1,
      "train_df.drop('label', axis=1)": 1,
      "x_train.values": 1,
      "c_mat1": 1,
      "c_mat2": 1,
      "a": 1,
      "alldata": 1,
      "scaled_train": 1,
      "scaled_test": 1,
      "vect.transform(list(pd.DataFrame(train_data.text).append(pd.DataFrame(test_data.text), ignore_index=True).text)[:100]).toarray()": 1,
      "customer_data[columns]": 1,
      "train[features].iloc[:, 1:].fillna(train.fillna(train.mean()))": 1,
      "train_features.iloc[:, gene_features]": 1,
      "train_features.iloc[:, cell_features]": 1,
      "selected_data_train": 1,
      "descriptors": 1,
      "points_norm": 1,
      "vector1": 1,
      "vector2": 1,
      "fnc_sample.values": 1,
      "sm_data": 1,
      "df1.drop(['y', 'ID'], axis=1)": 1,
      "train_scaler": 1,
      "XTrainScaled": 1,
      "scld_train_features": 1,
      "X2": 1,
      "train_df[pca_FEATURES]": 1,
      "df1[feats]": 1,
      "min_max_X_train": 1,
      "train_X_prep": 1,
      "trainN": 1,
      "img": 1,
      "X_train_norm": 1,
      "train_norm_feat": 1,
      "test_norm_feat": 1,
      "trX[num_cols]": 1,
      "img_X": 1,
      "X_le_pca": 1,
      "xSfit": 1,
      "rescaledX": 1,
      "rescaledX_test": 1,
      "wgt": 1,
      "gFeature": 1,
      "cFeature": 1,
      "train_norm": 1,
      "X_test": 1
    },
    "sklearn.decomposition._truncated_svd.TruncatedSVD.__init__.n_components": {
      "n_comp": 150,
      "n_components": 114,
      "2": 101,
      "10": 81,
      "200": 74,
      "100": 48,
      "25": 46,
      "120": 34,
      "50": 27,
      "5": 23,
      "400": 23,
      "20": 16,
      "N_COMP": 14,
      "30": 12,
      "1": 11,
      "300": 10,
      "1000": 9,
      "32": 9,
      "150": 8,
      "ncomp": 7,
      "128": 6,
      "3": 6,
      "350": 6,
      "500": 6,
      "11": 6,
      "n_comp_GENES": 5,
      "n_comp_CELLS": 5,
      "140": 5,
      "n_topics": 5,
      "COMPONENTS": 5,
      "180": 4,
      "9": 4,
      "8": 4,
      "12": 4,
      "60": 4,
      "SVD_COMPONENTS": 4,
      "self.svd_n_components": 3,
      "4": 3,
      "components": 3,
      "svd_n_components": 3,
      "1500": 3,
      "15": 3,
      "n_components_gege_txt": 3,
      "komponent": 3,
      "svd_size": 2,
      "35": 2,
      "x": 2,
      "i": 2,
      "40": 2,
      "390": 2,
      "n_svd_comps": 2,
      "textNC": 2,
      "560": 2,
      "k": 2,
      "SVD_FEATURES": 2,
      "n_comps": 2,
      "2000": 2,
      "EMBEDDING_SIZE": 2,
      "n_feats": 2,
      "16": 2,
      "70": 2,
      "len(df_num.columns.values) - 1": 2,
      "n_compute": 2,
      "n": 1,
      "np.unique(y_author).shape[0]": 1,
      "450": 1,
      "175": 1,
      "430": 1,
      "tfidf_svd_components": 1,
      "out_dim": 1,
      "3500": 1,
      "1750": 1,
      "n_com": 1,
      "90": 1,
      "n_comp_tSVD": 1,
      "nbr_topics": 1,
      "410": 1,
      "80": 1,
      "n_comp_name": 1,
      "n_comp_description": 1,
      "210": 1,
      "601": 1,
      "dim": 1,
      "n_components_gege_img": 1,
      "7": 1,
      "ndim": 1,
      "ira": 1,
      "ncomps": 1,
      "X_sparse.shape[1] - 1": 1,
      "2500": 1,
      "TFIDF_SVD_WORDVEC_DIM": 1,
      "COMP": 1,
      "size": 1,
      "num_decompose": 1,
      "NUMBER_OF_COMPONENTS": 1,
      "self.lsa_components": 1,
      "201": 1,
      "n_dim": 1,
      "N": 1,
      "64": 1,
      "n_components[idx]": 1
    },
    "sklearn.decomposition._truncated_svd.TruncatedSVD.__init__.random_state": {
      "None": 497,
      "42": 120,
      "2016": 88,
      "1337": 84,
      "420": 55,
      "seed": 25,
      "12": 18,
      "17": 12,
      "1": 10,
      "0": 7,
      "1301": 7,
      "kaeru_seed": 7,
      "5511": 6,
      "10": 5,
      "random_state": 4,
      "101": 4,
      "8": 4,
      "2434": 4,
      "7": 3,
      "31": 3,
      "4": 2,
      "random_seed": 2,
      "self.seed": 2,
      "2": 2,
      "SEED": 2,
      "1024": 2,
      "2017": 2,
      "6465": 1,
      "100": 1,
      "2020": 1,
      "5115": 1,
      "15": 1,
      "1881": 1,
      "421": 1,
      "113120": 1,
      "32": 1,
      "11": 1,
      "2019": 1,
      "12345": 1,
      "777": 1,
      "rstate": 1,
      "2021": 1,
      "41": 1,
      "56": 1,
      "rs": 1,
      "98": 1
    },
    "sklearn.decomposition._truncated_svd.TruncatedSVD.fit.X": {
      "X": 42,
      "full_tfidf": 40,
      "xtrain_tfv": 17,
      "test_data": 13,
      "X_tfv": 4,
      "X_train": 3,
      "desc": 2,
      "train_vectors": 2,
      "X_train_tfv": 2,
      "fit_data": 2,
      "V[:len(train_idx)]": 2,
      "x_train_copy": 2,
      "X_train_feats": 2,
      "s_data": 2,
      "full_count.asfptype()": 2,
      "full_tfidf.asfptype()": 2,
      "df_num": 2,
      "xtrain_ctv": 2,
      "data_features[GENES]": 1,
      "data_features[CELLS]": 1,
      "trainig[trainig.columns[2:]]": 1,
      "y": 1,
      "X[genes]": 1,
      "X[cells]": 1,
      "tr_X": 1,
      "df_tfidf": 1,
      "test_tfidf": 1,
      "train": 1,
      "vstack([X, X_test])": 1,
      "onehot_df": 1,
      "x_train": 1,
      "train_x_tfidf": 1,
      "X_breeds_transformed": 1,
      "features_df.loc[pet_ids_or_filenames, :]": 1,
      "corpus_transformed": 1,
      "train1": 1,
      "tfidf_vector": 1,
      "qs_tfidf": 1,
      "X_tfidf": 1,
      "full_sparse": 1,
      "freq_matrix": 1,
      "transformed": 1,
      "trainSVD": 1,
      "txt_trasf": 1,
      "des_trasf": 1,
      "jlad_trasf": 1,
      "data": 1,
      "train_tfidf": 1,
      "X_tr_names": 1,
      "vstack([train, test])": 1,
      "fnc": 1,
      "desc_X_train": 1,
      "tfidf.transform(pd.concat([train_df['description'], test_df['description']]))": 1,
      "tfidf.transform(pd.concat([train_df['title'], test_df['title']]))": 1,
      "cv[list_train[index]]": 1,
      "ssp.vstack([X_tfidf, X_tfidf_test])": 1,
      "des_tfidf": 1,
      "title_tfidf": 1,
      "train_tfidf / 1.0": 1,
      "train_count / 1.0": 1,
      "xtrain_tfidf": 1,
      "alldata": 1,
      "allrIdy": 1,
      "tfidf_output_csr": 1,
      "bow_x_train": 1,
      "prof_dtm": 1
    },
    "sklearn.decomposition._factor_analysis.FactorAnalysis.__init__.n_components": {
      "n_comp": 16,
      "N_COMP": 3,
      "None": 3,
      "3": 2,
      "COMPONENTS": 2,
      "2": 1,
      "n_components": 1,
      "ncompo_genes": 1,
      "ncompo_cells": 1,
      "n_com": 1,
      "1": 1,
      "15": 1,
      "30": 1
    },
    "sklearn.decomposition._factor_analysis.FactorAnalysis.__init__.random_state": {
      "0": 11,
      "42": 10,
      "1903": 6,
      "seed": 3,
      "RANDOM_STATE": 2,
      "15": 1,
      "17": 1
    },
    "sklearn.decomposition._factor_analysis.FactorAnalysis.fit.X": {
      "data[GENES]": 6,
      "data[CELLS]": 6,
      "data_features[GENES]": 1,
      "data_features[CELLS]": 1,
      "stats_scaled": 1,
      "df_scaled": 1
    },
    "sklearn.cluster._kmeans.KMeans.fit.X": {
      "data": 104,
      "X": 63,
      "np.reshape(middle, [np.prod(middle.shape), 1])": 25,
      "train": 16,
      "loc_df": 15,
      "x": 12,
      "preprocess_inputs(train)[:, :, 0]": 12,
      "df": 12,
      "X_train": 10,
      "scaled_features": 8,
      "features": 8,
      "x_3d": 7,
      "P2": 7,
      "k_data": 6,
      "tocluster": 5,
      "PCA_components[['pc1', 'pc2']]": 5,
      "x2": 5,
      "x2b": 5,
      "train_": 5,
      "reduced_data": 4,
      "full[['longitude', 'latitude']]": 4,
      "img_l": 4,
      "df_train[min_max_cols]": 4,
      "target.iloc[:, 1:]": 4,
      "train_0[time_features]": 4,
      "features_scaled": 4,
      "image_2d_scaled[int(a0 / 2) - 100:int(a0 / 2) + 100, int(a1 / 2) - 100:int(a1 / 2) + 100].reshape(-1, 1)": 4,
      "x_train_pca": 3,
      "Xpca": 3,
      "temp[['longitude', 'latitude']]": 3,
      "X1": 3,
      "df_pick": 3,
      "coi[['x_center', 'y_center']]": 3,
      "reduced_data_0": 3,
      "shops_cats": 3,
      "df_sg": 3,
      "tsne_components[['t1', 't2']]": 3,
      "x_train_sc": 3,
      "df_id_vs_variable": 3,
      "x.reshape(-1, 1)": 3,
      "y.reshape(-1, 1)": 3,
      "features_cbsd": 3,
      "X_reduced": 3,
      "X_subset": 3,
      "norm_feat": 3,
      "dataset": 2,
      "user_reduced_scaled[outliers == 1, :]": 2,
      "image_array": 2,
      "animalsBow": 2,
      "df[['pickup_longitude', 'pickup_latitude']]": 2,
      "df[['dropoff_longitude', 'dropoff_latitude']]": 2,
      "X_train_multilabel": 2,
      "park_listings": 2,
      "subway_listings": 2,
      "L1_one_hot[column_names]": 2,
      "L2_one_hot[column_names]": 2,
      "train_bookingszna": 2,
      "df1": 2,
      "preprocess_inputs(df, preprocess_cols)[:, :, 0]": 2,
      "pd.DataFrame(y)": 2,
      "im_small_long": 2,
      "data_transformed": 2,
      "image": 2,
      "trainFactors": 2,
      "x_zeros": 2,
      "x_ones": 2,
      "nan_features": 2,
      "train[['pickup_longitude', 'pickup_latitude']]": 2,
      "train[['dropoff_longitude', 'dropoff_latitude']]": 2,
      "tr": 2,
      "km[km.columns[1:3]]": 2,
      "df_analyze": 2,
      "x_sc": 2,
      "x_train": 2,
      "preprocess_features(train)[:, :, 2]": 2,
      "results": 2,
      "X_tr": 2,
      "df1.iloc[:, 1:25]": 2,
      "df2.iloc[:, 1:25]": 2,
      "train_targets_nonscored.iloc[:, 1:]": 2,
      "training_features": 2,
      "dat": 2,
      "X_trainS": 2,
      "Lat_longs": 2,
      "df_numeric": 2,
      "features.values": 2,
      "train_test": 2,
      "EncoderScaled": 2,
      "X_train_pre": 2,
      "train_norm_feat": 2,
      "pick_pos": 2,
      "drop_pos": 2,
      "X_wna": 2,
      "X_idf": 2,
      "k_mean_X": 2,
      "train_labels": 1,
      "df_new.loc[index_train]": 1,
      "proj_2d": 1,
      "coords": 1,
      "feature_matrix": 1,
      "grayimg.reshape(grayimg.shape[0] * grayimg.shape[1], 1)": 1,
      "normalized_df[['Recency', 'Frequency', 'Monetary']]": 1,
      "pickups_arr": 1,
      "dropoffs_arr": 1,
      "tfidf_matrix_bis": 1,
      "data_input_0": 1,
      "pickup": 1,
      "dropoff": 1,
      "np.array([ws, hs]).T": 1,
      "airinfo[['longitude', 'latitude']]": 1,
      "df_test": 1,
      "X1_train": 1,
      "X2_train": 1,
      "X3_train": 1,
      "X4_train": 1,
      "latlong_X": 1,
      "dominant_hsv": 1,
      "temp": 1,
      "X_digit": 1,
      "train[['ConfirmedCases']]": 1,
      "df_cluster": 1,
      "df_cluster.loc[mask, cols]": 1,
      "df_coordinates.filter(regex='pickup')": 1,
      "df_coordinates.filter(regex='dropoff')": 1,
      "df.pickup_minute_of_the_day[:500000].values.reshape(-1, 1)": 1,
      "df[['pickup_latitude', 'pickup_longitude']][:500000]": 1,
      "df[['dropoff_latitude', 'dropoff_longitude']][:500000]": 1,
      "sales2": 1,
      "cluster": 1,
      "df_set": 1,
      "train.drop(['id', 'target'], axis=1).iloc[:len(train) * 8 // 10]": 1,
      "train.drop(['id', 'target'], axis=1)": 1,
      "train_embedded": 1,
      "df_bird.drop(['bird', 'id'], axis=1)": 1,
      "StSc.fit_transform(loaded_dfs[CLUSTER_FTS])": 1,
      "images[:, first:last, first:last].reshape(timesteps, -1)": 1,
      "df[['hour']]": 1,
      "dft[['pickup_longitude', 'pickup_latitude']]": 1,
      "kmeans_features": 1,
      "sequence_vectors": 1,
      "kmeansdf": 1,
      "X_transformed": 1,
      "sports_array": 1,
      "sports_km": 1,
      "data.drop('private', axis=1)": 1,
      "my_transaction[c_features]": 1,
      "my_transaction[pca_d]": 1,
      "train_clus": 1,
      "part1": 1,
      "part2": 1,
      "X[mask][self.keys]": 1,
      "data_clusmean": 1,
      "y_pred": 1,
      "store_sales": 1,
      "Xy": 1,
      "base[['app', 'device', 'os', 'channel', 'ip', 'click2attr']]": 1,
      "site_1_2": 1,
      "both_loc": 1,
      "PCA_train_x": 1,
      "X_encoded_reshape": 1,
      "centers": 1,
      "return_by_date_df['returnNormalised'].values": 1,
      "corr_feat_mtx": 1,
      "dataXY": 1,
      "encoded_embeddings_train_left": 1,
      "featurearr[i:i + samplesize]": 1,
      "test.values": 1,
      "X_scaled": 1,
      "principalComponents_df.values": 1,
      "train_x": 1,
      "areas": 1,
      "ratios": 1,
      "trainHFactors": 1,
      "df_dataset4_week1.loc[527057:527070, ['x', 'y']]": 1,
      "df2": 1,
      "df_labels": 1,
      "df[columns]": 1,
      "df[c_features]": 1,
      "df[pca_d]": 1,
      "df_analyze.drop('position', axis=1)": 1,
      "train_X": 1,
      "in_df[['Green', 'Red-Green', 'Red-Green-Sd']]": 1,
      "xtrain": 1,
      "st_cluster_data": 1,
      "X_test": 1,
      "X[conts]": 1,
      "gifts[usecols]": 1,
      "train[['Pclass', 'Fare']]": 1,
      "test[['Pclass', 'Fare']]": 1,
      "tmp_cluster": 1,
      "lattice_vector_123": 1,
      "seq": 1,
      "x_train_s": 1,
      "points": 1,
      "transformed": 1,
      "transformed_data": 1,
      "feature_df": 1,
      "img": 1,
      "X_scaled_cluster": 1,
      "preprocess_inputs(train, token2int)[:, :, 0]": 1,
      "result[idx]": 1,
      "feature": 1,
      "details": 1,
      "embeddings": 1,
      "scaled_big_df": 1,
      "reshape": 1,
      "train[train['target'] == 0][cols]": 1,
      "train[train['target'] == 0][[0, 1, 2, 3]]": 1,
      "pdesc_transformed": 1,
      "xyw[['x', 'y']]": 1,
      "df_std": 1,
      "[[x] for x in train['trip_distance'].values]": 1,
      "[[x, y] for (x, y) in zip(train['pickup_latitude'].values, train['pickup_longitude'].values)]": 1,
      "[[x, y] for (x, y) in zip(train['dropoff_latitude'].values, train['dropoff_longitude'].values)]": 1,
      "train_df4": 1,
      "train_df[:100000][['pickup_longitude', 'pickup_latitude']]": 1,
      "pngfile": 1,
      "xk": 1,
      "np.array(df[['nmask_norm', 'H', 'V', 'mask_diff']])": 1,
      "encoded_data": 1,
      "tfidf_matrix": 1,
      "df_fs": 1,
      "tmp_cut": 1,
      "self.w2vecarrays": 1,
      "input_x": 1,
      "input_c": 1,
      "cbsd_features": 1,
      "training_dataset_data": 1,
      "hists": 1,
      "selected_data_train": 1,
      "selected_data_train1": 1,
      "latlong": 1,
      "mnist_features_prepared": 1,
      "X_train[columns]": 1,
      "X[genes].append(X_test[genes])": 1,
      "X[cells].append(X_test[cells])": 1,
      "res.reshape(-1, 1)": 1,
      "train.drop(columns=['Id', 'idhogar'])[train['Target'] == t]": 1,
      "encode": 1,
      "X_node_org[:, :, 0]": 1,
      "survey_cs.drop('Q5', axis=1)": 1,
      "test_norm_feat": 1,
      "tpick_pos": 1,
      "tdrop_pos": 1,
      "Train": 1,
      "pd.concat([X_train[genes], X_test[genes]])": 1,
      "pd.concat([X_train[cells], X_test[cells]])": 1,
      "extracted_features": 1,
      "X_std": 1,
      "geo_df[['latitude', 'longitude']]": 1,
      "y2": 1,
      "f1.values.reshape(-1, 1)": 1,
      "flat_image": 1
    },
    "sklearn.cluster._kmeans.KMeans.__init__.n_clusters": {
      "n_clusters": 151,
      "2": 97,
      "k": 77,
      "5": 65,
      "4": 64,
      "3": 61,
      "i": 52,
      "8": 28,
      "10": 26,
      "20": 25,
      "num_clusters": 23,
      "6": 20,
      "15": 16,
      "200": 15,
      "30": 12,
      "n": 11,
      "9": 8,
      "42": 7,
      "numFeaturesToSelect": 7,
      "7": 6,
      "25": 6,
      "n_cluster": 5,
      "ncl": 5,
      "12": 5,
      "100": 4,
      "top_colors": 4,
      "clusters": 4,
      "11": 4,
      "best_n_clusters": 4,
      "n_boats": 3,
      "24": 3,
      "50": 3,
      "self.num_clusters": 3,
      "self.k": 3,
      "nums_cluster": 3,
      "true_k": 3,
      "cluster_num": 2,
      "clusters_count": 2,
      "n_colors": 2,
      "numOfClusters": 2,
      "1": 2,
      "ncomp": 2,
      "park_n_clusters": 2,
      "subway_n_clusters": 2,
      "K": 2,
      "par": 2,
      "k_neg": 2,
      "k_pos": 2,
      "13": 2,
      "n_clust": 2,
      "clusterNum": 2,
      "205": 2,
      "knn_cls": 2,
      "NUM_CLUSTERS": 2,
      "18": 1,
      "40": 1,
      "kernels": 1,
      "cell_k": 1,
      "gene_k": 1,
      "combined_k": 1,
      "selected_K": 1,
      "var[1]": 1,
      "int(df.shape[0] / 10)": 1,
      "3000": 1,
      "210": 1,
      "KMEANS_CLUSTERS": 1,
      "num": 1,
      "62": 1,
      "20000": 1,
      "2250": 1,
      "CFG['n_clusters'][n_model]": 1,
      "CFG['n_clusters']": 1,
      "CFG['n_class'] * 2": 1,
      "len(centers)": 1,
      "n_clusters_kmeans": 1,
      "55": 1,
      "16": 1,
      "cluster_count": 1,
      "kc": 1,
      "k_val": 1,
      "1600": 1,
      "N_CLUSTERS": 1,
      "train_df[lion_class_str][int(img_fn)]": 1,
      "57": 1,
      "250": 1,
      "550": 1,
      "n_col": 1,
      "48": 1,
      "K_best": 1,
      "1410": 1,
      "n_best_clusters": 1,
      "n_clus": 1,
      "n_comp": 1,
      "cluster": 1,
      "get_cluster_n(centers)": 1,
      "17": 1,
      "number_of_clusters": 1,
      "FDIV": 1,
      "CDIV": 1,
      "numClusters": 1,
      "1000": 1,
      "n_genes": 1,
      "n_cells": 1,
      "cl_n": 1,
      "optnClusters": 1,
      "group[1]": 1,
      "14": 1,
      "n_classes": 1,
      "n_clusters_per_class": 1,
      "35": 1,
      "32": 1,
      "id_n": 1,
      "10000": 1
    },
    "sklearn.cluster._kmeans.KMeans.__init__.random_state": {
      "None": 468,
      "0": 143,
      "SEED": 99,
      "42": 49,
      "1": 15,
      "110": 15,
      "22": 14,
      "2": 12,
      "random_state": 8,
      "1234": 7,
      "RANDOM_SEED": 7,
      "101": 6,
      "77": 6,
      "1618033": 6,
      "2020": 5,
      "111": 5,
      "10": 4,
      "4": 4,
      "42 * 42": 4,
      "CFG['seed']": 3,
      "13": 3,
      "30": 3,
      "5": 2,
      "12": 2,
      "seed": 2,
      "self.random_state": 2,
      "2018": 2,
      "3471": 2,
      "529": 2,
      "666": 2,
      "20": 2,
      "123": 2,
      "125": 2,
      "982": 2,
      "16446054": 2,
      "15": 1,
      "k": 1,
      "17": 1,
      "314": 1,
      "rand_seed": 1,
      "self.seed": 1,
      "RANDOM_SEED_KMEANS": 1,
      "1111": 1,
      "1995": 1,
      "4241": 1,
      "51": 1,
      "6": 1,
      "3": 1,
      "23": 1,
      "420": 1,
      "14": 1
    },
    "sklearn.cluster._kmeans.KMeans.predict.X": {
      "train_.values": 26,
      "test_.values": 26,
      "X": 20,
      "train.values": 13,
      "test.values": 13,
      "X_test": 10,
      "test": 7,
      "dft": 5,
      "tocluster": 5,
      "np.c_[xx.ravel(), yy.ravel()]": 5,
      "df[['pickup_longitude', 'pickup_latitude']]": 5,
      "reduced_data": 4,
      "full[['longitude', 'latitude']]": 4,
      "df": 4,
      "train": 4,
      "pngfile[:, :]": 4,
      "data.loc[:, relevant_pvars]": 3,
      "x_train_pca": 3,
      "Xpca": 3,
      "data": 3,
      "df_drop": 3,
      "test_data[['pickup_longitude', 'pickup_latitude']]": 3,
      "test_data[['dropoff_longitude', 'dropoff_latitude']]": 3,
      "X_train": 3,
      "coi[['x_center', 'y_center']]": 3,
      "df[['dropoff_longitude', 'dropoff_latitude']]": 3,
      "test[['pickup_longitude', 'pickup_latitude']]": 3,
      "test[['dropoff_longitude', 'dropoff_latitude']]": 3,
      "x_train_sc": 3,
      "user_reduced_scaled": 2,
      "image_array": 2,
      "X1_train": 2,
      "X1_val": 2,
      "X1_test": 2,
      "X2_train": 2,
      "X2_val": 2,
      "X2_test": 2,
      "X3_train": 2,
      "X3_val": 2,
      "X3_test": 2,
      "X4_train": 2,
      "X4_val": 2,
      "X4_test": 2,
      "pd.DataFrame(y)": 2,
      "train[['pickup_longitude', 'pickup_latitude']]": 2,
      "train[['dropoff_longitude', 'dropoff_latitude']]": 2,
      "tr": 2,
      "df_train[min_max_cols]": 2,
      "km[km.columns[1:3]]": 2,
      "x_val_sc": 2,
      "x_train": 2,
      "x_val": 2,
      "df_id_vs_variable": 2,
      "gifts[usecols]": 2,
      "X_train[flist].values": 2,
      "X_test[flist].values": 2,
      "c": 2,
      "c_test": 2,
      "Y": 2,
      "x": 2,
      "selected_data_test": 2,
      "train_data_pre": 2,
      "pick_pos": 2,
      "drop_pos": 2,
      "k_data": 2,
      "train_labels": 1,
      "train[['pickup_latitude', 'pickup_longitude']]": 1,
      "train[['dropoff_latitude', 'dropoff_longitude']]": 1,
      "test[['pickup_latitude', 'pickup_longitude']]": 1,
      "test[['dropoff_latitude', 'dropoff_longitude']]": 1,
      "test_tfidf": 1,
      "X_Tr[flist].values": 1,
      "Xte[flist].values": 1,
      "airinfo[['longitude', 'latitude']]": 1,
      "X_cell_v": 1,
      "X_gene_e": 1,
      "X_cell_gene": 1,
      "dominant_hsv[:len(x_train_hsv)]": 1,
      "dominant_hsv[len(x_train_hsv):]": 1,
      "np.array(X_test[var[0]]).reshape(-1, 1)": 1,
      "df_cluster": 1,
      "df_cluster.loc[mask, cols]": 1,
      "df.loc[:, cols]": 1,
      "df.pickup_minute_of_the_day.values.reshape(-1, 1)": 1,
      "df[['pickup_latitude', 'pickup_longitude']]": 1,
      "df[['dropoff_latitude', 'dropoff_longitude']]": 1,
      "df_set": 1,
      "train.drop(['id', 'target'], axis=1).iloc[len(train) * 8 // 10:]": 1,
      "test.drop(['id'], axis=1)": 1,
      "df[['hour']]": 1,
      "dft[['pickup_longitude', 'pickup_latitude']]": 1,
      "[vec]": 1,
      "X_test_transformed1": 1,
      "test_df[['sport_count_1500', 'sport_count_2000', 'sport_count_3000', 'sport_count_5000']]": 1,
      "test_df[['basketball_km', 'swim_pool_km', 'stadium_km']]": 1,
      "my_transaction[c_features]": 1,
      "my_transaction[pca_d]": 1,
      "train_clus": 1,
      "part2": 1,
      "part1": 1,
      "X[self.keys]": 1,
      "PCA_components[['pc1', 'pc2']]": 1,
      "tsne_components[['t1', 't2']]": 1,
      "L1_one_hot_test[column_names]": 1,
      "L2_one_hot_test[column_names]": 1,
      "data_test_cluster_group": 1,
      "y_pred": 1,
      "test_bookingszna": 1,
      "store_sales": 1,
      "out": 1,
      "X_val": 1,
      "test_data_final": 1,
      "base[['app', 'device', 'os', 'channel', 'ip', 'click2attr']]": 1,
      "site2": 1,
      "site_unknown": 1,
      "PCA_train_x": 1,
      "coords": 1,
      "encoded_embeddings_test": 1,
      "featurearr[i:i + samplesize]": 1,
      "df[columns]": 1,
      "df[c_features]": 1,
      "df[pca_d]": 1,
      "train_X": 1,
      "x_sc": 1,
      "score_test[np.newaxis, :]": 1,
      "sample_pca.astype(x_pca.dtype)": 1,
      "points": 1,
      "data_transformed": 1,
      "details": 1,
      "scaled_big_df": 1,
      "train[train['target'] == 0][cols]": 1,
      "[[x] for x in test['trip_distance'].values]": 1,
      "[[x, y] for (x, y) in zip(test['pickup_latitude'].values, test['pickup_longitude'].values)]": 1,
      "[[x, y] for (x, y) in zip(test['dropoff_latitude'].values, test['dropoff_longitude'].values)]": 1,
      "train_df[['dropoff_longitude', 'dropoff_latitude']]": 1,
      "centroids": 1,
      "X_test_reduced": 1,
      "ds[['pickup_longitude', 'pickup_latitude']]": 1,
      "ds[['dropoff_longitude', 'dropoff_latitude']]": 1,
      "X_trainS": 1,
      "Lat_longs": 1,
      "Train[['Lat', 'Long']]": 1,
      "Test_to_submit[['Lat', 'Long']]": 1,
      "df_numeric": 1,
      "x2": 1,
      "x2b": 1,
      "np.reshape(middle, [np.prod(middle.shape), 1])": 1,
      "input_x": 1,
      "input_c": 1,
      "test_data_vec": 1,
      "train[col].values": 1,
      "test[col].values": 1,
      "selected_data_train": 1,
      "selected_data_train1": 1,
      "selected_data_test1": 1,
      "dftest[['pickup_latitude', 'pickup_longitude']].values": 1,
      "dftest[['dropoff_latitude', 'dropoff_longitude']].values": 1,
      "full_data.loc[:, relevant_pvars]": 1,
      "test_data1": 1,
      "train_": 1,
      "test_": 1,
      "test_X_scaled": 1,
      "tpick_pos": 1,
      "tdrop_pos": 1,
      "Train": 1,
      "Test": 1,
      "df_test": 1,
      "X_wna": 1
    },
    "sklearn.model_selection._split.GroupKFold.split.groups": {
      "groups": 110,
      "df_train.question_body": 50,
      "unique_vis": 42,
      "group": 37,
      "train_df.image_id.tolist()": 22,
      "split_groups": 19,
      "train['cluster_id']": 14,
      "train['date'].values": 11,
      "X_train['DT_M']": 10,
      "molecules": 9,
      "train.question_body": 8,
      "dir_df[dir_df.columns[0]].values": 8,
      "reduce_train['installation_id']": 8,
      "df.id.tolist()": 6,
      "X_train['date_block_num']": 6,
      "df.question_body": 6,
      "av_data['installation_id']": 6,
      "df.StudyInstanceUID.tolist()": 5,
      "s": 5,
      "X['installation_id']": 5,
      "df.image_id.values": 4,
      "X['GameId']": 4,
      "train['Patient']": 4,
      "train_df.StudyInstanceUID.tolist()": 4,
      "dataset['image_name']": 4,
      "train_study_ids": 4,
      "train['group']": 4,
      "train['month']": 4,
      "get_groups(train_df, target_meter)": 4,
      "df_x.iloc[indices]['patient_id']": 3,
      "train_df['RescuerID']": 3,
      "train_id": 3,
      "df['dataset_title']": 3,
      "id_groups": 3,
      "Play_trk['PlayerGamePlay']": 3,
      "train_data['id']": 3,
      "df['Patient']": 3,
      "train_basetable['GameId']": 3,
      "train[group_col]": 3,
      "df['GameId']": 3,
      "train_df.question_body": 3,
      "df['Patient'].values": 2,
      "train_df['ID'].tolist()": 2,
      "train.label_group": 2,
      "X_train.question_body": 2,
      "df['label_group']": 2,
      "data['SentenceId']": 2,
      "self.train_df['installation_id']": 2,
      "df.StudyInstanceUID": 2,
      "train_df['patient_id'].tolist()": 2,
      "train_df['group']": 2,
      "X['molecule_name']": 2,
      "df_train.label_group": 2,
      "X_train['patient_id'].tolist()": 2,
      "train_df.filename.tolist()": 2,
      "df_split.unique_images.values": 2,
      "train_pet_ids": 2,
      "group_array": 2,
      "x_train['date']": 2,
      "df_train['label_group']": 2,
      "data[:, 'path']": 2,
      "G": 2,
      "rescuerid_encoder.transform(train_df['RescuerID'])": 2,
      "train['installation_id']": 2,
      "train['fullVisitorId']": 2,
      "g": 2,
      "train['cluster_id'] if STRATIFY else None": 2,
      "train['patient_id']": 2,
      "molecules_id": 2,
      "self.train_df[self.group]": 2,
      "train_df.url": 2,
      "train['stratify_group']": 2,
      "train.Patient": 1,
      "np.array(groups)": 1,
      "dev_df['molecule_name'].values": 1,
      "df['question_body'].values": 1,
      "GROUP": 1,
      "X_train['PatientID']": 1,
      "df['recording_id']": 1,
      "train.image_id.values": 1,
      "data[data.WHERE == 'train'].Patient.values": 1,
      "df['patient_id']": 1,
      "self.train_df.question_body_orig": 1,
      "train['patient_id'].tolist()": 1,
      "train['cluster']": 1,
      "X_train['DT_M'].to_pandas()": 1,
      "data_tr['RescuerID']": 1,
      "data[GROUP]": 1,
      "sample_indexes": 1,
      "grp_train": 1,
      "groups_train": 1,
      "extended.id.tolist()": 1,
      "groups.loc[train.index].sample(len(train), random_state=random_state)": 1,
      "train_fam": 1,
      "abnormal_train_df.image_id.tolist()": 1,
      "label_csv.StudyInstanceUID.tolist()": 1,
      "game_ids": 1,
      "y": 1,
      "groups_shuffled": 1,
      "train_df.image_id.to_list()": 1,
      "ins_ids_train": 1,
      "train_df['GameId']": 1,
      "data['patient_id'].tolist()": 1,
      "X['group']": 1,
      "self.resc": 1,
      "resc": 1,
      "kmeans_labels": 1,
      "data.iloc[:, -1]": 1,
      "replay_group": 1,
      "X_train['RescuerID']": 1,
      "train.id.tolist()": 1,
      "df['PatientID'].values": 1,
      "data.loc[:, 'path']": 1,
      "y['group_id'].values": 1,
      "full_train_df['group']": 1,
      "xtrain.question_body": 1,
      "train.excerpt": 1,
      "df.index": 1,
      "traindf['image_id']": 1,
      "split_by_building": 1,
      "split_by_site": 1,
      "split_by_month": 1,
      "X_train['MSSubClass']": 1,
      "train_labels.installation_id": 1,
      "X_train['GameId']": 1,
      "train_df['patient_id']": 1,
      "df['path']": 1,
      "labels[pass_index]": 1,
      "df.combined_src": 1,
      "train_x.question_body": 1,
      "df.image_id.tolist()": 1,
      "selected['groups']": 1,
      "rescuer_id": 1,
      "train['question_body']": 1,
      "train_df['user_id']": 1,
      "adjusted_group_df['GameId']": 1,
      "df_train['PatientID']": 1,
      "train_agg.PlayerKey.values": 1,
      "X_game_id": 1,
      "pre_train['batch']": 1,
      "df_folds[config.group_kfold_split].values": 1,
      "groups_by_patient_id_list": 1,
      "train['label_group']": 1,
      "game_id": 1,
      "train_group": 1,
      "train.date.values": 1,
      "X_train['installation_id']": 1,
      "X_train['month']": 1,
      "train_data.group": 1,
      "df_annotations_wbf.image_id.tolist()": 1,
      "df_kfold.id.tolist()": 1,
      "df_annotations.study_id.tolist()": 1,
      "game_id[season != 2017]": 1,
      "dates": 1,
      "group_train": 1,
      "train['basic_murcko_scaffold']": 1,
      "train['BM_scaffold']": 1,
      "df[groups_col].tolist()": 1,
      "install_ids.installation_id_x": 1,
      "train.category": 1,
      "image_level_df.StudyInstanceUID.tolist()": 1,
      "install_ids": 1,
      "_df_train.question_body": 1,
      "gr1": 1,
      "gr2": 1,
      "unique_sessions": 1,
      "new_train_nn['kid_id']": 1
    },
    "sklearn.model_selection._split.GroupKFold.split.X": {
      "train": 80,
      "X": 64,
      "df_train.question_body": 50,
      "X_train": 46,
      "folds": 45,
      "unique_vis": 42,
      "train_df": 38,
      "df": 37,
      "TRAIN": 9,
      "dir_df": 9,
      "train['action'].values": 8,
      "train.question_body": 7,
      "reduce_train": 7,
      "self.raw": 6,
      "df.question_body": 6,
      "x_train": 6,
      "av_data": 6,
      "data": 5,
      "df_train": 5,
      "dataset.index": 4,
      "train_image_paths": 4,
      "train[features]": 4,
      "x": 3,
      "indices": 3,
      "dataset": 3,
      "np.zeros(train_len)": 3,
      "dfx_train": 3,
      "train_df.values": 3,
      "train_data[features]": 3,
      "train_basetable['GameId']": 3,
      "train_df.question_body": 3,
      "df_folds": 3,
      "X_df": 2,
      "Xtrain": 2,
      "df.values": 2,
      "X_train.question_body": 2,
      "self.train_df": 2,
      "np.zeros(len(X_train))": 2,
      "df_split": 2,
      "feat_array": 2,
      "fnames": 2,
      "train['resp'].values": 2,
      "tr": 2,
      "X_data": 2,
      "y_mae_usage": 2,
      "train_df.url": 2,
      "train_inputs_all_cat": 2,
      "train_feat": 1,
      "np.array(Xs)": 1,
      "dev_df[TARGET].values": 1,
      "y": 1,
      "[0] * len(train_df)": 1,
      "df['recording_id']": 1,
      "df['posting_id']": 1,
      "z2": 1,
      "self.train_df.question_body_orig": 1,
      "train_df[cat_vars + cont_vars]": 1,
      "data_tr": 1,
      "data[GROUP]": 1,
      "numpy.arange(len(train))": 1,
      "train_x_numeric": 1,
      "sales_x": 1,
      "sample_indexes": 1,
      "x_train_std": 1,
      "train_df[features]": 1,
      "extended": 1,
      "train.sample(len(train), random_state=random_state)": 1,
      "train_fam": 1,
      "abnormal_train_df": 1,
      "ds.slices": 1,
      "label_csv": 1,
      "X_node": 1,
      "train_df[['x_min', 'y_min', 'x_max', 'y_max']]": 1,
      "np.zeros(len(data))": 1,
      "X_train_cat": 1,
      "pet_ids": 1,
      "train_inputs": 1,
      "data.iloc[:, :-4]": 1,
      "full_train_df": 1,
      "xtrain.question_body": 1,
      "train.excerpt": 1,
      "traindf": 1,
      "train_labels": 1,
      "train_X_df": 1,
      "np.zeros(len(train_df))": 1,
      "inputs[pass_index]": 1,
      "train_x.question_body": 1,
      "range(len(selected))": 1,
      "range(len(X))": 1,
      "train['question_body']": 1,
      "adjusted_group_df": 1,
      "y_clf": 1,
      "y_reg": 1,
      "np.arange(len(train_agg))": 1,
      "train.values": 1,
      "train['StudyInstanceUID']": 1,
      "pre_train": 1,
      "train_x": 1,
      "train.action.values": 1,
      "train_data.iloc[:, :200]": 1,
      "df_annotations_wbf": 1,
      "df_kfold": 1,
      "df_annotations": 1,
      "samples": 1,
      "train.category": 1,
      "self.train_df[self.features]": 1,
      "self.train_df[self.features + self.categoricals]": 1,
      "image_level_df": 1,
      "_df_train.question_body": 1,
      "tr1_X": 1,
      "unique_sessions": 1,
      "merged_df.iloc[:len_train]": 1,
      "normalized_train_X": 1,
      "trainAfterNMSTable": 1,
      "list(range(X.shape[0]))": 1
    },
    "sklearn.model_selection._split.GroupKFold.split.y": {
      "None": 231,
      "y": 77,
      "unique_vis": 42,
      "y_train": 32,
      "folds[TARGET]": 29,
      "train[target]": 29,
      "train['reactivity']": 14,
      "target": 11,
      "Y_train": 11,
      "train['action'].values": 8,
      "folds[CFG.target_cols]": 7,
      "self.raw": 6,
      "cl_y": 5,
      "train_df['target']": 4,
      "self.train_df[self.target]": 4,
      "dataset['label']": 4,
      "train_gt_labels": 4,
      "train['FVC']": 3,
      "folds[PARAMETER.target_cols]": 3,
      "train_df['AdoptionSpeed']": 3,
      "dfy_train": 3,
      "target.values": 3,
      "train_y": 3,
      "train_data['reactivity']": 3,
      "train_basetable['GameId']": 3,
      "df_folds[config.class_col_name]": 3,
      "ytrain": 2,
      "dataset": 2,
      "df.values": 2,
      "Y_train_reg": 2,
      "train_df": 2,
      "train['resp'].values": 2,
      "tr['FVC'].values": 2,
      "train['deg_Mg_pH10']": 2,
      "y_data": 2,
      "data[:, ['x', 'y', 'floor']]": 2,
      "folds['FVC']": 2,
      "y_mae_usage": 2,
      "y[:, 0]": 2,
      "y_df": 1,
      "np.array(ys)": 1,
      "dev_df[TARGET].values": 1,
      "X_train[X_train.columns[1:12]]": 1,
      "folds[CFG['target_cols']]": 1,
      "df['species_id']": 1,
      "df['label_group']": 1,
      "df['target']": 1,
      "train['target']": 1,
      "X_train.isFraud": 1,
      "label_tr": 1,
      "sales_y": 1,
      "yv": 1,
      "train_df[targets]": 1,
      "folds[CFG.target_col]": 1,
      "train[target_columns].sample(len(train), random_state=random_state)": 1,
      "X_train['target']": 1,
      "As": 1,
      "train_df['class_id']": 1,
      "data['target']": 1,
      "answer": 1,
      "df['reactivity']": 1,
      "act_lis": 1,
      "X_train['AdoptionSpeed'].values": 1,
      "full_train_df['building_id']": 1,
      "df.site": 1,
      "folds[target_cols]": 1,
      "train_labels.accuracy_group": 1,
      "folds['resp']": 1,
      "train_Y_df": 1,
      "df['floor']": 1,
      "df['open_channels']": 1,
      "stratify[pass_index]": 1,
      "train_df['accuracy_group']": 1,
      "y_clf": 1,
      "y_reg": 1,
      "df_train[targets]": 1,
      "train[target_cols]": 1,
      "y_labels": 1,
      "TRAIN_TAB[tar_col[tar]]": 1,
      "train_data.building": 1,
      "y_label": 1,
      "tr1_y": 1,
      "unique_sessions": 1,
      "labels": 1
    },
    "sklearn.model_selection._validation.cross_validate.cv": {
      "5": 84,
      "cv": 29,
      "kf": 29,
      "cv_split": 25,
      "3": 22,
      "kfold": 16,
      "cv_strategy": 16,
      "10": 15,
      "skf": 15,
      "rkf": 11,
      "None": 8,
      "8": 5,
      "StratifiedKFold(30)": 4,
      "6": 3,
      "folds": 2,
      "tscv": 2,
      "sk": 2,
      "KFold(n_splits=4)": 1,
      "gkf": 1,
      "100": 1,
      "GroupKFold(3).split(X_train, y_train, groups=groups)": 1,
      "cvsplit": 1,
      "group_kfold": 1,
      "2": 1,
      "4": 1,
      "CV_FOLDS": 1,
      "self.cv": 1,
      "num_folds": 1
    },
    "sklearn.model_selection._validation.cross_validate.estimator": {
      "model": 48,
      "clf": 22,
      "alg": 13,
      "est": 12,
      "pipeline": 10,
      "rf": 9,
      "pipe": 5,
      "forest": 5,
      "c": 5,
      "xgb": 4,
      "dummy_clf": 4,
      "DecisionTree": 4,
      "knn_pipe": 4,
      "svm": 3,
      "rfc": 3,
      "classifier": 3,
      "xgb_clf": 3,
      "vote_hard": 3,
      "vote_soft": 3,
      "p": 3,
      "logreg": 3,
      "random_forest": 3,
      "stacked": 3,
      "modelCV": 2,
      "model_two": 2,
      "xgbrf_model": 2,
      "ridge_model": 2,
      "knn": 2,
      "lr": 2,
      "ridge": 2,
      "lasso": 2,
      "DecisionTreeRegressor": 2,
      "LGBMRegressor": 2,
      "XGBRegressor": 2,
      "SVR": 2,
      "RandomForestRegressor": 2,
      "Ridge": 2,
      "Lasso": 2,
      "grid_hard": 2,
      "lgb20": 2,
      "lr_clf": 1,
      "xgb_reg": 1,
      "SVC": 1,
      "reference": 1,
      "multi_output_estimator": 1,
      "cls": 1,
      "m['model']": 1,
      "model()": 1,
      "model3": 1,
      "model7": 1,
      "model10": 1,
      "model_SVC_OVR": 1,
      "model_SGD_OVR": 1,
      "model_LinearSVC_OVR": 1,
      "model_LogisticRegression_OVR": 1,
      "clf_dummy": 1,
      "linear_model": 1,
      "model_tree": 1,
      "reg": 1,
      "svr": 1,
      "lsvr": 1,
      "sgd": 1,
      "decisiontree": 1,
      "ransac": 1,
      "en": 1,
      "kernelridge": 1,
      "gradientboost": 1,
      "lgbm": 1,
      "catboost": 1,
      "bernoulli_nb": 1,
      "logistic_regr": 1,
      "nu_svc": 1,
      "c_svc": 1,
      "LGBMRegressor()": 1,
      "base_model": 1,
      "rgr": 1,
      "lin_reg": 1,
      "Rf": 1,
      "LGBM": 1,
      "GBR": 1,
      "ensemble": 1,
      "pipline": 1,
      "best_lr_model": 1,
      "triv_model": 1,
      "linear_model.LogisticRegressionCV()": 1,
      "tree.DecisionTreeClassifier()": 1,
      "ensemble.RandomForestClassifier()": 1,
      "XGBClassifier()": 1,
      "baseline_pipe": 1,
      "ohe_pipeline": 1,
      "fe_pipeline": 1,
      "fs_pipeline": 1,
      "algo": 1,
      "gbr_target_carbon_monoxide": 1,
      "gbr_target_nitrogen_oxides": 1,
      "gbr_target_benzene": 1,
      "classif": 1,
      "elastic": 1,
      "model_xgb": 1,
      "RandomForestClassifier(n_estimators=100)": 1,
      "LogisticRegression()": 1,
      "gclf": 1,
      "dtc": 1,
      "model_pipeline": 1,
      "make_pipeline(TfidfVectorizer(stop_words=None, preprocessor=None, max_features=None, ngram_range=(1, 2)), LinearRegression())": 1,
      "LR": 1,
      "SVM": 1,
      "LDA": 1,
      "QDA": 1,
      "KNN": 1,
      "bayes": 1,
      "voting": 1,
      "LGBMR": 1,
      "grid_soft": 1,
      "lgb14": 1,
      "nb_clf": 1,
      "svm_clf": 1,
      "knn_clf": 1,
      "logReg_clf": 1,
      "RandomForestClassifier(n_estimators=10, random_state=1)": 1,
      "nb": 1,
      "lr_tfv": 1,
      "random_forest_tfv": 1,
      "estimator": 1,
      "estimator['estimator']": 1,
      "lr1": 1,
      "final_pipe": 1,
      "gr_boosting": 1,
      "fit": 1,
      "lgb": 1
    },
    "sklearn.model_selection._validation.cross_validate.X": {
      "X_train": 85,
      "X": 57,
      "x_train": 19,
      "train_feature": 16,
      "x": 13,
      "X_tr": 5,
      "train[x_feat]": 4,
      "train_x": 4,
      "train_feature_vectors": 4,
      "feature_2": 4,
      "X_arr": 3,
      "X_train_resampled": 3,
      "X_v1": 3,
      "X_train_scaled": 3,
      "ing_vectors": 3,
      "X.toarray()": 3,
      "X.loc[df.is_tourney, cv_features]": 2,
      "X_train_pca": 2,
      "data['Phrase']": 2,
      "balanced_data[selected_features]": 2,
      "gr.drop(['target', 'dataset', 'target_name'], axis=1)": 2,
      "train_X": 2,
      "X_test": 2,
      "X_tfv.toarray()": 2,
      "X_all": 2,
      "X_t": 2,
      "X_data": 2,
      "X_ohe": 2,
      "X_train_sc": 1,
      "train": 1,
      "final_train[cols]": 1,
      "new": 1,
      "x_pc1": 1,
      "train_generated.values": 1,
      "ss_X": 1,
      "balanced_data": 1,
      "df": 1,
      "data1[data1_X]": 1,
      "train_df.preprocessed": 1,
      "train_x_scl": 1,
      "temp.drop(['target', 'dataset', 'target_name'], axis=1)": 1,
      "data[0]": 1,
      "df_train[feature_set]": 1,
      "new_set": 1,
      "XX": 1,
      "train_dataset_df.query('group != 5').iloc[:, 4:]": 1,
      "y_pred": 1,
      "X_train_numeric": 1,
      "x_train.head(10000)": 1,
      "X_train_temp": 1,
      "data_X": 1,
      "X_train_preprocessed": 1,
      "X_sample": 1,
      "x[features]": 1,
      "X_new": 1,
      "X_standard": 1,
      "train_prep": 1,
      "train_features": 1,
      "train_df['excerpt']": 1,
      "x_data": 1,
      "x_train[train_features]": 1,
      "x_train[lgb20_test_feat_top]": 1,
      "X_train_linear": 1,
      "X_train_monotonic": 1,
      "X_train_tree": 1,
      "X_train[f].to_frame()": 1,
      "trainX": 1,
      "train_data": 1,
      "self._trainX_preprocessed": 1,
      "X_scl": 1,
      "feat": 1,
      "X_ohe_fs": 1,
      "X_ohe_rfecv": 1,
      "train_df[x_calls]": 1
    },
    "sklearn.model_selection._validation.cross_validate.y": {
      "y_train": 101,
      "y": 77,
      "train_target": 16,
      "target": 12,
      "Y": 10,
      "y_equidistant": 8,
      "y_balanced": 8,
      "y_true": 5,
      "Y_train": 4,
      "train[y_feat]": 4,
      "train_y": 4,
      "y_train_resampled": 3,
      "y_v1": 3,
      "y_data": 3,
      "y.loc[df.is_tourney]": 2,
      "Ydf": 2,
      "data['Sentiment']": 2,
      "gr.target": 2,
      "train_Y": 2,
      "y_test": 2,
      "y_all": 2,
      "y_t": 2,
      "target.values": 1,
      "ss_y": 1,
      "df.label": 1,
      "data1[Target].values.reshape(-1)": 1,
      "train_df.cleaned_label": 1,
      "train_y_impute": 1,
      "temp.target": 1,
      "data[1]": 1,
      "df_train['TARGET']": 1,
      "new_target": 1,
      "train_dataset_df.query('group != 5')['is_related']": 1,
      "y_train.head(10000)": 1,
      "y_train_temp": 1,
      "data_y": 1,
      "Y_sample": 1,
      "x[target].values.ravel()": 1,
      "np.array(train_tgt)": 1,
      "train_targets": 1,
      "train_df['target']": 1,
      "trainy": 1,
      "box_cox_trans": 1,
      "self._trainY_preprocessed": 1,
      "tar": 1,
      "train_df.TARGET": 1,
      "None": 1
    },
    "sklearn.model_selection._search.GridSearchCV.__init__.param_grid": {
      "param_grid": 621,
      "parameters": 429,
      "params": 390,
      "grid": 77,
      "parameter_grid": 60,
      "param": 52,
      "tuned_parameters": 33,
      "params_dict": 31,
      "param_test1": 25,
      "rf_params": 21,
      "hyperparameters": 17,
      "rf_param_grid": 16,
      "ridge_params_": 15,
      "grid_values": 13,
      "gridParams": 13,
      "grid_params": 13,
      "param_dist": 13,
      "lasso_params_": 12,
      "grid_param": 12,
      "param_test2": 11,
      "lasso_params": 10,
      "ex_param_grid": 10,
      "search_params": 9,
      "param_test3": 9,
      "ridge_params": 9,
      "params_grid": 9,
      "param_test": 8,
      "xgb_param_grid": 8,
      "param_test4": 7,
      "param_test5": 7,
      "parametersGrid": 7,
      "knn_params": 7,
      "parameter": 7,
      "gb_params": 7,
      "pgrid": 7,
      "cv_params": 6,
      "param_grid_rf": 6,
      "classifier_param[i]": 6,
      "{'n_estimators': range(40, 60)}": 6,
      "gs_params": 6,
      "mp['params']": 5,
      "tree_params": 5,
      "gbm_param_grid": 5,
      "hyper": 5,
      "{'n_estimators': [30, 50, 80, 100, 200]}": 5,
      "{'n_estimators': range(45, 55), 'learning_rate': [0.05, 0.1, 0.15, 0.2, 0.25, 0.3]}": 5,
      "parameters_log": 5,
      "param_grid2": 5,
      "logit_param_grid": 5,
      "pipeline_params": 5,
      "lgb_param_grid": 5,
      "lr_param_grid": 5,
      "param_tuning": 4,
      "params1": 4,
      "params2": 4,
      "params_rf": 4,
      "gb_param_grid": 4,
      "{'scale_pos_weight': [1, 2, 6, 12]}": 4,
      "param_search": 4,
      "xgb_params": 4,
      "random_grid": 4,
      "gridParameters": 4,
      "p_grid": 4,
      "{'booster': ['gbtree', 'gblinear', 'dart'], 'n_estimators': [2, 5, 10, 20, 50], 'max_depth': [3, 4, 5, 6, 10, 20], 'subsample': [0.6, 0.7, 0.8]}": 4,
      "svc_param_grid": 4,
      "{'alpha': alphas}": 4,
      "hyper_parameters": 3,
      "param_test6": 3,
      "knn_param_grid": 3,
      "params_xgb": 3,
      "rbf_param_grid": 3,
      "linear_param_grid": 3,
      "poly_param_grid": 3,
      "dict()": 3,
      "parameter_space": 3,
      "space": 3,
      "{'C': np.logspace(0.01, 2, 10)}": 3,
      "{'C': np.logspace(0.01, 1, 10)}": 3,
      "hyperparameters[name]": 3,
      "param_dict": 3,
      "params_svm": 3,
      "svm_param_grid": 3,
      "rand_forest_grid": 3,
      "est_params": 3,
      "parameters1": 3,
      "{'criterion': ['gini', 'entropy']}": 3,
      "dt_grid": 3,
      "{}": 3,
      "knn_param": 3,
      "parmas": 3,
      "lgbm_params": 3,
      "model['hyperparameters']": 3,
      "svr_params": 3,
      "model_grid": 3,
      "dict(max_depth=max_depths, min_samples_leaf=min_samples_leaves)": 3,
      "hyper_parameter": 3,
      "rf_parametros": 3,
      "{'k_init': [0.1, 1], 'k_upper': [1, 10], 'c_init': [0, init_count]}": 3,
      "hyper_params": 3,
      "ada_param_grid": 3,
      "{'n_estimators': [100, 1000]}": 3,
      "param_grid_lr": 3,
      "param_lr": 2,
      "in_parameters": 2,
      "dict(clf__C=C)": 2,
      "tree_params_grid": 2,
      "params3": 2,
      "params7": 2,
      "params_knn": 2,
      "params_lgbm": 2,
      "rf_grid": 2,
      "hyperparmeter_C": 2,
      "para_knn": 2,
      "para_dt": 2,
      "{'max_depth': [2, 4, 6]}": 2,
      "model_params": 2,
      "{'alpha': alpha}": 2,
      "{'max_depth': [16]}": 2,
      "alg_params": 2,
      "{'C': np.logspace(0.1, 1.5, 10)}": 2,
      "{'alpha': [1, 10, 30, 50]}": 2,
      "para_grids": 2,
      "param_grid_lasso": 2,
      "paremeters_rf": 2,
      "forest_param_grid": 2,
      "para1": 2,
      "para2": 2,
      "para3": 2,
      "parameters2": 2,
      "parameters3": 2,
      "egb_params": 2,
      "rf_para": 2,
      "etc_para": 2,
      "dict(alpha=alphas)": 2,
      "distributions": 2,
      "param_grid1": 2,
      "grid_parameters": 2,
      "{'max_features': [50, 100, 150], 'min_samples_leaf': [1, 5], 'n_estimators': [1000]}": 2,
      "clf['params']": 2,
      "tree_param": 2,
      "{'n_estimators': np.arange(100, 160, 20), 'learning_rate': np.arange(0.1, 1, 0.2)}": 2,
      "rf_parameters": 2,
      "mlp_parameters": 2,
      "{'penalty': ['l1', 'l2'], 'C': [0.001, 0.01, 1, 10, 100, 1000]}": 2,
      "knears_params": 2,
      "svc_params": 2,
      "param_grid_GBC": 2,
      "param_grid_RFC": 2,
      "tuned_parameters_preselected": 2,
      "xgboost_params": 2,
      "lightgbm_params": 2,
      "lightran_params": 2,
      "lf_params": 2,
      "lightree_params": 2,
      "param_dictionary": 2,
      "forestgrid": 2,
      "parametros": 2,
      "search_grid": 2,
      "lgb_params": 2,
      "xrf_param_grid": 2,
      "svm": 2,
      "k": 2,
      "xg": 2,
      "alpha_ridge": 2,
      "params_lr": 2,
      "param_lgb": 2,
      "unscaled_knn_param_grid": 2,
      "scaled_knn_param_grid": 2,
      "lbm_param_grid": 2,
      "self.param_grid": 2,
      "{'alpha': [0.1, 0.3, 0.6, 0.9, 1.0]}": 2,
      "dt_params": 2,
      "{'n_estimators': [2, 4, 6, 8, 10, 12]}": 2,
      "params_sgd": 2,
      "param_nb": 2,
      "param_nbBer": 2,
      "{'colsample_bytree': [0.8, 1.0], 'min_child_weight': [0.8, 1.0, 1.2], 'max_depth': [3, 4, 5], 'n_estimators': [500, 600, 750]}": 2,
      "param_grid_1": 2,
      "mlp_params": 2,
      "possible_params": 2,
      "params_bnb": 2,
      "{'n_estimators': range(20, 200, 10), 'learning_rate': np.linspace(0.05, 0.5, 10)}": 2,
      "gb_parameters": 2,
      "xgb_parameters": 2,
      "param_rf": 1,
      "param_sv": 1,
      "param_dt": 1,
      "param_kn": 1,
      "{'max_depth': range(8, 13)}": 1,
      "{'n_estimators': [50, 100, 150]}": 1,
      "{'max_depth': [3, 5, 7], 'tol': [0.001, 0.01, 0.0001], 'learning_rate': [0.1, 0.2, 0.3]}": 1,
      "{'learning_rate': [0.1, 0.5, 1, 1.5], 'n_estimators': [50, 100]}": 1,
      "{'n_estimators': [50, 100, 150], 'gamma': [0, 0.5, 1]}": 1,
      "param['params']": 1,
      "log_reg_grid": 1,
      "parametrs_sgd": 1,
      "rf_parametrs": 1,
      "parameterGrid": 1,
      "params[name]": 1,
      "best_params_2": 1,
      "params2_degree3": 1,
      "params5": 1,
      "params8": 1,
      "params9": 1,
      "params_ridge": 1,
      "params_lasso": 1,
      "parameters_best_model": 1,
      "lgbm_parameters_best_model": 1,
      "xgboost_parameters_best_model": 1,
      "{'n_estimators': [50, 250], 'max_depth': [1, 10], 'min_samples_split': [2, 10], 'min_samples_leaf': [1, 10]}": 1,
      "LR_param_grid": 1,
      "grid_params_1": 1,
      "paramsLinReg": 1,
      "{'colsample_bytree': [0.1], 'learning_rate': [0.1, 0.01], 'max_depth': [16], 'alpha': [5], 'n_estimators': [50]}": 1,
      "{'learning_rate': [0.1], 'max_depth': [12]}": 1,
      "{'n_neighbors': [5], 'weights': ['uniform', 'distance']}": 1,
      "{'max_depth': [8, 9, 10, 11, 12, 13, 14, 15, 16], 'n_estimators': [1000, 5000], 'learning_rate': [0.01]}": 1,
      "param_grid_n": 1,
      "hyper_space": 1,
      "config['params']": 1,
      "boost_params": 1,
      "param_grid_ridge": 1,
      "param_grid_elastic": 1,
      "param_grid_svr": 1,
      "param_grid_extra": 1,
      "param_grid_random": 1,
      "param_grid_gradient": 1,
      "br_param_grid": 1,
      "params_logr": 1,
      "params_lgb": 1,
      "param_space": 1,
      "lasso_param_grid": 1,
      "dict(pca__n_components=n_components, linear__alpha=[0.0, 1.0, 2.0, 4.0, 16.0, 32.0, 64.0, 128.0, 256.0])": 1,
      "gbm_grid": 1,
      "extra_trees_grid": 1,
      "adaboost_grid": 1,
      "hiperparametros_1": 1,
      "hiperparametros_2": 1,
      "hiperparametros_3": 1,
      "hiperparametros_4": 1,
      "hyperF": 1,
      "{'rnn__rnn_type': ('lstm', 'gru'), 'rnn__hidden_layer': ([], [64], [64, 32]), 'rnn__epochs': (30, 60, 90), 'rnn__dropout': (0, 0.15, 0.3)}": 1,
      "{'rnn__epochs': (25, 30, 35, 40, 45, 50), 'rnn__dropout': (0.25, 0.3, 0.35, 0.4)}": 1,
      "params[classifier]": 1,
      "grid_parms": 1,
      "para0": 1,
      "para4": 1,
      "para5": 1,
      "para6": 1,
      "parameters_lin": 1,
      "parameters_lasso": 1,
      "parameters_ridge": 1,
      "parameters_dtr": 1,
      "xgr_params": 1,
      "{'n_estimators': [300, 500, 800]}": 1,
      "{'n_estimators': range(50, 60), 'learning_rate': [0.05, 0.1, 0.15, 0.2, 0.25, 0.3]}": 1,
      "svm_para": 1,
      "{'booster': ['gbtree', 'gblinear', 'dart'], 'n_estimators': [25, 50, 75]}": 1,
      "boosting_params": 1,
      "forest_params": 1,
      "tunned_params": 1,
      "{'max_depth': [1, 2, 3]}": 1,
      "param_test6b": 1,
      "param_test7": 1,
      "{'max_features': range(50, 401, 50)}": 1,
      "{'noise': [x / 20.0 for x in range(3, 7)]}": 1,
      "{'pca__n_components': (0.95, 0.975, 0.99, None)}": 1,
      "{'C': np.logspace(0.0001, 10, 10)}": 1,
      "{'C': np.logspace(0.0001, 2, 10)}": 1,
      "{'alpha': [0, 10, 30, 50]}": 1,
      "optimization_dict": 1,
      "param_grid_ranFor": 1,
      "param_grid_SVM": 1,
      "param_grid3": 1,
      "{'C': [1, 2, 4, 5], 'kernel': ['linear', 'sigmoid', 'rbf']}": 1,
      "xgbc_grid": 1,
      "{'n_estimators': [1], 'max_depth': [2, 4, 8, 10, 12, 14, 16, 18, 20, 22, 24]}": 1,
      "{'C': range(1, 10)}": 1,
      "{'estimators_weight': [[w, 1 - w] for w in np.linspace(0.2, 0.8, 7)]}": 1,
      "pipe_2_params": 1,
      "log_param": 1,
      "{'criterion': ['mse', 'friedman_msemae', 'poisson']}": 1,
      "{'n_estimators': [100, 150], 'criterion': ['mse']}": 1,
      "{'kernel': ['rbf', 'linear'], 'C': [0.1, 0.5, 1, 2]}": 1,
      "{'n_neighbors': [5, 7, 10], 'weights': ['unform', 'distance']}": 1,
      "{'n_estimators': np.arange(50, 150, 20), 'learning_rate': np.arange(0.1, 1, 0.2)}": 1,
      "rfpg1": 1,
      "rfpg2": 1,
      "svm_parameters": 1,
      "knn_parameters": 1,
      "params_grid[0]": 1,
      "dict(trans__min_data_portion=min_cat_size)": 1,
      "hyperparams": 1,
      "params[pipe_name]": 1,
      "knn_grid": 1,
      "parameters_lgb": 1,
      "param_grids": 1,
      "{'C': np.arange(1, 12), 'kernel': ['rbf', 'poly', 'sigmoid']}": 1,
      "{'n_estimator': [50], 'gamma': np.arange(0.1, 0.8, 0.1), 'learning_rate': [0.3], 'max_depth': [6]}": 1,
      "{'C': [1e-05 + i * 10.0**(-6) for i in np.arange(0, 21)], 'verbose': [0]}": 1,
      "params[key]": 1,
      "{'n_estimators': [100], 'criterion': ['entropy'], 'max_depth': [30, 35], 'min_samples_split': [1, 2, 3], 'min_samples_leaf': [1, 2, 3]}": 1,
      "{'n_estimators': [70], 'criterion': ['gini', 'entropy'], 'max_depth': [7], 'bootstrap': [True]}": 1,
      "log_reg_params": 1,
      "param_CNN": 1,
      "grid_tree_regressor": 1,
      "grid_random_forests_regressor": 1,
      "grid_gradient_boosting_regressor": 1,
      "grid_ada_boost_regressor": 1,
      "grid_xgboost_regressor": 1,
      "grid_lgb_regressor": 1,
      "log_param_grid": 1,
      "tree_param_grid": 1,
      "rfor_param_grid": 1,
      "gbmn_params_gs": 1,
      "lgbm_grid": 1,
      "[{'kernel': ['poly'], 'degree': list(para_degree), 'C': list(para_C)}]": 1,
      "learners[i]['Params']": 1,
      "parameteres": 1,
      "[{'alpha': np.linspace(0, 100, 300)}]": 1,
      "[{'max_depth': [9, 12, 15], 'n_estimators': [350, 750, 1000], 'max_features': ['sqrt', 'auto']}]": 1,
      "[{'max_depth': [3, 4], 'eta': [0.1, 0.05], 'gamma': [0], 'n_estimators': [450], 'subsample': [0.9], 'colsample_bytree': [0.3, 0.4]}]": 1,
      "[{'alpha': np.linspace(0, 30, 100)}]": 1,
      "espaco_de_parametros": 1,
      "param()": 1,
      "lgbm_param_grid": 1,
      "xgbc_param_grid": 1,
      "p1": 1,
      "p2": 1,
      "param_opt": 1,
      "h": 1,
      "rdf_hyperparam": 1,
      "parameters_Linear": 1,
      "parameters_Ridge": 1,
      "parameters_Lasso": 1,
      "parameters_ElaNet": 1,
      "kneighb_params": 1,
      "{'KNN1__n_neighbors': [1, 3, 5]}": 1,
      "{'kbest__k': [1, 2, 3, 4], 'lr__C': np.logspace(-10, 10, 5)}": 1,
      "{'pca__n_components': [2, 4, 6], 'lr__C': np.logspace(-10, 10, 5)}": 1,
      "{'pca__n_components': [2, 4, 6]}": 1,
      "parameters_GBR": 1,
      "parameters_XGB": 1,
      "parameters_LGBM": 1,
      "parameters[pipe_index]": 1,
      "{'C': [1, 2, 4, 5], 'kernel': ['linear', 'rbf', 'sigmoid']}": 1,
      "{'max_depth': [2, 4, 6, 8, 10], 'n_estimators': [50, 100, 150, 200]}": 1,
      "{'C': [1.0, 10.0, 100.0, 1000.0, 10000.0], 'gamma': np.logspace(-5, -2, 2, 5)}": 1,
      "{'max_features': [0.4, 0.5, 0.6]}": 1,
      "{'selector__k': [70], 'model__n_estimators': np.arange(500, 550, 50), 'model__max_depth': [15]}": 1,
      "{'selector__k': [70, 80], 'model__max_depth': [12, 13, 15]}": 1,
      "{'selector__k': [70], 'model__learning_rate': [0.05], 'model__n_estimators': [3000, 5000], 'model__max_depth': [10], 'model__colsample_bytree': [0.3]}": 1,
      "{'selector__k': [70], 'model__learning_rate': [0.01], 'model__num_iterations': [10000], 'model__n_estimators': [500], 'model__max_bin': [100], 'model__num_leaves': [40, 50]}": 1,
      "features_parameters": 1,
      "param_rfc": 1,
      "param_etc": 1,
      "param_xgb": 1,
      "{'solver': ['lsqr'], 'shrinkage': [0, 0.25, 0.5, 0.75, 1], 'n_components': [None, 2, 5, 10]}": 1,
      "{'knn__n_neighbors': [25], 'knn__algorithm': ['ball_tree'], 'knn__leaf_size': [2, 3, 4], 'knn__p': [1]}": 1,
      "{'n_estimators': [100, 200], 'criterion': ['gini', 'entropy'], 'max_features': [18, 20], 'max_depth': [8, 10], 'bootstrap': [True]}": 1,
      "{'algorithm': ['SAMME', 'SAMME.R'], 'n_estimators': [10, 25, 50], 'learning_rate': [0.001, 0.01, 0.1]}": 1,
      "{'n_estimators': [100, 200], 'max_depth': [2, 3, 4], 'max_features': [10, 15, 20], 'learning_rate': [0.1, 1]}": 1,
      "params_gamma": 1,
      "params_4": 1,
      "params_lambda": 1,
      "Hyperparameter_d": 1,
      "paramG": 1,
      "r1": 1,
      "mlp_cv_params": 1,
      "param_lass": 1,
      "clf_pars": 1,
      "parametrs_des_regr": 1,
      "{'n_estimators': [100, 300]}": 1,
      "clf_params": 1,
      "{'n_estimators': np.arange(1, 300, 50), 'max_depth': np.arange(10, 110, 10), 'criterion': ['gini', 'entropy'], 'bootstrap': [True, False]}": 1,
      "param_e": 1,
      "param_Rf": 1,
      "param_GB": 1,
      "pars": 1,
      "kn_grid": 1,
      "{'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']}": 1,
      "{'svc__C': [0.01, 0.1, 1]}": 1,
      "param_distribs": 1,
      "{'max_depth': [2, 4, 6, 8], 'n_estimators': [20, 50, 100, 200]}": 1,
      "scaled_logistic_param_grid": 1,
      "unscaled_tree_param_grid": 1,
      "unscaled_rf_param_grid": 1,
      "estimator_parms": 1,
      "{'C': [0.0001, 0.001, 0.01, 0.1, 1]}": 1,
      "parameters_grid": 1,
      "rd_params_": 1,
      "la_params": 1,
      "self.svm_params": 1,
      "self.rand_forest_params": 1,
      "self.lgb_params": 1,
      "my_param_grid": 1,
      "RF_grid": 1,
      "linear_hyperparameters": 1,
      "grid_params_RF": 1,
      "grid_params_GB": 1,
      "params_LR": 1,
      "params_GNB": 1,
      "params_SVC": 1,
      "params_DT": 1,
      "params_RF": 1,
      "{'colsample_bytree': [1.0], 'min_child_weight': [1.0, 1.2], 'max_depth': [3, 4, 6], 'n_estimators': [5, 10, 100]}": 1,
      "params[i]": 1,
      "search_parameters": 1,
      "{'C': [1.0, 0.1, 1, 10], 'tol': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0]}": 1,
      "{'solver': ['newton-cg', 'sag', 'saga'], 'C': [1.0, 0.1, 1, 10], 'tol': [0.001, 0.01, 0.1, 1.0, 10.0]}": 1,
      "param_grid_svc": 1,
      "{'smotetomek__ratio': [0.8], 'randomforestclassifier__max_depth': [25]}": 1,
      "gbm_params": 1,
      "model[label]['param_grid']": 1,
      "params_grid_svm": 1,
      "{'max_depth': range(3, 7), 'n_estimators': (10, 50, 100, 1000)}": 1,
      "grid_rf": 1,
      "grid_lgbm": 1,
      "GSearch_param": 1,
      "pipe_grid_2": 1,
      "ff": 1,
      "logreg_params": 1,
      "et_params": 1,
      "mlp_grid": 1,
      "{'max_depth': [2, 4, 6], 'n_estimators': [500]}": 1,
      "scl_params": 1,
      "param_line": 1,
      "{'alpha': [1, 10]}": 1,
      "self.hyperparameters": 1,
      "{'C': [0.01, 0.1, 1, 10], 'gamma': [0.01, 0.1, 1, 10]}": 1,
      "dict(pca__n_components=n_components)": 1,
      "grid_param_lasso": 1,
      "param_grid_forest": 1,
      "{'l1_ratio': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], 'alpha': [0.0005]}": 1,
      "{'n_estimators': [300], 'min_samples_leaf': [1, 2, 3, 4, 5], 'max_depth': [200, 250, 300, 350, 400]}": 1,
      "{'loss': ['ls', 'lad', 'huber', 'quartile'], 'n_estimators': [100, 200, 300, 400], 'min_samples_leaf': [3, 5, 10, 20]}": 1,
      "{'scoring': ['neg_mean_squared_error'], 'min_samples_leaf': [20]}": 1,
      "grid_params_GRA": 1,
      "{'C': [0.01, 0.1, 1, 10, 100, 1000]}": 1,
      "{'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}": 1,
      "{'n_estimators': [10, 100, 200]}": 1,
      "{'alpha': [0.01, 0.1, 1, 10, 50, 100]}": 1,
      "ridge_param": 1,
      "{'alpha': np.logspace(-4, -3, 5)}": 1,
      "{'alpha': np.linspace(10, 30, 10)}": 1,
      "{'alpha': np.linspace(0.0001, 0.001, 10), 'l1_ratio': np.linspace(0.5, 1.5, 10)}": 1,
      "lr_hyper_tune": 1,
      "adb_hyper_tune": 1,
      "bgr_hyper_tune": 1,
      "grad_hyper_tune": 1,
      "dictionary": 1,
      "{'n_neighbors': [1, 2, 3, 4, 5]}": 1,
      "param_DTC": 1,
      "param_RFC": 1,
      "param_KNN": 1,
      "gauss_dic": 1,
      "bernoulli_dic": 1,
      "forest_dic": 1,
      "xgb_dic": 1,
      "params.get(model_name)": 1,
      "{'alpha': [1.0, 0.1, 0.01, 0.001], 'gamma': np.logspace(-2, 2, 5)}": 1,
      "{'C': [1.0, 10.0, 100.0, 1000.0], 'gamma': np.logspace(-2, 2, 5)}": 1,
      "search_param": 1,
      "{'max_depth': [1, 3, 5], 'n_estimators': [50, 100, 200]}": 1,
      "params[idx]": 1,
      "elastic_param": 1,
      "lgbm_param": 1,
      "svr_param": 1,
      "scaled_logistic_param": 1,
      "unscaled_decision_param_grid": 1,
      "unscaled_randomforest_param_grid": 1,
      "svc_param": 1,
      "rf_param": 1,
      "{'reg_alpha': [0.0001, 0.0002, 0.0004, 0.0008, 0.0016], 'reg_lambda': [0.01, 0.02, 0.04, 0.08, 0.16]}": 1,
      "hyperparameter_grid": 1,
      "{'C': Cs}": 1,
      "{'C': np.logspace(-2, 10, 10)}": 1,
      "{'C': np.logspace(-2, 10, 3), 'gamma': np.logspace(-9, 3, 3)}": 1,
      "{'n_estimators': n_estimators}": 1,
      "param_forest": 1,
      "baseline_params": 1,
      "lr_grid": 1,
      "svm_grid": 1,
      "params_classifier": 1,
      "param_grid_xgb1": 1,
      "param_grid_xgb2": 1,
      "param_grid_xgb3": 1,
      "param_grid_gbr1": 1,
      "param_grid_gbr2": 1,
      "param_grid_gbr3": 1,
      "param_grid_xgb": 1,
      "params[n]": 1,
      "test_params": 1,
      "para": 1,
      "mlp_param_grid": 1,
      "gbc_param_grid": 1,
      "gbc_params": 1,
      "{'kernel': ['rbf', 'linear', 'poly', 'sigmoid']}": 1,
      "params_tree": 1,
      "params_forest": 1,
      "narrow_grid": 1,
      "narrower_grid": 1,
      "params_Ridge": 1,
      "{'min_samples_split': range(5, 30, 5), 'n_estimators': range(20, 100, 20), 'max_depth': range(5, 20, 5)}": 1,
      "{'n_neighbors': np.arange(1, 100), 'p': np.arange(1, 10)}": 1,
      "mnb_parameters": 1,
      "ada_parameters": 1,
      "svc_parameters": 1,
      "logr_parameters": 1,
      "rfc_parameters": 1,
      "linreg_parameters": 1,
      "elnet_parameters": 1,
      "ridge_parameters": 1,
      "dtr_parameters": 1,
      "pipe_params": 1,
      "CV_grid": 1,
      "{'max_depth': [5, 6], 'n_estimators': [10, 25, 30], 'learning_rate': [0.1, 0.2, 0.3]}": 1,
      "params_grid_svc": 1,
      "params_grid_rf": 1,
      "params_grid_gb": 1,
      "params_grid_xgb": 1,
      "params_grid_knn": 1,
      "null": 1
    },
    "sklearn.model_selection._search.GridSearchCV.__init__.scoring": {
      "None": 995,
      "'accuracy'": 285,
      "'roc_auc'": 279,
      "'neg_mean_squared_error'": 244,
      "'neg_log_loss'": 142,
      "'neg_root_mean_squared_error'": 100,
      "'r2'": 80,
      "'neg_mean_absolute_error'": 64,
      "rmsle_scorer": 61,
      "'neg_mean_squared_log_error'": 51,
      "scorer": 47,
      "'f1'": 37,
      "scoring": 35,
      "mll_scorer": 28,
      "'f1_macro'": 28,
      "score": 21,
      "'recall'": 16,
      "accuracy_scorer": 13,
      "robust_roc_auc": 7,
      "accuracy": 7,
      "metric": 6,
      "make_scorer(roc_auc_score)": 6,
      "score_calc": 6,
      "sc": 6,
      "RMSLE": 6,
      "RMSE": 5,
      "mse_scorer": 5,
      "scoring_fnc": 5,
      "roc_auc_scorer": 5,
      "custom_scorer": 4,
      "get_rmspe_score": 4,
      "my_scorer": 4,
      "'mse'": 4,
      "acc_score": 4,
      "'roc_auc_ovr'": 4,
      "ll": 4,
      "model_scorer": 3,
      "my_score": 3,
      "'f1_micro'": 3,
      "rmse": 3,
      "kappa_score": 3,
      "'mean_absolute_error'": 3,
      "score_gini": 3,
      "'precision'": 3,
      "'average_precision'": 3,
      "acc_scorer": 3,
      "('r2', 'neg_mean_squared_error')": 3,
      "self.scorer": 3,
      "WMAE_error": 3,
      "{'acc': accuracy_scorer, 'ftwo': ftwo_scorer}": 3,
      "log_loss_build": 3,
      "rmspe_scorer": 2,
      "mape_scorer": 2,
      "weighted_mae": 2,
      "smape_scorer": 2,
      "make_scorer(baseline_loss_metric, greater_is_better=True)": 2,
      "'%s_macro' % score": 2,
      "make_scorer(f1_score)": 2,
      "mse": 2,
      "my_roc_auc_score": 2,
      "['f1_micro', 'precision', 'recall']": 2,
      "evaluation_scoring": 2,
      "auc_scorer": 2,
      "f_scorer": 2,
      "cv_scorer": 2,
      "log_scorer": 2,
      "custom_score": 2,
      "make_scorer(log_loss, greater_is_better=False, needs_proba=True)": 2,
      "parameter_selction_scoring_type": 2,
      "rmsle_score": 1,
      "log_mae_scorer": 1,
      "LL": 1,
      "'f1_weighted'": 1,
      "score_func": 1,
      "r2": 1,
      "qwk_scorer": 1,
      "ras": 1,
      "custom_scoring": 1,
      "scorers": 1,
      "the_scorer": 1,
      "make_scorer(r2_score)": 1,
      "l1(70)": 1,
      "['roc_auc', 'neg_log_loss']": 1,
      "LogLoss": 1,
      "score_dict": 1,
      "mean_squared_error_": 1,
      "'log_loss'": 1,
      "score_fn": 1,
      "'explained_variance'": 1,
      "'brier_score_loss'": 1,
      "ev_score": 1,
      "smape_score": 1,
      "gini_scorer": 1,
      "rmsle": 1,
      "mae_scorer": 1,
      "logloss_score": 1,
      "scoring_param": 1,
      "ndcg_scorer": 1,
      "'balanced_accuracy'": 1,
      "['accuracy']": 1,
      "scoring_fit": 1,
      "get_mean_auc": 1,
      "model[label]['scoring']": 1,
      "make_scorer(rmsle, greater_is_better=False)": 1,
      "accuracy_scoring": 1,
      "['accuracy', 'roc_auc']": 1,
      "make_scorer(score_func=roc_auc_score, greater_is_better=True, needs_proba=True)": 1,
      "CV_SCORERS": 1,
      "tree_scoring": 1,
      "absolute_scoring": 1,
      "l1": 1,
      "custom_gini_eval": 1,
      "'roc_auc-score'": 1,
      "roc_scorer": 1,
      "['neg_mean_absolute_error', 'r2']": 1,
      "RMSLE_scorer": 1,
      "ftwo_scorer": 1,
      "'neg_median_absolute_error'": 1,
      "cks": 1,
      "f'{score}_macro'": 1,
      "neg_cross_entropy": 1,
      "standard_roc_auc": 1
    },
    "sklearn.model_selection._search.GridSearchCV.__init__.n_jobs": {
      "None": 1516,
      "-1": 916,
      "4": 145,
      "1": 63,
      "5": 31,
      "2": 16,
      "3": 13,
      "n_jobs": 11,
      "8": 10,
      "10": 9,
      "processors": 8,
      "6": 5,
      "-2": 4,
      "16": 2,
      "number_cpus": 1,
      "multiprocessing.cpu_count() - 1": 1,
      "12": 1
    },
    "sklearn.model_selection._search.GridSearchCV.__init__.estimator": {
      "model": 255,
      "clf": 152,
      "rf": 92,
      "pipe": 62,
      "pipeline": 51,
      "lr": 48,
      "RandomForestRegressor()": 47,
      "SVC()": 45,
      "xgb": 43,
      "estimator": 42,
      "logreg": 41,
      "rfc": 39,
      "ridge": 39,
      "knn": 37,
      "svc": 33,
      "lasso": 32,
      "classifier": 30,
      "LogisticRegression()": 26,
      "xgb_model": 25,
      "RandomForestClassifier()": 23,
      "forest": 21,
      "GradientBoostingClassifier()": 19,
      "regressor": 17,
      "gbm": 17,
      "XGBClassifier()": 16,
      "SVR()": 16,
      "svr": 16,
      "ridge_m_": 14,
      "lgb.LGBMClassifier()": 14,
      "DecisionTreeClassifier()": 13,
      "forest_reg": 13,
      "RFC": 13,
      "est": 12,
      "lasso_m_": 12,
      "gbr": 12,
      "svm.SVC()": 12,
      "KNeighborsClassifier()": 11,
      "KNeighborsRegressor()": 11,
      "dt": 11,
      "reg": 11,
      "base_model": 11,
      "LinearSVC()": 11,
      "xgb1": 11,
      "lgbm": 11,
      "Ridge()": 10,
      "gb": 10,
      "rfr": 9,
      "SVC(kernel=kernal)": 9,
      "linreg": 9,
      "XGB": 9,
      "SVR(kernel='rbf', tol=0.01)": 8,
      "rf_reg": 7,
      "mdl": 7,
      "ElasticNet()": 7,
      "GBC": 7,
      "Lasso()": 7,
      "LR": 7,
      "xgb_clf": 7,
      "mlp": 7,
      "XGBRegressor()": 6,
      "mnb": 6,
      "log_reg": 6,
      "xgb2": 6,
      "qda": 6,
      "GradientBoostingRegressor()": 6,
      "svm": 6,
      "LGBMClassifier()": 6,
      "dtr": 6,
      "xgb_reg": 6,
      "XGBRegressor(**initial_params)": 6,
      "mp['model']": 5,
      "model2": 5,
      "RFR()": 5,
      "eNet": 5,
      "first_tree": 5,
      "knn_pipe": 5,
      "knc": 5,
      "LogisticRegression(random_state=0, max_iter=2000)": 5,
      "rf_model": 5,
      "classifier[i]": 5,
      "RandomForestClassifier(random_state=42)": 5,
      "pipeline_log": 5,
      "p": 5,
      "pl": 4,
      "XGBClassifier(learning_rate=0.1, n_estimators=140, max_depth=5, min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8, objective='binary:logistic', nthread=4, scale_pos_weight=1, seed=27)": 4,
      "KernelRidge(kernel='rbf')": 4,
      "lgb": 4,
      "ENet": 4,
      "RandomForest": 4,
      "MultinomialNB()": 4,
      "clf_rf": 4,
      "abc": 4,
      "sgd": 4,
      "feature_selector.estimator_": 4,
      "clf_sw": 4,
      "lgb_clf": 4,
      "forest_clf": 4,
      "esNet": 4,
      "rd": 4,
      "logit": 4,
      "cbc": 4,
      "ada": 4,
      "model_rf": 4,
      "neural_network.MLPClassifier()": 4,
      "random_forest": 4,
      "m": 4,
      "tree.DecisionTreeRegressor()": 4,
      "model['estimator']": 4,
      "tree": 4,
      "logistic": 4,
      "LogisticRegression(solver='lbfgs')": 4,
      "GBR": 4,
      "rdr": 4,
      "gbrt_reg": 4,
      "clf_xgb": 4,
      "classifier_pipeline": 4,
      "xg": 4,
      "XGBClassifier(use_label_encoder=False, verbosity=0)": 4,
      "LGB": 4,
      "ensemble.GradientBoostingRegressor(**params)": 4,
      "model1": 3,
      "NuSVR(kernel='rbf', tol=0.01)": 3,
      "AdaBoostClassifier()": 3,
      "lasso_model": 3,
      "model_xgb": 3,
      "CatBoostClassifier(iterations=885, loss_function='MultiClass', random_seed=123, depth=6)": 3,
      "Tree": 3,
      "LogisticRegression(max_iter=200)": 3,
      "gbdt": 3,
      "bnb": 3,
      "bag": 3,
      "LogisticRegression(max_iter=100)": 3,
      "SVC(probability=True)": 3,
      "gb_model": 3,
      "RandomForestClassifier(random_state=0)": 3,
      "ensemble.AdaBoostClassifier()": 3,
      "svm_clf": 3,
      "clf2": 3,
      "SVC": 3,
      "model3": 3,
      "xgr": 3,
      "rdt": 3,
      "pipeline0": 3,
      "pipeline1": 3,
      "RFR": 3,
      "gb_reg": 3,
      "linear_model.LogisticRegression()": 3,
      "dtree": 3,
      "sv": 3,
      "nb": 3,
      "pipe_2": 3,
      "lg": 3,
      "lgb_model": 3,
      "xrf_pipe": 3,
      "my_pipe": 3,
      "rfe": 3,
      "log_clf": 3,
      "GradientBoostingClassifier(n_estimators=1000)": 3,
      "clf1": 2,
      "reg4": 2,
      "regtree3": 2,
      "regtree2": 2,
      "model5": 2,
      "model6": 2,
      "elastic_net": 2,
      "main_pipeline": 2,
      "LGBMRegressor()": 2,
      "grid_model": 2,
      "my_model_1": 2,
      "log_clf_pipe": 2,
      "my_pipeline": 2,
      "basic_elastic_model": 2,
      "GradientBoostingClassifier(learning_rate=0.1, min_samples_split=500, min_samples_leaf=50, max_depth=8, max_features='sqrt', subsample=0.8, random_state=10)": 2,
      "RandomForesClassifiertModel": 2,
      "ridge_model": 2,
      "knn_model": 2,
      "model_lr": 2,
      "SVC(kernel='rbf')": 2,
      "xg_reg": 2,
      "knn_reg": 2,
      "dt_reg": 2,
      "alg_model": 2,
      "MLP": 2,
      "etc": 2,
      "RF": 2,
      "knn_clf": 2,
      "rf_clf": 2,
      "ExtraTreesRegressor()": 2,
      "Gbr": 2,
      "LogisticRegression(max_iter=1000)": 2,
      "lasso_pipeline": 2,
      "ensemble.GradientBoostingClassifier()": 2,
      "KNN": 2,
      "DTC": 2,
      "pipeline_bow_RR": 2,
      "pipeline_tfidf_RR": 2,
      "syntax_pipeline": 2,
      "las": 2,
      "log": 2,
      "xgb3": 2,
      "alg": 2,
      "egb": 2,
      "ExtraTreesClassifier()": 2,
      "dtm": 2,
      "temp": 2,
      "XGBClassifier(learning_rate=0.1, n_estimators=200, max_depth=5, min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8, use_label_encoder=False, objective='binary:logistic', nthread=4, scale_pos_weight=1, seed=27)": 2,
      "XGBClassifier(learning_rate=0.1, n_estimators=200, max_depth=7, min_child_weight=1, gamma=0.4, subsample=0.8, colsample_bytree=0.8, use_label_encoder=False, objective='binary:logistic', nthread=4, scale_pos_weight=1, seed=27)": 2,
      "XGBClassifier(learning_rate=0.1, n_estimators=200, max_depth=7, min_child_weight=1, gamma=0.4, subsample=0.75, colsample_bytree=0.85, use_label_encoder=False, objective='binary:logistic', nthread=4, scale_pos_weight=1, seed=27)": 2,
      "xgbreg": 2,
      "svm_classifier": 2,
      "gradient_booster": 2,
      "clf['instance']": 2,
      "RFC()": 2,
      "lgb_estimator": 2,
      "MLPClassifier()": 2,
      "model_log_reg": 2,
      "model_lasso": 2,
      "modelXgb": 2,
      "ensemble.RandomForestClassifier()": 2,
      "neighbors.KNeighborsClassifier()": 2,
      "gnb": 2,
      "lgr": 2,
      "rforest": 2,
      "my_model": 2,
      "classifier1": 2,
      "classifier2": 2,
      "Ensemble": 2,
      "RandomForestClassifier(warm_start=True, random_state=seed)": 2,
      "LogisticRegression(random_state=seed)": 2,
      "tree_regressor": 2,
      "random": 2,
      "lf": 2,
      "grad": 2,
      "Classification": 2,
      "rfdtm": 2,
      "XGBR": 2,
      "LGBM": 2,
      "ExtC": 2,
      "models[model]": 2,
      "MLPerseptron": 2,
      "lgb4": 2,
      "SVR(kernel='rbf', gamma=0.1)": 2,
      "LogisticRegression(solver='liblinear', random_state=20)": 2,
      "lr()": 2,
      "knn()": 2,
      "xgb()": 2,
      "sgd_reg": 2,
      "model_lgbm_regr": 2,
      "scaled_logistic_pipe": 2,
      "unscaled_knn_pipe": 2,
      "scaled_knn_pipe": 2,
      "lbm": 2,
      "LinearRegression()": 2,
      "DecisionTreeRegressor()": 2,
      "LogisticCurve(k_lower=1e-18, c_lower=0, c_upper=maximum)": 2,
      "lgbm_clf": 2,
      "toxic_clf": 2,
      "pipe_xg": 2,
      "ElasticNet": 2,
      "rf_m": 2,
      "lasso_m": 2,
      "KernelRidge(kernel='rbf', gamma=0.1)": 2,
      "GaussianNB()": 2,
      "BernoulliNB()": 2,
      "XGBClassifier(learning_rate=0.1, n_estimators=177, max_depth=5, min_child_weight=1, gamma=0.0, subsample=0.9, colsample_bytree=0.9, objective='binary:logistic', nthread=4, scale_pos_weight=1, seed=27)": 2,
      "SVMC": 2,
      "LGBMClassifier(objective='binary', boosting_type='gbdt', n_jobs=-1, eval_metric='auc', silent=1, random_state=random_seed)": 2,
      "bst": 2,
      "mlp_model": 2,
      "lir": 2,
      "regr": 2,
      "svc_grid_search": 2,
      "pipe_lgbm": 2,
      "pipe_lr": 2,
      "clf[1]": 2,
      "xgb.XGBRegressor()": 2,
      "GradientBoostingClassifier(learning_rate=0.01, n_estimators=500, max_features='sqrt', random_state=1)": 2,
      "adaDTC": 2,
      "AdaBoostRegressor()": 2,
      "ridreg": 2,
      "model[1]": 2,
      "pipe_TE": 2,
      "lgb_temp": 1,
      "xgb_temp": 1,
      "Lmodel": 1,
      "model4": 1,
      "text_clf": 1,
      "clf_gb": 1,
      "param['model']": 1,
      "kn": 1,
      "model_class()": 1,
      "GradientBoostingClassifier(learning_rate=0.1, n_estimators=80, max_features='sqrt', subsample=0.8, random_state=10)": 1,
      "GradientBoostingClassifier(learning_rate=0.1, n_estimators=80, max_depth=15, max_features='sqrt', subsample=0.8, random_state=10)": 1,
      "GradientBoostingClassifier(learning_rate=0.1, n_estimators=80, max_depth=15, min_samples_split=1000, min_samples_leaf=30, subsample=0.8, random_state=10)": 1,
      "GradientBoostingClassifier(learning_rate=0.1, n_estimators=80, max_depth=15, min_samples_split=1000, min_samples_leaf=30, max_features=7, random_state=10)": 1,
      "XGBClassifier(learning_rate=0.1, n_estimators=140, max_depth=5, min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8, objective='binary:logistic', nthread=4, scale_pos_weight=1, seed=27)": 1,
      "XGBClassifier(learning_rate=0.1, n_estimators=140, max_depth=9, min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8, objective='binary:logistic', nthread=4, scale_pos_weight=1, seed=27)": 1,
      "XGBClassifier(learning_rate=0.1, n_estimators=177, max_depth=5, min_child_weight=1, gamma=0.2, subsample=0.8, colsample_bytree=0.8, objective='binary:logistic', nthread=4, scale_pos_weight=1, seed=27)": 1,
      "default_rf": 1,
      "text_clf1": 1,
      "text_clf2": 1,
      "text_clf3": 1,
      "text_clf4": 1,
      "text_clf5": 1,
      "text_clf6": 1,
      "sgd_estimator": 1,
      "rf_estimator": 1,
      "XGBRmodel": 1,
      "v_reg": 1,
      "linear_model_sgd": 1,
      "Logis_clf": 1,
      "pipeline_elasticnet": 1,
      "pipeline_xg": 1,
      "xgb_pipeline": 1,
      "tree.DecisionTreeRegressor(random_state=1)": 1,
      "LGBMRegressor(objective='regression', boosting_type='gbdt', metric='rmse', random_state=1)": 1,
      "XGBRegressor(objective='reg:linear', booster='gbtree', eval_metric='rmse', random_state=1)": 1,
      "modelLR": 1,
      "LogisticRegression(max_iter=5000, random_state=0)": 1,
      "rnd_clf": 1,
      "final_pipeline": 1,
      "SVCreg": 1,
      "ctb_reg": 1,
      "ext_reg": 1,
      "rfc_b": 1,
      "LDA": 1,
      "LRC": 1,
      "model_nv": 1,
      "ada_clf": 1,
      "cb_clf": 1,
      "GradientBoostingRegressor(random_state=0)": 1,
      "xgb_formation": 1,
      "xgb_bandgap": 1,
      "KNeighborsClassifier(n_neighbors=30)": 1,
      "rfEstimator": 1,
      "models": 1,
      "SVC(C=200, kernel='rbf', degree=5, gamma=1, coef0=1, shrinking=True, tol=0.001, probability=False, cache_size=200, class_weight=None, verbose=True, max_iter=-1, decision_function_shape=None, random_state=None)": 1,
      "DT": 1,
      "logi": 1,
      "dectree": 1,
      "chosen_pipeline": 1,
      "config['model']": 1,
      "GradientBoostingClassifier(random_state=0)": 1,
      "model(**kwargs)": 1,
      "LR1": 1,
      "RF_GS": 1,
      "KNN_GS": 1,
      "model_for_grid": 1,
      "mlp_reg": 1,
      "RandomForestClassifier(n_estimators=100)": 1,
      "br_model": 1,
      "DecisionTreeClassifier(random_state=17)": 1,
      "svm_model": 1,
      "elanet": 1,
      "pipe_cv": 1,
      "GBM": 1,
      "XGBRegressor(min_child_weight=0, gamma=0, colsample_bytree=0.7, objective='reg:squarederror', nthread=-1, scale_pos_weight=1, subsample=0.7, seed=27)": 1,
      "LGBMRegressor(boosting_type='gbdt', objective='regression', bagging_fraction=0.8, bagging_freq=1, verbose=-1)": 1,
      "RandomForestRegressor(oob_score=True, random_state=10)": 1,
      "RandomForestRegressor(n_estimators=best_n_estimators, oob_score=True, random_state=10)": 1,
      "RandomForestRegressor(n_estimators=best_n_estimators, max_depth=best_max_depth, oob_score=True, random_state=10)": 1,
      "RandomForestRegressor(n_estimators=best_n_estimators, max_depth=best_max_depth, min_samples_split=best_min_samples_split, oob_score=True, random_state=10)": 1,
      "RandomForestRegressor(n_estimators=best_n_estimators, max_depth=best_max_depth, min_samples_split=best_min_samples_split, min_samples_leaf=best_min_samples_leaf, oob_score=True, random_state=10)": 1,
      "rfreg": 1,
      "gbreg": 1,
      "lsvm": 1,
      "bdt": 1,
      "logmod": 1,
      "lgb_mod": 1,
      "clf3": 1,
      "SVC(C=1)": 1,
      "Elastic": 1,
      "XGBRegressor(learning_rate=0.125, n_estimators=1000, max_depth=9, min_child_weight=4, gamma=0.125, subsample=0.8, colsample_bytree=0.8, random_state=42)": 1,
      "RFmodel": 1,
      "new_model": 1,
      "ortho": 1,
      "ARD": 1,
      "baye": 1,
      "SGD": 1,
      "logist_reg": 1,
      "rf1": 1,
      "rf2": 1,
      "rf3": 1,
      "xgb0": 1,
      "xgb4": 1,
      "xgb5": 1,
      "xgb6": 1,
      "xgboost.XGBRegressor(random_state=i)": 1,
      "sgd_clf": 1,
      "mnb_gs": 1,
      "base_elastic_model": 1,
      "pre_process_pl": 1,
      "clf_rfc": 1,
      "symbRegage": 1,
      "XGBClassifier(tree_method='gpu_hist')": 1,
      "model_ls": 1,
      "XGBClassifier(learning_rate=0.1, n_estimators=200, max_depth=7, min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8, use_label_encoder=False, objective='binary:logistic', nthread=4, scale_pos_weight=1, seed=27)": 1,
      "XGBClassifier(learning_rate=0.1, n_estimators=200, max_depth=7, min_child_weight=1, gamma=0.4, subsample=0.75, colsample_bytree=0.85, use_label_encoder=False, objective='binary:logistic', nthread=4, reg_alpha=10, scale_pos_weight=1, seed=27)": 1,
      "KNeighborsClassifier(weights='uniform')": 1,
      "KNeighborsClassifier(weights='distance')": 1,
      "MyPipe": 1,
      "fp": 1,
      "SVC(kernel=kernel)": 1,
      "RandomForestRegressor(n_estimators=250, n_jobs=4, min_samples_split=25, min_samples_leaf=25, max_depth=3)": 1,
      "sgdc": 1,
      "modelregr": 1,
      "RR": 1,
      "LaR": 1,
      "DTR": 1,
      "confirmed_cases_predictor": 1,
      "fatalities_predictor": 1,
      "elasticnet": 1,
      "stack_gen": 1,
      "ml_pipe": 1,
      "ranFor3": 1,
      "rfkkkkkk": 1,
      "model_to_set": 1,
      "RandomForestRegressor(random_state=my_randome_state)": 1,
      "XGBRegressor(random_state=1)": 1,
      "br": 1,
      "logistic_classifier": 1,
      "XGBClassifier(random_state=random_state)": 1,
      "xgbc": 1,
      "RandomForestClassifier(n_jobs=-1, random_state=0)": 1,
      "xgb.XGBClassifier(objective='multi:softmax', eval_metric='mlogloss', seed=42, use_label_encoder=False)": 1,
      "stacked_model": 1,
      "sum_pipeline": 1,
      "xgbr": 1,
      "lr_pipe2": 1,
      "log_pipe": 1,
      "tree_pipe": 1,
      "RandomForestClassifier(class_weight='balanced')": 1,
      "xgboost.XGBClassifier(subsample=0.5, colsample_bytree=0.25, eval_metric='auc', use_label_encoder=False)": 1,
      "pipe_1_rf": 1,
      "pipe_2_rf": 1,
      "tree_reg": 1,
      "svm.SVR()": 1,
      "MLPRegressor(activation='relu', solver='adam', max_iter=300)": 1,
      "model_pipeline": 1,
      "DecisionTreeClassifier(random_state=2021)": 1,
      "pipelines[pipe_name]": 1,
      "RandomForestRegressor(random_state=42)": 1,
      "LinearSVR()": 1,
      "lgbc": 1,
      "etc_clf": 1,
      "lgbm_lr": 1,
      "svr_basic": 1,
      "XGBRegressor(learning_rate=0.1, n_estimators=50, max_depth=3, min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8, nthread=4, scale_pos_weight=1, seed=27, tree_method='gpu_hist')": 1,
      "XGBRegressor(learning_rate=0.05, n_estimators=150, max_depth=10, min_child_weight=6, subsample=0.7, colsample_bytree=0.7, objective='reg:linear', seed=27)": 1,
      "ls": 1,
      "estimator_lasso": 1,
      "pa": 1,
      "XGBRegressor(random_state=my_randome_state)": 1,
      "rfclf": 1,
      "models[key]": 1,
      "ExtraTreesClassifier(random_state=1)": 1,
      "RandomForestClassifier(random_state=1)": 1,
      "AdaBoostClassifier(random_state=1)": 1,
      "full_pipeline": 1,
      "keras_reg": 1,
      "random_forests_regressor": 1,
      "gradient_boosting_regressor": 1,
      "ada_boost_regressor": 1,
      "xgboost_regressor": 1,
      "lgb_regressor": 1,
      "RandomForestClassifier(n_jobs=10)": 1,
      "eclf_h": 1,
      "tree.DecisionTreeClassifier()": 1,
      "xgb.XGBClassifier(silent=True)": 1,
      "gbmn": 1,
      "neural_network": 1,
      "WordSelector()": 1,
      "xgb.XGBClassifier(objective='binary:logistic', eval_metric='rmse', use_label_encoder=False, random_state=42)": 1,
      "learners[i]['Model']": 1,
      "Ridge(random_state=251)": 1,
      "RandomForestRegressor(n_jobs=-1, criterion='mse', random_state=151)": 1,
      "XGBRegressor(seed=101, tree_method='gpu_hist', predictor='gpu_predictor')": 1,
      "Ridge(random_state=51)": 1,
      "lgb_clf2": 1,
      "ensemble.RandomForestClassifier(min_samples_split=5, random_state=1)": 1,
      "MLPRegressor()": 1,
      "rfr_d": 1,
      "rfdtm_LF": 1,
      "EL": 1,
      "AdaBoostR": 1,
      "KernelDensity()": 1,
      "dtregressor": 1,
      "Rf": 1,
      "Class_name": 1,
      "clf_tree": 1,
      "clf_NaiveBayes": 1,
      "clf_Xg": 1,
      "LinearSVC(max_iter=350)": 1,
      "Cat": 1,
      "models[i]": 1,
      "gboost": 1,
      "model_GridSearch": 1,
      "RF_Model": 1,
      "mlp1": 1,
      "mlp2": 1,
      "rdf": 1,
      "RF_init": 1,
      "pipe_Linear": 1,
      "pipe_Ridge": 1,
      "pipe_Lasso": 1,
      "pipe_ElaNet": 1,
      "g_NB": 1,
      "ppl": 1,
      "kneighb": 1,
      "pipe_1": 1,
      "pipe_3": 1,
      "pipe_4": 1,
      "lgb1": 1,
      "lgb2": 1,
      "lgb3": 1,
      "pipe_GBR": 1,
      "pipe_XGB": 1,
      "pipe_LGBM": 1,
      "pipelines[pipe_index]": 1,
      "RandomForestRegressor(n_estimators=100, criterion='mse', min_impurity_decrease=0.001, n_jobs=-1, random_state=RANDOM_STATE)": 1,
      "MLPClassifier(max_iter=2500)": 1,
      "xgc": 1,
      "optimal_clf": 1,
      "forest_tune_pipeline": 1,
      "tree_tune_pipeline": 1,
      "xgb_tune_pipeline": 1,
      "lgb_tune_pipeline": 1,
      "bb_xgb": 1,
      "XGBClassifier(random_state=0, objective='multi:softprob')": 1,
      "logit_pipline": 1,
      "pipe_rfc": 1,
      "pipe_etc": 1,
      "pipe_xgb": 1,
      "xgboost.XGBRegressor(**ind_params)": 1,
      "lgb_scaled": 1,
      "logistic_regression": 1,
      "xg2": 1,
      "rand_clf": 1,
      "eclf": 1,
      "grid_pipeline": 1,
      "LinearDiscriminantAnalysis()": 1,
      "Pipeline([('min_max_scaler', MinMaxScaler()), ('knn', KNeighborsClassifier())])": 1,
      "AdaBoostClassifier(random_state=seed)": 1,
      "GradientBoostingClassifier(warm_start=True, random_state=seed)": 1,
      "best_estimator_2": 1,
      "estimator_4": 1,
      "estimator_lambda": 1,
      "LogisticRegression(random_state=42)": 1,
      "SVC(random_state=42)": 1,
      "mixed_pipe": 1,
      "Knno": 1,
      "RandomForestRegressor(random_state=0)": 1,
      "model_reg": 1,
      "XGBRegressor(**ind_params)": 1,
      "gbm_CC": 1,
      "gbm_F": 1,
      "lgb()": 1,
      "xgb.XGBClassifier(objective='binary:logistic', seed=42, subsample=0.9, colsample_bytree=0.5)": 1,
      "xgb.XGBClassifier(objective='multi:softprob', eval_metric=['mlogloss'], seed=42, use_label_encoder=False, colsample_bytree=0.5, subsample=0.9)": 1,
      "knn_classifier": 1,
      "base_resnet": 1,
      "classifier_RF": 1,
      "en": 1,
      "cat": 1,
      "clf_lr": 1,
      "gbr_tuned": 1,
      "logreg0": 1,
      "lass0": 1,
      "lgbm_model": 1,
      "lr_boost": 1,
      "lr_lassocv_boost": 1,
      "lr_ridgecv_boost": 1,
      "lr_elastic_netcv_boost": 1,
      "knn_boost": 1,
      "dtr_bagging": 1,
      "etr": 1,
      "lgbpipe": 1,
      "ridgepipe": 1,
      "model_lassoreg": 1,
      "model_ridgereg": 1,
      "model_elasticnetreg": 1,
      "model_kernelridgereg": 1,
      "algorithms['Neural Network']": 1,
      "algorithms['Support Vector Machine']": 1,
      "algorithms['K Neighbors']": 1,
      "algorithms['Xgboost']": 1,
      "rfc()": 1,
      "Lasso(random_state=1)": 1,
      "ElasticNet(random_state=1)": 1,
      "RandomForestRegressor(random_state=1)": 1,
      "GradientBoostingRegressor(random_state=1)": 1,
      "LGBMRegressor(verbose_eval=False, random_state=1)": 1,
      "kn_rand_grid": 1,
      "model_knn": 1,
      "XGBClassifier(random_state=my_randome_state, objective='multi:softprob')": 1,
      "pipeline_svm": 1,
      "naive": 1,
      "unscaled_tree_pipe": 1,
      "unscaled_rf_pipe": 1,
      "nn_clf": 1,
      "logregr": 1,
      "clf_pipeline": 1,
      "rf_classifier": 1,
      "XGBClassifier(random_state=1, objective='multi:softprob')": 1,
      "estimator1": 1,
      "model_cas_tune": 1,
      "model_reg_tune": 1,
      "LassoReg": 1,
      "RidgeReg": 1,
      "first_knn": 1,
      "rd_cv": 1,
      "la_cv": 1,
      "self.svm": 1,
      "self.rf_model": 1,
      "self.lgb_model": 1,
      "LogisticRegression(max_iter=10, class_weight='balanced')": 1,
      "RF_model": 1,
      "linear_model": 1,
      "neigh": 1,
      "xgb_ft": 1,
      "svm_gs": 1,
      "LogisticCurve(k_lower=1e-18, c_lower=0, c_upper=maximum * 0.5)": 1,
      "rf_optimize": 1,
      "li_reg": 1,
      "multinomial_nb_bow": 1,
      "self.feature_selector.estimator_": 1,
      "regs[i]": 1,
      "classifiers": 1,
      "SVC(kernel='linear')": 1,
      "final_model": 1,
      "rf_e": 1,
      "rf_mx": 1,
      "rf_sl": 1,
      "logReg": 1,
      "xgb.XGBClassifier(learning_rate=0.1, n_estimators=50, gamma=0, subsample=0.9, colsample_bytree=0.6, objective='binary:logistic', nthread=-1, scale_pos_weight=1, reg_alpha=0, reg_lambda=1, seed=42)": 1,
      "xgb.XGBClassifier(learning_rate=0.1, n_estimators=50, min_child_weight=best_params_1['min_child_weight'], max_depth=best_params_1['max_depth'], subsample=0.9, colsample_bytree=0.6, objective='binary:logistic', nthread=-1, scale_pos_weight=1, reg_alpha=0, reg_lambda=1, seed=42)": 1,
      "xgb.XGBClassifier(learning_rate=0.1, n_estimators=50, gamma=best_params_2['gamma'], min_child_weight=best_params_1['min_child_weight'], max_depth=best_params_1['max_depth'], objective='binary:logistic', nthread=-1, scale_pos_weight=1, reg_alpha=0, reg_lambda=1, seed=42)": 1,
      "xgb.XGBClassifier(learning_rate=0.1, n_estimators=50, gamma=best_params_2['gamma'], min_child_weight=best_params_1['min_child_weight'], max_depth=best_params_1['max_depth'], subsample=best_params_3['subsample'], colsample_bytree=best_params_3['colsample_bytree'], objective='binary:logistic', nthread=-1, scale_pos_weight=1, reg_lambda=1, seed=42)": 1,
      "xgb.XGBClassifier(learning_rate=0.1, n_estimators=50, gamma=best_params_2['gamma'], min_child_weight=best_params_1['min_child_weight'], max_depth=best_params_1['max_depth'], subsample=best_params_3['subsample'], colsample_bytree=best_params_3['colsample_bytree'], objective='binary:logistic', nthread=-1, scale_pos_weight=1, reg_alpha=best_params_4['reg_alpha'], seed=42)": 1,
      "clf_linear_svc_grid": 1,
      "clf_logistic_regression_grid": 1,
      "clf_extra_trees_grid": 1,
      "clf_random_forest": 1,
      "reduc_estimator": 1,
      "pipe_svc": 1,
      "model_lgb": 1,
      "model[label]['estimator']": 1,
      "SVC(kernel='rbf', random_state=42)": 1,
      "svm.SVC(kernel='rbf')": 1,
      "lr_clf": 1,
      "model_lgbm": 1,
      "model_GB": 1,
      "XGBClassifier(warm_start=True)": 1,
      "modelo": 1,
      "et": 1,
      "scl": 1,
      "SVC_clf": 1,
      "GradientBoostingRegressor(loss='huber')": 1,
      "classifier_CNN": 1,
      "log_model": 1,
      "self.model": 1,
      "lr_model": 1,
      "svm_grid_search": 1,
      "rf_regressor": 1,
      "LGBMClassifier(random_state=42)": 1,
      "model_Lasso": 1,
      "ETR": 1,
      "forest_class": 1,
      "HistGradientBoostingRegressor()": 1,
      "ridge_regressor": 1,
      "md_KNN": 1,
      "gbc": 1,
      "self.clf": 1,
      "rg4": 1,
      "RidgeClassifier()": 1,
      "C": 1,
      "enet": 1,
      "pipe_adb": 1,
      "pipe_bgr": 1,
      "pipe_grad_boost": 1,
      "tr": 1,
      "boost": 1,
      "model_kernal": 1,
      "SVC(gamma='scale', kernel='poly')": 1,
      "tree_classification": 1,
      "BellModel()": 1,
      "PolynomialRidgeRegression()": 1,
      "PolynomialSVRRegression()": 1,
      "gauss": 1,
      "bernoulli": 1,
      "pipe_log_reg": 1,
      "pipe_rf": 1,
      "pipe_5": 1,
      "pipe_sgd": 1,
      "pipe_bnb": 1,
      "prep_pipeline": 1,
      "xgbm": 1,
      "classifiers[idx]": 1,
      "elastic": 1,
      "unscaled_decision_pipe": 1,
      "unscaled_randomforest_pipe": 1,
      "lr_pipe": 1,
      "rf_pipe": 1,
      "xgd_pipe": 1,
      "rfcl": 1,
      "clfLR": 1,
      "GradientBoostingClassifier(learning_rate=0.01, n_estimators=1000, max_features='sqrt', random_state=1)": 1,
      "linear_model.Lasso()": 1,
      "pipeline_rf": 1,
      "gbm3": 1,
      "XGBClassifier(learning_rate=0.1, n_estimators=150, max_depth=5, min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8, objective='binary:logistic', nthread=4, scale_pos_weight=3, seed=27)": 1,
      "rr": 1,
      "lda": 1,
      "XGBRegressor_model": 1,
      "voting_clf_soft": 1,
      "SVR(kernel='linear')": 1,
      "LinearSVC(multi_class='ovr')": 1,
      "SVC(kernel='rbf', decision_function_shape='ovr')": 1,
      "RandomForestClassifier(n_jobs=-1)": 1,
      "xgb_baseline": 1,
      "xgb_grid_1": 1,
      "xgb_grid_2": 1,
      "xgb_grid_3": 1,
      "rn_regressor": 1,
      "Ridge(max_iter=1000)": 1,
      "rid_reg": 1,
      "pipe_svm": 1,
      "RandomForestClassifier(random_state=12, n_jobs=-1)": 1,
      "LogisticRegression(random_state=12, solver='liblinear')": 1,
      "RandomForestClassifier(random_state=12, n_jobs=6)": 1,
      "pipeline_logreg": 1,
      "gbr1": 1,
      "gbr2": 1,
      "gbr3": 1,
      "lreg": 1,
      "cl3": 1,
      "clf_C": 1,
      "treeRegressor": 1,
      "forestRegressor": 1,
      "extraRegressor": 1,
      "adaRegressor": 1,
      "modelXGB": 1,
      "modellgbm": 1,
      "MNBclf": 1,
      "select_classifier": 1,
      "GradientBoostingClassifier(n_estimators=90, learning_rate=0.1, min_samples_leaf=50, max_features='sqrt', subsample=0.8, random_state=10)": 1,
      "GradientBoostingClassifier(learning_rate=0.1, max_depth=8, min_samples_split=1000, max_features='sqrt', subsample=0.8, random_state=10)": 1,
      "GradientBoostingClassifier(n_estimators=90, learning_rate=0.1, max_depth=8, min_samples_split=1000, max_features=5, min_samples_leaf=80, random_state=10)": 1,
      "ABC": 1,
      "xgb_c": 1,
      "pipeline_without_svd": 1,
      "pipeline_with_svd": 1,
      "rfr_pipeline": 1,
      "lasreg": 1,
      "GBclf": 1,
      "tree_clf": 1,
      "lgb_train": 1,
      "gbm_tune1": 1,
      "gbm_tune2": 1,
      "randomforest_model": 1,
      "tune_rfmodel_colley": 1,
      "tune_knnmodel_colley": 1,
      "tune_lrmodel_colley": 1,
      "tune_rfmodel_all": 1,
      "tune_knnmodel_all": 1,
      "tune_lrmodel_all": 1,
      "sample_train_pipeline": 1,
      "ridge_reg": 1,
      "clf_cat": 1,
      "lgb.LGBMRegressor(random_state=42)": 1,
      "RandomForestClassifier(n_estimators=45, random_state=42, max_depth=11)": 1,
      "logregModel": 1,
      "rfc_2": 1,
      "logr": 1,
      "elnet": 1,
      "svc_clf": 1,
      "rf_grid": 1,
      "classifier()": 1,
      "svc_pipe": 1,
      "ada_pipe": 1,
      "sclf": 1,
      "regr_XGB": 1,
      "lr_pca": 1,
      "rf_pca": 1,
      "lr_sne": 1,
      "rf_sne": 1
    },
    "sklearn.ensemble._voting.VotingClassifier.__init__.estimators": {
      "estimators": 45,
      "[('lr', sig_clf1), ('svc', sig_clf2), ('rf', sig_clf3)]": 14,
      "vote_est": 14,
      "models": 8,
      "classifiers": 5,
      "[('dt', best_estimators[0]), ('rfc', best_estimators[2]), ('lr', best_estimators[3])]": 5,
      "[('lr', clf1), ('rf', clf2), ('gnb', clf3)]": 5,
      "clfs": 5,
      "[('lr', clflog), ('rf', clfrf), ('gnb', clfgn), ('svc', clfsvc), ('knn', clfknn)]": 5,
      "[('KNN', KNN), ('NB', NAIVE), ('SVM', SVM), ('DT', DT), ('LR', LR), ('RF', RF)]": 4,
      "[('knn', best_knn), ('rf', best_rf), ('svc', best_svc)]": 4,
      "[('clf1', LogisticRegression(C=10, dual=False)), ('clf2', SVC(C=100, gamma=1, kernel='rbf', probability=True))]": 3,
      "[('KNN', KNN), ('NB', NAIVE), ('SVM', SVM), ('DT', DT), ('LR', LR), ('RF', RF), ('NN', NN)]": 3,
      "voting_estimators": 3,
      "[('lr', model1), ('dt', model2)]": 2,
      "[('KNN', KNeighborsClassifier(n_neighbors=10)), ('RBF', svm.SVC(probability=True, kernel='rbf', C=0.5, gamma=0.1)), ('RFor', RandomForestClassifier(n_estimators=500, random_state=0)), ('LR', LogisticRegression(C=0.05)), ('DT', DecisionTreeClassifier(random_state=0)), ('NB', GaussianNB()), ('svm', svm.SVC(kernel='linear', probability=True))]": 2,
      "[rf, svc, knn]": 2,
      "[('lr', clf1), ('rf', clf2), ('dt', clf3)]": 2,
      "[('lr', lr), ('knn', knn), ('rf', rf), ('gnb', gnb), ('svc', svc)]": 2,
      "[('knn', best_knn), ('rf', best_rf), ('svc', best_svc), ('lr', best_lr)]": 2,
      "[('rf1', rf1), ('rf2', rf2), ('gbc', gbc), ('xgb', xgb)]": 2,
      "[('mnb', mnb), ('knn', knn), ('rfc', rfc), ('gbc', gbc), ('abc', abc)]": 2,
      "[('mnb', mnb), ('rfc', rfc), ('gbc', gbc)]": 2,
      "vc_estimators.items()": 2,
      "select(list(zip([c.__class__.__name__ for c in classifiers], best_estimators)), 1, 3, 4)": 2,
      "select(list(zip([c.__class__.__name__ for c in classifiers], best_estimators)), 1, 3, 4, 7)": 2,
      "list(zip([c.__class__.__name__ for c in classifiers], best_estimators))": 2,
      "list(zip([c.__class__.__name__ for c in classifiers][:-1], best_estimators[:-1]))": 2,
      "[(clf_name, clf['best_estimator']) for (clf_name, clf) in clfs.items()]": 2,
      "[('clf1', LogisticRegression(random_state=42)), ('clf2', SVC(kernel='linear', random_state=42, probability=True)), ('clf3', RandomForestClassifier(n_estimators=600, random_state=42))]": 2,
      "[('svc', clf1), ('knn', clf2), ('gbc', clf3), ('xgbc', clf4), ('rf', clf5)]": 2,
      "[('svcgrid', clfs['svcgrid']['clf']), ('lrgrid', clfs['lrgrid']['clf']), ('gbc', clfs['gbc']['clf'])]": 2,
      "[('svcgrid', clfs['svcgrid']['clf']), ('lrgrid', clfs['lrgrid']['clf']), ('nb', clfs['gbc']['clf'])]": 2,
      "[('rf', rf_clf2), ('xgb', xgb_clf2), ('mlp', mlp_clf2), ('cb', cb_clf2)]": 2,
      "[('log', clflog), ('dt', clfdt), ('rf', clfrf), ('gnb', clfgnb)]": 2,
      "[('rfc', rfc), ('mlp', mlp), ('svc', svc), ('lr', lr)]": 2,
      "[('lr', lr), ('knn', knn), ('DTC', DTC), ('svm', svm)]": 2,
      "named_estimators": 2,
      "[('ExTrees', clf1), ('CatBoost', clf2), ('RF', clf3)]": 2,
      "[('xgb', xgb_clf), ('lgb', lgb_clf)]": 2,
      "[('lr', l), ('sgd', n), ('lr1', o), ('rdf', p)]": 2,
      "[('dt', dt), ('rf', rf), ('svc', svc), ('lg', lg)]": 2,
      "[('lr', best_lr), ('rfc', best_rf), ('svc', best_sv), ('dtc', best_dt), ('knc', best_kn)]": 1,
      "[('gm', gradient_model), ('xg', xg_model), ('lgbm', lgbm_model)]": 1,
      "[('lr', lr), ('knn', knn), ('rf', rf)]": 1,
      "[('lr', clf1), ('xgb', clf4), ('svm', clf5), ('rf2', clf6), ('svm2', clf7)]": 1,
      "[('rf', gcv[3]), ('svc', gcv[2]), ('log_reg', gcv[0]), ('knn', gcv[1])]": 1,
      "[('dt', dt_classifier), ('rf', rf_classifier), ('xgb', xg_classifier), ('lgbm', lg_classifier)]": 1,
      "[i for i in zip(['svc' + str(i) for i in range(0, 10)], modelsSVC)]": 1,
      "[('lda', LDA_best), ('gbc', GBC_best), ('mlp', MLP_best), ('lrc', LRC_best)]": 1,
      "[('LR', log_reg1), ('CRF', calibrated_clf1), ('GNB', gnb1)]": 1,
      "[('LR', log_reg), ('CRF', calibrated_clf), ('GNB', gnb)]": 1,
      "[('lr', Pipe_lr), ('xgb', pipe_xgb)]": 1,
      "[('RF', RandomForestModel2), ('LGBM', LGBMModel2), ('XGB', XGBModel2), ('ADA', AdaBoostModel2)]": 1,
      "[('clf1', LogisticRegression(C=10, dual=False)), ('clf2', SVC(C=100, gamma=1, kernel='rbf', probability=True)), ('clf', RandomForestClassifier(n_jobs=-1, n_estimators=30, min_samples_leaf=3, max_features=0.7, oob_score=True))]": 1,
      "[('dt', tree_clf), ('svc', poly_kernel_svm_clf)]": 1,
      "[('ext', clf_ext), ('lgbm', clf_lgbm)]": 1,
      "[('knn', cl1), ('rfc', cl2), ('svm', cl3)]": 1,
      "[('lr', log_clf), ('nb', nb_clf), ('lsv', lsv_clf)]": 1,
      "[('dt', dt), ('knn', knn), ('gnb', gnb)]": 1,
      "[('cat', cat_model), ('lgb', lgb_model), ('xgd', xgd_model)]": 1,
      "[('lr', clf1), ('LinearSVC', clf2), ('SGD', clf3)]": 1,
      "[('lr', GradientBoostingClassifier()), ('rf', AdaBoostClassifier()), ('xgb', XGBClassifier())]": 1,
      "[('hgbc', hgbc), ('mlp', mlp), ('abc', abc)]": 1,
      "[('log_clf', LogisticRegression(penalty='l2', fit_intercept=False, C=0.0001, verbose=False, max_iter=1000, solver='lbfgs')), ('svm_clf', SVC(probability=True)), ('dt_clf', DecisionTreeClassifier(random_state=666))]": 1,
      "[('clf1', ovrMLP), ('clf2', ovrETC), ('clf3', ovrLSVC), ('clf4', ovrLR)]": 1,
      "[('ETC', ETC), ('RFC', RFC), ('DTC', DTC), ('XGB', XGB)]": 1,
      "[('lr', log_selector), ('rf', rand_clf), ('ex', extra_clf), ('sv', svm_clf)]": 1,
      "[('lr', lr_clf), ('rf', rf_clf), ('adb', adb_clf), ('gdb', gdb_clf), ('etc', et_clf), ('svc', svc_clf), ('xgb', xgb_clf), ('lgbm', lgb_clf)]": 1,
      "[('xgb', xgb_cfl), ('gb', gb_cfl), ('lgb', lgb_cfl)]": 1,
      "[('id3', id3), ('dt', dt), ('rf', rf_clf), ('xgb', xgb_clf), ('lgb', lgb_clf), ('nb', gnb)]": 1,
      "[('rf', clf5), ('gnb', clf6), ('lgb', clf1)]": 1,
      "list(zip([c.__class__.__name__ for c in classifiers], classifiers))": 1,
      "[('gb', bost), ('rf', rnd)]": 1,
      "modelsNames": 1,
      "[('xgbclassifier', p1), ('randomforestclassifier', p2), ('extratreesclassifier', p3)]": 1,
      "[('lr', clf1), ('rf', clf2), ('gb', clf4)]": 1,
      "[('KNN', KNN), ('NB', NAIVE), ('SVM', SVM), ('DR', DR), ('LR', LR), ('RFC', RFC)]": 1,
      "[('rf', rf_clf), ('svc', svc), ('mlp', mlp)]": 1,
      "[('bag', clf_bag), ('ada', clf_ada), ('GBCT', clf_GBCT)]": 1,
      "[('svc_best', svc_best), ('rf_best', rf_best), ('gbrc_best', gbrc_best)]": 1,
      "[('random forest', rfc), ('XG Boost', xgboost), ('catboost', catboost)]": 1,
      "[('LogisticRegresion', LR_pipe), ('BernoulliNB', BNB_pipe), ('DecisionTree', DT_pipe), ('LinearSVC', SVC_pipe)]": 1,
      "[('DecisionTree', DT_pipe), ('LogisticRegression', LR_pipe)]": 1,
      "[('DecisionTree', DT_pipe), ('LinearSVC', SVC_pipe)]": 1,
      "[('BernoulliNB', BNB_pipe), ('DecisionTree', DT_pipe)]": 1,
      "clsfs": 1,
      "[('rfc', RFC2), ('extc', et2), ('lgb', lgb)]": 1,
      "[('et', et), ('rf', rf), ('bc', bc), ('ab', ab)]": 1,
      "[('lr', log_reg), ('dt', tree_clf), ('xgbc', xgb_clf), ('rf', rf_clf), ('abc', ada_clf)]": 1,
      "[('bag', model), ('xgb', xgbc)]": 1,
      "[('rf', rf), ('xgb', xgb), ('svm', svm), ('adaboost', ada)]": 1,
      "[('LR', LR), ('NB', NB)]": 1,
      "[('rfc', rfc), ('cat_model', cat_model), ('xgb_model', xgb_model)]": 1,
      "[('4', classifiers[4]), ('3', classifiers[3]), ('5', classifiers[5])]": 1,
      "[('rf', rf_best), ('bag', bag_best)]": 1,
      "[('bagging', bagging), ('boosting', boosting)]": 1,
      "[('rf', clf1), ('gnb', clf2), ('gbc', clf)]": 1,
      "[('model_GaussianNB', classifier), ('model_DT', model_DT), ('kmeans', kmeans)]": 1,
      "[('lr', lr_clf), ('xgb', xgb_clf), ('lgbm', lgbm_clf), ('gbf', gbf_clf), ('mnb', mnb_clf), ('dtc', dtc_clf), ('rf', rnd_clf), ('gnb', gnb_clf)]": 1,
      "[('rfc', RFC_best), ('extc', ExtC_best), ('lgbm', lgbm_best), ('xgb', XGBC_best)]": 1,
      "[('rfc', clf1), ('gbc', clf2)]": 1,
      "[(str(score), estimator) for (score, estimator) in best_estimators]": 1,
      "[('lsvc', lsvcClassifier), ('lr', lrClassifier)]": 1,
      "[('model_1', model_1), ('model_2', model_2)]": 1,
      "[('knn_best', knn_best), ('rf_best', rf_best)]": 1,
      "[('xgb', xgb_pipline), ('logit', logit_pipline)]": 1,
      "[('rfc', RandomForestClassifier(n_estimators=100, max_depth=25)), ('etc', ExtraTreesClassifier(n_estimators=100, max_depth=25)), ('xgb', XGBClassifier(n_estimators=100, max_depth=25))]": 1,
      "[('rfc', RandomForestClassifier(n_estimators=100, max_depth=25)), ('etc', model_etc), ('xgb', model_xgb)]": 1,
      "[('rf', rf), ('et', et), ('lr', log_reg), ('xgb', xgb)]": 1,
      "[('RFC', clf1), ('logit', clf2), ('Bag', clf3), ('ETC', clf4), ('KNN', clf6)]": 1,
      "[('lr', a), ('k1', k1), ('lg', b)]": 1,
      "[('lr', a), ('k1', k1), ('lg', r1)]": 1,
      "[('dt', d_tree), ('rfc', rf), ('lr', logreg)]": 1,
      "[('lr', lr_clf), ('svc', svc_clf), ('gbc', gbc_clf)]": 1,
      "[('LR', Logreg_classifier), ('RF', rf_classifier), ('SVML', svm_classifier)]": 1,
      "ests": 1,
      "[('NB', model_2), ('LR', model_3), ('LIN', model_1)]": 1,
      "[('svm', svm_classifier_best), ('rf', rf_classifier_best)]": 1,
      "[('lgbmc', lgbmc_clf), ('ada', ada_clf), ('boost', xgb_clf)]": 1,
      "clf_list": 1,
      "est_vote": 1,
      "[('Random Forest', random_forest_mod), ('KNN Classifier', knn_mod)]": 1,
      "[('lr', log_clf), ('rf', rand_clf), ('ex', extra_clf), ('sv', svm_clf)]": 1,
      "[('lr', log_reg), ('rf', clf)]": 1,
      "[('sgd', sgd_clf), ('rfc', rf_clf), ('knn', knn_clf), ('svc', svm_clf)]": 1,
      "[('rfc', rf_clf), ('knn', knn_clf), ('svc', svm_clf)]": 1,
      "[('lr', lr), ('rf', rf), ('gnb', gclf)]": 1,
      "[('xgboost', xgboost_model), ('model_lgmb_100', model_lgmb_100), ('model_lgmb_400', model_lgmb_400), ('model_lgmb_1000', model_lgmb_1000), ('model_lgmb_1500', model_lgmb_1500), ('model_lgmb_2000', model_lgmb_2000), ('xboost', xgboost_model)]": 1,
      "[('lr', LogisticRegression(random_state=42)), ('svc', SVC(kernel='linear', random_state=42, probability=True)), ('rfc', RandomForestClassifier(n_estimators=500, random_state=42))]": 1,
      "[('lr', clf1), ('rf', clf2)]": 1,
      "[('clf1', clf1_cv), ('clf2', OvRSVC)]": 1,
      "[('lr', lr), ('knn', knn), ('rf', rf), ('gnb', gnb), ('svc', svc), ('xgb', xgb)]": 1,
      "[('XGBoost', xgb_b.best_estimator_), ('Random Forest', rf_b.best_estimator_), ('Gradient boosting', gb_b.best_estimator_)]": 1,
      "[('xgb', clf_xgb), ('svc', svc)]": 1,
      "[('rf', rf_best), ('bag', bag_best), ('gbc', gbc_best), ('lr', lr_best), ('svc', svc_best)]": 1,
      "ensemble": 1,
      "[('Support Vector Classifier', SVC(C=1, gamma=1, kernel='linear')), ('Gaussian Naive Bayes', GaussianNB())]": 1,
      "[('lr', clf1), ('rf', clf2), ('gb', clf3)]": 1,
      "[('svm', clf), ('extra', ex), ('rf', rf)]": 1,
      "[('rfc', RFC_best), ('extc', ExtC_best), ('adac', ada_best), ('gbc', GBC_best)]": 1,
      "[('random_forest', random), ('OnevsRest', ovr_classifier), ('Kernel_SVM', svm_rbf)]": 1,
      "[('clf1', RandomForestClassifier(n_estimators=50, random_state=42)), ('clf2', LogisticRegression(random_state=42)), ('clf3', SVC(kernel='linear', random_state=42, probability=True))]": 1,
      "[('lgbm', pipe_lgbm), ('cat', pipe_cat), ('xgb', pipe_xgb), ('bnb', pipe_bnb), ('lr', pipe_lr), ('sgd', pipe_sgd), ('rf', pipe_rf)]": 1,
      "[('lgbm', lgbm), ('bnb', bnb), ('cat', cat)]": 1,
      "ets": 1,
      "[('NB', nb_clf), ('SVM', svm_clf), ('KNN', knn_clf), ('LogReg', logReg_clf)]": 1,
      "[('lr', linear_model.LogisticRegression(random_state=101, C=0.04)), ('rf', ensemble.RandomForestClassifier(max_depth=10)), ('nb', naive_bayes.MultinomialNB())]": 1,
      "estms": 1,
      "[('rf', rf_model), ('lr', lr_model), ('nb', nb_model), ('dt', dt_model), ('ab', ab_model), ('xgb', xgb_model)]": 1,
      "[('lr', pipe1), ('rf', pipe2), ('gnb', pipe3)]": 1,
      "[('gnb', GaussianNB()), ('xgb', xgb.XGBClassifier(max_dept=100, n_estimators=15, learning_rate=0.05, colsample_bytree=0.5, gamma=0.01, reg_alpha=4, objective='binary:logistic')), ('knn', KNeighborsClassifier(n_neighbors=500)), ('rf', RandomForestClassifier(max_depth=3, n_estimators=100)), ('lr', LogisticRegression()), ('dt', DecisionTreeClassifier(max_depth=3, criterion='entropy')), ('adb', AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3, criterion='entropy'), learning_rate=0.05)), ('gb', GradientBoostingClassifier(max_depth=3, learning_rate=0.05, n_estimators=100)), ('qda', QuadraticDiscriminantAnalysis()), ('lda', LinearDiscriminantAnalysis())]": 1,
      "[('lr', LR_best), ('lda', LDA_best), ('adac', ada_best), ('rfc', RFC_best), ('gbc', GBC_best)]": 1,
      "[('dt', clf_1_1), ('rf', clf_1_2), ('et', clf_1_3)]": 1,
      "[('dt', clf_2_1), ('rf', clf_2_2), ('et', clf_2_3)]": 1,
      "[('dt', clf_3_1), ('rf', clf_3_2), ('et', clf_3_3)]": 1,
      "[('rf', model_rf), ('gbm', model_gbm), ('nn', model_nn)]": 1,
      "[('rf', final_rf), ('lr', lr_model), ('nb', final_model)]": 1,
      "[('ab', clf1), ('etc', clf2), ('xgb', clf3), ('gbc', clf4)]": 1,
      "[('LR', LR), ('LGBM', LG), ('EXT', ext), ('GB', gb), ('NN', keras_clf)]": 1,
      "[('rf1', rf1), ('rf2', rf2), ('rf3', rf3), ('rf4', rf4), ('et1', et1), ('et2', et2), ('lgbm1', lgbm1), ('gb1', gb1), ('adboost1', adboost1), ('logisticR1', logisticR1), ('XGB1', XGB1)]": 1,
      "[('lr', LR_best), ('mlp', MLP_best), ('xgb', XGB_Best), ('rfc', RFC_best), ('extc', ExtC_best), ('svc', SVMC_best), ('adac', ada_best), ('gbc', GBC_best)]": 1,
      "[('lr', lr), ('nb', nb), ('rf', rf)]": 1,
      "vote_test": 1,
      "[('extra', ExtraTreesClassifier(max_depth=85, n_estimators=65, max_features=33)), ('rf', RandomForestClassifier(n_estimators=100, max_depth=70, max_features=9))]": 1,
      "[('rf', rf), ('ab', ab), ('xg', xg)]": 1,
      "clfs.items()": 1
    },
    "sklearn.ensemble._voting.VotingClassifier.__init__.voting": {
      "'soft'": 173,
      "'hard'": 124,
      "voting": 5,
      "vote_type": 2
    },
    "sklearn.ensemble._voting.VotingClassifier.__init__.n_jobs": {
      "None": 263,
      "-1": 35,
      "4": 4,
      "1": 1,
      "10": 1
    },
    "sklearn.ensemble._voting.VotingClassifier.fit.X": {
      "X_train": 107,
      "X": 27,
      "x_train": 18,
      "train_x_onehotCoding": 14,
      "train_x": 10,
      "train_X": 8,
      "X_train_scaled": 8,
      "xtrain": 4,
      "df_train_data": 2,
      "train_data": 2,
      "X_v1": 2,
      "ttextdataemx_train": 2,
      "trainfeature": 2,
      "tsiftdatax_train": 2,
      "x_nb": 2,
      "X_train_sc": 1,
      "xTrain": 1,
      "TRAIN[ind_train]": 1,
      "train[feature_names]": 1,
      "xtrain_tfidf": 1,
      "X.toarray()": 1,
      "train_data[train_data.columns[:-1]]": 1,
      "train_vectorized": 1,
      "Xn_train": 1,
      "x": 1,
      "selected_x_train": 1,
      "X_cv": 1,
      "train": 1,
      "X_train_val": 1,
      "predictors_tr": 1,
      "X_final": 1,
      "X_train_std": 1,
      "X_preprocessed": 1,
      "X_training": 1,
      "variables_train": 1,
      "X_train_tfidf1": 1,
      "data_df": 1,
      "rfe_feature3": 1,
      "titanic_prepared": 1,
      "X[:]": 1,
      "X2f": 1,
      "xtrain_stra": 1,
      "X_train_boruta": 1,
      "self.x_train": 1,
      "X_train_scaled_pca": 1,
      "selected_data_train": 1,
      "Xt": 1,
      "X_train.drop(et_drop_cols, axis=1)": 1,
      "train_feature_vectors": 1,
      "tr_X": 1,
      "train_df[num_cols]": 1,
      "X_train_prepared_small": 1,
      "df_train_final.iloc[:, final_selected_features]": 1,
      "X_val": 1,
      "X1": 1,
      "X3": 1,
      "X5": 1,
      "Data": 1,
      "data_x": 1,
      "X_train_array": 1,
      "X_data": 1,
      "X_train_new": 1,
      "csr_matrix(df_train.iloc[train_index].fillna(0)).tocsr(copy=False)": 1,
      "df_train.iloc[train_index]": 1
    },
    "sklearn.ensemble._voting.VotingClassifier.fit.y": {
      "y_train": 128,
      "train_y": 26,
      "y": 24,
      "Y_train": 16,
      "Y": 8,
      "train_Y": 5,
      "yTrain": 2,
      "target": 2,
      "df_train_results": 2,
      "train_label": 2,
      "y_v1": 2,
      "ttextdataemy_train": 2,
      "ttexty_train": 2,
      "tsiftdatay_train": 2,
      "ztrain": 2,
      "train_y.values.ravel()": 2,
      "np.array(y_target.iloc[train_index])": 2,
      "target[ind_train]": 1,
      "train_data['target']": 1,
      "training_set['target']": 1,
      "ytrain": 1,
      "y_train_val": 1,
      "targets_tr": 1,
      "lb.inverse_transform(y_train)": 1,
      "lb.inverse_transform(y)": 1,
      "y_training": 1,
      "labels_train": 1,
      "y_inp": 1,
      "train.iloc[:, 1]": 1,
      "titanic_labels": 1,
      "y[:]": 1,
      "yf": 1,
      "y_train.ravel()": 1,
      "ytrain_stra": 1,
      "self.y_train": 1,
      "Yt": 1,
      "tr_y_tr": 1,
      "le.transform(train_df[target_col])": 1,
      "y_train_small": 1,
      "y_train_final": 1,
      "y_val": 1,
      "Y1": 1,
      "Y3": 1,
      "Y5": 1,
      "labels": 1,
      "data_y": 1,
      "y_data": 1
    },
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.bootstrap": {
      "True": 5124,
      "False": 42,
      "Best_Parameter['bootstrap']": 4,
      "params['bootstrap']": 2,
      "bootstrap": 2,
      "'False'": 1,
      "best_params['bootstrap']": 1,
      "parameters['bootstrap']": 1,
      "rf_bp['bootstrap']": 1,
      "int(population[i][4])": 1,
      "rf_random.best_params_['bootstrap']": 1
    },
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.max_features": {
      "'auto'": 4644,
      "'sqrt'": 99,
      "0.5": 81,
      "'log2'": 33,
      "max_features": 22,
      "0.2": 19,
      "20": 19,
      "g['mf']": 17,
      "None": 16,
      "5": 14,
      "2": 13,
      "6": 13,
      "10": 11,
      "1": 10,
      "3": 9,
      "17": 9,
      "0.3": 8,
      "30": 8,
      "0.7": 7,
      "num_features": 7,
      "64": 7,
      "50": 6,
      "min(max_features, 0.999)": 6,
      "8": 5,
      "val": 5,
      "Best_Parameter['max_features']": 4,
      "trial.suggest_categorical('max_features', ['sqrt', 'log2'])": 4,
      "25": 4,
      "0.6": 4,
      "9": 4,
      "40": 3,
      "4": 3,
      "1000": 3,
      "0.8": 2,
      "n_features": 2,
      "19": 2,
      "41": 2,
      "100": 2,
      "study.best_params['max_features']": 2,
      "12": 2,
      "38": 2,
      "grid.best_params_['max_features']": 2,
      "0.8500000000000001": 2,
      "15": 2,
      "21": 2,
      "42": 2,
      "m": 2,
      "trial.suggest_int('max_features', 5, 15)": 1,
      "split_pct_features": 1,
      "168": 1,
      "1.0": 1,
      "True": 1,
      "params['max_features']": 1,
      "m_f": 1,
      "best_params['max_features']": 1,
      "34": 1,
      "80": 1,
      "0.8963320961378558": 1,
      "70": 1,
      "num": 1,
      "str(params['max_features'])": 1,
      "parameters['max_features']": 1,
      "0.4": 1,
      "min(params['max_features'], 0.999)": 1,
      "x": 1,
      "forest.best_params_['max_features']": 1,
      "rf_random.best_params_['max_features']": 1,
      "int(round(max_features))": 1,
      "300": 1,
      "space['max_features']": 1,
      "best['max_features']": 1,
      "0.7859074745773753": 1,
      "MAX_FEAT": 1,
      "68": 1,
      "60": 1,
      "0.34844887659754137": 1,
      "11": 1,
      "max_feature": 1,
      "43": 1,
      "45": 1,
      "47": 1,
      "13": 1
    },
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.min_samples_leaf": {
      "1": 4736,
      "2": 95,
      "3": 67,
      "5": 47,
      "4": 39,
      "10": 31,
      "100": 21,
      "25": 18,
      "50": 12,
      "20": 12,
      "8": 10,
      "6": 9,
      "15": 7,
      "min_samples_leaf": 7,
      "30": 5,
      "200": 4,
      "7": 4,
      "150": 3,
      "0.005": 3,
      "125": 3,
      "trial.suggest_int('min_samples_leaf', 1, 5, 1)": 2,
      "rf_clf.best_params_['min_samples_leaf']": 2,
      "12": 2,
      "trial.suggest_float('min_samples_leaf', 0.0001, 0.1)": 2,
      "0.001": 2,
      "14": 1,
      "trial.suggest_int('min_samples_leaf', 1, 10)": 1,
      "17": 1,
      "l": 1,
      "params['min_samples_leaf']": 1,
      "best_params['min_samples_leaf']": 1,
      "24": 1,
      "num": 1,
      "1000": 1,
      "9": 1,
      "parameters['min_samples_leaf']": 1,
      "rf_bp['min_samples_leaf']": 1,
      "int(round(rf_b_o.max['params']['min_samples_leaf']))": 1,
      "int(round(best['min_samples_leaf']))": 1,
      "best['min_samples_leaf']": 1,
      "int(population[i][3])": 1,
      "int(population[bestFitnessIndex][3])": 1,
      "0.1": 1,
      "300": 1,
      "75": 1,
      "int(round(min_samples_leaf))": 1,
      "int(round(10.898930640403934))": 1,
      "x": 1,
      "500": 1,
      "rf_random.best_params_['min_samples_leaf']": 1,
      "trial.suggest_int('min_samples_leaf', 5, 12)": 1,
      "800": 1,
      "40": 1,
      "leaf_size": 1,
      "parameter[0]": 1,
      "13": 1,
      "0.01865186498148891": 1,
      "0.04742472303688006": 1,
      "0.04145631437008027": 1,
      "36": 1,
      "19": 1,
      "18": 1
    },
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.min_samples_split": {
      "2": 4828,
      "5": 70,
      "10": 48,
      "4": 40,
      "1": 23,
      "3": 18,
      "20": 14,
      "min_samples": 13,
      "6": 12,
      "8": 11,
      "12": 9,
      "100": 8,
      "9": 8,
      "int(min_samples_split)": 6,
      "7": 4,
      "200": 4,
      "50": 4,
      "15": 4,
      "25": 4,
      "min_samples_split": 4,
      "250": 3,
      "30": 3,
      "0.005": 3,
      "300": 2,
      "40": 2,
      "int(params['min_samples_split'])": 2,
      "rf_clf.best_params_['min_samples_split']": 2,
      "trial.suggest_float('min_samples_split', 0.0001, 0.1)": 2,
      "41": 2,
      "19": 1,
      "trial.suggest_int('min_samples_split', 2, 10)": 1,
      "s": 1,
      "params['min_samples_split']": 1,
      "best_params['min_samples_split']": 1,
      "18": 1,
      "parameters['min_samples_split']": 1,
      "min_split": 1,
      "1.0": 1,
      "rf_bp['min_samples_split']": 1,
      "int(round(rf_b_o.max['params']['min_samples_split']))": 1,
      "int(round(best['min_samples_split']))": 1,
      "best['min_samples_split']": 1,
      "int(population[i][2])": 1,
      "int(population[bestFitnessIndex][2])": 1,
      "1000": 1,
      "int(round(min_samples_split))": 1,
      "x": 1,
      "80": 1,
      "rf_random.best_params_['min_samples_split']": 1,
      "0.1": 1,
      "0.010377003772355852": 1,
      "0.0671810090247945": 1,
      "0.0852885149102395": 1,
      "0.8": 1,
      "16": 1,
      "350": 1
    },
    "sklearn.metrics._regression.mean_squared_log_error.y_true": {
      "y_test": 72,
      "y_val": 46,
      "y_true_cases[-optim_days:]": 41,
      "A1": 39,
      "A2": 39,
      "y_true": 37,
      "y_true_fat[-optim_days:]": 36,
      "pred": 33,
      "y_true_valid['ConfirmedCases']": 25,
      "y_true_valid['Fatalities']": 25,
      "y_valid": 24,
      "y_pred": 24,
      "y_train": 20,
      "np.clip(valid_y, 0, np.inf)": 18,
      "np.clip(valid_y_fat, 0, np.inf)": 18,
      "test_pred": 15,
      "np.expm1(y_true)": 13,
      "narf.ConfirmedCases": 12,
      "groundtruth.Fatalities.values": 11,
      "y": 10,
      "Y_test": 10,
      "groundtruth.ConfirmedCases.values": 10,
      "pred.reshape(-1, 1)": 8,
      "Y_valid_1": 8,
      "Y_valid_2": 8,
      "np.exp(y_test)": 7,
      "predicted": 7,
      "cases_targ": 6,
      "fatal_targ": 6,
      "test_df[target].values": 6,
      "train_price": 5,
      "test_price": 5,
      "actual": 5,
      "y1_train": 5,
      "y2_train": 5,
      "valid_price": 5,
      "valid['price']": 5,
      "y_train_1": 5,
      "np.expm1(y_test)": 5,
      "ytrue": 5,
      "d_set[3]": 5,
      "validacao['count']": 4,
      "train.ConfirmedCases": 4,
      "model_preds": 4,
      "y_valid.iloc[:, 0]": 4,
      "y_valid.iloc[:, 1]": 4,
      "y_valid.iloc[:, 2]": 4,
      "y_test_confirmed": 4,
      "y_test_fatal": 4,
      "yTest": 4,
      "filtered_data": 3,
      "eval1['ConfirmedCases_x'].values": 3,
      "eval1['Fatalities_x'].values": 3,
      "train.ConfirmedCases[train.serd >= 64]": 3,
      "train.Fatalities[train.serd >= 64]": 3,
      "y_test_cc": 3,
      "y_test_fat": 3,
      "data.ConfirmedCases": 3,
      "df_score['ConfirmedCases_act']": 3,
      "df_score['Fatalities_act']": 3,
      "y_test_1": 3,
      "np.exp(y_train)": 3,
      "y_predict": 3,
      "targ": 3,
      "y_predTrain": 3,
      "np.exp(y_train_total) - 1": 3,
      "np.exp(y_test_total) - 1": 3,
      "test_y": 3,
      "y_trainl": 3,
      "y_validl": 3,
      "merged_eval['ConfirmedCases_x'].values": 3,
      "merged_eval['Fatalities_x'].values": 3,
      "valid['ConfirmedCases'].values": 3,
      "valid['Fatalities'].values": 3,
      "np.exp(valid['count'])": 3,
      "np.exp(y_valid)": 3,
      "test_['ConfirmedCases']": 3,
      "test_t['ConfirmedCases']": 3,
      "test_region['ConfirmedCases']": 3,
      "test_['Fatalities']": 3,
      "test_t['Fatalities']": 3,
      "test_region['Fatalities']": 3,
      "Y[test]": 3,
      "y1_test": 3,
      "y2_test": 3,
      "valid_pred": 3,
      "total_pred": 3,
      "predictions": 2,
      "np.clip(y, 0, np.inf)": 2,
      "np.clip(y_fat, 0, np.inf)": 2,
      "train.ConfirmedCases[train.serd > 70]": 2,
      "train.Fatalities[train.serd > 70]": 2,
      "Y[0]": 2,
      "cases_train": 2,
      "fat_train": 2,
      "cases_test": 2,
      "fat_test": 2,
      "np.expm1(y)": 2,
      "ytr": 2,
      "yval": 2,
      "rf_y_test['ConfirmedCases']": 2,
      "rf_y_test['Fatalities']": 2,
      "y_pred_diff_res[['cc_cumsum', 'dd_cumsum']]": 2,
      "np.exp(y_val)": 2,
      "y_data_cc[-NUMBER_OF_PUBLIC_PRED_DATES:]": 2,
      "y_data_fat[-NUMBER_OF_PUBLIC_PRED_DATES:]": 2,
      "train_y": 2,
      "np.exp(y_true)": 2,
      "np.exp(y_train_pred)": 2,
      "np.exp(y_pred)": 2,
      "y_val['Confirmed']": 2,
      "y_val['Fatalities']": 2,
      "train['ConfirmedCases']": 2,
      "YC_test": 2,
      "YD_test": 2,
      "y.values[test_index]": 2,
      "y_true_valid['Confirmed']": 2,
      "y_test + 1": 2,
      "df.loc[df['split'] == 'test', label]": 2,
      "df1": 2,
      "reg_pred": 2,
      "cas_pred": 2,
      "y_train.iloc[test_split_index]": 1,
      "t_test_2": 1,
      "t_test_1": 1,
      "t_test_3": 1,
      "y_true_scaled": 1,
      "data['unit_sales'].clip(0, 999999)": 1,
      "y_test_std": 1,
      "y_test2_std": 1,
      "test_series": 1,
      "train.ConfirmedCases[train.serd >= 71]": 1,
      "train.Fatalities[train.serd >= 71]": 1,
      "train.ConfirmedCases[train.serd > 80]": 1,
      "train.Fatalities[train.serd > 80]": 1,
      "yte_cm": 1,
      "yte_be": 1,
      "yte_no": 1,
      "X_test": 1,
      "y_vl": 1,
      "housing_df_y": 1,
      "clf_preds": 1,
      "model_preds1": 1,
      "model_preds2": 1,
      "model_preds3": 1,
      "df_filt_score['ConfirmedCases_act']": 1,
      "df_filt_score['Fatalities_act']": 1,
      "df_filt_score2['ConfirmedCases_act']": 1,
      "df_filt_score2['Fatalities_act']": 1,
      "df_filt_score3['ConfirmedCases_act']": 1,
      "df_filt_score3['Fatalities_act']": 1,
      "train_data.get_label()": 1,
      "np.exp(lgb_train.get_label())": 1,
      "train_predictions": 1,
      "test_predictions": 1,
      "[max(x, 0) for x in fit1.predict(X)]": 1,
      "[max(x, 0) for x in fit2.predict(X)]": 1,
      "y_test_2": 1,
      "y_test_3": 1,
      "y_val_lr": 1,
      "ytest": 1,
      "np.exp(val_y)": 1,
      "preds": 1,
      "labels": 1,
      "np.exp(y)": 1,
      "y_predict_cc": 1,
      "y_predict_deaths": 1,
      "df_chk[['cc_log', 'deaths_log']]": 1,
      "np.round(df_chk[['cc_log', 'deaths_log']]).astype('int')": 1,
      "test_check[['ConfirmedCases', 'Fatalities']]": 1,
      "data": 1,
      "tgt": 1,
      "Y_val": 1,
      "np.exp(y_test) - 1": 1,
      "val_y": 1,
      "y_valid_final": 1,
      "y_valid_pca": 1,
      "train_data['log_prices']": 1,
      "validation_data['log_prices']": 1,
      "np.exp(train['count'])": 1,
      "pred_test.SalePrice.values": 1,
      "test_cases": 1,
      "test_fatalities": 1,
      "y_valid1": 1,
      "y_valid2": 1,
      "train['revenue']": 1,
      "groundtruth.Confirmed.values": 1,
      "rf1_val_pred": 1,
      "y_val.loc[i]": 1,
      "act_prices": 1,
      "y_pred_train_cc": 1,
      "y_pred_test_cc": 1,
      "np.array(np.exp(Y_test) - 1)": 1,
      "prediction['count']": 1,
      "np.expm1(y_val_preds)": 1,
      "work_day_reg_pred": 1,
      "work_day_casual_pred": 1,
      "work_day['count']": 1,
      "non_work_day_reg_pred": 1,
      "non_work_day_casual_pred": 1,
      "non_work_day['count']": 1,
      "df['count']": 1,
      "y_train.iloc[:i]": 1,
      "y_sc": 1,
      "Y_valid_1[x_pred['Date'] >= '2020-03-20']": 1,
      "Y_valid_2[x_pred['Date'] >= '2020-03-20']": 1,
      "sampled_y": 1,
      "test_data['price']": 1,
      "y_trim": 1,
      "y1_vld": 1,
      "y2_vld": 1,
      "ytest1": 1,
      "y_validation": 1,
      "b1_test": 1,
      "b2_test": 1,
      "b3_test": 1,
      "test_labels": 1,
      "pr_fat": 1,
      "y_pred_lasso": 1,
      "y_train_pred": 1,
      "y_test_gam": 1,
      "y_test_gam_cc": 1,
      "cc_true": 1,
      "f_true": 1,
      "y_eval[:, 0]": 1,
      "y_eval[:, 1]": 1,
      "y_tests": 1,
      "train_pred.ConfirmedCases": 1,
      "train_pred.Fatalities": 1,
      "confirmed": 1,
      "fatali": 1,
      "confirmed_ch": 1,
      "fatal_ch": 1,
      "confirmed_ind": 1,
      "fatal_ind": 1,
      "x_pred_without_outliers": 1,
      "y_pred_without_outliers": 1,
      "model.predict(X_test)": 1,
      "et_model.predict(X_train)": 1,
      "et_model.predict(X_test)": 1,
      "xgb_trainpred": 1,
      "xgb_validpred": 1,
      "xgb_final_trainpred": 1,
      "xgb_final_validpred": 1,
      "gbr_trainpred": 1,
      "gbr_validpred": 1,
      "gbr_final_trainpred": 1,
      "gbr_final_validpred": 1,
      "adr_trainpred": 1,
      "adr_validpred": 1,
      "truth[:, 0]": 1,
      "truth[:, 1]": 1,
      "truth[:, 2]": 1,
      "x_test": 1,
      "y_val[:, 0]": 1,
      "y_val[:, 1]": 1,
      "y_val[:, 2]": 1,
      "y_data.values": 1,
      "y_train_ca": 1,
      "y_valid_ca": 1,
      "y_train_re": 1,
      "y_valid_re": 1,
      "y_test.values": 1,
      "temp_df[(temp_df.Day >= const.TEST_DAY_FROM) & (temp_df.Day <= const.TEST_DAY_TO)].ConfirmedCases": 1,
      "pred_tr": 1,
      "total_train_pred": 1,
      "abs(train_pred)": 1,
      "abs(valid_pred)": 1
    },
    "sklearn.metrics._regression.mean_squared_log_error.y_pred": {
      "y_pred": 85,
      "y_test": 63,
      "y_pred_cases[-optim_days:]": 41,
      "Y1": 39,
      "Y2": 39,
      "y_pred_fat[-optim_days:]": 36,
      "np.clip(predict_y, 0, np.inf)": 20,
      "np.clip(predict_yfat, 0, np.inf)": 20,
      "y_preds": 18,
      "y_pred_valid['ConfirmedCases']": 18,
      "y_pred_valid['Fatalities']": 18,
      "y_valid": 18,
      "pred": 16,
      "preds": 14,
      "np.expm1(y_pred)": 14,
      "y": 14,
      "predictions": 13,
      "predictions.Fatalities.values": 11,
      "predictions.ConfirmedCases.values": 10,
      "y_train": 9,
      "pre": 8,
      "y_pred_valid[:, 0]": 7,
      "y_pred_valid[:, 1]": 7,
      "y_predict": 7,
      "forecast_value": 7,
      "yvaltest": 6,
      "cases_pred": 6,
      "fatal_pred": 6,
      "valid_preds": 6,
      "te": 6,
      "y_val_c": 5,
      "train_preds": 5,
      "tar_train": 5,
      "tar_valid": 5,
      "y_train_pred": 4,
      "y1_valid": 4,
      "y2_valid": 4,
      "y_hat": 4,
      "narf.y_hat_ens": 4,
      "Y_predicted": 4,
      "y_pred_rf": 4,
      "y_test_main[t].to_numpy().reshape(-1, 1)": 4,
      "y_test_outlier[t].to_numpy().reshape(-1, 1)": 4,
      "np.exp(y_pred)": 4,
      "np.exp(pred)": 4,
      "Y_test": 4,
      "rf_pred": 4,
      "sigmoid(list(range(sum(data == 0), len(data))), M, beta, alpha)": 3,
      "eval1['ConfirmedCases_y']": 3,
      "eval1['Fatalities_y']": 3,
      "y_pred_cc": 3,
      "y_pred_fat": 3,
      "pred[:, 0]": 3,
      "df_score['ConfirmedCases_pred']": 3,
      "df_score['Fatalities_pred']": 3,
      "y_pred1": 3,
      "ypred": 3,
      "Y_test2": 3,
      "preds['ConfirmedCases']": 3,
      "preds['Fatalities']": 3,
      "previsao": 3,
      "test_['ConfirmedCases_pred']": 3,
      "test_t['ConfirmedCases_pred']": 3,
      "test_region['ConfirmedCases_pred']": 3,
      "test_['Fatalities_pred']": 3,
      "test_t['Fatalities_pred']": 3,
      "test_region['Fatalities_pred']": 3,
      "y_pred_dt_confirmed": 3,
      "y_pred_dt_fatal": 3,
      "x_pred['Predictions1']": 3,
      "x_pred['Predictions2']": 3,
      "pred_train": 3,
      "pred_test": 3,
      "registered_valid": 3,
      "casual_valid": 3,
      "y_valid_pred": 2,
      "trainpred.ConfirmedCases[(trainpred.serd > 70) & (trainpred.serd <= max(train.serd))]": 2,
      "trainpred.Fatalities[(trainpred.serd > 70) & (trainpred.serd <= max(train.serd))]": 2,
      "trainpred.ConfirmedCases[(trainpred.serd >= 64) & (trainpred.serd <= max(train.serd))]": 2,
      "trainpred.Fatalities[(trainpred.serd >= 64) & (trainpred.serd <= max(train.serd))]": 2,
      "Y_pred": 2,
      "pred_rf": 2,
      "train.wg": 2,
      "narf.wg_y": 2,
      "narf.SARIMAX": 2,
      "narf.y_hat_log_y": 2,
      "narf.y_hat_xgb_c": 2,
      "np.exp(Y_predicted)": 2,
      "np.expm1(preds)": 2,
      "cases_pred_train": 2,
      "fat_pred_train": 2,
      "cases_pred_test": 2,
      "fat_pred_test": 2,
      "pred_egb": 2,
      "y_tr_pred": 2,
      "y_val_pred": 2,
      "np.exp(preds)": 2,
      "y_val": 2,
      "rf_y_test_pred2['ConfirmedCases']": 2,
      "rf_y_test_pred2['Fatalities']": 2,
      "cases_pred[:NUMBER_OF_PUBLIC_PRED_DATES]": 2,
      "fatalities_pred[:NUMBER_OF_PUBLIC_PRED_DATES]": 2,
      "y_pred2": 2,
      "y_pred3": 2,
      "np.exp(y_pred_train)": 2,
      "np.exp(y_pred_test)": 2,
      "np.exp(y_train)": 2,
      "np.exp(y_valid)": 2,
      "merged_eval['ConfirmedCases_y'].values": 2,
      "merged_eval['Fatalities_y'].values": 2,
      "actual": 2,
      "result_confirmed": 2,
      "result_fatality": 2,
      "c_train": 2,
      "abs(pred)": 2,
      "xgb_preds": 2,
      "val_preds": 2,
      "y_pred_lr": 2,
      "y_pred_valid['Confirmed']": 2,
      "y_pred + 1": 2,
      "regr.predict(X_test)": 2,
      "rough": 2,
      "yTestPredLGB": 2,
      "yTestPredXGB": 2,
      "df.loc[df['split'] == 'test', label + '_yesterday'] + y_pred": 2,
      "df2": 2,
      "y_pred_lgbR": 2,
      "np.expm1(pred_test)": 2,
      "dummy_regr.predict(Xs_train)": 1,
      "regressor1.predict(train_data)": 1,
      "regressor1.predict(test_data)": 1,
      "regressor2.predict(train_data)": 1,
      "regressor2.predict(test_data)": 1,
      "regressor4.predict(train_data)": 1,
      "regressor4.predict(test_data)": 1,
      "regressor5.predict(train_data)": 1,
      "regressor5.predict(test_data)": 1,
      "regressor6.predict(train_data)": 1,
      "regressor6.predict(test_data)": 1,
      "pred_2": 1,
      "pred_1": 1,
      "pred_3": 1,
      "y_pred_scaled": 1,
      "data['yhat'].fillna(0).clip(0, 999999)": 1,
      "y_test_predict": 1,
      "y_test2_predict": 1,
      "forecast[:len(test_series)]": 1,
      "trainpred.ConfirmedCases[(trainpred.serd >= 71) & (trainpred.serd <= max(train.serd))]": 1,
      "trainpred.Fatalities[(trainpred.serd >= 71) & (trainpred.serd <= max(train.serd))]": 1,
      "trainpred.ConfirmedCases[trainpred.serd > 80]": 1,
      "trainpred.Fatalities[train.serd > 80]": 1,
      "trainpred.ConfirmedCases[trainpred.serd >= 64]": 1,
      "trainpred.Fatalities[train.serd >= 64]": 1,
      "catregcm.predict(xtest)": 1,
      "catregbe.predict(xtest)": 1,
      "catregno.predict(xtest)": 1,
      "pred_tree": 1,
      "pred_tree2": 1,
      "np.exp(pred_gbm)": 1,
      "previsao**(1 / 2)": 1,
      "train.wg2": 1,
      "train.wg3": 1,
      "data.wg": 1,
      "data.wg2": 1,
      "data.wg3": 1,
      "y_preds2": 1,
      "df_filt_score['ConfirmedCases_pred']": 1,
      "df_filt_score['Fatalities_pred']": 1,
      "df_filt_score2['ConfirmedCases_pred']": 1,
      "df_filt_score2['Fatalities_pred']": 1,
      "df_filt_score3['ConfirmedCases_pred']": 1,
      "df_filt_score3['Fatalities_pred']": 1,
      "np.exp(lgb_train.get_label())": 1,
      "train_y": 1,
      "test_y": 1,
      "y1": 1,
      "y2": 1,
      "y_pred_target_benzene": 1,
      "y_pred_target_carbon_monoxide": 1,
      "y_pred_target_nitrogen_oxides": 1,
      "pred_lr": 1,
      "pred_nn": 1,
      "pred_xgr": 1,
      "y_Optimal_pred": 1,
      "ypreds": 1,
      "np.exp(cv_preds)": 1,
      "Y": 1,
      "np.abs(model.predict(data))": 1,
      "np.exp(y_train_pred)": 1,
      "np.exp(y_train_pred_l)": 1,
      "results_train": 1,
      "results_test": 1,
      "y_valid['cc']": 1,
      "y_valid['deaths']": 1,
      "model_check[['ConfirmedCases', 'Fatalities']]": 1,
      "np.expm1(pred)": 1,
      "algo_mean": 1,
      "y_pred_SVR": 1,
      "y_pred_dt": 1,
      "y_pred_gbm": 1,
      "y_pred_8": 1,
      "sigmoid(past, *params)": 1,
      "predc": 1,
      "predf": 1,
      "y_pred_CO": 1,
      "y_pred_C6H6": 1,
      "y_pred_NOx": 1,
      "act": 1,
      "final": 1,
      "np.exp(lin_reg.predict(train_X))": 1,
      "np.exp(lin_reg.predict(test_X))": 1,
      "logistic_reg.predict(train_X)": 1,
      "logistic_reg.predict(test_X)": 1,
      "np.exp(y_pred) - 1": 1,
      "y_pred.iloc[:, 0]": 1,
      "y_pred.iloc[:, 1]": 1,
      "y_pred.iloc[:, 2]": 1,
      "np.array(preds).T": 1,
      "y_pred_final": 1,
      "y_pred_pca": 1,
      "count_predictions": 1,
      "y_vld": 1,
      "merged_eval['ConfirmedCases_y']": 1,
      "merged_eval['Fatalities_y']": 1,
      "y_train_predicted": 1,
      "y_final_pred": 1,
      "ytrain_predict": 1,
      "yval_predict": 1,
      "np.exp(train_preds)": 1,
      "np.exp(preds2)": 1,
      "np.exp(preds3)": 1,
      "pred_test.Label.values": 1,
      "y_pred_gs": 1,
      "predicted_cases": 1,
      "predicted_fatalities": 1,
      "p2": 1,
      "p3": 1,
      "train_pred": 1,
      "y_lasso_train": 1,
      "predictions.Confirmed.values": 1,
      "y_pred.loc[i]": 1,
      "pred_prices": 1,
      "y_pred_abr": 1,
      "y_pred_knn": 1,
      "yhat": 1,
      "lin_predictions": 1,
      "tree_predictions": 1,
      "xgb_predictions": 1,
      "y_train_cc": 1,
      "y_test_cc": 1,
      "y_": 1,
      "np.maximum(0, prediction)": 1,
      "self.y_hat": 1,
      "prediction['count_pred']": 1,
      "np.expm1(y_val)": 1,
      "count_pred['count_pred']": 1,
      "nw_count_pred['nw_count_pred']": 1,
      "final_count": 1,
      "yp": 1,
      "testm['sale_LassoLarsCV_predictions'].values": 1,
      "testm['sale_KNN_Regressor_predictions'].values": 1,
      "testm['sale_RF_Regressor_predictions'].values": 1,
      "testm['sale_XGBoost_predictions'].values": 1,
      "testm['sale_Ensembled_predictions'].values": 1,
      "testm['sale_predictions'].values": 1,
      "opti_dtc_final_predictions": 1,
      "model2_final_predictions": 1,
      "pred_all": 1,
      "y_pred_rfc_confirmed": 1,
      "y_pred_rfc_fatal": 1,
      "predictions1": 1,
      "predictions2": 1,
      "np.round(x_pred['Predictions1'])": 1,
      "np.round(x_pred['Predictions2'])": 1,
      "x_pred[x_pred['Date'] >= '2020-03-20']['Predictions1']": 1,
      "x_pred[x_pred['Date'] >= '2020-03-20']['Predictions2']": 1,
      "np.ceil(x_pred2[x_pred2['Date'] <= '2020-03-23']['Predictions1'])": 1,
      "np.round(x_pred2[x_pred2['Date'] <= '2020-03-23']['Predictions2'])": 1,
      "x_pred2[x_pred2.Date.isin(dates_overlap)]['Predictions1']": 1,
      "x_pred2[x_pred2.Date.isin(dates_overlap)]['Predictions2']": 1,
      "np.floor(x_pred2[x_pred2.Date.isin(dates_overlap)]['Predictions1'])": 1,
      "np.floor(x_pred2[x_pred2.Date.isin(dates_overlap)]['Predictions2'])": 1,
      "np.clip(sampled_prediction, 0, None)": 1,
      "y_test_pred": 1,
      "tr1_pred": 1,
      "tr2_pred": 1,
      "ypred1": 1,
      "pred_val": 1,
      "out1": 1,
      "out2": 1,
      "out3": 1,
      "model.predict(test_data)": 1,
      "y1_hat_train": 1,
      "y1_hat_test": 1,
      "y2_hat_train": 1,
      "y2_hat_test": 1,
      "predict1[prediction]": 1,
      "predict2[prediction]": 1,
      "y_pred_ridge": 1,
      "np.clip(np.expm1(y_pred), 0, None)": 1,
      "predictions_cc": 1,
      "cc_pred": 1,
      "f_pred": 1,
      "preds_eval[:, 0]": 1,
      "preds_eval[:, 1]": 1,
      "y_predtrain2": 1,
      "train_pred.ConfirmedPred": 1,
      "train_pred.FatalitiesPred": 1,
      "fit1.fittedvalues": 1,
      "fit2.fittedvalues": 1,
      "fit3.fittedvalues": 1,
      "fit4.fittedvalues": 1,
      "fit5.fittedvalues": 1,
      "fit6.fittedvalues": 1,
      "pred[:, 1]": 1,
      "pred[:, 2]": 1,
      "carbon_pred": 1,
      "benzene_pred": 1,
      "nitrogen_pred": 1,
      "y_pred_class": 1,
      "pred_data.values": 1,
      "train": 1,
      "pred_y": 1,
      "preds_train_ca": 1,
      "preds_valid_ca": 1,
      "preds_train_re": 1,
      "preds_valid_re": 1,
      "preds_train": 1,
      "preds_valid": 1,
      "preds_train_merge_count": 1,
      "preds_valid_merge_count": 1,
      "y_preds_lgb": 1,
      "temp_df[(temp_df.Day >= const.TEST_DAY_FROM) & (temp_df.Day <= const.TEST_DAY_TO)].ConfirmedCases_inversed_predicted": 1,
      "abs(val_preds_c)": 1,
      "abs(val_preds_f)": 1,
      "abs(val_preds)": 1
    },
    "sklearn.model_selection._search.RandomizedSearchCV.__init__.param_distributions": {
      "params": 124,
      "param_grid": 90,
      "random_grid": 49,
      "parameters": 29,
      "param_dist": 27,
      "grid": 13,
      "rf_grid": 12,
      "param_distribs": 12,
      "param_test": 12,
      "hyperparameter_grid": 11,
      "param": 10,
      "random_parameters": 8,
      "distributions": 8,
      "param_distributions": 7,
      "tune_params": 6,
      "gbm_param_grid": 4,
      "gridParams": 4,
      "params_grid": 4,
      "param_dict": 4,
      "hyperparameters": 4,
      "rf_param_grid": 3,
      "params_xgb": 3,
      "rf_params": 3,
      "lgbParameters": 2,
      "log_reg_grid": 2,
      "hyperparameters_grid": 2,
      "xgb_params": 2,
      "lr_params": 2,
      "param_grid_svm": 2,
      "adaboost_params": 2,
      "search_space": 2,
      "grid_params": 2,
      "grid_param": 2,
      "lgbm_grid": 2,
      "param_search": 2,
      "model_grid": 2,
      "bayesian_grid": 2,
      "model_params_grid": 2,
      "Random_Search_Params": 2,
      "rand_grid": 2,
      "param_rand": 2,
      "random_search": 2,
      "PARAMS": 2,
      "hyper_params": 2,
      "pipe_params": 2,
      "param_grid_xgb": 1,
      "r_grid": 1,
      "random_grid_rfr": 1,
      "xgbr_param_grid": 1,
      "xgbc_param_grid": 1,
      "space": 1,
      "random_param": 1,
      "random_grid_lgbm": 1,
      "xgparam": 1,
      "adaparam": 1,
      "para": 1,
      "paran": 1,
      "xg_c_param_grid": 1,
      "{'n_estimators': [int(x) for x in np.linspace(start=1, stop=50, num=10)], 'criterion': ['gini', 'entropy'], 'max_features': ['auto', 'sqrt', 'log2'], 'min_samples_split': range(1, 10), 'min_samples_leaf': range(1, 10), 'max_depth': [int(x) for x in np.linspace(start=1, stop=30, num=2)]}": 1,
      "param_RFC": 1,
      "param_LR": 1,
      "{'max_depth': np.arange(1, 25), 'min_samples_leaf': np.arange(1e-05, 0.3, 1e-05)}": 1,
      "{'max_depth': np.arange(1, 30), 'min_samples_leaf': np.arange(0.0001, 0.3, 0.0001)}": 1,
      "params_rf": 1,
      "params_etc": 1,
      "params[name]": 1,
      "params_dist_grid": 1,
      "CTL.gridsearch_param_grid": 1,
      "rand_list": 1,
      "rf_grid_2": 1,
      "lr_grid": 1,
      "param_grid_initial": 1,
      "param_grid_model_specific[model_name]": 1,
      "random_grid_par": 1,
      "params2": 1,
      "espaco_de_parametros": 1,
      "hyper_parameter": 1,
      "gs_params": 1,
      "param_opt": 1,
      "paramR": 1,
      "clf[1]": 1,
      "Random_Search_lgb_Params": 1,
      "Random_Search_xgb_Params": 1,
      "parameter_grid": 1,
      "lgbc_params": 1,
      "xgbc_params": 1,
      "model": 1,
      "estimator[list(estimator.keys())[0]]": 1,
      "hyp_grid": 1,
      "{'C': [1, 10, 20], 'kernel': ['rbf', 'linear', 'poly']}": 1,
      "pipe_grid": 1,
      "params_lgb_grid": 1,
      "self.hyperparameters": 1,
      "random_grid_co": 1,
      "random_grid_no": 1,
      "tuned_parameters_xgb": 1,
      "tuned_parameters_lgb": 1,
      "lasso_param": 1,
      "param_grid[0]": 1,
      "ada_param_grid": 1,
      "ex_param_grid": 1,
      "gb_param_grid": 1,
      "random_gbr": 1,
      "rfr_random_grid": 1,
      "distributions_set9": 1,
      "gbm_param": 1,
      "rf_param": 1,
      "xgb_gs_params": 1,
      "parameter_distributions": 1,
      "param_space": 1,
      "svm_params": 1,
      "raf_params": 1,
      "rs_params": 1,
      "selector_grid": 1,
      "lgbm_tunning_grid": 1,
      "tunning_param_grid": 1,
      "xgbParameters": 1,
      "grid_RFR": 1,
      "param_grid_rand": 1,
      "model['hyperparameters']": 1,
      "randomGrid": 1,
      "rf_tuned_params": 1,
      "DT_tuned_params": 1,
      "randomCV_grid": 1,
      "params_LGB": 1,
      "params_XGB": 1,
      "paramters_xgb": 1
    },
    "sklearn.model_selection._search.RandomizedSearchCV.__init__.n_iter": {
      "10": 247,
      "100": 81,
      "5": 26,
      "50": 26,
      "20": 25,
      "n_iter_search": 17,
      "200": 14,
      "param_comb": 12,
      "n_HP_points_to_test": 11,
      "15": 11,
      "2": 10,
      "40": 10,
      "n_iter": 10,
      "25": 10,
      "12": 8,
      "1000": 6,
      "4": 6,
      "500": 5,
      "max_iter": 4,
      "3": 3,
      "1": 3,
      "30": 2,
      "NUM_ITER": 2,
      "N_ITER": 2,
      "iterations": 2,
      "400": 2,
      "param_combination": 2,
      "7": 1,
      "4 * 4 * 4 * 4": 1,
      "13": 1,
      "300": 1,
      "CTL.gridsearch_n_iter": 1,
      "32": 1,
      "120": 1,
      "10000": 1,
      "80": 1,
      "8": 1,
      "n_search": 1,
      "num_iters": 1,
      "75": 1,
      "paramCombinations": 1,
      "samples": 1,
      "800": 1
    },
    "sklearn.model_selection._search.RandomizedSearchCV.__init__.cv": {
      "5": 191,
      "3": 133,
      "None": 61,
      "4": 41,
      "10": 34,
      "cv": 20,
      "kfold": 12,
      "2": 11,
      "folds": 8,
      "skf.split(X, y)": 5,
      "skf.split(X_train, y_train)": 5,
      "kf": 4,
      "KFold(3)": 3,
      "KFold(n_splits=5)": 3,
      "7": 3,
      "skf": 3,
      "skf.split(X, Y)": 3,
      "20": 3,
      "cv_rs": 3,
      "8": 2,
      "n_folds": 2,
      "cv_sets": 2,
      "cv_method": 1,
      "15": 1,
      "StratifiedKFold(n_splits=4)": 1,
      "inner_cv": 1,
      "GroupKFold(n_splits=3)": 1,
      "CTL.gridsearch_cv": 1,
      "skf.split(train, target)": 1,
      "KFold(n_splits=5, shuffle=True)": 1,
      "[(train_indices, valid_indices)]": 1,
      "tscv": 1,
      "StratifiedKFold(n_splits=5, random_state=1)": 1,
      "kfolds": 1,
      "KFold()": 1,
      "cvs": 1,
      "skf.split(X_log, y)": 1,
      "pds": 1,
      "rskf": 1,
      "11": 1,
      "skf.split(train[feat_imp.features], train.action)": 1,
      "KFold(n_splits=5, shuffle=True, random_state=params['random_state'])": 1,
      "StratifiedKFold(4).split(X_train, y_train)": 1
    },
    "sklearn.model_selection._search.RandomizedSearchCV.__init__.verbose": {
      "0": 248,
      "2": 92,
      "1": 77,
      "True": 53,
      "3": 38,
      "10": 23,
      "5": 19,
      "False": 5,
      "-1": 4,
      "20": 3,
      "verbose": 3,
      "4": 2,
      "8": 2,
      "7": 2,
      "100": 1,
      "250": 1
    },
    "sklearn.model_selection._search.RandomizedSearchCV.__init__.estimator": {
      "model": 46,
      "clf": 46,
      "rf": 40,
      "xgb": 20,
      "pipe": 17,
      "pipeline": 12,
      "RandomForestRegressor()": 11,
      "RandomForestClassifier()": 10,
      "rfr": 8,
      "regressor": 8,
      "estimator": 7,
      "classifier": 7,
      "lgb_clf": 6,
      "reg_case": 6,
      "reg_fatal": 6,
      "reg_case_f": 6,
      "reg_fatal_f": 6,
      "RF_Model": 6,
      "reg": 5,
      "RF": 5,
      "lr": 5,
      "lgbm": 5,
      "SVC()": 4,
      "rfc": 4,
      "XGB": 4,
      "model_abr": 4,
      "RandomForestRegressor(n_jobs=-1, random_state=42)": 4,
      "regrMdl": 4,
      "AdaBoostRegressor()": 3,
      "xgbr": 3,
      "xgbc": 3,
      "xgb.XGBClassifier()": 3,
      "lgb_model": 3,
      "pipe_xg": 3,
      "gbm": 3,
      "xgbmodel": 3,
      "model2": 3,
      "clf_1": 3,
      "xgb_model": 3,
      "xgb.XGBRegressor()": 3,
      "forest_reg": 3,
      "gbr": 3,
      "xgb_reg": 3,
      "mdl": 3,
      "XGBRegressor()": 2,
      "LogisticRegression()": 2,
      "gb_model": 2,
      "text_clf": 2,
      "svc_model": 2,
      "Rfr": 2,
      "rf_clf": 2,
      "clf_xgb": 2,
      "xg": 2,
      "svc": 2,
      "c": 2,
      "asdf": 2,
      "lgb_reg": 2,
      "lgb_estimator": 2,
      "lgbm_pipe": 2,
      "random_forest": 2,
      "sgd": 2,
      "type_model": 2,
      "lgb": 2,
      "bayesian": 2,
      "regrMdl1": 2,
      "regrMdl2": 2,
      "GradientBoostingClassifier()": 2,
      "keras_clf": 2,
      "xgb2": 2,
      "AdaBoost": 2,
      "forest_clf": 2,
      "RandomForestRegressor(n_jobs=-1, random_state=12)": 1,
      "lgb_classifer": 1,
      "reg_keras": 1,
      "lgb.LGBMRegressor()": 1,
      "regressor_hyp": 1,
      "RandomForestModel2": 1,
      "LGBMModel2": 1,
      "XGBModel2": 1,
      "AdaBoostModel2": 1,
      "dec_reg": 1,
      "rf_regressor": 1,
      "hyper_xgboost": 1,
      "hyper_adaboost": 1,
      "classifier_etc": 1,
      "classifier_k_best": 1,
      "cdr": 1,
      "ridge": 1,
      "xg_c": 1,
      "xgb_r": 1,
      "rf_reg": 1,
      "modelRF": 1,
      "modelLR": 1,
      "fatal": 1,
      "tree": 1,
      "clf_rf": 1,
      "clf_etc": 1,
      "boost": 1,
      "XGBClassifier(*xgbc_fixed)": 1,
      "LogisticRegression(random_state=1)": 1,
      "MultinomialNB()": 1,
      "DecisionTreeClassifier(random_state=1)": 1,
      "KNeighborsClassifier(n_jobs=-1)": 1,
      "num_pipeline": 1,
      "GradientBoostingRegressor(random_state=0, loss='lad', n_estimators=50, max_depth=2, criterion='friedman_mse', init=LinearRegression())": 1,
      "clf_rfc": 1,
      "eval_pipeline": 1,
      "Ridge()": 1,
      "Model": 1,
      "XGB_Model": 1,
      "lr_clf": 1,
      "sgd_clf": 1,
      "rf_pipe": 1,
      "rf_pipe_2": 1,
      "lr_pipe": 1,
      "models['Logistic Regression']": 1,
      "RandomForestClassifier(class_weight='balanced')": 1,
      "xgb.XGBRegressor(objective='reg:squarederror')": 1,
      "tb": 1,
      "rd": 1,
      "m": 1,
      "lr2": 1,
      "rf_model": 1,
      "rf2_cases": 1,
      "rf2_fatalities": 1,
      "skrg": 1,
      "rf_3": 1,
      "rf_4": 1,
      "model_RandomSearch": 1,
      "rf_tune": 1,
      "reg_rf": 1,
      "LogisticRegression(solver='saga')": 1,
      "full_pipeline": 1,
      "XGBRegressor(tree_method='gpu_hist')": 1,
      "rf_selection": 1,
      "RandomForestRegressor(random_state=0)": 1,
      "ensemble_model_v2": 1,
      "cbr": 1,
      "clf[0]": 1,
      "rforest": 1,
      "KNeighborsClassifier(p=2)": 1,
      "forest": 1,
      "xgb_model_train": 1,
      "rf_obj": 1,
      "BaggingClassifier(DecisionTreeClassifier(), max_features=0.5)": 1,
      "rf_rand_grid": 1,
      "svm": 1,
      "lgbc": 1,
      "Rfr_clf": 1,
      "model3": 1,
      "lgbm_srch": 1,
      "pips[0]": 1,
      "clf_tree": 1,
      "list(estimator.keys())[0]": 1,
      "CatBoostRegressor(verbose=0)": 1,
      "GradientBoostingClassifier(random_state=42)": 1,
      "SVR()": 1,
      "SVC(gamma='auto')": 1,
      "cnn": 1,
      "raw_model": 1,
      "lgbm_model": 1,
      "pipeline_xgb": 1,
      "mlp": 1,
      "self.model": 1,
      "XGBClassifier(n_estimators=3000)": 1,
      "rf_co": 1,
      "rf_no": 1,
      "log_R": 1,
      "SGD": 1,
      "model_CV": 1,
      "LGBMRegressor()": 1,
      "C": 1,
      "lasso": 1,
      "p": 1,
      "rf1": 1,
      "RFG": 1,
      "model_kernal": 1,
      "adaDTC": 1,
      "ExtC": 1,
      "RFC": 1,
      "GBC": 1,
      "svr_reg": 1,
      "logistic": 1,
      "gauss": 1,
      "dtr": 1,
      "abr": 1,
      "gbdt_clf": 1,
      "random_forest_clf": 1,
      "knn_cl_grid_rd": 1,
      "svr": 1,
      "clfETC": 1,
      "dtree": 1,
      "LGBMC": 1,
      "svm_pipeline": 1,
      "raf_pipeline": 1,
      "xgb_pipeline": 1,
      "lr_model": 1,
      "rf_hyp": 1,
      "xg.XGBRegressor(objective='reg:squarederror')": 1,
      "selector_pipe": 1,
      "tunning_pipeline": 1,
      "logreg": 1,
      "ridge_clf_normalize_false": 1,
      "ridge_clf_normalize_true": 1,
      "lgbm_classifier": 1,
      "ensemble.GradientBoostingClassifier()": 1,
      "lgbmr": 1,
      "earth": 1,
      "estimator['estimator']": 1,
      "lgbAttributes": 1,
      "xgbAttribute": 1,
      "final_pipe": 1,
      "logistic_regression_model": 1,
      "rfc_tunned": 1,
      "knn_tunned": 1,
      "lgbm_tunned": 1,
      "gb_tuned": 1,
      "rfr_pipeline": 1,
      "model_rs": 1,
      "model['estimator']": 1,
      "xgbrM": 1,
      "catM": 1,
      "sample_train_pipeline": 1,
      "RandomForestClassifier(random_state=RANDOM_STATE)": 1,
      "RFModel": 1,
      "DTReg": 1,
      "rf_random": 1,
      "LGBReg": 1,
      "XGBReg": 1,
      "xgb_grid_search": 1
    },
    "sklearn.feature_extraction.text.CountVectorizer.fit.raw_documents": {
      "corpus": 145,
      "X_train": 35,
      "txt": 30,
      "list(X_train['features']) + list(X_test['features'])": 28,
      "list(xtrain) + list(xvalid)": 23,
      "train_df['Gene']": 14,
      "train_df['Variation']": 14,
      "train_df['TEXT']": 14,
      "list(train_df['features']) + list(test_df['features'])": 14,
      "train_x": 13,
      "train['text']": 11,
      "train_df['features']": 11,
      "x_train": 9,
      "words_list": 9,
      "X": 9,
      "train_df['text'].values.tolist() + test_df['text'].values.tolist()": 8,
      "all_text": 8,
      "pd.concat((trainDF.ix[:, 'question1'], trainDF.ix[:, 'question2'])).unique()": 7,
      "train_docs_clean": 6,
      "words": 6,
      "train['Phrase']": 5,
      "data": 5,
      "train.Phrase": 5,
      "list(X_train) + list(X_test)": 5,
      "train": 4,
      "test['Phrase']": 4,
      "comments_train": 4,
      "X_train.head()": 4,
      "docs_clean": 4,
      "train_data['text']": 4,
      "text": 4,
      "pd.concat((train.question1, train.question2)).unique()": 4,
      "df_train['name'] + ' ' + df_train['item_description']": 4,
      "X_train['text'].values.tolist() + X_test['text'].values.tolist()": 4,
      "X_train['Variation']": 4,
      "queries[train_idx]": 4,
      "test_x": 3,
      "train_X": 3,
      "data['text']": 3,
      "itertools.chain(df_all['question1'], df_all['question2'])": 3,
      "df_train['name_old']": 3,
      "df_train['brand_cat']": 3,
      "df_train['item_description']": 3,
      "labels": 3,
      "X_train_clean": 3,
      "Xarr": 3,
      "X_train['Text']": 3,
      "X_test['Text']": 3,
      "X_test['Variation']": 3,
      "X_train.text": 3,
      "x_train_text": 2,
      "x_val_text": 2,
      "test['clean_text']": 2,
      "sentences": 2,
      "df_train.text": 2,
      "pd.concat((df['text'], df_test['text']), axis=0)": 2,
      "df_test['text']": 2,
      "trainText2": 2,
      "list(news_train_df['headline'])": 2,
      "sample['name'] + ' ' + sample['item_description']": 2,
      "sample[:split_num]['brand_cat']": 2,
      "sample[:train.shape[0]]['old_name']": 2,
      "sample[:train.shape[0]]['item_description']": 2,
      "df.values": 2,
      "full_data['text']": 2,
      "list(train['review']) + list(test['review'])": 2,
      "train['ingredients']": 2,
      "df_train_1.Phrase": 2,
      "train.text": 2,
      "df['name']": 2,
      "words_train": 2,
      "pd.concat((df_train.ix[:, 'question1'], df_train.ix[:, 'question2'])).unique()": 2,
      "docs[train_idx]": 2,
      "titles[:10158]": 2,
      "train_data['sub_category1']": 2,
      "train_data['sub_category2']": 2,
      "train_data['sub_category3']": 2,
      "train_data['brand_name']": 2,
      "train_data['name']": 2,
      "pd.concat([train['question1'], train['question2']])": 2,
      "train['Phrase'].values.tolist() + test['Phrase'].values.tolist()": 2,
      "train['review']": 2,
      "all_qs": 2,
      "temp": 2,
      "pd.concat((trainText, validText, testText))": 2,
      "xtrain": 2,
      "train.ngrams": 2,
      "X_train.keyword": 2,
      "train_set.text": 2,
      "df_train['joined_ing'].values.tolist()": 1,
      "subj_df.text": 1,
      "review_df.text": 1,
      "df.Tokens": 1,
      "ingredient_list": 1,
      "train_labels['molecule']": 1,
      "clean_text": 1,
      "train['stemed_text']": 1,
      "preprocessed_reviews": 1,
      "final_word": 1,
      "feature_tr": 1,
      "dftrain['Phrase']": 1,
      "train_corpus": 1,
      "test['text']": 1,
      "train['keyword']": 1,
      "test['keyword']": 1,
      "sample_text": 1,
      "train_df['text'].values.astype('U')": 1,
      "train_text": 1,
      "import_df['project_essay_1'] + import_df['project_essay_2']": 1,
      "ingredients": 1,
      "train['new_text2']": 1,
      "list(train_data['Description'].values) + list(test_data['Description'].values)": 1,
      "[words_excerpt]": 1,
      "df['question_text'].append(df_test['question_text'])": 1,
      "X_train['essay'].values": 1,
      "X_train['school_state'].values": 1,
      "X_train['teacher_prefix'].values": 1,
      "X_train['project_grade_category'].values": 1,
      "X_train['clean_categories'].values": 1,
      "X_train['clean_subcategories'].values": 1,
      "items.item_name.tolist()": 1,
      "items.item_name.apply(preprocess_text).tolist()": 1,
      "train.question_text": 1,
      "wordCollection": 1,
      "X + X_test": 1,
      "sortedFeatures": 1,
      "word": 1,
      "test_df.append(train_df, sort=False)['text']": 1,
      "train_data['stem_text']": 1,
      "train_df['Phrase']": 1,
      "test_df['Phrase']": 1,
      "simple_train": 1,
      "train_df['lemm_lower']": 1,
      "trn_polarized.selected_text": 1,
      "train_polarized.selected_text": 1,
      "df_train['all_ingredients']": 1,
      "train['cleaned']": 1,
      "tags_all_text": 1,
      "df_train['Province/State']": 1,
      "df_train['Country/Region']": 1,
      "train_model": 1,
      "all_content": 1,
      "train_feature": 1,
      "train[key].apply(str)": 1,
      "train['question_text_no_punc']": 1,
      "corpus_name": 1,
      "corpus_desc": 1,
      "np.concatenate([train_df['excerpt_clean'].values, test_df['excerpt_clean'].values])": 1,
      "train_qs.unique()": 1,
      "text_list": 1,
      "full_text": 1,
      "X_train['category_name'].astype('category')": 1,
      "train_df['clean_text'].values.tolist() + test_df['clean_text'].values.tolist()": 1,
      "X2_train": 1,
      "train_qs": 1,
      "train['text'].apply(lambda x: x.lower())": 1,
      "test['text'].apply(lambda x: x.lower())": 1,
      "train[col].apply(lambda x: x.lower())": 1,
      "test[col].apply(lambda x: x.lower())": 1,
      "test_corpus": 1,
      "df_all['text']": 1,
      "all_data['Description'].fillna('NULL')": 1,
      "all_data['Name'].fillna('NULL')": 1,
      "train.text_processed": 1,
      "train_data_no_duplicates['text']": 1,
      "txts": 1,
      "pd.concat((train_df.question1, train_df.question2)).unique()": 1,
      "df_concat.cleaned_text": 1,
      "list(train_df.cleaned_text.values) + list(test_df.cleaned_text.values)": 1,
      "allText": 1,
      "train_df.text": 1,
      "all_text_joined": 1,
      "texts": 1,
      "names_tr": 1,
      "small_sample.selected_text": 1,
      "line": 1,
      "test.Phrase": 1,
      "text_train": 1,
      "list(fullSent['Phrase'])": 1,
      "pd.concat((train['text_cleaned'], test['text_cleaned']), axis=0)": 1,
      "X_train['project_title']": 1,
      "X_train['project_essay_1']": 1,
      "X_train['project_essay_2']": 1,
      "X_train['project_resource_summary']": 1,
      "X_train['description']": 1,
      "s1.append(s2)": 1,
      "train_qs.append(test_qs)": 1,
      "df['question_text'].append(test['question_text'])": 1,
      "train_df.question_text.values": 1,
      "excerpts_train": 1,
      "preprocessed_comments_train": 1,
      "train_df['genres_mod'] + train_df.cast_mod": 1,
      "df.brand_name": 1,
      "df.main_category": 1,
      "df.sub_category": 1,
      "df.item_type": 1,
      "finaldata": 1,
      "self.training_data['text']": 1,
      "df['total_text']": 1,
      "trainData['Phrase']": 1,
      "list(subdata['features'])": 1,
      "text_pos": 1,
      "text_neg": 1,
      "final.values": 1,
      "train_comments": 1,
      "train['pos'].values.tolist() + test['pos'].values.tolist()": 1,
      "list(train_df.text.values) + list(test_df.text.values)": 1,
      "List_of_tweets(train)": 1,
      "pd.concat((train.ix[:, 'question1'], train.ix[:, 'question2'])).unique()": 1,
      "X_test_final": 1,
      "headlineT": 1,
      "provider": 1,
      "headlines": 1,
      "sset": 1,
      "saus": 1,
      "list(X_train.features) + list(X_test.features)": 1,
      "x_train['cat1'].values": 1,
      "x_train['cat2'].values": 1,
      "x_train['cat3'].values": 1,
      "x_train['brand_name'].values": 1,
      "train['cleaned'].values": 1,
      "doc_clean.loc[train.index]": 1,
      "train_x['question_text']": 1,
      "docs": 1,
      "train_df.question_text": 1,
      "insincere['clean']": 1,
      "corpus1": 1,
      "corpus2": 1,
      "X_train['Gene']": 1,
      "X_train['TEXT']": 1,
      "new_df": 1,
      "df_train['ingredients_str']": 1,
      "column": 1,
      "X_test": 1,
      "train['question_text'].append(test['question_text'])": 1,
      "xdf": 1,
      "df_test.text": 1,
      "x_tr['essay']": 1,
      "x_tr['title']": 1,
      "x_tr['clean_categories']": 1,
      "x_tr['clean_subcategories']": 1,
      "grouped_cleaned": 1,
      "[submission['text'][row]]": 1,
      "X['review']": 1,
      "X_test['review']": 1,
      "train['stemmed_text']": 1,
      "train_df['text']": 1,
      "corpus_1": 1,
      "list(resampled_dataset['question_text'].values) + list(resampled_dataset['question_text'].values)": 1,
      "df['text']": 1,
      "X_train['brand_name'].values": 1,
      "X_train['name'].values": 1,
      "X_train['main_cat'].values": 1,
      "X_train['subcat_1'].values": 1,
      "X_train['subcat_2'].values": 1,
      "tr[feature].values": 1,
      "test_df.append(train_df)['text']": 1,
      "list(x['question_text'].values) + list(validation_data['question_text'].values)": 1,
      "self.train.question_text": 1,
      "train['category_name'].values": 1,
      "train['main_category'].values": 1,
      "train['sub_cat_1'].values": 1,
      "train['sub_cat_2'].values": 1,
      "train['brand_name'].astype(str)": 1,
      "tweets['text']": 1,
      "train_df['preprocessed_excerpt']": 1,
      "tweets": 1,
      "df.text": 1,
      "df": 1,
      "list(X_train)": 1
    },
    "sklearn.feature_extraction.text.CountVectorizer.__init__.ngram_range": {
      "(1, 1)": 2262,
      "(1, 2)": 253,
      "(1, 3)": 153,
      "(2, 2)": 82,
      "(3, 3)": 36,
      "ngram_range": 29,
      "(n, n)": 23,
      "(1, 4)": 13,
      "(2, 3)": 11,
      "(1, 5)": 9,
      "(n_grams, n_grams)": 8,
      "[1, 3]": 5,
      "(1, 7)": 4,
      "(ngram, ngram)": 4,
      "n_gram": 3,
      "(1, 6)": 3,
      "(2, 4)": 3,
      "(1, 8)": 3,
      "(1, 10)": 3,
      "(3, 6)": 3,
      "ngrams": 2,
      "(grams, grams)": 2,
      "(n_ngram, n_ngram)": 2,
      "(1, ngramLength)": 2,
      "n": 2,
      "ngramrange": 2,
      "(4, 4)": 1,
      "(ngram_range, ngram_range)": 1,
      "[1, 4]": 1,
      "(3, 5)": 1,
      "(r, r)": 1,
      "(2, 5)": 1,
      "(m, n)": 1,
      "ngrams[i]": 1,
      "ngram": 1,
      "(ngram_range_start, ngram_range_end)": 1,
      "bow_ngrams": 1,
      "(1, ngram)": 1,
      "(n_gram, n_gram)": 1,
      "{1, 2}": 1,
      "(1, max_ngram)": 1
    },
    "sklearn.feature_extraction.text.CountVectorizer.__init__.stop_words": {
      "None": 2211,
      "'english'": 601,
      "russian_stop": 17,
      "stopwords": 13,
      "stopwords.words('russian')": 12,
      "stop_words": 12,
      "stopwords.words('english')": 10,
      "stop": 9,
      "{'english'}": 8,
      "[stopwords, string.punctuation]": 8,
      "stoplist": 6,
      "st_wd": 5,
      "nltk.corpus.stopwords.words('english')": 5,
      "stoplist_combined": 3,
      "ENGLISH_STOP_WORDS": 3,
      "['shot']": 2,
      "my_stop_words": 2,
      "stopword_list": 1,
      "set(stopwords.words('english'))": 1,
      "all_stopwords": 1,
      "STOPWORDS": 1,
      "set(['brown', 'fresh', 'purple'])": 1,
      "stop_words_new": 1,
      "custom_stop_words": 1,
      "STOP_WORDS": 1,
      "en_stopwords": 1,
      "Stopwords": 1
    },
    "sklearn.feature_extraction.text.CountVectorizer.transform.raw_documents": {
      "corpus": 144,
      "test_df['features']": 115,
      "X_test": 87,
      "X_train": 51,
      "test['text']": 45,
      "test_df['text']": 41,
      "txt": 31,
      "test_df[col]": 31,
      "X['features']": 29,
      "x_test": 26,
      "xtrain": 26,
      "clean_test_reviews": 25,
      "xvalid": 22,
      "test_x": 22,
      "pos_train['text']": 21,
      "neutral_train['text']": 21,
      "neg_train['text']": 21,
      "test_df['Gene']": 19,
      "cv_df['Gene']": 19,
      "test_df['Variation']": 18,
      "cv_df['Variation']": 18,
      "test_df['TEXT']": 17,
      "cv_df['TEXT']": 17,
      "train_df['features']": 17,
      "pos_tr['text']": 16,
      "neutral_tr['text']": 16,
      "neg_tr['text']": 16,
      "test_data['text']": 15,
      "train_text": 15,
      "ts_brand_col": 15,
      "ts_cat1": 15,
      "x_train": 14,
      "train_x": 13,
      "ts_col": 13,
      "train['text']": 12,
      "df_test['text']": 12,
      "docs_clean": 11,
      "X": 11,
      "df_test['features']": 11,
      "train_df_tr['features']": 11,
      "test['name']": 10,
      "words_list": 9,
      "ts_col[:ts_part_data_len]": 9,
      "ts_cat2": 9,
      "ts_cat3": 9,
      "ts_cat_n": 9,
      "X_test.values": 8,
      "validate_x": 8,
      "train_df['text'].values.tolist()": 8,
      "test_df['text'].values.tolist()": 8,
      "test_text": 8,
      "ts_brand_col + ' ' + ts_col": 8,
      "test['question_text']": 7,
      "text": 7,
      "train['question1']": 7,
      "train['question2']": 7,
      "trainDF.ix[:, 'question1']": 7,
      "trainDF.ix[:, 'question2']": 7,
      "testDF.ix[:, 'question1']": 7,
      "testDF.ix[:, 'question2']": 7,
      "ts_cat_col": 7,
      "train_docs_clean": 6,
      "validate_docs_clean": 6,
      "data": 6,
      "test_data": 6,
      "[sent1, sent2]": 6,
      "df_test['request_text_edit_aware']": 6,
      "[x]": 6,
      "test_ingredients_words": 6,
      "test_ingredients": 6,
      "ts_brand_col + ' ' + ts_name_col": 6,
      "test_corpus": 5,
      "X_val": 5,
      "test": 5,
      "train_data['text']": 5,
      "df['item_description']": 5,
      "words": 5,
      "test_words": 5,
      "X_test.text": 5,
      "df['name']": 5,
      "train": 4,
      "validate": 4,
      "comments_train": 4,
      "comments_test": 4,
      "[string]": 4,
      "X_train.head()": 4,
      "test_df.name.tolist()": 4,
      "df_test.text": 4,
      "df['name'] + ' ' + df['item_description']": 4,
      "df_submission['name']": 4,
      "df_submission['item_description']": 4,
      "df_submission['name_bi']": 4,
      "test['comment_text']": 4,
      "texts": 4,
      "X_test['Variation']": 4,
      "X_test['text']": 4,
      "train['review']": 4,
      "test['clean_text']": 4,
      "df_sub.category_name": 4,
      "df_sub.brand_name": 4,
      "X_train['text'].values.tolist()": 4,
      "X_test['text'].values.tolist()": 4,
      "corpus_test": 4,
      "xtest": 4,
      "X_train.text": 4,
      "test_docs_clean": 3,
      "df.Tokens": 3,
      "df_test.Tokens": 3,
      "train_X": 3,
      "validate_X": 3,
      "valid['request_text_edit_aware']": 3,
      "test_df2['text']": 3,
      "[text10]": 3,
      "df_train.text": 3,
      "test_df['question_text']": 3,
      "df['name_old']": 3,
      "df['brand_cat']": 3,
      "inputs['text']": 3,
      "labels": 3,
      "test[COMMENT]": 3,
      "test_X": 3,
      "test.comment_text": 3,
      "test['ingredients']": 3,
      "train_df['text']": 3,
      "test['hashtags']": 3,
      "test.text": 3,
      "[str(i) for i in features_test_processed]": 3,
      "X_e.excerpt": 3,
      "test2.excerpt": 3,
      "clean_test": 3,
      "X_train['Text']": 3,
      "X_test['Text']": 3,
      "X_train['Variation']": 3,
      "X_dev.text_1.to_numpy()": 3,
      "tweets_test": 3,
      "docs_new": 3,
      "s1": 3,
      "s2": 3,
      "sd3": 3,
      "sd4": 3,
      "se5": 3,
      "[doc]": 3,
      "test_df.text": 3,
      "test_total_data['Text']": 3,
      "train_df_te['features']": 3,
      "X_test.keyword": 3,
      "clean_test_review": 2,
      "test.Phrase": 2,
      "train.Phrase[train['Sentiment'] == 0]": 2,
      "validation_texts": 2,
      "df.text.values": 2,
      "df_test['comment_text']": 2,
      "test['keyword']": 2,
      "train['question_text']": 2,
      "clean_test_phrase": 2,
      "text_test": 2,
      "df['text'].values": 2,
      "tx": 2,
      "df_test['text'].values": 2,
      "X_train['non_selected']": 2,
      "test_df_final['text']": 2,
      "docs_clean_test": 2,
      "testData": 2,
      "test_data['clean_text']": 2,
      "dev_data": 2,
      "X.iloc[i:min(i + self.batch_size, n_samples)]": 2,
      "sample[:split_num]['name'] + ' ' + sample[:split_num]['item_description']": 2,
      "sample[split_num:]['name'] + ' ' + sample[split_num:]['item_description']": 2,
      "sample['brand_cat']": 2,
      "sample['old_name']": 2,
      "sample['item_description']": 2,
      "df_test['question_text']": 2,
      "train[COMMENT]": 2,
      "X_test['keyword']": 2,
      "test['review']": 2,
      "train['ingredients']": 2,
      "df_train_1[df_train_1.Sentiment == 0].Phrase": 2,
      "df_train_1[df_train_1.Sentiment == 1].Phrase": 2,
      "df_train_1[df_train_1.Sentiment == 2].Phrase": 2,
      "df_train_1[df_train_1.Sentiment == 3].Phrase": 2,
      "df_train_1[df_train_1.Sentiment == 4].Phrase": 2,
      "phrase_test": 2,
      "test_df['name']": 2,
      "tweets['text']": 2,
      "words_train": 2,
      "words_test": 2,
      "test['text_cleaned']": 2,
      "df_train.name.values.astype('U').tolist()": 2,
      "df_train.item_description.values.astype('U').tolist()": 2,
      "df_test.name.values.astype('U').tolist()": 2,
      "df_test.item_description.values.astype('U').tolist()": 2,
      "test_feature": 2,
      "test_question_list": 2,
      "sentence_list_test": 2,
      "testing_data['text']": 2,
      "df_train.ix[:, 'question1']": 2,
      "df_train.ix[:, 'question2']": 2,
      "df_test.ix[:, 'question1']": 2,
      "df_test.ix[:, 'question2']": 2,
      "c": 2,
      "X_dev['text'].to_numpy()": 2,
      "X_dev.text_2.to_numpy()": 2,
      "titles[all_idx]": 2,
      "docs[all_idx]": 2,
      "titles[all_indices]": 2,
      "description[all_indices]": 2,
      "titles": 2,
      "df_test['name']": 2,
      "train_data['sub_category1']": 2,
      "validation_data['sub_category1']": 2,
      "test_data['sub_category1']": 2,
      "train_data['sub_category2']": 2,
      "validation_data['sub_category2']": 2,
      "test_data['sub_category2']": 2,
      "train_data['sub_category3']": 2,
      "validation_data['sub_category3']": 2,
      "test_data['sub_category3']": 2,
      "train_data['brand_name']": 2,
      "validation_data['brand_name']": 2,
      "test_data['brand_name']": 2,
      "train_data['name']": 2,
      "validation_data['name']": 2,
      "test_data['name']": 2,
      "test['links']": 2,
      "test['mentions']": 2,
      "train['Phrase'].values": 2,
      "test['Phrase'].values": 2,
      "[review1]": 2,
      "[comment]": 2,
      "all_qs": 2,
      "transformed_sentences_train['question1_lowercase']": 2,
      "transformed_sentences_train['question2_lowercase']": 2,
      "temp_features['common_tokens']": 2,
      "X_test_final": 2,
      "trainText": 2,
      "validText": 2,
      "testText": 2,
      "df['brand_name']": 2,
      "df['subcat_0']": 2,
      "df['subcat_1']": 2,
      "df['subcat_2']": 2,
      "(df['item_condition_id'] + 10 * df['shipping']).apply(str)": 2,
      "df['cat_brand']": 2,
      "test['category_name']": 2,
      "a": 2,
      "dataset['general_cat']": 2,
      "dataset['subcat_1']": 2,
      "dataset['subcat_2']": 2,
      "X_cv['comment_text'].values": 2,
      "X_test['comment_text'].values": 2,
      "test_docs": 2,
      "test_total_data['Variation']": 2,
      "test_df['stemmed']": 2,
      "validation_data['question_text']": 2,
      "X_train.keyword": 2,
      "test[col].astype(str)": 2,
      "positive_tweets['text']": 2,
      "negative_tweets['text']": 2,
      "test_set.text": 2,
      "dfTest['name']": 2,
      "train_data['question_text'].values.tolist()": 1,
      "test_data['question_text'].values.tolist()": 1,
      "df_train['joined_ing'].values.tolist()": 1,
      "df_test['joined_ing'].values.tolist()": 1,
      "subj_df.text": 1,
      "review_df.text": 1,
      "test_document": 1,
      "ingredient_list": 1,
      "df_test.name": 1,
      "df_test.category_name": 1,
      "df_test.brand_name": 1,
      "df_test.item_description": 1,
      "x_train_text": 1,
      "x_test_text": 1,
      "train.Phrase": 1,
      "pos_doc_mat": 1,
      "neu_doc_mat": 1,
      "sneg_doc_mat": 1,
      "spos_doc_mat": 1,
      "train.Phrase[train['Sentiment'] == 4]": 1,
      "X_test['Color']": 1,
      "X_test['SexuponOutcome']": 1,
      "X_test['Breed']": 1,
      "test['Color']": 1,
      "test['SexuponOutcome']": 1,
      "test['Breed']": 1,
      "test['stemed_text']": 1,
      "preprocessed_reviews": 1,
      "test_raw['comment_text']": 1,
      "list(sentences_test)": 1,
      "sentences": 1,
      "valid.text.values": 1,
      "final_word_test": 1,
      "feature": 1,
      "dftrain['Phrase']": 1,
      "dftest['Phrase']": 1,
      "train_corpus": 1,
      "test_data.url_legal": 1,
      "trainDF['question1'].values.astype('U')": 1,
      "trainDF['question2'].values.astype('U')": 1,
      "train['keyword']": 1,
      "validation_X_": 1,
      "df_holdout.loc[:, 'ingredients'].apply(clean_ingredients_list, bigrams=False)": 1,
      "cv_df['brand_name'].values": 1,
      "test['brand_name'].values": 1,
      "cv_df['gencat_name'].values": 1,
      "test['gencat_name'].values": 1,
      "cv_df['subcat1_name'].values": 1,
      "test['subcat1_name'].values": 1,
      "cv_df['subcat2_name'].values": 1,
      "test['subcat2_name'].values": 1,
      "data['new_column']": 1,
      "t['new_column']": 1,
      "mycorpus_test": 1,
      "sample_text": 1,
      "train_df['question1'].values.astype('U')": 1,
      "train_df['question2'].values.astype('U')": 1,
      "X_pred_final": 1,
      "test['general_cat']": 1,
      "test['subcat_1']": 1,
      "test['subcat_2']": 1,
      "valid_x": 1,
      "X_val_set": 1,
      "X_test_set": 1,
      "x_cv['text']": 1,
      "all_text": 1,
      "combine[1]['text']": 1,
      "features_sub": 1,
      "dfTest.text": 1,
      "import_df['project_essay_1'] + import_df['project_essay_2']": 1,
      "test['project_essay_1'] + test['project_essay_2']": 1,
      "ingredients": 1,
      "recipes_test.ingredients.str.join(' ')": 1,
      "test_df['ingredients']": 1,
      "test['mer_cate_id_list']": 1,
      "test['nmt_mer_cate_id_list']": 1,
      "X_train['question1'].apply(lambda x: x).tolist()": 1,
      "X_train['question2'].apply(lambda x: x).tolist()": 1,
      "X_val['question1'].apply(lambda x: x).tolist()": 1,
      "X_val['question2'].apply(lambda x: x).tolist()": 1,
      "test_df['description']": 1,
      "train['new_text2']": 1,
      "test['new_text2']": 1,
      "train_data['Description']": 1,
      "test_data['Description']": 1,
      "df_test.ingredients_concat": 1,
      "df_test['all_ingredients'].values": 1,
      "test_name": 1,
      "clean_test_data": 1,
      "[words_excerpt]": 1,
      "x_test1.values": 1,
      "sample.excerpt": 1,
      "X_test_val['Gene']": 1,
      "X_test['Gene']": 1,
      "X_test_val['Variation']": 1,
      "X_test_val['TEXT']": 1,
      "X_test['TEXT']": 1,
      "test_data['keyword']": 1,
      "X_train['essay'].values": 1,
      "X_cv['essay'].values": 1,
      "X_test['essay'].values": 1,
      "X_train['school_state'].values": 1,
      "X_cv['school_state'].values": 1,
      "X_test['school_state'].values": 1,
      "X_train['teacher_prefix'].values": 1,
      "X_cv['teacher_prefix'].values": 1,
      "X_test['teacher_prefix'].values": 1,
      "X_train['project_grade_category'].values": 1,
      "X_cv['project_grade_category'].values": 1,
      "X_test['project_grade_category'].values": 1,
      "X_train['clean_categories'].values": 1,
      "X_cv['clean_categories'].values": 1,
      "X_test['clean_categories'].values": 1,
      "X_train['clean_subcategories'].values": 1,
      "X_cv['clean_subcategories'].values": 1,
      "X_test['clean_subcategories'].values": 1,
      "items.item_name.apply(preprocess_text).tolist()": 1,
      "shuffled_train['text']": 1,
      "test_df['lemmatize_text']": 1,
      "[review]": 1,
      "testv['text']": 1,
      "test['name_bi']": 1,
      "X_test_preprocessed": 1,
      "wordCollection": 1,
      "x_val": 1,
      "df_test['text'].tolist()": 1,
      "testrest_cat['category_name']": 1,
      "train.text": 1,
      "test_data['stem_text']": 1,
      "test_df[Col]": 1,
      "test.tokens": 1,
      "[v_tweet[0]]": 1,
      "train_df['Phrase']": 1,
      "test_df['Phrase']": 1,
      "simple_train": 1,
      "simple_test": 1,
      "test['link']": 1,
      "test['tagged']": 1,
      "train_df['lemm_lower']": 1,
      "test_df['lemm_lower']": 1,
      "test['features']": 1,
      "submiss_data['Gene']": 1,
      "submiss_data['Variation']": 1,
      "submiss_data['TEXT']": 1,
      "trn_polarized.selected_text": 1,
      "val_polarized.text": 1,
      "substrings": 1,
      "train_polarized.selected_text": 1,
      "df_train['all_ingredients']": 1,
      "df_test['all_ingredients']": 1,
      "test_tweet['text']": 1,
      "t": 1,
      "test['excerpt_clean']": 1,
      "test.excerpt": 1,
      "test['lemma_str']": 1,
      "test['cleaned']": 1,
      "train['Tags']": 1,
      "test['Tags']": 1,
      "test1['text']": 1,
      "df_train['Province/State']": 1,
      "df_test['Province/State']": 1,
      "df_train['Country/Region']": 1,
      "df_test['Country/Region']": 1,
      "train_model": 1,
      "validate_model": 1,
      "docs_test_clean": 1,
      "submission_df['question_text']": 1,
      "train_content": 1,
      "test_content": 1,
      "train_feature": 1,
      "test_csr_matrix['name']": 1,
      "test_csr_matrix['brand_name']": 1,
      "test_csr_matrix['main_category']": 1,
      "test_csr_matrix['subcat_1']": 1,
      "test_csr_matrix['subcat_2']": 1,
      "essays_test": 1,
      "test['project_title']": 1,
      "essays_test + ' ' + test['project_title']": 1,
      "xtest.iloc[:, 0]": 1,
      "xtest.iloc[:, 1]": 1,
      "df_test.clean_text": 1,
      "train[key].apply(str)": 1,
      "test[key].apply(str)": 1,
      "train[train['target'] == 1]['question_text_no_punc']": 1,
      "train[train['target'] == 0]['question_text_no_punc']": 1,
      "x_test.clean_categories.values": 1,
      "test.clean_categories.values": 1,
      "x_test.clean_subcategories.values": 1,
      "test.clean_subcategories.values": 1,
      "preds_corpus": 1,
      "all_test": 1,
      "x": 1,
      "df_test.question1.fillna('')": 1,
      "df_test.question2.fillna('')": 1,
      "train.name.values": 1,
      "test.name.values": 1,
      "train.item_description.values": 1,
      "test.item_description.values": 1,
      "X_train_df['name']": 1,
      "X_test_df['name']": 1,
      "result['Gene'][first:]": 1,
      "result['Variation'][first:]": 1,
      "result['TEXT'][first:]": 1,
      "train_df['excerpt_clean'].values": 1,
      "test_df['excerpt_clean'].values": 1,
      "df_test['ingredient_text']": 1,
      "submission['ingredient_text']": 1,
      "testdf['text']": 1,
      "features_test": 1,
      "train_df.ix[:, 'question1']": 1,
      "train_df.ix[:, 'question2']": 1,
      "X['clean_text']": 1,
      "test['text'].values": 1,
      "train['Clean Review']": 1,
      "test['Clean Review']": 1,
      "test['question_title']": 1,
      "test['question_body']": 1,
      "test['question_user_page']": 1,
      "test['answer']": 1,
      "test['answer_user_page']": 1,
      "test['url']": 1,
      "test['host']": 1,
      "tweets_test['text']": 1,
      "X_train['category_name'].astype('category')": 1,
      "X_cv['category_name'].astype('category')": 1,
      "data_test['category_name'].astype('category')": 1,
      "test_features['name']": 1,
      "corpus_holdout": 1,
      "X_test['cleaned_comment']": 1,
      "test_full_df['Text']": 1,
      "test_full_df['Variation']": 1,
      "X_dev['text_2'].to_numpy()": 1,
      "test_input['text_1'].to_numpy()": 1,
      "train_df['clean_text'].values.tolist()": 1,
      "test_df['clean_text'].values.tolist()": 1,
      "X2_train": 1,
      "X2_test": 1,
      "unpredicted_texts": 1,
      "train[train.Sentiment == 2].Phrase": 1,
      "submit_data.review": 1,
      "df_test['Tokens_clean_text']": 1,
      "testData['text']": 1,
      "ingredient_list2": 1,
      "list_sentences_train": 1,
      "list_sentences_test": 1,
      "pd.Series(df_train_rebalanced['question1'].tolist())": 1,
      "pd.Series(df_train_rebalanced['question2'].tolist())": 1,
      "df_test.loc[:, 'question1']": 1,
      "df_test.loc[:, 'question2']": 1,
      "df_test.question_text": 1,
      "test_df['concat_ingredients']": 1,
      "pd.Series(test['preprocessed_text'].tolist())": 1,
      "df_test['category_main']": 1,
      "df_test['category_sub1']": 1,
      "df_test['category_sub2']": 1,
      "raw_documents[y == self.positive_class_label]": 1,
      "raw_documents": 1,
      "X_t": 1,
      "[s]": 1,
      "train['Description'].fillna('NULL')": 1,
      "test['Description'].fillna('NULL')": 1,
      "train['Name'].fillna('NULL')": 1,
      "test['Name'].fillna('NULL')": 1,
      "train.text_processed": 1,
      "test.text_processed": 1,
      "train_data_no_duplicates['text']": 1,
      "dft['fea_des_stem1']": 1,
      "txts": 1,
      "train_df.question1": 1,
      "train_df.question2": 1,
      "test_df.question1": 1,
      "test_df.question2": 1,
      "df_test['cat1']": 1,
      "df_test['cat2']": 1,
      "validation.clean_text": 1,
      "get_stemmed_text(pd_test_set['text'])": 1,
      "df_concat.cleaned_text": 1,
      "y_pred": 1,
      "test[['comment_text']].as_matrix().reshape((-1, ))": 1,
      "train_df.cleaned_text.values": 1,
      "featureCol": 1,
      "testFeatureCol": 1,
      "valid_data": 1,
      "test_original['pos_tag_sentence']": 1,
      "test_texts": 1,
      "names_tr": 1,
      "names_te": 1,
      "test['clean_txt']": 1,
      "df_test['Phrase']": 1,
      "x_train['text']": 1,
      "x_valid['text']": 1,
      "d_test.text.values": 1,
      "small_sample.selected_text": 1,
      "line": 1,
      "X_test_text": 1,
      "test_df['cleaned_text']": 1,
      "X_test.stemmed_words": 1,
      "document": 1,
      "pos_train['text_lemmas']": 1,
      "neutral_train['text_lemmas']": 1,
      "neg_train['text_lemmas']": 1,
      "text_train": 1,
      "[sentence]": 1,
      "examples": 1,
      "train_df['category_name'].values.tolist()": 1,
      "test_df['category_name'].values.tolist()": 1,
      "train_df['brand_name'].values.tolist()": 1,
      "test_df['brand_name'].values.tolist()": 1,
      "phrase_train": 1,
      "train['text_cleaned']": 1,
      "d_test.comment_text": 1,
      "X_donor_choose_validation['project_subject_categories'].values": 1,
      "test_df_pre_processed_original['project_subject_categories'].values": 1,
      "X_donor_choose_validation['project_subject_subcategories'].values": 1,
      "test_df_pre_processed_original['project_subject_subcategories'].values": 1,
      "X_donor_choose_validation['teacher_prefix'].values": 1,
      "test_df_pre_processed_original['teacher_prefix'].values": 1,
      "X_donor_choose_validation['project_grade_category'].values": 1,
      "test_df_pre_processed_original['project_grade_category'].values": 1,
      "X_donor_choose_validation['school_state'].values": 1,
      "test_df_pre_processed_original['school_state'].values": 1,
      "X_donor_choose_validation['essay']": 1,
      "test_df_pre_processed_original['essay']": 1,
      "test['sub_category1']": 1,
      "test['sub_category2']": 1,
      "test['sub_category3']": 1,
      "df_ltest": 1,
      "data['ingredients']": 1,
      "train.selected_text[train.sentiment == 'negative'].fillna(' ')": 1,
      "train.selected_text[train.sentiment == 'positive'].fillna(' ')": 1,
      "train.selected_text[train.sentiment == 'neutral'].fillna(' ')": 1,
      "dfQ['question1']": 1,
      "dfQ['question2']": 1,
      "di1": 1,
      "di2": 1,
      "eq": 1,
      "traintit['test']": 1,
      "testtit['test']": 1,
      "test['question1']": 1,
      "test['question2']": 1,
      "test['translated']": 1,
      "test['content']": 1,
      "df['question_text']": 1,
      "nb_X_train.apply(lambda x: ' '.join(x)).values": 1,
      "nb_X_val.apply(lambda x: ' '.join(x)).values": 1,
      "excerpts_train": 1,
      "excerpts_val": 1,
      "cleaned_tweet_test": 1,
      "clean_valid_excerpts": 1,
      "clean_test_excerpts": 1,
      "test.hashtags": 1,
      "preprocessed_comments_train": 1,
      "preprocessed_comments_valid": 1,
      "preprocessed_comments_test": 1,
      "testcorpus": 1,
      "cleaned_test_Reviews": 1,
      "train_df['genres_mod'] + train_df.cast_mod": 1,
      "test_df['genres_mod'] + test_df.cast_mod": 1,
      "x_test['text']": 1,
      "df.brand_name": 1,
      "df1.brand_name": 1,
      "df2.brand_name": 1,
      "df.main_category": 1,
      "df1.main_category": 1,
      "df2.main_category": 1,
      "df.sub_category": 1,
      "df1.sub_category": 1,
      "df2.sub_category": 1,
      "df.item_type": 1,
      "df1.item_type": 1,
      "df2.item_type": 1,
      "test_df['tidy_tweets']": 1,
      "finaldata": 1,
      "testdata": 1,
      "self.training_data['text']": 1,
      "self.test_data['text']": 1,
      "train1['total_text']": 1,
      "test1['total_text']": 1,
      "['As soon as I opened the door , I gasped..']": 1,
      "df_test['clean_text']": 1,
      "x_tst": 1,
      "df_test['Address'].values": 1,
      "sample.values": 1,
      "col": 1,
      "X_test['location']": 1,
      "test['location']": 1,
      "test_df.comment_text": 1,
      "subdata['features']": 1,
      "final.values": 1,
      "final_test.values": 1,
      "df2['text']": 1,
      "train_comments": 1,
      "test_comments": 1,
      "train['pos'].values.tolist()": 1,
      "test['pos'].values.tolist()": 1,
      "x_test.values": 1,
      "train_df.text.values": 1,
      "test_df.text.values": 1,
      "test['lemmatized']": 1,
      "test_df['text_clean']": 1,
      "val_train_data['text']": 1,
      "train.ix[:, 'question1']": 1,
      "train.ix[:, 'question2']": 1,
      "test.ix[:, 'question1']": 1,
      "test.ix[:, 'question2']": 1,
      "xcvalid": 1,
      "[headlines]": 1,
      "[prov]": 1,
      "[headlineT]": 1,
      "[' '.join(aud)]": 1,
      "[' '.join(subjects)]": 1,
      "features_list_test": 1,
      "x_v['clean']": 1,
      "x_test['clean']": 1,
      "x_train['cat1'].values": 1,
      "x_cv['cat1'].values": 1,
      "test_data['cat1'].values": 1,
      "x_train['cat2'].values": 1,
      "x_cv['cat2'].values": 1,
      "test_data['cat2'].values": 1,
      "x_train['cat3'].values": 1,
      "x_cv['cat3'].values": 1,
      "test_data['cat3'].values": 1,
      "x_train['brand_name'].values": 1,
      "x_cv['brand_name'].values": 1,
      "test_data['brand_name'].values": 1,
      "test_data['review']": 1,
      "test_data['Phrase']": 1,
      "train['cleaned'].values": 1,
      "test['cleaned'].values": 1,
      "doc_clean.loc[train.index]": 1,
      "doc_clean.loc[validate.index]": 1,
      "doc_clean_test": 1,
      "q1_p": 1,
      "q2_p": 1,
      "df_test['comment_text'].values": 1,
      "submission['comment_text'].values": 1,
      "train_x['question_text']": 1,
      "test_x['question_text']": 1,
      "docs": 1,
      "docs_validate": 1,
      "docs_test": 1,
      "insincere['clean']": 1,
      "X_train['clean']": 1,
      "X_dev['clean']": 1,
      "test['clean']": 1,
      "x_test['Gene']": 1,
      "x_crossval['Gene']": 1,
      "x_test['Variation']": 1,
      "x_crossval['Variation']": 1,
      "x_test['TEXT']": 1,
      "x_crossval['TEXT']": 1,
      "x_test.Gene": 1,
      "x_test.Variation": 1,
      "x_test.Text": 1,
      "testData.Gene": 1,
      "testData.Variation": 1,
      "testData.Text.astype(str)": 1,
      "test.text.values": 1,
      "X['product_title'].drop_duplicates()": 1,
      "X['product_description'].drop_duplicates()": 1,
      "tweets2.clean": 1,
      "test.question_text": 1,
      "df_train['ingredients_str']": 1,
      "df_test['ingredients_str']": 1,
      "test['text'].tolist()": 1,
      "name[~dataset['for_train']]": 1,
      "item_description[~dataset['for_train']]": 1,
      "sequence[train_size:]": 1,
      "column": 1,
      "train.ngrams": 1,
      "test.ngrams": 1,
      "submission_data['Gene']": 1,
      "submission_data['Variation']": 1,
      "submission_data['TEXT']": 1,
      "texts_test": 1,
      "xdf": 1,
      "xdf1": 1,
      "public['stemmed']": 1,
      "public['text']": 1,
      "raw_x_test": 1,
      "raw_x_train": 1,
      "kaggle_X": 1,
      "data['name']": 1,
      "data['category_name']": 1,
      "pos_train['clean_selected_text']": 1,
      "neutral_train['clean_selected_text']": 1,
      "neg_train['clean_selected_text']": 1,
      "test_file.question_text": 1,
      "x_tr['essay']": 1,
      "x_cv['essay']": 1,
      "x_test['essay']": 1,
      "x_tr['title']": 1,
      "x_cv['title']": 1,
      "x_test['title']": 1,
      "x_tr['clean_categories']": 1,
      "x_cv['clean_categories']": 1,
      "x_test['clean_categories']": 1,
      "x_tr['clean_subcategories']": 1,
      "x_cv['clean_subcategories']": 1,
      "x_test['clean_subcategories']": 1,
      "stemmer_corpus_test": 1,
      "lem_corpus_test": 1,
      "grouped_cleaned": 1,
      "X['review']": 1,
      "X_test['review']": 1,
      "test['stemmed_text']": 1,
      "test_data['text_simple']": 1,
      "corpus1": 1,
      "corpus_1": 1,
      "corpus_2": 1,
      "df['text']": 1,
      "text2": 1,
      "val_X.values": 1,
      "X_train['brand_name'].values": 1,
      "X_test['brand_name'].values": 1,
      "X_train['name'].values": 1,
      "X_test['name'].values": 1,
      "X_train['main_cat'].values": 1,
      "X_test['main_cat'].values": 1,
      "X_train['subcat_1'].values": 1,
      "X_test['subcat_1'].values": 1,
      "X_train['subcat_2'].values": 1,
      "X_test['subcat_2'].values": 1,
      "tr[feature].values": 1,
      "ts[feature].values": 1,
      "dataframe['brand_name'].values": 1,
      "dataframe['name'].values": 1,
      "dataframe['main_cat'].values": 1,
      "dataframe['subcat_1'].values": 1,
      "dataframe['subcat_2'].values": 1,
      "self.train.question_text": 1,
      "self.test.question_text": 1,
      "train['Phrase']": 1,
      "documents2": 1,
      "valid_all_tokens": 1,
      "test['category_name'].values": 1,
      "test['main_category'].values": 1,
      "test['sub_cat_1'].values": 1,
      "test['sub_cat_2'].values": 1,
      "test['brand_name'].astype(str)": 1,
      "train_df['preprocessed_excerpt']": 1,
      "tweets": 1,
      "test_df['res_description']": 1,
      "X_predict['text']": 1,
      "list(X_train)": 1,
      "list(X_test)": 1,
      "train_set.text": 1,
      "dfTest['category_name']": 1,
      "dfTest['object']": 1,
      "dfTest['brand_name']": 1,
      "dfTest['item_description']": 1
    },
    "sklearn.neighbors._classification.KNeighborsClassifier.__init__.n_neighbors": {
      "5": 664,
      "3": 186,
      "i": 93,
      "k": 83,
      "n_neighbors": 73,
      "alpha[best_alpha]": 72,
      "10": 51,
      "7": 50,
      "1": 48,
      "4": 48,
      "11": 47,
      "n": 31,
      "30": 24,
      "17": 23,
      "9": 22,
      "2": 20,
      "25": 20,
      "20": 18,
      "100": 14,
      "15": 11,
      "50": 10,
      "12": 10,
      "40": 9,
      "6": 8,
      "k_Optimal": 8,
      "26": 6,
      "16": 6,
      "8": 5,
      "best_k": 5,
      "14": 5,
      "500": 5,
      "I": 5,
      "neighbors": 4,
      "optimal_k": 4,
      "n_neighborss": 4,
      "melhork": 3,
      "33": 3,
      "np.floor(np.sqrt(y.size) / cte).astype(int)": 3,
      "np.floor(np.sqrt(y.size) / 5.3).astype(int)": 3,
      "300": 3,
      "13": 3,
      "55": 3,
      "200": 3,
      "35": 3,
      "nn": 3,
      "101": 3,
      "29": 2,
      "71": 2,
      "i + 1": 2,
      "150": 2,
      "np.floor(np.sqrt(y.size) / 5.1282).astype(int)": 2,
      "28": 2,
      "K": 2,
      "140": 2,
      "c": 2,
      "131": 2,
      "np.floor(np.sqrt(y.size) / nt).astype(int)": 2,
      "60": 2,
      "70": 2,
      "bestn": 2,
      "45": 2,
      "39": 2,
      "600": 2,
      "i_": 2,
      "68": 2,
      "np.floor(np.sqrt(y.size) / ct).astype(int)": 1,
      "51": 1,
      "81": 1,
      "32": 1,
      "len(l)": 1,
      "neighbor": 1,
      "n_neighbor": 1,
      "count": 1,
      "80": 1,
      "int(len(clean_traindata) / 20)": 1,
      "34": 1,
      "320": 1,
      "neighbours": 1,
      "87": 1,
      "73": 1,
      "maxk": 1,
      "22": 1,
      "97": 1,
      "65": 1,
      "x": 1,
      "num": 1,
      "OptK": 1,
      "48": 1,
      "np.floor(np.sqrt(y.size)).astype(int)": 1,
      "clf.best_params_['n_neighbors']": 1,
      "n_cuisine": 1,
      "79": 1,
      "400": 1,
      "numero_vizinhos": 1,
      "37": 1,
      "scores.argmax()": 1,
      "36": 1,
      "chosenK": 1,
      "128": 1,
      "params['n_neighbors_knn']": 1,
      "kvalues[i]": 1,
      "dim": 1,
      "23": 1,
      "knn_n": 1,
      "27": 1,
      "k + 1": 1,
      "k_best": 1,
      "188": 1,
      "x * 100": 1,
      "x * 10 + mscores.index(max(mscores)) * 100": 1,
      "x + mscores2.index(max(mscores2)) * 10": 1,
      "int(round(n_neighbors))": 1,
      "best": 1,
      "np.floor(np.sqrt(y.size) / 8).astype(int)": 1,
      "number_classes": 1,
      "bestk": 1,
      "nearest": 1,
      "np.floor(np.sqrt(y.size) / 5.2632).astype(int)": 1,
      "233": 1,
      "99": 1,
      "j": 1,
      "self.uniform_neighbours_num": 1,
      "self.distance_neighbours_num": 1
    },
    "sklearn.neighbors._classification.KNeighborsClassifier.fit.X": {
      "X_train": 374,
      "X": 140,
      "x_train": 94,
      "train_x_responseCoding": 66,
      "Xtrain": 23,
      "train3[train_index, :]": 15,
      "x": 13,
      "X_tr": 12,
      "train_features": 11,
      "train_X": 10,
      "xtrain": 8,
      "train": 8,
      "trainRI": 7,
      "X_train_cv": 7,
      "train_data": 6,
      "X_train_std": 6,
      "train_x": 6,
      "X_train_res": 4,
      "features": 4,
      "X_train_scaled": 4,
      "X_learn": 4,
      "X_train_pca": 4,
      "XHHI": 4,
      "X_train_flatten": 4,
      "train_x_onehotCoding": 4,
      "x0": 4,
      "xdat": 4,
      "train_merge4": 3,
      "XdataTrain": 3,
      "train[idx_tr][col]": 3,
      "X_pca": 3,
      "np.array(list(neighborhood.keys())).reshape(-1, 1)": 3,
      "Xdf": 3,
      "X_treino": 3,
      "train3p[train_index, :]": 3,
      "X_scaled": 3,
      "X_train1": 3,
      "X_train3": 3,
      "X_train4": 3,
      "X_train_new": 3,
      "x.loc[train_index][cols_important]": 3,
      "train_df": 3,
      "x_train_dum": 2,
      "X_norm": 2,
      "feature_frames['train']": 2,
      "X1": 2,
      "normalized_train_X": 2,
      "trainX": 2,
      "X_train[tr_idx]": 2,
      "train[features]": 2,
      "X_Train_CS": 2,
      "Xhouse": 2,
      "Xtrain2": 2,
      "train_set": 2,
      "X_train_trans": 2,
      "train_f": 2,
      "trainfeature": 2,
      "tsiftdatax_train": 2,
      "X_train_": 2,
      "Xhousehold": 2,
      "UpdatedTrain_X": 2,
      "images": 2,
      "XHHItrain": 2,
      "Xs_train_firep": 2,
      "X_train_trf": 2,
      "e__[:self.lentrain]": 2,
      "X_subset": 2,
      "x[c]": 2,
      "X_trainS": 2,
      "train[['PdDistrict', 'X', 'Y']]": 2,
      "mnist_features_prepared": 2,
      "svd_x_train": 2,
      "Xncr_train": 2,
      "ines": 1,
      "X_trn": 1,
      "normX": 1,
      "tr": 1,
      "temp[['hotel_continent', 'site_name', 'srch_rm_cnt', 'srch_adults_cnt', 'srch_children_cnt', 'srch_destination_id', 'cnt']]": 1,
      "XTrain": 1,
      "train_x_train": 1,
      "gmm_train": 1,
      "trainImage_pca": 1,
      "trainImage": 1,
      "training": 1,
      "vector_tr": 1,
      "train_tfidf": 1,
      "x_train_tf": 1,
      "X_training": 1,
      "scaled_train_X": 1,
      "X_": 1,
      "train[variables]": 1,
      "X_train_prepared": 1,
      "train3": 1,
      "train_X_std": 1,
      "xTrain": 1,
      "Xadult": 1,
      "TrainData": 1,
      "xs_train": 1,
      "features[:700]": 1,
      "X_train[rfe_result]": 1,
      "newCosta.iloc[:, 0:137]": 1,
      "x_traintf": 1,
      "x_traincv": 1,
      "trainFeat": 1,
      "train_s": 1,
      "Xtreino": 1,
      "data_train1": 1,
      "XtrainCR": 1,
      "X_train_cv1": 1,
      "X_train3D": 1,
      "X_train2D": 1,
      "Xcosta": 1,
      "X_train_minmax": 1,
      "xtrn1": 1,
      "slim_train_features[train_index, :]": 1,
      "Xpov": 1,
      "xcosta": 1,
      "Xhh": 1,
      "np.vstack(train_images['pixel_array'])": 1,
      "list1": 1,
      "x_train_augmented": 1,
      "ttextdataemx_train": 1,
      "timagearrayx_train": 1,
      "x_cleaned": 1,
      "X_resampled": 1,
      "train_vector": 1,
      "scaler.transform(train[['day_of_week_encoded', 'pd_district_encoded', 'x', 'y', 'hour']])": 1,
      "datawindnot0[wcol]": 1,
      "X_train_new_2": 1,
      "xpop": 1,
      "XhdbTrain": 1,
      "X_train_Scaled": 1,
      "X_train_scal": 1,
      "index_embeddings": 1,
      "matriz_treino_atributos": 1,
      "X_train_ol": 1,
      "df_train[df_train['Year'] == y1].loc[:, ['Hour', 'IsWeekend', 'Month']]": 1,
      "train_df_x": 1,
      "df_train_x": 1,
      "cr_train_X": 1,
      "Xntrain": 1,
      "X_train2": 1,
      "X2": 1,
      "Xtrain_h": 1,
      "Xtrainadult": 1,
      "nXtrain": 1,
      "trainDataX": 1,
      "ppX_train": 1,
      "ziptrainin": 1,
      "ziptraininxx": 1,
      "X_train_augmented": 1,
      "X_train_norm": 1,
      "x_trainsplit": 1,
      "label_X_train": 1,
      "X_train_aug": 1,
      "pca_X_train": 1,
      "xtrain_tfv": 1,
      "train_feature": 1,
      "final_titanic": 1,
      "Xdt_train": 1,
      "features_v2": 1,
      "X_f_train_scaled": 1,
      "X_subset2": 1,
      "train3[train_index]": 1,
      "monster_train_A[features]": 1,
      "XCostaRica": 1,
      "X1CostaRica": 1,
      "xndf": 1,
      "x_train_3": 1,
      "X_train_reduced": 1,
      "self.x_train": 1,
      "X_train_tranformed": 1,
      "Xcr": 1,
      "xknn": 1,
      "reduce_train[features]": 1,
      "X_2": 1,
      "XCR": 1,
      "x_train_trans": 1,
      "transformed_data_train[train_index]": 1,
      "Xcosta_rican": 1,
      "X_train_count": 1,
      "X_train_tfidf": 1,
      "Xt": 1,
      "trn_x": 1,
      "X[:10]": 1,
      "z[:train_df.shape[0]]": 1,
      "y_pred[:, 96:96 + 20]": 1,
      "x[:40000]": 1,
      "x[:42000]": 1,
      "dfX": 1,
      "train_scaled": 1,
      "X_train_scaled_pca": 1,
      "train_df[selected_col]": 1,
      "trainDataVecs": 1,
      "Xpovertytrain": 1,
      "x_train_std": 1,
      "X_train_scale": 1,
      "x.multiply(r)": 1,
      "X_new": 1,
      "X[300000:]": 1,
      "x_train1": 1,
      "X_train_sub": 1,
      "trainx": 1,
      "data_x": 1,
      "XHouseHold": 1,
      "XcostaRican": 1,
      "Xcrica": 1,
      "df_X": 1,
      "df_train.iloc[ktrain][cols].values": 1,
      "X_gtrain_scaled": 1,
      "k_nearest_train_points": 1,
      "tr_x": 1,
      "x_scaled": 1
    },
    "sklearn.neighbors._classification.KNeighborsClassifier.fit.y": {
      "y_train": 451,
      "y": 157,
      "train_y": 82,
      "Y_train": 62,
      "Ytrain": 23,
      "y_train.values.ravel()": 14,
      "train2.loc[train_index]['target']": 14,
      "Y": 13,
      "ytrain": 13,
      "target": 7,
      "y_tr": 7,
      "trainRL": 7,
      "y_train_cv": 7,
      "train_Y": 6,
      "np.ravel(y_tr)": 6,
      "trainLabels": 5,
      "label": 5,
      "y_train_res": 4,
      "train[idx_tr]['target']": 4,
      "y_learn": 4,
      "YHHI": 4,
      "y[train_index]": 4,
      "y0": 4,
      "YdataTrain": 3,
      "list(neighborhood.values())": 3,
      "Ydf": 3,
      "y_treino": 3,
      "train2p.loc[train_index]['target']": 3,
      "y_train1": 3,
      "y_train3": 3,
      "y_train4": 3,
      "Y_subset": 3,
      "y_train_dum": 2,
      "trainLabel": 2,
      "y_train.toxic": 2,
      "train['signal']": 2,
      "trainY": 2,
      "y_train[tr_idx]": 2,
      "labels": 2,
      "Yhouse": 2,
      "Ytrain2": 2,
      "train_label": 2,
      "y_train_augmented": 2,
      "ttexty_train": 2,
      "tsiftdatay_train": 2,
      "Yhousehold": 2,
      "YHHItrain": 2,
      "y_train_firep": 2,
      "x[T]": 2,
      "YCostaRica": 2,
      "train_labels": 2,
      "train['Resolution']": 2,
      "mnist_labels": 2,
      "class_y_train": 2,
      "Yncr_train": 2,
      "outes": 1,
      "y_trn": 1,
      "normY": 1,
      "train_df['hotel_cluster']": 1,
      "YTrain": 1,
      "train_y_train": 1,
      "train_pred": 1,
      "Y_tr": 1,
      "f_label": 1,
      "y_training": 1,
      "y_": 1,
      "yTrain": 1,
      "Yadult": 1,
      "TrainLabel": 1,
      "ys_train": 1,
      "targets[:700]": 1,
      "newCosta.iloc[:, 137:138]": 1,
      "y_traintf": 1,
      "y_traincv": 1,
      "train_resp": 1,
      "Ytreino": 1,
      "y1_Train_CS": 1,
      "y2_Train_CS": 1,
      "label_train1": 1,
      "YtrainCR": 1,
      "y_train3D": 1,
      "y_train2D": 1,
      "Ycosta": 1,
      "ytrn1": 1,
      "np.ravel(train_y)": 1,
      "train_data.iloc[train_index]['target']": 1,
      "Ypov": 1,
      "ycosta": 1,
      "Yhh": 1,
      "train_images['label']": 1,
      "list3": 1,
      "train[target]": 1,
      "ttextdataemy_train": 1,
      "timagey_train.values": 1,
      "train_data.values[0:, 1]": 1,
      "y_resampled": 1,
      "train_true": 1,
      "train['category_predict']": 1,
      "datawindnot0['windspeed']": 1,
      "y_train_new['surface']": 1,
      "y_train['surface']": 1,
      "ypop": 1,
      "np.ravel(y_train)": 1,
      "YhdbTrain": 1,
      "y_tr[:, 0]": 1,
      "matriz_treino_alvo": 1,
      "df_train[df_train['Year'] == y1].loc[:, 'Category']": 1,
      "train_df_y": 1,
      "df_y": 1,
      "cr_train_Y": 1,
      "Yntrain": 1,
      "y_train2": 1,
      "y1": 1,
      "y2": 1,
      "Ytrain_h": 1,
      "Ytrainadult": 1,
      "trainDataY": 1,
      "ziptrainout": 1,
      "ziptrainoutxx": 1,
      "colors": 1,
      "y_trainsplit": 1,
      "Y_train_aug": 1,
      "labels.values.ravel()": 1,
      "np.argmax(train_y, axis=1)": 1,
      "ml_train": 1,
      "y_train.ravel()": 1,
      "ydt_train": 1,
      "y_f_train": 1,
      "Y_train.values.ravel()": 1,
      "Y_train1": 1,
      "monster_train_A['type']": 1,
      "yndf": 1,
      "y_train_3": 1,
      "y_train_new": 1,
      "self.y_train": 1,
      "Ycr.astype('int32')": 1,
      "yknn": 1,
      "y_train.astype('int')": 1,
      "reduce_train['accuracy_group']": 1,
      "y_2": 1,
      "YCR": 1,
      "y_train.iloc[train_index]": 1,
      "Ycosta_rican": 1,
      "y_fatal_train": 1,
      "y_conf_train": 1,
      "y_train_count": 1,
      "y_train_tfidf": 1,
      "Yt": 1,
      "trn_y": 1,
      "Y[:10]": 1,
      "train_df['label']": 1,
      "train.label[:40000]": 1,
      "train.label[:42000]": 1,
      "dfY": 1,
      "train_target": 1,
      "train_df['isFraud']": 1,
      "Ypovertytrain": 1,
      "Y_completo": 1,
      "Y[300000:]": 1,
      "fakeClasses": 1,
      "Y_train_sub": 1,
      "trainy": 1,
      "data_y": 1,
      "YHouseHold": 1,
      "YcostaRican": 1,
      "new_train.loc[train_index]['target']": 1,
      "Ycrica": 1,
      "df_Y": 1,
      "df_train.iloc[ktrain]['interest_level']": 1,
      "k_nearest_train_labels": 1,
      "tr_y": 1,
      "arr[:, 22]": 1
    },
    "sklearn.neighbors._classification.KNeighborsClassifier.predict.X": {
      "X_test": 236,
      "x_test": 84,
      "test": 31,
      "test_data.drop('RefId', axis=1)": 28,
      "X_train": 21,
      "X": 14,
      "Xtest": 14,
      "X_val": 13,
      "test_data": 11,
      "test_feature": 10,
      "test_X": 9,
      "X_valid": 6,
      "X_cv": 6,
      "X_test1": 5,
      "test_data.drop('Id', axis=1)": 5,
      "test_set": 5,
      "xvalid": 5,
      "X_tr": 5,
      "df_test": 4,
      "knn_test[['X', 'Y']]": 4,
      "X_test_scaled": 4,
      "X_teste": 4,
      "pred_new": 4,
      "timagearrayx_test": 4,
      "tsiftdatax_test": 4,
      "test_x": 4,
      "df.loc[miss, base]": 4,
      "X_valid_cv": 4,
      "test_merge4": 3,
      "train_merge4": 3,
      "train_data": 3,
      "x_valid": 3,
      "X_dev": 3,
      "x_val": 3,
      "df.pickup_longitude.reshape(-1, 1)": 3,
      "df.dropoff_longitude.reshape(-1, 1)": 3,
      "ttextdataemx_test": 3,
      "testfeature": 3,
      "X_test_res": 3,
      "X_test_cv": 3,
      "X_test_new": 3,
      "X_test_pca": 3,
      "x_test_dum": 2,
      "test_fill": 2,
      "norm.transform(test_fill)": 2,
      "[X_test[i]]": 2,
      "df1": 2,
      "normalized_test_X": 2,
      "testX": 2,
      "TestData": 2,
      "x": 2,
      "X_Test_CS": 2,
      "HHItest": 2,
      "dfx": 2,
      "X_test_trans": 2,
      "Xntest": 2,
      "val_X": 2,
      "test_f": 2,
      "tft": 2,
      "testImputed": 2,
      "testRI": 2,
      "X_test_": 2,
      "Xtesthousehold": 2,
      "UpdatedTest_X": 2,
      "X_test_std": 2,
      "X_test3": 2,
      "X_test4": 2,
      "ziptestin": 2,
      "XHHItest": 2,
      "X_test_firep": 2,
      "X_test_trf": 2,
      "X_validation": 2,
      "e__": 2,
      "train[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]": 2,
      "svd_x_test": 2,
      "X_predict": 2,
      "[dtm]": 1,
      "X_test_dataset": 1,
      "ts": 1,
      "x_train_dum": 1,
      "temp_test": 1,
      "XTest": 1,
      "gmm_val": 1,
      "testImage_pca": 1,
      "testImage": 1,
      "testXAxisImg": 1,
      "testing": 1,
      "X_sub": 1,
      "XdataTrain": 1,
      "XdataTest": 1,
      "testdf": 1,
      "test_tfidf": 1,
      "test_data.drop(['Id'], axis=1)": 1,
      "test1": 1,
      "x_test_tf": 1,
      "tst_data": 1,
      "test_df.drop('RefId', axis=1)": 1,
      "test_df": 1,
      "geoprop.loc[miss, base]": 1,
      "X_train_scaled": 1,
      "X_validate_scaled": 1,
      "scaled_test_X": 1,
      "np.c_[xx.ravel(), yy.ravel()]": 1,
      "x[None]": 1,
      "testL": 1,
      "XtestAdult": 1,
      "X_pca_test": 1,
      "xs_test": 1,
      "features[700:]": 1,
      "X_test[rfe_result]": 1,
      "test_features": 1,
      "test.drop(labels=['Id'], axis=1)": 1,
      "newCostaRicaTest": 1,
      "finalTest": 1,
      "x_validtf": 1,
      "x_validcv": 1,
      "xx": 1,
      "X_t": 1,
      "td": 1,
      "testFeatures": 1,
      "x_train": 1,
      "Xteste": 1,
      "sample": 1,
      "Xhousetest": 1,
      "data_val1": 1,
      "XtestCR": 1,
      "X_test_cv1": 1,
      "X_test3D": 1,
      "X_train3D": 1,
      "X_test2D": 1,
      "X_train2D": 1,
      "Xtest3": 1,
      "XtestCosta": 1,
      "X_teste.iloc[0:2]": 1,
      "ntest": 1,
      "xtst1": 1,
      "train_X": 1,
      "XtestPov": 1,
      "xteste": 1,
      "np.vstack(test_images['pixel_array'])": 1,
      "mm1": 1,
      "valid[features]": 1,
      "x_cleaned": 1,
      "data_test": 1,
      "test_vector": 1,
      "scaler.transform(train[['day_of_week_encoded', 'pd_district_encoded', 'x', 'y', 'hour']])": 1,
      "datawind0[wcol]": 1,
      "X_train_": 1,
      "X_test_new_2": 1,
      "teste": 1,
      "XhdbTrain": 1,
      "XhdbTest": 1,
      "test_Scaled": 1,
      "X_train_scal": 1,
      "X_test_scal": 1,
      "sub_data": 1,
      "query_embeddings": 1,
      "matriz_validacao_atributos": 1,
      "df_test[df_test['Year'] == y2].loc[:, ['Hour', 'IsWeekend', 'Month']]": 1,
      "test_df_x": 1,
      "teste_data": 1,
      "cr_test_X": 1,
      "images_test": 1,
      "X_test2": 1,
      "X1": 1,
      "X2": 1,
      "Xtestadult": 1,
      "nXtest": 1,
      "testDataX": 1,
      "ppX_test": 1,
      "X_cv1": 1,
      "X_cv3": 1,
      "X_cv4": 1,
      "elmo_test_new": 1,
      "X_test_norm": 1,
      "normalize(X_pred)": 1,
      "test2": 1,
      "Z_test": 1,
      "label_X_valid": 1,
      "X_vid": 1,
      "pca_X_test": 1,
      "xvalid_tfv": 1,
      "xtest_tfv": 1,
      "Test": 1,
      "dfb_sc_final": 1,
      "atest": 1,
      "Xtesthouse": 1,
      "Xdt_test": 1,
      "test_PCA": 1,
      "test_set_upd": 1,
      "test_set_upd_v2": 1,
      "XtestHHI": 1,
      "X_f_test_scaled": 1,
      "XFINALtest": 1,
      "xtrain": 1,
      "xtest": 1,
      "testdata.drop('Id', axis=1)": 1,
      "Xhat": 1,
      "monster_train_B[features]": 1,
      "XTestCostaRica": 1,
      "X1TestCostaRica": 1,
      "xtest.fillna(0)": 1,
      "test_df.drop('Id', axis=1)": 1,
      "x_train_3": 1,
      "X_test_reduced": 1,
      "self.x_test": 1,
      "X_test_tranformed": 1,
      "XtestCr": 1,
      "X_valS": 1,
      "df_test[df_test.columns[2:]]": 1,
      "raw.drop(raw[raw['Age'].isna() | raw['Fare'].isna()].index, axis=0).drop('Embarked', axis=1)": 1,
      "X.loc[miss_embark].drop('embarked', axis=1)": 1,
      "reduce_train[features]": 1,
      "reduce_test[features]": 1,
      "validate_X": 1,
      "X_test_2": 1,
      "XCRtest": 1,
      "cv.transform(x_test)": 1,
      "new_test": 1,
      "Xtestcosta_rican": 1,
      "X_test_count": 1,
      "X_test_tfidf": 1,
      "z[:train_df.shape[0]]": 1,
      "z[train_df.shape[0]:]": 1,
      "x[40000:42000]": 1,
      "x[42000:]": 1,
      "X_submission": 1,
      "test[test.columns[2:]]": 1,
      "test_scaled": 1,
      "test_df[selected_col]": 1,
      "target": 1,
      "some_digits_prepared": 1,
      "test_prep[5].reshape(1, -1)": 1,
      "row.reshape(1, -1)": 1,
      "train_feature_vectors": 1,
      "test_feature_vectors": 1,
      "Xpovertytest": 1,
      "test_data.drop(labels=['Id'], axis=1)": 1,
      "X_test_knn": 1,
      "x_test_std": 1,
      "test.drop('RefId', axis=1)": 1,
      "test.drop('Id', axis=1)": 1,
      "test_main_scale": 1,
      "X[0:300000]": 1,
      "x_testna": 1,
      "svd_x_train": 1,
      "XTestHouseHold": 1,
      "Xtdf": 1,
      "X_new": 1,
      "XTestcostaRican": 1,
      "Xncr_test": 1,
      "XtestCrica": 1,
      "test_df_X": 1,
      "final_X": 1,
      "X_gtest_scaled": 1,
      "valid_x": 1,
      "k_nearest_test_points": 1,
      "va_x": 1,
      "x_scaled": 1,
      "null": 1
    },
    "sklearn.preprocessing._label.LabelBinarizer.fit.y": {
      "y": 12,
      "class_map_df_root.label": 8,
      "class_map_df_vowel.label": 8,
      "class_map_df_cons.label": 8,
      "y_test": 5,
      "ALL_LABELS": 4,
      "ori_label": 4,
      "train_set[feature]": 3,
      "self.df[c].values": 2,
      "cat_df['category']": 2,
      "y_train": 2,
      "range(len(predictions) + 1)": 2,
      "X": 2,
      "flatdata": 2,
      "train_label": 2,
      "list(Class_dict.values())": 2,
      "train_df['item_value']": 2,
      "Y_train": 2,
      "range(12)": 1,
      "test_feat_1": 1,
      "test_feat_2": 1,
      "test_feat_3": 1,
      "train_target['grapheme_root']": 1,
      "train_target['vowel_diacritic']": 1,
      "train_target['consonant_diacritic']": 1,
      "X['cp_type']": 1,
      "X['cp_dose']": 1,
      "train.iloc[:, 0]": 1,
      "train_sentiment": 1,
      "y_encoded": 1,
      "label": 1,
      "train_df.label": 1,
      "df.category_level1.values": 1,
      "df.category_level2.values": 1,
      "df.category_level3.values": 1,
      "df['brand_name']": 1,
      "df['item_condition_id']": 1,
      "df['shipping']": 1,
      "df['version']": 1,
      "df['len_desc']": 1,
      "train_data['author']": 1,
      "labels": 1,
      "X_train['brand_name'].astype('category')": 1,
      "df['SmokingStatus']": 1,
      "df['Gender']": 1,
      "train_df['author'].as_matrix()": 1,
      "Y": 1,
      "column": 1,
      "data.label": 1,
      "colM": 1,
      "y.values.reshape(-1, 1)": 1,
      "trainY": 1,
      "train_set['author']": 1,
      "self.df[cat].values": 1,
      "X_train['store']": 1,
      "X_train['item']": 1,
      "authors": 1,
      "data['label']": 1,
      "range(len(predictions[0]) + 1)": 1,
      "list(set(int_labels))": 1,
      "X.ravel()": 1,
      "levels": 1,
      "ga_train['group']": 1,
      "data_raw['color']": 1,
      "pd.concat([breedLabelDf['breed1'], breedLabelDf['breed2']])": 1,
      "features['AnimalType']": 1,
      "pd.concat([colorLabelDf['color1'], colorLabelDf['color2']])": 1
    },
    "sklearn.preprocessing._label.LabelBinarizer.transform.y": {
      "test['brand_name']": 13,
      "y": 12,
      "test['item_condition_id']": 10,
      "test['shipping']": 10,
      "y_test": 6,
      "np.array(graphemeLabels)": 6,
      "np.array(vowelLabels)": 6,
      "np.array(consonantLabels)": 6,
      "y_pred": 5,
      "test['main_cat']": 4,
      "test['sub_cat']": 4,
      "test['item_cat']": 4,
      "ori_label": 4,
      "train_data.landmark_id": 3,
      "ground_truth": 3,
      "X": 3,
      "df_test['brand_name']": 3,
      "flattestin": 3,
      "test_data": 3,
      "self.df[c].values": 2,
      "y_train": 2,
      "test['cp_dose']": 2,
      "test[col]": 2,
      "test_df['brand_name']": 2,
      "test_df['item_condition_id']": 2,
      "test_df['shipping']": 2,
      "X_cv['brand_name']": 2,
      "flatdata": 2,
      "flattrainin": 2,
      "flattrainout": 2,
      "train_label": 2,
      "test['subcat_1']": 2,
      "test['subcat_2']": 2,
      "test['subcat_3']": 2,
      "test['cat_1']": 2,
      "test['cat_2']": 2,
      "test['cat_3']": 2,
      "train_df['item_value']": 2,
      "test_df['item_value']": 2,
      "dataset['brand_name']": 2,
      "predictions": 2,
      "colorLabelDf['color1']": 2,
      "colorLabelDf['color2']": 2,
      "breedLabelDf['breed1']": 2,
      "breedLabelDf['breed2']": 2,
      "test_data[col]": 1,
      "y_test_": 1,
      "test_feat_1": 1,
      "test_feat_2": 1,
      "test_feat_3": 1,
      "train_df['grapheme_root']": 1,
      "train_df['vowel_diacritic']": 1,
      "train_df['consonant_diacritic']": 1,
      "test_labels": 1,
      "xtestq": 1,
      "X['cp_type']": 1,
      "test['cp_type']": 1,
      "X['cp_dose']": 1,
      "train.iloc[:, 0]": 1,
      "test.iloc[:, 0]": 1,
      "train_sentiment": 1,
      "test_sentiment": 1,
      "y_encoded": 1,
      "label": 1,
      "price_binner([sum_prices[i] for i in test.index])": 1,
      "quantity_binner([sum_nitems[i] for i in test.index])": 1,
      "[sub_states[idx] for idx in test.index]": 1,
      "[sub_grades[idx] for idx in test.index]": 1,
      "[sub_cats[idx] for idx in test.index]": 1,
      "[sub_subcats[idx] for idx in test.index]": 1,
      "y_val": 1,
      "test_df['cat_dae']": 1,
      "test_df['cat_jung']": 1,
      "test_df['cat_so']": 1,
      "test_rest['brand_name']": 1,
      "testrest_cat['brand_name']": 1,
      "test_cat[col]": 1,
      "df_val['species'].values": 1,
      "test_csr_matrix['item_condition_id']": 1,
      "test_csr_matrix['shipping']": 1,
      "df_test['brand_name'].fillna('nan')": 1,
      "labels": 1,
      "y_classes": 1,
      "X_cv['main_category']": 1,
      "X_cv['sub_category_1']": 1,
      "X_cv['sub_category_2']": 1,
      "X_train['brand_name'].astype('category')": 1,
      "data_test['brand_name']": 1,
      "test_resources[label]": 1,
      "inputdata['SmokingStatus']": 1,
      "inputdata['Gender']": 1,
      "df[category_col].as_matrix()": 1,
      "flattrainin01": 1,
      "flattrainin02": 1,
      "flattrainin03": 1,
      "flattrainin04": 1,
      "flattrainout01": 1,
      "flattrainout02": 1,
      "flattrainout03": 1,
      "flattrainout04": 1,
      "flattraininj1": 1,
      "flattraininj2": 1,
      "flattraininj3": 1,
      "flattraininj4": 1,
      "flattrainoutj1": 1,
      "flattrainoutj2": 1,
      "flattrainoutj3": 1,
      "flattrainoutj4": 1,
      "flattraininx": 1,
      "flattrainoutx": 1,
      "flattraininxx": 1,
      "flattrainoutxx": 1,
      "Y": 1,
      "column": 1,
      "test['cat_top']": 1,
      "test['cat_sub']": 1,
      "test['item']": 1,
      "test_df['cat_1']": 1,
      "test_df['cat_2']": 1,
      "test_df['cat_3']": 1,
      "train.label": 1,
      "val.label": 1,
      "colM": 1,
      "X['Condition2']": 1,
      "train_data['target']": 1,
      "df_test['gencat_name']": 1,
      "df_test['subcat1_name']": 1,
      "df_test['subcat2_name']": 1,
      "y_train.values.reshape(-1, 1)": 1,
      "y_test.values.reshape(-1, 1)": 1,
      "test['gencat_name']": 1,
      "test['subcat1_name']": 1,
      "test['subcat2_name']": 1,
      "trainY": 1,
      "valY": 1,
      "df_test['parent_category_name']": 1,
      "df_test['category_name']": 1,
      "df_test['region']": 1,
      "df_test['city']": 1,
      "df_test['image_top_1']": 1,
      "df_test['user_type']": 1,
      "Y_train": 1,
      "X_train['store']": 1,
      "X_test['store']": 1,
      "X_pred['store']": 1,
      "X_train['item']": 1,
      "X_test['item']": 1,
      "X_pred['item']": 1,
      "authors": 1,
      "data_brand_name": 1,
      "data['label']": 1,
      "X_test[['Country_Region']]": 1,
      "X_test[['Province_State']]": 1,
      "int_labels": 1,
      "int_external_labels": 1,
      "z[:, 0]": 1,
      "z[:, 1]": 1,
      "z[:, 2]": 1,
      "predictions_test": 1,
      "ga_train['group']": 1,
      "labels['str']": 1,
      "dt['color']": 1,
      "features['AnimalType']": 1,
      "featuresTest['AnimalType']": 1
    },
    "sklearn.metrics._classification.classification_report.y_true": {
      "y_test": 1138,
      "y_val": 182,
      "y_train": 124,
      "y_true": 115,
      "y": 107,
      "y_valid": 99,
      "yvalid": 77,
      "Y_test": 63,
      "y_pred": 53,
      "target": 30,
      "y_test_c": 25,
      "targets": 25,
      "test_Y_cat": 23,
      "ytest": 20,
      "Y_train": 19,
      "test_y": 18,
      "test_labels": 18,
      "valid_y": 14,
      "predictions": 13,
      "Y": 13,
      "preds": 13,
      "y_pc_imp_train": 12,
      "Y_true": 11,
      "actual": 11,
      "y_pc_imp_test": 11,
      "labels": 10,
      "y_train_tfidf": 10,
      "pred": 9,
      "prediction": 9,
      "np.argmax(valid_Y, -1)": 9,
      "test_cat": 9,
      "target_test": 9,
      "y_test1": 9,
      "Y_test1": 8,
      "Y_val": 8,
      "yTest": 8,
      "ydt_test": 8,
      "flat_predictions": 7,
      "y_test_res": 7,
      "expected": 7,
      "val_generator.classes": 6,
      "y_test.argmax(axis=1)": 6,
      "test_target": 6,
      "y_test['toxic']": 6,
      "y_test['severe_toxic']": 6,
      "y_test['obscene']": 6,
      "y_test['threat']": 6,
      "y_test['insult']": 6,
      "y_test['identity_hate']": 6,
      "valid_labels": 6,
      "validation_y": 6,
      "val_y": 6,
      "y_validation": 6,
      "test_true": 6,
      "y_dev": 6,
      "titanic_labels": 6,
      "y_mtest": 6,
      "y_f_test": 6,
      "pred_tag": 5,
      "y_validate": 5,
      "true_labels": 5,
      "validation_generator.classes": 5,
      "yy_test": 5,
      "np.argmax(y_val, axis=1)": 4,
      "titanic_train['Survived']": 4,
      "val_gen.classes": 4,
      "Ymod1test": 4,
      "y_test.iloc[:, i]": 4,
      "valid_generator.classes": 4,
      "y_test_df": 4,
      "y_validtf": 4,
      "y_validcv": 4,
      "y_test_data": 4,
      "interp.y_true.numpy()": 4,
      "y_tr": 4,
      "y_val_raw_modf": 4,
      "test_df['category']": 4,
      "y_test_array": 4,
      "y[label]": 4,
      "labels[:lengte]": 4,
      "val_data.labels": 4,
      "ground": 4,
      "np.concatenate(actual_buffer)": 4,
      "y_test_b": 4,
      "train_df['target']": 3,
      "cross_validation_target": 3,
      "svm.predict(x_val)": 3,
      "label": 3,
      "data_y": 3,
      "testlabels": 3,
      "sentiment_test": 3,
      "y_test_cv": 3,
      "train_sample['HasDetections'][mask]": 3,
      "ys_test": 3,
      "y_complete": 3,
      "np.argmax(y_test, axis=1)": 3,
      "y3_valid": 3,
      "y_test_true": 3,
      "np.where(d > 0)[1]": 3,
      "patient_only_train['target'].iloc[val_idx]": 3,
      "labels_test2": 3,
      "y_test_new": 3,
      "y_actuals": 3,
      "preds_df['result']": 3,
      "pred1": 3,
      "y_test.values": 3,
      "y[col]": 3,
      "true": 2,
      "testdata.classes": 2,
      "y_test['Depression']": 2,
      "y_test['Alcohol']": 2,
      "y_test['Suicide']": 2,
      "y_test['Drugs']": 2,
      "ovr.predict(x_val)": 2,
      "clf.predict(x_val)": 2,
      "Y_validation": 2,
      "np.argmax(Y_test, axis=1)": 2,
      "y_test2": 2,
      "test_target_class": 2,
      "preds_df['target']": 2,
      "targets_test": 2,
      "test_df['isup_grade']": 2,
      "all_sentiments_predictions": 2,
      "val_preds": 2,
      "df_pred_tta_ver.label": 2,
      "label_actual": 2,
      "y_folds": 2,
      "testGen.classes": 2,
      "y_val_new": 2,
      "original_class": 2,
      "targets1": 2,
      "targets2": 2,
      "targets0": 2,
      "test_lbls": 2,
      "y_reg_true": 2,
      "valid['toxic']": 2,
      "references": 2,
      "y_truec": 2,
      "rf_valid_cv_appr_results['Real']": 2,
      "data.private": 2,
      "y_teste": 2,
      "target_df.target": 2,
      "reduce_train['accuracy_group'].values": 2,
      "val_labels.values": 2,
      "y_train_drop": 2,
      "Target": 2,
      "ytrain": 2,
      "y_train_csv": 2,
      "y_rus": 2,
      "y_baseline": 2,
      "p": 2,
      "validation_truth": 2,
      "valid_lab": 2,
      "np.argmax(test_Y, -1)": 2,
      "y_res_test": 2,
      "val_labels.cpu()": 2,
      "y_smote_v": 2,
      "classes": 2,
      "my_list": 2,
      "y_30_test": 2,
      "n_b_predictions": 2,
      "pd.get_dummies(y_valid)": 2,
      "Y_training_actual": 2,
      "compare": 2,
      "Y_cls": 2,
      "classifier.predict(x_val)": 2,
      "train_y": 2,
      "Y_valid": 2,
      "pred_results['actual']": 2,
      "clf.best_estimator_.predict(test_X)": 2,
      "y_test_tfidf": 2,
      "FinalTrainLabels": 2,
      "FinalTestLabels": 2,
      "training['target']": 2,
      "y_pred_svc": 2,
      "target[val]": 2,
      "trainSet2['Target']": 2,
      "y_test_pca": 2,
      "y_tru": 2,
      "train_df['cuisine']": 2,
      "valid_df['diagnosis'].astype('int')": 2,
      "yt": 2,
      "y_test9": 2,
      "np.argmax(y_true, axis=1) if AUG_TYPE is 'CUTMIXUP' else y_true": 2,
      "pred2": 2,
      "test_lab": 2,
      "y_train1": 2,
      "rounded_labels": 1,
      "df_test.Score": 1,
      "test_generator.classes": 1,
      "test['Insult']": 1,
      "x_test['AdoptionSpeed']": 1,
      "predict2.Response": 1,
      "Ytrain_df": 1,
      "Y_tr_2": 1,
      "ypred": 1,
      "Y_Test": 1,
      "data['target']": 1,
      "y_train_ce": 1,
      "y_test_ce": 1,
      "df_train['open_channels']": 1,
      "np.argmax(y_val, 1)": 1,
      "testY": 1,
      "y_act": 1,
      "predM": 1,
      "predRF": 1,
      "Predxgb": 1,
      "y_train[j]": 1,
      "y_train[label]": 1,
      "y_train[i]": 1,
      "Ymod1": 1,
      "Y_testl1": 1,
      "complete_outputs": 1,
      "LSTM_y_test": 1,
      "GRU_y_test": 1,
      "sepcnn_y_test": 1,
      "preds[0][1].numpy()": 1,
      "y_true_eval": 1,
      "val.target": 1,
      "objetivo": 1,
      "y_ttest.argmax(axis=1)": 1,
      "list(y_test)": 1,
      "y_true2": 1,
      "y_preds_bool": 1,
      "y_val_ch": 1,
      "y_val_vt": 1,
      "y_val_gr": 1,
      "y_dig": 1,
      "df_pred_tta_base.label": 1,
      "df_pred_tta_avg.label": 1,
      "df_pred_tta_max.label": 1,
      "df_pred_tta_mode.label": 1,
      "df_pred_tta_logits_avg.label": 1,
      "df_pred.actual_label": 1,
      "metrics['y']": 1,
      "clf_final.predict(x_train_work)": 1,
      "val_labels.astype(np.uint8)": 1,
      "image_val.classes": 1,
      "results.Resp": 1,
      "knn_results.label": 1,
      "xgc_results.label": 1,
      "xgc_results.target": 1,
      "results.label": 1,
      "results.cuisine": 1,
      "quora_train.target.values": 1,
      "y_eval_actual": 1,
      "y_true_test": 1,
      "y_true_pred": 1,
      "yv": 1,
      "logreg.predict(x_val)": 1,
      "pred_dec": 1,
      "y_preds": 1,
      "train_toxic['toxic']": 1,
      "train['toxic']": 1,
      "test['Cover_Type']": 1,
      "train_target": 1,
      "self.y_true": 1,
      "ytest[:, 0]": 1,
      "ytest[:, 1]": 1,
      "ytest[:, 2]": 1,
      "ytest[:, 3]": 1,
      "ytest[:, 4]": 1,
      "df_results.true": 1,
      "Y.values": 1,
      "new_y": 1,
      "y_valid['bm']": 1,
      "y_valid['cb']": 1,
      "y_valid['cf']": 1,
      "y_valid['cs']": 1,
      "y_valid['ms']": 1,
      "outputs": 1,
      "valid_cv_results['Real']": 1,
      "train_predict": 1,
      "svm_train_pred": 1,
      "ds_train_pred": 1,
      "rf_train_pred": 1,
      "g_y_vldt": 1,
      "gold_train": 1,
      "true_state[ix]": 1,
      "true_state": 1,
      "test_set['target']": 1,
      "nb_preds": 1,
      "knn_preds": 1,
      "rfc_preds": 1,
      "dt_preds": 1,
      "y_test_vec": 1,
      "Y_valid.argmax(axis=1)": 1,
      "y_test.data": 1,
      "y_pred_norm": 1,
      "model.predict_classes(x_te_w2v)": 1,
      "cm_correct_labels": 1,
      "pred_valid": 1,
      "test_true_labels": 1,
      "inv_true_labels": 1,
      "y_crossval": 1,
      "val_preds_lgb": 1,
      "np.argmax(y, axis=1)": 1,
      "df_train[target]": 1,
      "train.label.values": 1,
      "df_test['cuisine']": 1,
      "First['Man']": 1,
      "Second['Man']": 1,
      "All['Man']": 1,
      "submission_sample['target']": 1,
      "val_df['is_attributed']": 1,
      "y_tst": 1,
      "np.argmax(y_val, axis=-1)": 1,
      "y_": 1,
      "test_truth": 1,
      "y_smote": 1,
      "y_trfull": 1,
      "y_va": 1,
      "Y2_train": 1,
      "train.open_channels": 1,
      "t['y_test']": 1,
      "np.concatenate(tests)": 1,
      "act_y": 1,
      "mnb_predictions": 1,
      "svm_predictions": 1,
      "out_pred": 1,
      "y_grid5": 1,
      "Ytest": 1,
      "test.target": 1,
      "df_train['label']": 1,
      "yreal": 1,
      "val_preds_df['diagnosis']": 1,
      "val_trues": 1,
      "validation_actual": 1,
      "valid_dl.dataset.tensors[2].numpy()": 1,
      "gap_train[['A-coref', 'B-coref', 'NEITHER']]": 1,
      "train_df.label.values": 1,
      "labels_test_2": 1,
      "truth": 1,
      "ycv": 1,
      "y_cv": 1,
      "prediction_generator.classes": 1,
      "pred_nval_y": 1,
      "pred_glove_val_y": 1,
      "labels_test": 1,
      "y_tt": 1,
      "list(test_data.sentiment)": 1,
      "actual_labels": 1,
      "test_set.classes": 1,
      "y_test_final": 1,
      "y_values": 1,
      "yR": 1,
      "set_validacion_ordenado.classes": 1,
      "y_test_as_class": 1,
      "expected_y": 1,
      "label_array": 1,
      "final['label']": 1,
      "y_new": 1,
      "test": 1,
      "test_label": 1,
      "dtree_train_y": 1,
      "labelsTest1": 1,
      "yTrue": 1,
      "res": 1,
      "valid_rfc2[xvad_indx]": 1,
      "valid_dtc2[xvad_indx]": 1,
      "valid_svm2[xvad_indx]": 1,
      "valid_lr2[xvad_indx]": 1,
      "valid_lr4[xvad_indx]": 1,
      "valid_lr3[xvad_indx]": 1,
      "valid_bc[xvad_indx]": 1,
      "valid_adac[xvad_indx]": 1,
      "valid_gbc[xvad_indx]": 1,
      "valid_catc[xvad_indx]": 1,
      "df_test.target": 1,
      "check": 1,
      "gt": 1,
      "Id": 1,
      "train_filtered.surface": 1,
      "validation_label": 1,
      "y_val_actual": 1,
      "train_df['AdoptionSpeed']": 1,
      "label_val_split": 1,
      "np.argmax(train_Y, axis=1)": 1,
      "clf.predict(test_X)": 1,
      "true_labels_list": 1,
      "y_real": 1,
      "train[dep]": 1,
      "test[dep]": 1,
      "y_ts": 1,
      "y_test_classes": 1,
      "train_labels": 1,
      "y_pred_knn": 1,
      "y_pred_ada": 1,
      "y_pred_gnb": 1,
      "y_pred_tree": 1,
      "true_classes": 1,
      "y_valid2": 1,
      "[pred_return(x) for x in predictions]": 1,
      "y_extra_validate": 1,
      "label_test": 1,
      "Y_tes": 1,
      "np.array(predictions)": 1,
      "y_eval": 1,
      "up_test": 1,
      "df_train['sentiment']": 1,
      "df_test['sentiment']": 1,
      "y_test_under": 1,
      "y_test_over": 1,
      "orig": 1,
      "train.target.values": 1,
      "train.target.astype(int).values": 1,
      "test_df['target']": 1,
      "data['payout'].round()": 1,
      "Train_Y": 1,
      "np.argmax(test_y, axis=1)": 1,
      "Y_pred_train": 1,
      "scores": 1,
      "y_test10": 1,
      "y_test3": 1,
      "y_test4": 1,
      "y_test5": 1,
      "y_test6": 1,
      "y_test7": 1,
      "y_test8": 1,
      "gender_submission['Survived']": 1,
      "label_arr": 1,
      "X_train['Label']": 1,
      "X_test['Label']": 1,
      "y_whole": 1,
      "lr.predict(X_val)": 1,
      "lb": 1,
      "pred_binary": 1,
      "predictions_final": 1,
      "pred[calc_idx[1]]": 1,
      "y_fea_2_te_equid": 1,
      "y_test_split": 1,
      "error_df.true.values": 1,
      "Y1_test": 1,
      "Y2_test": 1,
      "test_pred": 1,
      "predict2": 1,
      "train_data['target']": 1,
      "preds.cpu()": 1,
      "df['target']": 1,
      "val_labels": 1,
      "pred_1": 1,
      "pred_2": 1,
      "y_target": 1,
      "dftrain.open_channels": 1,
      "y_ground_truth": 1,
      "target_class": 1,
      "pred_test": 1,
      "df.iloc[test_idx, 1].values": 1,
      "y_pred_nb": 1,
      "y_pred_rf": 1,
      "y_pred_lr": 1,
      "y_pred_lr1": 1,
      "y_predicted": 1,
      "y_predictt": 1
    },
    "sklearn.metrics._classification.classification_report.y_pred": {
      "y_pred": 717,
      "predictions": 238,
      "pred": 139,
      "y_test": 78,
      "y_preds": 50,
      "preds": 46,
      "y_val": 45,
      "predicted": 39,
      "prediction": 32,
      "test_pred": 25,
      "y_predict": 25,
      "pred_y": 24,
      "Y_pred": 22,
      "pred_Y_cat": 21,
      "y_pred_val": 20,
      "y_pred1": 19,
      "y_test_pred": 15,
      "y_preds_res": 14,
      "y_pred_binary": 11,
      "y_val_pred": 11,
      "pred1": 11,
      "rfc_pred": 11,
      "(oof > 0.5).astype(int)": 11,
      "Y_pred_classes": 10,
      "np.argmax(pred_Y, -1)": 9,
      "y_predicted": 9,
      "train_predictions": 9,
      "predict": 9,
      "rf_pred": 9,
      "pred_cat": 9,
      "train_preds": 9,
      "valid_preds": 9,
      "y_pred_class": 9,
      "predicted_classes": 8,
      "y_pred_train": 8,
      "preds_binary": 8,
      "y_pred_xgb": 8,
      "model.predict(X_test)": 8,
      "y_pred_rf": 8,
      "y_pred.round()": 8,
      "clf.predict(train_data)": 8,
      "flat_true_labels": 7,
      "ypred": 7,
      "y_pred2": 7,
      "y_pred3": 7,
      "lr_pred": 7,
      "y_pred4": 6,
      "prediction2": 6,
      "pred_knn": 6,
      "opt_oof.argmax(axis=1)": 6,
      "y_hat.argmax(axis=1)": 5,
      "val_predictions": 5,
      "val_preds": 5,
      "y_hat": 5,
      "pred_rfc": 5,
      "y_final": 5,
      "target_pred": 5,
      "y_train": 5,
      "predicted_class": 5,
      "Y_pred_test": 5,
      "train_y": 5,
      "y_": 5,
      "prediction_probability": 4,
      "predicted_y": 4,
      "predicted_y_test[:, 0]": 4,
      "predicted_y_test[:, 1]": 4,
      "predicted_y_test[:, 2]": 4,
      "predicted_y_test[:, 3]": 4,
      "pred_y_test[:, 0]": 4,
      "pred_y_test[:, 1]": 4,
      "pred_y_test[:, 2]": 4,
      "pred_y_test[:, 3]": 4,
      "predict_val": 4,
      "y_pred_test": 4,
      "yhat": 4,
      "y": 4,
      "val_pred": 4,
      "y_pred_lr": 4,
      "ovr_oof.argmax(axis=1)": 4,
      "predictions[1] > 0.5": 4,
      "y_train_stack_pred": 4,
      "test_y": 4,
      "test_predictions": 4,
      "interp.pred_class.numpy()": 4,
      "y_pred5": 4,
      "Y_pred_class": 4,
      "train.Sentiment": 4,
      "pred_valid_y": 4,
      "target_test": 4,
      "model.predict(preds_val)": 4,
      "cv_pred": 4,
      "y_predit_svc": 4,
      "rf_preds": 4,
      "np.around(y_pred)": 4,
      "validation_predictions": 4,
      "prediction_classes": 4,
      "Y_test": 4,
      "pred_val": 4,
      "y_prediction": 4,
      "y_validation": 4,
      "pred2": 4,
      "Y_pred_train": 4,
      "np.concatenate(results_buffer)": 4,
      "y_pred_b": 4,
      "y_train_pred_rf": 3,
      "y_pred_test_rf": 3,
      "y_pred_test_rf_val": 3,
      "pred_train": 3,
      "predicted_y_test[:, 4]": 3,
      "predicted_y_test[:, 5]": 3,
      "pred_y_test[:, 4]": 3,
      "pred_y_test[:, 5]": 3,
      "y_pred_bnb": 3,
      "valid_predictions": 3,
      "pred3": 3,
      "pred4": 3,
      "pred5": 3,
      "self.oof.argmax(1)": 3,
      "prediction1": 3,
      "knn_pred": 3,
      "pred_svm": 3,
      "best_pred": 3,
      "final_pred": 3,
      "results.y_pred": 3,
      "pred_valid_y_labels": 3,
      "y_pred_gnb": 3,
      "y_pred_valid": 3,
      "preds1": 3,
      "complete_preds": 3,
      "y3_pred.astype('int')": 3,
      "res": 3,
      "kmeans.labels_": 3,
      "y_train_pred": 3,
      "train_pred": 3,
      "y_pred_classes": 3,
      "predicted_result": 3,
      "np.argmax(y_pred, axis=1)": 3,
      "pred_labels": 3,
      "y_rf": 3,
      "model_outputs": 3,
      "y_dt": 3,
      "pred[:len(y)]": 3,
      "answer": 3,
      "y_pred_rfc": 3,
      "val_pred_whole": 3,
      "np.round(regr.predict(X))": 3,
      "y_pred_lstm": 3,
      "pred_mode": 3,
      "ytrain_pred": 3,
      "pred_rf": 3,
      "pred_xgb": 3,
      "preds_df['target']": 3,
      "y_pre": 3,
      "m.predict(xs)": 3,
      "Pred_labels": 2,
      "pred_test": 2,
      "pred_classes": 2,
      "ytest": 2,
      "clf.predict(X_test)": 2,
      "pred_xgb_train": 2,
      "predictions_train": 2,
      "predictions_test": 2,
      "Y_Pred": 2,
      "preds_df['prediction']": 2,
      "log_grid_preds": 2,
      "prediction3": 2,
      "predictions4": 2,
      "rndm_preds": 2,
      "sgb_preds": 2,
      "xgb_preds": 2,
      "logRes": 2,
      "final_clf.predict(X_test)": 2,
      "test_df['isup_grade_pred']": 2,
      "df_test['sentiment']": 2,
      "y_pred_X": 2,
      "lr.predict(X_test)": 2,
      "y_preds_clf": 2,
      "tes": 2,
      "clf.predict(Xtest)": 2,
      "clf2.predict(Xtest)": 2,
      "y_pred_": 2,
      "df_pred_tta_ver.label_pred": 2,
      "label_pred": 2,
      "prediction_folds": 2,
      "pred_Y_cat[0]": 2,
      "y_test1": 2,
      "best_pred_smote": 2,
      "xgc_results.y_pred": 2,
      "predIdxs": 2,
      "y_pred_logreg": 2,
      "lr_tfidf_predict": 2,
      "X_round['open_channels']": 2,
      "preds2": 2,
      "preds0": 2,
      "y_reg_pred": 2,
      "np.round(valid['pred'])": 2,
      "predicted_labels": 2,
      "test_data_label": 2,
      "y_pred6": 2,
      "y_pred7": 2,
      "y_pred8": 2,
      "y_predc.round()": 2,
      "y_pred.astype('int')": 2,
      "model.predict(X_train)": 2,
      "model.predict(X_val)": 2,
      "clf.predict(X)": 2,
      "lgb_oof.argmax(axis=1)": 2,
      "oof.argmax(axis=1)": 2,
      "target_df.predict": 2,
      "y_test_predict": 2,
      "lgbm.predict(X_valid)": 2,
      "exact_predictions": 2,
      "y_valid": 2,
      "pred_fet": 2,
      "lr_predict": 2,
      "y_predict_rfcl": 2,
      "y_predict_lgb": 2,
      "logit.predict(test_features)": 2,
      "out_pred": 2,
      "pred_Y_cat.astype(int)": 2,
      "logits.argmax(1)": 2,
      "inj_clf_cv": 2,
      "pre": 2,
      "cv_predict": 2,
      "y_pred_gbc": 2,
      "y_xgb": 2,
      "new_predictions": 2,
      "y_prima": 2,
      "val_y": 2,
      "y_30_predicted": 2,
      "predict_labels": 2,
      "y_pred_test > t": 2,
      "val_prediction": 2,
      "svm_pred": 2,
      "Y_pred_cls": 2,
      "pred_svc": 2,
      "y_test_svc": 2,
      "Y_pred_labels": 2,
      "pred_results['predicted']": 2,
      "y_pred_bidirectional_lstm": 2,
      "y_pred_cnn": 2,
      "y_pred_lstm_cnn": 2,
      "y_pred_bidirectional_lstm_cnn": 2,
      "pred_log": 2,
      "pred_nb": 2,
      "pred_nbBer": 2,
      "pred_dt": 2,
      "pred_gbm": 2,
      "pred_lgbm": 2,
      "pred_nn": 2,
      "pre_d": 2,
      "random_forest_predicted": 2,
      "y_pred9": 2,
      "Y_val": 2,
      "Predict_Validation_data": 2,
      "y_pred.argmax(axis=1)": 2,
      "bnb_y_": 2,
      "xgb_y_": 2,
      "ensemble_y_": 2,
      "results": 2,
      "y_val_predictions": 2,
      "p_lab": 2,
      "predi": 2,
      "lr_preds": 2,
      "sgd_predictions": 1,
      "train_df['predictions']": 1,
      "pred_combined2": 1,
      "knn_predictions": 1,
      "random_predictions": 1,
      "bayes_predictions": 1,
      "nbg.predict(x_test)": 1,
      "nb_clf.predict(X_test)": 1,
      "mlp_clf.predict(X_test)": 1,
      "lgbc_clf.predict(X_test)": 1,
      "cbc.predict(X_test)": 1,
      "df_test.Sentiment": 1,
      "predict_values": 1,
      "val_test_pred_lgb": 1,
      "predictions_2": 1,
      "pred_1": 1,
      "pred_2": 1,
      "pred_3": 1,
      "pred_4": 1,
      "pred_5": 1,
      "pred_6": 1,
      "pred_7": 1,
      "pred_vc": 1,
      "y_pred_NN": 1,
      "pred_fin": 1,
      "dtest_Y": 1,
      "predict2.Predicted": 1,
      "linear_model_sgd_prediction": 1,
      "clf.predict(X_train)": 1,
      "Y_preds_knn": 1,
      "Y_preds_lg": 1,
      "Y_preds_gnb": 1,
      "Y_preds_dt": 1,
      "Y_preds_rfc": 1,
      "y_pred_test2_final_class": 1,
      "pred_xgb_train_ce": 1,
      "pred_xgb_test_ce": 1,
      "pred_xgb_test": 1,
      "y_pred_val1": 1,
      "y_pred_val2": 1,
      "y_pred_val3": 1,
      "(y_proba_test > my_th).astype(int).argmax(axis=1)": 1,
      "y_predictions": 1,
      "df_train['gm_label']": 1,
      "np.argmax(model.predict(x_val), 1)": 1,
      "PredictedY": 1,
      "Y_prediction": 1,
      "predA": 1,
      "predB": 1,
      "np.argmax(pred_val_y, axis=1)": 1,
      "predictions_rf": 1,
      "nbg.predict(X_test)": 1,
      "dt.predict(X_test)": 1,
      "rf.predict(X_test)": 1,
      "xgb.predict(X_test)": 1,
      "(self.oof > 0.5) * 1": 1,
      "RandomForestModel.predict(X_test)": 1,
      "LGBMModel.predict(X_test)": 1,
      "XGBModel.predict(X_test)": 1,
      "AdaBoostModel.predict(X_test)": 1,
      "RandomForestModel2.predict(X_test)": 1,
      "LGBMModel2.predict(X_test)": 1,
      "XGBModel2.predict(X_test)": 1,
      "AdaBoostModel2.predict(X_test)": 1,
      "votingModel.predict(X_test)": 1,
      "BlenderModel.predict(Blend_X)": 1,
      "LogisticRegressionModel.predict(X_test)": 1,
      "DecisionTreeModel.predict(X_test)": 1,
      "KNeighborsClassifierModel.predict(X_test)": 1,
      "GaussianNBModel.predict(X_test)": 1,
      "RandomForestClassifierModel.predict(X_test)": 1,
      "grid_predictions": 1,
      "xgb_rndm_preds": 1,
      "vc_preds": 1,
      "tf_prediction": 1,
      "new_rf_pred": 1,
      "(preds_train[:, i] > 0.5).astype(int)": 1,
      "pred_label": 1,
      "predictedmod2": 1,
      "predictedmodtr": 1,
      "oof": 1,
      "test_pred11": 1,
      "test_pred1b1": 1,
      "Y_pred1": 1,
      "predicted1": 1,
      "predicted2": 1,
      "predicted2r": 1,
      "predicted3": 1,
      "predicteda": 1,
      "predicteda1": 1,
      "predicteda2": 1,
      "predicteda2a": 1,
      "predicteda4": 1,
      "y_preds2": 1,
      "y_predDT": 1,
      "y_predSVM": 1,
      "y_predLR": 1,
      "pred_KNN": 1,
      "(pd.Series(oof) > 0.5).astype(np.int8)": 1,
      "complete_labels": 1,
      "pred_lsvm": 1,
      "pred_vote": 1,
      "LSTM_yhat_test": 1,
      "GRU_yhat_test": 1,
      "RandomForestClassifier_yhat_test": 1,
      "SGDClassifier_yhat_test": 1,
      "MultinomialNB_yhat_test": 1,
      "sepcnn_yhat_test": 1,
      "(preds[0][0] > i).numpy().astype(int)": 1,
      "predicted_1": 1,
      "y_eval": 1,
      "y_pred_lrcv": 1,
      "(y_pre > thresh).astype(int)": 1,
      "lr.predict(Xtest)": 1,
      "y_predimb_": 1,
      "y_model_hat": 1,
      "gbm_cls.predict(X_tr)": 1,
      "gbm_cls.predict(X_val)": 1,
      "gbm_y_hat": 1,
      "prediccion": 1,
      "preds.argmax(axis=1)": 1,
      "model_rf1.predict(x_valid)": 1,
      "model_rf2.predict(x_valid)": 1,
      "model_rf3.predict(x_valid)": 1,
      "model_extra1.predict(x_valid)": 1,
      "model_extra2.predict(x_valid)": 1,
      "model_extra3.predict(x_valid)": 1,
      "model_extra4.predict(x_valid)": 1,
      "model_extra5.predict(x_valid)": 1,
      "model_extra6.predict(x_valid)": 1,
      "[1 if x > 0.5 else 0 for x in y_pred]": 1,
      "y_preds_bool2": 1,
      "onevsall": 1,
      "logreg": 1,
      "ridge_ch": 1,
      "ridge_vt": 1,
      "ridge_gr": 1,
      "final_res": 1,
      "ahuste_lgbm.predict(X_test)": 1,
      "y_pred_label1[class_names[i]]": 1,
      "y_pred_label2[class_names[i]]": 1,
      "y_pred_label3[class_names[i]]": 1,
      "y_pred_label4[class_names[i]]": 1,
      "preds_dig": 1,
      "train_preds.round()": 1,
      "df_pred_tta_base.label_pred": 1,
      "df_pred_tta_avg.label_pred": 1,
      "df_pred_tta_max.label_pred": 1,
      "df_pred_tta_mode.label_pred": 1,
      "df_pred_tta_logits_avg.label_pred": 1,
      "df_pred.label": 1,
      "metrics['predictions_folds']": 1,
      "truth": 1,
      "mnb_test_model": 1,
      "log_predictions": 1,
      "tree_predictions": 1,
      "rf_predictions": 1,
      "predict_y_t": 1,
      "ys_pred": 1,
      "opt_val_predictions": 1,
      "m.predict(X_valid)": 1,
      "knn_results.y_pred": 1,
      "best_predictions": 1,
      "y_true": 1,
      "y_pred_tree": 1,
      "log_reg.predict(x)": 1,
      "gnb.predict(x)": 1,
      "dt_class.predict(x)": 1,
      "rf_class.predict(x)": 1,
      "lgbm.predict(x_val_new)": 1,
      "xgbc.predict(x_val_new)": 1,
      "y_eval_pred_bin": 1,
      "xgb_prediction": 1,
      "y_test_pred_binary": 1,
      "y_train_pred1": 1,
      "y_train_pred2": 1,
      "y_train_pred3": 1,
      "y_train_pred4": 1,
      "y_train_pred5": 1,
      "y_train_pred6": 1,
      "y_train_maj_vot_pred": 1,
      "y_predmnbtf": 1,
      "y_predmnbcv": 1,
      "y_predlogregtf": 1,
      "y_predlogregcv": 1,
      "y_predlsvctf": 1,
      "y_predlsvccv": 1,
      "y_predknntf": 1,
      "y_predknncv": 1,
      "pred_MNB": 1,
      "cboost.predict(X_valid).reshape(-1)": 1,
      "cboost2.predict(X_valid2).reshape(-1)": 1,
      "np.round(val_prob[:, 1], 0).astype(int)": 1,
      "Y_val_pred": 1,
      "pred_br": 1,
      "pred_ga": 1,
      "pred_ada": 1,
      "valid_pred": 1,
      "np.round(train_toxic['pred'])": 1,
      "np.round(train['pred'])": 1,
      "predict1": 1,
      "predict2": 1,
      "predict3": 1,
      "predict4": 1,
      "predict5": 1,
      "predicted_targets": 1,
      "self.y_pred": 1,
      "y_pred.iloc[:, 0] > best_thresh": 1,
      "yhat[:, 0]": 1,
      "yhat[:, 1]": 1,
      "yhat[:, 2]": 1,
      "yhat[:, 3]": 1,
      "yhat[:, 4]": 1,
      "np.where(df_results.predict > 0.5, 1, 0)": 1,
      "dtrain_predictions": 1,
      "model3.predict(X_arr)": 1,
      "p_pred": 1,
      "y_pred_log": 1,
      "y_fit": 1,
      "predictions_nb": 1,
      "list(submission['target'])": 1,
      "np.argmax(custom_model.predict_generator(valid_generator), axis=1)": 1,
      "y_pred_keras": 1,
      "valid_cv_results['median']": 1,
      "rf_valid_cv_appr_results['avg']": 1,
      "y_pred_XGB": 1,
      "g_y_pred_label_vldt": 1,
      "y_pred_bi": 1,
      "y_pred_tri": 1,
      "pred_val_y": 1,
      "predicts": 1,
      "y_pred_logistic": 1,
      "y_pred_dt": 1,
      "predicions_test": 1,
      "y_train_predicted": 1,
      "cv_y_predicted": 1,
      "y_pred_list": 1,
      "base_y_pred_int": 1,
      "y_pred_ser1": 1,
      "y_pred_ser2": 1,
      "y_pred_ser3": 1,
      "y_pred_ser4": 1,
      "pos_dec_predictions[ix]": 1,
      "pos_dec_predictions": 1,
      "np.argmax(Y_pred, axis=1)": 1,
      "predicted_result_2": 1,
      "baseline.predict(X_test)": 1,
      "predictions_ANN": 1,
      "result": 1,
      "m.predict(X_valid).argmax(axis=1)": 1,
      "predict_y.data": 1,
      "y_predict_pipe_1": 1,
      "y_predict_pipe_2": 1,
      "nn_oof.argmax(axis=1)": 1,
      "results_valid": 1,
      "optR.predict(preds.reshape(-1), coefficients)": 1,
      "regr_to_label(preds.reshape(-1))": 1,
      "rfg.predict(X_valid)": 1,
      "gbm.predict(X_valid)": 1,
      "ada.predict(X_valid)": 1,
      "xgb.predict(X_valid)": 1,
      "cbc.predict(X_valid)": 1,
      "y_pred_max": 1,
      "cm_predictions": 1,
      "y_pred_final": 1,
      "test_pred_labels": 1,
      "inv_pred_labels": 1,
      "yh_crossval": 1,
      "df_train_pred[target]": 1,
      "train_pred_output": 1,
      "df_test['pred']": 1,
      "First['Pred']": 1,
      "Second['Pred']": 1,
      "All['Pred']": 1,
      "submission['target']": 1,
      "baseline_ngram_lr_preds": 1,
      "new_pred": 1,
      "y_pred_valid_f1": 1,
      "predictions_lgbm_valdf": 1,
      "prds": 1,
      "xgbc.predict(X_test)": 1,
      "vc.predict(X_test)": 1,
      "preds_class": 1,
      "tf_preds_class": 1,
      "pred_LR": 1,
      "pred_SVC": 1,
      "pred_MultinomialNB": 1,
      "predict_rfc": 1,
      "predict_nb": 1,
      "predict_svm": 1,
      "RFC_pred_y_bin": 1,
      "LGBM_pred_y_bin": 1,
      "p": 1,
      "nbpred": 1,
      "rf_predicted": 1,
      "xgb_predicted": 1,
      "knn_predicted": 1,
      "scv_predicted": 1,
      "predictions1": 1,
      "q": 1,
      "Y_train_prediction": 1,
      "train['scaled_signal'].clip(0, 10).round()": 1,
      "np.concatenate(predictions)": 1,
      "mlp.predict(x_val)": 1,
      "est.predict(X)": 1,
      "np.round(np.argmax(y_preds, axis=1)).astype(int)": 1,
      "y_val2": 1,
      "tx_valid_df['content_category']": 1,
      "y_preds_log_reg": 1,
      "y_res_preds_log_reg": 1,
      "y_res_pred": 1,
      "y_hat_cnn": 1,
      "test_prediction": 1,
      "val_preds.cpu()": 1,
      "val_preds.argmax(dim=1).cpu()": 1,
      "y_pred_gbc_umap2": 1,
      "umap_only['y_pred_gbc_umap' + str(n_components)]": 1,
      "raw_add_umap['y_pred_gbc_umap' + str(n_components)]": 1,
      "pred.argmax(axis=1)": 1,
      "np.argmax(y, axis=1)": 1,
      "y_svc_pred": 1,
      "val_preds_df['preds']": 1,
      "y_lr": 1,
      "y_pca": 1,
      "pred_oof1": 1,
      "pred_oof2": 1,
      "mean_pred_oof": 1,
      "lr_prediction": 1,
      "validation_prediction": 1,
      "train_preds[['A', 'B', 'NEITHER']]": 1,
      "labels": 1,
      "predicted_naive": 1,
      "predictions_7": 1,
      "y_predAda": 1,
      "pr_svr_s": 1,
      "predictions_xgb": 1,
      "predictions_ada": 1,
      "rez_pr": 1,
      "predicted_y_log": 1,
      "xgboost_yhat": 1,
      "prediction_rfc": 1,
      "nlp_predicted": 1,
      "cv_predicted": 1,
      "prediction.round()": 1,
      "predicoes1": 1,
      "predicoes2": 1,
      "ypredicted": 1,
      "SVMperc": 1,
      "y_predicts": 1,
      "ada_pred": 1,
      "et_pred": 1,
      "probs[:, 1] > 0.01": 1,
      "clf_.predict(X_tr)": 1,
      "clf_.predict(X_tt)": 1,
      "prediction_": 1,
      "y_pred_1d": 1,
      "pred0.round()": 1,
      "pred1.round()": 1,
      "target": 1,
      "predicted_label_list": 1,
      "predictedForest": 1,
      "y_preds1": 1,
      "y_preds3": 1,
      "y_preds4": 1,
      "y_preds6": 1,
      "y_pred_dec_tree": 1,
      "y_predicted_train1": 1,
      "preds_valid_arg": 1,
      "predict_labels1": 1,
      "predict_labels2": 1,
      "predict_labels3": 1,
      "yR_predict": 1,
      "mnb_prediction": 1,
      "predicciones_val": 1,
      "predicted_train": 1,
      "predicted_test": 1,
      "nn1_pred_as_class": 1,
      "MLP1_preds": 1,
      "MLP2_preds": 1,
      "MLP3_preds": 1,
      "MLP4_preds": 1,
      "pref_y_bin": 1,
      "final['label_pred']": 1,
      "y_finalpred": 1,
      "training_predictions1": 1,
      "training_predictions2": 1,
      "ad_pred": 1,
      "log_pred": 1,
      "pred_class": 1,
      "y_rfc": 1,
      "y_tf": 1,
      "y_grdrfc": 1,
      "y_grdsvc": 1,
      "y_preds_xgb": 1,
      "yPred": 1,
      "py_test": 1,
      "validation_pred_rfc2[xvad_indx]": 1,
      "validation_pred_dtc2[xvad_indx]": 1,
      "validation_pred_svm2[xvad_indx]": 1,
      "validation_pred_lr2[xvad_indx]": 1,
      "validation_pred_lr4[xvad_indx]": 1,
      "validation_pred_lr3[xvad_indx]": 1,
      "validation_pred_bc[xvad_indx]": 1,
      "validation_pred_adac[xvad_indx]": 1,
      "validation_pred_gbc[xvad_indx]": 1,
      "validation_pred_catc[xvad_indx]": 1,
      "ypredictions": 1,
      "baseline_predictions": 1,
      "model_predictions": 1,
      "ydt_pred1": 1,
      "ydt_pred2": 1,
      "ydt_pred3": 1,
      "ydt_pred4": 1,
      "ydt_pred5": 1,
      "ydt_pred6": 1,
      "ydt_pred7": 1,
      "ydt_pred8": 1,
      "data_test_labels": 1,
      "pl": 1,
      "pred_logistic_regression": 1,
      "pred_gaussianNB": 1,
      "pred_decision_tree": 1,
      "pred_random_forest": 1,
      "Target": 1,
      "y_pred_gs": 1,
      "y_pred_rs": 1,
      "y_pred_mbet": 1,
      "y_pred_mbrf": 1,
      "y_pred_mxgB": 1,
      "y_mpred_lgbm": 1,
      "train_y_pred": 1,
      "val_y_pred": 1,
      "predictions2": 1,
      "log_reg1.predict(X_test)": 1,
      "log_reg_sig.predict(X_test)": 1,
      "y_f_test_RFC": 1,
      "y_test_NB": 1,
      "y_test_knn": 1,
      "y_test_dt": 1,
      "ensemble_prediction.surface": 1,
      "predt": 1,
      "y_cv": 1,
      "predicted_label": 1,
      "Tr_predict": 1,
      "test_predict": 1,
      "rf_pred_test": 1,
      "rf_pred_train_2": 1,
      "rf_pred_test_2": 1,
      "rf_pred_train_3": 1,
      "rf_pred_test_3": 1,
      "rf_pred_train_4": 1,
      "rf_pred_test_4": 1,
      "rf_pred_train_5": 1,
      "rf_pred_test_5": 1,
      "rf_pred_train_6": 1,
      "rf_pred_test_6": 1,
      "rf_pred_train_7": 1,
      "rf_pred_test_7": 1,
      "rf_pred_train_8": 1,
      "rf_pred_test_8": 1,
      "rf_pred_train_9": 1,
      "rf_pred_test_9": 1,
      "predictions_tuned_linear_svc": 1,
      "predictions_tuned_logistic_regression": 1,
      "predictions_tuned_extra_trees": 1,
      "predictions_tuned_random_forest": 1,
      "pred_tuned_mode": 1,
      "model2.predict(X_test)": 1,
      "rfc_predict": 1,
      "val_predlabels": 1,
      "_preds": 1,
      "preds_list": 1,
      "y_my_preds": 1,
      "XGB_classifier_predict_smote": 1,
      "prediction_train": 1,
      "prediction_train_1": 1,
      "predictions_1": 1,
      "prediction_test": 1,
      "XGB_pred": 1,
      "GBM_pred": 1,
      "RanForpred": 1,
      "treeclfpred": 1,
      "y_pred_dtc": 1,
      "y_pred_bagclf": 1,
      "y_pred_abc": 1,
      "y_pred_xbc": 1,
      "model_pred": 1,
      "Predict": 1,
      "y_base > 0.5": 1,
      "y_upsampling > 0.5": 1,
      "y_downsampling > 0.5": 1,
      "y_upweighting > 0.5": 1,
      "grid.predict(X_valid2)": 1,
      "pred_caret": 1,
      "test_v['Target_Ensembled_predictions']": 1,
      "pred_sklearn": 1,
      "pred_tpot": 1,
      "pred_hyperopt": 1,
      "pred_keras_": 1,
      "pred_mljar": 1,
      "gluon_pred": 1,
      "h2o_pred_": 1,
      "sele_pred": 1,
      "predictions_random": 1,
      "predictions_grid": 1,
      "pred_tabnet": 1,
      "Prediction_LR": 1,
      "Prediction_KNN": 1,
      "model.predict(x_train)": 1,
      "model.predict(x_valid)": 1,
      "pred_y_val": 1,
      "grid.predict(X_test)": 1,
      "model.predict_classes(X_extra_validate)": 1,
      "log_model.predict(X_test)": 1,
      "clf_predict": 1,
      "Y_predict": 1,
      "Y_predict_smote": 1,
      "Y_predict_pca": 1,
      "Y_predict_rf": 1,
      "gender_submission['Survived']": 1,
      "preds_norm": 1,
      "preds_rounded": 1,
      "sub": 1,
      "output.argmax(1)": 1,
      "predIdxs_VGG": 1,
      "predIdxs_ResNet": 1,
      "predIdxs_INResNet2": 1,
      "predIdxs_dense": 1,
      "model.predict(features)": 1,
      "np.argmax(test_targets, axis=1)": 1,
      "np.round(y_pred)": 1,
      "np.around(y_pred, decimals=0)": 1,
      "ypre": 1,
      "df_train['Overall_Sentiment_using_tweet']": 1,
      "df_test['Overall_Sentiment_using_tweet']": 1,
      "y_gb": 1,
      "y_svm": 1,
      "y_pred_under": 1,
      "y_pred_over": 1,
      "pred_gr": 1,
      "a": 1,
      "label_test": 1,
      "y_pred_nb": 1,
      "y_pred_knn": 1,
      "np.argmax(y_score, axis=1)": 1,
      "train[column].values": 1,
      "train[column].astype(int).values": 1,
      "model1.predict(X_train_scaled)": 1,
      "model1.predict(X_test_scaled)": 1,
      "model2.predict(X_train_pca)": 1,
      "model2.predict(X_test_pca)": 1,
      "train_df['predict_threshold']": 1,
      "test_df['predict_threshold']": 1,
      "predict_list[n]": 1,
      "np.argmax(pred_y, axis=1)": 1,
      "DT_cv_pred": 1,
      "RF_cv_pred": 1,
      "lightGBM_pred": 1,
      "Y_train": 1,
      "pred.round()": 1,
      "np.array(np.diag(cosine_scores) > best_thr).astype('int').tolist()": 1,
      "y_pred10": 1,
      "svm.predict(X_train)": 1,
      "rf.predict(X_train)": 1,
      "y_train_predict": 1,
      "p > 0.5": 1,
      "prediction_svc": 1,
      "prediction_lr": 1,
      "nb_clf.predict(train_feature_vectors)": 1,
      "svm_clf.predict(train_feature_vectors)": 1,
      "knn_clf.predict(train_feature_vectors)": 1,
      "logReg_clf.predict(train_feature_vectors)": 1,
      "voting_clf.predict(train_feature_vectors)": 1,
      "gender_submission['prediction']": 1,
      "dt_pred": 1,
      "rf_pre": 1,
      "xg_pred": 1,
      "Rfc.predict(X_tst)": 1,
      "cat.predict(X_tst)": 1,
      "pred_arr": 1,
      "np.argmax(model.predict(word_seq_train), axis=1)": 1,
      "np.argmax(model.predict(word_seq_test), axis=1)": 1,
      "rfc_pred_whole": 1,
      "y_predict1D": 1,
      "op": 1,
      "(y_pred > threshold).astype('int')": 1,
      "y_pred_LGB": 1,
      "y_train[test_index[calc_idx[1]]]": 1,
      "knn_predict": 1,
      "y_pred_split": 1,
      "self.predict(X_test)": 1,
      "train_bool": 1,
      "test_bool": 1,
      "yTestPredLGB": 1,
      "yTestPredXGB": 1,
      "solution['Prediction']": 1,
      "truey": 1,
      "classifier_predict": 1,
      "labels.cpu()": 1,
      "y_pred_validate": 1,
      "probas.argmax(axis=1)": 1,
      "y_pred_class_logreg": 1,
      "y_pred_class_SGD": 1,
      "y_pred_class_rfc": 1,
      "y_predbool": 1,
      "predict_val_bool": 1,
      "predict_val_bool_w": 1,
      "testY": 1,
      "y_predicted[:, 1] > best[0]": 1,
      "pred_mc": 1,
      "prediction_class": 1,
      "y_pred_mnb": 1,
      "predictions['Random Forest']": 1,
      "predictions['Extra Trees']": 1,
      "predictions['Gradient Boosting']": 1,
      "predictions['Ada Boost']": 1,
      "pred[0]": 1,
      "prediction_lr_var": 1,
      "prediction_rfc_var": 1,
      "y2_preds": 1,
      "y_pred_bool": 1,
      "grid_search.best_estimator_.predict(X_test)": 1,
      "train_meta": 1,
      "y_true_tag": 1,
      "y_valid_predict": 1,
      "test_df['vani_pred']": 1,
      "test_df['res_pred']": 1,
      "y_pred_res": 1,
      "grid.best_estimator_.predict(X_test)": 1,
      "logpred": 1,
      "lgbpred": 1,
      "cls.predict(X_train)": 1,
      "cls.predict(X_test)": 1,
      "(val_pred > threshold).astype(int)": 1,
      "(glove_val_pred > glove_threshold).astype(int)": 1,
      "(para_val_pred > para_threshold).astype(int)": 1,
      "(wiki_val_pred > wiki_threshold).astype(int)": 1,
      "(val_prod > threshold_global).astype(int)": 1
    },
    "sklearn.metrics._classification.confusion_matrix.y_true": {
      "y_test": 1354,
      "cm_correct_labels": 231,
      "y_true": 185,
      "y_val": 183,
      "y": 145,
      "y_train": 135,
      "y_valid": 101,
      "Y_test": 79,
      "Y_true": 68,
      "target": 67,
      "y_pred": 64,
      "test_y": 57,
      "act": 29,
      "test_labels": 26,
      "Y": 26,
      "y_test_c": 25,
      "truth": 25,
      "val_y": 24,
      "ts_y": 24,
      "Y_train": 23,
      "Ytest": 23,
      "test_Y_cat": 22,
      "Yt": 22,
      "predictor": 21,
      "pred": 21,
      "actuals": 21,
      "labels": 21,
      "Yv": 21,
      "Ytest1": 20,
      "actual": 18,
      "Y_val": 18,
      "Titanic_test_y": 16,
      "valid_label": 16,
      "vy": 15,
      "valid_df['diagnosis'].astype('int')": 14,
      "y_cv": 14,
      "true": 13,
      "y_test1": 12,
      "y_Val": 12,
      "trueY": 12,
      "yv": 11,
      "valid_labels": 11,
      "np.argmax(valid_Y, -1)": 11,
      "test_lbls": 11,
      "ytest": 11,
      "train['diagnosis'].astype('int')": 11,
      "yvl": 11,
      "t": 10,
      "y_map": 10,
      "y_validation": 10,
      "train_labels": 10,
      "ypred": 9,
      "train_y": 9,
      "list(map(lambda x: np.argmax(x), y_test))": 9,
      "val_labels": 9,
      "yvalid": 9,
      "valid_y": 8,
      "measured": 8,
      "test_cat": 8,
      "merge_df.label.values": 8,
      "predict": 8,
      "scores": 8,
      "y_test_new": 8,
      "ydt_test": 8,
      "train_df['target']": 7,
      "test_target": 7,
      "label": 7,
      "train['target']": 7,
      "y_grand_truth": 7,
      "test.target": 7,
      "test_df['category']": 7,
      "true_labels": 7,
      "y_test_res": 7,
      "result": 7,
      "pseudo_label[target_col]": 7,
      "y_test['toxic']": 6,
      "y_test['severe_toxic']": 6,
      "y_test['obscene']": 6,
      "y_test['threat']": 6,
      "y_test['insult']": 6,
      "y_test['identity_hate']": 6,
      "y_oof": 6,
      "np.argmax(pred_val, axis=1)": 6,
      "val_generator.classes": 6,
      "y_dev": 6,
      "yy_test": 6,
      "y_test.argmax(axis=1)": 6,
      "a1": 6,
      "y_te_equid": 6,
      "y_te_balan": 6,
      "labels.argmax(axis=1)": 5,
      "self.y_train": 5,
      "self.y_test": 5,
      "real": 5,
      "testlabels": 5,
      "gt": 5,
      "y_test_df": 5,
      "validation_labels": 5,
      "targets": 5,
      "y2": 5,
      "error_df.true_class": 5,
      "train_df.iloc[valid_idx][target].values": 5,
      "trainf2_target": 5,
      "valid_labels[:len(fit_valid_label)]": 5,
      "y_test_class": 4,
      "y_test2": 4,
      "list(valid_set['diagnosis'].astype('int64'))": 4,
      "preds": 4,
      "y_act": 4,
      "val_gen.classes": 4,
      "train_df['diagnosis'].astype('int')": 4,
      "valid_generator.classes": 4,
      "y_test_val": 4,
      "np.argmax(y_val, axis=1)": 4,
      "np.argmax(y_test, axis=1)": 4,
      "y_cora_test_": 4,
      "Y_valid": 4,
      "y_val_raw_modf": 4,
      "y_check": 4,
      "test_set.classes": 4,
      "yTest": 4,
      "y_train_pred_final.Survived": 4,
      "true[:m]": 4,
      "YTest": 4,
      "y_pred_r": 4,
      "rounded_labels": 3,
      "y_t": 3,
      "y_valid[:, 1]": 3,
      "data_y": 3,
      "predictedVals": 3,
      "np.argmax(Y_val, axis=1)": 3,
      "y_test_cv": 3,
      "true_y": 3,
      "val_trues": 3,
      "ys_test": 3,
      "np.array(targets0)": 3,
      "y_complete": 3,
      "pred_y": 3,
      "y1_test": 3,
      "y2_test": 3,
      "y3_test": 3,
      "cls_true": 3,
      "predictions": 3,
      "y_cvp": 3,
      "expected": 3,
      "yCV": 3,
      "labels_test2": 3,
      "train_real": 3,
      "org_label": 3,
      "validation_generator.classes": 3,
      "y[label]": 3,
      "result['label']": 3,
      "y[col]": 3,
      "survived": 3,
      "y_test_b": 3,
      "(sub.label == 'FAKE').values": 3,
      "testdata.classes": 2,
      "y_test['Depression']": 2,
      "y_test['Alcohol']": 2,
      "y_test['Suicide']": 2,
      "y_test['Drugs']": 2,
      "Y_validation": 2,
      "labels_for_acc": 2,
      "error_df.True_class": 2,
      "testLabel": 2,
      "Y_test_clf": 2,
      "experData_y.astype(int).astype(str)": 2,
      "test_target_class": 2,
      "validY": 2,
      "y_val.idxmax(axis=1)": 2,
      "preds_df['target']": 2,
      "test_label == n": 2,
      "targets_test": 2,
      "y_pred_val": 2,
      "y_validate": 2,
      "all_sentiments_predictions": 2,
      "np.array(y_val)": 2,
      "errors['truth']": 2,
      "y_dig": 2,
      "y_label": 2,
      "np.round(valid_pred)": 2,
      "bert_pred_df.label.values": 2,
      "xlmbase_pred_df.label.values": 2,
      "xlmlarge_pred_df.label.values": 2,
      "result.argmax(axis=1)": 2,
      "test_generator.classes": 2,
      "actVal": 2,
      "validLabels": 2,
      "y_reg_true": 2,
      "np.argmax(Y_train, axis=1)": 2,
      "y_all": 2,
      "clf.predict(X_test)": 2,
      "test": 2,
      "rr": 2,
      "new_y2": 2,
      "df1[output]": 2,
      "y_teste": 2,
      "test_Y": 2,
      "valid_df.y.values": 2,
      "y_tr": 2,
      "y_test_tfidf": 2,
      "np.argmax(valid_y, axis=1)": 2,
      "truelabels": 2,
      "cm_correct_labels_results[0]": 2,
      "y_Test": 2,
      "y.cpu().numpy()": 2,
      "y4_test": 2,
      "pred_valid": 2,
      "y_train_drop": 2,
      "ytrain": 2,
      "y_train_csv": 2,
      "target.argmax(axis=1)": 2,
      "test_set_y": 2,
      "p": 2,
      "test_labels_mult": 2,
      "validation_truth": 2,
      "y_real": 2,
      "valid_lab": 2,
      "np.argmax(test_Y, -1)": 2,
      "df['Target']": 2,
      "val_labels.cpu()": 2,
      "sent_test": 2,
      "np.array(y_valid)": 2,
      "y_smote_v": 2,
      "data.type": 2,
      "test_df['target']": 2,
      "classes": 2,
      "my_list": 2,
      "y_30_test": 2,
      "val_real": 2,
      "prediction": 2,
      "train_data.label": 2,
      "dig_data.label": 2,
      "n_b_predictions": 2,
      "target_test": 2,
      "true_bio_labels": 2,
      "y.iloc[val_idx].values": 2,
      "y_test_le": 2,
      "actual_label": 2,
      "Y_actual": 2,
      "data_label": 2,
      "y_test_ex": 2,
      "Y_cls": 2,
      "mtrain_[self.lentrain:][self.veld]": 2,
      "sample_sub['target']": 2,
      "pred_results['actual']": 2,
      "y_test_true": 2,
      "training['target']": 2,
      "true_classes": 2,
      "target[val]": 2,
      "trainSet2['Target']": 2,
      "predArr": 2,
      "Y_val_classes": 2,
      "target[val_idx]": 2,
      "y_test_pca": 2,
      "test_image_label": 2,
      "train_df['cuisine']": 2,
      "yteste": 2,
      "target2": 2,
      "[y_i.argmax() for y_i in y_true]": 2,
      "dev_true": 2,
      "y_train_images[0:no_of_train_test]": 2,
      "test_batches.labels": 2,
      "Yvalid": 2,
      "y_test_label": 2,
      "y_val.values": 2,
      "one_hot_labs": 2,
      "cv['target']": 2,
      "test['target']": 2,
      "df_train['is_duplicate']": 2,
      "y_fea_2_te_equid": 2,
      "y_fea_2_te_balan": 2,
      "error_df.true": 2,
      "train.target": 2,
      "test['diagnosis'].astype('int')": 2,
      "target_": 1,
      "target_train": 1,
      "Y_Act_Classes": 1,
      "y_actual": 1,
      "(y.isManPred >= best_idx / 100).astype(int)": 1,
      "y.isManPred": 1,
      "df[op]": 1,
      "np.array([idx2label[v] for v in y_true])": 1,
      "np.array([idx2label[v] for v in validation_df.label.values])": 1,
      "test_generator.labels": 1,
      "labels_list": 1,
      "y_val_actual": 1,
      "x_test['AdoptionSpeed']": 1,
      "y_test['AdoptionSpeed']": 1,
      "df_test['target']": 1,
      "predict2.Response": 1,
      "Ytrain_df": 1,
      "RFMPredict": 1,
      "KNCPredict": 1,
      "Y_tr_2": 1,
      "real_bins": 1,
      "data['target']": 1,
      "y_train_ce": 1,
      "y_test_ce": 1,
      "ytrue": 1,
      "y_truth[idx]": 1,
      "Final_permis.action": 1,
      "Y_Val": 1,
      "y_test.values": 1,
      "y['surface']": 1,
      "testY": 1,
      "test_result": 1,
      "y_pred_log": 1,
      "y_pred_sgd": 1,
      "y_pred_dtc": 1,
      "y_pred_rfc": 1,
      "y_pred_gbdt": 1,
      "y_pred_xgb": 1,
      "y_pred_lgbm": 1,
      "input_data[output_var]": 1,
      "y0": 1,
      "correct_labels": 1,
      "true_label": 1,
      "df_train['target']": 1,
      "y_test_non_category": 1,
      "complete_outputs": 1,
      "df.target": 1,
      "y_true_eval": 1,
      "objetivo": 1,
      "y_true2": 1,
      "y_preds_bool": 1,
      "t[:data_count]": 1,
      "y_train[f:t]": 1,
      "(y_test.iloc[:, 1:] == 1).idxmax(1)": 1,
      "trn_istoxic": 1,
      "clf_final.predict(x_train_work)": 1,
      "tr_true": 1,
      "y_binary_test_raw": 1,
      "sub['Survived']": 1,
      "df_gmm_train['target_gmm']": 1,
      "train_opench[i, :]": 1,
      "df_train_test['diagnosis'].astype('int')": 1,
      "image_val.classes": 1,
      "results.Resp": 1,
      "knn_results.label": 1,
      "xgc_results.label": 1,
      "xgc_results.target": 1,
      "results.label": 1,
      "results.cuisine": 1,
      "test_df[target]": 1,
      "y_te": 1,
      "trainset_test_ybin": 1,
      "val_y.accuracy_group.reset_index(drop=True)": 1,
      "label.accuracy_group.reset_index(drop=True)": 1,
      "y_loc": 1,
      "validation_classes": 1,
      "y_holdout": 1,
      "validation_predictions": 1,
      "y_true_test": 1,
      "list(df_TestData.label)": 1,
      "np.array(targets1)": 1,
      "np.array(targets2)": 1,
      "y_ts": 1,
      "y_true_thresh": 1,
      "tsty": 1,
      "clf.predict(X_train)": 1,
      "ytest[:, 0]": 1,
      "ytest[:, 1]": 1,
      "ytest[:, 2]": 1,
      "ytest[:, 3]": 1,
      "ytest[:, 4]": 1,
      "y_train.argmax(axis=1)[0:len(train_data)]": 1,
      "test_labels.argmax(axis=1)": 1,
      "df_results.true": 1,
      "Y_test_old": 1,
      "y_train_1": 1,
      "y_hat": 1,
      "label_val1": 1,
      "Y_true2": 1,
      "label_val3": 1,
      "valid_cv_results['Real']": 1,
      "rf_valid_cv_appr_results['Real']": 1,
      "expected_labels": 1,
      "y_label.values": 1,
      "data.private": 1,
      "y2_cross": 1,
      "train_dataset.iloc[TRAIN_DATASET_SIZE:, [5]]": 1,
      "train_Y": 1,
      "data['Cover_Type']": 1,
      "valid_y_nn": 1,
      "gold_train": 1,
      "X_test_df_result['Actuals']": 1,
      "valid_df['complex'][:928]": 1,
      "x": 1,
      "sst2_y_test": 1,
      "nb_preds": 1,
      "knn_preds": 1,
      "rfc_preds": 1,
      "dt_preds": 1,
      "valset[:][1]": 1,
      "y_test_vec": 1,
      "Y_valid.argmax(axis=1)": 1,
      "Y_true_classes": 1,
      "y_pred_norm": 1,
      "v_y": 1,
      "y_true[:, i]": 1,
      "time_level_prediction['targets']": 1,
      "true_class": 1,
      "y_train_4": 1,
      "model.predict_classes(x_te_w2v)": 1,
      "corporate_facilities_df['water_stress_area_actual']": 1,
      "y_test_word2vec": 1,
      "mnb_pred": 1,
      "gnb_pred": 1,
      "lr_pred": 1,
      "va_v_trues": 1,
      "va_c_trues": 1,
      "va_g_trues": 1,
      "va_trues[i]": 1,
      "va_trues[0]": 1,
      "va_trues[-2]": 1,
      "va_trues[-1]": 1,
      "y5_test": 1,
      "y6_test": 1,
      "test_df['age'].round(-1).astype(int)": 1,
      "val_labels.values": 1,
      "test_true_labels": 1,
      "inv_true_labels": 1,
      "np.argmax(Y_test, axis=1)": 1,
      "yVal": 1,
      "submit['diagnosis']": 1,
      "valid_.label.values": 1,
      "train.label.values": 1,
      "y_val.sum(axis=1) - 1": 1,
      "First['Man']": 1,
      "Second['Man']": 1,
      "val_df['is_attributed']": 1,
      "train_clean['open_channels']": 1,
      "y_correct": 1,
      "actual_ratings": 1,
      "y_tst": 1,
      "np.argmax(y_val, axis=-1)": 1,
      "y_va": 1,
      "y_Q2": 1,
      "y_test_count": 1,
      "train['label'].astype('int')": 1,
      "data_pred_cls": 1,
      "t1": 1,
      "Y2_test": 1,
      "np.argmax(Y_test.to_numpy(), axis=1)": 1,
      "train.open_channels": 1,
      "act_y": 1,
      "y_testR": 1,
      "tx_valid_df['content_category']": 1,
      "y_grid5": 1,
      "train_df.open_channels": 1,
      "target[df.Id.isin(test2.Id)]": 1,
      "target[~df.Id.isin(test2.Id)]": 1,
      "y_test_fold": 1,
      "y_train_9": 1,
      "X_train['AdoptionSpeed'].values": 1,
      "df_train['label']": 1,
      "ytest[class_name]": 1,
      "yhat": 1,
      "yreal": 1,
      "Y_valid_base": 1,
      "y_real_int": 1,
      "ygt": 1,
      "y1": 1,
      "y_train.iloc[idx_train]": 1,
      "y_train.iloc[idx_validation]": 1,
      "y[val_idx][:, 0]": 1,
      "lb.inverse_transform(y_val)": 1,
      "train_df.label.values": 1,
      "test_predict_df['target']": 1,
      "heads['Target']": 1,
      "labels_test_2": 1,
      "y_b": 1,
      "le.transform(train_df['label'])": 1,
      "y_data": 1,
      "valid_real": 1,
      "train_df_all.outliers": 1,
      "dev_y": 1,
      "et.predict(X_test)": 1,
      "rm_correct_labels": 1,
      "y_true.argmax(axis=1)": 1,
      "prediction_generator.classes": 1,
      "valid_logistic_pred": 1,
      "y_true_for_label": 1,
      "pred_nval_y": 1,
      "pred_glove_val_y": 1,
      "ground_truth": 1,
      "test_data.sentiment.to_list()": 1,
      "error_df.Converted": 1,
      "oof_tars": 1,
      "vali_y": 1,
      "cm_correct_labelsall": 1,
      "cm_correct_labels_n": 1,
      "actual_labels": 1,
      "np.ravel(test_y)": 1,
      "y_test_final": 1,
      "yR": 1,
      "set_validacion_ordenado.classes": 1,
      "true_ent_labels": 1,
      "y_val_glove": 1,
      "y_test_sampled": 1,
      "expected_y": 1,
      "label_array": 1,
      "bnb": 1,
      "dt": 1,
      "num_label": 1,
      "np.argmax(train_labels[val_dataframe.index], axis=1)": 1,
      "dtree_train_y": 1,
      "y_test_lr": 1,
      "y_test_rf": 1,
      "y_test4": 1,
      "y_test_xg1": 1,
      "y_test_xg2": 1,
      "self.target": 1,
      "yTrue": 1,
      "valid_rfc2[xvad_indx]": 1,
      "valid_dtc2[xvad_indx]": 1,
      "valid_svm2[xvad_indx]": 1,
      "valid_lr2[xvad_indx]": 1,
      "valid_lr4[xvad_indx]": 1,
      "valid_lr3[xvad_indx]": 1,
      "valid_bc[xvad_indx]": 1,
      "valid_adac[xvad_indx]": 1,
      "valid_gbc[xvad_indx]": 1,
      "valid_catc[xvad_indx]": 1,
      "df_sub['sentiment_actual'].values": 1,
      "y_train_0": 1,
      "answers[33600:]": 1,
      "df['diagnosis'].astype('int')": 1,
      "Id": 1,
      "'Target'": 1,
      "Y_val_str": 1,
      "Y_val_resnet_str": 1,
      "targs": 1,
      "trainpredi": 1,
      "predt": 1,
      "validation_label": 1,
      "Y_Train.flatten()": 1,
      "Dev_Y.flatten()": 1,
      "X_actual": 1,
      "y_pc_imp_train": 1,
      "model_actual": 1,
      "y_train_true": 1,
      "label_val_split": 1,
      "np.argmax(train_Y, axis=1)": 1,
      "true_label_final": 1,
      "true_labels_list": 1,
      "np.argmax(model.predict(valX), axis=1)": 1,
      "oof['label']": 1,
      "y_test_classes": 1,
      "one_hot_to_dense(y_valid)": 1,
      "y_train_tensor": 1,
      "y_validation_tensor": 1,
      "train['target'].values": 1,
      "base_class": 1,
      "val_truth": 1,
      "[pred_return(x) for x in predictions]": 1,
      "train_generator.classes": 1,
      "Y_train_s": 1,
      "averager_pre": 1,
      "valid": 1,
      "orginal": 1,
      "transform_average_result(preds_origin_test)": 1,
      "y_cross_val": 1,
      "train_labels_concat": 1,
      "valid_labels_concat": 1,
      "Ytest_cnn": 1,
      "y_test_under": 1,
      "y_test_over": 1,
      "orig": 1,
      "y_val.astype(int)": 1,
      "df[human_tag]": 1,
      "act.astype(int)": 1,
      "pred_val": 1,
      "Train_Y": 1,
      "m_train_label": 1,
      "np.argmax(test_y, axis=1)": 1,
      "train_new['diagnosis'].astype('int')": 1,
      "mnist_label_preds": 1,
      "gender_submission['Survived']": 1,
      "_y_test": 1,
      "label_arr": 1,
      "y_whole": 1,
      "target_validation": 1,
      "new_truth": 1,
      "results['y_val']": 1,
      "y_train_lr": 1,
      "label_valid": 1,
      "lb": 1,
      "y_target": 1,
      "valid_target": 1,
      "valid_pred.argmax(axis=1)": 1,
      "np.array(y_test)": 1,
      "labels_test": 1,
      "results.iloc[:, 0]": 1,
      "test_dataloader": 1,
      "real_Y": 1,
      "df_train.target[:6500]": 1,
      "actual_class": 1,
      "OOF_PRED['Survived']": 1,
      "np.argmax(pred_train, axis=1)": 1,
      "np.argmax(pred_test, axis=1)": 1,
      "sm": 1,
      "y[:400000]": 1,
      "validation_targets": 1,
      "targ": 1,
      "yforest_test": 1,
      "original": 1,
      "predict2": 1,
      "loss_ktru": 1,
      "loss_rtru": 1,
      "qwk_ktru": 1,
      "qwk_rtru": 1,
      "optqwk_ktru": 1,
      "optqwk_rtru": 1,
      "pred1": 1,
      "pred_1": 1,
      "sent_pred": 1,
      "y_pred_rf": 1,
      "cm_labels": 1,
      "datatest[clas]": 1,
      "y_ground_truth": 1,
      "y_val_true": 1,
      "df['target']": 1,
      "pred_test": 1,
      "self.y_true['val'][-1]": 1,
      "all_preds['y_true']": 1,
      "y_is9_validation": 1,
      "valid['duration_group']": 1,
      "preds[index_]": 1,
      "predicted": 1,
      "df_validate['Cover_Type'].values": 1,
      "labelsValidate": 1,
      "null": 1
    },
    "sklearn.metrics._classification.confusion_matrix.y_pred": {
      "y_pred": 896,
      "cm_predictions": 225,
      "pred": 219,
      "predictions": 165,
      "y_test": 111,
      "preds": 77,
      "Y_pred_classes": 69,
      "y_preds": 49,
      "predicted": 46,
      "y_predict": 42,
      "y_predicted": 40,
      "Y_pred": 40,
      "y_val_pred": 39,
      "y_pred_class": 36,
      "prediction": 34,
      "predict_y": 28,
      "train_predictions": 28,
      "train_preds": 26,
      "ts_p": 24,
      "y_train_pred": 23,
      "pred_Y_cat": 23,
      "test_pred": 22,
      "pred_val": 22,
      "valid_preds": 21,
      "pred_trn": 21,
      "y_test_pred": 20,
      "y_val": 20,
      "pred1": 20,
      "pred_test1": 20,
      "pred_test": 20,
      "y_pred_test": 17,
      "y_pred_train": 16,
      "predictions.argmax(axis=1)": 16,
      "predict": 16,
      "y_preds_res": 15,
      "vp > last_best_p_th": 15,
      "y_pred_rf": 14,
      "y_pred1": 12,
      "result": 12,
      "y_pre_test": 12,
      "predicted_binary": 12,
      "np.argmax(pred_Y, -1)": 11,
      "p": 11,
      "rfc_pred": 11,
      "predicted_y": 11,
      "pred_labels": 11,
      "Y_pred.round()": 11,
      "y_pred_xgb": 10,
      "y_pred_classes": 10,
      "y_pred2": 10,
      "pred_y": 10,
      "np.argmax(oof_preds, axis=-1)": 10,
      "ypred": 9,
      "y_test_hat": 9,
      "train_pred": 9,
      "model_a_evaluer.predict(X)": 9,
      "preds_binary": 8,
      "yhat": 8,
      "pred_cat": 8,
      "y": 8,
      "np.array(np.diag(cosine_scores) > best_thr).astype('int').tolist()": 8,
      "model2[0].predict(X_test)": 8,
      "test.pred": 7,
      "y_train_hat": 7,
      "val_pred": 7,
      "y_final": 7,
      "predicted_label": 7,
      "(p_tst > th).astype(int)": 7,
      "test_y": 7,
      "predicted_classes": 6,
      "test_generator.labels": 6,
      "best_predictions": 6,
      "pred3": 6,
      "pred4": 6,
      "np.argmax(pred_val_y, axis=1)": 6,
      "prediction2": 6,
      "rf_pred": 6,
      "y_pred_lr": 6,
      "pred2": 6,
      "y_pred.round()": 6,
      "lr.predict(xvl)": 6,
      "y_pred_rfc": 6,
      "predYClasses": 6,
      "y_pred_Classes": 6,
      "out_class": 6,
      "a2": 6,
      "valid_predictions": 5,
      "y_pred4": 5,
      "logist_pred_var": 5,
      "y_pred_knn": 5,
      "model.predict(X_test)": 5,
      "y_hat": 5,
      "y_train['surface']": 5,
      "prediction1": 5,
      "pred_knn": 5,
      "y_pred3": 5,
      "y_train": 5,
      "val_preds": 5,
      "predicted_labels": 5,
      "predicts": 5,
      "y_class": 5,
      "cv_pred": 5,
      "oof[valid_idx].round()": 5,
      "fit_valid_label": 5,
      "valp": 5,
      "pred_cv": 5,
      "pred_val_y > results['threshold']": 5,
      "(predict >= 0.5) * 1": 4,
      "predicted_y_test[:, 0]": 4,
      "predicted_y_test[:, 1]": 4,
      "predicted_y_test[:, 2]": 4,
      "predicted_y_test[:, 3]": 4,
      "pred_y_test[:, 0]": 4,
      "pred_y_test[:, 1]": 4,
      "pred_y_test[:, 2]": 4,
      "pred_y_test[:, 3]": 4,
      "target['surface']": 4,
      "results": 4,
      "y_valid_pred": 4,
      "pred5": 4,
      "dt.predict(X_test)": 4,
      "predictions > p": 4,
      "validation_predictions": 4,
      "y_pred_binary": 4,
      "y_train_stack_pred": 4,
      "valid_pred": 4,
      "res": 4,
      "y_pred_dt": 4,
      "pred_valid_y": 4,
      "target_test": 4,
      "model.predict(preds_val)": 4,
      "y_predit_svc": 4,
      "y_valid": 4,
      "model_pred": 4,
      "Y_predict": 4,
      "pred_rf": 4,
      "prediction_classes": 4,
      "predicted_class": 4,
      "y_pred.argmax(axis=1)": 4,
      "Y_pred_labels": 4,
      "labels": 4,
      "pipeline.predict(X_train)": 4,
      "y_": 4,
      "pred_train": 4,
      "model3[0].predict(X_test)": 4,
      "pred_nbBer": 4,
      "pred[:m]": 4,
      "Y_test": 4,
      "knn_predict": 4,
      "y_predi": 4,
      "y_pred_test_rf": 3,
      "predicted_y_test[:, 4]": 3,
      "predicted_y_test[:, 5]": 3,
      "pred_y_test[:, 4]": 3,
      "pred_y_test[:, 5]": 3,
      "np.argmax(y_prob_val, axis=1)": 3,
      "y_pred_svc": 3,
      "y_pred_bnb": 3,
      "y_p": 3,
      "ytest": 3,
      "knn_pred": 3,
      "validVals": 3,
      "predictionTrain": 3,
      "Y_Pred": 3,
      "s_predicted": 3,
      "preds_df['prediction']": 3,
      "self.oof.argmax(1)": 3,
      "prediction3": 3,
      "y1": 3,
      "val_df['event'].values": 3,
      "np.round(oof_preds)": 3,
      "pred_rfc": 3,
      "pred_svm": 3,
      "logistic.predict(X_test)": 3,
      "test_df['res_pred']": 3,
      "best_pred": 3,
      "final_pred": 3,
      "results.y_pred": 3,
      "pred_valid_y_labels": 3,
      "y_pred_logreg": 3,
      "np.array(preds0)": 3,
      "validation_preds": 3,
      "complete_preds": 3,
      "list(map(lambda x: np.argmax(x), y_hat))": 3,
      "val_df[veld].values": 3,
      "y_true": 3,
      "clf.predict(X_train)": 3,
      "y_testpred": 3,
      "rounded_predictions": 3,
      "opt_oof.argmax(axis=1)": 3,
      "cls_pred": 3,
      "out_pred": 3,
      "y_dt": 3,
      "y_rf_pred": 3,
      "y_gb_pred": 3,
      "dt_pred": 3,
      "result['label_pred']": 3,
      "np.round(regr.predict(X))": 3,
      "svmTestLabels": 3,
      "ytrain_pred": 3,
      "y_pred_nb": 3,
      "y_pred_svm": 3,
      "(pred > 0.5).long().numpy()": 3,
      "pred_binary": 3,
      "y_predictedCV": 3,
      "test_predictions": 3,
      "pred_class": 3,
      "ft": 3,
      "y_pred_b": 3,
      "sub.pred > 0.5": 3,
      "(pred_mean >= 0.5) * 1": 2,
      "y_train_pred_rf": 2,
      "y_pred_test_rf_val": 2,
      "y.playingMan": 2,
      "preds_for_acc": 2,
      "log_pred": 2,
      "pred_classes": 2,
      "y_pred_dtc": 2,
      "predict_val": 2,
      "y_val_predicted": 2,
      "y_test.toxic": 2,
      "testLabel": 2,
      "linear_model_sgd_prediction": 2,
      "clf_rf.predict(X_val)": 2,
      "pred_xgb_train": 2,
      "modelgsGBCtestpre_y.astype(str)": 2,
      "oof": 2,
      "y_predictions": 2,
      "Y_prediction": 2,
      "rf.predict(X_test)": 2,
      "xgb.predict(X_test)": 2,
      "log_grid_preds": 2,
      "predictions4": 2,
      "rndm_preds": 2,
      "sgb_preds": 2,
      "xgb_preds": 2,
      "LR_cnt_pred_val": 2,
      "clf_1.predict(pca_X_test)": 2,
      "clf_4.predict(pca_X_test)": 2,
      "clf_5.predict(pca_X_test)": 2,
      "clf_6.predict(pca_X_test)": 2,
      "clf_7.predict(pca_X_test)": 2,
      "df_test['sentiment']": 2,
      "y_predDT": 2,
      "y_predLR": 2,
      "lr.predict(X_test)": 2,
      "y_preds_clf": 2,
      "tes": 2,
      "test_df['vani_pred']": 2,
      "errors['pred']": 2,
      "ovr_oof.argmax(axis=1)": 2,
      "t_train_pred": 2,
      "train_preds.round()": 2,
      "target_pred": 2,
      "best_pred_smote": 2,
      "xgc_results.y_pred": 2,
      "bert_pred_df.pred_label.values": 2,
      "xlmbase_pred_df.pred_label.values": 2,
      "xlmlarge_pred_df.pred_label.values": 2,
      "majority_voting_df.majority.values": 2,
      "weighted_voting_df.majority.values": 2,
      "averaged_prob_df.pred_label.values": 2,
      "weighted_prob_df.pred_label.values": 2,
      "result.argmax(axis=1)": 2,
      "y_pred_gnb": 2,
      "predVal": 2,
      "pred_valid_binary": 2,
      "y_reg_pred": 2,
      "model.predict_classes(X_train)": 2,
      "model.predict_classes(X_val)": 2,
      "rf.predict(X_valid)": 2,
      "list(map(lambda x: np.argmax(x), y_hat_2))": 2,
      "list(map(lambda x: np.argmax(x), y_hat_3))": 2,
      "Y_pred_lr": 2,
      "uu": 2,
      "y_pred5": 2,
      "y_pred6": 2,
      "y_pred7": 2,
      "y_pred8": 2,
      "kmeans.labels_": 2,
      "xgb_pred": 2,
      "np.argmax(valid_predictions, 1)": 2,
      "y_pred_logistic": 2,
      "predictions_NN_01": 2,
      "np.argmax(preds, axis=1)": 2,
      "clf.predict(train_data)": 2,
      "clf.predict(X)": 2,
      "y_predicted_counts": 2,
      "y_predicted_tfidf": 2,
      "valid_tta_preds.argmax(1).cpu().numpy()": 2,
      "ratin_y_predict": 2,
      "result_test": 2,
      "y_pred > 0.5": 2,
      "pred_fet": 2,
      "Y_prediction_SVM": 2,
      "Y_prediction_RF": 2,
      "pred_val_lbl": 2,
      "y2_predicted": 2,
      "y3_predicted": 2,
      "lr_predict": 2,
      "y_predict_rfcl": 2,
      "y_predict_lgb": 2,
      "test_prediction_mult": 2,
      "Ypred": 2,
      "train_predict": 2,
      "model_outputs": 2,
      "predict_train": 2,
      "logits.argmax(1)": 2,
      "inj_clf_cv": 2,
      "np.array(y_pred)": 2,
      "cv_predict": 2,
      "y_pred_gbc": 2,
      "predict_labels": 2,
      "data.predict_type": 2,
      "test_preds": 2,
      "lgb_pred": 2,
      "y_rf": 2,
      "y_xgb": 2,
      "predicted_index": 2,
      "predictions_l": 2,
      "model.predict(X)": 2,
      "new_predictions": 2,
      "predictions_v2": 2,
      "val_y": 2,
      "y_30_predicted": 2,
      "y_pred_test_vc": 2,
      "target": 2,
      "pred_Dig": 2,
      "rf_predictions": 2,
      "kn_predictions": 2,
      "pred_bio_labels": 2,
      "model4[0].predict(X_test)": 2,
      "y_validation": 2,
      "y_oof[val_idx].round()": 2,
      "np.argmax(val_pred, axis=1)": 2,
      "train_y": 2,
      "oof_label[:, i_w]": 2,
      "yPred": 2,
      "Y_pred_cls": 2,
      "pred.round()": 2,
      "pred[self.lentrain:]": 2,
      "y_train_pred_final.predicted": 2,
      "y_train_pred_final[i]": 2,
      "y_prediction": 2,
      "pred_results['predicted']": 2,
      "knnTestLabels": 2,
      "labels[indeces]": 2,
      "(predicted_y > threshold).astype(int)": 2,
      "(predicted_y > best_threshold).astype(int)": 2,
      "pred_log": 2,
      "pred_nb": 2,
      "pred_dt": 2,
      "pred_lgbm": 2,
      "pred_xgb": 2,
      "pred_nn": 2,
      "trueArr": 2,
      "oof[val_idx].round()": 2,
      "clf_predict": 2,
      "np.argmax(test_pred, axis=1)": 2,
      "y_pred_gb": 2,
      "y_pred_ab": 2,
      "random_forest_predicted": 2,
      "predicao": 2,
      "[y_ip.argmax() for y_ip in y_pred]": 2,
      "dev_pred": 2,
      "original_ytrain[valid_id]": 2,
      "original_ytest": 2,
      "np.around(predictions, decimals=0).argmax(axis=1)": 2,
      "pred_label": 2,
      "Ypredict": 2,
      "model_xgb.predict(data=X_train)": 2,
      "y_pred_temp": 2,
      "one_hot_preds": 2,
      "lrm.predict(x_train)": 2,
      "dt.predict(X_train)": 2,
      "tr_pred": 2,
      "te_pred": 2,
      "pred_test_MNB": 2,
      "y_mNB": 2,
      "clf.predict(X_test)": 2,
      "y_pred_LGB": 2,
      "y_pred_equid": 2,
      "y_pred_balan": 2,
      "DecisionTree_confusion.predict(X_te_equid)": 2,
      "DecisionTree_confusion.predict(X_te_balan)": 2,
      "forest_confusion.predict(X_te_equid)": 2,
      "forest_confusion.predict(X_te_balan)": 2,
      "bnb_y_": 2,
      "xgb_y_": 2,
      "ensemble_y_": 2,
      "class_predict": 2,
      "m.predict(xs)": 2,
      "y_val_predictions": 2,
      "y_pred_forest": 2,
      "gbt.predict(X_train)": 2,
      "y_test_df": 2,
      "best_lgbm.predict(X_test)": 2,
      "output": 2,
      "(valid_score >= 0.5) * 1": 1,
      "(train_pred['valid'] >= 0.5) * 1": 1,
      "train_df['predictions']": 1,
      "y_pred_lgbm": 1,
      "clf.predict(x_t)": 1,
      "clf.predict(x_opt_sc)": 1,
      "knn_predictions": 1,
      "random_predictions": 1,
      "bayes_predictions": 1,
      "y_real": 1,
      "df[i]": 1,
      "gnb_predictions": 1,
      "np.array([idx2label[v] for v in y_pred])": 1,
      "np.array([idx2label[v] for v in validation_df.prediction.values])": 1,
      "val_test_pred_lgb": 1,
      "mlp_predict": 1,
      "predict[col].values": 1,
      "dtree_predict": 1,
      "random_forest_predict": 1,
      "xgboost_pred": 1,
      "y_pred_linear_svc": 1,
      "y_pred_sgd": 1,
      "pred_fin": 1,
      "predict2.Predicted": 1,
      "predicted_bins": 1,
      "baseline_prediction": 1,
      "Y_pred_xgb": 1,
      "Y_pred_lgbm": 1,
      "Y_clf_hat": 1,
      "[random.choice([0, 1, 2]) for i in range(len(Y_test_clf))]": 1,
      "ypredict": 1,
      "y_pred_test2_final_class": 1,
      "pred_xgb_train_ce": 1,
      "pred_xgb_test_ce": 1,
      "pred_xgb_test": 1,
      "y_pred_val1": 1,
      "y_pred_val2": 1,
      "y_pred_val3": 1,
      "(y_proba_test > my_th).astype(int).argmax(axis=1)": 1,
      "Y_CV": 1,
      "ypred_classes": 1,
      "Final_permis.y_pred": 1,
      "y_pred_X_test": 1,
      "y_pred_changed": 1,
      "predictions_train": 1,
      "oof_lgb.argmax(1)": 1,
      "PredictedY": 1,
      "predA": 1,
      "predB": 1,
      "gnb_pred": 1,
      "dtc_pred": 1,
      "svc_pred": 1,
      "logreg_pred": 1,
      "ann_pred": 1,
      "tahmin": 1,
      "y_knn_pred": 1,
      "predictions_rf": 1,
      "random_forest1.predict(X=input_data[input_vars])": 1,
      "nbg.predict(X_test)": 1,
      "(self.oof > 0.5) * 1": 1,
      "valid_pr": 1,
      "grid_predictions": 1,
      "xgb_rndm_preds": 1,
      "vc_preds": 1,
      "tf_prediction": 1,
      "Y_knn_Pred": 1,
      "Y_log_Pred": 1,
      "new_rf_pred": 1,
      "y_pred_SVM": 1,
      "y_pred_RF": 1,
      "y_pred_AdaBoost": 1,
      "y_pred_kNN": 1,
      "y_pred_Bagging": 1,
      "y_pred_ANN": 1,
      "y_pred_LSTM": 1,
      "y_pred_Bi_LSTM": 1,
      "y_pred_val": 1,
      "y_validate": 1,
      "cls_predictions": 1,
      "train_pred_int": 1,
      "y_predict_non_category": 1,
      "y_predSVM": 1,
      "pred_KNN": 1,
      "(pd.Series(oof) > 0.5).astype(np.int8)": 1,
      "complete_labels": 1,
      "pred_lsvm": 1,
      "pred_vote": 1,
      "y_train_pred_clf": 1,
      "y_train_pred_knn": 1,
      "predicted_1": 1,
      "y_pred_pca": 1,
      "y_eval": 1,
      "clf.predict(Xtest)": 1,
      "prediccion": 1,
      "model_rf1.predict(x_valid)": 1,
      "model_rf2.predict(x_valid)": 1,
      "model_rf3.predict(x_valid)": 1,
      "model_extra1.predict(x_valid)": 1,
      "model_extra2.predict(x_valid)": 1,
      "model_extra3.predict(x_valid)": 1,
      "model_extra4.predict(x_valid)": 1,
      "model_extra5.predict(x_valid)": 1,
      "model_extra6.predict(x_valid)": 1,
      "y_preds_bool2": 1,
      "y_hat1": 1,
      "onevsall": 1,
      "logreg": 1,
      "p[:data_count]": 1,
      "preds_dig": 1,
      "model.predict(x)": 1,
      "model.predict(df_dummies[f:t])": 1,
      "pred_ens": 1,
      "np.where(trn_pred >= 0.5, 1, 0)": 1,
      "y_hat_test": 1,
      "y_predR": 1,
      "pred_Y_cat[0]": 1,
      "y_test1": 1,
      "(tr_pred > best_thresh).astype(int)": 1,
      "ys_pred": 1,
      "y_pred_RF_class": 1,
      "cat": 1,
      "hidden_states[i, :]": 1,
      "m.predict(X_valid)": 1,
      "test_labels": 1,
      "knn_results.y_pred": 1,
      "trainset_pred_bin": 1,
      "val_y.accuracy_group.reset_index(drop=True)": 1,
      "label.accuracy_group.reset_index(drop=True)": 1,
      "train_meta_ints": 1,
      "yp": 1,
      "yp_loctest": 1,
      "i.predict(test_X)": 1,
      "y_pred_tree": 1,
      "val_predict.argmax(axis=1)": 1,
      "log_reg.predict(x)": 1,
      "gnb.predict(x)": 1,
      "valid_p": 1,
      "results_holdout": 1,
      "y_val.idxmax(axis=1)": 1,
      "y_test_pred_binary": 1,
      "list(df_CM.prediction)": 1,
      "y_train_pred1": 1,
      "y_train_pred2": 1,
      "y_train_pred3": 1,
      "y_train_pred4": 1,
      "y_train_pred5": 1,
      "y_train_pred6": 1,
      "y_train_maj_vot_pred": 1,
      "smote_prediction": 1,
      "np.array(preds1)": 1,
      "np.array(preds2)": 1,
      "model.predict_classes(x_val)": 1,
      "[np.round(x) for x in train['preds_avg']]": 1,
      "[np.round(x) for x in train['preds_knn']]": 1,
      "[np.round(x) for x in train['preds_svc']]": 1,
      "val_predictions": 1,
      "y_pr": 1,
      "[1 if x > 0.5 else 0 for x in y_train_predicted]": 1,
      "[1 if x > 0.5 else 0 for x in y_dev_predicted]": 1,
      "y_pred_thresh": 1,
      "clf.predict(x_all)": 1,
      "logit.predict(X_valid)": 1,
      "svc.predict(X_valid)": 1,
      "yhat[:, 0]": 1,
      "yhat[:, 1]": 1,
      "yhat[:, 2]": 1,
      "yhat[:, 3]": 1,
      "yhat[:, 4]": 1,
      "list(map(lambda x: np.argmax(x), y_hat_6))": 1,
      "list(map(lambda x: np.argmax(x), y_hat_5))": 1,
      "pred.argmax(axis=1)[0:len(train_data)]": 1,
      "pred_test_labels.argmax(axis=1)": 1,
      "np.where(df_results.predict > 0.5, 1, 0)": 1,
      "rf_predict_resampled": 1,
      "predxg": 1,
      "shelter_dt.predict(X_train_dm)": 1,
      "shelter_dt_20.predict(X_train_dm)": 1,
      "shelter_dt_1.predict(X_train_dm_1)": 1,
      "y_pred_dict[variant_group][variant]['y']['test']": 1,
      "getPredictions(bestThreshold)": 1,
      "getPredictions(0.311984)": 1,
      "np.where(h_preds_.isFraud > 0.5, 1, 0)": 1,
      "y_pred_log": 1,
      "eval_predictions_lg": 1,
      "new_predictions_nb_": 1,
      "random_forest1.predict(X=df1[input])": 1,
      "bost.predict(Xn_test)": 1,
      "rnd.predict(Xn_test)": 1,
      "eclf1.predict(Xn_test)": 1,
      "Y_pred_classes2": 1,
      "rbf_pred": 1,
      "y_pred_keras": 1,
      "valid_cv_results['median']": 1,
      "y_pred_XGB": 1,
      "our_labels": 1,
      "y_label_pred": 1,
      "nb_pred": 1,
      "ad.predict(train_X)": 1,
      "ad.predict(test_X)": 1,
      "word_clf.predict(x_test_word)": 1,
      "char_clf.predict(x_test_char)": 1,
      "combined_predictions": 1,
      "to_np(preds.argmax(dim=-1))": 1,
      "clf.predict(valid_xs)": 1,
      "y_pred_bi": 1,
      "y_pred_tri": 1,
      "pred_val_y": 1,
      "devOut": 1,
      "pred_76": 1,
      "pred_86": 1,
      "pred_56": 1,
      "pred_46": 1,
      "Model_final_ExtraTreesClassifier.predict(X_t3gram_vectorizer_test_)": 1,
      "Model_final_LinearSVC.predict(X_Singt3gram_vectorizer_test_)": 1,
      "Model_final_LogReg.predict(X_t3gram_vectorizer_test_)": 1,
      "Model_final_MLPClassifier.predict(X_t3gram_vectorizer_test_)": 1,
      "X_test_df_result['TARGET']": 1,
      "output_complx": 1,
      "train_preds_class": 1,
      "base_y_pred_int": 1,
      "y_pred_ser1": 1,
      "y_pred_ser2": 1,
      "y_pred_ser3": 1,
      "y_pred_ser4": 1,
      "y_head_lr": 1,
      "y_head_nb": 1,
      "y_preds_rand": 1,
      "Y_pred_val": 1,
      "estimator.predict(X_test)": 1,
      "list(map(lambda v: v > 0.5, y_hat_4))": 1,
      "predictions_ANN": 1,
      "m.predict(X_valid).argmax(axis=1)": 1,
      "Y_valid_pred": 1,
      "predict_y.data": 1,
      "y_predict_pipe_1": 1,
      "y_predict_pipe_2": 1,
      "classes": 1,
      "train_preds.argmax(dim=1)": 1,
      "(t_y >= bt).astype(int)": 1,
      "time_level_prediction['pred'] > 0.06": 1,
      "ln.predict(X_test)": 1,
      "lgb_oof.argmax(axis=1)": 1,
      "oof.argmax(axis=1)": 1,
      "nn_oof.argmax(axis=1)": 1,
      "eval_pred_class": 1,
      "y_predicit_4": 1,
      "np.round(oof_preds).astype(np.int8)": 1,
      "ytrain_df['surface']": 1,
      "y_pred_lgr": 1,
      "y_pred_rc": 1,
      "scores": 1,
      "corporate_facilities_df['water_stress_area_stated']": 1,
      "y_predicted_word2vec": 1,
      "predictions_lgbm_01": 1,
      "va_v_preds": 1,
      "va_c_preds": 1,
      "va_g_preds": 1,
      "va_preds[i]": 1,
      "va_preds[0]": 1,
      "va_preds[-2]": 1,
      "va_preds[-1]": 1,
      "y1_pred": 1,
      "y2_pred": 1,
      "y3_pred": 1,
      "y4_pred": 1,
      "y5_pred": 1,
      "y6_pred": 1,
      "y_predicted.round(-1).astype(int)": 1,
      "exact_predictions": 1,
      "y_pred_final": 1,
      "test_pred_labels": 1,
      "inv_pred_labels": 1,
      "Y_pred_test": 1,
      "df['diagnosis']": 1,
      "Y_pred_train": 1,
      "Y_prediction_KNN": 1,
      "Y_prediction_GaussNB": 1,
      "Y_prediction_DecisionTree": 1,
      "Y_prediction_LR": 1,
      "Y_prediction_NN": 1,
      "true": 1,
      "np.argmax(val_preds, axis=1)": 1,
      "train_pred_output": 1,
      "y_predict.round()": 1,
      "First['Pred']": 1,
      "Second['Pred']": 1,
      "new_pred": 1,
      "predictions_lgbm_valdf": 1,
      "preds_class": 1,
      "tf_preds_class": 1,
      "pred_LR": 1,
      "pred_SVC": 1,
      "pred_MultinomialNB": 1,
      "predicted_ratings": 1,
      "predict_rfc": 1,
      "predict_nb": 1,
      "predict_svm": 1,
      "y4_predicted": 1,
      "RFC_pred_y_bin": 1,
      "LGBM_pred_y_bin": 1,
      "nbpred": 1,
      "rf_predicted": 1,
      "xgb_predicted": 1,
      "knn_predicted": 1,
      "scv_predicted": 1,
      "rf_preds": 1,
      "xg_clas.predict(X_Q2)": 1,
      "predictions_count": 1,
      "predictions_tfidf": 1,
      "results.astype('int')": 1,
      "Y_pred_clf": 1,
      "y_pred_df": 1,
      "data_predicted_cls": 1,
      "predictions1": 1,
      "pred1s": 1,
      "q": 1,
      "Y_test_prediction": 1,
      "y_predd": 1,
      "np.argmax(model.predict(X_test), axis=1)": 1,
      "train['scaled_signal'].clip(0, 10).round()": 1,
      "y_val2": 1,
      "y_train_star": 1,
      "predict_cv": 1,
      "test_prediction": 1,
      "val_preds.cpu()": 1,
      "val_preds.argmax(dim=1).cpu()": 1,
      "train_df.prediction": 1,
      "pred[df.Id.isin(test2.Id)]": 1,
      "pred[~df.Id.isin(test2.Id)]": 1,
      "yCVPredSVM": 1,
      "yCVPredLR": 1,
      "yCVPredRF": 1,
      "y_pred_gbc_umap2": 1,
      "y_pred_gbc_add_umap2": 1,
      "y_pred_gbc_umap6_only": 1,
      "y_pred_gbc_umap6": 1,
      "umap_only['y_pred_gbc_umap' + str(n_components)]": 1,
      "raw_add_umap['y_pred_gbc_umap' + str(n_components)]": 1,
      "pred.argmax(axis=1)": 1,
      "np.argmax(y, axis=1)": 1,
      "x_pred": 1,
      "y_lr": 1,
      "y_pca": 1,
      "y_pred_custom": 1,
      "lr_prediction": 1,
      "Y_valid1_int": 1,
      "y_calc_int": 1,
      "y_valid1_int": 1,
      "classifier.predict(X_val_bow_df)": 1,
      "RFCpreds": 1,
      "XGBpreds": 1,
      "y_pred_with_gaussian": 1,
      "y_pred_with_gaussian_and_deskew": 1,
      "y_gbclf": 1,
      "y_rfclf": 1,
      "y_knclf": 1,
      "y_etclf": 1,
      "y_xgclf": 1,
      "np.round()[:, 0]": 1,
      "np.where(pred_val > threshold, 1, 0)": 1,
      "pipe_vc.predict(X_val)": 1,
      "test_predict_df['prediction']": 1,
      "test_df['prediction']": 1,
      "rf.predict(heads[feats])": 1,
      "final_model.predict(x)": 1,
      "pr_svr_s": 1,
      "predictions_xgb": 1,
      "predictions_ada": 1,
      "rez_pr": 1,
      "predicted_y_log": 1,
      "xgboost_yhat": 1,
      "prediction_rfc": 1,
      "pre_cls": 1,
      "prediction.round()": 1,
      "predicoes1": 1,
      "predicoes2": 1,
      "train_df_all.predict_outliers": 1,
      "np.array([np.argmax(x) for x in oof_preds]).reshape(-1, 1)": 1,
      "np.array([np.argmax(x) for x in model.predict(X_valid)]).reshape(-1, 1)": 1,
      "preds.argmax(1)": 1,
      "SVMperc": 1,
      "rm_predictions": 1,
      "y_pred[:15204, ]": 1,
      "y_preds.argmax(axis=1)": 1,
      "y_predicts": 1,
      "y_pred_for_label": 1,
      "1 * (y_test == 0)": 1,
      "probs[:, 1] > 0.01": 1,
      "Y_train_predicted": 1,
      "lgbm_train > 0.5": 1,
      "y_pred_1d": 1,
      "oof_preds": 1,
      "vali_y_test": 1,
      "ada_pred": 1,
      "count_nb_pred": 1,
      "count_bnb_pred": 1,
      "count_lsvc_pred": 1,
      "count_svc_pred": 1,
      "count_nusvc_pred": 1,
      "count_sgd_pred": 1,
      "count_lr_pred": 1,
      "cm_predictionsall": 1,
      "cm_predictions_n": 1,
      "vgg16_preds": 1,
      "mob_preds": 1,
      "dense_preds": 1,
      "predicted_label_list": 1,
      "y_pred_dec_tree": 1,
      "yhat_classes": 1,
      "y_predicted_train1": 1,
      "y_predicted_train2": 1,
      "y_predicted_train": 1,
      "y_predicted_train3": 1,
      "preds_valid_arg": 1,
      "rf_aug_pred": 1,
      "kn_aug_pred": 1,
      "bag_train_preds": 1,
      "emb_train_preds": 1,
      "yR_predict": 1,
      "mnb_prediction": 1,
      "predicciones_val": 1,
      "predicted_train": 1,
      "predicted_test": 1,
      "pred_ent_labels": 1,
      "log_preds": 1,
      "y_predicted_glove": 1,
      "pref_y_bin": 1,
      "y_val_predict": 1,
      "np.argmax(oof_preds, axis=1)": 1,
      "y_pred_bow2": 1,
      "y_pred_tfidf4": 1,
      "pred_stem_xg": 1,
      "pred_lemma_xg": 1,
      "pred_val_y > best_thresh": 1,
      "self.argmax": 1,
      "y_rfc": 1,
      "y_tf": 1,
      "y_grdrfc": 1,
      "y_grdsvc": 1,
      "lr_pred": 1,
      "dtree_pred": 1,
      "svr_pred": 1,
      "rdf_pred": 1,
      "lgbm_pred": 1,
      "py_test": 1,
      "validation_pred_rfc2[xvad_indx]": 1,
      "validation_pred_dtc2[xvad_indx]": 1,
      "validation_pred_svm2[xvad_indx]": 1,
      "validation_pred_lr2[xvad_indx]": 1,
      "validation_pred_lr4[xvad_indx]": 1,
      "validation_pred_lr3[xvad_indx]": 1,
      "validation_pred_bc[xvad_indx]": 1,
      "validation_pred_adac[xvad_indx]": 1,
      "validation_pred_gbc[xvad_indx]": 1,
      "validation_pred_catc[xvad_indx]": 1,
      "yPredict": 1,
      "predict > 0.5": 1,
      "y_nbcP": 1,
      "y_rfcp": 1,
      "df_sub['sentiment_predicted'].values": 1,
      "ypredictions": 1,
      "dtmodel.predict(x_train)": 1,
      "ydt_pred1": 1,
      "ydt_pred2": 1,
      "ydt_pred3": 1,
      "ydt_pred4": 1,
      "ydt_pred5": 1,
      "ydt_pred6": 1,
      "ydt_pred7": 1,
      "ydt_pred8": 1,
      "predict_train_gs": 1,
      "predict_test_gs": 1,
      "melb_preds": 1,
      "pred_logistic_regression": 1,
      "pred_gaussianNB": 1,
      "pred_svc": 1,
      "pred_decision_tree": 1,
      "pred_random_forest": 1,
      "pred_RFC": 1,
      "pred_KNN_9": 1,
      "pred_GBDT": 1,
      "Target": 1,
      "test['prediction']": 1,
      "Y_pred_conv": 1,
      "Y_pred_conv_res[:, 0]": 1,
      "preds_f": 1,
      "predict1": 1,
      "Y_train": 1,
      "predict_dev": 1,
      "val_y_pred": 1,
      "temp": 1,
      "temp_D": 1,
      "ans1": 1,
      "X_pred": 1,
      "Tr_predict": 1,
      "model_predict": 1,
      "np.where(pred_all_y > 0.5, 1, 0)": 1,
      "rfc_predict": 1,
      "val_predlabels": 1,
      "valid_y": 1,
      "real": 1,
      "pre_label_final": 1,
      "preds_list": 1,
      "np.argmax(valY, axis=1)": 1,
      "y_my_preds": 1,
      "y_test_pred_sgd": 1,
      "classifier.predict(train_vector)": 1,
      "oof['preds']": 1,
      "prediction4": 1,
      "prediction5": 1,
      "prediction6": 1,
      "y_pred_bagclf": 1,
      "y_pred_abc": 1,
      "y_pred_xbc": 1,
      "y_dev_pred": 1,
      "stack_ytrain_pred": 1,
      "np.array(ytrain_pred)": 1,
      "y_valid_pred_class": 1,
      "np.argmax(y_pred.detach().numpy(), axis=1)": 1,
      "pred_glove_train_y > thresh_train": 1,
      "pred_glove_val_y > thresh_valid": 1,
      "pred_caret": 1,
      "test_v['Target_Ensembled_predictions']": 1,
      "pred_sklearn": 1,
      "pred_tpot": 1,
      "pred_hyperopt": 1,
      "pred_keras_": 1,
      "pred_mljar": 1,
      "gluon_pred": 1,
      "h2o_pred_": 1,
      "sele_pred": 1,
      "val_prediction": 1,
      "model1.predict(test_x)": 1,
      "model2.predict(test_x)": 1,
      "log_model.predict(X_test)": 1,
      "Y_pred_Fine_tune_HyperParmeters": 1,
      "pred21": 1,
      "pred22": 1,
      "preds_random": 1,
      "predx": 1,
      "y_predx": 1,
      "Y_predict_smote": 1,
      "Y_predict_pca": 1,
      "Y_predict_rf": 1,
      "Y_pred1": 1,
      "(pred > thr).long().numpy()": 1,
      "sub_preds": 1,
      "np.round(oof)": 1,
      "pred_v1": 1,
      "pred_v2": 1,
      "pred_v3": 1,
      "model.predict(features)": 1,
      "binary_preds": 1,
      "np.around(y_pred, decimals=0)": 1,
      "y_ran_pred": 1,
      "np.argmax(train_preds_concat, axis=1)": 1,
      "np.argmax(valid_preds_concat, axis=1)": 1,
      "cm_pre": 1,
      "RFC_predict": 1,
      "np.argmax(Ypredict_cnn, axis=1)": 1,
      "y_gb": 1,
      "y_svm": 1,
      "y_pred_under": 1,
      "y_pred_over": 1,
      "pred_gr": 1,
      "a": 1,
      "np.argmax(y_score, axis=1)": 1,
      "y_training_pred": 1,
      "model1.predict(X_train_scaled)": 1,
      "model1.predict(X_test_scaled)": 1,
      "model2.predict(X_train_pca)": 1,
      "model2.predict(X_test_pca)": 1,
      "train_df['predict_threshold']": 1,
      "test_df['predict_threshold']": 1,
      "df[pred_tag]": 1,
      "pred.astype(int)": 1,
      "pred_valid": 1,
      "predict_list[n]": 1,
      "pred_val1": 1,
      "pred_val2": 1,
      "np.argmax(pred_y, axis=1)": 1,
      "DT_cv_pred": 1,
      "RF_cv_pred": 1,
      "lightGBM_pred": 1,
      "lr_y_pred": 1,
      "lr_tuned_y_pred": 1,
      "rf_y_pred": 1,
      "rf_tuned_y_pred": 1,
      "lgbm_y_pred": 1,
      "lgbm_tuned_y_pred": 1,
      "mnist_labels": 1,
      "y_train_predict": 1,
      "prediction_svc": 1,
      "prediction_lr": 1,
      "gender_submission['prediction']": 1,
      "rf_pre": 1,
      "xg_pred": 1,
      "_y_prediction": 1,
      "pred_arr": 1,
      "rfc_pred_whole": 1,
      "classify_accuracy_group(gbm.predict(features_validation), 0.9999, 1.5, 2.19)": 1,
      "new_preds": 1,
      "results['y_hat']": 1,
      "clf.predict(X_train_lr)": 1,
      "predY": 1,
      "preds_valid": 1,
      "preds1": 1,
      "y_predict1D": 1,
      "op": 1,
      "gs": 1,
      "y_val_predicted3": 1,
      "y_val_predicted4": 1,
      "test_res": 1,
      "oof_reg_preds": 1,
      "prediction_ans": 1,
      "valid['label'][:200]": 1,
      "y_pred_tags": 1,
      "y_pred_list": 1,
      "y_predict_transform": 1,
      "RandomForest_Predictions": 1,
      "[1 if pred >= class_thresh else 0 for pred in y_pred_proba]": 1,
      "results.iloc[:, 1]": 1,
      "y_pred_valid": 1,
      "lineal_pred": 1,
      "np.round(OOF_PRED['EnsPred'])": 1,
      "np.argmax(y_val_pred, axis=1)": 1,
      "df_train['Target'].values": 1,
      "df_test['Target'].values": 1,
      "sub['target']": 1,
      "target_pre": 1,
      "y_hat_labels_sum": 1,
      "final_predictions": 1,
      "predicted_lables": 1,
      "clf_pipe.predict(X_test)": 1,
      "Pred_train": 1,
      "yforest_predicted": 1,
      "y_pred_cnn": 1,
      "yTestPredLGB": 1,
      "yTestPredXGB": 1,
      "np.where(train_preds > 0.5, 1, 0)": 1,
      "truey": 1,
      "log_predict": 1,
      "test_preds['KNN']": 1,
      "pred_valid.pred": 1,
      "y_pred_class_logreg": 1,
      "y_pred_class_SGD": 1,
      "y_pred_class_rfc": 1,
      "np.round(loss_kpre)": 1,
      "np.round(loss_rpre)": 1,
      "np.round(qwk_kpre)": 1,
      "np.round(qwk_rpre)": 1,
      "optqwk_kpre": 1,
      "optqwk_rpre": 1,
      "model_LR.predict(X_valid)": 1,
      "sent_test": 1,
      "cm_preds": 1,
      "classifier1.predict(X_train)": 1,
      "classifier1.predict(X_test)": 1,
      "prediction[:, idx]": 1,
      "Y_pred_rand": 1,
      "y_pred_k": 1,
      "label['surface']": 1,
      "y_pred_mnb": 1,
      "predictions['Random Forest']": 1,
      "predictions['Extra Trees']": 1,
      "predictions['Gradient Boosting']": 1,
      "predictions['Ada Boost']": 1,
      "pred[0]": 1,
      "round(df['pred'])": 1,
      "prediction_lr_var": 1,
      "prediction_rfc_var": 1,
      "y2_preds": 1,
      "y_pred_res": 1,
      "RFC.predict(X_test)": 1,
      "y_pred_rbf": 1,
      "grid.predict(X_test)": 1,
      "self.y_pred['val'][-1]": 1,
      "all_preds['y_pred_bin']": 1,
      "logpred": 1,
      "lgbpred": 1,
      "y[[index_]]": 1,
      "labelsSampled[validate_idx]": 1,
      "label_scaler.inverse_transform(predicted.reshape(-1, 1)).flatten().astype(np.int32)": 1,
      "np.array(predicted_classes).reshape((-1, 1))": 1,
      "values": 1,
      "y_pred_bin": 1,
      "y_train_lr": 1,
      "y_train_svc": 1,
      "y_train_rf": 1,
      "y_train_gb": 1,
      "y_train_xgb": 1,
      "y_train_knn": 1,
      "null": 1
    },
    "sklearn.tree._classes.DecisionTreeClassifier.fit.X": {
      "X_train": 385,
      "x_train": 117,
      "X": 84,
      "x": 26,
      "train_X": 24,
      "train_x": 18,
      "train.drop(['id', 'target'], axis=1)": 13,
      "train_data": 12,
      "dtm": 6,
      "xtrain": 6,
      "train": 6,
      "X_tr": 5,
      "X_train_dm": 5,
      "X_train_res": 4,
      "features": 4,
      "features_one": 4,
      "train[features]": 4,
      "trainpara['data']": 4,
      "X_train_sm": 4,
      "train_merge4": 3,
      "x1": 3,
      "xTrain": 3,
      "X_learn": 3,
      "X_Train": 3,
      "train_df[feat]": 3,
      "features_train": 3,
      "X_train_std": 3,
      "train_x_sparse": 2,
      "X_train.values.reshape(-1, 1)": 2,
      "X_train_scaled": 2,
      "train_tfidf": 2,
      "normalized_train_X": 2,
      "data_train": 2,
      "X_treino": 2,
      "x_train1": 2,
      "treino.drop(['target'], axis=1)": 2,
      "X_train_trans": 2,
      "trainfeature": 2,
      "tsiftdatax_train": 2,
      "train_data[features]": 2,
      "bow_train": 2,
      "train_features": 2,
      "trainX": 2,
      "x_train_holdout": 2,
      "data_train_t": 2,
      "x_train_3": 2,
      "X_tr_equid": 2,
      "X_tr_balan": 2,
      "X_train.Age.to_frame()": 1,
      "normX": 1,
      "a": 1,
      "lsa_scores_train": 1,
      "train_t_predictor": 1,
      "predictor": 1,
      "trainImage_pca": 1,
      "trainImage": 1,
      "np.reshape(X_learn_clf, (X_learn_clf.shape[0], 1))": 1,
      "data": 1,
      "X_over": 1,
      "train_ind": 1,
      "train[:, :-1]": 1,
      "X_training": 1,
      "STDTrain": 1,
      "scaled_train_X": 1,
      "xtrain_count": 1,
      "train[variables]": 1,
      "X_train_prepared": 1,
      "text": 1,
      "X.loc[:, [col]]": 1,
      "titanic": 1,
      "Xs": 1,
      "Xp": 1,
      "df_comb[cols]": 1,
      "df_comb[cols2]": 1,
      "x_train_nonan": 1,
      "TrainData": 1,
      "X_orig_train": 1,
      "df_train": 1,
      "indTrain": 1,
      "X_train_vect": 1,
      "X_train_vect_TFID": 1,
      "X_f_train[[feature]]": 1,
      "X_train_dm_1": 1,
      "X_train.todense()": 1,
      "table_tf1": 1,
      "train_data['x']": 1,
      "images_resized": 1,
      "train_feature": 1,
      "X[col].values.reshape(-1, 1)": 1,
      "scaler.fit_transform(X_train)": 1,
      "train[pd.notnull(train[num_features[f]])][features2]": 1,
      "train_explan": 1,
      "ttextdataemx_train": 1,
      "train_vector": 1,
      "training_set[features].iloc[train_indices]": 1,
      "bag_of_words": 1,
      "X_train_": 1,
      "dw.drop(columns='Target')": 1,
      "self.train_data": 1,
      "featurevals": 1,
      "preprocessed_train_X": 1,
      "X_train_new_2": 1,
      "df_trn": 1,
      "train[features1]": 1,
      "images": 1,
      "data_train[feature_cols]": 1,
      "X_train_ol": 1,
      "df.drop('target', axis=1)": 1,
      "x_train[:2500].drop('wheezy-copper-turtle-magic', axis=1)": 1,
      "sub_train": 1,
      "X_train_sc": 1,
      "train.drop('Cover_Type', axis=1)": 1,
      "X_train[columns]": 1,
      "data[params]": 1,
      "newTrain": 1,
      "count_train": 1,
      "label_X_train": 1,
      "X.drop(columns=cols_with_nulls)": 1,
      "bow_train2": 1,
      "x_train_tfidf_vec[:10000]": 1,
      "x_train_data": 1,
      "X_train_tfidf": 1,
      "xtrain_tfv": 1,
      "X_train_tfidf_stem_dt": 1,
      "X_train_tfidf_lemma_dt": 1,
      "X_train_pca": 1,
      "XX_train": 1,
      "trainf1_input": 1,
      "Xdt_train": 1,
      "features_v2": 1,
      "train_set": 1,
      "train_attributes_n": 1,
      "X_f_train_scaled": 1,
      "X_train_c": 1,
      "train_df[feature].values.reshape(-1, 1)": 1,
      "train_df[feature].cat.codes.values.reshape(-1, 1)": 1,
      "monster_train_A[features]": 1,
      "x.reshape(-1, 1)": 1,
      "np.array(xtrain)": 1,
      "x_train_imp": 1,
      "X_train_reduced": 1,
      "X[train_index]": 1,
      "train[bin_cols]": 1,
      "train['bins_reordered'].reshape(-1, 1)": 1,
      "X1": 1,
      "X2": 1,
      "X5": 1,
      "X3": 1,
      "X4": 1,
      "XTRAIN": 1,
      "X_train[feature].fillna(0).to_frame()": 1,
      "df.drop('cuisine', axis=1)": 1,
      "XTrain": 1,
      "dtm_train1": 1,
      "X_test": 1,
      "X_sliced_array_train": 1,
      "X_resampled": 1,
      "X_numeric_train": 1,
      "df[[var_col]].as_matrix()": 1,
      "train[feature_col]": 1,
      "train_df": 1,
      "t_train": 1,
      "train_data[selected_features]": 1,
      "df_nona[['team_id', 'minutes_remaining']]": 1,
      "x_tr": 1,
      "train_data_new[features]": 1,
      "df_X": 1,
      "X_trains_b": 1,
      "dtrain": 1,
      "x_train_pca": 1,
      "train[x]": 1,
      "tr_x": 1,
      "x[temp_cols]": 1
    },
    "sklearn.tree._classes.DecisionTreeClassifier.fit.y": {
      "y_train": 455,
      "y": 68,
      "Y_train": 67,
      "train_y": 43,
      "Y": 21,
      "target": 15,
      "y1": 15,
      "train.target": 13,
      "y2": 12,
      "ytrain": 10,
      "train['target']": 8,
      "train_results": 8,
      "y_train.values.ravel()": 7,
      "y_tr": 6,
      "y_train_res": 4,
      "target_train": 4,
      "y_train_cc": 4,
      "y_train_ft": 4,
      "trainpara['target']": 4,
      "y_train_sm": 4,
      "y_equidistant": 4,
      "y_balanced": 4,
      "yTrain": 3,
      "y_learn": 3,
      "labels": 3,
      "train[target]": 3,
      "train_df.y_class": 3,
      "train_labels": 3,
      "trainLabel": 2,
      "train_Y": 2,
      "df_comb['HasDetections']": 2,
      "y_train1": 2,
      "treino['target']": 2,
      "y_f_train": 2,
      "y_Train": 2,
      "ttexty_train": 2,
      "tsiftdatay_train": 2,
      "trainY": 2,
      "y_train_holdout": 2,
      "label": 2,
      "train_df['AdoptionSpeed']": 2,
      "data_train_c": 2,
      "y_train_3": 2,
      "y_tr_equid": 2,
      "y_tr_balan": 2,
      "X_train.Survived": 1,
      "normY": 1,
      "y_train.values": 1,
      "speed": 1,
      "train_t_target": 1,
      "Y_learn_clf": 1,
      "y_over.values.ravel()": 1,
      "y_c": 1,
      "y_d": 1,
      "train_dep": 1,
      "train[:, -1]": 1,
      "y_training": 1,
      "train['signal']": 1,
      "titanic_labels": 1,
      "Y_treino": 1,
      "yp": 1,
      "TrainLabel": 1,
      "y_orig_train": 1,
      "df_train_y": 1,
      "depTrain": 1,
      "y_train_1": 1,
      "train_data['y']": 1,
      "train.Sentiment": 1,
      "y_treino": 1,
      "train[pd.notnull(train[num_features[f]])][target]": 1,
      "train_object": 1,
      "ttextdataemy_train": 1,
      "train_true": 1,
      "training_set['HasDetections'].iloc[train_indices]": 1,
      "traindf['cuisine']": 1,
      "dw['Target']": 1,
      "self.train_target": 1,
      "y_train_new['surface']": 1,
      "y_trn": 1,
      "train[target1]": 1,
      "labels.values.ravel()": 1,
      "data_train[output]": 1,
      "train_data[target1]": 1,
      "train_data[target2]": 1,
      "df['target']": 1,
      "y_train[:2500]": 1,
      "sub_target_train": 1,
      "train['Cover_Type']": 1,
      "colors": 1,
      "data['price']": 1,
      "trainTarget": 1,
      "train[col][:10000]": 1,
      "y_train_data": 1,
      "y_train_dt1": 1,
      "y_train_dt2": 1,
      "yy_train": 1,
      "trainf1_target": 1,
      "ml_train": 1,
      "ydt_train": 1,
      "Y1": 1,
      "Y2": 1,
      "train_matchType": 1,
      "train_target_class_n": 1,
      "Y_Train": 1,
      "y_train_c": 1,
      "y1_train": 1,
      "y2_train": 1,
      "monster_train_A['type']": 1,
      "np.array(ytrain)": 1,
      "y_train_imp": 1,
      "y[train_index]": 1,
      "y5": 1,
      "y3": 1,
      "y4": 1,
      "df.cuisine": 1,
      "YTrain": 1,
      "train1['target']": 1,
      "y_test": 1,
      "y_train_res[:20000]": 1,
      "y_resampled": 1,
      "y_train['target']": 1,
      "df[label_col].values": 1,
      "train['Category']": 1,
      "train_targets": 1,
      "survived": 1,
      "s_train": 1,
      "df_nona[['shot_made_flag']]": 1,
      "train_data_new['crime']": 1,
      "df_Y": 1,
      "y_trains_b": 1,
      "train_label": 1,
      "Xtarget": 1,
      "labels_train": 1,
      "train['duration_group']": 1,
      "tr_y": 1
    },
    "sklearn.tree._classes.BaseDecisionTree.predict.X": {
      "X_test": 417,
      "x_test": 171,
      "X_train": 76,
      "test": 56,
      "X_val": 46,
      "val_X": 33,
      "X_valid": 28,
      "test_x": 27,
      "test_data": 26,
      "validate_x": 23,
      "x_train": 21,
      "X": 21,
      "test2.signal.values[100000 * a:100000 * (a + 1)].reshape((-1, 1))": 20,
      "test_merged[features]": 18,
      "test_X": 15,
      "x_val": 14,
      "x": 12,
      "test_feature": 10,
      "test_features": 9,
      "dtm_validate": 7,
      "X_train_dm": 7,
      "train_X": 6,
      "X_test_scaled": 5,
      "X_test1": 5,
      "Y": 5,
      "testfeature": 5,
      "X.head()": 5,
      "train_data": 4,
      "validacao[usadas]": 4,
      "test_encoded": 4,
      "tsiftdatax_test": 4,
      "df_test[['Country_Region', 'Province_State', 'Date']]": 4,
      "traindata": 4,
      "testdata": 4,
      "cyc_data[x_ipts]": 4,
      "cyc_data_tstpart[x_ipts]": 4,
      "xvalid": 4,
      "test_merge4": 3,
      "train_merge4": 3,
      "df_test": 3,
      "X_test_cc": 3,
      "X_test_fat": 3,
      "X_test[:, None]": 3,
      "np.array([el[0]]).reshape(1, -1)": 3,
      "normalized_test_X": 3,
      "valid[cols]": 3,
      "ttextdataemx_test": 3,
      "housing_prepared": 3,
      "test_df": 3,
      "features_test": 3,
      "test[features]": 3,
      "X_test_std": 3,
      "x_valid": 3,
      "X_test_confirmed": 3,
      "X_test_fatal": 3,
      "XD_test": 3,
      "valid.fillna(-1)[feats]": 3,
      "graph_x / scaler_X.scale_[2]": 2,
      "validate_x_sparse": 2,
      "X_validation": 2,
      "X_test_dataset": 2,
      "x.head()": 2,
      "X_train[var].to_frame()": 2,
      "X_test[var].to_frame()": 2,
      "np.reshape(X_test_clf, (X_test_clf.shape[0], 1))": 2,
      "df1": 2,
      "test_tfidf": 2,
      "final_x": 2,
      "X_test_pca": 2,
      "data_test": 2,
      "test_clean": 2,
      "test2.signal.values[1000000:2000000].reshape((-1, 1))": 2,
      "TestData": 2,
      "teste.drop(['target'], axis=1)": 2,
      "X_xTest_CS": 2,
      "X_xtest_Cs": 2,
      "X_train_dm_1": 2,
      "X_test_trans": 2,
      "test_flt_train": 2,
      "x_tr": 2,
      "val_x": 2,
      "X_Val": 2,
      "X_testNorm": 2,
      "X_testNorm1": 2,
      "X_testNorm2": 2,
      "p_test[features]": 2,
      "x_test_imp": 2,
      "array_test": 2,
      "X_test2": 2,
      "X_submit_test": 2,
      "X_train_prepared": 2,
      "X_test_prepared": 2,
      "test_data[features]": 2,
      "bow_train": 2,
      "bow_test": 2,
      "X_pred": 2,
      "pd.DataFrame(np.c_[xx.ravel(), yy.ravel()], columns=train.columns)": 2,
      "Xtest": 2,
      "x1": 2,
      "x3": 2,
      "X_test[100].reshape(1, 784)": 2,
      "x_train_holdout": 2,
      "x_test_holdout": 2,
      "test_vectorized": 2,
      "dev_x": 2,
      "df_test[common_features]": 2,
      "test3": 2,
      "train[train.columns[1:-1]]": 2,
      "tsne_test": 2,
      "dtest": 2,
      "xTest": 2,
      "X_te_equid": 2,
      "X_te_balan": 2,
      "X_test_b": 2,
      "test.drop(['Target', 'members_ids'], axis=1)": 1,
      "X_testsc": 1,
      "x2": 1,
      "test[col]": 1,
      "test6": 1,
      "X_test_5": 1,
      "X_test_main": 1,
      "cleaned_test": 1,
      "lsa_scores_test": 1,
      "X2_test_DTR": 1,
      "test_t_predictor": 1,
      "test_predictor": 1,
      "testImage_pca": 1,
      "testImage": 1,
      "X_test[['readability', 'len_words', 'len_chars', 'sentiment']]": 1,
      "testing_data": 1,
      "titanic_test": 1,
      "te": 1,
      "testFactors": 1,
      "Xtst_transform": 1,
      "df_Test": 1,
      "x_val[col_n]": 1,
      "X_test_pc": 1,
      "actual_test_data": 1,
      "ensemble_test_df": 1,
      "[[-0.371641]]": 1,
      "test_ind": 1,
      "xtrain": 1,
      "test_merged[X.columns]": 1,
      "test[:, :-1]": 1,
      "STDTest": 1,
      "STDTdata": 1,
      "X1": 1,
      "scaled_test_X": 1,
      "xvalid_count": 1,
      "test_df[predictors]": 1,
      "X_cv": 1,
      "X_pred_confirmed": 1,
      "X_pred_fatalities": 1,
      "titanic[:5]": 1,
      "titanic": 1,
      "testeData": 1,
      "np.c_[xx.ravel(), yy.ravel()]": 1,
      "x_test_nonan": 1,
      "test_tree_predict": 1,
      "Submit": 1,
      "tests.drop(columns=['ID_code', 'var_120'])": 1,
      "indTest": 1,
      "X_t[cols]": 1,
      "x2_test": 1,
      "x4_test": 1,
      "X_test_vect": 1,
      "X_test_vect_TFID": 1,
      "xCC_test": 1,
      "xF_test": 1,
      "XCC": 1,
      "test.drop(['Id'], axis=1)": 1,
      "test_sample": 1,
      "[random_image_resized]": 1,
      "test_images_resized": 1,
      "x_sets[i]": 1,
      "X_test_CC": 1,
      "X_test_Fat": 1,
      "train_feature": 1,
      "X_Test_new": 1,
      "final_test": 1,
      "final_test_new": 1,
      "scaler.transform(X_test)": 1,
      "test_merged[x.columns]": 1,
      "X_test.fillna(0)": 1,
      "test_dtm": 1,
      "x_ts": 1,
      "final": 1,
      "test_explan": 1,
      "Xsub[:, 1:]": 1,
      "cv_x": 1,
      "v_X": 1,
      "test_vector": 1,
      "x_testFixed": 1,
      "v1_test.drop(['id'], axis=1)": 1,
      "v2_test.drop(['id'], axis=1)": 1,
      "X_test_": 1,
      "self.test_data": 1,
      "test['price_doc']": 1,
      "preprocessed_val_X": 1,
      "train": 1,
      "test.signal.values[0 * a:1 * a].reshape((-1, 1))": 1,
      "test.signal.values[1 * a:2 * a].reshape((-1, 1))": 1,
      "test.signal.values[2 * a:3 * a].reshape((-1, 1))": 1,
      "test.signal.values[3 * a:4 * a].reshape((-1, 1))": 1,
      "test.signal.values[4 * a:5 * a].reshape((-1, 1))": 1,
      "test.signal.values[5 * a:6 * a].reshape((-1, 1))": 1,
      "test.signal.values[6 * a:7 * a].reshape((-1, 1))": 1,
      "test.signal.values[7 * a:8 * a].reshape((-1, 1))": 1,
      "test.signal.values[8 * a:9 * a].reshape((-1, 1))": 1,
      "test.signal.values[9 * a:10 * a].reshape((-1, 1))": 1,
      "test.signal.values[10 * a:20 * a].reshape((-1, 1))": 1,
      "X_test_new_2": 1,
      "DT_Test": 1,
      "df_X_validation": 1,
      "x_val[:1000]": 1,
      "x_train[:10000]": 1,
      "X_processed_final_test": 1,
      "X_valid_prepared": 1,
      "test[features1]": 1,
      "X_test_transformed_stand": 1,
      "test_df[[str(x) for x in range(300)]]": 1,
      "data_test[feature_cols]": 1,
      "x_eval": 1,
      "X_test_ol": 1,
      "x_test_1": 1,
      "x_test_2": 1,
      "X_test[col].to_frame()": 1,
      "x_teste": 1,
      "titanic_test2": 1,
      "testX": 1,
      "x_val[0:5]": 1,
      "copy": 1,
      "X_val[columns]": 1,
      "data[params]": 1,
      "submission[['Age', 'Sex', 'Pclass']]": 1,
      "realTest2": 1,
      "count_test": 1,
      "label_X_valid": 1,
      "X_inf_val": 1,
      "X_dth_val": 1,
      "X_test_inf": 1,
      "X_test_dth": 1,
      "x_validate": 1,
      "X_validate": 1,
      "test_dummies.fillna(0)": 1,
      "bow_train2": 1,
      "bow_test2": 1,
      "x_test_data": 1,
      "X_vid": 1,
      "trial": 1,
      "train[features]": 1,
      "X_train_SC": 1,
      "X_test_SC": 1,
      "[X_test[i]]": 1,
      "xvalid_tfv": 1,
      "xtest_tfv": 1,
      "sample_data": 1,
      "X_test_tfidf_stem_dt": 1,
      "X_test_tfidf_lemma_dt": 1,
      "X_test[8000].reshape(1, 784)": 1,
      "X_valid_scaled": 1,
      "XX_test": 1,
      "trainf2_input": 1,
      "Xdt_test": 1,
      "[[6, 1345, 3.0, 560.0, 800.0, 760, 2, 7, 2003, 2005]]": 1,
      "test_set_upd": 1,
      "test_set_upd_v2": 1,
      "Xt": 1,
      "Xs": 1,
      "[test_attributes_n.loc[i]]": 1,
      "df_test.drop(['Date', 'ForecastId'], axis=1)": 1,
      "df_test.drop(['Date', 'ForecastId', 'ConfirmedCases'], axis=1)": 1,
      "X_Test": 1,
      "X_f_test_scaled": 1,
      "X_train_c": 1,
      "X_test_c": 1,
      "X_unlabeled": 1,
      "X_test.iloc[:, :-1]": 1,
      "test[independent_variable]": 1,
      "test_X_fat": 1,
      "decision_model_test_1": 1,
      "train_df[feature].values.reshape(-1, 1)": 1,
      "train_df[feature].cat.codes.values.reshape(-1, 1)": 1,
      "data_test_t": 1,
      "data_test_post": 1,
      "monster_train_B[features]": 1,
      "np.array(xtest)": 1,
      "test1": 1,
      "x_test_3": 1,
      "x_train_3": 1,
      "X_test_reduced": 1,
      "calc.values.reshape(-1, 1)": 1,
      "X_validation.drop(columns=['extra'])": 1,
      "validation_x": 1,
      "X_t": 1,
      "test.iloc[:, test.columns != 'id']": 1,
      "train_x": 1,
      "X_fe_emb_val": 1,
      "scaled_testX": 1,
      "tfidf_test": 1,
      "test[names]": 1,
      "Xx": 1,
      "test_merg[X.columns]": 1,
      "test[binarias + discretas]": 1,
      "XTEST": 1,
      "xtest": 1,
      "X_test[feature].fillna(0).to_frame()": 1,
      "td": 1,
      "XX.head()": 1,
      "x_test_competi\u00e7\u00e3o": 1,
      "X_test_1": 1,
      "X_test_4": 1,
      "train_clean_cases": 1,
      "train_clean_fatal": 1,
      "test_clean_cases": 1,
      "test_clean_fatal": 1,
      "x1_vld": 1,
      "x2_vld": 1,
      "A1_test": 1,
      "A2_test": 1,
      "A3_test": 1,
      "blind": 1,
      "x_t": 1,
      "target": 1,
      "XTest": 1,
      "X_train_std": 1,
      "test[feats]": 1,
      "test_merged[data_merged.columns.drop(['Sales', 'Date', 'Customers'])]": 1,
      "X_sliced_array_test": 1,
      "test[feature_col]": 1,
      "test_merged1[X_train.columns]": 1,
      "test_df.iloc[3:4]": 1,
      "val_df": 1,
      "X_val_final": 1,
      "test_final": 1,
      "np.array([[1000]])": 1,
      "Deaths_data_value": 1,
      "X_teste_submit": 1,
      "t_test": 1,
      "test_main": 1,
      "test_data1": 1,
      "df_test[s_fet]": 1,
      "test_data[selected_features]": 1,
      "features_valid": 1,
      "D1_test": 1,
      "XT": 1,
      "X_test[555].reshape(1, 784)": 1,
      "test_df_X": 1,
      "testik": 1,
      "_products.head()": 1,
      "_products": 1,
      "tr[features]": 1,
      "pro_data[0:100, 5:]": 1,
      "test_set": 1,
      "x_test_pca": 1,
      "valid[x]": 1,
      "va_x": 1,
      "df_test_fin": 1,
      "test_x[temp_cols]": 1
    },
    "sklearn.metrics._ranking.roc_curve.pos_label": {
      "None": 1228,
      "1": 152,
      "2": 21,
      "0": 5,
      "i": 2,
      "True": 2,
      "clf.classes_[1]": 1
    },
    "sklearn.metrics._ranking.roc_curve.y_true": {
      "y_test": 289,
      "y_train": 104,
      "y": 89,
      "y_true": 84,
      "y_valid": 58,
      "target": 49,
      "y_val": 43,
      "Y_train": 26,
      "labels": 24,
      "Y_test": 23,
      "sick_vec": 20,
      "y_.iloc[val_idx]": 20,
      "roc_validation_generator.classes": 16,
      "y_val_f": 14,
      "y_test[:, i]": 14,
      "test_y": 13,
      "y_": 12,
      "test_labels": 11,
      "val_y": 10,
      "y_test.ravel()": 10,
      "y[test]": 10,
      "y_cv": 9,
      "actual": 9,
      "test_generator.classes": 8,
      "np.argmax(valid_Y, -1) == 0": 8,
      "y_test.iloc[:, i]": 8,
      "y_resampled": 8,
      "y_train_rus": 8,
      "y_test_rus": 8,
      "y_test1": 7,
      "yvl": 7,
      "train_y": 6,
      "yTest": 6,
      "train_df[target]": 6,
      "test_gen.classes": 6,
      "y.iloc[val_idx]": 6,
      "yval[:, i]": 6,
      "y_true.ravel()": 5,
      "error_df.true_class": 5,
      "train_df.iloc[valid_idx][target].values": 5,
      "y[label]": 5,
      "y_tst": 4,
      "target_data.iloc[index]": 4,
      "train_label": 4,
      "ytest": 4,
      "y_test_df": 4,
      "testy": 4,
      "y_validate": 4,
      "valid_y": 4,
      "y_cora_test_": 4,
      "Y": 4,
      "validation_generator.classes": 4,
      "yActual": 4,
      "y_test_b": 4,
      "self.y_val": 3,
      "true": 3,
      "y_valid[:, 1]": 3,
      "train['target']": 3,
      "t_y": 3,
      "y_validation": 3,
      "new_y22[:, i]": 3,
      "df1.target": 3,
      "truth": 3,
      "y_pred": 3,
      "train_labels": 3,
      "label": 3,
      "TARGET": 3,
      "y_label": 3,
      "y[col]": 3,
      "valid_labels.reshape(66187)": 3,
      "validate_y": 2,
      "Y_valid": 2,
      "df.iloc[valid_idx].target": 2,
      "yTrue": 2,
      "data_y[test_indices].ravel()": 2,
      "y_true_train": 2,
      "y_true_val": 2,
      "df_train['HasDetections'].values": 2,
      "TestLabel": 2,
      "test['TARGET']": 2,
      "Y_BIN[:, i]": 2,
      "new_y22.ravel()": 2,
      "eee[:, i]": 2,
      "y_true[:, i]": 2,
      "Y_val": 2,
      "y_train_reg": 2,
      "y.iloc[index]": 2,
      "y_val.numpy()": 2,
      "y_train_drop": 2,
      "resnet50_test_data_gen.classes": 2,
      "y[:, 0]": 2,
      "Y_valid[:, i]": 2,
      "true_list": 2,
      "train['action'].values": 2,
      "valid_lab": 2,
      "ground_truth_labels": 2,
      "y_smote_v": 2,
      "Y_tr.values[test]": 2,
      "check_agreement_labels": 2,
      "~missing['miss_totals.transactionRevenue']": 2,
      "y_obs": 2,
      "y.iloc[val_idx].values": 2,
      "val_y[label].values": 2,
      "oof[class_names[i_class]].iloc[val_idx]": 2,
      "y_target": 2,
      "np.ravel(yTest)": 2,
      "y_train_valid_part": 2,
      "df_valid_results_per_fold_per_epoch['targets'].astype(float).astype(int)": 2,
      "df_train_results_per_fold_per_epoch['targets'].astype(float).astype(int)": 2,
      "label_data": 2,
      "self.vLabels": 2,
      "y_train_pred_final.Survived": 2,
      "y_true_for_curr_class": 2,
      "y_true_binary": 2,
      "y_val.astype(np.uint8)": 2,
      "target[val_idx]": 2,
      "y_test_pca": 2,
      "targets_val": 2,
      "np.array(y_t)": 2,
      "y_list": 2,
      "y_is9_validation": 2,
      "y_train.iloc[tes]": 1,
      "y_test_d": 1,
      "y_test_bin[:, i]": 1,
      "y_test_bin.ravel()": 1,
      "labels.astype('int').values": 1,
      "cv_scores['fold_0_val']": 1,
      "cv_scores['fold_1_val']": 1,
      "cv_scores['fold_2_val']": 1,
      "cv_scores['fold_3_val']": 1,
      "actual_": 1,
      "dtest_Y": 1,
      "df_y_valid": 1,
      "df_test['target']": 1,
      "test_data_gen.classes": 1,
      "y_real": 1,
      "y_test_ce": 1,
      "experData_y": 1,
      "logModel.predict(X)": 1,
      "df_target": 1,
      "validation_y": 1,
      "y_pred_train": 1,
      "y_pred_cv": 1,
      "input_data[output_var]": 1,
      "y_train['insult']": 1,
      "y_true[i]": 1,
      "df.target": 1,
      "valid_generator.classes": 1,
      "target_np": 1,
      "val[TARGET]": 1,
      "y_valid_l": 1,
      "y_valid_x": 1,
      "y_te": 1,
      "validation_classes": 1,
      "test_features": 1,
      "targs": 1,
      "self.y_true": 1,
      "y[ds]": 1,
      "Y_test.values": 1,
      "Y_BIN.ravel()": 1,
      "eee.ravel()": 1,
      "y3_valid": 1,
      "y_label.values": 1,
      "X_test_df_result['Actuals']": 1,
      "train['target'].values": 1,
      "y_train.iloc[valid_idx].values": 1,
      "pred": 1,
      "valid_y[:, i]": 1,
      "rf_results_df[TARGET]": 1,
      "y_test_dummies[:, i]": 1,
      "df.SeriousDlqin2yrs": 1,
      "y.iloc[test]": 1,
      "yv": 1,
      "cv_y": 1,
      "y_train.as_matrix()[test]": 1,
      "y[k_test]": 1,
      "oof[class_true[i_class]].iloc[val_idx]": 1,
      "y_test[:, idx].astype(int)": 1,
      "y_test + 1": 1,
      "y_test.values + 1": 1,
      "training_set['HasDetections'].iloc[test_indices]": 1,
      "mobilenetv2_test_data_gen.classes": 1,
      "train_targets": 1,
      "np.array(valid_targets, np.int)": 1,
      "First['Man']": 1,
      "All['Man']": 1,
      "df[y_true]": 1,
      "val_df['is_attributed']": 1,
      "Y_valid.ravel()": 1,
      "true_value": 1,
      "true_value_test": 1,
      "true_label": 1,
      "y_val_true": 1,
      "Y2_train": 1,
      "y_actual_binary[:, i]": 1,
      "y_actual_binary.ravel()": 1,
      "y_test > 0": 1,
      "Ytest": 1,
      "actual_labels": 1,
      "df_test_oh['target']": 1,
      "df_test_le['target']": 1,
      "y_train.iloc[idx_train]": 1,
      "y_train.iloc[idx_validation]": 1,
      "y_b": 1,
      "val_merged.target_x": 1,
      "train_merged.target_x": 1,
      "test_output['expected']": 1,
      "error_df.Converted": 1,
      "test_data.classes": 1,
      "true_labels": 1,
      "y_test_final": 1,
      "y_train__": 1,
      "model.predict(X_test)[:, 1]": 1,
      "data_Y.values[test]": 1,
      "trainingset['is_duplicate']": 1,
      "y_test_": 1,
      "y_donor_choose_train": 1,
      "y_donor_choose_validation": 1,
      "preds['trueLabel']": 1,
      "error_df.True_class": 1,
      "y_train_true": 1,
      "y_test_true": 1,
      "label_val_split": 1,
      "oof_target": 1,
      "y_cal": 1,
      "y_train[trn_idx]": 1,
      "y_train[val_idx]": 1,
      "self.test_y[:, i]": 1,
      "self.test_y.ravel()": 1,
      "training['target']": 1,
      "data_out[test_idx]": 1,
      "torch_y_val.cpu()": 1,
      "y_train.iloc[test]": 1,
      "y[val_idx, 4]": 1,
      "y_trn": 1,
      "gt": 1,
      "y_true.get_label()": 1,
      "val_targets": 1,
      "y_val[:, i]": 1,
      "y_val.ravel()": 1,
      "Y_ValidData": 1,
      "y_validation[tag]": 1,
      "valid_target": 1,
      "y_train_roc": 1,
      "y_test_roc": 1,
      "validation_targets": 1,
      "error_df.true": 1,
      "(y_true == classes[i]).astype(int)": 1,
      "test_data.answered_correctly": 1,
      "valtargets": 1,
      "valtargets_pesudo": 1,
      "datatest[clas]": 1,
      "raw_train.target[valid]": 1,
      "train_eval['signal']": 1,
      "test_df.TARGET": 1
    },
    "sklearn.metrics._ranking.roc_curve.y_score": {
      "y_pred": 100,
      "predictions": 77,
      "preds": 40,
      "y_valid": 34,
      "probs": 30,
      "pred": 29,
      "y_pred_proba": 26,
      "gbc_clf_scores": 26,
      "y_score[:, i]": 21,
      "sick_score": 20,
      "oof_preds_[val_idx]": 20,
      "logit_scores": 20,
      "oof_preds": 19,
      "proba": 18,
      "y_score.ravel()": 17,
      "y_scores": 16,
      "preds_val": 14,
      "y_pred_keras": 14,
      "predicted": 14,
      "logreg.predict_proba(X_test)[:, 1]": 13,
      "logist_pred": 12,
      "clf.predict_proba(X_test)[:, 1]": 12,
      "probas_[:, 1]": 12,
      "oof_preds_": 11,
      "prob_psv": 10,
      "preds_valid": 9,
      "y_predict": 9,
      "logit_scores_val": 9,
      "pred1": 9,
      "data_all": 8,
      "pred_Y[:, 0]": 8,
      "logit_resampled_scores": 8,
      "y_scores_test": 8,
      "y_train_pred": 8,
      "y_test_pred": 8,
      "y_score": 8,
      "y_pred_rf": 7,
      "probabilities": 7,
      "val_predict.argmax(axis=1)": 7,
      "ns_probs": 7,
      "y_predict_prob": 7,
      "scores": 6,
      "train_pred": 6,
      "GBC_scores": 6,
      "oof_preds[val_idx]": 6,
      "error_df.reconstruction_error": 6,
      "rf_predictions": 6,
      "y_pred_val": 5,
      "prediction": 5,
      "y_proba": 5,
      "Y_train_pred[:, 1]": 5,
      "prob": 5,
      "y_pred_prob": 5,
      "lr_probs": 5,
      "oof[valid_idx]": 5,
      "val_pred": 5,
      "pipeline.predict_proba(X_train)[:, 1]": 4,
      "resu": 4,
      "predictions[1]": 4,
      "predict": 4,
      "oof": 4,
      "predict_proba[:, 1]": 4,
      "ycls[:, i]": 4,
      "yPred": 4,
      "y_prob": 4,
      "predicted_y": 4,
      "y_predi": 4,
      "y_scores_rf": 3,
      "predictions[:, 1]": 3,
      "model.predict_proba(X_test)[:, 1]": 3,
      "y_prob_val[:, 1]": 3,
      "xgb_pred": 3,
      "y_preds": 3,
      "clf.predict_proba(val_x)[:, 1]": 3,
      "p_y": 3,
      "Y_valid_pred[:, 1]": 3,
      "valid_pred": 3,
      "lr.predict_proba(X_test)[:, 1]": 3,
      "probabilities[:, i]": 3,
      "df1[0]": 3,
      "y_proba[:, 1]": 3,
      "random_probs": 3,
      "Y_pred_train": 3,
      "Y_pred_test": 3,
      "test_prediction": 3,
      "oof[class_preds[i_class]].iloc[val_idx]": 3,
      "y_val_pred": 3,
      "cv_pred": 3,
      "y_pred[:len(y)]": 3,
      "train_preds": 3,
      "test_preds": 3,
      "pred_prob": 3,
      "y_hat": 3,
      "ytrain_pred": 3,
      "y_probab": 3,
      "y_predictedtrain": 3,
      "y_predictedCV": 3,
      "pred_probs['Insincere']": 2,
      "rfc_pred": 2,
      "probs[:, 1]": 2,
      "y_pred_proba[:, 1]": 2,
      "pred2[:, 1]": 2,
      "predictions_test": 2,
      "model3.predict_proba(val_x)[:, 1]": 2,
      "y_pred3": 2,
      "y_predicted_labels": 2,
      "average_valid_predicts": 2,
      "y_train_pred_proba": 2,
      "probas": 2,
      "y_pred_lr.iloc[:, i]": 2,
      "y_pred.iloc[:, i]": 2,
      "y_pred2.iloc[:, i]": 2,
      "ensemble_score.iloc[:, i]": 2,
      "p[:, 1]": 2,
      "y_pred_train": 2,
      "df_train['Prob'].values": 2,
      "predicted_proba[:, -1]": 2,
      "xgb_pred_valid": 2,
      "knn.predict_proba(X_test)[:, 1]": 2,
      "gaussian.predict_proba(X_test)[:, 1]": 2,
      "random_forest.predict_proba(X_test)[:, 1]": 2,
      "probabilities_lg[:, i]": 2,
      "probabilities_lg.ravel()": 2,
      "oof_train_rf": 2,
      "oof_train_xgb": 2,
      "oof_train_lgb": 2,
      "oof_train_lr": 2,
      "prediction[:, 1]": 2,
      "pre_y": 2,
      "probability": 2,
      "Y_pred_true": 2,
      "probas[:, 1]": 2,
      "pred_fet": 2,
      "y_pred_RF1": 2,
      "valid_preds": 2,
      "resnet50_model_predictions": 2,
      "score": 2,
      "y_test": 2,
      "y_probas": 2,
      "prob_list": 2,
      "score_value": 2,
      "y_pred2": 2,
      "cv_predict": 2,
      "pred_train": 2,
      "y_pred.ravel()": 2,
      "y_oof[val_idx]": 2,
      "oof_proba[:, i_w]": 2,
      "y_pred_prob[:, 1]": 2,
      "np.ravel(probs)": 2,
      "df_valid_results_per_fold_per_epoch['predictions'].astype(float)": 2,
      "df_train_results_per_fold_per_epoch['predictions'].astype(float)": 2,
      "y_train_pred_final.Survived_Prob": 2,
      "train_proba": 2,
      "y_preds_for_curr_class": 2,
      "y_preds_binary": 2,
      "oof[val_idx]": 2,
      "pred_pro": 2,
      "y_scores_forest": 2,
      "np.array(y_p)": 2,
      "y_scores[:, 1]": 2,
      "lr_pred": 2,
      "logit": 2,
      "xgb_proba[:, 1]": 2,
      "y_pred_xgb": 1,
      "y_pred_lrg": 1,
      "y_pred_knn": 1,
      "Y_pred_proba": 1,
      "check": 1,
      "nb.predict_proba(X_test)[:, 1]": 1,
      "tree.predict_proba(X_test)[:, 1]": 1,
      "model.predict_proba(X_test_d)[:, 1]": 1,
      "clf.predict(df_uncorr_train.values)": 1,
      "model_probs": 1,
      "val_pred_lgb": 1,
      "clf.predict(x_test)": 1,
      "cv_scores['fold_0_predict_proba']": 1,
      "cv_scores['fold_1_predict_proba']": 1,
      "cv_scores['fold_2_predict_proba']": 1,
      "cv_scores['fold_3_predict_proba']": 1,
      "log_pred": 1,
      "gbm_pred": 1,
      "deepl_pred": 1,
      "pred_all": 1,
      "prediction_probabilities": 1,
      "pred_val": 1,
      "train_predict": 1,
      "valid_predict": 1,
      "train['classifier_32']": 1,
      "pred_xgb_test_ce": 1,
      "pred_xgb_test": 1,
      "modelgsGBCtestpre_y": 1,
      "y_pred_new_RF": 1,
      "y": 1,
      "predictions_train": 1,
      "val_preds": 1,
      "y_svc": 1,
      "y_log": 1,
      "y_sgd": 1,
      "y_train": 1,
      "y_cv": 1,
      "rf_1s_preds": 1,
      "o": 1,
      "y_pred_original": 1,
      "y_pred_score": 1,
      "y_predicted_prob_rf[:, 1]": 1,
      "y_pred[i]": 1,
      "y_train_probs[:, 1]": 1,
      "y_val_probs[:, 1]": 1,
      "y_pred_proba_pca": 1,
      "clf.predict_proba(xtest)[:, 1]": 1,
      "clf.decision_function(xtest)": 1,
      "log_model_lasso_pred_proba[:, -1]": 1,
      "y_pred_keras.ravel()": 1,
      "y_pred_keras2.ravel()": 1,
      "log_clf.predict(TestData)": 1,
      "ada_real.predict(TestData)": 1,
      "logreg.predict_proba(test_df)[:, 1]": 1,
      "clf.predict_proba(test_df)[:, 1]": 1,
      "output_np[:, 1]": 1,
      "(y_val_pred > 0.5) * 1": 1,
      "valid_preds_lgb": 1,
      "predict_probs": 1,
      "validation_predictions": 1,
      "y_scores_nb[:, 1]": 1,
      "y_scores_mlp[:, 1]": 1,
      "y_scores_rf[:, 1]": 1,
      "m['model'].predict_proba(X_validation).T[1]": 1,
      "predict_prob": 1,
      "probs_t": 1,
      "yhat": 1,
      "test['TARGET']": 1,
      "self.y_pred": 1,
      "y_predict_proba[ds]": 1,
      "output.toxic.values": 1,
      "model.predict_proba(X)[:, 1]": 1,
      "pipeline.predict_proba(X)[:, 1]": 1,
      "probabilities.ravel()": 1,
      "probabilities_nb[:, i]": 1,
      "Y_predict1_proba": 1,
      "Y_predict2_proba": 1,
      "Y_predict3_proba": 1,
      "Y_predict4_proba": 1,
      "Y_predict5_proba": 1,
      "Y_predict6_proba": 1,
      "Y_predict7_proba": 1,
      "Y_predict8_proba": 1,
      "y3_pred": 1,
      "LR_probs": 1,
      "XGB_probs": 1,
      "LGBM_probs": 1,
      "y_proba_pred": 1,
      "y_pred_valid": 1,
      "probs1": 1,
      "y_pred_proba_xgb_default[:, 1]": 1,
      "y_pred_proba_xgb[:, 1]": 1,
      "status[:, 1]": 1,
      "Model_final_MLPClassifier.predict(X_t3gram_vectorizer_test_)": 1,
      "Model_final_ExtraTreesClassifier.predict(X_t3gram_vectorizer_test_)": 1,
      "Model_final_LinearSVC.predict(X_Singt3gram_vectorizer_test_)": 1,
      "Model_final_LogReg.predict(X_t3gram_vectorizer_test_)": 1,
      "X_test_df_result['TARGET']": 1,
      "y_pred_rt": 1,
      "y_pred_rf_lm": 1,
      "y_pred_grd_lm": 1,
      "y_pred_grd": 1,
      "predictions_bin": 1,
      "predictions_NN_prob": 1,
      "y_preds[:, i]": 1,
      "yhat_prob": 1,
      "logreg.predict_proba(X_val1)[:, 1]": 1,
      "model_lr.predict_proba(X_test)[:, 1]": 1,
      "true": 1,
      "preds[:, i]": 1,
      "rf_results_df['RFHasDetScore']": 1,
      "xgb_model.predict_proba(X_test)[:, 1]": 1,
      "pred_prob[:, 1]": 1,
      "clf_rf_pp[:, 1]": 1,
      "clf_dt_pp[:, 1]": 1,
      "clf_xgb_pp[:, 1]": 1,
      "zeros_probs": 1,
      "pred_train_prob[:, 1]": 1,
      "preds_roc": 1,
      "Y_score": 1,
      "pred0[:, 1]": 1,
      "clf.predict_proba(X_valid)[:, 1]": 1,
      "predict_y_train": 1,
      "predict_y": 1,
      "rigid": 1,
      "ensemble_model.predict_proba(train_predictions)[:, 1]": 1,
      "train_prediction": 1,
      "preds_val.numpy()[:, 1]": 1,
      "y_pred[:, idx]": 1,
      "prob[:, 1]": 1,
      "mobilenetv2_model_predictions": 1,
      "train_predictions": 1,
      "np.array(valid_predictions).ravel()": 1,
      "First['MLPProb']": 1,
      "All['Pred']": 1,
      "train_proba[:, 0]": 1,
      "train_proba[:, 1]": 1,
      "y_pred_proba[:, 0]": 1,
      "df[y_score]": 1,
      "predictions_lgbm_valdf": 1,
      "pred_valid[:, i]": 1,
      "pred_valid.ravel()": 1,
      "rf.predict_proba(X_test)[:, 1]": 1,
      "score_test": 1,
      "model.predict(val_images)": 1,
      "y_preds[:, 1]": 1,
      "Y_pred_proba_clf[:, 1]": 1,
      "Y_pred_proba_rf[:, 1]": 1,
      "nb_clf.predict_proba(X_train)[:, 1]": 1,
      "rf_clf.predict_proba(X_train)[:, 1]": 1,
      "logit_clf.predict_proba(X_train)[:, 1]": 1,
      "lda_clf.predict_proba(X_train)[:, 1]": 1,
      "qda_clf.predict_proba(X_train)[:, 1]": 1,
      "Y_train_prediction": 1,
      "y_pred_df": 1,
      "y_pred_binary[:, i]": 1,
      "y_pred_binary.ravel()": 1,
      "train_predict_prob[:, 1]": 1,
      "y_hat_lstm": 1,
      "y_hat_cnn": 1,
      "pred_labels": 1,
      "y_hat[Label]": 1,
      "log_scores": 1,
      "y_pred_xgboost_v1": 1,
      "y_pred_xgboost": 1,
      "pred_oh": 1,
      "pred_le": 1,
      "model.predict_proba(x_train.iloc[idx_train])[:, 1]": 1,
      "model.predict_proba(x_train.iloc[idx_validation])[:, 1]": 1,
      "p_b": 1,
      "val_merged.target_y": 1,
      "train_merged.target_y": 1,
      "lr.predict_proba(X_val)[:, 1]": 1,
      "y1_pred": 1,
      "pipe3_pred": 1,
      "y2_pred": 1,
      "eclfY": 1,
      "test_output['results']": 1,
      "pred_prob_y": 1,
      "missing['miss_' + c]": 1,
      "~missing['miss_' + c]": 1,
      "count_nb_pred": 1,
      "count_bnb_pred": 1,
      "count_lsvc_pred": 1,
      "count_svc_pred": 1,
      "count_nusvc_pred": 1,
      "count_sgd_pred": 1,
      "count_lr_pred": 1,
      "ada_pred": 1,
      "LRClassifer.predict_proba(X_test)[:, 1]": 1,
      "NBClassifer.predict_proba(X_test)[:, 1]": 1,
      "DTClassifer.predict_proba(X_test)[:, 1]": 1,
      "XGBClassifer.predict_proba(X_test)[:, 1]": 1,
      "pred_probs": 1,
      "logpred": 1,
      "randforestpred": 1,
      "lgbmpred": 1,
      "y_train_predict": 1,
      "y_test_predict": 1,
      "Lrpredictions": 1,
      "pred_proba": 1,
      "y_score[:, 1]": 1,
      "prob_y_valrf": 1,
      "pred_y": 1,
      "y_train_pred1": 1,
      "train_preds__": 1,
      "clf.predict_proba(X_val)[:, 1]": 1,
      "predictions_val": 1,
      "pred_val_y": 1,
      "pred_Y": 1,
      "np.zeros_like(trainingset['is_duplicate']) + prob": 1,
      "npPred": 1,
      "Y_pred": 1,
      "pred[:, 1]": 1,
      "log_model.predict_proba(X_test)[:, 1]": 1,
      "log_model_.predict_proba(X_test_)[:, 1]": 1,
      "pred_prob_lr": 1,
      "pred_prob_sgdc": 1,
      "pred_prob_nb": 1,
      "y_predicted_for_bow_with_best_alpha_train": 1,
      "y_predicted_for_bow_with_best_alpha_validation": 1,
      "y_all_features.round()": 1,
      "y_selected_features.round()": 1,
      "test_pred": 1,
      "y_predicted": 1,
      "train_pred_prob": 1,
      "train_prob_rd": 1,
      "train_prob_nn": 1,
      "X_train_gnb": 1,
      "preds['anomalyScore']": 1,
      "error_df.Reconstruction_error": 1,
      "y_train_prob": 1,
      "y_test_prob": 1,
      "oof_predictions": 1,
      "y_test_pred_clf": 1,
      "y_cal_pred_clf": 1,
      "y_probs": 1,
      "predictions_2": 1,
      "clf.predict_proba(X_train[trn_idx])[:, 1]": 1,
      "clf.predict_proba(X_train[val_idx])[:, 1]": 1,
      "np.zeros(len(y_test))": 1,
      "stack_ytrain_pred": 1,
      "self.mdl.predict(data_in[test_idx])": 1,
      "clf.predict_proba(X)[:, 1]": 1,
      "y_pred[:, 1]": 1,
      "Y_predict": 1,
      "Y_predict_smote": 1,
      "Y_predict_pca": 1,
      "Y_predict_rf": 1,
      "y_pred1": 1,
      "final[:, 1]": 1,
      "oof_weighted_resp": 1,
      "oof_zero": 1,
      "oof_probas[val_idx, 4]": 1,
      "trn_pred": 1,
      "p_class": 1,
      "val_answers": 1,
      "pred_val.numpy()[:, 1]": 1,
      "Predict_ValidData": 1,
      "valp": 1,
      "DT_cv_pred": 1,
      "RF_cv_pred": 1,
      "lightGBM_pred": 1,
      "Y_test_pridict": 1,
      "fpred": 1,
      "pred_train_mtx": 1,
      "y_probability[:, 1]": 1,
      "probs[n][:, 1]": 1,
      "gs": 1,
      "oof_reg_preds": 1,
      "prediction_ans": 1,
      "clf2.decision_function(X_test)": 1,
      "y_train_pred_probs": 1,
      "y_valid_pred_probs": 1,
      "y_predict_proba": 1,
      "y_oob": 1,
      "validation_probabilities": 1,
      "error_df.error": 1,
      "y_pred[:, i]": 1,
      "predictions[:, i]": 1,
      "OOF": 1,
      "y_pred_classes[:, i]": 1,
      "lgbm.y_pred": 1,
      "yPredLGB": 1,
      "yPredXGB": 1,
      "n_probs": 1,
      "lgbm_probs": 1,
      "valpreds": 1,
      "valpreds_pesudo": 1,
      "y_pred[:, [1]]": 1,
      "y_predict_prob[:, 1]": 1,
      "y_pred_prob_logreg_class1": 1,
      "y_pred_prob_rfc_class1": 1,
      "y_pred_prob_SGD": 1,
      "predict[:, 1]": 1,
      "prediction[:, idx]": 1,
      "tree_pred": 1,
      "nb_pred": 1,
      "logreg.predict_proba(X_test_b)[:, 1]": 1,
      "clf.predict_proba(X_test_b)[:, 1]": 1,
      "dt.predict_proba(X_test_b)[:, 1]": 1,
      "model.predict_proba(X_test_b)[:, 1]": 1,
      "train_eval_probs": 1,
      "forest_scores": 1,
      "probabilities[:, 0]": 1,
      "decision_function": 1,
      "y_prob_nb": 1,
      "result.reshape(66187)": 1,
      "y_pred_Xception": 1,
      "y_pred_Incep": 1,
      "pred_probs['Pos']": 1,
      "test_df.TARGET_prob": 1
    },
    "sklearn.metrics._ranking.auc.x": {
      "fpr": 521,
      "false_positive_rate": 65,
      "x": 36,
      "fpr[i]": 36,
      "mean_fpr": 29,
      "fpr['micro']": 23,
      "recall": 21,
      "fpr_keras": 20,
      "train_fpr": 16,
      "fpr['macro']": 14,
      "test_fpr": 13,
      "re": 10,
      "frp": 7,
      "fpr2": 5,
      "xgb_recall": 4,
      "fpr1": 3,
      "fpr3": 3,
      "fpr_train": 3,
      "fpr4": 3,
      "fp": 3,
      "fp_rf": 3,
      "fpr_rf": 3,
      "FPR": 2,
      "val_fpr": 2,
      "fp_rates": 2,
      "fpr_rfc": 2,
      "fpr_xgb": 2,
      "fpr_lgb": 2,
      "fpr_lr": 2,
      "fpr_test": 2,
      "f": 2,
      "fpr_train_bow": 2,
      "fpr_validation_bow": 2,
      "falsePositiveRate['micro']": 2,
      "fpr_": 2,
      "fpr[label_num]": 2,
      "fpr_val": 2,
      "fpr0": 1,
      "FPR1": 1,
      "cv_fpr": 1,
      "lg_recall": 1,
      "ada_recall": 1,
      "rec": 1,
      "val_rec": 1,
      "fpr_keras2": 1,
      "fpr_1": 1,
      "tg": 1,
      "false_positive_rate_nb": 1,
      "false_positive_rate_mlp": 1,
      "false_positive_rate_rf": 1,
      "fpr_valid": 1,
      "false": 1,
      "fpr_gus": 1,
      "fpr_lstm": 1,
      "fpr_cnn": 1,
      "fpr_p": 1,
      "fpr_n": 1,
      "fpr5": 1,
      "fpr6": 1,
      "fpr7": 1,
      "fpr8": 1,
      "fpr9": 1,
      "false_pos_logreg": 1,
      "false_pos_rf": 1,
      "false_pos_lgbm": 1,
      "fpr_all_features": 1,
      "fpr_selected_features": 1,
      "false_pos_rate": 1,
      "falsePositiveRate[i]": 1,
      "falsePositiveRate['macro']": 1,
      "act": 1,
      "fp_rate": 1,
      "trn_fpr": 1,
      "fpr_stack": 1,
      "fpr_bert": 1,
      "rcl": 1,
      "False_Positive_rate": 1,
      "fpr[clas]": 1,
      "fpr['all']": 1,
      "r": 1,
      "fpr_ensemble": 1,
      "fpr_Xception": 1,
      "fpr_Incep": 1,
      "fpr_knn": 1
    },
    "sklearn.metrics._ranking.auc.y": {
      "tpr": 501,
      "true_positive_rate": 43,
      "tpr[i]": 36,
      "y": 35,
      "mean_tpr": 29,
      "tpr['micro']": 23,
      "recall": 22,
      "precision": 20,
      "tpr_keras": 20,
      "train_tpr": 16,
      "tpr['macro']": 14,
      "test_tpr": 13,
      "pr": 11,
      "tpr_cut": 8,
      "tpr_previous": 8,
      "trp": 7,
      "tpr2": 5,
      "xgb_precision": 4,
      "rc": 4,
      "tpr1": 3,
      "tpr3": 3,
      "tpr_train": 3,
      "tpr4": 3,
      "tp": 3,
      "tp_rf": 3,
      "tpr_rf": 3,
      "TPR": 2,
      "val_tpr": 2,
      "tp_rates": 2,
      "tpr_rfc": 2,
      "tpr_xgb": 2,
      "tpr_lgb": 2,
      "tpr_lr": 2,
      "tpr_test": 2,
      "t": 2,
      "tpr_train_bow": 2,
      "tpr_validation_bow": 2,
      "truePositiveRate['micro']": 2,
      "tpr_": 2,
      "tpr[label_num]": 2,
      "tpr_val": 2,
      "tpr0": 1,
      "TPR1": 1,
      "cv_tpr": 1,
      "lg_precision": 1,
      "ada_precision": 1,
      "prec": 1,
      "val_prec": 1,
      "tpr_keras2": 1,
      "tpr_1": 1,
      "true_positive_rate_nb": 1,
      "true_positive_rate_mlp": 1,
      "true_positive_rate_rf": 1,
      "tpr_valid": 1,
      "true": 1,
      "tpr_gus": 1,
      "tpr_lstm": 1,
      "tpr_cnn": 1,
      "tpr_p": 1,
      "tpr_n": 1,
      "tpr5": 1,
      "tpr6": 1,
      "tpr7": 1,
      "tpr8": 1,
      "tpr9": 1,
      "true_pos_logreg": 1,
      "true_pos_rf": 1,
      "true_pos_lgbm": 1,
      "tpr_all_features": 1,
      "tpr_selected_features": 1,
      "true_pos_rate": 1,
      "truePositiveRate[i]": 1,
      "truePositiveRate['macro']": 1,
      "pred": 1,
      "tp_rate": 1,
      "trn_tpr": 1,
      "tpr_stack": 1,
      "tpr_bert": 1,
      "y - ymin": 1,
      "prc": 1,
      "precison": 1,
      "True_Positive_rate": 1,
      "tpr[clas]": 1,
      "tpr['all']": 1,
      "p": 1,
      "tpr_ensemble": 1,
      "tpr_Xception": 1,
      "tpr_Incep": 1,
      "tpr_knn": 1
    },
    "sklearn.metrics._regression.mean_absolute_error.y_true": {
      "y_test": 564,
      "y_valid": 219,
      "y": 193,
      "y_val": 134,
      "numpy.expm1(Y_val)": 131,
      "y_train": 115,
      "val_y": 65,
      "y_true": 63,
      "y_pred": 43,
      "Y_test": 42,
      "predictions": 41,
      "y_train.values.flatten()": 37,
      "true": 31,
      "m.predict(X_train)": 26,
      "pred": 25,
      "test_y": 24,
      "y_eval": 23,
      "m.predict(X_valid)": 22,
      "Y_real": 22,
      "Y_train": 16,
      "oof_pred": 15,
      "x_val.logerror": 15,
      "prediction": 14,
      "y_tr": 14,
      "true_regression_line": 14,
      "train_y": 13,
      "ytr": 13,
      "Y_valid": 12,
      "preds": 12,
      "targets['target']": 12,
      "y_trainval": 12,
      "val_predictions": 11,
      "np.exp(preds)": 11,
      "full_rows.Age": 11,
      "true_regression_line[test_set]": 10,
      "y_test_rf": 10,
      "np.exp(y)": 9,
      "np.exp(y) - shift": 9,
      "np.exp(y_val)": 9,
      "ytest": 9,
      "y_train_valid": 9,
      "validation_target": 9,
      "Y_val": 8,
      "rf_val_predictions": 8,
      "optimization_target": 8,
      "valid_y": 7,
      "Y": 7,
      "validate_Y": 7,
      "y_test2": 6,
      "my_model.predict(test_X)": 6,
      "loaded_dfs['time_to_eruptionmean']": 6,
      "df[target_col]": 6,
      "y1Val": 6,
      "y2Val": 6,
      "train['FVC']": 5,
      "y_vl": 5,
      "predicted": 5,
      "np.exp(y_label_log)": 5,
      "10**Y_test": 5,
      "logReal": 4,
      "target": 4,
      "ypred": 4,
      "y_valid.rolling(28).mean()[28:]": 4,
      "np.expm1(y_test)": 4,
      "sample_y": 4,
      "my_model.predict(train_X)": 4,
      "y_test1": 4,
      "_output['val'].to_numpy()": 4,
      "pred_train": 4,
      "Ytest": 4,
      "np.log1p(y_train)": 4,
      "np.log1p(y_test)": 4,
      "y_ts": 4,
      "m3.predict(x_train)": 4,
      "m3.predict(x_val)": 4,
      "Y_cv": 4,
      "y_valid_f": 4,
      "y_ts.as_matrix()": 4,
      "y_valid_per_fold": 4,
      "test[:, -1]": 4,
      "Model_y_test": 4,
      "m.predict(X_test)": 4,
      "train['logerror'].values": 4,
      "Y_train_model": 4,
      "y_test_reg_us.TargetValue": 4,
      "train_df['winPlacePerc']": 4,
      "np.exp(sdc_loss.inverse_transform(y_train))": 4,
      "np.exp(sdc_loss.inverse_transform(y_test))": 4,
      "series[window:]": 3,
      "test_sales": 3,
      "train.time_to_failure[:-5]": 3,
      "y_test.values": 3,
      "RF.predict(x_train)": 3,
      "RF.predict(x_val)": 3,
      "y_t": 3,
      "x": 3,
      "y2_valid": 3,
      "confirm_va1": 3,
      "fatal_val1": 3,
      "predictions_prob": 3,
      "y_predict": 3,
      "oof_pred_lgb": 3,
      "oof_pred_cat": 3,
      "model.predict(x_train)": 3,
      "model.predict(x_val)": 3,
      "ytrainpred": 3,
      "ytestpred": 3,
      "predict": 3,
      "np.exp(yte) - 200": 3,
      "test_linear_pred": 3,
      "y_val_ar": 3,
      "scaler_target.inverse_transform(test_y)": 3,
      "y[index1]": 3,
      "y[index2]": 3,
      "y[index3]": 3,
      "y[index4]": 3,
      "y[index5]": 3,
      "y[index6]": 3,
      "y[index7]": 3,
      "mfcc_ttf_df.time_to_failure": 3,
      "yt": 3,
      "data_pred.winPlacePerc": 3,
      "y_meas": 3,
      "sample_drop_y": 3,
      "y_val_pred": 2,
      "Y_predict": 2,
      "np.exp(y_test)": 2,
      "train[TARGET].values": 2,
      "cv_train[TARGET].values": 2,
      "cv_val[TARGET].values": 2,
      "labels": 2,
      "ysub_val": 2,
      "np.exp(Y_test_0)": 2,
      "np.exp(Y_test_1)": 2,
      "np.exp(Y_test_2)": 2,
      "df_test_local['Expected']": 2,
      "df_test_local[df_test_local['Expected'] > outlier]['Expected']": 2,
      "df_test_local[df_test_local['Expected'] < outlier]['Expected']": 2,
      "predictions_2": 2,
      "rfh_y_pred": 2,
      "y_test_values": 2,
      "dftestY": 2,
      "gbm.predict(x_valid)": 2,
      "data_test['Weekly_Sales']": 2,
      "[predictions] * len(test_y)": 2,
      "my_model.predict(train_X[:500])": 2,
      "train[target]": 2,
      "train.loc[idx, target]": 2,
      "y_labels": 2,
      "tuned_predictions": 2,
      "yval": 2,
      "yte": 2,
      "true_cases": 2,
      "true_fatalities": 2,
      "y_train_f": 2,
      "rf.predict(x_train)": 2,
      "rf.predict(x_val)": 2,
      "df['age']": 2,
      "df['domain1_var1']": 2,
      "df['domain1_var2']": 2,
      "df['domain2_var1']": 2,
      "df['domain2_var2']": 2,
      "output['val'].to_numpy()": 2,
      "actuals": 2,
      "ground_truth": 2,
      "y_train.values": 2,
      "ytrain": 2,
      "rf_predictions": 2,
      "y_test_br": 2,
      "y_valid.values.flatten()": 2,
      "val_prediction": 2,
      "Y_pred": 2,
      "y_val.values.flatten()": 2,
      "df['winPlacePerc']": 2,
      "np.log(y_test)": 2,
      "testing['loss']": 2,
      "cases_test": 2,
      "All_RF.Sales": 2,
      "All_NN.Sales": 2,
      "df_val[label]": 2,
      "y_test.iloc[:, 0]": 2,
      "y_test.iloc[:, 1]": 2,
      "y_test.iloc[:, 2]": 2,
      "housing_labels": 2,
      "predictions_val['Weekly_Sales']": 2,
      "df[df.jtype == t]['y_true']": 2,
      "truth": 2,
      "y_valid1": 2,
      "y_test_ind": 2,
      "df_trn3['winPlacePerc']": 2,
      "actualFVC": 2,
      "np.expm1(Y_test)": 2,
      "train[train['month'] >= m]['logerror'].values": 2,
      "Test_us['y']": 2,
      "y_test[:10000]": 2,
      "np.exp(y) - 200": 2,
      "dtrain['logerror']": 2,
      "predict_val": 2,
      "test_labels": 2,
      "prob": 2,
      "trainSet2['SalePrice']": 2,
      "y_v": 2,
      "pred_vals": 2,
      "X.time_to_failure": 2,
      "claims_predict": 2,
      "Y_values": 2,
      "test_df.iloc[:, -1]": 2,
      "yTest": 2,
      "pred_df[d]": 2,
      "df_val['winPlacePerc']": 2,
      "validation_y": 2,
      "df[target]": 1,
      "y[valid_mask]": 1,
      "opt_sigma[valid_mask]": 1,
      "x['y']": 1,
      "x['so']": 1,
      "model.predict(X_test)": 1,
      "model2.predict(X_test)": 1,
      "inv_y": 1,
      "y_temp": 1,
      "train_df['winPlacePerc_mean']": 1,
      "10**Y1": 1,
      "np.expm1(house_prices_model_pred)": 1,
      "pred.reshape([30490 * 28, 1])": 1,
      "Yts": 1,
      "train_sales": 1,
      "np.exp(y_train) - shift": 1,
      "y_test * 10**(-5)": 1,
      "y_monthly_test * 10**(-5)": 1,
      "linreg.predict(X_val)": 1,
      "forest.predict(X_val)": 1,
      "test_set['wx']": 1,
      "test_set['wy']": 1,
      "test_set['wz']": 1,
      "y_test[0]": 1,
      "y_cross": 1,
      "knn.predict(x_tr)": 1,
      "xgb.predict(x_tr)": 1,
      "xgb.predict(x_te)": 1,
      "selected_model.predict(train_signal)": 1,
      "selected_model.predict(validation_signal)": 1,
      "abs(modelpred).astype(int)": 1,
      "modelpredss": 1,
      "lr_y": 1,
      "svr_y": 1,
      "knn_y": 1,
      "dt_y": 1,
      "rf_y": 1,
      "xgb_y": 1,
      "adb_y": 1,
      "xgh_y_pred": 1,
      "final_pred": 1,
      "predict_1": 1,
      "fpredict": 1,
      "np.expm1(y_train_rnn)": 1,
      "np.expm1(y_val_rnn)": 1,
      "np.expm1(y_train_ridge)": 1,
      "np.expm1(y_val_ridge)": 1,
      "np.expm1(y_val_rnn.values.reshape(-1, 1))": 1,
      "np.expm1(y_train_rnn.values.reshape(-1, 1))": 1,
      "y_cv": 1,
      "y_trn_df": 1,
      "derived_trn.target": 1,
      "prediction1": 1,
      "original_df.sales[-28:]": 1,
      "predict_train": 1,
      "predict_train_rfr": 1,
      "val_test": 1,
      "fitted[test, 2]": 1,
      "train.loc[idx, 'FVC']": 1,
      "y_pred_k": 1,
      "y_pred_rf": 1,
      "_pred": 1,
      "preds_1": 1,
      "preds_2": 1,
      "preds_3": 1,
      "y_valid_4": 1,
      "loaded_dfs['time_to_eruptionmean'][val_idx]": 1,
      "y_pred1": 1,
      "np.expm1(Y_train)": 1,
      "np.expm1(Y_val)": 1,
      "self.Y": 1,
      "y_trn_cv": 1,
      "y_val_cv": 1,
      "test_predictions": 1,
      "test_data": 1,
      "df_train.target": 1,
      "reg.predict(Xv)": 1,
      "y_test_age": 1,
      "y_train_age": 1,
      "y_test_d1v1": 1,
      "y_train_d1v1": 1,
      "y_test_d1v2": 1,
      "y_train_d1v2": 1,
      "y_test_d2v1": 1,
      "y_train_d2v1": 1,
      "y_test_d2v2": 1,
      "y_train_d2v2": 1,
      "train_result['PredPrice']": 1,
      "pred_valid": 1,
      "train[label]": 1,
      "y_val.flatten()": 1,
      "mt_target_test": 1,
      "m1.predict(X_train)": 1,
      "all_y_cnn": 1,
      "y_train_true": 1,
      "y_train[:i]": 1,
      "rf_val_predictions1": 1,
      "rf_val_predictions2": 1,
      "TimeData.values.flatten()": 1,
      "RFR.predict(x_train)": 1,
      "RFR.predict(x_val)": 1,
      "tr_y": 1,
      "va_y": 1,
      "y_inv": 1,
      "unit_sales_by_date.values[moving_average_days:]": 1,
      "np.ravel(y_val.values)": 1,
      "y_te": 1,
      "data[window_size:]": 1,
      "target2": 1,
      "y_valid.tolist()": 1,
      "real_values": 1,
      "dtrain['winPlacePerc'].values": 1,
      "rf_n_estimators_val_predictions": 1,
      "np.log(y_valid)": 1,
      "y_valid_final": 1,
      "np.log(y_valid_final)": 1,
      "y_valid_pca": 1,
      "np.log(y_valid_pca)": 1,
      "transform(x, True)": 1,
      "np.exp(x)": 1,
      "pubg_y": 1,
      "label_valid": 1,
      "model.predict(valid[cols])": 1,
      "model.predict(X_valid)": 1,
      "exps_data[k][1]": 1,
      "teY": 1,
      "dy_test": 1,
      "oof": 1,
      "ytrue": 1,
      "gscv.predict(X_pca)": 1,
      "results": 1,
      "y_test3": 1,
      "subs[i].values[:, 1:]": 1,
      "y_true.values.flatten()": 1,
      "y_test_ll": 1,
      "y_test_fr": 1,
      "y_test_p24": 1,
      "y_test_p25": 1,
      "y_test.iloc[:, i]": 1,
      "y_test.iloc[:, 3]": 1,
      "df.Fatalities.values": 1,
      "y_trainset": 1,
      "predictions_val_lr['Weekly_Sales']": 1,
      "Y_test_mod": 1,
      "test_label": 1,
      "np.exp(preds) - SHIFT": 1,
      "y_true.cpu().numpy()": 1,
      "val_y1": 1,
      "val_y2": 1,
      "val_y3": 1,
      "gbm.predict(X_valid, num_iteration=gbm.best_iteration)": 1,
      "np.exp(y_tr) - shift": 1,
      "np.exp(y_val) - shift": 1,
      "test": 1,
      "targets_orig": 1,
      "val_predictions_tree": 1,
      "val_predictions_XG": 1,
      "val_prediction_LSTM": 1,
      "ypred_lr": 1,
      "ypred_lasso": 1,
      "model.predict(x_train, num_iteration=model.best_iteration)": 1,
      "model.predict(x_val, num_iteration=model.best_iteration)": 1,
      "df_solo['winPlacePerc']": 1,
      "validation": 1,
      "target_lr": 1,
      "avg_ytest": 1,
      "y_train_pred": 1,
      "preidct_2": 1,
      "self.y_test": 1,
      "np.exp(model.predict(X_val)) - shift": 1,
      "final_fold_prediction": 1,
      "target_train": 1,
      "y_linear": 1,
      "sgd_lin_reg.predict(train_data)": 1,
      "sgd_lin_reg.predict(test_data)": 1,
      "ridge_lin_reg.predict(train_data)": 1,
      "ridge_lin_reg.predict(test_data)": 1,
      "lin_SVR.predict(train_data)": 1,
      "lin_SVR.predict(test_data)": 1,
      "kernel_SVR.predict(train_data)": 1,
      "kernel_SVR.predict(test_data)": 1,
      "forest_reg.predict(train_data)": 1,
      "forest_reg.predict(test_data)": 1,
      "lgbm_model.predict(train_data)": 1,
      "lgbm_model.predict(test_data)": 1,
      "rnd_search.best_estimator_.predict(test_data)": 1,
      "Y_scaled": 1,
      "Y[test_index]": 1,
      "pred_price": 1,
      "x['sales']": 1,
      "valY": 1,
      "test[:, 1]": 1,
      "y_test_s": 1,
      "rfr_y_prediction": 1,
      "y_pull_alarm": 1,
      "val_predictions_xgb": 1,
      "ensemble_preds": 1,
      "np.exp(labels) - lift": 1,
      "np.exp(y) - lift": 1,
      "test['sales']": 1,
      "Y_validation": 1,
      "pred_line": 1,
      "pred_ridge": 1,
      "pred_lasso": 1,
      "pred_net": 1,
      "pred_knn": 1,
      "pred_svm": 1,
      "pred_dt": 1,
      "pred_rf": 1,
      "pred_gbm": 1,
      "pred_lgbm": 1,
      "pred_xgb": 1,
      "pred_nn": 1,
      "ones * inc_angles_train.mean()": 1,
      "ones * inc_angles_train.median()": 1,
      "ones * inc_angles_train.astype(np.double).round(1).mode()[0]": 1,
      "predicted_angles": 1,
      "per_type_data[t]['true']": 1,
      "p_LinearModel": 1,
      "p_kNN": 1,
      "p_DT": 1,
      "p_GBR": 1,
      "p_RFR": 1,
      "p_ADA": 1,
      "p_XGB": 1,
      "predicted_vals": 1,
      "y_predictions": 1,
      "m.predict(X_train2)": 1,
      "m.predict(X_valid2)": 1,
      "val_Y": 1,
      "train_Y": 1,
      "y_test['winPlacePerc']": 1,
      "predicted_val": 1,
      "np.expm1(preds)": 1,
      "test_data_target": 1,
      "train_y.values": 1,
      "np.exp(y_true)": 1,
      "y[:NUM_SEGMENTS]": 1,
      "y_cv_t": 1,
      "subs[i][t]": 1,
      "predictions_1": 1,
      "predictions_3": 1,
      "predictions_4": 1,
      "y.target": 1,
      "visibletrain.loss * 2904.0861863904365 + 3037.3376856699792": 1,
      "blindtrain.loss * 2904.0861863904365 + 3037.3376856699792": 1,
      "psdata.target": 1,
      "y_test_plot": 1,
      "y_array": 1,
      "pdct1": 1,
      "y_train_scaled[0:1459]": 1,
      "best_model.predict(dtest)": 1,
      "svm_test_pred": 1,
      "test_bayesian_pred": 1,
      "train_labels": 1,
      "y_valid_1": 1,
      "model.predict(x_test)": 1,
      "y_ds_test": 1,
      "y_solo_test": 1,
      "y_all_test": 1,
      "y_tes": 1,
      "m.predict(X)": 1,
      "val": 1,
      "targets[:len(toxicity_scores)]": 1,
      "obscenities[:len(toxicity_scores)]": 1,
      "severe_toxicities[:len(toxicity_scores)]": 1,
      "[y for x in y_test_overall for y in x]": 1,
      "rf_yval": 1,
      "model.predict(test)": 1,
      "model1.predict(test)": 1,
      "xgb_trainpred": 1,
      "xgb_validpred": 1,
      "xgb_final_trainpred": 1,
      "xgb_final_validpred": 1,
      "gbr_trainpred": 1,
      "gbr_validpred": 1,
      "gbr_final_trainpred": 1,
      "gbr_final_validpred": 1,
      "adr_trainpred": 1,
      "adr_validpred": 1,
      "feature": 1,
      "truth_class": 1,
      "preds_xgb": 1,
      "Xs[:, -28:]": 1,
      "np.expm1(y_train_pred)": 1,
      "np.expm1(y_val_pred)": 1,
      "np.expm1(y_test_pred)": 1,
      "train_predict": 1,
      "rf.predict(X_test)": 1,
      "rf1.predict(X_test1)": 1,
      "y_true.reshape(-1, n_out)": 1,
      "y_true[~mask[:, j], j]": 1,
      "forecast[col]": 1,
      "y_test_CC": 1,
      "y_test_Fa": 1,
      "y_vali": 1,
      "np.exp(y_valid) - shift": 1,
      "np.exp(target) - shift": 1,
      "y_org_test": 1,
      "y_shift_test": 1,
      "yvalid": 1,
      "predictions_XGboostRegressor": 1,
      "predictions_linReg": 1,
      "predictions_DTR": 1,
      "predictions_RFR": 1,
      "predictions_GBR": 1,
      "predictions_catb": 1,
      "predictions_lightgbm": 1,
      "b_test['Lake_Level']": 1,
      "b_test.loc[:datetime.date(2017, 1, 1), 'Lake_Level']": 1,
      "b_test['Flow_Rate']": 1,
      "b_test.loc[:datetime.date(2017, 1, 1), 'Flow_Rate']": 1,
      "error_calc_df['Depth_to_Groundwater_P24']": 1,
      "error_calc_df['Depth_to_Groundwater_P25']": 1,
      "monthly_pred['Depth_to_Groundwater_P24']": 1,
      "monthly_pred['Depth_to_Groundwater_P25']": 1,
      "pred_df.loc[:datetime.date(2019, 1, 1), d]": 1,
      "pred_df.loc[:datetime.date(2015, 1, 1), d]": 1,
      "outputs": 1,
      "cases.iloc[0:13459]": 1,
      "train[['FVC']]": 1,
      "self.y_true['train'][-1]": 1,
      "self.y_true['val'][-1]": 1,
      "oof['target']": 1,
      "oof_noDWT['target']": 1,
      "y1_test_pred": 1,
      "y2_test_pred": 1
    },
    "sklearn.metrics._regression.mean_absolute_error.y_pred": {
      "y_pred": 308,
      "numpy.expm1(model.predict(X_val[:, i_cols_list]))": 130,
      "y_test": 106,
      "preds": 92,
      "pred[:, 1]": 89,
      "pred": 82,
      "y_valid": 77,
      "y_pred_valid": 72,
      "predictions": 69,
      "y_train": 54,
      "y_val": 43,
      "val_y": 41,
      "y_predict": 36,
      "test_y": 35,
      "Y_pred": 34,
      "predicted": 33,
      "oof": 33,
      "fudge * valid_pred": 22,
      "train_preds": 21,
      "val_preds": 21,
      "y_val_pred": 21,
      "y_predicted": 21,
      "test_pred": 18,
      "y_head": 18,
      "valid_pred": 16,
      "y_valid_pred": 16,
      "train_pred": 16,
      "prediction": 15,
      "xgb_oof_train": 14,
      "val_predictions": 13,
      "y_final_test_predict": 13,
      "y_pred['yhat']": 13,
      "oof_preds[val_idx]": 12,
      "y_pred_rf": 12,
      "np.exp(labels)": 11,
      "y_preds": 10,
      "oof_preds": 9,
      "np.exp(yhat)": 9,
      "y_test_pred": 9,
      "ypred": 9,
      "y_pred1": 9,
      "oof_part": 9,
      "xgb_pred": 9,
      "train_preds[:, 1]": 8,
      "np.exp(yhat) - shift": 8,
      "np.exp(scores_val)": 8,
      "zy_slope.predict(X)": 8,
      "xzy_slope.predict(X)": 8,
      "val_pred": 7,
      "y_pred_train": 7,
      "p": 7,
      "y": 7,
      "y_hat": 7,
      "pred_val": 7,
      "log_test_prices": 7,
      "RFG.predict(x_test)": 6,
      "preds_val": 6,
      "models.predict(test_x)": 6,
      "pred_rf": 6,
      "log_train_prices": 6,
      "ans": 6,
      "y1Pred": 6,
      "y2Pred": 6,
      "y_pred2": 5,
      "pred_train": 5,
      "train_y": 5,
      "y_train_pred": 5,
      "yhat": 5,
      "readable_preds": 5,
      "tar_train": 5,
      "tar_valid": 5,
      "predictions1": 4,
      "oof_preds[valid_idx]": 4,
      "p_test": 4,
      "Y_predict": 4,
      "Y_test": 4,
      "predict_val": 4,
      "pd.Series(y_pred_valid).rolling(28).mean()[28:]": 4,
      "val_y_pred": 4,
      "y_pred_test": 4,
      "pred_knn": 4,
      "xgb_pred1": 4,
      "xgb_pred2": 4,
      "pred_oob": 4,
      "y_test1": 4,
      "oof_LGBM": 4,
      "oof_final": 4,
      "_output['pred'].to_numpy()": 4,
      "np.log1p(y_train_pred_xgb)": 4,
      "np.log1p(y_test_pred_xgb)": 4,
      "predict": 4,
      "model1": 4,
      "model2": 4,
      "model1 * 0.5 + model2 * 0.5": 4,
      "one_result": 4,
      "model0.predict(x_ts)": 4,
      "baseline_predictions": 4,
      "y_gp": 4,
      "model.predict(df[feature_col].replace(values_dict).values.reshape(-1, 1))[:, 1]": 4,
      "knn_preds": 3,
      "predictions2": 3,
      "rolling_mean[window:]": 3,
      "clf.predict(X_test)": 3,
      "test_prediction": 3,
      "model.predict(X_train)": 3,
      "model.predict(X_test)": 3,
      "y_pred_xgb": 3,
      "y_predicted_r": 3,
      "pred0": 3,
      "end": 3,
      "y2_pred": 3,
      "reg.predict(X)": 3,
      "confirm_test_case": 3,
      "fatal_test_case": 3,
      "y_trainpred": 3,
      "pred1": 3,
      "model.predict(X_val)": 3,
      "targets": 3,
      "np.log(y_pred)": 3,
      "y_true": 3,
      "Y_test_predict": 3,
      "forest_predictions": 3,
      "inc_angles_valid": 3,
      "testPredictions": 3,
      "pred_median": 3,
      "prediction_pp_xg": 3,
      "pre": 3,
      "y_test_confirmed": 3,
      "yp": 3,
      "data_pred.adj_winPlacePerc": 3,
      "y_predicted_d": 3,
      "Dec_Tree": 2,
      "pred2": 2,
      "rfr_preds": 2,
      "lr_preds": 2,
      "y_pred_next": 2,
      "predictions_rforest": 2,
      "deep_predictions": 2,
      "BASELINE_FUDGE_FACTOR * valid_pred": 2,
      "fudge0 + fudge1 * valid_pred": 2,
      "0 * ypred": 2,
      "model.predict(X_valid)": 2,
      "FUDGE_FACTOR * valid_pred": 2,
      "train.final_prediction[:-5]": 2,
      "y_pred1 * 0.5 + y_pred2 * 0.5": 2,
      "xg_pred": 2,
      "y_tr": 2,
      "y_te": 2,
      "XGBpredictions": 2,
      "rf_predictions": 2,
      "adb_y": 2,
      "predicted_values": 2,
      "y_predicted_values": 2,
      "rf.predict(X_val)": 2,
      "pred_rfr": 2,
      "lgbm.predict(X_test, num_iteration=lgbm.best_iteration_)": 2,
      "y_pred_lr": 2,
      "np.expm1(predict)": 2,
      "temp_predict": 2,
      "train_y[:500]": 2,
      "preds_ensemble_avg": 2,
      "preds[:, 1]": 2,
      "oof_preds_m": 2,
      "oof_df[m]": 2,
      "oof_df.loc[idx, m]": 2,
      "y_pred_results": 2,
      "m.predict(X_test)": 2,
      "y_p": 2,
      "lr_tfidf_predict": 2,
      "y_test_flatten1": 2,
      "predictions / ((count + 1) * (count1 + 1))": 2,
      "pred_cases": 2,
      "pred_fatalities": 2,
      "oof_geomean": 2,
      "y_pred_dt": 2,
      "y_pred_knn": 2,
      "predict_dt1": 2,
      "reg.predict(X_test)": 2,
      "output['pred'].to_numpy()": 2,
      "Y": 2,
      "oof_predictions": 2,
      "pre_train": 2,
      "pre_test": 2,
      "xg_oof_train": 2,
      "et_oof_train": 2,
      "rf_oof_train": 2,
      "model1[test_set]": 2,
      "model2[test_set]": 2,
      "(model1 * 0.5 + model2 * 0.5)[test_set]": 2,
      "y_pred_br": 2,
      "valid_y": 2,
      "cbr_pred": 2,
      "lmpr": 2,
      "xgbpr": 2,
      "lspr": 2,
      "rdgr": 2,
      "ecnpr": 2,
      "adrpr": 2,
      "clfcv.best_estimator_.predict(x_tr_n)": 2,
      "clfcv.best_estimator_.predict(x_ts_n)": 2,
      "predictValues": 2,
      "model.predict(x_test)": 2,
      "intercept + x1param * model1 + x2param * model2": 2,
      "ridge_oof": 2,
      "y_hold": 2,
      "preds_f": 2,
      "All_RF.Predicted": 2,
      "All_NN.Predicted": 2,
      "y_prediction": 2,
      "x_values": 2,
      "y_predict_": 2,
      "y_train_predicted": 2,
      "sgd_pred": 2,
      "y_pred_2": 2,
      "housing_predictions": 2,
      "df[df.jtype == t]['y_pred']": 2,
      "predictions_fat": 2,
      "LinReg.predict(x_test)": 2,
      "y_test_predict": 2,
      "yPredict": 2,
      "predictedFVC[:, 1]": 2,
      "scores_val": 2,
      "np.expm1(model.predict(X_test))": 2,
      "valid_preds": 2,
      "predictions_2": 2,
      "stores_and_dept_preds": 2,
      "y_linear_pred_train": 2,
      "y_linear_pred": 2,
      "y_xgb_preds_train": 2,
      "y_xgb_preds": 2,
      "y_cat_preds_train": 2,
      "y_cat_preds": 2,
      "y_test_pred2": 2,
      "Test_us['yhat']": 2,
      "(y_pred_train + offset) * mult": 2,
      "dtrain_predprob": 2,
      "y_test_c": 2,
      "pred_svr": 2,
      "y_treino": 2,
      "predicted_home_prices": 2,
      "val_y['SalePrice']": 2,
      "model.predict(df[feature_col].values.reshape(-1, 1))[:, 1]": 2,
      "pred_nb": 2,
      "np.expm1(y_val)": 2,
      "rf_preds": 2,
      "lir_preds": 2,
      "sgdr_preds": 2,
      "lir_preds2": 2,
      "averaged_train_predict": 2,
      "pred_time": 2,
      "pred_diff": 2,
      "pred_comb": 2,
      "final_prediction": 2,
      "pred[:, 0]": 2,
      "y_predicted_p": 2,
      "estimator.predict(X)": 2,
      "gr_predict": 2,
      "pred_df['pred']": 2,
      "np.expm1(lgb.predict(x_test))": 2,
      "p_valid": 2,
      "predTest": 1,
      "Ridge": 1,
      "Lasso": 1,
      "Lpred2": 1,
      "m": 1,
      "pred_mean[valid_mask]": 1,
      "pred_sigma[valid_mask]": 1,
      "x['p']": 1,
      "x['s']": 1,
      "grid_predictions": 1,
      "lightgbm_predictions": 1,
      "svr_predictions": 1,
      "xgboost_predictions": 1,
      "gbr_predictions": 1,
      "elastic_predictions": 1,
      "lasso_predictions": 1,
      "stack_predictions": 1,
      "blend_predictions": 1,
      "inv_yhat": 1,
      "m.predict(x_train)": 1,
      "val_test_pred_lgb": 1,
      "10**Y1p": 1,
      "np.expm1(val_y)": 1,
      "y_train_1.reshape([30490 * 28, 1])": 1,
      "np.exp(y_pred)": 1,
      "train_prediction": 1,
      "train.prediction.values": 1,
      "train.lgbm_prediction[:-5]": 1,
      "np.exp(xgb2_oof_train) - shift": 1,
      "house_pred_dt": 1,
      "house_pred_dtmax": 1,
      "house_pred_rf": 1,
      "val": 1,
      "0.5 * y_pred1 + 0.5 * y_pred2": 1,
      "y_pred * 10**(-5)": 1,
      "y_monthly_pred * 10**(-5)": 1,
      "predictions[:, 0]": 1,
      "predictions[:, 1]": 1,
      "predictions[:, 2]": 1,
      "model_RF_pred_valset": 1,
      "model_CatBoost_pred_valset": 1,
      "Y_0_hat": 1,
      "[np.median(np.exp(Y_test_0))] * len(np.exp(Y_test_0))": 1,
      "Y_1_hat": 1,
      "[np.median(np.exp(Y_test_1))] * len(np.exp(Y_test_1))": 1,
      "np.exp(Y_2_hat)": 1,
      "[np.exp(np.median(Y_test_2))] * len(Y_test_2)": 1,
      "df_test_local['y_hat']": 1,
      "[df_learn_local['Expected'].median()] * df_test_local['Id'].nunique()": 1,
      "df_test_local[df_test_local['Expected'] > outlier]['y_hat']": 1,
      "[df_test_local[df_test_local['Expected'] > outlier]['Expected'].median()] * df_test_local[df_test_local['Expected'] > outlier]['Id'].nunique()": 1,
      "df_test_local[df_test_local['Expected'] < outlier]['y_hat']": 1,
      "[df_test_local[df_test_local['Expected'] < outlier]['Expected'].median()] * df_test_local[df_test_local['Expected'] < outlier]['Id'].nunique()": 1,
      "y_pred.tail(test_size)['yhat']": 1,
      "test_predict[:, 0]": 1,
      "predict_transformed(X_cross, est)": 1,
      "train_quaketime": 1,
      "validation_quaketime": 1,
      "y_validation_clean": 1,
      "lr_predictions": 1,
      "lr_y": 1,
      "svr_y": 1,
      "knn_y": 1,
      "dt_y": 1,
      "rf_y": 1,
      "xgb_y": 1,
      "xgh_y_pred": 1,
      "y_hat_testSAL": 1,
      "predictions_1": 1,
      "y_pred_cat": 1,
      "y_predict_x": 1,
      "np.random.random(len(y_test))": 1,
      "garbled_predictions": 1,
      "train_preds['Pred'].values": 1,
      "val_preds1": 1,
      "val_preds2": 1,
      "np.expm1(rnn_train_preds)": 1,
      "np.expm1(rnn_val_preds)": 1,
      "np.expm1(train_ridge_preds)": 1,
      "np.expm1(val_ridge_preds)": 1,
      "aggregate_val": 1,
      "aggregate_train": 1,
      "pred_cv": 1,
      "pred_lgbm": 1,
      "predictions_training": 1,
      "preds_valid": 1,
      "rf_predt": 1,
      "sample_pred": 1,
      "stack_trn": 1,
      "data_test['Weekly_Sales_pred']": 1,
      "data_test['Weekly_Sales_pred_rf_ref']": 1,
      "oof.mean(axis=1)": 1,
      "y_pred_lgb": 1,
      "tree_predictions": 1,
      "unscaled_df.pred_value[-28:]": 1,
      "y_fatalities": 1,
      "observed[test]": 1,
      "stack_train": 1,
      "oof[idx]": 1,
      "train_copy.iloc[:, train_copy.columns == 33].values": 1,
      "_y_val": 1,
      "y_valid_1": 1,
      "y_valid_2": 1,
      "y_valid_3": 1,
      "preds_4": 1,
      "np.full((len(loaded_dfs), ), loaded_dfs['time_to_eruptionmean'].mean())": 1,
      "predictions[val_idx] / ((count + 1) * (count1 + 1))": 1,
      "np.expm1(reg.predict(X_train))": 1,
      "np.expm1(reg.predict(X_val))": 1,
      "y_Optimal_pred": 1,
      "y_pred_trn_cv": 1,
      "y_pred_val_cv": 1,
      "iofs_preds": 1,
      "oofs_preds": 1,
      "forecast": 1,
      "pseudo['time_to_eruption']": 1,
      "Yv": 1,
      "y_pred_age_test": 1,
      "y_pred_age_train": 1,
      "y_pred_d1v1_test": 1,
      "y_pred_d1v1_train": 1,
      "y_pred_d1v2_test": 1,
      "y_pred_d1v2_train": 1,
      "y_pred_d2v1_test": 1,
      "y_pred_d2v1_train": 1,
      "y_pred_d2v2_test": 1,
      "y_pred_d2v2_train": 1,
      "y_pred_age_tot_test": 1,
      "y_pred_age_tot_train": 1,
      "y_pred_d1v1_tot_test": 1,
      "y_pred_d1v1_tot_train": 1,
      "y_pred_d1v2_tot_test": 1,
      "y_pred_d1v2_tot_train": 1,
      "y_pred_d2v1_tot_test": 1,
      "y_pred_d2v1_tot_train": 1,
      "y_pred_d2v2_tot_test": 1,
      "y_pred_d2v2_tot_train": 1,
      "test_labels": 1,
      "linear_reg.predict(X_test)": 1,
      "lasso_reg.predict(X_test)": 1,
      "xgb_reg.predict(X_test)": 1,
      "YTest": 1,
      "train_data['SalePrice']": 1,
      "quant_5": 1,
      "cat.predict(train_samples)": 1,
      "mt_target_pred": 1,
      "Y_train": 1,
      "oof_cnn": 1,
      "Ypred": 1,
      "predictlinear": 1,
      "predictBayesRidge": 1,
      "y_pred_svm": 1,
      "(intercept + x1param * model1 + x2param * model2)[test_set]": 1,
      "y_pred_LR": 1,
      "y_pred_MLP": 1,
      "y_pred_GBR": 1,
      "p_train": 1,
      "p_val": 1,
      "val_y1": 1,
      "val_y2": 1,
      "y_pred_SVR": 1,
      "y_pred_gbm": 1,
      "y_pred_8": 1,
      "TimePredict": 1,
      "predictionsLR": 1,
      "predictionsDTR": 1,
      "predictionsKNNR": 1,
      "tr_pred": 1,
      "va_pred": 1,
      "y_pred_inv": 1,
      "GUIPred(combo[:xtr.shape[0]])": 1,
      "clf.predict(x_tr)": 1,
      "clfcv.best_estimator_.predict(x_tr)": 1,
      "clfcv.best_estimator_.predict(x_ts)": 1,
      "moving_avg": 1,
      "ar_predictions": 1,
      "arma_predictions": 1,
      "arima_predictions": 1,
      "model.predict(val_X)": 1,
      "Yt": 1,
      "np.ravel(y_pred)": 1,
      "model.predict(X_te)": 1,
      "df['win_pred']": 1,
      "df['win_perc']": 1,
      "model.predict(test_x)": 1,
      "gbr.predict(test_x)": 1,
      "rf.predict(test_x)": 1,
      "abr.predict(test_x)": 1,
      "br.predict(test_x)": 1,
      "gpr.predict(test_x)": 1,
      "full_rows['Age01_mean']": 1,
      "full_rows['Age02_sex']": 1,
      "full_rows['Age03_pclass']": 1,
      "full_rows['Age04_sibsp']": 1,
      "full_rows['Age05_parch']": 1,
      "full_rows['Age06_embarked']": 1,
      "full_rows['Age07_SexPClassEmbarkedMean']": 1,
      "full_rows['Age08_PClassEmbarkedMean']": 1,
      "full_rows['Age09_ClassEmbarkedTree']": 1,
      "full_rows['Age10_ClassEmbarkedSexTree']": 1,
      "full_rows['Age11_ClassEmbarkedSexHaveRelativesTree']": 1,
      "rolling_mean[window_size:]": 1,
      "ridge_oof2": 1,
      "y_pred_en": 1,
      "pred_xgb": 1,
      "grid_pred_neural": 1,
      "pred_knnr": 1,
      "predictions_treemodel": 1,
      "Prediction": 1,
      "dtrain_predictions": 1,
      "np.exp(lr_preds)": 1,
      "np.exp(rf_preds)": 1,
      "np.exp(ridge_preds)": 1,
      "np.exp(lasso_preds)": 1,
      "np.exp(preds)": 1,
      "y_pred_final": 1,
      "np.log(y_pred_final)": 1,
      "y_pred_pca": 1,
      "np.log(y_pred_pca)": 1,
      "transform(y, True)": 1,
      "np.exp(y)": 1,
      "np.clip(predict_train_rf, 0, 1)": 1,
      "result": 1,
      "valid['item_cnt_month']": 1,
      "Y_valid": 1,
      "my_model.predict(X_valid)": 1,
      "Tree_preds": 1,
      "Forest_preds": 1,
      "fitted_values": 1,
      "predicts": 1,
      "preds_d": 1,
      "oof[val_idx]": 1,
      "model.predict(X_tr)": 1,
      "lm.predict(X_train)": 1,
      "lm.predict(X_test)": 1,
      "lm.predict(X_train) + model.predict(X_train)": 1,
      "lm.predict(X_test) + model.predict(X_test)": 1,
      "y_pred_GBoost": 1,
      "[sum(results) / N] * len(results)": 1,
      "pred_lr": 1,
      "pred_nn": 1,
      "pred_bag": 1,
      "y_val_predict": 1,
      "y_baseline_predict": 1,
      "predictions3": 1,
      "predict_important": 1,
      "y_pred_other": 1,
      "y_pred_solo": 1,
      "y_pred_multi": 1,
      "y_test_predicted": 1,
      "lin_pred": 1,
      "ela_pred": 1,
      "preds_train": 1,
      "subs[j].values[:, 1:]": 1,
      "y_pred_ll": 1,
      "y_pred_fr": 1,
      "y_pred_p24": 1,
      "y_pred_p25": 1,
      "y_pred_LT2": 1,
      "y_pred_SAL": 1,
      "y_pred_CoS": 1,
      "y_pred[i]": 1,
      "y_pred_0": 1,
      "y_pred_1": 1,
      "y_pred_3": 1,
      "df.predictions.values": 1,
      "x_value": 1,
      "x_value_lgb": 1,
      "predictions_val['Label']": 1,
      "predictions_val['lag_sales']": 1,
      "predictions_val_lr['Label']": 1,
      "model_pred": 1,
      "pred_train_median": 1,
      "pred_val_median": 1,
      "y_naive_pred": 1,
      "val_tree_predictions": 1,
      "np.exp(labels) - SHIFT": 1,
      "y_pred.cpu().numpy()": 1,
      "oof_pred1": 1,
      "oof_pred2": 1,
      "oof_pred3": 1,
      "np.exp(tr_pr) - shift": 1,
      "np.exp(valid) - shift": 1,
      "lgbm.predict(X_test)": 1,
      "lgbm.predict(X_test_ind)": 1,
      "df_trn3['winPlacePercPred']": 1,
      "df_trn3['winPlacePercPred_Rank']": 1,
      "results.predicted_player_rank": 1,
      "results.predicted_team_rank_max": 1,
      "results.predicted_team_rank_mean": 1,
      "tavg_ensemble_pred": 1,
      "vavg_ensemble_pred": 1,
      "preds_orig": 1,
      "y_predict_test_linear": 1,
      "y_predict_test_Random": 1,
      "y_predict_test_LGB": 1,
      "y_predict_test_XGB": 1,
      "y_preds_0": 1,
      "y_preds_rs": 1,
      "baseline_pipe.predict(X_val)": 1,
      "ohe_pipeline.predict(X_val)": 1,
      "fe_pipeline.predict(X_val)": 1,
      "fs_pipeline.predict(X_val)": 1,
      "rf.predict(X_test)": 1,
      "rf1.predict(X_test)": 1,
      "LinReg.predict(X_test)": 1,
      "pred_test_slr_SC": 1,
      "pred_test_en_SC": 1,
      "pred_test_knr_SC": 1,
      "pred_test_dtr_SC": 1,
      "pred_test_slr": 1,
      "pred_test_en": 1,
      "pred_test_knr": 1,
      "pred_test_dtr": 1,
      "train[:, -prediction_size:]": 1,
      "y_pred_val": 1,
      "self.df_predicted": 1,
      "np.exp(y_val) - shift": 1,
      "final_fold_real": 1,
      "10**model.predict(X_test)": 1,
      "10**model2.predict(X_test)": 1,
      "10**model3.predict(X_test)": 1,
      "10**model4.predict(X_test)": 1,
      "10**stack_model.predict(X_test)": 1,
      "y_train_reg": 1,
      "y_test_reg": 1,
      "target_train_predict": 1,
      "Y_predict_scaled": 1,
      "y_mean_pred_train": 1,
      "y_mean_pred": 1,
      "stores_and_dept_preds_train": 1,
      "y_test_price": 1,
      "x['predictions']": 1,
      "predictions_from_features": 1,
      "linear_pred": 1,
      "y_pred_svr": 1,
      "y_pred_gbr": 1,
      "y_pred_rfg": 1,
      "pred_rf2": 1,
      "pred_xg2": 1,
      "Lgb_predictions": 1,
      "df_y_test": 1,
      "output['prediction'][:10000]": 1,
      "y_test[:10000].mean() * np.ones(y_test[:10000].shape)": 1,
      "model.predict(X_test_sc)": 1,
      "val_predictions_nn": 1,
      "val_predictions_rf": 1,
      "pred_test": 1,
      "np.exp(preds) - lift": 1,
      "np.exp(yhat) - lift": 1,
      "ytrain_pred": 1,
      "ytest_pred": 1,
      "ytest_pred_ridge": 1,
      "ytest_pred_ridge_randomized": 1,
      "ytest_pred_lasso_grid": 1,
      "ytest_pred_lasso_randomized": 1,
      "y_train_predict": 1,
      "y_train_predict2": 1,
      "y_test_predict2": 1,
      "test['Predictions']": 1,
      "pred_dtree": 1,
      "pred_cb": 1,
      "y_train_pred_xgb": 1,
      "y_test_pred_xgb": 1,
      "best_fit.predict(X_test)": 1,
      "regressor.predict(X_test)": 1,
      "np.expm1(pred)": 1,
      "predicted_decision_trees": 1,
      "predicted_random_forest": 1,
      "predicted_XGBoost": 1,
      "preds_cc": 1,
      "preds_ft": 1,
      "y_set.item_cnt_month": 1,
      "pred_sklearn": 1,
      "pred_tpot": 1,
      "pred_hyperopt": 1,
      "pred_keras_": 1,
      "mljar_pred": 1,
      "gluon_pred": 1,
      "h2o_pred_": 1,
      "caret_pred": 1,
      "test_v['SalePrice_predictions']": 1,
      "per_type_data[t]['pred']": 1,
      "test_predictions": 1,
      "train_predictions": 1,
      "dec_tree_pred": 1,
      "svr_pred": 1,
      "ann_pred": 1,
      "trip_pred": 1,
      "prediction_pp_rf": 1,
      "prediction_nb": 1,
      "prediction_knn": 1,
      "pred_Y": 1,
      "regr_model.predict(train_X)": 1,
      "predicted_melbourne_prices": 1,
      "melbourne_forest_preds": 1,
      "tmp_winPlacePerc['winPlacePerc']": 1,
      "val_y_train": 1,
      "predict1": 1,
      "predict2": 1,
      "predict3": 1,
      "lr_predict": 1,
      "np.exp(base_predictions)": 1,
      "np.exp(pred)": 1,
      "numpy.expm1(model.predict(X_val))": 1,
      "oof_preds[:NUM_SEGMENTS]": 1,
      "train_preds[index1]": 1,
      "train_preds[index2]": 1,
      "train_preds[index3]": 1,
      "train_preds[index4]": 1,
      "train_preds[index5]": 1,
      "train_preds[index6]": 1,
      "train_preds[index7]": 1,
      "_train_preds_aug[index1]": 1,
      "_train_preds_aug[index2]": 1,
      "_train_preds_aug[index3]": 1,
      "_train_preds_aug[index4]": 1,
      "_train_preds_aug[index5]": 1,
      "_train_preds_aug[index6]": 1,
      "_train_preds_aug[index7]": 1,
      "_train_preds_final[index1]": 1,
      "_train_preds_final[index2]": 1,
      "_train_preds_final[index3]": 1,
      "_train_preds_final[index4]": 1,
      "_train_preds_final[index5]": 1,
      "_train_preds_final[index6]": 1,
      "_train_preds_final[index7]": 1,
      "cv_preds_t": 1,
      "subs[j][t]": 1,
      "GPI(alldata[:X_tr.shape[0]])": 1,
      "trainpreds": 1,
      "GPI(X)": 1,
      "GPII(X)": 1,
      "GPI(alldata[:mfcc_ttf_df.shape[0]])": 1,
      "GPII(alldata[:mfcc_ttf_df.shape[0]])": 1,
      "0.5 * GPI(alldata[:mfcc_ttf_df.shape[0]]) + 0.5 * GPII(alldata[:mfcc_ttf_df.shape[0]])": 1,
      "x": 1,
      "lm_pred": 1,
      "y_pred_plot": 1,
      "for_valid[:, 1]": 1,
      "best_model.predict(x_test)": 1,
      "y_test_xg": 1,
      "y_test_xg_ls": 1,
      "y_test_li_ls": 1,
      "pred_val[:, 1]": 1,
      "pdct1": 1,
      "ridge_prediction": 1,
      "y_1": 1,
      "y_2": 1,
      "rf_predictions_1": 1,
      "y_train_lr_pred": 1,
      "oof_train[:, 1]": 1,
      "error_pred": 1,
      "pred_mean": 1,
      "(pred_time + pred_diff) / 2": 1,
      "pred_mel": 1,
      "(pred_mel + pred_comb) / 2": 1,
      "y_ds_pred_post": 1,
      "y_solo_pred_post": 1,
      "y_all_pred": 1,
      "y_pred_lreg": 1,
      "y_pred_dtree": 1,
      "y_pred_rforest": 1,
      "model0.predict(X_val)": 1,
      "prelgb1['TTF'].values": 1,
      "prexgb01['TTF'].values": 1,
      "(prelgb1['TTF'].values + y_gp) * 1 / 2": 1,
      "(prelgb1['TTF'].values + prexgb01['TTF'].values + y_gp) * 1 / 3": 1,
      "y_pred_LogReg": 1,
      "y_pred_DTR": 1,
      "trained_xgb": 1,
      "final_test": 1,
      "toxicity_scores[:len(toxicity_scores)]": 1,
      "obscenity_scores[:len(toxicity_scores)]": 1,
      "severe_toxicity_scores[:len(toxicity_scores)]": 1,
      "pred_train_1a": 1,
      "pred_train_1b": 1,
      "pred_train_1c": 1,
      "pred_train_1d": 1,
      "pred_train_1e": 1,
      "pred_train_1f": 1,
      "pred_train_1g": 1,
      "pred_train_1h": 1,
      "pred_train_1i": 1,
      "pred_train_1j": 1,
      "pred_train_1k": 1,
      "pred_train_2": 1,
      "model_xgb.predict(x_train_mms)": 1,
      "model_rf.predict(x_train)": 1,
      "linear_model.predict(x_train_mms)": 1,
      "model_gbm.predict(x_train_mms)": 1,
      "[y for x in y_pred_overall for y in x]": 1,
      "oof_pred": 1,
      "best_oof": 1,
      "lr.predict(X_val)": 1,
      "xgb_model.predict(X_val)": 1,
      "model_lr.predict(df_val)": 1,
      "best_model_lr.predict(X_val_LR)": 1,
      "previsoes": 1,
      "y_pred_without_outliers": 1,
      "y_train_cat": 1,
      "np.exp(sdc_loss.inverse_transform(lr.predict(x_train.toarray())))": 1,
      "np.exp(sdc_loss.inverse_transform(lr.predict(x_test.toarray())))": 1,
      "np.exp(sdc_loss.inverse_transform(lr_ridge.predict(x_train.toarray())))": 1,
      "np.exp(sdc_loss.inverse_transform(lr_ridge.predict(x_test.toarray())))": 1,
      "np.exp(sdc_loss.inverse_transform(lr_lasso.predict(x_train.toarray())))": 1,
      "np.exp(sdc_loss.inverse_transform(lr_lasso.predict(x_test.toarray())))": 1,
      "np.exp(sdc_loss.inverse_transform(gbr_cv.predict(x_train.toarray())))": 1,
      "np.exp(sdc_loss.inverse_transform(gbr_cv.predict(x_test.toarray())))": 1,
      "data[0:12212]['Fatalities']": 1,
      "data1[0:12212]['ConfirmedCases']": 1,
      "pred_class": 1,
      "model_predictions": 1,
      "preds_rf": 1,
      "yTestPredLGB": 1,
      "yTestPredXGB": 1,
      "Xp[:, -56:-28]": 1,
      "val_split_y": 1,
      "test_y_reshape": 1,
      "np.expm1(y_train)": 1,
      "np.expm1(y_test)": 1,
      "preds['mid']": 1,
      "y_preed": 1,
      "ypred1": 1,
      "Y_pred_train": 1,
      "Y_pred_test": 1,
      "y_pred_class": 1,
      "rdg_predict": 1,
      "rf_predict": 1,
      "xgb_predict": 1,
      "lgb_predict": 1,
      "vote_predict": 1,
      "sr_predict": 1,
      "x_test_pred": 1,
      "xgb_model_1_predict": 1,
      "lgbm_model_1_predict": 1,
      "0.5 * xgb_model_1_predict + 0.5 * lgbm_model_1_predict": 1,
      "xgb_model_2_predict": 1,
      "lgbm_model_2_predict": 1,
      "0.5 * xgb_model_2_predict + 0.5 * lgbm_model_2_predict": 1,
      "pred / (j + 1)": 1,
      "(oof_lgb + oof_lgb2 + oof_lgb3 + oof_xgb + oof_xgb2) / 5": 1,
      "averaged2_train_predict": 1,
      "stacked_train_pred": 1,
      "y_pred.reshape(-1, n_out)": 1,
      "y_pred[~mask[:, j], j]": 1,
      "test_data[col]": 1,
      "prediction_CC": 1,
      "prediction_Fa": 1,
      "vali_pred[vali_idx]": 1,
      "vali_pred": 1,
      "np.exp(y_pred) - shift": 1,
      "np.exp(score)": 1,
      "y_org_pred": 1,
      "y_shift_pred": 1,
      "inv_test_predict": 1,
      "pd.Series(level_predictions)": 1,
      "pd.Series(level_predictions).loc[:datetime.date(2017, 1, 1)]": 1,
      "pd.Series(flow_predictions)": 1,
      "pd.Series(flow_predictions).loc[:datetime.date(2017, 1, 1)]": 1,
      "error_calc_df['pred_24']": 1,
      "error_calc_df['pred_25']": 1,
      "monthly_pred['pred_24']": 1,
      "monthly_pred['pred_25']": 1,
      "pred_df.loc[:datetime.date(2019, 1, 1), 'pred']": 1,
      "pred_df.loc[:datetime.date(2015, 1, 1), 'pred']": 1,
      "cases_pred": 1,
      "self.y_pred['train'][-1]": 1,
      "self.y_pred['val'][-1]": 1,
      "predictions_test": 1,
      "predictions_validation": 1,
      "predictions_testingData": 1,
      "predictions_validationData": 1,
      "oof['predict']": 1,
      "oof_noDWT['predict']": 1,
      "y_test[:, 0]": 1,
      "y_test[:, 1]": 1
    },
    "sklearn.metrics._classification.log_loss.labels": {
      "None": 3744,
      "[0, 1]": 158,
      "clf.classes_": 132,
      "rfc.classes_": 6,
      "[False, True]": 4,
      "LR.classes_": 4,
      "mnb.classes_": 4,
      "labels": 2,
      "[0, 1, 2]": 2,
      "[0, 1, 2, 3]": 2,
      "classes": 2,
      "clfLR.classes_": 2,
      "linearsvc.classes_": 2,
      "l": 2,
      "np.unique(y_val)": 2,
      "r_cfl.classes_": 1,
      "[1, 2, 3, 4, 5, 6, 7, 8, 9]": 1,
      "list(range(9))": 1,
      "y": 1,
      "qda.classes_": 1,
      "lda.classes_": 1,
      "logreg.classes_": 1,
      "rforest.classes_": 1,
      "np.unique(y_train)": 1,
      "[1, 0]": 1
    },
    "sklearn.multioutput.MultiOutputClassifier.__init__.estimator": {
      "XGBClassifier(tree_method='gpu_hist')": 27,
      "MultinomialNB()": 3,
      "xgb_estimator": 3,
      "base_model": 3,
      "LogisticRegression(C=c, class_weight={0: 0.4, 1: 0.6})": 2,
      "model": 2,
      "LogisticRegression(class_weight='balanced', max_iter=3000)": 2,
      "LogisticRegression(max_iter=10000, tol=0.1, C=0.5, verbose=0, random_state=42)": 2,
      "classifier_XG": 2,
      "XGBClassifier()": 2,
      "xgb": 2,
      "XGBClassifier(**params, tree_method='gpu_hist')": 1,
      "LogisticRegression(verbose=True)": 1,
      "logistic": 1,
      "XGBClassifier(tree_method='gpu_hist', n_jobs=-1)": 1,
      "cbc": 1,
      "LogisticRegression(max_iter=10000, tol=0.1, C=0.5, verbose=0, random_state=SEED)": 1,
      "MLPClassifier(random_state=42)": 1,
      "XGBClassifier().set_params(**params)": 1,
      "XGBClassifier(**param)": 1,
      "XGBClassifier(n_estimators=150, reg_lambda=0.1, max_depth=5, learning_rate=0.1, scale_pos_weight=8, max_delta_step=5, booster='gbtree', tree_method='gpu_hist', gpu_id=0, seed=42)": 1,
      "XGBClassifier(tree_method='gpu_hist', n_estimators=130, max_depth=3, reg_alpha=2, min_child_weight=2, gamma=3, learning_rate=0.0580666601841646, colsample_bytree=0.58)": 1,
      "CatBoostClassifier(n_estimators=10, max_depth=10)": 1,
      "voting_clf": 1,
      "clf": 1,
      "Perceptron(class_weight='balanced', random_state=1, max_iter=20000)": 1,
      "LogisticRegression(penalty='l2', C=100, solver='saga', n_jobs=12)": 1,
      "cls(tree_method='gpu_hist')": 1,
      "catboost_model": 1
    },
    "sklearn.pipeline.Pipeline.predict_proba.X": {
      "X_test": 80,
      "X_val": 26,
      "xs": 18,
      "test": 15,
      "[X_test[idx]]": 12,
      "X_valid": 12,
      "X_train": 11,
      "x_test": 11,
      "[new['comment_text'][0]]": 6,
      "X.iloc[test]": 6,
      "val_x": 5,
      "preds_with_consistency": 4,
      "X": 4,
      "x_val_L1": 4,
      "test_pca": 4,
      "data.loc['validation']": 4,
      "test_data": 3,
      "x_test_selected": 3,
      "test_features": 2,
      "test_X": 2,
      "t_data": 2,
      "test_df_x": 2,
      "Xt": 2,
      "out_df[model_cols]": 2,
      "X_train2": 2,
      "test['comment_text'].values": 2,
      "df_test": 2,
      "text_series": 2,
      "validation_stack": 2,
      "test2['comment_text']": 1,
      "X_sub": 1,
      "X_train[i_train]": 1,
      "X_train[i_valid]": 1,
      "X_te": 1,
      "quora_test.question_text.values": 1,
      "new_feature": 1,
      "X_target_1_upload": 1,
      "kf_val_x": 1,
      "test_images_set": 1,
      "X_test_xgb": 1,
      "test[X.columns]": 1,
      "X_cleaned_test": 1,
      "T": 1,
      "x_train[list_features].as_matrix()[test]": 1,
      "test_df['question_text']": 1,
      "features_test": 1,
      "df_test.drop('id', axis=1)": 1,
      "X_pred": 1,
      "[val['question_text'][idx]]": 1,
      "[X_val.iloc[idx]]": 1,
      "x1": 1,
      "xtest": 1,
      "[text]": 1,
      "text_excl_words": 1,
      "test3": 1,
      "x_test_sgd": 1,
      "x_val_sgd": 1,
      "x_test_xgb": 1,
      "x_val_xgb": 1,
      "x_test_lgbm": 1,
      "x_val_lgbm": 1,
      "test['comment_text']": 1,
      "test['text']": 1,
      "X_test[:len(X_test) // 2]": 1,
      "X_test[len(X_test) // 2:]": 1,
      "['Dogs love us !']": 1,
      "holdout.drop(['shot_made_flag', 'shot_id'], axis=1)": 1,
      "xtest.comment_text": 1,
      "Xts.comment_text": 1,
      "train_tfidf": 1,
      "test_tfidf": 1,
      "X_final": 1,
      "X_test_final": 1,
      "df_kaggle_test": 1,
      "test.drop('ID_code', axis=1)": 1,
      "test_data_pca": 1,
      "test_df.text": 1,
      "xTe[:, binsOfInterest]": 1,
      "xTe[:, selected_binsOfInterest]": 1,
      "Xval[:, binsOfInterest]": 1,
      "Xval[:, selected_binsOfInterest]": 1,
      "test.comment_text": 1,
      "test.stem.values": 1,
      "test.question_text.values": 1,
      "test.lemm.values": 1,
      "X_test_split": 1,
      "pr.values": 1,
      "val_X": 1,
      "df.iloc[test_idx, 0].values": 1,
      "test_examples.question_text.values": 1,
      "['']": 1,
      "features": 1
    },
    "sklearn.linear_model._logistic.LogisticRegression.__init__.n_jobs": {
      "None": 4840,
      "-1": 192,
      "1": 44,
      "self.n_jobs": 15,
      "4": 15,
      "10": 7,
      "-2": 5,
      "6": 3,
      "2": 3,
      "3": 1,
      "model_njobs": 1,
      "RunConfig.N_JOB": 1,
      "8": 1,
      "12": 1
    },
    "sklearn.feature_extraction.text.TfidfVectorizer.fit.raw_documents": {
      "all_text": 111,
      "X_train": 46,
      "traindata": 44,
      "list(train_desc)": 29,
      "full_data": 24,
      "list(xtrain) + list(xvalid)": 23,
      "full_text": 23,
      "clean_corpus": 17,
      "text": 10,
      "corpus": 9,
      "X": 9,
      "group.text": 8,
      "all_data['Description'].fillna('').values": 8,
      "train_text": 8,
      "x_train": 8,
      "train_x": 6,
      "s_data": 6,
      "list(train['review']) + list(test['review'])": 6,
      "train_df['TEXT']": 6,
      "txt1": 5,
      "list(train_texts[col].fillna('')) + list(test_texts[col].fillna(''))": 5,
      "texts": 5,
      "[json_data['document_text']]": 5,
      "train_df['Gene']": 5,
      "train_df['Variation']": 5,
      "all_text_1": 4,
      "all_text_2": 4,
      "all_text_3": 4,
      "X_train.head(5)": 4,
      "train['text']": 4,
      "train['project_subject_categories']": 4,
      "train['project_subject_subcategories']": 4,
      "train['project_title']": 4,
      "train['project_resource_summary']": 4,
      "train['project_essay_1']": 4,
      "train['project_essay_2']": 4,
      "X_all": 4,
      "list(X_train) + list(X_test)": 4,
      "all_text[traindex]": 4,
      "test['title']": 4,
      "data": 4,
      "list(train_desc) + list(test_desc)": 3,
      "clean_text": 3,
      "train.Phrase": 3,
      "test_corpus": 3,
      "df_all[c]": 3,
      "nlp_corpus": 3,
      "train_df['comment_text']": 3,
      "train_text_df['Text']": 3,
      "train['Phrase']": 3,
      "train.comment_text": 3,
      "pd.concat([df, df_t], axis=0).title": 3,
      "df.description.values": 3,
      "df['title']": 2,
      "train_tokens + test_tokens": 2,
      "train_corpus": 2,
      "list(train_text.values) + list(test_text.values)": 2,
      "train.question_text": 2,
      "train['question_text_final']": 2,
      "train_df['seperated_ingredients'].values": 2,
      "df_text": 2,
      "list_sentences_train": 2,
      "train_full['Text']": 2,
      "trainText2": 2,
      "list(train_data['Description'].values) + list(test_data['Description'].values)": 2,
      "all_comment_text": 2,
      "train_texts": 2,
      "trainjoin1": 2,
      "trainjoin2": 2,
      "train_df['text']": 2,
      "train['question_text']": 2,
      "df.clean_review": 2,
      "train_text + test_text": 2,
      "all_texts": 2,
      "vectorizer_text": 2,
      "wordSpace": 2,
      "list(x_train) + list(x_test)": 2,
      "df": 2,
      "train.comment_text.values": 2,
      "pd.concat([train_data['comment'], test_data['comment']])": 2,
      "X_train['question_text']": 2,
      "data['text']": 2,
      "EAP_data['text']": 2,
      "HPL_data['text']": 2,
      "MWS_data['text']": 2,
      "BagOfWords": 2,
      "text_docs": 2,
      "food['ingredientTextClean']": 2,
      "COMMENT_TEXT": 2,
      "train_data": 2,
      "all1": 2,
      "docs[:10158]": 2,
      "train_data['item_description']": 2,
      "all_comments": 2,
      "list(train)": 2,
      "cleaned_texts": 2,
      "lebeldesc_texts": 2,
      "train['Phrase'].values.tolist() + test['Phrase'].values.tolist()": 2,
      "train['Description']": 2,
      "[document]": 2,
      "test_text": 2,
      "train_data['ciphertext']": 2,
      "train['Phrase_Clean']": 2,
      "combined_df['comment_text']": 2,
      "article_text": 2,
      "title_text": 2,
      "resource_text": 2,
      "all_phrases": 2,
      "x_tr['title']": 2,
      "x_tr['essay']": 2,
      "x_tr['clean_categories']": 2,
      "x_tr['clean_subcategories']": 2,
      "df_train['question_text'].values.tolist() + df_test['question_text'].values.tolist()": 1,
      "train_x.text": 1,
      "df_train['joined_ing'].values.tolist()": 1,
      "tweets_df['Concatenated']": 1,
      "x": 1,
      "list(X_train) + list(X_valid)": 1,
      "names_to_match.append(self.ground_truth)[self.col]": 1,
      "preprocessed_reviews": 1,
      "questions[c]": 1,
      "list(test_desc)": 1,
      "train_cleaned": 1,
      "list(grouped_text['text'].values)": 1,
      "preprocessed_essays_x_train": 1,
      "preprocessed_title_x_train": 1,
      "train['title']": 1,
      "train['seperated_ingredients'].values": 1,
      "pd.concat([train_df['question_text'], test_df['question_text']])": 1,
      "train.question1 + train.question2": 1,
      "df_train.text": 1,
      "clean_train_reviews": 1,
      "pd.concat([train_text, test_text])": 1,
      "new['comment_text']": 1,
      "wordbag": 1,
      "train_ingredients_text": 1,
      "X_train['comment_text']": 1,
      "Train['project_subject_categories']": 1,
      "Train['project_subject_subcategories']": 1,
      "Train['project_title']": 1,
      "Train['project_resource_summary']": 1,
      "Train['project_essay_1']": 1,
      "Train['project_essay_2']": 1,
      "train_df['clean_comment']": 1,
      "nlp_items_corpus": 1,
      "train_df['text_clean']": 1,
      "list(train_data['concat_text'].values) + list(test_data['concat_text'].values)": 1,
      "identity_hate_only": 1,
      "[words_excerpt]": 1,
      "df_under['question_text']": 1,
      "df['description']": 1,
      "[submission_texts[idx] for idx in train.index]": 1,
      "train_docs": 1,
      "sample.excerpt": 1,
      "train.excerpt": 1,
      "X_train['essay'].values": 1,
      "train[COMMENT]": 1,
      "pd.concat([train_v[COMMENT], val[COMMENT]])": 1,
      "full_data['text']": 1,
      "test['Phrase']": 1,
      "train['question_text_lemma']": 1,
      "train['ingredients']": 1,
      "X + X_test": 1,
      "[q, q]": 1,
      "X_for_tfidf": 1,
      "tweets": 1,
      "train.text": 1,
      "df1['ingredients1'].values": 1,
      "full_data[c]": 1,
      "lst": 1,
      "tags": 1,
      "list(train_text) + list(test_text)": 1,
      "train_orig.cast_crew.fillna('')": 1,
      "train_orig.production_companies.fillna('')": 1,
      "train_orig.production_countries.fillna('')": 1,
      "fulldf['Description']": 1,
      "dataset['ingredients'].apply(','.join)": 1,
      "train[key].apply(str)": 1,
      "list(xvalid) + list(xtrain)": 1,
      "train_data.url": 1,
      "X_train[:85000]": 1,
      "sentences": 1,
      "self.words_tr": 1,
      "x_j": 1,
      "list(corpus)": 1,
      "X_alphanum": 1,
      "X_train['item_description']": 1,
      "X_train['name']": 1,
      "df.text": 1,
      "train_2['geoNetwork.networkDomain']": 1,
      "list(desc)": 1,
      "train_data_clean": 1,
      "train_df['token_text']": 1,
      "train_X": 1,
      "df_train['seperated_ingredients'].values": 1,
      "reviews + reviewsT": 1,
      "train_keyword": 1,
      "train_location": 1,
      "train['labelAnnotations_des'].fillna('NULL')": 1,
      "X_train.values": 1,
      "df.loc[traindex, :].text.values": 1,
      "X[feature]": 1,
      "pd.concat([train_text[text_column], test_text[text_column]])": 1,
      "train['search_term']": 1,
      "train_v1": 1,
      "train_v2": 1,
      "X_train['text']": 1,
      "X_test['text']": 1,
      "self.fit_comments": 1,
      "train_comments": 1,
      "train_df['questions_title_and_body']": 1,
      "comment_text": 1,
      "list(train_df.cleaned_text.values) + list(test_df.cleaned_text.values)": 1,
      "list(train_data['prep_text']) + list(test_data['text'])": 1,
      "list(train.preprocessed_question_text.values) + list(test.preprocessed_question_text.values)": 1,
      "train_df.seperated_ingredients.values": 1,
      "f_train.text": 1,
      "pd.concat([train['question_text'], test['question_text']])": 1,
      "df_train.review.values": 1,
      "train_df[TEXTCOL]": 1,
      "df.iloc[0:trainlen, :]['Phrase']": 1,
      "train['name_and_breeds']": 1,
      "df['merge']": 1,
      "list(fullSent['Phrase'])": 1,
      "pdesc['product_description']": 1,
      "pd.concat((train['text_cleaned'], test['text_cleaned']), axis=0)": 1,
      "data.question_text": 1,
      "pd.concat([train_text, test_text], axis=0)": 1,
      "merged_training_df['Text']": 1,
      "pd.concat([train_df['description'], test_df['description']])": 1,
      "pd.concat([train_df['title'], test_df['title']])": 1,
      "train_text_phrases": 1,
      "X_train['project_title']": 1,
      "X_train['project_essay_1']": 1,
      "X_train['project_essay_2']": 1,
      "X_train['project_resource_summary']": 1,
      "X_train['description']": 1,
      "[token_ingredients]": 1,
      "txt.q": 1,
      "train_df['premise'].values.tolist() + test_df['premise'].values.tolist()": 1,
      "train_df['hypothesis'].values.tolist() + test_df['hypothesis'].values.tolist()": 1,
      "list(x_train.values) + list(x_valid.values)": 1,
      "X_train[name].values": 1,
      "all_titles": 1,
      "all_essays": 1,
      "all_cats": 1,
      "all_itemtypes": 1,
      "train_data['comment_text']": 1,
      "traindata['ingredients']": 1,
      "df.name": 1,
      "df.item_description": 1,
      "self.training_data['text']": 1,
      "dfboth": 1,
      "data['description']": 1,
      "data['title']": 1,
      "df['total_text']": 1,
      "train['comment_text']": 1,
      "test['comment_text']": 1,
      "df['question_text'].append(test['question_text'])": 1,
      "q_total": 1,
      "items_train": 1,
      "merge": 1,
      "pd.concat([dtrain['product_title'], dtest['product_title']], axis=0).drop_duplicates().dropna()": 1,
      "pd.concat([dtrain['product_description'], dtest['product_description']], axis=0).drop_duplicates().dropna()": 1,
      "pd.concat([dtrain['search_term'], dtest['search_term']], axis=0).drop_duplicates().dropna()": 1,
      "df_train_key_grpd.keyword": 1,
      "text_data": 1,
      "[str(i) for i in features]": 1,
      "train['processed1']": 1,
      "final_text['excerpt']": 1,
      "words": 1,
      "train_df['text'].values.tolist() + test_df['text'].values.tolist()": 1,
      "list(pd.DataFrame(train_data.text).append(pd.DataFrame(test_data.text), ignore_index=True).text)": 1,
      "list(train_df[textcol].values)": 1,
      "datatrain['Cleaned_tweet']": 1,
      "data['question_text']": 1,
      "train['cleaned'].values": 1,
      "project[c]": 1,
      "df_train['dataset_title']": 1,
      "df_train['json_text']": 1,
      "X_cv_train": 1,
      "train_df['Text']": 1,
      "list_questions": 1,
      "xtrain": 1,
      "train_df['text_final']": 1,
      "original_data['ready_text']": 1,
      "pd.concat([train_X, test_X])": 1,
      "prior_ord['product_set']": 1,
      "pd.concat([train['comment_text'], test['comment_text']], axis=0)": 1,
      "train_0.question_text_cleaned": 1,
      "X_train.question_text_cleaned": 1,
      "train.question_text_cleaned": 1,
      "x_cv['clean_categories']": 1,
      "x_test['clean_categories']": 1,
      "train_features": 1,
      "train_df['Text'].values.astype('U')": 1,
      "df['text']": 1,
      "list(X_train) + list(X_val)": 1,
      "df_train['title']": 1,
      "df['question_text'].values": 1,
      "data['ingredients'].values": 1,
      "joined.comment_text": 1,
      "sentences2": 1,
      "df_train.description.values": 1,
      "all_text['excerpt']": 1,
      "data_train_cleaned['overview'].fillna('')": 1,
      "data_train_cleaned['tagline'].fillna('')": 1,
      "q[:85000]": 1,
      "q": 1,
      "all_comment_list": 1,
      "txt_all": 1,
      "self.train.question_text": 1,
      "train_df.question_text": 1,
      "test_df.question_text": 1,
      "train_df.question_text.append(test_df.question_text)": 1,
      "train_df.loc[train_df.target > 0, 'question_text']": 1,
      "train_df.loc[0 == train_df.target, 'question_text']": 1,
      "documents": 1,
      "train_df['lower_case_text'].values": 1
    },
    "sklearn.svm._classes.LinearSVC.__init__.random_state": {
      "None": 368,
      "0": 24,
      "42": 22,
      "1": 20,
      "123": 3,
      "1001": 2,
      "RND_ST": 2,
      "3": 2,
      "32": 1,
      "2021": 1,
      "RS": 1,
      "20": 1,
      "rnd": 1,
      "seed": 1,
      "123456": 1,
      "2": 1,
      "5": 1,
      "101": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.shuffle": {
      "True": 841
    },
    "sklearn.tree._classes.DecisionTreeRegressor.fit.X": {
      "X_train": 184,
      "x_train": 69,
      "X": 42,
      "x": 31,
      "train_X": 31,
      "train_x": 21,
      "train": 11,
      "xs": 8,
      "train_data": 4,
      "treino[usadas]": 4,
      "X_train_confirmed": 4,
      "train_encoded": 4,
      "features": 4,
      "df[['Country_Region', 'Province_State', 'Date']]": 4,
      "cyc_data[x_ipts]": 4,
      "cyc_data_train[x_ipts]": 4,
      "input_data": 4,
      "X_train_scaled": 3,
      "to.train.xs": 3,
      "train[feats]": 3,
      "X_train_cc": 3,
      "X_train_fat": 3,
      "X_train[:, None]": 3,
      "train[cols]": 3,
      "housing_prepared": 3,
      "X_trn": 3,
      "X_train_fatal": 3,
      "X_train[var].to_frame()": 2,
      "xtrain": 2,
      "X_xTrain_CS": 2,
      "X_xtrain_Cs": 2,
      "X_train1": 2,
      "data[TRAIN_FEATS]": 2,
      "X_trainNorm": 2,
      "X_trainNorm1": 2,
      "X_trainNorm2": 2,
      "X_train_prepared": 2,
      "xs_cm": 2,
      "X_train3": 2,
      "XD_train": 2,
      "train.fillna(-1)[feats]": 2,
      "X_trainsc": 1,
      "X_train_5": 1,
      "X2": 1,
      "trainFactors": 1,
      "x_train[col_n]": 1,
      "X_train_pc": 1,
      "X_train_pca": 1,
      "X_train_fatalities": 1,
      "X[cols]": 1,
      "x2_train": 1,
      "x4_train": 1,
      "xCC_train": 1,
      "xF_train": 1,
      "XdataTrain": 1,
      "X_Train_new": 1,
      "X_new": 1,
      "x_tr": 1,
      "pubg.drop(columns=['winPlacePerc'])": 1,
      "X[:, 1:]": 1,
      "train[features]": 1,
      "t_X": 1,
      "x_trainFixed": 1,
      "x_train_imp": 1,
      "v1_train.drop(['id', 'target'], axis=1)": 1,
      "v2_train.drop(['id', 'target'], axis=1)": 1,
      "DT_Train": 1,
      "df_X_train": 1,
      "x_train[:10000]": 1,
      "features_train": 1,
      "df.drop(labels=target, axis=1)": 1,
      "x1": 1,
      "x2": 1,
      "X_train[col].to_frame()": 1,
      "data_train": 1,
      "train_features": 1,
      "data": 1,
      "Xs_train": 1,
      "Xs_train_a": 1,
      "X_inf_train": 1,
      "X_dth_train": 1,
      "X_inf_scaled": 1,
      "X_dth_scaled": 1,
      "tr_x": 1,
      "X_train_SC": 1,
      "final_df.drop('SalePrice', axis=1)": 1,
      "train[independent_variable]": 1,
      "tree_df.drop('target', axis=1)": 1,
      "X_fat": 1,
      "decision_model_train_1": 1,
      "df_green2[df_green2.columns[3:11]]": 1,
      "xs_bz": 1,
      "xs_no": 1,
      "to_cm.train.xs": 1,
      "X_train.drop(columns=['extra'])": 1,
      "train_df[['shop_id', 'item_id', 'date_block_num']]": 1,
      "X_fe_emb_train": 1,
      "tfidf_train": 1,
      "train[names]": 1,
      "train[binarias + discretas]": 1,
      "X_train[feature].fillna(0).to_frame()": 1,
      "XX": 1,
      "X_train_1": 1,
      "X_train_4": 1,
      "train_clean_cases": 1,
      "train_clean_fatal": 1,
      "x1_tr": 1,
      "x2_tr": 1,
      "x_train_scaled": 1,
      "A1_train": 1,
      "A2_train": 1,
      "A3_train": 1,
      "vis": 1,
      "train[train.columns[1:-1]]": 1,
      "X_train_std": 1,
      "df_train_x": 1,
      "X_train_final": 1,
      "Deaths_data_value": 1,
      "X_casa_treino": 1,
      "x_data": 1,
      "_products": 1,
      "tr[features].values": 1
    },
    "sklearn.tree._classes.DecisionTreeRegressor.fit.y": {
      "y_train": 225,
      "y": 53,
      "train_y": 53,
      "Y_train": 23,
      "y1": 15,
      "y2": 11,
      "y_train_cc": 9,
      "Y": 7,
      "y_train_ft": 6,
      "target": 6,
      "ylog1p_train": 6,
      "treino['count']": 4,
      "y_train_confirmed": 4,
      "train['target']": 4,
      "to.train.y": 3,
      "train['rentals']": 3,
      "y_train_fat": 3,
      "y_trn": 3,
      "target1": 3,
      "target2": 3,
      "y_train_fatal": 3,
      "y_train_scaled": 2,
      "X_train['target']": 2,
      "ytrain": 2,
      "y_train1": 2,
      "y_train[['ConfirmedCases']]": 2,
      "y_train[['Fatalities']]": 2,
      "y_train['ConfirmedCases']": 2,
      "y_train['Fatalities']": 2,
      "data[TARGET_COL]": 2,
      "housing_labels": 2,
      "y_no": 2,
      "df[['ConfirmedCases']]": 2,
      "df[['Fatalities']]": 2,
      "cyc_data.casual": 2,
      "cyc_data.registered": 2,
      "cyc_data_train.casual": 2,
      "cyc_data_train.registered": 2,
      "y_cm": 2,
      "y_confrm": 2,
      "y_fat": 2,
      "y_1": 2,
      "y_2": 2,
      "YD_train": 2,
      "train.fillna(-1)['count']": 2,
      "train_price": 1,
      "y_train_5": 1,
      "Y2": 1,
      "t1": 1,
      "t2": 1,
      "trainResponse": 1,
      "y_train.iloc[:, i]": 1,
      "y_train_fatalities": 1,
      "val_train": 1,
      "y1_xTrain_CS": 1,
      "y2_xTrain_CS": 1,
      "y1_xTrain": 1,
      "y2_xTrain": 1,
      "yCC_train": 1,
      "yF_train": 1,
      "YdataTrain": 1,
      "y_train['confirmed']": 1,
      "y_train['deaths']": 1,
      "y['confirmed']": 1,
      "y['deaths']": 1,
      "y_tr": 1,
      "pubg['winPlacePerc']": 1,
      "train[target]": 1,
      "t_y": 1,
      "v1_train.target": 1,
      "v2_train.target": 1,
      "train_data['SalePrice']": 1,
      "y_train_log": 1,
      "df_Y_train": 1,
      "y_train[:10000]": 1,
      "cases_train": 1,
      "y_trainl": 1,
      "Y1.values.ravel()": 1,
      "Y2.values.ravel()": 1,
      "df[target]": 1,
      "train_label": 1,
      "y_train.ConfirmedCases": 1,
      "y_train.Fatalities": 1,
      "y_co": 1,
      "y_benz": 1,
      "y_inf_train['confirmed']": 1,
      "y_dth_train['deaths']": 1,
      "y_infections['confirmed']": 1,
      "y_deaths['deaths']": 1,
      "tr_y": 1,
      "np.log1p(y_train)": 1,
      "final_df['SalePrice']": 1,
      "train[train[target_column].notnull()][target_column]": 1,
      "train[dependent_variable]": 1,
      "tree_df['target']": 1,
      "df_green2['sustainable']": 1,
      "y_bz": 1,
      "to_cm.train.y": 1,
      "train_df['total_sales']": 1,
      "train['Target']": 1,
      "yy": 1,
      "Y_train_1": 1,
      "Y_train_4": 1,
      "train_y1": 1,
      "train_y2": 1,
      "y1_tr": 1,
      "y2_tr": 1,
      "b1_train": 1,
      "b2_train": 1,
      "b3_train": 1,
      "target_1": 1,
      "target_2": 1,
      "target_3": 1,
      "train.y.values[train_index]": 1,
      "train.y": 1,
      "df_train_y": 1,
      "Confirmed_data_value": 1,
      "y_casa_treino": 1,
      "train_Y": 1,
      "y_train.ravel()": 1,
      "y_data": 1,
      "tr.target": 1
    },
    "sklearn.tree._classes.DecisionTreeRegressor.__init__.max_depth": {
      "None": 657,
      "5": 32,
      "10": 24,
      "3": 18,
      "4": 18,
      "20": 17,
      "max_depth": 16,
      "2": 14,
      "6": 13,
      "15": 12,
      "11": 10,
      "i": 8,
      "9": 7,
      "50": 5,
      "treeDepth": 5,
      "depth": 4,
      "8": 4,
      "1": 4,
      "12": 4,
      "30": 4,
      "25": 2,
      "tree_depth": 2,
      "100": 2,
      "22": 2,
      "17": 2,
      "7": 2,
      "68": 2,
      "depth_range_optim": 1,
      "max": 1,
      "31": 1,
      "14": 1,
      "md": 1,
      "args['max_depth']": 1
    },
    "sklearn.tree._classes.DecisionTreeRegressor.__init__.random_state": {
      "None": 551,
      "0": 98,
      "1": 77,
      "42": 70,
      "27": 12,
      "seed": 11,
      "100": 11,
      "123": 9,
      "3508": 9,
      "5": 7,
      "2": 6,
      "2021": 4,
      "SEED": 3,
      "11": 2,
      "random_state": 2,
      "666": 2,
      "443": 2,
      "32": 2,
      "6967": 2,
      "tree_seed": 2,
      "2019": 1,
      "33": 1,
      "101": 1,
      "50": 1,
      "19": 1,
      "43": 1,
      "520": 1,
      "i + 1": 1,
      "198": 1,
      "17": 1,
      "21": 1,
      "140": 1,
      "RANDOM_STATE_DEC_TREE": 1,
      "711": 1
    },
    "sklearn.tree._export.export_graphviz.out_file": {
      "None": 118,
      "dot_data": 23,
      "'tree.dot'": 17,
      "f": 16,
      "dotfile": 10,
      "'small_tree.dot'": 3,
      "'tree_limited.dot'": 3,
      "'tree_nonlimited.dot'": 2,
      "'titanic_tree.dot'": 2,
      "'des_tree.dot'": 1,
      "'tunedtreewithdummies.dot'": 1,
      "f'one_tree_{algo}.dot'": 1,
      "Nomr": 1,
      "'add-to-cart-order-tree.png'": 1,
      "'loan_tree.dot'": 1,
      "outfile": 1,
      "'../model.dot'": 1
    },
    "sklearn.tree._export.export_graphviz.feature_names": {
      "None": 26,
      "df.columns": 19,
      "x_train.columns": 16,
      "columns": 15,
      "train.drop(['id', 'target'], axis=1).columns.values": 13,
      "X.columns": 12,
      "['signal']": 11,
      "features": 10,
      "X_train.columns": 10,
      "cols": 7,
      "feature_cols_": 5,
      "X_test.columns": 4,
      "train_selected.columns": 4,
      "feats": 4,
      "names": 3,
      "labels": 3,
      "feature_list": 3,
      "feat": 3,
      "feature_names": 2,
      "data_feature_names": 2,
      "feature_cols": 2,
      "gen_features": 2,
      "train_df.columns": 2,
      "Xs.columns": 1,
      "cols2": 1,
      "features_list": 1,
      "list(Planet_data_dummies.columns[2:])": 1,
      "list(X)": 1,
      "['\u6e29\u5ea6', '\u53e3\u5473', '\u5c3a\u5bf8']": 1,
      "train.drop(['id', 'target'], axis=1).columns": 1,
      "['num_place', 'FoA']": 1,
      "dt_feature_names": 1,
      "['Age', 'Sex', 'Pclass']": 1,
      "['addr1']": 1,
      "featureNames": 1,
      "['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF', '1stFlrSF', 'FullBath', 'TotRmsAbvGrd', 'YearBuilt', 'YearRemodAdd']": 1,
      "list(X_train.columns)": 1,
      "test.drop(['id'], axis=1).columns": 1,
      "independent_variable": 1,
      "tree_df.drop('target', axis=1).columns": 1,
      "df_green2.columns[3:11]": 1,
      "['Age', 'Sex', 'Pclass', 'Fare']": 1,
      "train_new.drop(['id', 'target', 'target_ord'], axis=1).columns.values.tolist()": 1,
      "train_names": 1,
      "df_feature": 1,
      "X_train_speed.columns": 1,
      "shop_data.columns[~shop_data.columns.isin(['item_cnt_day', 'date', 'item_category_name_en', 'item_name_en'])]": 1
    },
    "sklearn.tree._export.export_graphviz.decision_tree": {
      "model": 47,
      "clf": 25,
      "t": 19,
      "decision_tree": 15,
      "tree_model": 8,
      "estimator": 6,
      "best_model": 6,
      "Model": 5,
      "Model.estimators_[idx]": 5,
      "dtree": 5,
      "dt": 4,
      "DecisionTree": 4,
      "tree_grid.best_estimator_": 3,
      "dtr": 2,
      "clf1s": 2,
      "clf1f": 2,
      "clf3": 2,
      "clf5": 2,
      "clf10": 2,
      "estimators": 2,
      "tree": 2,
      "small_tree": 2,
      "estimator_limited": 2,
      "estimator_nonlimited": 2,
      "treeclf_light": 2,
      "classifier": 1,
      "DecisionTreeModel": 1,
      "one_tree": 1,
      "tree1": 1,
      "rf_estimator": 1,
      "tree_list[0]": 1,
      "tree_list[1]": 1,
      "decisiontree": 1,
      "decision_tree_regressor": 1,
      "house_prices_model": 1,
      "tree_clf": 1,
      "dt_clf": 1,
      "dectree": 1,
      "my_tree_one": 1,
      "d_tree": 1,
      "tree_small": 1,
      "trainedtree": 1,
      "data": 1,
      "model2": 1,
      "model.estimators_[0]": 1,
      "model.estimators_[1]": 1,
      "treeclf": 1,
      "rf.estimators_[0]": 1,
      "products_model": 1,
      "dtree1": 1,
      "regressor": 1
    },
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.n_jobs": {
      "None": 3537,
      "-1": 1401,
      "4": 93,
      "1": 45,
      "2": 42,
      "8": 10,
      "6": 9,
      "n_jobs": 7,
      "3": 6,
      "10": 6,
      "5": 5,
      "-2": 4,
      "16": 3,
      "12": 2,
      "13": 2,
      "nproc": 2,
      "7": 2,
      "42": 1,
      "model_njobs": 1,
      "jobs": 1,
      "forest.best_params_['n_jobs']": 1
    },
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.random_state": {
      "None": 2866,
      "0": 518,
      "42": 509,
      "1": 432,
      "50": 171,
      "10": 82,
      "seed": 62,
      "2016": 50,
      "random_state": 43,
      "2": 31,
      "123": 27,
      "11": 21,
      "100": 17,
      "g['rs']": 17,
      "99": 15,
      "RANDOM_STATE": 15,
      "111": 13,
      "44": 13,
      "101": 11,
      "SEED": 11,
      "2018": 10,
      "14": 10,
      "3": 8,
      "43": 8,
      "5": 8,
      "13": 8,
      "rnd": 8,
      "1337": 8,
      "4141": 7,
      "2019": 6,
      "17": 6,
      "2021": 6,
      "4": 6,
      "39": 5,
      "777": 5,
      "12": 5,
      "314": 5,
      "1234": 5,
      "7": 4,
      "RANDOM_SEED": 4,
      "22": 4,
      "41": 4,
      "1301": 4,
      "369": 4,
      "8": 3,
      "121": 3,
      "60": 3,
      "rand_state": 3,
      "400": 3,
      "2020": 3,
      "24": 3,
      "random_seed": 3,
      "seed_value": 3,
      "25": 2,
      "30": 2,
      "45": 2,
      "202": 2,
      "self.seed": 2,
      "217 + i": 2,
      "140001742": 2,
      "34": 2,
      "159": 2,
      "12345": 2,
      "376": 2,
      "33": 2,
      "1412": 2,
      "20": 2,
      "666": 2,
      "123456": 2,
      "222": 2,
      "52": 2,
      "241": 2,
      "2525": 1,
      "451": 1,
      "36": 1,
      "19": 1,
      "456": 1,
      "18": 1,
      "217": 1,
      "4211": 1,
      "20190603": 1,
      "65": 1,
      "k": 1,
      "1000": 1,
      "21": 1,
      "40": 1,
      "432": 1,
      "168": 1,
      "154": 1,
      "RS": 1,
      "29": 1,
      "86": 1,
      "342": 1,
      "543": 1,
      "32": 1,
      "1729": 1,
      "6": 1,
      "1998": 1,
      "4422": 1,
      "457": 1,
      "47": 1,
      "57": 1,
      "1357": 1,
      "8012": 1,
      "234": 1,
      "51": 1,
      "58": 1,
      "14113": 1,
      "102": 1,
      "300": 1,
      "9": 1,
      "78": 1,
      "55": 1,
      "23": 1,
      "53": 1
    },
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.n_estimators": {
      "100": 2714,
      "200": 345,
      "1000": 206,
      "500": 197,
      "10": 185,
      "50": 183,
      "300": 116,
      "150": 75,
      "20": 69,
      "i": 51,
      "alpha[int(best_alpha / 2)]": 51,
      "250": 48,
      "400": 46,
      "40": 46,
      "30": 45,
      "70": 41,
      "alpha[int(best_alpha / 4)]": 40,
      "700": 36,
      "n_estimators": 34,
      "80": 32,
      "600": 30,
      "25": 23,
      "2000": 19,
      "g['ne']": 17,
      "best_n": 16,
      "15": 14,
      "120": 14,
      "n_tree": 14,
      "60": 14,
      "800": 13,
      "1800": 13,
      "5": 12,
      "num_trees": 12,
      "1100": 12,
      "1": 11,
      "3": 10,
      "n": 10,
      "350": 9,
      "107": 8,
      "75": 8,
      "N_ESTIMATORS": 8,
      "grid.best_params_['n_estimators']": 8,
      "890": 8,
      "1500": 7,
      "int(params['n_estimators'])": 6,
      "estimators": 6,
      "128": 6,
      "OptEstimator": 6,
      "180": 5,
      "5000": 5,
      "n_trees": 5,
      "1750": 5,
      "750": 5,
      "12": 5,
      "nestimator": 5,
      "c - 1": 5,
      "190": 5,
      "13": 5,
      "182": 5,
      "Best_Parameter['n_estimators']": 4,
      "10000": 4,
      "90": 4,
      "int(n_estimators)": 4,
      "900": 4,
      "1600": 4,
      "Estimator": 4,
      "707": 4,
      "377": 4,
      "140": 3,
      "24": 3,
      "num_estimators": 3,
      "290": 3,
      "160": 3,
      "n_estimator": 3,
      "11": 3,
      "375": 3,
      "4": 3,
      "27": 3,
      "8": 3,
      "1250": 3,
      "trial.suggest_int('n_estimators', 10, 1000)": 3,
      "96": 3,
      "256": 2,
      "trial.suggest_int('n_estimators', 100, 2000, 100)": 2,
      "est": 2,
      "params['n_estimators']": 2,
      "325": 2,
      "3000": 2,
      "best_params['n_estimators']": 2,
      "n_est": 2,
      "450": 2,
      "best_estimator": 2,
      "31": 2,
      "study.best_params['n_estimators']": 2,
      "int(round(best['n_estimators'], 0))": 2,
      "36": 2,
      "rf_clf.best_params_['n_estimators']": 2,
      "clf.best_params_['n_estimators']": 2,
      "173": 2,
      "int(best['n_estimators'])": 2,
      "52": 2,
      "110": 2,
      "938": 2,
      "225": 2,
      "58": 2,
      "51": 2,
      "64": 2,
      "alpha[best_alpha]": 2,
      "1200": 2,
      "6": 2,
      "170": 2,
      "50000": 2,
      "233": 2,
      "estimator": 2,
      "treeCount": 2,
      "701": 2,
      "45": 2,
      "77": 1,
      "277": 1,
      "trial.suggest_int('n_estimators', 50, 1000, 25)": 1,
      "192": 1,
      "46": 1,
      "580": 1,
      "21": 1,
      "127": 1,
      "211": 1,
      "9": 1,
      "270": 1,
      "205": 1,
      "max_iter": 1,
      "54": 1,
      "48": 1,
      "num": 1,
      "134": 1,
      "22": 1,
      "421": 1,
      "402": 1,
      "720": 1,
      "f": 1,
      "760": 1,
      "1700": 1,
      "49": 1,
      "99": 1,
      "rf_bp['n_estimators']": 1,
      "int(round(rf_b_o.max['params']['n_estimators'], 0))": 1,
      "int(population[i][1])": 1,
      "int(population[bestFitnessIndex][1])": 1,
      "n_rf_trees": 1,
      "115": 1,
      "201": 1,
      "3500": 1,
      "72": 1,
      "trees": 1,
      "200 * i": 1,
      "2500": 1,
      "model_config['max_depth']": 1,
      "480": 1,
      "240": 1,
      "x": 1,
      "k": 1,
      "32": 1,
      "forest.best_params_['n_estimators']": 1,
      "rf_n_estimators": 1,
      "rf_random.best_params_['n_estimators']": 1,
      "int(round(n_estimators))": 1,
      "228": 1,
      "84": 1,
      "optimal_k": 1,
      "space['n_estimators']": 1,
      "best['n_estimators']": 1,
      "118": 1,
      "n_estimators_size": 1,
      "parameter[1]": 1,
      "446": 1,
      "330": 1,
      "898": 1,
      "137": 1,
      "332": 1,
      "175": 1,
      "2": 1,
      "550": 1,
      "j": 1,
      "155": 1,
      "105": 1,
      "17": 1,
      "'auto'": 1,
      "16": 1,
      "515": 1,
      "1001": 1,
      "19": 1,
      "144": 1,
      "198": 1,
      "285": 1,
      "263": 1,
      "grid_rf.best_params_['n_estimators']": 1,
      "n_estimator_i": 1,
      "59": 1,
      "69": 1,
      "255": 1,
      "ntrees": 1
    },
    "sklearn.base.ClassifierMixin.score.X": {
      "X_train": 716,
      "X_test": 652,
      "x_test": 176,
      "x_train": 132,
      "X": 114,
      "X_val": 108,
      "X_valid": 37,
      "x_val": 29,
      "X_test_std": 20,
      "X_train_std": 19,
      "train_X": 17,
      "testRI": 17,
      "data.iloc[val_idx]": 15,
      "train": 13,
      "x_test_3": 11,
      "val_X": 10,
      "images2": 10,
      "X.iloc[val_idx]": 9,
      "train_x": 9,
      "x_train_vector": 9,
      "x_valid": 9,
      "X_tr": 9,
      "X_test_vec": 9,
      "tr.iloc[test_index]": 8,
      "testfeature": 8,
      "Xtrain": 7,
      "train_scaled": 7,
      "ttextdataemx_test": 7,
      "tsiftdatax_test": 7,
      "df_X": 7,
      "X_train.iloc[val_idx]": 6,
      "test_x": 6,
      "x": 6,
      "features": 6,
      "X_test_flatten": 6,
      "X_test_cv": 6,
      "xtrain_cv": 6,
      "X_test_full": 6,
      "X_train_scaled": 5,
      "Xval": 5,
      "Xtest": 5,
      "x_train[test]": 5,
      "X_cv": 5,
      "X_ref_test_vec": 5,
      "xtrain_tv": 5,
      "feat_train": 4,
      "feat_val": 4,
      "X_test_scaled": 4,
      "x_mod_treino": 4,
      "test_features": 4,
      "x_train_pca[test]": 4,
      "X_train_cv": 4,
      "test_count1": 4,
      "X_train1": 4,
      "x_train_pca": 4,
      "x_val_pca": 4,
      "X_test_rf": 4,
      "X_train.todense()": 4,
      "test_data": 4,
      "X_train_scaled.iloc[val_idx]": 4,
      "X_trcv": 4,
      "X_tscv": 4,
      "X_test_ol": 4,
      "X_test_norm": 4,
      "testdata1[tix]": 4,
      "pca_X_cv": 4,
      "xTest": 4,
      "features_v2": 4,
      "embeddings_test": 4,
      "X[val_idx]": 4,
      "train_df[selected_col]": 4,
      "xtest": 3,
      "x_mod_teste": 3,
      "xts": 3,
      "gmm_train": 3,
      "x_train_tfidf": 3,
      "new_x_train": 3,
      "X_over": 3,
      "X_test_transform": 3,
      "testdata": 3,
      "X_train_counts": 3,
      "X_test_tfidf": 3,
      "traintext": 3,
      "clfX_test": 3,
      "test_X": 3,
      "x_cv": 3,
      "temp_test": 3,
      "inputs_test": 3,
      "images_resized": 3,
      "X_test_normalized": 3,
      "x_test.T": 3,
      "x_train_std": 3,
      "x_valid_pca": 3,
      "x_train_test": 3,
      "features_one": 3,
      "X_subset": 3,
      "x_trainnew": 3,
      "x_testnew": 3,
      "x_test_imp": 3,
      "validate_X": 3,
      "X_tra.iloc[val_idx]": 3,
      "xtrain_ctv": 3,
      "xvalid_ctv": 3,
      "xTrain": 3,
      "xvalid_features": 3,
      "train.iloc[test_index]": 3,
      "test_X1": 3,
      "valX": 3,
      "x_test1": 3,
      "trainFeatures_factors": 2,
      "df_train": 2,
      "test_tf": 2,
      "XtrNow": 2,
      "Xtr": 2,
      "train_df[test_index]": 2,
      "X_train.toarray()": 2,
      "X_test2": 2,
      "X_validate_scaled": 2,
      "X_test_pca": 2,
      "X_train_prepared": 2,
      "text": 2,
      "X2": 2,
      "test_df": 2,
      "X_train_1": 2,
      "x_validate": 2,
      "x_valid_tfidf": 2,
      "enc_val": 2,
      "x_val_emb": 2,
      "df_train_sum.iloc[test_index]": 2,
      "X_train_pca": 2,
      "Xss": 2,
      "X_teste": 2,
      "X_train_matrix": 2,
      "X_test_matrix": 2,
      "x_vali": 2,
      "x_fid_vali": 2,
      "train_data.iloc[val_idx]": 2,
      "X_trainval": 2,
      "x_test_std": 2,
      "x3_test": 2,
      "X_trtf": 2,
      "X_tstf": 2,
      "val_": 2,
      "x_test.drop('wheezy-copper-turtle-magic', axis=1)": 2,
      "sub_test": 2,
      "X_train_count": 2,
      "text_bow_train": 2,
      "text_bow_test": 2,
      "global_features": 2,
      "X_val[columns_n]": 2,
      "X_val_2[columns_n]": 2,
      "X_train[columns]": 2,
      "X_val[columns]": 2,
      "get_input(train_df)": 2,
      "get_input(valid_df)": 2,
      "testdata[tix]": 2,
      "Xi[i2]": 2,
      "train[columns]": 2,
      "X_training_scaled": 2,
      "X_train2": 2,
      "X_devtest": 2,
      "X_test1": 2,
      "val_set": 2,
      "test_set": 2,
      "xvalid_tfv_std": 2,
      "x_train_bf": 2,
      "x_valid_bf": 2,
      "xTrain.iloc[val_idx]": 2,
      "df_keep.iloc[test_index]": 2,
      "train_text_vect": 2,
      "X_test_negd": 2,
      "x_train_scaled": 2,
      "xtrain_tfv": 2,
      "xvalid_tfv": 2,
      "xtrain_svd_scl": 2,
      "xvalid_svd_scl": 2,
      "X_val[:, i_cols_list]": 2,
      "xtrain": 2,
      "X_cv.drop(et_drop_cols, axis=1)": 2,
      "data.values": 2,
      "train.iloc[valid_idx]": 2,
      "vectorizer.transform(X_test)": 2,
      "X[train_index]": 2,
      "X[val_index]": 2,
      "X_train.values": 2,
      "X_test.values": 2,
      "train[X_cols]": 2,
      "df": 2,
      "X_train_tf": 2,
      "X_valid_tf": 2,
      "train.iloc[val_idx]": 2,
      "X_test[feature_cols]": 2,
      "train_features": 2,
      "x_test_1": 2,
      "x_test_2": 2,
      "X_train_testsplit": 2,
      "X[33000:]": 1,
      "x_validation": 1,
      "x_train_rfecv": 1,
      "x_test_rfecv": 1,
      "X_trans": 1,
      "df_val": 1,
      "train_data[:, 1:]": 1,
      "cv.drop('Cover_Type', axis=1)": 1,
      "X_SMOTE": 1,
      "xtr": 1,
      "df_test[features]": 1,
      "train_x_test": 1,
      "X_disc": 1,
      "X_test.toarray()": 1,
      "X_test_df": 1,
      "X_train.astype(int)": 1,
      "X_test.astype(int)": 1,
      "y2[:990, :]": 1,
      "NN_rep1[:990, :]": 1,
      "training_data_X": 1,
      "train_X_std": 1,
      "Xte": 1,
      "x_train1": 1,
      "val_data": 1,
      "X_val_1": 1,
      "X_cv_score": 1,
      "data_numpy_image": 1,
      "testFeat": 1,
      "X_test_c2": 1,
      "df_test_input": 1,
      "inputs_train": 1,
      "X_train_dm": 1,
      "X_test_dm": 1,
      "valid_comment": 1,
      "df_val_X": 1,
      "data_val3": 1,
      "X_val_scaled": 1,
      "x2_train": 1,
      "x2_cross": 1,
      "filt_data": 1,
      "Xtest_pca": 1,
      "X_test_minmax": 1,
      "matrix_train": 1,
      "matrix_vp": 1,
      "mat_trn_pol": 1,
      "df_initial_train": 1,
      "X_train_tfidf": 1,
      "X_train_reg": 1,
      "X_train_nb": 1,
      "X_v": 1,
      "selected_x_val": 1,
      "timagearrayx_test": 1,
      "X_dev": 1,
      "dev_data": 1,
      "df_test": 1,
      "Red_test": 1,
      "x2_test": 1,
      "x4_test": 1,
      "train_numer_df": 1,
      "feat_array": 1,
      "X_tefull": 1,
      "ytr_pred_probs": 1,
      "yt_pred_probs": 1,
      "valid_X": 1,
      "d_f_test_new": 1,
      "df_trn": 1,
      "x_val.values": 1,
      "train_std": 1,
      "x_test_umap_2": 1,
      "x_test_add_umap2": 1,
      "projected_validation": 1,
      "X_testing": 1,
      "X_train_bow_df": 1,
      "X_val_bow_df": 1,
      "label_test_data": 1,
      "x_train.T": 1,
      "X_Test": 1,
      "valores_pred": 1,
      "vect.transform(X_train)": 1,
      "X_test_ml": 1,
      "X_value": 1,
      "vali_x": 1,
      "x_trainsplit": 1,
      "x_testsplit": 1,
      "testDataFrameNewX": 1,
      "train1.iloc[te][colu]": 1,
      "train_set": 1,
      "X_training": 1,
      "X_val2": 1,
      "X_testest": 1,
      "X_testf": 1,
      "X[:threshold]": 1,
      "X[threshold:]": 1,
      "xValidStack": 1,
      "xte": 1,
      "train_attributes_n": 1,
      "X_subset2": 1,
      "data[:, :-1]": 1,
      "data.drop('type', axis=1)": 1,
      "X_train1hot_scaled": 1,
      "X_trainlabel_scaled": 1,
      "test_image_vector": 1,
      "X_test_feature": 1,
      "pca.transform(X_test)": 1,
      "data_test": 1,
      "X_train_norm": 1,
      "ensemble": 1,
      "X[3000:159571]": 1,
      "val_text_vect": 1,
      "Xs_train": 1,
      "unmissed.drop('survived', axis=1)": 1,
      "unmissed.drop(['survived', 'Q', 'S'], axis=1)": 1,
      "with_alone.drop('survived', axis=1)": 1,
      "unmissed[['class', 'sex', 'age']]": 1,
      "pc_data": 1,
      "pca_with_unmissed": 1,
      "famsize_with_unmissed": 1,
      "xsvm": 1,
      "xknn": 1,
      "X.drop(['survived'], axis=1)": 1,
      "X_train_flatten": 1,
      "transformed_data_train[validation_index]": 1,
      "X_test_rfe": 1,
      "q": 1,
      "xtrain_svd": 1,
      "xvalid_svd": 1,
      "Xv": 1,
      "X_val_2": 1,
      "X_features": 1,
      "test_": 1,
      "X_train_scaled_pca": 1,
      "X_cv_train_tf_sm": 1,
      "X_cv_test_tf": 1,
      "messages_tfidf": 1,
      "train_feature_vectors": 1,
      "X_eval": 1,
      "X_tst": 1,
      "TrainingSet": 1,
      "X_mr_train": 1,
      "X_mr_test": 1,
      "X_not_mr_train": 1,
      "X_not_mr_test": 1,
      "mr_train_df": 1,
      "not_mr_train_df": 1,
      "validX": 1,
      "X_val_prepared": 1,
      "train[feature_col]": 1,
      "vectorizer.transform(x_test)": 1,
      "train_test_data": 1,
      "knn_train.iloc[test_index]": 1,
      "test_X2": 1,
      "test_X3": 1,
      "le_test": 1,
      "xforest_test": 1,
      "df_test_X": 1,
      "testx": 1,
      "X_smote": 1,
      "test[X_cols]": 1,
      "X_testcv": 1,
      "new_X": 1,
      "X1_train_valid_standard": 1,
      "train_X_scaler": 1,
      "Y": 1,
      "df[feature_cols]": 1,
      "X_train[feature_cols]": 1,
      "tr.iloc[train_index]": 1
    },
    "sklearn.base.ClassifierMixin.score.y": {
      "y_test": 892,
      "y_train": 601,
      "Y_train": 321,
      "y_val": 138,
      "y": 82,
      "y_valid": 55,
      "Y_test": 30,
      "ytrain": 23,
      "testRL": 17,
      "train_y": 15,
      "Y": 15,
      "y_train['surface'][val_idx]": 14,
      "y[val_idx]": 13,
      "Y_val": 12,
      "target['surface'][test_index]": 12,
      "y_equidistant": 12,
      "y_balanced": 12,
      "target['surface'][val_idx]": 11,
      "y_test_3": 11,
      "yvalid": 11,
      "val_y": 10,
      "labels2": 10,
      "target": 9,
      "y_train[test]": 9,
      "y_test1": 9,
      "y_cv": 9,
      "label": 9,
      "y_ref_test": 9,
      "ttexty_test": 8,
      "y_tr": 8,
      "test_y": 7,
      "ttextdataemy_test": 7,
      "tsiftdatay_test": 7,
      "train_target": 7,
      "df_Y": 7,
      "train_Y": 6,
      "labels": 6,
      "y_train_lg": 6,
      "y_test_lg": 6,
      "unmissed['survived']": 6,
      "y_test_full": 6,
      "ytest": 5,
      "train_pred": 5,
      "np.argmax(y_train, axis=1)": 4,
      "np.argmax(y_val, axis=1)": 4,
      "y_mod_treino": 4,
      "yval": 4,
      "train_labels": 4,
      "Ytrain": 4,
      "y[test_index]": 4,
      "Y_test_rf": 4,
      "1 * (testpart1['hotel_cluster'][tix].values == i)": 4,
      "trainLabels": 4,
      "yTest": 4,
      "Y_subset": 4,
      "y_pred": 4,
      "train_df['isFraud']": 4,
      "yTrain": 4,
      "survived": 4,
      "y_mod_teste": 3,
      "ytr": 3,
      "yts": 3,
      "test_labels": 3,
      "y_over": 3,
      "testlabels": 3,
      "y_validate": 3,
      "targets": 3,
      "y_train_cv": 3,
      "clfY_test": 3,
      "y_train1": 3,
      "temp_label_test": 3,
      "expected_output_test": 3,
      "y2_test": 3,
      "y_tr[:, 0]": 3,
      "y_te[:, 0]": 3,
      "test[category]": 3,
      "y_test_cv": 3,
      "y_val_2": 3,
      "y_train_test": 3,
      "Y_training_actual": 3,
      "y_test_imp": 3,
      "validate_Y": 3,
      "Y_tra['surface'][val_idx]": 3,
      "train_y1": 3,
      "predict_Y1": 3,
      "valY": 3,
      "y_cols": 3,
      "titanic_train['Survived']": 2,
      "y_value": 2,
      "ytrNow": 2,
      "Ytest": 2,
      "target_df['surface'][test_index]": 2,
      "nlabels": 2,
      "y_train_pca": 2,
      "y_val_pca": 2,
      "train_targets.iloc[valid_id]": 2,
      "test_data_label": 2,
      "test_target": 2,
      "y_teste": 2,
      "test_label": 2,
      "y_vali": 2,
      "y_fid_vali": 2,
      "y1_test": 2,
      "y3_test": 2,
      "sub_target_test": 2,
      "Y_train1": 2,
      "get_labels(train_df)": 2,
      "get_labels(valid_df)": 2,
      "y[i2]": 2,
      "train['label']": 2,
      "y_devtest": 2,
      "val_matchType": 2,
      "test_matchType": 2,
      "y1_a": 2,
      "y2_a": 2,
      "y2": 2,
      "one_hot_to_dense(y_train)": 2,
      "one_hot_to_dense(y_valid)": 2,
      "y_val.ravel()": 2,
      "yTrain['label'][val_idx]": 2,
      "new_target['surface'].values": 2,
      "y['surface'][valid_idx]": 2,
      "data_y[val_idx]": 2,
      "y[train_index]": 2,
      "y[val_index]": 2,
      "Y_cv": 2,
      "y_train_tf": 2,
      "y_valid_tf": 2,
      "label['surface'][val_idx]": 2,
      "X_test['surface']": 2,
      "y_test_1": 2,
      "y_test_2": 2,
      "Y_test_split": 2,
      "Y[33000:]": 1,
      "y_validation": 1,
      "train_data[:, 0]": 1,
      "cv['Cover_Type'].values": 1,
      "y_SMOTE": 1,
      "df_test['target']": 1,
      "train_y_test": 1,
      "Y_disc": 1,
      "y_test_label": 1,
      "y_test2": 1,
      "y_train.astype(int)": 1,
      "y_test.astype(int)": 1,
      "training_data_Y": 1,
      "Y2": 1,
      "Yte": 1,
      "val_label1": 1,
      "y_train_1": 1,
      "y_val_1": 1,
      "y_cv_score": 1,
      "actual": 1,
      "data_numpy_label": 1,
      "testLabels": 1,
      "y_test_c2": 1,
      "y.iloc[:, 0]": 1,
      "df_test_output": 1,
      "expected_output_train": 1,
      "df_val_y": 1,
      "label_val3": 1,
      "Yval": 1,
      "y2_train": 1,
      "y2_cross": 1,
      "trn_polarized.sentiment": 1,
      "val_polarized.sentiment": 1,
      "train_polarized.sentiment": 1,
      "target_initial_train": 1,
      "y_train_reg": 1,
      "y_train_nb": 1,
      "Y_tr": 1,
      "Y_v": 1,
      "df.SeriousDlqin2yrs": 1,
      "timagey_test.values": 1,
      "y_train_encoded": 1,
      "y_validate_encoded": 1,
      "y_dev": 1,
      "dev_label": 1,
      "y1_trainval": 1,
      "y2_trainval": 1,
      "names_test": 1,
      "y4_test": 1,
      "y_tefull": 1,
      "valid_y": 1,
      "d_f2_test_new": 1,
      "y_trn": 1,
      "y_val.values": 1,
      "y_testing": 1,
      "lb.inverse_transform(y_train)": 1,
      "lb.inverse_transform(y_val)": 1,
      "y_test.T": 1,
      "y_train.T": 1,
      "Y_Test": 1,
      "vali_y": 1,
      "y_trainsplit": 1,
      "y_testsplit": 1,
      "testDataFrameNewY": 1,
      "1 * (testpart['hotel_cluster'][tix].values == 1)": 1,
      "1 * (testpart['hotel_cluster'][tix].values == j)": 1,
      "np.ravel(train_y)": 1,
      "np.ravel(test_y)": 1,
      "train1.iloc[te][['target']]": 1,
      "Ypos": 1,
      "Yneg": 1,
      "y_val2": 1,
      "y_train2": 1,
      "y_testest": 1,
      "y_testf": 1,
      "ml_train": 1,
      "ml_val": 1,
      "y[:threshold]": 1,
      "y[threshold:]": 1,
      "yValid": 1,
      "yte": 1,
      "y1": 1,
      "y_n": 1,
      "train_target_class_n": 1,
      "data[:, -1]": 1,
      "data['type']": 1,
      "label_test": 1,
      "truth": 1,
      "y_train[3000:]": 1,
      "with_alone['survived']": 1,
      "ysvm": 1,
      "yknn": 1,
      "X['survived']": 1,
      "y_train.iloc[validation_index]": 1,
      "w": 1,
      "Yv": 1,
      "submission_label.iloc[:]['target']": 1,
      "y_cv_train_binary_sm": 1,
      "y_cv_test_binary": 1,
      "train['sentiment']": 1,
      "y_eval": 1,
      "y_val_cls": 1,
      "targetData": 1,
      "y_mr_train": 1,
      "y_mr_test": 1,
      "y_not_mr_train": 1,
      "y_not_mr_test": 1,
      "mr_y_train": 1,
      "not_mr_y_train": 1,
      "validY": 1,
      "train['Category']": 1,
      "Pre['WnvPresent']": 1,
      "labels_test": 1,
      "y_train_data['surface']": 1,
      "y_val_data['surface']": 1,
      "train_y2": 1,
      "predict_Y2": 1,
      "train_y3": 1,
      "predict_Y3": 1,
      "target_pre": 1,
      "yforest_test": 1,
      "clf_svc.predict(df_test_X)": 1,
      "testy": 1,
      "y_smote": 1,
      "y_testcv": 1,
      "y_train[label]": 1,
      "1 - fit_data_to_regression['answered_correctly']": 1,
      "train_y_np": 1,
      "Xtarget": 1,
      "Ytarget": 1,
      "df['surface']": 1,
      "X_train['surface']": 1,
      "target['surface'][train_index]": 1,
      "null": 1
    },
    "sklearn.linear_model._logistic.LogisticRegression.__init__.penalty": {
      "'l2'": 4753,
      "'l1'": 315,
      "'none'": 20,
      "penalty": 12,
      "'elasticnet'": 8,
      "all_parameters['penalty'][j]": 4,
      "reg": 2,
      "lr_study.best_params['penalty']": 2,
      "best_penalty": 2,
      "params_log['penalty']": 2,
      "trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet', 'none'])": 1,
      "result.best_params_['penalty']": 1,
      "grid_search_lr.best_params_['penalty']": 1,
      "clf.best_params_['penalty']": 1,
      "'L1'": 1,
      "'L2'": 1,
      "penalty_best": 1,
      "trial.suggest_categorical('penalty', ['l2', 'none'])": 1,
      "grid_search.best_params_.get('penalty')": 1
    },
    "sklearn.feature_extraction.text.CountVectorizer.__init__.analyzer": {
      "'word'": 2816,
      "'char'": 47,
      "text_process": 15,
      "preprocess_text": 9,
      "'char_wb'": 8,
      "clean_text": 8,
      "process_text": 7,
      "preprocess": 5,
      "lambda x: x": 5,
      "get_process": 4,
      "own_analyser": 3,
      "test_select": 2,
      "text_processing": 2,
      "cleaner": 1,
      "text_preprocess": 1,
      "data_preprocess": 1,
      "cleanup_message": 1,
      "analyzer": 1,
      "message_cleaning": 1
    },
    "sklearn.feature_extraction.text.TfidfTransformer.__init__.norm": {
      "'l2'": 335,
      "None": 1
    },
    "sklearn.feature_extraction.text.TfidfTransformer.__init__.sublinear_tf": {
      "False": 328,
      "True": 8
    },
    "sklearn.feature_extraction.text.CountVectorizer.fit_transform.raw_documents": {
      "train_df['features']": 92,
      "X_train": 55,
      "train['text']": 46,
      "corpus": 39,
      "train_df['text']": 38,
      "merge['general_cat']": 37,
      "merge['subcat_1']": 37,
      "merge['subcat_2']": 37,
      "merge['name']": 36,
      "train_df[col]": 31,
      "clean_train_reviews": 27,
      "text": 27,
      "df['category_name']": 24,
      "X_train['text']": 24,
      "df['name']": 23,
      "data": 23,
      "train_df['Gene']": 22,
      "train_df['Variation']": 20,
      "train_df['TEXT']": 19,
      "df['TEXT']": 17,
      "merge['category_name']": 17,
      "train_df['text'][0:5]": 16,
      "tr_brand_col": 15,
      "tr_cat1": 15,
      "train['name']": 14,
      "X": 13,
      "sentence": 11,
      "df_train['features']": 11,
      "tr_brand_col + ' ' + tr_desc_col": 10,
      "tr_brand_col + ' ' + tr_col": 10,
      "train_x": 9,
      "fin": 9,
      "train['clean_text']": 9,
      "tr_cat2": 9,
      "tr_cat3": 9,
      "tr_cat_n": 9,
      "tr_col": 9,
      "x_train": 8,
      "X_train.values": 8,
      "df_train['text']": 8,
      "train_data['text']": 8,
      "tr_cat_col": 7,
      "train_data": 6,
      "combined_sample['item_description']": 6,
      "df['text']": 6,
      "df_train['name']": 6,
      "tr_brand_col + ' ' + tr_name_col": 6,
      "news_train_df['headline'].values": 5,
      "train['title'].append(test['title'])": 5,
      "train_data['clean_text']": 5,
      "train['comment_text']": 5,
      "df['Tags']": 5,
      "df['brand_name']": 5,
      "small_text_sample": 5,
      "sample_texts": 4,
      "name_corpus": 4,
      "df['ip'].apply(lambda x: str(x))": 4,
      "df['username'].apply(lambda x: str(x))": 4,
      "df_train['item_description']": 4,
      "df_train['name_bi']": 4,
      "preprocessed_df['Tags']": 4,
      "list_of_ingredient": 4,
      "[str(i) for i in features_processed]": 4,
      "train.excerpt": 4,
      "df.category_name": 4,
      "df.brand_name": 4,
      "X_train.text_1.to_numpy()": 4,
      "cat_in_the_hat_docs": 4,
      "train['Tags']": 4,
      "col": 4,
      "train['category_name']": 4,
      "selected_text_listt": 4,
      "clean_review": 3,
      "news_obs_df['headline'].values": 3,
      "preprocessed_data['tags']": 3,
      "full_data.description_new": 3,
      "train['request_text_edit_aware']": 3,
      "df_train['request_text_edit_aware']": 3,
      "train_df2['text']": 3,
      "corpus1": 3,
      "train_df['seperated_ingredients']": 3,
      "train['Phrase']": 3,
      "texts": 3,
      "df.text": 3,
      "inputs['text']": 3,
      "test['text']": 3,
      "train_X": 3,
      "train['question_text']": 3,
      "clean_test_reviews": 3,
      "X.text": 3,
      "train['hashtags']": 3,
      "test_df['features']": 3,
      "df['subcat_1']": 3,
      "df['subcat_2']": 3,
      "train.text": 3,
      "train_df['question_text']": 3,
      "train_docs_nonum": 3,
      "X_t.excerpt": 3,
      "tt_combine['main_cat']": 3,
      "tt_combine['subcat1']": 3,
      "tt_combine['subcat2']": 3,
      "tt_combine['subcat3']": 3,
      "tt_combine['subcat4']": 3,
      "tt_combine['name']": 3,
      "corpus_train": 3,
      "tr_te.txt1": 3,
      "tr_te.title": 3,
      "[wc_data]": 3,
      "docs": 3,
      "test_df['text']": 3,
      "test_data['clean_text']": 3,
      "s1": 3,
      "s2": 3,
      "sd3": 3,
      "sd4": 3,
      "se5": 3,
      "combined_data['tags']": 3,
      "mydoclist": 3,
      "stringsarray": 3,
      "twenty_databunch.data": 3,
      "df['item_description']": 3,
      "data_df['features']": 3,
      "df['action_type']": 2,
      "tweets_df['absolute_tidy_tweets']": 2,
      "phrase_sents": 2,
      "dataset['text']": 2,
      "sr_clean": 2,
      "all_texts": 2,
      "list(sentences)": 2,
      "train.text.values": 2,
      "X_train.comment_text": 2,
      "frame.comment_text": 2,
      "train": 2,
      "text_data": 2,
      "train_data_df.Text.tolist() + test_data_df.Text.tolist()": 2,
      "df_all['name']": 2,
      "train['general_cat']": 2,
      "train_df['dataset_title']": 2,
      "train_df['cleaned_label']": 2,
      "X_train['non_selected']": 2,
      "x_train['text']": 2,
      "ingredients": 2,
      "features": 2,
      "X_test": 2,
      "all_text['text']": 2,
      "x": 2,
      "message": 2,
      "message1": 2,
      "train_df['ingredients']": 2,
      "df[col]": 2,
      "train_df['description']": 2,
      "full_data['features'].apply(lambda x: ' '.join(['_'.join(i.split(' ')) for i in x]))": 2,
      "full_data['description']": 2,
      "full_data['street_address']": 2,
      "df": 2,
      "X_train['keyword']": 2,
      "data['cleaned_label']": 2,
      "train_tweet['text']": 2,
      "train_df['name']": 2,
      "df['ingredients'].apply(','.join)": 2,
      "X_train['text'][0:5]": 2,
      "train.tokens": 2,
      "headlines_lst": 2,
      "test['clean_text']": 2,
      "text_vec": 2,
      "train['features']": 2,
      "train['text'][0:5]": 2,
      "train['excerpt_clean']": 2,
      "train_question_list": 2,
      "train.comment_text": 2,
      "series": 2,
      "data['Phrase']": 2,
      "df_train['Text']": 2,
      "data.combined": 2,
      "all_df['excerpt']": 2,
      "X_train.text_2.to_numpy()": 2,
      "['no i have cows', 'i have no cows']": 2,
      "final_string": 2,
      "all_data['name']": 2,
      "dt.name": 2,
      "dt.category_name": 2,
      "df['text'].tolist()": 2,
      "df['text_lm'].tolist()": 2,
      "data.general_cat": 2,
      "sample_question_text": 2,
      "clean_train": 2,
      "alldata['comment_text']": 2,
      "corpus_test": 2,
      "train['links']": 2,
      "train['mentions']": 2,
      "final['CleanedText'].values": 2,
      "documents": 2,
      "trn.comment_text": 2,
      "sub.comment_text": 2,
      "pd.concat([trn.comment_text, sub.comment_text], axis=0)": 2,
      "['you have no dog', 'no, you have dog']": 2,
      "train_df.question_text.values": 2,
      "data[text_column]": 2,
      "df_train['keyword']": 2,
      "df_test['keyword']": 2,
      "dictionary['concatenated_questions']": 2,
      "df['subcat_0']": 2,
      "df['cat_brand']": 2,
      "(df['item_condition_id'] + 10 * df['shipping']).apply(str)": 2,
      "summary_df['excerpt']": 2,
      "data['text']": 2,
      "dataset['general_cat']": 2,
      "dataset['subcat_1']": 2,
      "dataset['subcat_2']": 2,
      "X_train['comment_text'].values": 2,
      "train_df['stemmed']": 2,
      "train['clean']": 2,
      "train[col].astype(str)": 2,
      "non_neutral['text']": 2,
      "train_data['question_text'].values.tolist() + test_data['question_text'].values.tolist()": 1,
      "X_train['features']": 1,
      "data['ip'].apply(lambda x: str(x))": 1,
      "data['username'].apply(lambda x: str(x))": 1,
      "train_document": 1,
      "df_train.name": 1,
      "df_train.category_name": 1,
      "df_train.brand_name": 1,
      "df_train.item_description": 1,
      "tag_data['Tags']": 1,
      "X_train['Color']": 1,
      "X_train['SexuponOutcome']": 1,
      "X_train['Breed']": 1,
      "train['stemed_text']": 1,
      "preprocessed_reviews": 1,
      "final_word": 1,
      "full_text": 1,
      "labels_corpus": 1,
      "train_data.url_legal": 1,
      "questions.values.astype('U')": 1,
      "['Bi-grams are cool?', 'more hi.', 'kake metros']": 1,
      "alldata['text']": 1,
      "train['item_description']": 1,
      "test['item_description']": 1,
      "test['name']": 1,
      "train_X_": 1,
      "clean_train_phrase": 1,
      "df.loc[:, 'ingredients'].apply(clean_ingredients_list, bigrams=False)": 1,
      "train_df['brand_name'].values": 1,
      "train_df['gencat_name'].values": 1,
      "train_df['subcat1_name'].values": 1,
      "train_df['subcat2_name'].values": 1,
      "xtr": 1,
      "train['seperated_ingredients']": 1,
      "df_train['Cleaned_Text']": 1,
      "mycorpus": 1,
      "text_train": 1,
      "curpus": 1,
      "df['text'].values": 1,
      "final_flood_words": 1,
      "data[Col].fillna('')": 1,
      "df_all['gen_cat']": 1,
      "df_all['cat1']": 1,
      "df_all['cat2']": 1,
      "train['subcat_1']": 1,
      "train['subcat_2']": 1,
      "data['all_ingredients'].values": 1,
      "positive": 1,
      "negative": 1,
      "combine[0]['text']": 1,
      "dfTrain.text": 1,
      "df[col].tolist()": 1,
      "df.tags": 1,
      "df.lemma": 1,
      "both_df['Ing']": 1,
      "df['Phrase']": 1,
      "data_copy['Tags']": 1,
      "train['mer_cate_id_list']": 1,
      "train['nmt_mer_cate_id_list']": 1,
      "combined_data['name']": 1,
      "combined_data['category_name']": 1,
      "combined_frac['item_description']": 1,
      "train_list": 1,
      "df_train.ingredients_concat": 1,
      "text_df['text']": 1,
      "df_train['all_ingredients'].values": 1,
      "train_df.preprocessed": 1,
      "xfeatures": 1,
      "sample['name']": 1,
      "sample['item_description']": 1,
      "clean_train_reviews1": 1,
      "df_all['category_general']": 1,
      "df_all['category_sub1']": 1,
      "df_all['category_sub2']": 1,
      "x_train1.values": 1,
      "sample.excerpt": 1,
      "all_recipe": 1,
      "train['pub_title']": 1,
      "train['dataset_title']": 1,
      "train['dataset_label']": 1,
      "X_train_val['Gene']": 1,
      "X_train_val['Variation']": 1,
      "X_train_val['TEXT']": 1,
      "test_ingredients": 1,
      "items.loc[:, 'item_name_clean']": 1,
      "train_df['lemmatize_text']": 1,
      "trainv['text']": 1,
      "train['name_bi']": 1,
      "X_train_preprocessed": 1,
      "['Hi How are you How are you doing', \"Hi what's up\", \"Wow that's awesome\"]": 1,
      "phrase_train": 1,
      "bulletins_df['text']": 1,
      "data['features_word']": 1,
      "combine_text": 1,
      "bag_of_features[feature_name]": 1,
      "train_df.features": 1,
      "merge['cat1']": 1,
      "merge['cat2']": 1,
      "merge['cat3']": 1,
      "train_data['stem_text']": 1,
      "train_df[Col]": 1,
      "all_data": 1,
      "treino_frase": 1,
      "df_no_dup['Tags']": 1,
      "preprocessed_data['Tags']": 1,
      "train['link']": 1,
      "train['tagged']": 1,
      "hpl": 1,
      "eap": 1,
      "mws": 1,
      "df_vec['metadata']": 1,
      "dictionary2": 1,
      "cleaned_rev": 1,
      "tweets": 1,
      "train.excerpt.append(test.excerpt)": 1,
      "df['lemma_str']": 1,
      "train1['text']": 1,
      "data['text_cleaned']": 1,
      "data_train['text']": 1,
      "train['first_category_name']": 1,
      "train['second_category_name']": 1,
      "train['third_category_name']": 1,
      "train['text'].values.astype('U')": 1,
      "train_feature": 1,
      "train_csr_matrix['name']": 1,
      "train_csr_matrix['brand_name']": 1,
      "train_csr_matrix['main_category']": 1,
      "train_csr_matrix['subcat_1']": 1,
      "train_csr_matrix['subcat_2']": 1,
      "[product_title_i, search_term_i]": 1,
      "[description_i, search_term_i]": 1,
      "[attribute_i, search_term_i]": 1,
      "essays_train": 1,
      "train['project_title']": 1,
      "essays_train + ' ' + train['project_title']": 1,
      "data['lemmatized']": 1,
      "sentence_list_lemmatized": 1,
      "sentence_list": 1,
      "xtrain.iloc[:, 0]": 1,
      "xtrain.iloc[:, 1]": 1,
      "df_train.clean_text": 1,
      "x_train.clean_categories.values": 1,
      "x_train.clean_subcategories.values": 1,
      "df['description'].fillna('')": 1,
      "questionnaire_sections['question_name']": 1,
      "pos": 1,
      "toxic_2": 1,
      "severe_toxic2": 1,
      "obscene2": 1,
      "threat2": 1,
      "insult2": 1,
      "identity_hate2": 1,
      "comment_text_train": 1,
      "set(data_sentences)": 1,
      "train_docs": 1,
      "test_X": 1,
      "result['Gene'][0:first]": 1,
      "result['Variation'][0:first]": 1,
      "result['TEXT'][0:first]": 1,
      "clean_text(train, train.shape[0])": 1,
      "sents": 1,
      "sentsT": 1,
      "X_train['text'].values.astype('U')": 1,
      "df['review']": 1,
      "df_train['ingredient_text']": 1,
      "copy_train.clean_text": 1,
      "test_data.clean_text": 1,
      "train[COMMENT]": 1,
      "traindf['text']": 1,
      "Corpus": 1,
      "headlines": 1,
      "title_data": 1,
      "clean_train_text": 1,
      "df.Word_list": 1,
      "train['question_title']": 1,
      "train['question_body']": 1,
      "train['question_user_page']": 1,
      "train['answer']": 1,
      "train['answer_user_page']": 1,
      "train['url']": 1,
      "train['host']": 1,
      "tweets['text']": 1,
      "df_train.text": 1,
      "train_features['name']": 1,
      "X_train['cleaned_comment']": 1,
      "X_train['text_2'].to_numpy()": 1,
      "train_input['text_1'].to_numpy()": 1,
      "df.name": 1,
      "df.c1": 1,
      "df.c2": 1,
      "df.c3": 1,
      "train[col]": 1,
      "df_test['text']": 1,
      "['andersen', 'petersen', 'petrov', 'smith']": 1,
      "[sample]": 1,
      "train_data.review": 1,
      "df_train['Tokens_clean_text']": 1,
      "train['name'].append(test['name'])": 1,
      "trainData['text'][0:5]": 1,
      "trainData['text']": 1,
      "ingredient_list1": 1,
      "news_obs_df['headline']": 1,
      "partial_news['headline']": 1,
      "df_train.question_text": 1,
      "df_text": 1,
      "pd.Series(train['preprocessed_text'].tolist())": 1,
      "merge['display_address']": 1,
      "merge['street_address']": 1,
      "merge['features_']": 1,
      "df_ga_full['app_lab'].fillna('Missing')": 1,
      "all_data['cat1']": 1,
      "all_data['cat2']": 1,
      "all_data['cat3']": 1,
      "df_train['category_main']": 1,
      "df_train['category_sub1']": 1,
      "df_train['category_sub2']": 1,
      "raw_documents": 1,
      "df_nb.joined": 1,
      "merged['name']": 1,
      "merged['cat_1']": 1,
      "merged['cat_2']": 1,
      "merged['cat_3']": 1,
      "combined_texts": 1,
      "df_train['text'][0:5]": 1,
      "all_addr": 1,
      "ex_list": 1,
      "train_df[text_col].as_matrix()": 1,
      "clean_train_review": 1,
      "df['fea_des_stem1']": 1,
      "X_valid": 1,
      "desc": 1,
      "train_fill['item_description_normalized']": 1,
      "df_train['cat1']": 1,
      "df_train['cat2']": 1,
      "train_df['all_ingredients'].values": 1,
      "dados[coluna_teste]": 1,
      "corpustrain": 1,
      "train.clean_text": 1,
      "get_stemmed_text(pd_train_set.text)": 1,
      "X_new": 1,
      "train.brand_name.astype('U')": 1,
      "train.name.astype('U')": 1,
      "train.item_description.astype('U')": 1,
      "df_all['clean_text']": 1,
      "mes": 1,
      "sent": 1,
      "train[['comment_text']].as_matrix().reshape((-1, ))": 1,
      "X_train.reshape(-1)": 1,
      "X_test.reshape(-1)": 1,
      "train_text.to_list()": 1,
      "x_test[0:1000]": 1,
      "x_train[0:1000]": 1,
      "complete_test['pos_tag_sentence']": 1,
      "df['excerpt']": 1,
      "dataset['name']": 1,
      "collect": 1,
      "collect_k": 1,
      "collect_l": 1,
      "clean_tweets": 1,
      "train_df[train_df['sentiment'] == corpus]['c_s_text']": 1,
      "train['clean_txt']": 1,
      "df_train['Phrase']": 1,
      "d_train.text.values": 1,
      "X_train_text": 1,
      "sample_corpora": 1,
      "train_df['cleaned_text']": 1,
      "X_train.stemmed_words": 1,
      "X_train.lemmatized_words": 1,
      "np.array([doc1, doc2])": 1,
      "df_dataclean_final['text_lemma']": 1,
      "df_dataclean_final['text_stem']": 1,
      "test['features']": 1,
      "tagged_sentences": 1,
      "train_df['category_name'].values.tolist() + test_df['category_name'].values.tolist()": 1,
      "train_df['brand_name'].values.tolist() + test_df['brand_name'].values.tolist()": 1,
      "train[:25].clean_text": 1,
      "user_products": 1,
      "[st]": 1,
      "train_data['name']": 1,
      "cleanq1s": 1,
      "cleanq2s": 1,
      "d_train.comment_text": 1,
      "X_donor_choose_train['project_subject_categories'].values": 1,
      "X_donor_choose_train['project_subject_subcategories'].values": 1,
      "X_donor_choose_train['teacher_prefix'].values": 1,
      "X_donor_choose_train['project_grade_category'].values": 1,
      "X_donor_choose_train['school_state'].values": 1,
      "X_donor_choose_train['essay']": 1,
      "df.ingredients.str.join(' ')": 1,
      "merge_2['name']": 1,
      "merge_2['category_name']": 1,
      "['andersen', 'peterson', 'petrov', 'smith']": 1,
      "train['sub_category1']": 1,
      "train['sub_category2']": 1,
      "train['sub_category3']": 1,
      "df_ltrain": 1,
      "electronics['name']": 1,
      "electronics['category_name']": 1,
      "data[descr].fillna('')": 1,
      "data['ingredients'].append(test['ingredients'])": 1,
      "train.text.fillna(' ') + ' ' + train.sentiment": 1,
      "(train.text.fillna(' ') + ' ' + train.sentiment).append(test.text.fillna(' '))": 1,
      "dfQ['question1']": 1,
      "dfQ['question2']": 1,
      "di1": 1,
      "di2": 1,
      "eq": 1,
      "train.Description.append(test.Description).fillna(' ')": 1,
      "traintit['test']": 1,
      "train['question1']": 1,
      "train['question2']": 1,
      "testtit['test']": 1,
      "test['question1']": 1,
      "test['question2']": 1,
      "train[train.toxic == 1]['comment_text']": 1,
      "train_df[train_df.target == 0].question_text.values": 1,
      "train_df[train_df.target == 1].question_text.values": 1,
      "train['comment_text'].apply(lambda x: str(x))": 1,
      "cleaned_tweet": 1,
      "clean_train_excerpts": 1,
      "train.hashtags": 1,
      "processed_text": 1,
      "df_train['every_ingredients'].values": 1,
      "all_data['category_main']": 1,
      "all_data['category_sub1']": 1,
      "all_data['category_sub2']": 1,
      "all_data['descr_length']": 1,
      "cleaned_train_reviews": 1,
      "train_df['tidy_tweets']": 1,
      "comb['first_category']": 1,
      "comb['second_category']": 1,
      "comb['third_category']": 1,
      "data['tidy_text']": 1,
      "train_full['Text']": 1,
      "train['sub_cat1']": 1,
      "train['sub_cat2']": 1,
      "df_train['clean_text']": 1,
      "test_df['Gene']": 1,
      "cv_df['Gene']": 1,
      "data.Tags": 1,
      "x_trn": 1,
      "train['description']": 1,
      "df_train['Address'].values": 1,
      "trainData['Phrase']": 1,
      "X_": 1,
      "Comment": 1,
      "sample.values": 1,
      "X_train['location']": 1,
      "df['lemme_text']": 1,
      "full_df['name']": 1,
      "full_df['category_name']": 1,
      "T[Col].fillna('')": 1,
      "df['lemmatized']": 1,
      "train_df['text_clean'][0:5]": 1,
      "train_df['text_clean']": 1,
      "train_train_data['text']": 1,
      "train.text_cleaned": 1,
      "train.text_ent_repl": 1,
      "train_data['text'][0:5]": 1,
      "train.text_without_stopwords": 1,
      "test.text_without_stopwords": 1,
      "df1['text'][0:5]": 1,
      "df1['text']": 1,
      "features_list": 1,
      "posts": 1,
      "data['combined_text']": 1,
      "x_text['clean']": 1,
      "(text for text in train['question_text'])": 1,
      "train_data['review']": 1,
      "train_data['Phrase']": 1,
      "sentiment_ru['Words']": 1,
      "lemmatize_data.text": 1,
      "doc_cleaned": 1,
      "train_text.text": 1,
      "X_train['Gene']": 1,
      "X_train['Variation']": 1,
      "X_train['TEXT']": 1,
      "train_df['clean_pub_title']": 1,
      "train_df['unicode_handled_title']": 1,
      "x_train.Gene": 1,
      "x_train.Variation": 1,
      "x_train.Text": 1,
      "df_test['Phrase']": 1,
      "new_df": 1,
      "X['search_term']": 1,
      "tx": 1,
      "list(train_X['comment_text_arranged'].values)": 1,
      "list(test_X['comment_text_arranged'].values)": 1,
      "name[dataset['for_train']]": 1,
      "item_description[dataset['for_train']]": 1,
      "texts[dataset['for_train']]": 1,
      "sequence[:train_size]": 1,
      "test['category_name']": 1,
      "c_df.excerpt": 1,
      "train_reviews_cleaned": 1,
      "test_reviews_cleaned": 1,
      "word_corpus": 1,
      "combi['tidy_text']": 1,
      "X_train['clean_selected_text']": 1,
      "stemmer_corpus_train": 1,
      "lem_corpus_train": 1,
      "train_text": 1,
      "train['stemmed_text']": 1,
      "data['title']": 1,
      "train_data['text_simple']": 1,
      "added_df['text']": 1,
      "test_corpus": 1,
      "train_X.values": 1,
      "Combined_data['name']": 1,
      "new_corpus": 1,
      "data['name']": 1,
      "data['comment_text']": 1,
      "desc_re['desc_count'].astype(str)": 1,
      "X_train['title'].append(X_test['title'])": 1,
      "ts_col": 1,
      "ts_brand_col + ' ' + ts_desc_col": 1,
      "messages.text": 1,
      "market_train_df.headline": 1,
      "market_train_df.subjects": 1,
      "r['tags']": 1,
      "df_con['name']": 1,
      "df['title']": 1,
      "train['features_new']": 1,
      "merged_df['ingredients'].apply(','.join)": 1,
      "dev_all_tokens": 1,
      "train_df['res_description']": 1,
      "X['text']": 1,
      "LECTURES['type_of']": 1,
      "x.loc[:, i]": 1,
      "ingr": 1,
      "train_cleaned['comment_text']": 1,
      "corpustr_br": 1,
      "corpustr_col": 1,
      "df_all['category_name']": 1,
      "train_words + test_words": 1,
      "df['object']": 1
    },
    "sklearn.feature_extraction.text.TfidfTransformer.transform.X": {
      "X": 10,
      "X_test": 7,
      "X_new_counts": 5,
      "cv10": 3,
      "train_data_cv": 3,
      "test_data_cv": 3,
      "X_test_counts": 3,
      "term_freq_matrix": 3,
      "cv.transform([doc])": 3,
      "x_train_dtm": 2,
      "df_test_bow_trans": 2,
      "train_X_bow": 2,
      "test_X_bow": 2,
      "X_test_vect": 2,
      "sentence_test_count": 2,
      "test_term_doc": 2,
      "X_train_counts": 2,
      "X_train": 2,
      "bow1": 2,
      "review_bow": 2,
      "terms_matrix_1": 2,
      "terms_matrix_2": 2,
      "common_terms_matrx": 2,
      "dev_X": 2,
      "test_X": 2,
      "x_test_counts": 1,
      "ingredient_list_count": 1,
      "train_text_bow": 1,
      "test_text_bow": 1,
      "train_keyword_bow": 1,
      "test_keyword_bow": 1,
      "X_val_counts": 1,
      "train_text_counts": 1,
      "test_text_counts": 1,
      "test": 1,
      "count_vector": 1,
      "train_sparse": 1,
      "test_sparse": 1,
      "phrases_bow": 1,
      "test_bow": 1,
      "X_train_dtm": 1,
      "test_df.iloc[:, 1:].values": 1,
      "X_test_vec": 1,
      "test_counts": 1,
      "cvec.transform(X_test)": 1,
      "X_t": 1,
      "count_vect.transform(test[['comment_text']].as_matrix().reshape((-1, )))": 1,
      "X_valid": 1,
      "df_test": 1,
      "small_tranformed": 1,
      "test_counts_transformed": 1,
      "cvec.transform(document)": 1,
      "finaldata": 1,
      "testdata": 1,
      "test_x": 1,
      "train_comments_count": 1,
      "test_comments_count": 1,
      "X_test_in": 1,
      "X_vect_train": 1,
      "X_vect_test": 1,
      "train_data_features": 1,
      "test_data_features": 1,
      "test_vec": 1,
      "public_vec": 1,
      "test_vec_b": 1,
      "test_vec_b_2": 1,
      "public_vec_b_2": 1,
      "counted_fitted_words": 1,
      "feature_vec": 1,
      "text_X_test": 1,
      "text_X_real": 1
    },
    "sklearn.metrics._classification.recall_score.average": {
      "'binary'": 462,
      "'macro'": 418,
      "'weighted'": 195,
      "'micro'": 23,
      "None": 19,
      "average_method": 3,
      "average": 2,
      "avg": 1,
      "'samples'": 1
    },
    "sklearn.metrics._classification.recall_score.y_true": {
      "y_test": 227,
      "cm_correct_labels": 221,
      "y_train": 44,
      "yvalid": 44,
      "y_val": 34,
      "y_true": 34,
      "val_y": 29,
      "y_valid": 25,
      "y": 16,
      "target": 15,
      "tsiftdatay_test": 15,
      "self.y_train": 14,
      "y_Val": 12,
      "Y_train": 11,
      "y_pc_imp_train": 11,
      "val_targ": 11,
      "y_pc_imp_test": 10,
      "correct_labels": 9,
      "self.y_val": 9,
      "ttexty_test": 9,
      "ttextdataemy_test": 8,
      "testY": 8,
      "labels": 7,
      "y_test_lg": 7,
      "testing_labels": 6,
      "Y_test": 6,
      "real": 6,
      "y_true_subset": 6,
      "valid_labels": 6,
      "ytest": 5,
      "self.y_test": 5,
      "pred_tag": 5,
      "test_labels": 5,
      "train_df.iloc[valid_idx][target].values": 5,
      "test_Y": 5,
      "targets": 5,
      "test_y": 4,
      "ground_truth": 4,
      "yy": 4,
      "y_sets[i]": 4,
      "trues_train": 4,
      "trues_valid": 4,
      "pred_y": 4,
      "true": 4,
      "y_pred": 4,
      "val_data.labels": 4,
      "yhat_Train": 4,
      "Y_valid": 3,
      "pred_labels[0]": 3,
      "pred_labels[1]": 3,
      "pred_labels[2]": 3,
      "y2": 3,
      "val_correct_labels": 3,
      "val_labels": 3,
      "train_df['TARGET']": 2,
      "df_train_[target_name]": 2,
      "predictions": 2,
      "oof_df['open_channels']": 2,
      "label": 2,
      "GBclf.predict(clfX_test)": 2,
      "current_y_val": 2,
      "y_train[idxV, 0]": 2,
      "y_train[idxV, 1]": 2,
      "y_train[idxV, 2]": 2,
      "true_labels": 2,
      "valid_y": 2,
      "test_target": 2,
      "y[test]": 2,
      "grapheme_final_output": 2,
      "vowel_final_output": 2,
      "consonant_final_output": 2,
      "tars_1": 2,
      "y_Test": 2,
      "y_cv": 2,
      "validate_labels": 2,
      "Holdy": 2,
      "ytrain": 2,
      "y_train_temp": 2,
      "y_test_temp": 2,
      "(train.resp > 0).astype(int)": 2,
      "(val.resp > 0).astype(int)": 2,
      "Y[test]": 2,
      "tgts": 2,
      "pred_label_graphemes": 2,
      "pred_label_vowels": 2,
      "pred_label_consonants": 2,
      "y.iloc[val_idx].values": 2,
      "oof_val_true": 2,
      "test_true": 2,
      "target[val_idx]": 2,
      "test_batches.labels": 2,
      "y_test9": 2,
      "list1": 2,
      "eval_table['true_target']": 1,
      "train_df['target']": 1,
      "y_": 1,
      "label_list": 1,
      "sub['prediction']": 1,
      "Y": 1,
      "root_val": 1,
      "vowel_val": 1,
      "consonant_val": 1,
      "np.argmax(validation_labels, axis=1)": 1,
      "input_grapheme_root": 1,
      "input_consonant_diacritic": 1,
      "input_vowel_diacritic": 1,
      "LSTM_y_test": 1,
      "GRU_y_test": 1,
      "sepcnn_y_test": 1,
      "ysp_test": 1,
      "self.valid_outputs[0]": 1,
      "self.valid_outputs[1]": 1,
      "self.valid_outputs[2]": 1,
      "yhat": 1,
      "validation_labels": 1,
      "true_value": 1,
      "train2.loc[train_index]['target']": 1,
      "train2.loc[val_index]['target']": 1,
      "Y_test_old": 1,
      "test": 1,
      "pred_survived": 1,
      "y_vldt": 1,
      "train_y": 1,
      "true_class": 1,
      "timagey_test.values": 1,
      "pre": 1,
      "va_g_trues": 1,
      "va_v_trues": 1,
      "va_c_trues": 1,
      "result": 1,
      "y_dev": 1,
      "val_preds_lgb": 1,
      "First['Man']": 1,
      "Second['Man']": 1,
      "y_te": 1,
      "train_df_all.outliers": 1,
      "rm_correct_labels": 1,
      "pred_nval_y": 1,
      "pred_glove_val_y": 1,
      "cm_correct_labelsall": 1,
      "cm_correct_labels_n": 1,
      "y_batch": 1,
      "ypred_Logreg": 1,
      "ypred_rfc": 1,
      "ypred_naive": 1,
      "set_validacion_ordenado.classes": 1,
      "targets[:, 0]": 1,
      "targets[:, 1]": 1,
      "targets[:, 2]": 1,
      "train_df2.iloc[val_idx]['target'].values": 1,
      "y_test_": 1,
      "y_train_0": 1,
      "sample_y_val": 1,
      "y_train_pred_final.Survived": 1,
      "sub_preds": 1,
      "y[0]": 1,
      "y[1]": 1,
      "y[2]": 1,
      "y_test10": 1,
      "y_test2": 1,
      "y_test1": 1,
      "y_test3": 1,
      "y_test4": 1,
      "y_test5": 1,
      "y_test6": 1,
      "y_test7": 1,
      "y_test8": 1,
      "mnist_labels": 1,
      "y_cv_test_binary": 1,
      "y_fullcv_test": 1,
      "test_gen.classes": 1,
      "results['y_val']": 1,
      "lb": 1,
      "cm_labels": 1,
      "xgb.predict(X_test)": 1,
      "catb.predict(X_test)": 1,
      "y_is9_validation": 1,
      "y.iloc[test_idx_3]": 1,
      "Y_validation": 1
    },
    "sklearn.metrics._classification.recall_score.y_pred": {
      "cm_predictions": 220,
      "y_pred": 168,
      "predictions": 60,
      "pred": 37,
      "y_pred_class": 23,
      "y_pred_train": 22,
      "y_test": 20,
      "y_pred_test": 17,
      "val_predictions": 12,
      "preds": 12,
      "y_pred_val": 12,
      "y_pred6": 12,
      "predicted": 11,
      "train_predictions": 11,
      "val_predict": 11,
      "y_pred_cat": 9,
      "y_preds": 9,
      "Y_pred_rand": 9,
      "prediction": 9,
      "y_predicted": 6,
      "y_pred_subset": 6,
      "y_val": 6,
      "train_pred": 5,
      "ypred_class": 5,
      "valid_pred": 5,
      "y_train_pred": 5,
      "predictcombine": 5,
      "oof[valid_idx].round()": 5,
      "pred1": 4,
      "preds_train": 4,
      "preds_valid": 4,
      "label_pre": 4,
      "label_pre >= thresh": 4,
      "predict_labels": 4,
      "rf_pred": 4,
      "predIdxs_VGG": 4,
      "yhat_test": 4,
      "y_predi": 4,
      "test_pred": 3,
      "y_train_pred_rf": 3,
      "y_pred_test_rf": 3,
      "y_pred_test_rf_val": 3,
      "pred3": 3,
      "pred4": 3,
      "y[:, 0]": 3,
      "y[:, 1]": 3,
      "y[:, 2]": 3,
      "predicted_labels": 3,
      "result": 3,
      "Y_pred": 3,
      "roc_predictions": 3,
      "y_valid": 3,
      "y_pred_lstm": 3,
      "pred_mode": 3,
      "valid_preds": 3,
      "y_test_preds": 3,
      "(pred_noemb_val_y_gru > thresh).astype(int)": 2,
      "(pred_noemb_val_y_lstm > thresh).astype(int)": 2,
      "(pred_glove_val_y_gru > thresh).astype(int)": 2,
      "(pred_glove_val_y_lstm > thresh).astype(int)": 2,
      "(pred_fasttext_val_y_gru > thresh).astype(int)": 2,
      "(pred_fasttext_val_y_lstm > thresh).astype(int)": 2,
      "(pred_paragram_val_y_gru > thresh).astype(int)": 2,
      "(pred_paragram_val_y_lstm > thresh).astype(int)": 2,
      "(pred_val_y_gru > thresh).astype(int)": 2,
      "(pred_val_y_lstm > thresh).astype(int)": 2,
      "predictions_2": 2,
      "y_pred1": 2,
      "y_pred_xgb": 2,
      "pred5": 2,
      "test_predictions": 2,
      "oof_df['oof']": 2,
      "predict": 2,
      "tes": 2,
      "clfY_test.values": 2,
      "np.round(oofmain)": 2,
      "np.round(oofsingle)": 2,
      "current_predictions": 2,
      "oof1b": 2,
      "oof2b": 2,
      "oof3b": 2,
      "yhat": 2,
      "grapheme_final_label": 2,
      "vowel_final_label": 2,
      "consonant_final_label": 2,
      "preds_1": 2,
      "(y_val_pred > f1_threshold).astype(int)": 2,
      "vc.predict(ttextdataemx_test)": 2,
      "clf.predict(testfeature)": 2,
      "vc.predict(testfeature)": 2,
      "vc.predict(tsiftdatax_test)": 2,
      "y_pred_round": 2,
      "validate_pre_label": 2,
      "Y_prediction_RF": 2,
      "label_predict": 2,
      "train_actions": 2,
      "val_actions": 2,
      "y_predict": 2,
      "val_y": 2,
      "y_pred_batch": 2,
      "true_label_graphemes": 2,
      "true_label_vowels": 2,
      "true_label_consonants": 2,
      "pred_labels[0]": 2,
      "pred_labels[1]": 2,
      "pred_labels[2]": 2,
      "y_oof[val_idx].round()": 2,
      "model.predict(X_test)": 2,
      "oof.round()": 2,
      "predictions.round()": 2,
      "y_pred_bidirectional_lstm": 2,
      "y_pred_cnn": 2,
      "y_pred_lstm_cnn": 2,
      "y_pred_bidirectional_lstm_cnn": 2,
      "oof[val_idx].round()": 2,
      "pred_label": 2,
      "y_pred9": 2,
      "predict_svc": 1,
      "eval_table['pred_target']": 1,
      "train_df['predictions']": 1,
      "predictions_DCmodel_1": 1,
      "predictions_DCmodel_2": 1,
      "predictions_DCmodel_3": 1,
      "predictions_LSTM_model_1": 1,
      "predictions_LSTM_model_2": 1,
      "predictions_LSTM_model_3": 1,
      "y_pred_NN": 1,
      "dtest_Y": 1,
      "best_preds": 1,
      "pred_list": 1,
      "y_pred_changed": 1,
      "root_preds": 1,
      "vowel_preds": 1,
      "consonant_preds": 1,
      "pred_xg": 1,
      "np.argmax(validation_outputs, axis=1)": 1,
      "train_pr": 1,
      "valid_pr": 1,
      "np.round(oof_preds[val_idx])": 1,
      "np.round(oof_preds)": 1,
      "output_grapheme_root": 1,
      "output_consonant_diacritic": 1,
      "output_vowel_diacritic": 1,
      "y_pred_rf": 1,
      "LSTM_yhat_test": 1,
      "GRU_yhat_test": 1,
      "RandomForestClassifier_yhat_test": 1,
      "SGDClassifier_yhat_test": 1,
      "MultinomialNB_yhat_test": 1,
      "sepcnn_yhat_test": 1,
      "ysp_pred": 1,
      "preds0": 1,
      "preds1": 1,
      "preds2": 1,
      "ypred": 1,
      "pred[:, 1] > thresh": 1,
      "ys": 1,
      "y_valid_pred": 1,
      "pred_bool": 1,
      "rf_predict_resampled": 1,
      "clf_rf.predict(x_val)": 1,
      "clf_rf.predict(test_features)": 1,
      "predict_nb": 1,
      "predict_dtc": 1,
      "predict_svm": 1,
      "predict_nn_plp": 1,
      "data_submittion": 1,
      "y_pred_valid.round()": 1,
      "y_int_max": 1,
      "y": 1,
      "pred_76": 1,
      "pred_86": 1,
      "pred_56": 1,
      "pred_46": 1,
      "y_pred_train_hyper": 1,
      "y_pred_hyper": 1,
      "y_preds_rand": 1,
      "y_val_pred": 1,
      "label": 1,
      "eval_pred_class": 1,
      "svc.predict(ttextdataemx_test)": 1,
      "clf.predict(ttextdataemx_test)": 1,
      "dt.predict(ttextdataemx_test)": 1,
      "rf.predict(ttextdataemx_test)": 1,
      "ab.predict(ttextdataemx_test)": 1,
      "est.predict(ttextdataemx_test)": 1,
      "svc.predict(testfeature)": 1,
      "dt.predict(testfeature)": 1,
      "rf.predict(testfeature)": 1,
      "ab.predict(testfeature)": 1,
      "est.predict(testfeature)": 1,
      "clf.predict(timagearrayx_test)": 1,
      "svc.predict(tsiftdatax_test)": 1,
      "clf.predict(tsiftdatax_test)": 1,
      "dt.predict(tsiftdatax_test)": 1,
      "rf.predict(tsiftdatax_test)": 1,
      "ab.predict(tsiftdatax_test)": 1,
      "est.predict(tsiftdatax_test)": 1,
      "tphasharrayy_test.values": 1,
      "clf2.predict(tsiftdatax_test)": 1,
      "predictsift": 1,
      "va_g_preds": 1,
      "va_v_preds": 1,
      "va_c_preds": 1,
      "result_test": 1,
      "Y_pred_grid": 1,
      "Holdgrouped['MLPPred']": 1,
      "First['Pred']": 1,
      "Second['Pred']": 1,
      "new_pred": 1,
      "predicts": 1,
      "p": 1,
      "pred_val": 1,
      "train_predict": 1,
      "scores": 1,
      "train_df_all.predict_outliers": 1,
      "y_predic": 1,
      "lr_pred": 1,
      "svc_pred": 1,
      "lstm_pred": 1,
      "cm_predictionsall": 1,
      "cm_predictions_n": 1,
      "predict_y_gbm": 1,
      "yhat_classes": 1,
      "y_test_pred": 1,
      "predicciones_val": 1,
      "pref_y_bin": 1,
      "pred_y": 1,
      "test": 1,
      "torch.round(val_preds.cpu())": 1,
      "val_preds": 1,
      "y_pred_": 1,
      "sample_y_pred": 1,
      "val_y_pred": 1,
      "y_train_pred_final.predicted": 1,
      "rf_pred_test": 1,
      "rf_pred_train_2": 1,
      "rf_pred_test_2": 1,
      "rf_pred_train_3": 1,
      "rf_pred_test_3": 1,
      "rf_pred_train_4": 1,
      "rf_pred_test_4": 1,
      "rf_pred_train_5": 1,
      "rf_pred_test_5": 1,
      "rf_pred_train_6": 1,
      "rf_pred_test_6": 1,
      "rf_pred_train_7": 1,
      "rf_pred_test_7": 1,
      "rf_pred_train_8": 1,
      "rf_pred_test_8": 1,
      "rf_pred_train_9": 1,
      "rf_pred_test_9": 1,
      "predictions_tuned_linear_svc": 1,
      "predictions_tuned_logistic_regression": 1,
      "predictions_tuned_extra_trees": 1,
      "predictions_tuned_random_forest": 1,
      "pred_tuned_mode": 1,
      "y_test_pred_sgd": 1,
      "NB_pred": 1,
      "SDG_pred": 1,
      "pred21": 1,
      "pred22": 1,
      "cm_pre": 1,
      "y_pred10": 1,
      "y_pred2": 1,
      "y_pred3": 1,
      "y_pred4": 1,
      "y_pred5": 1,
      "y_pred7": 1,
      "y_pred8": 1,
      "mnist_label_preds": 1,
      "identity_predicted": 1,
      "cv_predict": 1,
      "a": 1,
      "results['y_hat']": 1,
      "y_pred.round()": 1,
      "op": 1,
      "yt_pred": 1,
      "train_prediction": 1,
      "val_prediction": 1,
      "m.predict(xs)": 1,
      "pred_tr1": 1,
      "pred2": 1,
      "pred_tr2": 1,
      "pred_tr3": 1,
      "pred_tr4": 1,
      "y_pred_90": 1,
      "cm_preds": 1,
      "y_true_tag": 1,
      "y_predictions": 1,
      "val_predictions_flat": 1,
      "np.round(predictions_all[str(weight)])": 1,
      "pred_logit": 1
    },
    "sklearn.metrics._classification.precision_score.average": {
      "'binary'": 484,
      "'macro'": 358,
      "'weighted'": 233,
      "'micro'": 50,
      "None": 21,
      "average_method": 3,
      "average": 2,
      "avg": 1,
      "'samples'": 1
    },
    "sklearn.metrics._classification.precision_score.y_true": {
      "y_test": 249,
      "cm_correct_labels": 222,
      "y_train": 90,
      "y_val": 47,
      "yvalid": 44,
      "val_y": 37,
      "y_true": 37,
      "y_valid": 26,
      "y": 22,
      "Y_train": 15,
      "target": 14,
      "self.y_train": 14,
      "tsiftdatay_test": 14,
      "testing_labels": 12,
      "y_Val": 12,
      "y_pc_imp_train": 11,
      "val_targ": 11,
      "y_pc_imp_test": 10,
      "correct_labels": 9,
      "self.y_val": 9,
      "ttexty_test": 9,
      "ttextdataemy_test": 8,
      "labels": 7,
      "y_test_lg": 7,
      "Y_test": 6,
      "valid_labels": 6,
      "ytest": 5,
      "self.y_test": 5,
      "pred_tag": 5,
      "test_labels": 5,
      "train_df.iloc[valid_idx][target].values": 5,
      "test_Y": 5,
      "targets": 5,
      "ground_truth": 4,
      "yy": 4,
      "y_sets[i]": 4,
      "trues_train": 4,
      "trues_valid": 4,
      "pred_y": 4,
      "val_data.labels": 4,
      "yhat_Train": 4,
      "y2": 3,
      "val_correct_labels": 3,
      "y_pred": 3,
      "val_labels": 3,
      "train_df['TARGET']": 2,
      "df_train_[target_name]": 2,
      "test_y": 2,
      "Y_val": 2,
      "oof_df['open_channels']": 2,
      "label": 2,
      "GBclf.predict(clfX_test)": 2,
      "current_y_val": 2,
      "Y_valid": 2,
      "true_labels": 2,
      "y[test]": 2,
      "y_Test": 2,
      "y_cv": 2,
      "validate_labels": 2,
      "y_train_temp": 2,
      "y_test_temp": 2,
      "(train.resp > 0).astype(int)": 2,
      "(val.resp > 0).astype(int)": 2,
      "Y[test]": 2,
      "true": 2,
      "tgts": 2,
      "set_validacion_ordenado.classes": 2,
      "y.iloc[val_idx].values": 2,
      "y_test2": 2,
      "y_test3": 2,
      "y_test4": 2,
      "oof_val_true": 2,
      "test_true": 2,
      "target[val_idx]": 2,
      "test_batches.labels": 2,
      "y_test9": 2,
      "list1": 2,
      "eval_table['true_target']": 1,
      "train_df['target']": 1,
      "y_": 1,
      "label_list": 1,
      "sub['prediction']": 1,
      "Y": 1,
      "np.argmax(validation_labels, axis=1)": 1,
      "LSTM_y_test": 1,
      "GRU_y_test": 1,
      "sepcnn_y_test": 1,
      "ysp_test": 1,
      "yhat": 1,
      "validation_labels": 1,
      "true_value": 1,
      "train2.loc[train_index]['target']": 1,
      "train2.loc[val_index]['target']": 1,
      "Y_test_old": 1,
      "test": 1,
      "pred_survived": 1,
      "y_vldt": 1,
      "gold": 1,
      "train_y": 1,
      "true_class": 1,
      "timagey_test.values": 1,
      "pre": 1,
      "y_dev": 1,
      "y_te": 1,
      "pred": 1,
      "train_df_all.outliers": 1,
      "rm_correct_labels": 1,
      "cm_correct_labels_n": 1,
      "test_target": 1,
      "y_batch": 1,
      "ypred_Logreg": 1,
      "ypred_rfc": 1,
      "ypred_naive": 1,
      "y_test_dt1": 1,
      "y_test_dt2": 1,
      "y_test_xg1": 1,
      "y_test_xg2": 1,
      "train_df2.iloc[val_idx]['target'].values": 1,
      "y_test_": 1,
      "y_train_0": 1,
      "sample_y_val": 1,
      "~true": 1,
      "y_train_pred_final.Survived": 1,
      "sub_preds": 1,
      "y_test10": 1,
      "y_test1": 1,
      "y_test5": 1,
      "y_test6": 1,
      "y_test7": 1,
      "y_test8": 1,
      "mnist_labels": 1,
      "y_cv_test_binary": 1,
      "test_gen.classes": 1,
      "results['y_val']": 1,
      "lb": 1,
      "cm_labels": 1,
      "y_is9_validation": 1,
      "y.iloc[test_idx_3]": 1,
      "Y_validation": 1
    },
    "sklearn.metrics._classification.precision_score.y_pred": {
      "cm_predictions": 220,
      "y_pred": 173,
      "predictions": 59,
      "pred": 33,
      "y_pred_class": 23,
      "y_pred_train": 22,
      "y_pred_test": 17,
      "y_test": 17,
      "predicted": 13,
      "LR_cnt_pred_tr": 13,
      "val_predictions": 12,
      "preds": 12,
      "y_pred_val": 12,
      "y_pred6": 12,
      "train_predictions": 11,
      "prediction": 11,
      "val_predict": 11,
      "y_pred_cat": 9,
      "y_preds": 9,
      "Y_pred_rand": 9,
      "LR_cnt_pred_val": 7,
      "y_predicted": 6,
      "SVM_cnt_pred_tr": 6,
      "NB_cnt_pred_tr": 6,
      "LR_tfidf_pred_tr": 6,
      "SVM_tfidf_pred_tr": 6,
      "NB_tfidf_pred_tr": 6,
      "ypred_class": 5,
      "best_preds": 5,
      "y_train_pred": 5,
      "predictcombine": 5,
      "y_val": 5,
      "oof[valid_idx].round()": 5,
      "train_pred": 4,
      "pred1": 4,
      "predict_val": 4,
      "valid_pred": 4,
      "LR_cnt_pred_tst": 4,
      "preds_train": 4,
      "preds_valid": 4,
      "label_pre": 4,
      "label_pre >= thresh": 4,
      "predict_labels": 4,
      "predictions_l": 4,
      "rf_pred": 4,
      "predIdxs_VGG": 4,
      "yhat_test": 4,
      "y_predi": 4,
      "test_pred": 3,
      "y_train_pred_rf": 3,
      "y_pred_test_rf": 3,
      "y_pred_test_rf_val": 3,
      "pred3": 3,
      "pred4": 3,
      "predicted_labels": 3,
      "result": 3,
      "Y_pred": 3,
      "y_valid": 3,
      "y_pred_lstm": 3,
      "pred_mode": 3,
      "valid_preds": 3,
      "y_test_preds": 3,
      "predictions_DCmodel_1": 2,
      "predictions_DCmodel_2": 2,
      "predictions_DCmodel_3": 2,
      "predictions_LSTM_model_1": 2,
      "predictions_LSTM_model_2": 2,
      "predictions_LSTM_model_3": 2,
      "(pred_noemb_val_y_gru > thresh).astype(int)": 2,
      "(pred_noemb_val_y_lstm > thresh).astype(int)": 2,
      "(pred_glove_val_y_gru > thresh).astype(int)": 2,
      "(pred_glove_val_y_lstm > thresh).astype(int)": 2,
      "(pred_fasttext_val_y_gru > thresh).astype(int)": 2,
      "(pred_fasttext_val_y_lstm > thresh).astype(int)": 2,
      "(pred_paragram_val_y_gru > thresh).astype(int)": 2,
      "(pred_paragram_val_y_lstm > thresh).astype(int)": 2,
      "(pred_val_y_gru > thresh).astype(int)": 2,
      "(pred_val_y_lstm > thresh).astype(int)": 2,
      "predictions_2": 2,
      "y_pred1": 2,
      "y_pred_xgb": 2,
      "y_pred_valid": 2,
      "SVM_cnt_pred_tr_lin": 2,
      "SVM_cnt_pred_val_lin": 2,
      "pred5": 2,
      "test_predictions": 2,
      "oof_df['oof']": 2,
      "predict": 2,
      "tes": 2,
      "clfY_test.values": 2,
      "np.round(oofmain)": 2,
      "np.round(oofsingle)": 2,
      "current_predictions": 2,
      "yhat": 2,
      "(y_val_pred > f1_threshold).astype(int)": 2,
      "vc.predict(ttextdataemx_test)": 2,
      "clf.predict(testfeature)": 2,
      "vc.predict(testfeature)": 2,
      "vc.predict(tsiftdatax_test)": 2,
      "y_pred_round": 2,
      "validate_pre_label": 2,
      "Y_prediction_RF": 2,
      "label_predict": 2,
      "train_actions": 2,
      "val_actions": 2,
      "y_predict": 2,
      "y_pred_batch": 2,
      "predicciones_val": 2,
      "y_oof[val_idx].round()": 2,
      "roc_predictions": 2,
      "model.predict(X_test)": 2,
      "oof.round()": 2,
      "predictions.round()": 2,
      "y_pred_bidirectional_lstm": 2,
      "y_pred_cnn": 2,
      "y_pred_lstm_cnn": 2,
      "y_pred_bidirectional_lstm_cnn": 2,
      "oof[val_idx].round()": 2,
      "pred_label": 2,
      "y_pred9": 2,
      "m.predict(xs)": 2,
      "y_pred_rfc": 2,
      "y_pred_tree": 2,
      "eval_table['pred_target']": 1,
      "train_df['predictions']": 1,
      "y_pred_NN": 1,
      "pred_list": 1,
      "SVM_tst": 1,
      "y_pred_changed": 1,
      "np.argmax(validation_outputs, axis=1)": 1,
      "train_pr": 1,
      "valid_pr": 1,
      "SVM_cnt_pred_tr_rbf": 1,
      "SVM_cnt_pred_val_rbf": 1,
      "np.round(oof_preds[val_idx])": 1,
      "np.round(oof_preds)": 1,
      "y_pred_rf": 1,
      "LSTM_yhat_test": 1,
      "GRU_yhat_test": 1,
      "RandomForestClassifier_yhat_test": 1,
      "SGDClassifier_yhat_test": 1,
      "MultinomialNB_yhat_test": 1,
      "sepcnn_yhat_test": 1,
      "ysp_pred": 1,
      "ypred": 1,
      "pred[:, 1] > thresh": 1,
      "ys": 1,
      "y_valid_pred": 1,
      "pred_bool": 1,
      "rf_predict_resampled": 1,
      "predict_nb": 1,
      "predict_dtc": 1,
      "predict_svm": 1,
      "predict_nn_plp": 1,
      "data_submittion": 1,
      "y_int_max": 1,
      "y": 1,
      "pred_76": 1,
      "pred_86": 1,
      "pred_56": 1,
      "pred_46": 1,
      "y_pred_train_hyper": 1,
      "y_pred_hyper": 1,
      "logiPred": 1,
      "knnPrediction": 1,
      "DTCPreds": 1,
      "RMPreds": 1,
      "y_preds_rand": 1,
      "y_val_pred": 1,
      "eval_pred_class": 1,
      "svc.predict(ttextdataemx_test)": 1,
      "clf.predict(ttextdataemx_test)": 1,
      "dt.predict(ttextdataemx_test)": 1,
      "rf.predict(ttextdataemx_test)": 1,
      "ab.predict(ttextdataemx_test)": 1,
      "est.predict(ttextdataemx_test)": 1,
      "svc.predict(testfeature)": 1,
      "dt.predict(testfeature)": 1,
      "rf.predict(testfeature)": 1,
      "ab.predict(testfeature)": 1,
      "est.predict(testfeature)": 1,
      "clf.predict(timagearrayx_test)": 1,
      "svc.predict(tsiftdatax_test)": 1,
      "clf.predict(tsiftdatax_test)": 1,
      "dt.predict(tsiftdatax_test)": 1,
      "rf.predict(tsiftdatax_test)": 1,
      "ab.predict(tsiftdatax_test)": 1,
      "est.predict(tsiftdatax_test)": 1,
      "tphasharrayy_test.values": 1,
      "clf2.predict(tsiftdatax_test)": 1,
      "Y_pred_grid": 1,
      "predicts": 1,
      "p": 1,
      "pred_val": 1,
      "train_predict": 1,
      "scores": 1,
      "y_test_split": 1,
      "train_df_all.predict_outliers": 1,
      "rm_predictions": 1,
      "y_predic": 1,
      "lr_pred": 1,
      "svc_pred": 1,
      "lstm_pred": 1,
      "y_pred_RF": 1,
      "ypred_RN": 1,
      "cm_predictions_n": 1,
      "predict_y_gbm": 1,
      "yhat_classes": 1,
      "y_test_pred": 1,
      "pred_y": 1,
      "y_pred_bow": 1,
      "y_pred_bow2": 1,
      "y_pred_tfidf": 1,
      "y_pred_tfidf4": 1,
      "y_pred_stem_dt": 1,
      "y_pred_lemma_dt": 1,
      "pred_stem_xg": 1,
      "pred_lemma_xg": 1,
      "torch.round(val_preds.cpu())": 1,
      "val_preds": 1,
      "y_pred_": 1,
      "sample_y_pred": 1,
      "~pred": 1,
      "val_y_pred": 1,
      "y_train_pred_final.predicted": 1,
      "rf_pred_test": 1,
      "rf_pred_train_2": 1,
      "rf_pred_test_2": 1,
      "rf_pred_train_3": 1,
      "rf_pred_test_3": 1,
      "rf_pred_train_4": 1,
      "rf_pred_test_4": 1,
      "rf_pred_train_5": 1,
      "rf_pred_test_5": 1,
      "rf_pred_train_6": 1,
      "rf_pred_test_6": 1,
      "rf_pred_train_7": 1,
      "rf_pred_test_7": 1,
      "rf_pred_train_8": 1,
      "rf_pred_test_8": 1,
      "rf_pred_train_9": 1,
      "rf_pred_test_9": 1,
      "predictions_tuned_linear_svc": 1,
      "predictions_tuned_logistic_regression": 1,
      "predictions_tuned_extra_trees": 1,
      "predictions_tuned_random_forest": 1,
      "pred_tuned_mode": 1,
      "y_test_pred_sgd": 1,
      "NB_pred": 1,
      "SDG_pred": 1,
      "pred21": 1,
      "pred22": 1,
      "cm_pre": 1,
      "y_pred10": 1,
      "y_pred2": 1,
      "y_pred3": 1,
      "y_pred4": 1,
      "y_pred5": 1,
      "y_pred7": 1,
      "y_pred8": 1,
      "mnist_label_preds": 1,
      "identity_predicted": 1,
      "a": 1,
      "results['y_hat']": 1,
      "y_pred.round()": 1,
      "op": 1,
      "yt_pred": 1,
      "train_prediction": 1,
      "val_prediction": 1,
      "pred_tr1": 1,
      "pred2": 1,
      "pred_tr2": 1,
      "pred_tr3": 1,
      "pred_tr4": 1,
      "y_pred_90": 1,
      "cm_preds": 1,
      "y_true_tag": 1,
      "y_predictions": 1,
      "val_predictions_flat": 1,
      "np.round(predictions_all[str(weight)])": 1,
      "pred_logit": 1
    },
    "sklearn.svm._classes.LinearSVC.__init__.C": {
      "1.0": 382,
      "0.1": 10,
      "0.5": 7,
      "0.01": 7,
      "1": 7,
      "10": 5,
      "c": 3,
      "4": 3,
      "2.0": 2,
      "C_VAL": 2,
      "0.8": 2,
      "0.4": 2,
      "0.001": 2,
      "trial.suggest_float('C', 1e-10, 10000000000.0, log=True)": 1,
      "5": 1,
      "0.2": 1,
      "0.499": 1,
      "100": 1,
      "f": 1,
      "0.25": 1,
      "0.75": 1,
      "10.0": 1,
      "5.0": 1,
      "0.9": 1,
      "self.C": 1,
      "C": 1,
      "100.0": 1,
      "C_svm": 1,
      "res.x[0]": 1,
      "0.3999": 1,
      "5e-05": 1,
      "0.3": 1
    },
    "sklearn.svm._classes.LinearSVC.__init__.max_iter": {
      "1000": 388,
      "10000": 26,
      "2000": 11,
      "3000": 7,
      "100000": 5,
      "5000": 4,
      "500": 2,
      "5": 2,
      "100": 2,
      "1500": 2,
      "trial.suggest_int('max_iter', 1000, 3000, 50)": 1,
      "200": 1,
      "350": 1,
      "30000": 1
    },
    "sklearn.svm._classes.LinearSVC.__init__.tol": {
      "0.0001": 426,
      "1e-05": 13,
      "0.001": 10,
      "0.01": 2,
      "trial.suggest_float('tol', 1e-05, 0.1, log=True)": 1,
      "0.5": 1
    },
    "sklearn.svm._classes.LinearSVC.__init__.loss": {
      "'squared_hinge'": 438,
      "'hinge'": 13,
      "loss_svm": 1,
      "res.x[2]": 1
    },
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.sublinear_tf": {
      "False": 2238,
      "True": 626,
      "1": 350,
      "self.sublinear_tf": 1
    },
    "sklearn.model_selection._search.GridSearchCV.__init__.verbose": {
      "0": 1807,
      "1": 432,
      "2": 161,
      "True": 102,
      "10": 77,
      "3": 76,
      "5": 27,
      "7": 19,
      "4": 15,
      "False": 11,
      "20": 5,
      "50": 4,
      "verbose": 4,
      "-1": 2,
      "1000": 2,
      "100": 2,
      "15": 2,
      "25": 1,
      "6": 1,
      "42": 1,
      "150": 1
    },
    "sklearn.preprocessing._data.StandardScaler.fit.y": {
      "None": 1832,
      "y": 2,
      "data_target": 1,
      "s_labels": 1,
      "y_train": 1
    },
    "sklearn.svm._classes.SVC.__init__.kernel": {
      "'rbf'": 1304,
      "'linear'": 217,
      "'poly'": 108,
      "'sigmoid'": 12,
      "kernal": 9,
      "kernel": 7,
      "Best_Parameter['kernel']": 4,
      "k": 4,
      "trial.suggest_categorical('kernel', ['rbf'])": 2,
      "params['kernel']": 1,
      "kernelSVM[iii]": 1,
      "kernelSVM": 1,
      "kern": 1,
      "svm_study.best_params['kernel']": 1,
      "clf.best_params_['kernel']": 1,
      "trial.suggest_categorical('kernel', ['linear', 'rbf'])": 1,
      "svm_kernel": 1
    },
    "sklearn.model_selection._split.TimeSeriesSplit.__init__.n_splits": {
      "5": 47,
      "n_fold": 13,
      "2": 10,
      "10": 8,
      "FOLDS": 8,
      "self.n_splits": 7,
      "N_SPLITS": 5,
      "n_splits": 4,
      "3": 4,
      "8": 3,
      "splits": 2,
      "6": 2,
      "len(X) - 1": 2,
      "N_FOLDS": 2,
      "n_iter": 1,
      "split_num": 1,
      "NFOLDS": 1,
      "nr_folds": 1,
      "EPOCHS": 1,
      "SPLITS": 1,
      "CFG.nfolds": 1,
      "56": 1,
      "4": 1,
      "n_folds": 1
    },
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.n_estimators": {
      "100": 531,
      "3000": 71,
      "500": 47,
      "1000": 40,
      "4000": 34,
      "200": 33,
      "300": 23,
      "50": 17,
      "n_estimators": 16,
      "120": 15,
      "2000": 13,
      "10": 9,
      "250": 7,
      "400": 7,
      "n_trees": 7,
      "6000": 6,
      "110": 6,
      "600": 6,
      "1500": 5,
      "5000": 5,
      "10000": 5,
      "700": 5,
      "800": 5,
      "150": 5,
      "1120": 4,
      "3275": 4,
      "5": 3,
      "140": 3,
      "1992": 3,
      "3500": 3,
      "20": 2,
      "650": 2,
      "111": 2,
      "165": 1,
      "70": 1,
      "450": 1,
      "125": 1,
      "trial.suggest_categorical('n_estimators', [100])": 1,
      "study.best_trial.params['n_estimators']": 1,
      "30": 1,
      "num_trees": 1,
      "i": 1,
      "estimators": 1,
      "_n_estimators": 1,
      "1808": 1,
      "130": 1,
      "25": 1,
      "j": 1,
      "1250": 1,
      "94": 1,
      "35": 1,
      "75": 1,
      "342": 1,
      "308": 1,
      "159": 1,
      "38 * 8": 1,
      "141": 1,
      "trial.suggest_int('n_estimators', 1, 300)": 1,
      "gs.best_params_['n_estimators']": 1,
      "1070": 1,
      "40": 1,
      "255": 1,
      "4556": 1,
      "25000": 1,
      "2501": 1,
      "1200": 1,
      "900": 1,
      "tree": 1,
      "166": 1,
      "330": 1,
      "estimator": 1,
      "225": 1,
      "360": 1,
      "72": 1,
      "71": 1,
      "133": 1,
      "2200": 1,
      "8000": 1
    },
    "sklearn.preprocessing._label.LabelEncoder.inverse_transform.y": {
      "np.argsort(y_pred[i])[::-1]": 70,
      "np.argsort(y_pred, axis=1)[:, ::-1][:, :3]": 53,
      "y_test": 35,
      "pred.argsort()[-5:][::-1]": 30,
      "y_pred": 26,
      "np.linspace(0, 38, 39, dtype='int16')": 21,
      "all_data['Country_Region']": 20,
      "all_data['Province_State']": 20,
      "predictions": 13,
      "e.argsort()[-5:][::-1]": 13,
      "pred": 12,
      "sub_preds_rf.argmax(axis=1)": 11,
      "predicted.argmax(axis=1)": 11,
      "ytest": 11,
      "[argmax(each)]": 10,
      "y_train": 9,
      "pred_test": 8,
      "prediction": 8,
      "[argmax(each2)]": 8,
      "X['type']": 8,
      "classifier.predict(x_test)": 7,
      "predictions.argmax(axis=1)": 7,
      "[argmax(each3)]": 6,
      "classifier.predict(x_train)": 6,
      "Y_pred": 6,
      "test['Id'].values": 6,
      "model.classes_": 6,
      "prediction_lgb.argmax(1)": 5,
      "[np.argmax(e)]": 5,
      "lbl": 5,
      "self.ohe.inverse_tranform(x)": 5,
      "x": 5,
      "[i]": 5,
      "test['predictions']": 4,
      "y": 4,
      "[argmax(each4)]": 4,
      "preds": 4,
      "[action]": 4,
      "torch.argmax(pred.cpu(), dim=1)": 4,
      "y_score2": 4,
      "y_pred_test": 4,
      "[np.argmax(each[j])]": 4,
      "sub_preds": 4,
      "a": 3,
      "np.argmax(preds, axis=1)": 3,
      "prediction_svc.argmax(1)": 3,
      "y_val_s": 3,
      "df['Country']": 3,
      "df['State']": 3,
      "pred_template['PatientID']": 3,
      "out_df.columns": 3,
      "ind": 3,
      "predicted_labels": 3,
      "y_submission": 3,
      "test_top3": 3,
      "y_predict": 3,
      "predicted": 3,
      "data['Country/Region']": 3,
      "labels": 3,
      "Ans": 2,
      "submission1.surface": 2,
      "test_pred.columns": 2,
      "results": 2,
      "ytest2": 2,
      "prediction_class": 2,
      "encoded": 2,
      "np.argmax(categories[-1])": 2,
      "[argmax(each5)]": 2,
      "np.array([j])": 2,
      "(prediction_lgb + prediction_svc).argmax(1)": 2,
      "pred_test_kfold": 2,
      "y_predicted": 2,
      "preds_encoded": 2,
      "RandomForestClassifier_labels": 2,
      "MultinomialNB_labels": 2,
      "SGDClassifier_labels": 2,
      "[np.argmax(lstm_labels)]": 2,
      "[np.argmax(gru_labels)]": 2,
      "[np.argmax(sepcnn_labels)]": 2,
      "y_true": 2,
      "[current_action]": 2,
      "test_pred": 2,
      "test_Y": 2,
      "[np.argmax(pred) for pred in predictions_encoded]": 2,
      "integer_encoded2": 2,
      "prediction_lg": 2,
      "predictions_nb": 2,
      "predictedLabel": 2,
      "y_test_pred": 2,
      "all_data['Country/Region']": 2,
      "all_data['Province/State']": 2,
      "np.where(y == 1)[1][idx]": 2,
      "[19, 37]": 2,
      "pred_y": 2,
      "[1]": 2,
      "res_test": 2,
      "maj": 2,
      "Y_test": 2,
      "uniques[y_test.argmax(1)]": 2,
      "predicted_classes": 2,
      "correct_labels": 2,
      "z1": 2,
      "[preds[idx]]": 2,
      "p": 2,
      "y_preds": 2,
      "predictions.astype('int64')": 2,
      "[0, 1, 2, 3]": 2,
      "ovr_pred": 2,
      "predictOutput": 2,
      "mnb_test_pred_value": 1,
      "np.array(test_scores.sum(axis=1).argmax(axis=1), dtype=np.int8)": 1,
      "y_value": 1,
      "test_predictions": 1,
      "predicted_args": 1,
      "df['Country_Region']": 1,
      "df['Province_State']": 1,
      "mlp_pred": 1,
      "np.argmax(category)": 1,
      "Y_pred_classes": 1,
      "total_data['Country_Code']": 1,
      "all_tdata['country']": 1,
      "all_tdata['state']": 1,
      "y_test_submission": 1,
      "y_labels": 1,
      "df_pred['surface_code']": 1,
      "X_short['type']": 1,
      "Vclf1.fit(X, Y_train).predict(Xt)": 1,
      "Vclf.fit(X, Y_train).predict(Xt)": 1,
      "pred_gcv": 1,
      "pred_test_kfold[0:3810]": 1,
      "result.argsort()[-5:][::-1]": 1,
      "submission_predictions.argmax(axis=1)": 1,
      "predict": 1,
      "predictions.round().astype(np.int32)": 1,
      "y_pred_final": 1,
      "[np.argmax(sepcnn_yhat_test)]": 1,
      "y_out": 1,
      "(prediction_lgb + prediction_svc + prediction_rf).argmax(1)": 1,
      "np.argsort(prob)[::-1][:5]": 1,
      "pred[i]": 1,
      "X.loc[X['type'] == t]['type']": 1,
      "type_": 1,
      "clf.predict(test_attrs)": 1,
      "range(39)": 1,
      "predict_test": 1,
      "np.arange(39)": 1,
      "y_true_pred_le": 1,
      "[1, 2]": 1,
      "[argmax(onehot_encoded[0, :])]": 1,
      "df_pred['Ensemble_Result']": 1,
      "y_mnbpreds": 1,
      "y_predsvctf": 1,
      "[0, 1, 2]": 1,
      "pred_subm": 1,
      "device_id": 1,
      "misclassified_samples1": 1,
      "misclassified_samples2": 1,
      "pred_template_train['PatientID']": 1,
      "pred_template_test['PatientID']": 1,
      "res_svc": 1,
      "res_rf": 1,
      "res_lgb": 1,
      "model.predict_classes(X_pred)": 1,
      "np.argmax(model.predict(x).flatten(), axis=1)": 1,
      "[1, 1, 1, 0, 0, 1]": 1,
      "new_y": 1,
      "X": 1,
      "np.argmax(predictions, axis=1)": 1,
      "list(range(0, 9))": 1,
      "kmeans_pred": 1,
      "np.argsort(prediction_proba[2])[::-1][:5]": 1,
      "[li[0][1], li[1][1], li[2][1], li[3][1]]": 1,
      "dataset_resource": 1,
      "sub_preds_lgb.argmax(axis=1)": 1,
      "np.argmax((model1.predict(ingredients) + model2.predict(ingredients)) / 2)": 1,
      "top_k_preds(preds, 3)": 1,
      "[temp_label]": 1,
      "range(num_values)": 1,
      "ensemble_pred": 1,
      "prediction.argsort()[-5:][::-1]": 1,
      "pre": 1,
      "data_2.ID": 1,
      "test_df_pred['air_store_id']": 1,
      "y_test_pred_final": 1,
      "np.argmax(model.predict(x), axis=1)": 1,
      "df.label": 1,
      "y_pred.astype(int)": 1,
      "nb.predict(X_test)": 1,
      "y_sub": 1,
      "le.transform(df_annotations.label)": 1,
      "np.argmax(model.predict(x[None])[0])": 1,
      "clf_pred": 1,
      "raw_results.transpose().astype(int)": 1,
      "encoded_Y": 1,
      "full_train_df.groupby(['primary_use']).size().reset_index(name='counts')['primary_use']": 1,
      "np.argsort(predict[i])[::-1]": 1,
      "pred_class": 1,
      "enc.inverse_transform(our_predictions)": 1,
      "svm_pred": 1,
      "testMasterDf['Predictions']": 1,
      "[real_classes[i]]": 1,
      "pets2.PetID": 1,
      "np.argsort(ypred[i])[::-1]": 1,
      "list(map(np.argmax, predicted_test))": 1,
      "[np.argmax(each[0])]": 1,
      "y_test_count": 1,
      "np.argsort(x_pred[i])[::-1]": 1,
      "prediction.argsort()[-1:][::-1]": 1,
      "submission.country": 1,
      "[int(col) for col in predictions.columns]": 1,
      "predicted_classes2": 1,
      "knn.predict(x_test)": 1,
      "indices": 1,
      "Class_Acc.argsort()[0]": 1,
      "indicesC": 1,
      "Country_Acc.argsort()[1]": 1,
      "predictions_arr": 1,
      "range(pred.shape[1])": 1,
      "predictions_svm": 1,
      "[preds[i]]": 1,
      "guesses": 1,
      "prediction_": 1,
      "[meta_data[0]]": 1,
      "[metas_data[0]]": 1,
      "grid.predict(test['ingredients'])": 1,
      "svc_preds": 1,
      "rf_preds": 1,
      "np.array([np.argmax(preds[i]) for i in range(len(preds))])": 1,
      "[np.argmax(pred) for pred in y_test]": 1,
      "predicted_country": 1,
      "np.argsort(predictions[i])[::-1]": 1,
      "class_prediction": 1,
      "y_train[idx].argmax()": 1,
      "testX['Province_State']": 1,
      "range(20)": 1,
      "submission_df['air_store_id']": 1,
      "submission_df['visit_date']": 1,
      "forcast_rfc.argmax(axis=1)": 1,
      "y_test3": 1,
      "[y]": 1,
      "saved_idx": 1,
      "Y_test_sub": 1,
      "prediction.argmax(axis=1)": 1,
      "submission_final['surface']": 1,
      "train_set[feat]": 1,
      "predict.columns": 1,
      "pred_e.argmax(axis=1)": 1,
      "np.argsort(g111[i])[::-1]": 1,
      "test": 1,
      "model.predict(x_tst)": 1,
      "pre_label": 1,
      "predictlabel": 1,
      "[pred_digits[prop_class[count]]]": 1,
      "np.argmax([y_test[prop_class[count]]])": 1,
      "[pred_digits[mis_class[count]]]": 1,
      "np.argmax([y_test[mis_class[count]]])": 1,
      "[pred_pet[prop_class[count]]]": 1,
      "[np.argmax([y_test[prop_class[count]]])]": 1,
      "[pred_pet[mis_class[count]]]": 1,
      "[np.argmax([y_test[mis_class[count]]])]": 1,
      "np.where(d > g.th)[0]": 1,
      "df.loc[:, 'Country']": 1,
      "df.loc[:, 'State']": 1,
      "final_pred": 1,
      "classifier.predict(x_val)": 1,
      "y_val": 1,
      "clf1_cv.predict(X_train)": 1,
      "OvRSVC.predict(X_train)": 1,
      "predicted_result": 1,
      "np.argsort(y_pred1[i])[::-1]": 1,
      "np.argsort(y_pred2[i])[::-1]": 1,
      "np.argsort(y_pred3[i])[::-1]": 1,
      "np.argsort(avgProb[i])[::-1]": 1,
      "submission_pred": 1,
      "[0]": 1,
      "[2]": 1,
      "y_pred.all()": 1,
      "submission['type']": 1,
      "top_n": 1,
      "t['Date']": 1,
      "breed_index": 1,
      "model.predict(test_features)": 1,
      "model.predict(test_df.values).reshape(-1).astype(int)": 1,
      "pred_rf.argmax(1)": 1,
      "logreg_pred.argmax(1)": 1,
      "predictions.astype(int)": 1,
      "[images[i][1]]": 1,
      "_y_prediction": 1,
      "new_target['surface']": 1,
      "[label]": 1,
      "np.argsort(Y_combined_pred, axis=1)[:, ::-1][:, :3]": 1,
      "np.argsort(Y_combined_test, axis=1)[:, ::-1][:, :3]": 1,
      "Y_val": 1,
      "range(num_classes)": 1,
      "sub.Id": 1,
      "preds.argmax(axis=1)": 1,
      "np.argsort(result[i])[::-1]": 1,
      "np.argmax(y_predict, axis=1)": 1,
      "np.argmax(y_predict_sub, axis=1)": 1,
      "np.argsort(y_pred, axis=1)[:, ::-1][:, :10]": 1,
      "np.argmax(p_test, axis=1)": 1,
      "prediction_deep": 1,
      "range(len(self.classes))": 1,
      "df_predict['item_id']": 1,
      "y.astype(int)": 1,
      "test_df['cuisine']": 1,
      "test['Country/Region']": 1,
      "[cnt]": 1,
      "np.linspace(0, 38, 39, dtype='int')": 1,
      "y_test.reshape(-1, 1)": 1,
      "yPredicted": 1,
      "[np.argmax(i) for i in y_pred]": 1,
      "np.argsort(XGBC_pred_test_prob[i])[::-1][:5]": 1,
      "X_xTrain_CS2['Country']": 1,
      "X_xTrain_CS2['State']": 1,
      "cls": 1,
      "svc_pred": 1,
      "clf.classes_": 1,
      "y_pred[i].argsort()[::-1][:5]": 1,
      "[0, 1, 2, 3, 4, 5, 6, 7, 8]": 1,
      "i": 1,
      "predicted_class": 1,
      "args5": 1,
      "predictedEncoded": 1,
      "list(map(lambda x: x['class_ids'][0], predictions_raw))": 1,
      "np.arange(0, 5)": 1
    },
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.binary": {
      "False": 3060,
      "True": 152,
      "binary": 2,
      "cfg['text']['binary']": 1
    },
    "sklearn.feature_extraction.text.CountVectorizer.__init__.tokenizer": {
      "None": 2769,
      "tokenize": 55,
      "lambda x: x.split()": 18,
      "lambda x: [i.strip() for i in x.split(',')]": 10,
      "lambda x: x.split(' ')": 9,
      "spacy_tokenizer": 7,
      "token.tokenize": 6,
      "tokenizer": 6,
      "word_tokenize": 5,
      "LemmaTokenizer()": 5,
      "my_tokenizer": 5,
      "lambda x: x.split(', ')": 4,
      "lambda x: str(x).split()": 4,
      "lambda x: x.split('|')": 4,
      "lambda x: x": 3,
      "lambda x: [a.strip() for a in x.split(',')]": 2,
      "tokenizer.tokenize": 2,
      "nltk.word_tokenize": 2,
      "tweet_token_proces": 2,
      "lambda x: regex.findall('[^\\\\p{P}\\\\W]+', x)": 2,
      "TweetTokenizer().tokenize": 2,
      "token_r": 1,
      "wp_tokenizer.tokenize": 1,
      "tokenize_text": 1,
      "lambda text: text.split(' ')": 1,
      "lambda text: text.split()": 1,
      "lambda doc: [word.strip() for word in doc.split(',')]": 1,
      "tokenizer_ngrams": 1,
      "lemmatize": 1,
      "tokenizeText": 1,
      "tokenize_category_name": 1,
      "tokenize_brand_name": 1,
      "preproc": 1,
      "tokenize_def": 1,
      "my_tweet_tokenizer": 1,
      "pattern.tokenize": 1
    },
    "sklearn.feature_extraction.text.CountVectorizer.__init__.preprocessor": {
      "None": 2847,
      "get_col('title')": 17,
      "clean_text": 8,
      "get_col('text_feat')": 7,
      "build_preprocessor('brand_name')": 4,
      "build_preprocessor('shipping')": 4,
      "build_preprocessor('item_condition_id')": 4,
      "build_preprocessor('name', arr)": 3,
      "build_preprocessor('name')": 3,
      "build_preprocessor('category_name')": 3,
      "clean": 2,
      "build_preprocessor('category_name', arr)": 2,
      "build_preprocessor('shipping', arr)": 2,
      "build_preprocessor('item_condition_id', arr)": 2,
      "preprocessor('name')": 2,
      "preprocessor('general_cat')": 2,
      "preprocessor('subcat_1')": 2,
      "preprocessor('subcat_2')": 2,
      "preprocessor('brand_name')": 2,
      "preprocessor('shipping')": 2,
      "preprocessor('item_condition_id')": 2,
      "preprocessor": 2,
      "lambda x: x['project_title']": 1,
      "preprocess_sentence": 1,
      "my_preprocessor": 1,
      "prep_func": 1,
      "preprocess": 1,
      "preprocess_ngrams": 1,
      "build_preprocessor('subcat_0')": 1,
      "build_preprocessor('subcat_1')": 1,
      "build_preprocessor('subcat_2')": 1,
      "build_preprocessor('desc_len')": 1,
      "build_preprocessor('name_len')": 1,
      "get_col('project_title_count')": 1,
      "cleanText": 1
    },
    "sklearn.feature_extraction.text.CountVectorizer.__init__.max_features": {
      "None": 2287,
      "200": 161,
      "10000": 66,
      "5000": 60,
      "1000": 40,
      "150": 31,
      "2000": 28,
      "max_features": 20,
      "100000": 18,
      "3000": 15,
      "1500": 13,
      "50": 11,
      "50000": 11,
      "100": 10,
      "10": 9,
      "20000": 9,
      "maxNumFeatures": 9,
      "300": 8,
      "4": 7,
      "500": 7,
      "180000": 6,
      "40000": 6,
      "20": 6,
      "60000": 5,
      "200000": 4,
      "6000": 4,
      "int(len(brand_counts) * 0.5)": 4,
      "8000": 3,
      "10000 - 1": 3,
      "maxFeats": 3,
      "90000": 3,
      "n_words": 3,
      "2": 3,
      "int(len(cat_counts) * 0.5)": 3,
      "2500": 3,
      "4500": 2,
      "85": 2,
      "10000000": 2,
      "400": 2,
      "70": 2,
      "uniqueWordFrequents.shape[0]": 2,
      "4000": 2,
      "7000": 2,
      "5": 2,
      "409": 2,
      "250000": 2,
      "maxfeat": 2,
      "23000": 2,
      "14250": 1,
      "6877": 1,
      "6891": 1,
      "1500000": 1,
      "MAX_FEATURES_NM": 1,
      "MAX_DIMS": 1,
      "170": 1,
      "205": 1,
      "max_feat": 1,
      "DICT_SIZE": 1,
      "int(len(cat_counts) * 0.9)": 1,
      "15000": 1,
      "250": 1,
      "maxNumfeatures": 1,
      "256": 1,
      "MAX_NB_WORDS": 1,
      "max_words": 1,
      "n": 1,
      "12000": 1,
      "bag_size": 1,
      "MAX_FEATURES_NAME": 1,
      "30000": 1,
      "MAX_FEATURES": 1,
      "VOCAB_SIZE": 1,
      "130000": 1,
      "maxFeat": 1,
      "5500": 1,
      "vocab_size": 1,
      "175": 1,
      "no_features": 1,
      "resouse_tfidf_features": 1,
      "DESC_MAX_FEAT": 1
    },
    "sklearn.preprocessing._label.MultiLabelBinarizer.__init__.classes": {
      "None": 157,
      "classes": 7,
      "CFG.classes": 3,
      "list(LABEL_MAP.keys())": 3,
      "labels": 2,
      "np.array(list(labels_dict.keys()))": 1,
      "[n for n in range(19)]": 1,
      "mlb_df_columns": 1
    },
    "sklearn.preprocessing._label.MultiLabelBinarizer.fit_transform.y": {
      "s": 23,
      "df['labels'].values": 7,
      "df['split_tags']": 7,
      "labels": 6,
      "df['labels']": 5,
      "train['labels']": 4,
      "train_csv['Label']": 4,
      "resized_train['labels']": 3,
      "tmp_df['tags'].str.split()": 3,
      "splitted_labels": 3,
      "train['ingredients']": 3,
      "all_labels_set": 3,
      "y": 2,
      "y_train": 2,
      "train_df['attribute_ids']": 2,
      "x": 2,
      "X['features']": 2,
      "batch_labels": 1,
      "df_all_tag_questions['replaced_tag_name']": 1,
      "train['labelId']": 1,
      "train['new_labels']": 1,
      "train_df_list": 1,
      "dataset['genres']": 1,
      "dataset['production_companies']": 1,
      "dataset['production_countries']": 1,
      "dataset['spoken_languages']": 1,
      "dataset['original_language']": 1,
      "dataset['producers']": 1,
      "dataset['executive_producers']": 1,
      "dataset['directors']": 1,
      "df[LABELS_COL_NAME]": 1,
      "df_questions.tags.apply(lambda l: [f'tag_{int(t):03d}' for t in l])": 1,
      "targets": 1,
      "df_train.cuisine.values.reshape(-1, 1)": 1,
      "df['labels'].str.split(',')": 1,
      "input_Data['genre_extract']": 1,
      "input_Data['language_extract']": 1,
      "input_Data['country_extract']": 1,
      "input_Data['prod_house_extract']": 1,
      "skill_series": 1,
      "train_data['multilabel']": 1,
      "df.pop('genres')": 1,
      "df.pop('production_companies')": 1,
      "df.pop('production_countries')": 1,
      "df.pop('spoken_languages')": 1,
      "df.pop('Keywords')": 1,
      "df_train['tags2']": 1,
      "cuisine_vector": 1,
      "df['genres']": 1,
      "tdata['labels']": 1,
      "test_data['labels']": 1,
      "split_labels": 1,
      "df_train['category_list'].fillna('nan')": 1,
      "df_train['labels'].values": 1,
      "train_df.attribute_ids": 1,
      "s.values[:, None]": 1,
      "df['ingredients']": 1,
      "cleaned_traindf.labels": 1,
      "all_img_labels['Target']": 1,
      "[i.split(',') for i in list(train_df['labels'])]": 1,
      "alphabet": 1,
      "train_df.ingredients": 1,
      "questions.tags.str.split(' ')": 1,
      "f": 1,
      "tags": 1,
      "data['car_features']": 1,
      "train_labels_modified.Target": 1,
      "train.Label": 1,
      "dfx.Label": 1,
      "test['ingredients']": 1,
      "[str(df.loc[i, 'Label']).split('|') for i in range(len(df))]": 1,
      "Y_train": 1,
      "all_labels": 1,
      "data.pop('project_subject_categories_split')": 1,
      "data.pop('project_subject_subcategories_split')": 1,
      "_labels": 1,
      "indexed_sentences": 1,
      "train[labels]": 1
    },
    "sklearn.model_selection._search.GridSearchCV.__init__.cv": {
      "5": 852,
      "None": 534,
      "3": 332,
      "10": 257,
      "2": 110,
      "kfold": 98,
      "cv": 92,
      "4": 84,
      "folds": 57,
      "20": 20,
      "skf": 18,
      "nfolds": 16,
      "crossvalidation": 15,
      "[(X[mask_train].index, X[mask_test].index)]": 14,
      "7": 12,
      "n_folds": 11,
      "tscv": 10,
      "kfolds": 10,
      "cv_sets": 10,
      "StratifiedKFold(5)": 9,
      "kf": 8,
      "skfold.split(bike_train, year_month)": 8,
      "RepeatedKFold(n_splits=10, n_repeats=2, random_state=42)": 7,
      "cv_method": 7,
      "outer_cv": 7,
      "6": 6,
      "cv_split": 6,
      "15": 6,
      "StratifiedKFold(n_splits=10)": 5,
      "9": 5,
      "shuffle_split": 5,
      "100": 4,
      "fold": 4,
      "CV_FOLDS": 4,
      "nr_cv": 4,
      "StratifiedKFold(n_splits=5).split(train_X, train_y)": 4,
      "cv_splitter": 4,
      "StratifiedKFold(n_splits=5)": 3,
      "cross_validation": 3,
      "cv2": 3,
      "btscv": 3,
      "cv_folds": 3,
      "rskfold": 2,
      "cv1": 2,
      "PredefinedSplit(validation_split)": 2,
      "customKFoldAvoidLeakToValidation": 2,
      "folds_cv": 2,
      "ShuffleSplit(test_size=0.1, n_splits=1, random_state=0)": 2,
      "8": 2,
      "sss": 2,
      "LeaveOneOut()": 2,
      "1": 2,
      "k_fold": 2,
      "repfold": 2,
      "StratifiedKFold(n_splits=2)": 2,
      "12": 2,
      "StratifiedKFold(n_splits=5, shuffle=True)": 2,
      "KFold": 2,
      "sk_fold": 1,
      "Lcv": 1,
      "time_splits": 1,
      "str_cv": 1,
      "RepeatedKFold(n_splits=8, n_repeats=1, random_state=42)": 1,
      "gkf": 1,
      "StratifiedKFold(4)": 1,
      "cv_param": 1,
      "CROSS_VALIDATION": 1,
      "inner_cv": 1,
      "self.folds": 1,
      "GroupKFold(3).split(dfx_train, dfy_train, groups=id_groups)": 1,
      "grid_search_cv": 1,
      "skf.split(train, target)": 1,
      "skf.split(train3, train2['target'])": 1,
      "StratifiedKFold(n_splits=5, shuffle=True, random_state=25)": 1,
      "num_folds": 1,
      "shuffle": 1,
      "skf.split(x, y)": 1,
      "StratifiedKFold(n_splits=5).get_n_splits([X_train, y_train])": 1,
      "KFold(n_splits=5)": 1,
      "kfold_off": 1,
      "mskf": 1,
      "TimeSplitter()": 1,
      "KFold(n_splits=5, shuffle=True)": 1,
      "num_cv": 1,
      "CV_splitter": 1,
      "skf.split(X, y)": 1,
      "k": 1,
      "my_cv": 1,
      "RF_cv": 1,
      "50": 1,
      "StratifiedKFold(n_splits=5).split(X_train, y_train)": 1,
      "KFold(n_splits=7, shuffle=False)": 1,
      "cross_val": 1,
      "KFold(n_splits=3)": 1,
      "KFold(n_splits=5, shuffle=True, random_state=50)": 1,
      "self.cv": 1,
      "StratifiedKFold(4, random_state=3)": 1,
      "KFold(n_splits=5, shuffle=True, random_state=0)": 1,
      "cv_inner": 1,
      "StratifiedKFold(3)": 1,
      "RepeatedKFold(n_splits=10, n_repeats=2)": 1,
      "skf.split(x_train, y_train)": 1,
      "KFold_CV": 1,
      "gen_cv()": 1,
      "FOLDS": 1,
      "nr_folds": 1,
      "folds_iterable": 1,
      "split_data": 1
    },
    "sklearn.metrics._classification.matthews_corrcoef.y_true": {
      "train.Response": 51,
      "y": 14,
      "y_true": 12,
      "labels": 8,
      "dev_y": 5,
      "target": 4,
      "ytrain": 4,
      "gt": 4,
      "y_test": 3,
      "yval": 3,
      "y_cv": 3,
      "y_train.values.astype(np.float)": 3,
      "label": 2,
      "snap_dict['CA']": 2,
      "true_labels[i]": 2,
      "data[c[1]]": 2,
      "y_train": 2,
      "labels_flat": 2,
      "actual": 2,
      "valid.Response": 1,
      "test_labels": 1,
      "snap_dict['WI']": 1,
      "flat_true_labels": 1,
      "Y": 1,
      "test_array[:, -1]": 1,
      "Y_valid": 1,
      "true_value": 1,
      "true_value_test": 1,
      "true_label": 1,
      "t_y": 1,
      "y_train.values[val_indices].astype(np.float)": 1,
      "y_train.values[test_indices].astype(np.float)": 1,
      "y_val": 1,
      "missing['miss_' + col_w_missing[i]]": 1,
      "y_new": 1,
      "real_Y": 1
    },
    "sklearn.metrics._classification.matthews_corrcoef.y_pred": {
      "y_pred": 60,
      "preds > thr": 14,
      "pred": 8,
      "preds": 8,
      "guess_dev_negative_one": 4,
      "prediction": 3,
      "y_predict_cv": 3,
      "ypredt": 2,
      "ypredv": 2,
      "(y_proba > t).astype(np.uint8)": 2,
      "snap_dict['TX']": 2,
      "predictions": 2,
      "trainpredictions / folds > thr": 2,
      "data[c[0]]": 2,
      "clf.predict(train_data)": 2,
      "y_predict_train": 2,
      "pred_flat": 2,
      "predictions > threshold": 1,
      "guess_dev": 1,
      "predprobs > thr": 1,
      "mod.predict(X)": 1,
      "predict": 1,
      "snap_dict['WI']": 1,
      "pred_labels_i": 1,
      "np.argmax(predictions[i], axis=1).flatten()": 1,
      "flat_predictions": 1,
      "yp_bool": 1,
      "Y_pred": 1,
      "valid_pred": 1,
      "train_pred": 1,
      "new_pred": 1,
      "pred_test": 1,
      "results": 1,
      "yP": 1,
      "yp_val_fold.astype(np.float) > best_proba": 1,
      "yp_test_fold.astype(np.float) > best_proba": 1,
      "yp_train > t": 1,
      "yp_val > t": 1,
      "yp_test > t": 1,
      "missing['miss_' + col_w_missing[j]]": 1,
      "(prediction > threshold).astype(np.float64)": 1,
      "(prediction > self.threshold).astype(np.float64)": 1
    },
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.verbose": {
      "0": 4893,
      "1": 247,
      "2": 23,
      "True": 9,
      "3": 3,
      "False": 3,
      "5": 1,
      "4": 1
    },
    "sklearn.preprocessing._data.PolynomialFeatures.__init__.degree": {
      "2": 279,
      "3": 139,
      "degree": 42,
      "4": 40,
      "5": 15,
      "deg": 5,
      "7": 5,
      "1": 5,
      "6": 4,
      "i": 3,
      "self.degree": 3,
      "d": 3,
      "f_degree": 2,
      "power": 2,
      "population": 2,
      "weight": 2,
      "day": 2,
      "j": 1,
      "len(X)": 1,
      "8": 1,
      "self.polyorder": 1,
      "n": 1,
      "degrees": 1,
      "order": 1,
      "10": 1,
      "a + 1": 1
    },
    "sklearn.metrics._plot.precision_recall_curve.plot_precision_recall_curve.estimator": {
      "model": 2,
      "log_model": 2,
      "clf": 1,
      "pipeline_tf": 1,
      "classifier": 1
    },
    "sklearn.metrics._plot.precision_recall_curve.plot_precision_recall_curve.X": {
      "X_test": 4,
      "scaled_X_test": 2,
      "xtest": 1
    },
    "sklearn.metrics._plot.precision_recall_curve.plot_precision_recall_curve.y": {
      "y_test": 6,
      "ytest": 1
    },
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.use_idf": {
      "True": 2842,
      "1": 354,
      "False": 19
    },
    "sklearn.svm._classes.SVC.__init__.C": {
      "1.0": 1165,
      "10.0": 68,
      "1": 62,
      "0.025": 55,
      "10": 53,
      "100": 36,
      "0.1": 13,
      "100.0": 10,
      "50": 10,
      "5": 10,
      "1000": 10,
      "c": 9,
      "1.7": 8,
      "0.01": 7,
      "9": 7,
      "10000": 7,
      "C": 7,
      "2": 6,
      "C_opt": 5,
      "1e-06": 5,
      "200": 5,
      "Best_Parameter['C']": 4,
      "1e-07": 4,
      "float(C)": 4,
      "4": 4,
      "0.5": 4,
      "0.7": 4,
      "80": 3,
      "0.0001": 3,
      "20": 3,
      "250": 3,
      "9.0": 3,
      "1.2": 3,
      "0.8": 2,
      "10000000000.0": 2,
      "13.0": 2,
      "11.0": 2,
      "11": 2,
      "5.0": 2,
      "i": 2,
      "10.5": 2,
      "12.0": 2,
      "300": 2,
      "15": 2,
      "best_C": 2,
      "13": 2,
      "12": 2,
      "0.001": 2,
      "1.75": 2,
      "0.3": 1,
      "0.05": 1,
      "10**5": 1,
      "1e-09": 1,
      "1.4": 1,
      "1000000000.0": 1,
      "params['C']": 1,
      "0.15": 1,
      "2.8842926692105966": 1,
      "C_SVM[ii]": 1,
      "C_SVM": 1,
      "1.17": 1,
      "specs[k][0]": 1,
      "3.25": 1,
      "C_param": 1,
      "c_val": 1,
      "grid_search_svm.best_params_['C']": 1,
      "svm_study.best_params['c']": 1,
      "c_try": 1,
      "1000000.0": 1,
      "3": 1,
      "clf.best_params_['C']": 1,
      "0.4": 1,
      "trial.suggest_loguniform('C', 0.0001, 10000.0)": 1,
      "10.1": 1,
      "best_c[i]": 1,
      "0.75": 1,
      "trial.suggest_loguniform('C', 0.01, 0.1)": 1,
      "svm_c": 1,
      "20.0": 1,
      "trial.suggest_loguniform('C', 0.1, 0.5)": 1,
      "len(nCrime)": 1,
      "2.6": 1,
      "10**i": 1,
      "this_c": 1,
      "270": 1,
      "0.2933391008208308": 1,
      "this_C": 1,
      "15.0": 1,
      "400": 1,
      "13.450385695977566": 1,
      "0.02": 1,
      "120": 1
    },
    "sklearn.svm._classes.SVC.__init__.gamma": {
      "'scale'": 1276,
      "'auto'": 142,
      "0.0": 58,
      "1": 46,
      "0.1": 23,
      "0.01": 19,
      "0.001": 16,
      "1.4": 9,
      "2": 7,
      "Best_Parameter['gamma']": 4,
      "1.0": 4,
      "float(gamma)": 4,
      "10": 4,
      "0.0001": 4,
      "1.5": 3,
      "1.7": 3,
      "gamma": 3,
      "c": 3,
      "0.05": 3,
      "1e-07": 2,
      "0.006": 2,
      "0.5": 2,
      "0.7": 2,
      "5": 2,
      "trial.suggest_categorical('gamma', ['auto'])": 2,
      "best_gamma": 2,
      "0.8": 2,
      "1.3": 2,
      "0.08": 1,
      "0.02": 1,
      "0.6": 1,
      "0.016759846725511944": 1,
      "specs[k][1]": 1,
      "gamma_param": 1,
      "0.0005": 1,
      "0.06": 1,
      "3": 1,
      "svm_study.best_params['gamma']": 1,
      "0.085": 1,
      "0.25": 1,
      "j": 1,
      "100": 1,
      "trial.suggest_loguniform('gamma', 0.0001, 10000.0)": 1,
      "best_gamma[i]": 1,
      "0.4": 1,
      "6": 1,
      "0.015": 1,
      "this_g": 1,
      "7": 1,
      "1e-05": 1,
      "0.2": 1,
      "0.004315538019120583": 1,
      "800": 1,
      "0.9": 1
    },
    "sklearn.svm._classes.SVC.__init__.tol": {
      "0.001": 1652,
      "1e-10": 5,
      "0.0001": 5,
      "0.01": 2,
      "0.05500000000000001": 1,
      "0.6100000000000001": 1,
      "0.85": 1,
      "1.0": 1,
      "0.5000000000000001": 1,
      "grid_search_svm.best_params_['tol']": 1,
      "0.1": 1,
      "1e-05": 1,
      "0.002": 1,
      "0.005": 1,
      "1e-08": 1
    },
    "sklearn.svm._classes.SVC.__init__.verbose": {
      "False": 1643,
      "True": 25,
      "1": 2,
      "3": 2,
      "0": 1,
      "2": 1,
      "10": 1
    },
    "sklearn.svm._classes.SVC.__init__.max_iter": {
      "-1": 1655,
      "1000": 6,
      "10000": 3,
      "max_iter": 2,
      "100": 2,
      "3000": 1,
      "2000": 1,
      "50": 1,
      "epoch": 1,
      "7500": 1,
      "400": 1,
      "20000": 1
    },
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.criterion": {
      "'gini'": 4800,
      "'entropy'": 364,
      "criterion": 5,
      "Best_Parameter['criterion']": 4,
      "grid.best_params_['criterion']": 2,
      "best_params['criterion']": 1,
      "parameters['criterion']": 1,
      "clf.best_params_['criterion']": 1,
      "space['criterion']": 1,
      "['gini', 'entropy'][best['criterion']]": 1
    },
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.max_depth": {
      "None": 3852,
      "5": 228,
      "10": 144,
      "7": 72,
      "15": 61,
      "8": 57,
      "3": 53,
      "max_depth[int(best_alpha % 2)]": 51,
      "2": 49,
      "max_depth[int(best_alpha % 4)]": 40,
      "20": 39,
      "4": 38,
      "6": 38,
      "j": 35,
      "9": 33,
      "30": 29,
      "50": 24,
      "100": 21,
      "g['md']": 17,
      "25": 17,
      "max_depth": 15,
      "200": 15,
      "12": 14,
      "i": 12,
      "35": 10,
      "16": 10,
      "80": 8,
      "40": 8,
      "m": 8,
      "best_m": 8,
      "18": 7,
      "depth": 7,
      "11": 7,
      "13": 7,
      "23": 6,
      "int(params['max_depth'])": 6,
      "14": 6,
      "70": 6,
      "77": 6,
      "21": 5,
      "19": 5,
      "1": 5,
      "Best_Parameter['max_depth']": 4,
      "maxdepth": 4,
      "17": 3,
      "150": 3,
      "60": 3,
      "55": 3,
      "31": 3,
      "int(max_depth)": 3,
      "k": 2,
      "trial.suggest_int('max_depth', 5, 20, 5)": 2,
      "params['max_depth']": 2,
      "best_params['max_depth']": 2,
      "best_depth": 2,
      "study.best_params['max_depth']": 2,
      "int(round(best['max_depth'], 0))": 2,
      "600": 2,
      "rf_clf.best_params_['max_depth']": 2,
      "int(best['max_depth'])": 2,
      "int(round(max_depth))": 2,
      "83": 2,
      "38": 2,
      "grid.best_params_['max_depth']": 2,
      "300": 2,
      "24": 2,
      "trial.suggest_int('max_depth', 3, 2000)": 2,
      "20000": 1,
      "trial.suggest_int('max_depth', 5, 20)": 1,
      "C": 1,
      "best_c": 1,
      "l": 1,
      "i + 1": 1,
      "d": 1,
      "120": 1,
      "180": 1,
      "height": 1,
      "32": 1,
      "dep": 1,
      "parameters['max_depth']": 1,
      "max_dep": 1,
      "2 * img_size[0]": 1,
      "rf_bp['max_depth']": 1,
      "int(round(rf_b_o.max['params']['max_depth']))": 1,
      "int(population[i][0])": 1,
      "int(population[bestFitnessIndex][0])": 1,
      "26": 1,
      "90": 1,
      "clf.best_params_['max_depth']": 1,
      "x": 1,
      "28": 1,
      "forest.best_params_['max_depth']": 1,
      "rf_max_depth": 1,
      "rf_random.best_params_['max_depth']": 1,
      "trial.suggest_int('max_depth', 10, 25)": 1,
      "space['max_depth']": 1,
      "best['max_depth']": 1,
      "5.0": 1,
      "1417": 1,
      "1852": 1,
      "trial.suggest_int('max_depth', 2, 10)": 1,
      "132": 1,
      "62": 1,
      "88": 1,
      "87": 1,
      "27": 1,
      "max_depth_i": 1,
      "44": 1
    },
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.max_leaf_nodes": {
      "None": 5128,
      "30": 5,
      "60": 4,
      "40": 4,
      "maxleafnodes": 3,
      "270": 3,
      "10": 3,
      "4": 2,
      "maxleaf": 2,
      "16": 2,
      "18": 2,
      "100": 2,
      "5": 2,
      "128": 2,
      "220": 2,
      "trial.suggest_int('max_leaf_nodes', 500, 100000)": 2,
      "n": 2,
      "2000": 1,
      "max_leaf_nodes": 1,
      "15": 1,
      "x": 1,
      "5000": 1,
      "25": 1,
      "87127": 1,
      "9058": 1,
      "85221": 1,
      "200": 1
    },
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.oob_score": {
      "False": 4927,
      "True": 252,
      "VALIDATE": 1
    },
    "sklearn.utils.class_weight.compute_class_weight.class_weight": {
      "'balanced'": 251
    },
    "sklearn.tree._classes.DecisionTreeClassifier.__init__.criterion": {
      "'gini'": 1413,
      "'entropy'": 130,
      "grid.best_params_['criterion']": 3,
      "gridcv.best_params_['criterion']": 1,
      "dt_grid.best_params_.get('criterion')": 1
    },
    "sklearn.tree._classes.DecisionTreeClassifier.__init__.random_state": {
      "None": 1119,
      "0": 127,
      "42": 72,
      "1": 57,
      "random_state": 18,
      "seed": 17,
      "100": 12,
      "2021": 11,
      "10": 10,
      "SEED": 10,
      "123": 8,
      "101": 6,
      "1000": 4,
      "17": 4,
      "666": 4,
      "34": 4,
      "random_state_": 4,
      "2019": 3,
      "99": 3,
      "376": 3,
      "555": 3,
      "300": 2,
      "2017": 2,
      "202": 2,
      "55": 2,
      "RANDOM_STATE": 2,
      "randomState": 2,
      "6": 2,
      "3": 2,
      "11": 2,
      "tree_seed": 2,
      "369": 2,
      "14": 1,
      "200": 1,
      "121": 1,
      "120": 1,
      "self.random_state": 1,
      "5": 1,
      "1728": 1,
      "390": 1,
      "10000": 1,
      "1234": 1,
      "587": 1,
      "87": 1,
      "7": 1,
      "29": 1,
      "7541": 1,
      "4": 1,
      "777": 1,
      "24": 1,
      "25": 1,
      "2": 1,
      "random_seed": 1,
      "18": 1,
      "2020": 1,
      "RANDOM_SEED": 1,
      "1118": 1,
      "102": 1,
      "315": 1
    },
    "sklearn.tree._classes.DecisionTreeClassifier.__init__.max_depth": {
      "None": 1133,
      "5": 61,
      "3": 60,
      "10": 49,
      "1": 28,
      "4": 26,
      "2": 18,
      "8": 17,
      "i": 15,
      "20": 13,
      "15": 11,
      "7": 11,
      "best_parameters['max_depth']": 9,
      "30": 8,
      "OptDepth": 8,
      "13": 7,
      "6": 7,
      "depth": 7,
      "max_depth": 6,
      "100": 5,
      "9": 4,
      "50": 4,
      "max_depth_val": 3,
      "d": 2,
      "150": 2,
      "12": 2,
      "200": 2,
      "value": 2,
      "md": 2,
      "80": 2,
      "31": 2,
      "110": 2,
      "40": 2,
      "1000": 1,
      "18": 1,
      "16": 1,
      "max_depths": 1,
      "19": 1,
      "14": 1,
      "prime": 1,
      "prime * 1000": 1,
      "gridcv.best_params_['max_depth']": 1,
      "32": 1,
      "26": 1,
      "dt_grid.best_params_.get('max_depth')": 1,
      "pval": 1,
      "33": 1,
      "35": 1,
      "37": 1,
      "45": 1,
      "60": 1
    },
    "sklearn.tree._classes.DecisionTreeClassifier.__init__.min_samples_leaf": {
      "1": 1478,
      "5": 9,
      "best_parameters['min_samples_leaf']": 9,
      "3": 6,
      "10": 6,
      "80": 4,
      "20": 4,
      "15": 3,
      "100": 3,
      "6": 3,
      "min_samples_leaf": 2,
      "25": 2,
      "7": 2,
      "35": 2,
      "150": 1,
      "50": 1,
      "self.min_samples_leaf": 1,
      "40": 1,
      "best_sample_leaf": 1,
      "500": 1,
      "38": 1,
      "8": 1,
      "9": 1,
      "0.4": 1,
      "82": 1,
      "0.05": 1,
      "2": 1,
      "dt_grid.best_params_.get('max_leaf_nodes')": 1,
      "30": 1
    },
    "sklearn.preprocessing._encoders.OneHotEncoder.fit.X": {
      "pd.concat([X[categorical], X_test[categorical]])": 16,
      "merged": 14,
      "train": 9,
      "X": 9,
      "y_targets": 9,
      "y_test_targets": 9,
      "np.array(list(mapping_dict[col].values())).reshape(-1, 1)": 7,
      "data": 6,
      "witch_bin.reshape(-1, 1)": 6,
      "pd.concat([df_train, df_test])": 5,
      "X_target[target].unique().reshape((-1, 1))": 5,
      "np.resize(np.array(train_values).astype(float), (len(train_values), 1))": 5,
      "categorical_cols": 5,
      "categorical_cols_test": 5,
      "X[:, 0].reshape(-1, 1)": 4,
      "X[:, 1].reshape(-1, 1)": 4,
      "Correlation_df[category_col]": 4,
      "Titanic_train_x[category_col]": 4,
      "Titanic_predict_x[category_col]": 4,
      "train['Sentiment'].values.reshape(-1, 1)": 4,
      "y": 4,
      "yy": 4,
      "Y": 4,
      "train1[col]": 4,
      "train2[col]": 4,
      "raw_cat_ne_df": 3,
      "full_data[['location', 'keyword']]": 3,
      "X1[['sex', 'smokingstatus']]": 3,
      "df['Paises_Estado'].values.reshape(-1, 1)": 3,
      "train_df[features]": 3,
      "targets": 3,
      "X_train_cyclic": 3,
      "x.loc[:, [self.col]]": 2,
      "self.df[self.cat_feats].values": 2,
      "train[['matchType']]": 2,
      "test[['matchType']]": 2,
      "X_full[['host', 'category']]": 2,
      "train_features[req_train_cat_cols]": 2,
      "x[:, 1].reshape(-1, 1)": 2,
      "feature_df['part'].to_numpy().reshape(-1, 1)": 2,
      "full_data[LE_vars]": 2,
      "train_x2[cat_cols].fillna('NA')": 2,
      "X_train[cat_cols]": 2,
      "column": 2,
      "train[cat_features]": 2,
      "rf.apply(X_train)": 2,
      "meta_train[['target']]": 2,
      "np.array(Y_train)": 2,
      "full_data[features]": 2,
      "df_text": 2,
      "full_le": 2,
      "train_x": 2,
      "train_easy_OHE": 2,
      "df_keyword": 2,
      "encodedCategories": 2,
      "cat_features_train": 2,
      "np.array(unique_cats).reshape(-1, 1)": 2,
      "obj_train_data": 2,
      "np.array(label_names).reshape(-1, 1)": 2,
      "df.Score.to_numpy().reshape(-1, 1)": 1,
      "label": 1,
      "categories_idx": 1,
      "X_train[labels]": 1,
      "leb_enc": 1,
      "data[[cat]]": 1,
      "np.asarray(list(team_set)).reshape(-1, 1)": 1,
      "train[['Province_State', 'Country_Region']]": 1,
      "test[['Province_State', 'Country_Region']]": 1,
      "cluster.reshape(-1, 1)": 1,
      "np.concatenate((train[c].values.reshape(-1, 1).astype('str'), test[c].values.reshape(-1, 1).astype('str')))": 1,
      "train_df[['OffenseFormation']]": 1,
      "train_features[['cp_time', 'cp_dose']]": 1,
      "vec_cat": 1,
      "np.array(shops['shop_type'].unique()).reshape(len(shops['shop_type'].unique()), 1)": 1,
      "x_all_categorical": 1,
      "complete_df[catColumns]": 1,
      "lb_encoder.transform(df['loc'].values)": 1,
      "X[['quarter', 'down']]": 1,
      "X[['time_to_handoff']]": 1,
      "train[['category', 'host']].append(test[['category', 'host']]).values": 1,
      "pd.DataFrame({f: [np.uint16(i % features_cnt.get(f)) for i in range(hash_digit * 2)] for f in features})[features]": 1,
      "train_y.reshape(-1, 1)": 1,
      "eval_y.reshape(-1, 1)": 1,
      "X_train[categorical_vars]": 1,
      "train_data[cat_cols]": 1,
      "alldata": 1,
      "df[cat_cols]": 1,
      "df_train[['CNT_CHILDREN']]": 1,
      "self.label_cat_enc_.fit_transform(categories).reshape(-1, 1)": 1,
      "self.label_brand_enc_.fit_transform(brands).reshape(-1, 1)": 1,
      "categorical_ftrs": 1,
      "train['species_id'].values.reshape(-1, 1)": 1,
      "categorical_vector": 1,
      "list(train_features[category_feature_names].values) + list(test_features[category_feature_names].values)": 1,
      "train[num_algo_cat_features]": 1,
      "adoption_speed.reshape(-1, 1)": 1,
      "temp_data[:, 1:117]": 1,
      "self.dataframe[cat_features]": 1,
      "np.vstack((X[:, 1:], X_test[:, 1:]))": 1,
      "grd.apply(X_train)[:, :, 0]": 1,
      "sample": 1,
      "np.array(range(k)).reshape(-1, 1)": 1,
      "df_train[CATEGORICAL_FEATURES]": 1,
      "df[[col]]": 1,
      "[[0], [1]]": 1,
      "whole": 1,
      "all_MSSubClass_value": 1,
      "self.categorical_data": 1,
      "[[0], [1], [2]]": 1,
      "agent_enc": 1,
      "page_enc": 1,
      "acc_enc": 1,
      "pd.concat([X_train, X_test])": 1,
      "X_train": 1,
      "nom_cats": 1,
      "X_cat": 1,
      "t2": 1,
      "np.array(self.merged_data.loc[:, col])": 1,
      "train[cat_features].append(test[cat_features])": 1,
      "y.reshape(-1, 1)": 1,
      "train_data['SmokingStatus'].values.reshape(-1, 1)": 1,
      "train['color_id']": 1,
      "train_easy_OHE_prep": 1,
      "y_train.values.reshape(-1, 1)": 1,
      "train[features]": 1,
      "data_ref[['sentiment']]": 1,
      "X1[['Sex', 'SmokingStatus']]": 1,
      "whole_dataset": 1,
      "data[cat_cols]": 1,
      "bidarr": 1,
      "pd.concat((cats_train, cats_test), axis=0)": 1,
      "train[['Address_clean_encode']]": 1,
      "train.Sentiment.values.reshape(-1, 1)": 1,
      "df_train_cat[[column]]": 1,
      "df_test_cat[[column]]": 1,
      "pd.concat([x_train, x_test])": 1,
      "df[f].values.reshape(-1, 1)": 1,
      "np.array(train_df[col].values.tolist() + test_df[col].values.tolist()).reshape(-1, 1)": 1,
      "np.arange(100).reshape(-1, 1)": 1,
      "targetss": 1,
      "np.arange(num_classes).reshape(-1, 1)": 1,
      "np.arange(len(list(all_country_codes))).reshape(-1, 1)": 1,
      "np.arange(len(cntntns)).reshape(-1, 1)": 1,
      "np.arange(num_groups).reshape(-1, 1)": 1,
      "X_all": 1,
      "label_train": 1,
      "label_val": 1,
      "X_train[cat_feat]": 1,
      "categorical_columns": 1,
      "categorical_test": 1,
      "train_df[['Embarked']]": 1,
      "test_df[['Embarked']]": 1,
      "df": 1,
      "inputs_df[categorical_cols]": 1,
      "data[col]": 1,
      "X[one_hot_vars].fillna('unknown')": 1,
      "self.df_train[['sex', 'anatom_site_general_challenge']]": 1,
      "X_train_imputed": 1,
      "cat_all": 1,
      "train_feat[['cp_type', 'cp_time', 'cp_dose']]": 1,
      "np.array(data.matchType).reshape(-1, 1)": 1,
      "train[cat_columns]": 1,
      "data[label].to_numpy().reshape(-1, 1)": 1,
      "Y_train": 1,
      "Gene_vocab.values.reshape(-1, 1)": 1,
      "Variation_vocab.values.reshape(-1, 1)": 1,
      "x": 1,
      "df_test": 1,
      "x[:200000]": 1,
      "labels_encoded.reshape(-1, 1)": 1,
      "targets_predict": 1,
      "self.df[self.encode_cols].values": 1,
      "y_class": 1,
      "train_df['zone_id'].values": 1,
      "train_object": 1,
      "category_features_train.reshape(-1, 1)": 1,
      "train[cat_cols[3:]]": 1,
      "X_train.title.values.reshape(-1, 1)": 1,
      "df[Cat_columns]": 1,
      "data[categorical_var]": 1,
      "train[categorical_var]": 1,
      "df['month'].values.reshape(-1, 1)": 1,
      "df['town'].values.reshape(-1, 1)": 1,
      "df['meta_category'].values.reshape(-1, 1)": 1,
      "tmp.reshape((-1, 1))": 1,
      "np.array(cat).reshape(-1, 1)": 1,
      "X_xTrain_CS.Country.values.reshape(X_xTrain_CS.Country.shape[0], 1)": 1,
      "X_xTrain_CS.State.values.reshape(X_xTrain_CS.Country.shape[0], 1)": 1,
      "pd.DataFrame(train_test_combine_specs[cat_cols])": 1,
      "titanic[['Embarked']]": 1,
      "tpart": 1,
      "witch_bin": 1
    },
    "sklearn.preprocessing._encoders.OneHotEncoder.transform.X": {
      "test_df[[cat]]": 54,
      "X[categorical]": 16,
      "X_test[categorical]": 16,
      "test[features]": 15,
      "train[features]": 14,
      "train[i * m:(i + 1) * m]": 10,
      "test[i * m:(i + 1) * m]": 10,
      "X": 10,
      "df_test": 9,
      "y_targets": 9,
      "y_test_targets": 9,
      "y": 6,
      "raw_cat_ne_df": 6,
      "witch_bin2.reshape(-1, 1)": 6,
      "df_train": 5,
      "train[train['fold_id'] != i]['Sentiment'].values.reshape(-1, 1)": 5,
      "train[train['fold_id'] == i]['Sentiment'].values.reshape(-1, 1)": 5,
      "test": 5,
      "X_target[target].values.reshape((-1, 1))": 5,
      "np.resize(np.array(train_values).astype(float), (len(train_values), 1))": 5,
      "np.resize(np.array(test_values).astype(float), (len(test_values), 1))": 5,
      "self.la.transform(x.reshape(-1, 1))": 5,
      "categorical_cols": 5,
      "categorical_cols_test": 5,
      "X[:, 0].reshape(-1, 1)": 4,
      "X[:, 1].reshape(-1, 1)": 4,
      "X_test[:, 1].reshape(-1, 1)": 4,
      "x_test[ohe_features]": 4,
      "train_label": 4,
      "val_label": 4,
      "numpy.array(test_store[col].reshape(len(test_store[col]), 1))": 4,
      "Y": 4,
      "shuffled_train[['location', 'keyword']]": 4,
      "train[['location', 'keyword']]": 4,
      "test[['location', 'keyword']]": 4,
      "test_df[features]": 4,
      "train1[col]": 4,
      "test1[col]": 4,
      "train2[col]": 4,
      "test2[col]": 4,
      "witch_bin.reshape(-1, 1)": 4,
      "cat_data": 3,
      "X_valid[low_cardinality_cols]": 3,
      "test[cat_cols]": 3,
      "train[cat_features]": 3,
      "test[cat_features]": 3,
      "X_train": 3,
      "X_test": 3,
      "Y_train": 3,
      "X1[['sex', 'smokingstatus']]": 3,
      "X_test[['sex', 'smokingstatus']]": 3,
      "df['Paises_Estado'].values.reshape(-1, 1)": 3,
      "train_df[features]": 3,
      "targets": 3,
      "X_train_cyclic": 3,
      "Correlation_df[category_col]": 2,
      "Titanic_train_x[category_col]": 2,
      "Titanic_predict_x[category_col]": 2,
      "x.loc[:, [self.col]]": 2,
      "self.df[self.cat_feats].values": 2,
      "label": 2,
      "train[['matchType']]": 2,
      "test[['matchType']]": 2,
      "X[['host', 'category']]": 2,
      "cat_test": 2,
      "data[[cat]]": 2,
      "train_features[req_train_cat_cols]": 2,
      "test_features[req_train_cat_cols]": 2,
      "x[:, 1].reshape(-1, 1)": 2,
      "x_test[:, 1].reshape(-1, 1)": 2,
      "feature_df['part'].to_numpy().reshape(-1, 1)": 2,
      "numpy.array(test[col].reshape(len(test[col]), 1))": 2,
      "full_data[LE_vars]": 2,
      "y_val.values.reshape(-1, 1)": 2,
      "train_x2[cat_cols].fillna('NA')": 2,
      "test_x2[cat_cols].fillna('NA')": 2,
      "df[features]": 2,
      "X_train[cat_cols]": 2,
      "X_test[cat_cols]": 2,
      "test_data[cat_cols]": 2,
      "column": 2,
      "X_valid": 2,
      "x_test": 2,
      "rf.apply(X_train_lr)": 2,
      "validate_y": 2,
      "batch_y": 2,
      "df_text": 2,
      "df_text_test": 2,
      "t2": 2,
      "pd.DataFrame(X_test_cats, columns=[X_cats_names])[nominal_features]": 2,
      "train_le": 2,
      "test_le": 2,
      "train_x": 2,
      "train_easy_OHE": 2,
      "test_easy_OHE": 2,
      "df_keyword": 2,
      "X_test_norm": 2,
      "cat_test_features": 2,
      "cat_features_test": 2,
      "test[cat_features].fillna('0')": 2,
      "cat_dropTooMiss_replaceNo": 2,
      "obj_train_data": 2,
      "obj_test_data": 2,
      "data[categorical_var]": 2,
      "tpart": 2,
      "witch_bin22.reshape(-1, 1)": 2,
      "df.Score.to_numpy().reshape(-1, 1)": 1,
      "df_test[['item_condition_id', 'shipping']].values": 1,
      "df[labels]": 1,
      "X_train_2[[col]]": 1,
      "X_test_2[[col]]": 1,
      "X_train_3[[col]]": 1,
      "X_test_3[[col]]": 1,
      "X_train_4[[col]]": 1,
      "X_test_4[[col]]": 1,
      "breed": 1,
      "imputed_X_valid[categorical_cols]": 1,
      "imputed_X_test[categorical_cols]": 1,
      "X_test[obj_columns]": 1,
      "test[obj_columns]": 1,
      "test_cat": 1,
      "train[['Province_State', 'Country_Region']]": 1,
      "test[['Province_State', 'Country_Region']]": 1,
      "cluster.reshape(-1, 1)": 1,
      "cluster_test.reshape(-1, 1)": 1,
      "data[cat_vars]": 1,
      "valid['shipping'].values.reshape(-1, 1)": 1,
      "valid['item_condition_id'].values.reshape(-1, 1)": 1,
      "test['shipping'].values.reshape(-1, 1)": 1,
      "test['item_condition_id'].values.reshape(-1, 1)": 1,
      "train[c].values.reshape(-1, 1).astype('str')": 1,
      "test[c].values.reshape(-1, 1).astype('str')": 1,
      "train_df[['OffenseFormation']]": 1,
      "train_features[['cp_time', 'cp_dose']]": 1,
      "test_features[['cp_time', 'cp_dose']]": 1,
      "vec_cat": 1,
      "np.array(shops['shop_type']).reshape(-1, 1)": 1,
      "x_train_categorical": 1,
      "x_test_categorical": 1,
      "val_tv_X": 1,
      "complete_df[catColumns]": 1,
      "df_test[cat_columns]": 1,
      "df_test[cat_columns_reduce]": 1,
      "X[['quarter', 'down']]": 1,
      "X[['time_to_handoff']]": 1,
      "train[['category', 'host']]": 1,
      "test[['category', 'host']]": 1,
      "X_test[X_catCols]": 1,
      "train_y.reshape(-1, 1)": 1,
      "test_y.reshape(-1, 1)": 1,
      "eval_y.reshape(-1, 1)": 1,
      "test_data[train_object_cols]": 1,
      "X_train[categorical_vars]": 1,
      "X_test[categorical_vars]": 1,
      "y_valid.reshape(-1, 1)": 1,
      "train_data[cat_cols]": 1,
      "alldata": 1,
      "test[col4train]": 1,
      "x_val[['Sex', 'SmokingStatus']]": 1,
      "x[['Sex', 'SmokingStatus']]": 1,
      "df[cat_cols]": 1,
      "X2_valid_dnn": 1,
      "x2_t": 1,
      "df_train['CNT_CHILDREN'].values.reshape(-1, 1)": 1,
      "df_test['CNT_CHILDREN'].values.reshape(-1, 1)": 1,
      "self.label_brand_enc_.transform(new_brands).reshape(-1, 1)": 1,
      "self.label_cat_enc_.transform(new_categories).reshape(-1, 1)": 1,
      "np.array(preds).flatten().reshape(-1, 1)": 1,
      "categorical_vector": 1,
      "Canadate": 1,
      "train_features[category_feature_names]": 1,
      "test_features[category_feature_names]": 1,
      "df[num_algo_cat_features]": 1,
      "reshape_arr_val": 1,
      "adoption_speed.reshape(-1, 1)": 1,
      "array[:, 1:117]": 1,
      "dataframe_batch[self.cat_features]": 1,
      "X[:, 1:]": 1,
      "X_test[:, 1:]": 1,
      "grd.apply(X_train_lr)[:, :, 0]": 1,
      "rf.apply(X_val)": 1,
      "grd.apply(X_val)[:, :, 0]": 1,
      "rf.apply(X_test)": 1,
      "df[col]": 1,
      "clusters.reshape(-1, 1)": 1,
      "df[[col]]": 1,
      "x_test.iloc[:, 3].values.reshape(-1, 1)": 1,
      "test.iloc[:, 3].values.reshape(-1, 1)": 1,
      "df_test[oh_cols]": 1,
      "train_MSSubClass[['MSSubClass']]": 1,
      "test_MSSubClass[['MSSubClass']]": 1,
      "self.categorical_data": 1,
      "X_test[object_cols]": 1,
      "cur_test": 1,
      "df_train[features]": 1,
      "df_valid[features]": 1,
      "df['label'].to_numpy().reshape(-1, 1)": 1,
      "agent_enc": 1,
      "page_enc": 1,
      "acc_enc": 1,
      "X_valid_cat": 1,
      "X_test_cat": 1,
      "tst[cat_cols]": 1,
      "nom_cats": 1,
      "X_cat": 1,
      "feature_valid[cat_cols]": 1,
      "np.array(self.merged_data.loc[:, col])": 1,
      "train_X": 1,
      "y.reshape(-1, 1)": 1,
      "train['color_id']": 1,
      "test_x": 1,
      "train_easy_OHE_prep": 1,
      "test_easy_OHE_prep": 1,
      "test_df[low_cardinality_nom_cols]": 1,
      "y_train.values.reshape(-1, 1)": 1,
      "y_test.values.reshape(-1, 1)": 1,
      "np.array(data).reshape(-1, 1)": 1,
      "data_ref[['sentiment']]": 1,
      "test[['Neighborhood']]": 1,
      "submission.license.fillna('Not Known').values.reshape(-1, 1)": 1,
      "X1[['Sex', 'SmokingStatus']]": 1,
      "whole_dataset.iloc[:train_size, :]": 1,
      "whole_dataset.iloc[train_size:, :]": 1,
      "test_data": 1,
      "data[cat_cols]": 1,
      "bidarr": 1,
      "cats_train": 1,
      "cats_test": 1,
      "train[['Address_clean_encode']]": 1,
      "test[['Address_clean_encode']]": 1,
      "traindata[features]": 1,
      "testdata[features]": 1,
      "X_cats_full": 1,
      "_df['Condition2'].to_numpy().reshape(-1, 1)": 1,
      "test_df[cat_col]": 1,
      "df_test[categorical_feats]": 1,
      "sub[['SmokingStatus']]": 1,
      "sub[['fact_' + self.name]].replace(-1, 999)": 1,
      "df_train_cat[[column]]": 1,
      "df_test_cat[[column]]": 1,
      "val_X[oh_cols]": 1,
      "x_train_sub": 1,
      "x_val": 1,
      "data[to_append].fillna(0)": 1,
      "train[to_append]": 1,
      "data[to_append]": 1,
      "y_l.reshape(-1, 1)": 1,
      "train_df[col].values.reshape(-1, 1)": 1,
      "test_df[col].values.reshape(-1, 1)": 1,
      "train_train['wppBin'].values.reshape(-1, 1)": 1,
      "train_val['wppBin'].values.reshape(-1, 1)": 1,
      "train_train['wppBin2'].values.reshape(-1, 1)": 1,
      "train_val['wppBin2'].values.reshape(-1, 1)": 1,
      "train_train['wppBin3'].values.reshape(-1, 1)": 1,
      "train_val['wppBin3'].values.reshape(-1, 1)": 1,
      "targetss": 1,
      "_all_labels.reshape(-1, 1)": 1,
      "_countries.reshape(-1, 1)": 1,
      "_continents.reshape(-1, 1)": 1,
      "_areas.reshape(-1, 1)": 1,
      "[encodedCategories[0]]": 1,
      "X_test_actual": 1,
      "label_train": 1,
      "label_val": 1,
      "X_train[cat_feat]": 1,
      "X_test[cat_feat]": 1,
      "categorical_columns": 1,
      "categorical_test": 1,
      "train_df[['Embarked']]": 1,
      "test_df[['Embarked']]": 1,
      "imputed_valid[object_cols]": 1,
      "imputed_test[object_cols]": 1,
      "label_X_valid[object_cols]": 1,
      "X_valid[object_cols]": 1,
      "tmp_data": 1,
      "label_x_test": 1,
      "inputs_df[categorical_cols]": 1,
      "testing_data[categorical_cols].values": 1,
      "data[col]": 1,
      "test[col]": 1,
      "TEST[low_cardinal]": 1,
      "X[self.one_hot_vars].fillna('unknown')": 1,
      "data_test[objlist]": 1,
      "X_train[features]": 1,
      "X_valid[features]": 1,
      "X_train_imputed": 1,
      "X_valid_imputed": 1,
      "test_imputed": 1,
      "ctei[one_hot]": 1,
      "X[:, i].reshape(-1, 1)": 1,
      "X_test[:, i].reshape(-1, 1)": 1,
      "concat[column].values.reshape(-1, 1)": 1,
      "train_feat[['cp_type', 'cp_time', 'cp_dose']]": 1,
      "test_feat[['cp_type', 'cp_time', 'cp_dose']]": 1,
      "np.array(data.matchType).reshape(-1, 1)": 1,
      "np.array(test_fresh_data.matchType).reshape(-1, 1)": 1,
      "test_X[['cp_type', 'cp_dose', 'cp_time']]": 1,
      "train[cat_columns]": 1,
      "data[label].to_numpy().reshape(-1, 1)": 1,
      "Y_test": 1,
      "Y_val": 1,
      "data['Gene'].values.reshape(-1, 1)": 1,
      "data['Variation'].values.reshape(-1, 1)": 1,
      "test_data['Gene'].values.reshape(-1, 1)": 1,
      "test_data['Variation'].values.reshape(-1, 1)": 1,
      "x": 1,
      "x[:200000]": 1,
      "labels_encoded.reshape(-1, 1)": 1,
      "car_data_test[low_cardinality_cols]": 1,
      "targets_predict": 1,
      "df[cat].values": 1,
      "y_class": 1,
      "train_df['zone_id']": 1,
      "cat_X_test": 1,
      "submit.loc[:, feat_group['fea_cat']]": 1,
      "train_object": 1,
      "test_object": 1,
      "category_features_train.reshape(-1, 1)": 1,
      "category_features_test.reshape(-1, 1)": 1,
      "testdf.select_dtypes('object')": 1,
      "train[cat_cols[3:]]": 1,
      "test[cat_cols[3:]]": 1,
      "X_train.title.values.reshape(-1, 1)": 1,
      "X_test.title.values.reshape(-1, 1)": 1,
      "train_df['month'].values.reshape(-1, 1)": 1,
      "test_df['month'].values.reshape(-1, 1)": 1,
      "test_df['town'].values.reshape(-1, 1)": 1,
      "test_df['meta_category'].values.reshape(-1, 1)": 1,
      "np.array(valid_label).reshape(-1, 1)": 1,
      "np.array(class_label).reshape(-1, 1)": 1,
      "tmp.reshape((-1, 1))": 1,
      "test[['cp_type', 'cp_dose']]": 1,
      "y_cat.reshape(-1, 1)": 1,
      "X_xTrain_CS1.Country.values.reshape(X_xTrain_CS1.Country.shape[0], 1)": 1,
      "X_xTrain_CS1.State.values.reshape(X_xTrain_CS1.State.shape[0], 1)": 1,
      "X_xTest_CS1.Country.values.reshape(X_xTest_CS1.Country.shape[0], 1)": 1,
      "X_xTest_CS1.State.values.reshape(X_xTest_CS1.State.shape[0], 1)": 1,
      "X_xTrain_CS12.Country.values.reshape(X_xTrain_CS12.Country.shape[0], 1)": 1,
      "X_xTrain_CS12.State.values.reshape(X_xTrain_CS12.State.shape[0], 1)": 1,
      "train_test_combine_specs[cat_cols]": 1,
      "test_data_v8[hot_columns]": 1,
      "pred_kmeans": 1,
      "titanic[['Embarked']]": 1,
      "titanic_test[['Embarked']]": 1,
      "witch_bin": 1,
      "witch_bin2": 1,
      "tmp_ts": 1,
      "np.array([dfTest['item_condition_id'].tolist(), dfTest['shipping'].tolist()]).T": 1
    },
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.__init__.n_estimators": {
      "50": 304,
      "100": 60,
      "200": 30,
      "800": 24,
      "500": 13,
      "1000": 13,
      "10": 12,
      "250": 8,
      "300": 6,
      "600": 6,
      "20": 5,
      "5": 5,
      "n_estimators": 4,
      "30": 4,
      "400": 4,
      "150": 3,
      "n": 3,
      "700": 2,
      "gridcv.best_params_['n_estimators']": 2,
      "225": 2,
      "15": 2,
      "10000": 1,
      "2200": 1,
      "70": 1,
      "adaparam['n_estimators']": 1,
      "n_ada_iterations": 1,
      "900": 1,
      "n_est": 1,
      "8": 1,
      "num_trees": 1,
      "13": 1,
      "18": 1,
      "40": 1,
      "trial.suggest_int('n_estimators', 10, 1000)": 1,
      "96": 1,
      "377": 1
    },
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.__init__.random_state": {
      "None": 371,
      "1": 36,
      "0": 30,
      "42": 28,
      "seed": 27,
      "123": 9,
      "7": 5,
      "100": 4,
      "10": 3,
      "random_state": 3,
      "44": 2,
      "SEED": 2,
      "432": 1,
      "RS": 1,
      "random_seed": 1,
      "99": 1,
      "222": 1,
      "369": 1,
      "16446054": 1
    },
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.fit.X": {
      "X_train": 65,
      "train_x": 36,
      "x_train": 15,
      "train_features": 11,
      "X": 10,
      "train_numeric_X": 6,
      "train[feats]": 5,
      "train_X": 4,
      "xtrain": 4,
      "train_merge4": 3,
      "train_vectors": 3,
      "games[col].fillna(-1)": 3,
      "train": 2,
      "train[features]": 2,
      "train_data_features": 2,
      "trainfeature": 2,
      "tsiftdatax_train": 2,
      "cv_train": 1,
      "td_train": 1,
      "x_mod_treino": 1,
      "X_train_scaled": 1,
      "X_tr": 1,
      "train_tfidf": 1,
      "trainX": 1,
      "dtrain": 1,
      "X_mm": 1,
      "np.array(X).reshape(-1, comp_num)": 1,
      "TrainData": 1,
      "heads2[feats]": 1,
      "chunk[predictors]": 1,
      "ttextdataemx_train": 1,
      "X_fit": 1,
      "X_train_tl": 1,
      "bag_of_words": 1,
      "subset[['day_of_week_encoded', 'pd_district_encoded', 'x', 'y', 'hour']]": 1,
      "df_train": 1,
      "X_train_val": 1,
      "train_": 1,
      "df": 1,
      "train_val[features]": 1,
      "count_train": 1,
      "X_ros": 1,
      "x": 1,
      "xtrain_tfv": 1,
      "X_train.fillna(0)": 1,
      "X_train_balanced": 1,
      "X_train_ex.fillna(0)": 1,
      "heads[feats]": 1,
      "X_train_vec": 1,
      "embeddings_train": 1,
      "train[variables]": 1,
      "self.x_train": 1,
      "Xtrain": 1,
      "train[binarias + discretas]": 1,
      "train[x_cols]": 1,
      "features_train": 1,
      "X_train_df": 1,
      "predictor1": 1,
      "predictor2": 1,
      "selected_data_train": 1,
      "np.array(train_embeddings)": 1,
      "train_data[selected_features]": 1,
      "X_res": 1,
      "x_train.to_list()": 1,
      "tr_x": 1
    },
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.fit.y": {
      "y_train": 88,
      "train_y": 38,
      "y": 9,
      "target": 8,
      "ytrain": 8,
      "train['Target']": 6,
      "train['Cover_Type']": 6,
      "Y_train": 5,
      "Y": 4,
      "train['signal']": 3,
      "games['Pred']": 3,
      "train_numeric_Y[numeric_features_Y[0]]": 3,
      "train_numeric_Y[numeric_features_Y[1]]": 3,
      "labels": 2,
      "train_df['target']": 2,
      "train['sentiment']": 2,
      "ttexty_train": 2,
      "tsiftdatay_train": 2,
      "y_ref_train": 2,
      "y_mod_treino": 1,
      "y_tr": 1,
      "trainY": 1,
      "TrainLabel": 1,
      "train_Y": 1,
      "heads2['Target']": 1,
      "chunk['clicked']": 1,
      "ttextdataemy_train": 1,
      "y_fit": 1,
      "y_train_tl": 1,
      "traindf['cuisine']": 1,
      "subset['category_predict']": 1,
      "y_train_val": 1,
      "labels_test1": 1,
      "train_val['signal']": 1,
      "y_ros": 1,
      "y_train_balanced": 1,
      "y_train_ex": 1,
      "heads['Target']": 1,
      "self.y_train": 1,
      "data_clean_tr['target']": 1,
      "train['CategoryEncoded']": 1,
      "labels_train": 1,
      "target2": 1,
      "train['target']": 1,
      "y_res": 1,
      "tr_y": 1
    },
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.predict_proba.X": {
      "X_test": 12,
      "x_val": 2,
      "ada_test_df[features]": 2,
      "test": 2,
      "test[features]": 2,
      "test_final": 2,
      "X_valid": 2,
      "X_train": 1,
      "x_mod_teste": 1,
      "X_te": 1,
      "real_test": 1,
      "AdaBoost_train_set": 1,
      "AdaBoost_test_set": 1,
      "valid_x": 1,
      "TestData": 1,
      "X_validation": 1,
      "test_df_chunk.drop('click_id', axis=1)": 1,
      "chunk[predictors]": 1,
      "testfeature": 1,
      "tsiftdatax_test": 1,
      "x_test": 1,
      "valid_X": 1,
      "val_vec2": 1,
      "test_val[features]": 1,
      "xtest": 1,
      "test[variables]": 1,
      "test[x_cols]": 1,
      "features_test": 1,
      "test_features": 1,
      "X": 1,
      "x_test[:, 1:]": 1,
      "va_x": 1
    },
    "sklearn.linear_model._logistic.LogisticRegression.__init__.random_state": {
      "None": 4254,
      "0": 257,
      "42": 154,
      "SEED": 84,
      "1": 81,
      "random_state": 39,
      "seed": 35,
      "111": 19,
      "2021": 12,
      "17": 12,
      "123": 11,
      "2020": 11,
      "2": 10,
      "2019": 10,
      "RANDOM_STATE": 9,
      "101": 9,
      "777": 8,
      "13": 7,
      "3": 6,
      "i": 5,
      "RandomState": 5,
      "5": 4,
      "100": 4,
      "RANDOM_SEED": 4,
      "78": 4,
      "555": 4,
      "45": 3,
      "55": 3,
      "1580": 3,
      "7": 3,
      "4": 3,
      "44": 2,
      "33": 2,
      "29": 2,
      "202": 2,
      "666": 2,
      "my_randome_state": 2,
      "8119": 2,
      "RND_ST": 2,
      "376": 2,
      "20": 2,
      "21": 2,
      "12": 2,
      "71": 1,
      "49": 1,
      "34": 1,
      "451": 1,
      "200": 1,
      "80": 1,
      "2018": 1,
      "params['random_state']": 1,
      "self.params['random_state']": 1,
      "53": 1,
      "40": 1,
      "432": 1,
      "25": 1,
      "40 * i": 1,
      "1337": 1,
      "RS": 1,
      "86": 1,
      "4351": 1,
      "333": 1,
      "1812": 1,
      "65": 1,
      "47": 1,
      "41": 1,
      "234": 1,
      "18": 1,
      "102": 1,
      "2017": 1,
      "369": 1,
      "256": 1,
      "12345786": 1,
      "61": 1,
      "10": 1
    },
    "sklearn.tree._classes.DecisionTreeClassifier.predict_proba.X": {
      "X_test": 28,
      "df[feature_col].replace(values_dict).values.reshape(-1, 1)": 8,
      "x_train": 7,
      "X": 7,
      "X_valid": 6,
      "test": 5,
      "X_val": 4,
      "df[feature_col].values.reshape(-1, 1)": 4,
      "x_test": 3,
      "test.drop(columns=['ID_code'])": 3,
      "validate_x_sparse": 2,
      "test_inp": 2,
      "x_train2": 2,
      "X_Val": 2,
      "X_train": 2,
      "X1": 2,
      "validation_X": 2,
      "x2": 2,
      "X_train.Age.to_frame()": 1,
      "X_eval": 1,
      "X_fs_eval": 1,
      "test_t": 1,
      "bs_list_bin.values": 1,
      "real_test": 1,
      "test_df[predictors]": 1,
      "df_comb[cols]": 1,
      "df_comb[cols2]": 1,
      "test_X": 1,
      "df_test": 1,
      "X_f_test[[feature]]": 1,
      "X_test_scaled": 1,
      "X_test_file_scaled": 1,
      "table_tf2": 1,
      "dtest": 1,
      "train[pd.notnull(train[num_features[f]])][features2]": 1,
      "test_merge4": 1,
      "testfeature": 1,
      "tsiftdatax_test": 1,
      "training_set[features].iloc[test_indices]": 1,
      "x_val": 1,
      "X_test.drop(columns=cols_with_nulls)": 1,
      "x_test_tfidf_vec": 1,
      "train[features]": 1,
      "[X_test[i]]": 1,
      "X_test.values.reshape(-1, 1)": 1,
      "xtest": 1,
      "data_test": 1,
      "X_unlabeled": 1,
      "X[train_index]": 1,
      "X[test_index]": 1,
      "test_ensemble_pred": 1,
      "train[bin_cols]": 1,
      "train['bins_reordered'].reshape(-1, 1)": 1,
      "X2": 1,
      "X5": 1,
      "X3": 1,
      "X4": 1,
      "x": 1,
      "test_df": 1,
      "X_test[feature].fillna(0).to_frame()": 1,
      "X_numeric_train": 1,
      "X_numeric_valid": 1,
      "np.array(woe_label_encoder)": 1,
      "test_data_new[features]": 1,
      "test_data.values": 1,
      "b_test": 1,
      "X_test_b": 1,
      "features_test": 1,
      "va_x": 1,
      "test_x[temp_cols]": 1,
      "chunk[temp_cols]": 1
    },
    "sklearn.preprocessing._data.PowerTransformer.fit_transform.X": {
      "X": 8,
      "X_train": 5,
      "train_df[train_df.columns[1:-1]]": 2,
      "train": 2,
      "series": 2,
      "train_data": 2,
      "X[columns].values": 1,
      "test[columns].values": 1,
      "train_X_df": 1,
      "train[target_column].values.reshape(-1, 1)": 1,
      "train_df[raw_cols]": 1,
      "data_dict['test'][raw_cols]": 1,
      "train_features": 1,
      "test_features": 1,
      "data[model_x_columns_without_dummies]": 1,
      "features": 1,
      "np.nan_to_num(full_train_new)": 1,
      "xf": 1,
      "new_train['price_doc'].values.reshape(size, -1)": 1,
      "data": 1,
      "train_data[float_feat]": 1,
      "np.array(cleaned_df[col]).reshape(-1, 1)": 1,
      "data.values.reshape(-1, 1)": 1,
      "data_normalized[data_normalized.columns[:-4]]": 1,
      "train_data[['SalePrice']]": 1
    },
    "sklearn.compose._column_transformer.ColumnTransformer.__init__.transformers": {
      "[('num', numerical_transformer, numerical_cols), ('cat', categorical_transformer, categorical_cols)]": 27,
      "[('num', numeric_transformer, numeric_features), ('cat', categorical_transformer, categorical_features)]": 10,
      "[('num', num_pipeline, num_attribs), ('cat', OneHotEncoder(), cat_attribs)]": 8,
      "[('cat_label_encoder', ordinal_encoder_pipe, label_encoder_vars), ('cat_dummies', dummies_pipe, dummies_vars), ('numerical', numerical_pipe, numerical_vars), ('polynomial', polynomial_pipe, poly_colums)]": 7,
      "[('continuous', continuous_transformer, continuous_features), ('discrete', discrete_transformer, discrete_features)]": 7,
      "[('num', num_transformer, num_features), ('cat', cat_transformer, cat_features)]": 6,
      "[('num', MinMaxScaler(), algo_num_cols), ('cat', 'passthrough', algo_cat_cols)]": 6,
      "[('countvectorizer', vect, 'text')]": 6,
      "[('scale', RobustScaler(), loading_features)]": 5,
      "[('num', num_pipeline, num_attribs), ('cat', cat_pipeline, cat_attribs)]": 4,
      "[('num', num_pipeline, num_feats), ('cat', OneHotEncoder(), cat_feats)]": 4,
      "[('cat', OneHotEncoder(handle_unknown='ignore'), object_feats), ('num', RobustScaler(), numeric_feats)]": 4,
      "[('original', NoTransformer(), no_transform_attribs), ('MinMax', MinMaxScaler(), num_attribs), ('cat_encoder', OneHotEncoder(), cat_attribs)]": 3,
      "[('s', StandardScaler(), [0, 1, 2, 3]), ('o', OneHotEncoder(), [4, 5])]": 3,
      "[('num', num_transformer, num_cols)]": 3,
      "[['oe', OrdinalEncoder(), columns]]": 3,
      "[('num', numeric_transformer, selector(dtype_exclude='object')), ('cat', categorical_transformer, selector(dtype_include='object'))]": 3,
      "[('encoder', OneHotEncoder(), [0, 2])]": 3,
      "transformers": 3,
      "[('encoder', OneHotEncoder(), [0])]": 3,
      "[('cat', categorical_pipe, categorical_columns), ('num', numerical_pipe, numerical_columns)]": 3,
      "[('num', Nums, XE.select_dtypes(include=['int64', 'float64']).columns), ('cat', Text, XE.select_dtypes(include=['object']).columns)]": 3,
      "[('categorical_features', OrdinalEncoder(), categorical_features)]": 3,
      "[('num', num_processor, num_cols), ('cat', cat_processor, cat_cols)]": 2,
      "[('num', num_transformer, ori_cols), ('cat', cat_transformer, ori_cols)]": 2,
      "[('onehot', OrdinalEncoder(), slice(len(CAT))), ('quantile', QuantileTransformer(random_state=SEED, n_quantiles=1500), slice(len(CAT), len(CAT) + len(NUM) + 5))]": 2,
      "[('encoder', OneHotEncoder(drop='first'), ['Pclass', 'Sex', 'Embarked']), ('scaler', MinMaxScaler(), ['Age'])]": 2,
      "[('cat', categorical_transformer, categorical_cols), ('num', numerical_transformer, numerical_cols)]": 2,
      "[('k', TfidfVectorizer(stop_words=STOP_WORDS), 'keyword'), ('t', TfidfVectorizer(stop_words=STOP_WORDS), 'text')]": 2,
      "[('k', TfidfVectorizer(stop_words=STOP_WORDS, tokenizer=lemmatizer), 'keyword'), ('t', TfidfVectorizer(stop_words=STOP_WORDS, tokenizer=lemmatizer), 'text')]": 2,
      "[('num_transform', numerical_transformer, ['age_approx']), ('cat_transform', categorical_transformer, cat_cols)]": 2,
      "t": 2,
      "[('rs', RobustScaler(), num_columns), ('ohe', OneHotEncoder(), cat_columns)]": 2,
      "[('num', StandardScaler(), num_attribs), ('cat', OneHotEncoder(sparse=False), cat_attribs)]": 2,
      "[('pass_pipeline', pass_pipeline, pass_features), ('one_hot_pipeline', one_hot_pipeline, one_hot_features), ('avg_pipeline', avg_pipeline, avg_features)]": 2,
      "[('onehot', OneHotEncoder(categories='auto', sparse=False), categorical_features), ('onehotday', OneHotEncoder(categories=[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]], sparse=False), ['day']), ('standardize', StandardScaler(), standardize_features)]": 2,
      "[('num', numerical_transformer, num_cols), ('cat', categorical_transformer, cat_cols)]": 2,
      "[('numeric', numeric_transformer, numeric_features), ('minmax', minmax_transformer, minmax_features), ('categorical', categorical_transformer, categorical_features)]": 2,
      "[('ohe', ohe, cat_cols_idx)]": 2,
      "[('num', numerical_transformer, numerical_features), ('cat_nom', nominal_transformer, nominal_features), ('ord_nom', ordinal_transformer, ordinal_features)]": 2,
      "[('title', title_transformer, title_col), ('title2', title_transformer2, title_col), ('body', body_transformer, body_col), ('body2', body_transformer2, body_col), ('answer', answer_transformer, answer_col), ('answer2', answer_transformer2, answer_col), ('num', num_transformer, num_cols), ('cat', cat_transformer, cat_cols)]": 2,
      "[['ordinal_encoder', OrdinalEncoder(), categorical_variables]]": 2,
      "[['ordinal_encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), categorical_variables]]": 2,
      "[('num', numerical_transformer, numerical_features), ('cat', categorical_transformer, categorical_features)]": 2,
      "[('numeric', num_pipe, num_feat), ('categorical', cat_pipe, cat_feat)]": 2,
      "[('num', num_pipeline, num_attribs)]": 2,
      "[('scaler', StandardScaler(), num_columns_indexes)]": 2,
      "[('log_fare', FunctionTransformer(np.log1p), [0])]": 2,
      "[('log_fare', FunctionTransformer(), [0])]": 2,
      "[('ohe', OneHotEncoder(handle_unknown='error', drop='first'), cat_columns_indexes)]": 2,
      "[('ohe', FunctionTransformer(), cat_columns_indexes)]": 2,
      "[('poly', PolynomialFeatures(degree=2, include_bias=False, interaction_only=True), num_columns_indexes)]": 2,
      "[('poly', FunctionTransformer(), num_columns_indexes)]": 2,
      "[('impute_age', SimpleImputer(strategy='mean'), [0])]": 2,
      "[('impute_fare', SimpleImputer(strategy='median'), [1])]": 2,
      "[('mmscaler', MinMaxScaler(), [0, 1, 2, 3, 4])]": 2,
      "[('drop_cols', 'drop', drop_cols), ('num_process', num_pipeline, ['budget', 'popularity', 'runtime']), ('add_custom_attrs', CustomAttr(), ['belongs_to_collection', 'release_date']), ('cat_process', cat_pipeline, ['original_language', 'status']), ('jason_handler', JSONHandler(), ['genres', 'production_companies', 'production_countries', 'Keywords', 'cast'])]": 2,
      "[('Q-T', text_encoder, 'question_title'), ('Q-B', text_encoder, 'question_body'), ('A', text_encoder, 'answer'), ('URL', url_encoder, 'url'), ('Categoty', ohe, 'category'), ('W-C', word_counter, ['question_body', 'answer'])]": 2,
      "[('num', numeric_transformer, numeric_cols), ('cat', categorical_transformer, cat_cols)]": 2,
      "[('num', numeric_transformer, numeric_features)]": 2,
      "[('sbm', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_loading_features), ('fnc', FunctionTransformer(down_scale, kw_args={'factor': 1 / 600}, validate=True), col_fnc_features), ('internal_conn', FunctionTransformer(down_scale, kw_args={'factor': 1 / 600}, validate=True), col_internalconn_features), ('external_conn', FunctionTransformer(down_scale, kw_args={'factor': 1 / 600}, validate=True), col_externalconn_features), ('intmultext', FunctionTransformer(down_scale, kw_args={'factor': 1 / 600}, validate=True), col_intmultext_features)]": 2,
      "[('sbm', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_loading_features), ('sbm2', FunctionTransformer(square, validate=True), col_loading_features)]": 2,
      "[('fnc', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_fnc_features), ('internal_conn', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_internalconn_features), ('external_conn', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_externalconn_features), ('intmultext', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_intmultext_features), ('netmat', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_netmat_features), ('netmat2', FunctionTransformer(square, validate=True), col_netmat_features)]": 2,
      "[('one_hot_encoder', OneHotEncoder(categories='auto'), [0])]": 2,
      "[('encoder', OneHotEncoder(), categorical_cols)]": 2,
      "[('num', numeric_transformer, numeric_features), ('num_log', numeric_log_transformer, log_features), ('cat', categorical_transformer, categorical_features)]": 2,
      "[('numeric', numeric_transformer, treat_numeric), ('cat', categorical_transformer, treat_categ)]": 2,
      "[('encoder', OneHotEncoder(), [1, 5, 26, 93, 94])]": 2,
      "[('num_missing', num_imputer, train_df.columns)]": 2,
      "[('num_missing', num_imputer, X_train.columns)]": 2,
      "[('Quest-Title', text_encoder, 'question_title'), ('Question-Bbody', text_encoder, 'question_body'), ('Answer', text_encoder, 'answer'), ('URL', url_encoder, 'url'), ('Categoty', ohe, ['category']), ('Counters', counters, ['question_body', 'answer'])]": 1,
      "[('title', title_transformer, title_col), ('body', body_transformer, body_col), ('num', num_transformer, num_cols)]": 1,
      "[('num', num_pipeline, list(num_attribs)), ('cat', cat_pipeline, list(cat_attribs))]": 1,
      "[('encoder', OneHotEncoder(drop='first'), ['Pclass', 'Sex']), ('scaler', MinMaxScaler(), ['Age'])]": 1,
      "[('encoder', OneHotEncoder(drop='first'), ['Pclass', 'Sex', 'Embarked']), ('scaler', MinMaxScaler(), ['Age', 'Fare'])]": 1,
      "[('cat', categorical_transformer, list(X.select_dtypes(include=['category', 'bool']).columns)), ('num', numeric_transformer, list(X.select_dtypes(include='number').columns))]": 1,
      "[('cat', cat_transformer, cat_features)]": 1,
      "[('scale', RobustScaler(quantile_range=(5, 95)), non_bool_cols)]": 1,
      "[['oe', OrdinalEncoder(), training_df_cat]]": 1,
      "[('encoder', OneHotEncoder(), ['Sex', 'Embarked'])]": 1,
      "[('drop_columns', 'drop', ['id', 'url_legal', 'license', 'excerpt', 'ner_tags', 'pos_tags', 'excerpt_proc', 'nlp_text'])]": 1,
      "[('cat', cat_pipe, categorical), ('num', num_pipe, numerical)]": 1,
      "[('num', trans_num, fts_num)]": 1,
      "[('num', numeric_transformer, numerical_columns), ('cat', categorical_transformer, object_columns)]": 1,
      "[('bin', bin_transformer, BIN_FEATURES), ('nom_low_card', nom_low_card_transformer, NOM_LOW_CARD_FEATURES), ('nom_high_card', nom_high_card_transformer, NOM_HIGH_CARD_FEATURES), ('ord_alphabet', ordinal_alphabet_transformer, ORDINAL_ALPHABET_FEATURES), ('ord_enum', ordibal_enum_transformer, ORDINAL_ENUM_FEATURES), ('cyclic', cyclic_transformer, CYCLIC_FEATURES)]": 1,
      "[('num', numeric_transformer, num_features), ('cat', categorical_transformer, cat_features)]": 1,
      "[('feature_adder', NewFeaturesAdderTransformer(), ['text']), ('text_pipeline', preprocess_pipeline, ['text'])]": 1,
      "[('num_pipeline', num_pipeline, numerical_features)]": 1,
      "[('num', num_pipeline, np.array(num_attribs)), ('cat', cat_pipeline, np.array(cat_attribs))]": 1,
      "[('oh', OneHotEncoder(handle_unknown='ignore'), cat_cols)]": 1,
      "[('number', numeric_pipeline, numerical_features), ('category', categorical_pipeline, categorical_features)]": 1,
      "[('Min Maxing', MinMaxScaler(), scalingCols), ('Encode', OneHotEncoder(handle_unknown='ignore'), encodingCols)]": 1,
      "[('numeric', StandardScaler(), numeric_attributes), ('ordinal', OrdinalEncoder(), ordinal_attributes)]": 1,
      "[('numeric', StandardScaler(), numeric_attributes), ('ordinal', OrdinalEncoder(), ordinal_attributes), ('one_hot', OneHotEncoder(), one_hot_attributes)]": 1,
      "[('prev', PolynomialFeatures(degree=1, include_bias=False), features), ('loc', Pipeline([('label', lb_encoder), ('onehot', oh_encoder)]), 'loc')]": 1,
      "[('cat_onehot', ce_cat, nontarget_features), ('cat_target', ce_target, target_features), ('num_nobin', numeric_transformer1, nonbin_features), ('num_bin', numeric_transformer2, bin_features)]": 1,
      "[('cat', ce_cat, cat_features), ('num', numeric_transformer1, num_features)]": 1,
      "[('num', numerical_transformer_simple, numerical_cols), ('cat', categorical_transformer_simple, categorical_cols)]": 1,
      "[('num', numerical_transformer_pca, numerical_cols), ('cat', categorical_transformer_pca, categorical_cols)]": 1,
      "[('num', numeric_transformer, num_cols), ('cat', categorical_transformer, cat_cols)]": 1,
      "[('down_scale_fnc', FunctionTransformer(down_scale), fnc_features), ('scale_others', 'passthrough', loading_features)]": 1,
      "[('top_k', SelectKBest(f_regression, k=k), fnc_features), ('others', 'passthrough', loading_features)]": 1,
      "[('top_k', PCA(n_components=k), fnc_features), ('others', 'passthrough', loading_features)]": 1,
      "[('top_k', Pipeline([('PCA', PCA(n_components=k)), ('scale', FunctionTransformer(down_scale))]), fnc_features), ('others', 'passthrough', loading_features)]": 1,
      "[('num', n_t, numericals), ('cat', c_t, categoricals)]": 1,
      "[('encoder', OneHotEncoder(), [2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 58, 61, 62, 63, 73, 74])]": 1,
      "[('num', numerical_transformer, numerical_cols), ('cat_lo', categorical_transformer_lo_card, categorical_cols_lo_card), ('cat_hi', categorical_transformer_lo_card, categorical_cols_hi_card)]": 1,
      "[('cat_02', OneHotEncoder(sparse=False, handle_unknown='ignore'), ['EntryHeading', 'ExitHeading', 'City', 'Month', 'f3', 'f4', 'f6', 'EntryType', 'ExitType', 'HourGroup']), ('num_01', StandardScaler(), ['f4', 'Latitude', 'Longitude']), ('num_02', SimpleImputer(strategy='constant', fill_value=0), ['Weekend', 'SameStreetExact']), ('num_03', StandardScaler(), ['DistanceFromCenter'])]": 1,
      "[('categorical', OneHotEncoder(handle_unknown='ignore'), categorical_cols), ('numerical', StandardScaler(), numerical_cols)]": 1,
      "[('num', num_pipeline, numerical_cols), ('cat', cat_pipeline, categorical_cols), ('lab', lab_pipeline, label_cols)]": 1,
      "[('num', numeric_transformer, numeric_features), ('cat', cat_transformer, cat_features)]": 1,
      "[('imputer', imputer, cat)]": 1,
      "[('num', N_trans, X_N), ('cat', C_trans, X_C)]": 1,
      "[('num', numeric_transformer, num_cols), ('cat', object_transformer, object_cols)]": 1,
      "[('somename', StandardScaler(), df_to_scale.columns.tolist())]": 1,
      "preprocessor_steps": 1,
      "[('numerical', StandardScaler(), numerical_columns), ('categorical', OneHotEncoder(handle_unknown='ignore', sparse=False), categorical_columns)]": 1,
      "[('num', num_pipeline, list(titanic_num)), ('cat', cat_pipeline, list(titanic_cat))]": 1,
      "[('s', StandardScaler(), [0, 1, 2, 3, 6, 7, 8, 9]), ('o', OneHotEncoder(), [4, 5])]": 1,
      "[('Sex', OneHotEncoder(), [3, 4, 5, 6])]": 1,
      "[('log_scaling', logTransformer, ['GrLivArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'LotArea', 'AvgRoomSF', 'Shed', 'TotRmsAbvGrd']), ('neighborhood_onehot', OneHotEncoder(categories=[neighborhoodCategories]), ['Neighborhood']), ('neighborhood_grp_onehot', OneHotEncoder(), ['NeighborhoodGroups']), ('lot_shape_onehot', OneHotEncoder(categories=[lotShapeCategories]), ['LotShape']), ('land_slope_onehot', OneHotEncoder(categories=[landSlopeCategories]), ['LandSlope']), ('sale_condition_onehot', OneHotEncoder(categories=[saleCondCategories]), ['SaleCondition']), ('land_contour_onehot', OneHotEncoder(), ['LandContour']), ('zoning_onehot', OneHotEncoder(), ['MSZoning']), ('bldg_type_onehot', OneHotEncoder(), ['BldgType']), ('masvrn_type_onehot', OneHotEncoder(), ['MasVnrType']), ('house_style_onehot', OneHotEncoder(), ['HouseStyle']), ('season_onehot', OneHotEncoder(), ['Season'])]": 1,
      "[('cat', categorical_transformer, categorical_features), ('num', numeric_transformer, numeric_features)]": 1,
      "[('num', numeric_transformer, cont)]": 1,
      "[('cat', categorical_transformer, categorical_cols + high_cardinality)]": 1,
      "[('numerical', SimpleImputer(strategy='median'), cont_features), ('categorical', OneHotEncoder(handle_unknown='ignore'), cat_features)]": 1,
      "[('cat', categorical_transformer, categorical_cols), ('cont', 'passthrough', continuous_cols)]": 1,
      "col_transformers": 1,
      "[('ohe', OneHotEncoder(dtype=float), [1])]": 1,
      "[('bewskjp', v, numerical_cols), ('kjhk', p, cat_colmns)]": 1,
      "[('ohe', enc, ['Sex'])]": 1,
      "[('norm', Normalizer(norm='l2'), ['PassengerId', 'Fare'])]": 1,
      "[('one-hot', OneHotEncoder(sparse=False, handle_unknown='ignore'), custom_column_selector(type_select=['object', 'int64', 'float64'], max_nunique=100)), ('label-encode', OrdinalEncoder(), custom_column_selector(type_select=['object', 'int64', 'float64'], min_nunique=100, max_nunique=1000)), ('identity', 'passthrough', custom_column_selector(type_select=['int64', 'float64'], min_nunique=1000))]": 1,
      "[('one_hot_encode', OneHotEncoder(), ['Pclass', 'Sex', 'Embarked'])]": 1,
      "[('drop', 'drop', drop_att_LR), ('numerical', StandardScaler(), num_att_LR), ('categorical1', OrdinalEncoder(), cat_att1_LR), ('categorical2', OneHotEncoder(), cat_att2_LR)]": 1,
      "[('drop', 'drop', drop_att_BNB), ('numerical', StandardScaler(), num_att_BNB), ('categorical1', OrdinalEncoder(), cat_att1_BNB), ('categorical2', OneHotEncoder(), cat_att2_BNB)]": 1,
      "[('drop', 'drop', drop_att_DT), ('numerical', StandardScaler(), num_att_DT), ('categorical', OrdinalEncoder(), cat_att_DT)]": 1,
      "[('drop', 'drop', drop_att_SVC), ('numerical', StandardScaler(), num_att_SVC), ('categorical1', OrdinalEncoder(), cat_att1_SVC), ('categorical2', OneHotEncoder(), cat_att2_SVC)]": 1,
      "[('num', numerical_transformer, num_cols_to_use), ('cat', categorical_transformer, cols_to_use)]": 1,
      "[('catNo', catNo_pipe, cat_no), ('catOr', catOr_pipe, cat_or), ('num', num_pipe, numerical)]": 1,
      "[('encoder', OneHotEncoder(), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])]": 1,
      "[('cat', categorical_transformer, categorical_cols)]": 1,
      "[('cat', OneHotEncoder(handle_unknown='ignore'), cat_columns)]": 1,
      "[('catOneHot', OneHotEncoder(handle_unknown='ignore'), cat_columns[3:])]": 1,
      "[('imputer_0', imputer_0, imp_list_0), ('imputer_mean', imputer_mean, imp_list_mean), ('imputer_NA', imputer_NA, imp_list_NA), ('imputer_None', imputer_None, imp_list_None), ('imputer_mode', imputer_mode, imp_list_mode)]": 1,
      "[('numerical', 'passthrough', num_idx), ('encode', OneHotEncoder(), cat_idx)]": 1,
      "[('encoder', OneHotEncoder(), [idx for (idx, _) in enumerate(categorical)])]": 1,
      "[('scaler', StandardScaler(), [idx + 10 for (idx, _) in enumerate(continuous[:-1])])]": 1,
      "[('encoder', MultiColumnLabelEncoder(), [idx for (idx, _) in enumerate(categorical)])]": 1,
      "[('num', numerical_transformer, num_cols_train), ('cat', categorical_transformer, low_cardinality_cols)]": 1,
      "[('num', num_pipeline, num_attribs), ('cat', OneHotEncoder(handle_unknown='ignore'), cat_attribs)]": 1,
      "[('text', TfidfVectorizer(), 'text')]": 1,
      "[('num', numeric_prep, numeric_feat), ('cat', category_prep, category_feat)]": 1,
      "[('onehotencoding', OneHotEncoder(), ['category']), ('dropout', 'drop', ['question_title', 'question_body', 'question_user_page', 'answer', 'answer_user_page', 'url', 'host'])]": 1,
      "[('num', numeric_transformer, selector(dtype_exclude='category')), ('cat', categorical_transformer, selector(dtype_include='category'))]": 1,
      "[('num', numeric_pipe, selector(dtype_exclude=['category'])), ('ord_enc', ordinal_encoder, ordinal_cat_columns), ('cat_enc', categorical_encoder, cat_columns)]": 1,
      "[('num', numeric_pipe, selector(dtype_exclude=['category']))]": 1,
      "[('num_transformer', num_transformer, make_column_selector(dtype_include=['int64', 'float64'])), ('cat_transformer', cat_transformer, make_column_selector(dtype_include=['object']))]": 1,
      "[('num_transformer', num_transformer, get_features_to_scale(data)), ('cat_transformer', cat_transformer, make_column_selector(dtype_include=['object']))]": 1,
      "[('num', numerical_transformer, nums_cols), ('categorical', categorical_transformer, cat_cols)]": 1,
      "[('num', numerical_transformer, numeric_columns), ('cat', categorical_transformer, categorical_cols_low)]": 1,
      "[('onehot', OrdinalEncoder(), CAT), ('minmax', MinMaxScaler(), NUM)]": 1,
      "[['oe', OrdinalEncoder(), categorical_features]]": 1,
      "[['oe', OrdinalEncoder(), new_categorical_features]]": 1,
      "[['ohe', OneHotEncoder(), categorical_variables]]": 1,
      "[('drop', 'drop', columns_todrop), ('outlier', Outlier(f=numeric_features), numeric_features), ('numeric_process', numeric_transformer, numeric_features), ('nominal_process', categorical_transformer, categorical_features), ('ordinal_process', ordinal_transformer, ordinal_features)]": 1,
      "[('title', title_transformer, title_col), ('body', body_transformer, body_col), ('num', num_transformer, num_cols), ('cat', cat_transformer, cat_cols)]": 1,
      "[('scale', preprocessing.StandardScaler(), self.scale_features)]": 1,
      "[('drop_columns', 'drop', ['holiday', 'atemp', 'weather', 'season'])]": 1,
      "[('num', num_pip, num_list), ('cat', cat_pip, cat_list)]": 1,
      "[('num', numerical_transformer, numcols), ('cat', categorical_transformer, catcols)]": 1,
      "[('encoder', OneHotEncoder(drop='first'), [0, 1, 3, 4, 7]), ('minMaxScaler', MinMaxScaler(), [2, 8])]": 1,
      "[('ordinal_transformer', OrdinalEncoder(), ord_cols), ('nominal_transformer', OneHotEncoder(handle_unknown='ignore'), nom_cols), ('cyclic_transformer', CyclicEncoder(), cyc_cols)]": 1,
      "[('ordinal_transformer', MeanEncoder(), ord_cols), ('nominal_low_cardinality_transformer', NormalizedFrequencyEncoder(), nom_cols[:5]), ('nominal_high_cardinality_transformer', NormalizedFrequencyEncoder(log_scale=True), nom_cols[5:]), ('cyclic_transformer', CyclicEncoder(), cyc_cols)]": 1,
      "[('bin_0_2', 'passthrough', ['bin_0', 'bin_1', 'bin_2']), ('bin_3_4', FunctionTransformer(func=lambda X: X.replace({'F': 0, 'T': 1, 'N': 0, 'Y': 1}), validate=False), ['bin_3', 'bin_4']), ('nom_0_4', OneHotEncoder(sparse=True, handle_unknown='ignore'), ['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4', 'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']), ('ord', Pipeline(steps=[('replace', ColumnTransformer([('encoder', OrdinalEncoder(categories=[['Novice', 'Contributor', 'Expert', 'Master', 'Grandmaster'], ['Freezing', 'Cold', 'Warm', 'Hot', 'Boiling Hot', 'Lava Hot'], np.sort(train_df['ord_3'].unique()), np.sort(train_df['ord_4'].unique()), np.sort(train_df['ord_5'].unique())]), ['ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5'])], remainder='passthrough')), ('mm_scaler', MinMaxScaler())]), ['ord_0', 'ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5', 'day', 'month'])]": 1,
      "[('encoder', OrdinalEncoder(categories=[['Novice', 'Contributor', 'Expert', 'Master', 'Grandmaster'], ['Freezing', 'Cold', 'Warm', 'Hot', 'Boiling Hot', 'Lava Hot'], np.sort(train_df['ord_3'].unique()), np.sort(train_df['ord_4'].unique()), np.sort(train_df['ord_5'].unique())]), ['ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5'])]": 1,
      "[('num', num_transformer, num_features_final), ('cat_nom', cat_transformer_nominal, cat_features_nominal_final), ('cat_ord', cat_transformer_ordinal, cat_features_ordinal_final)]": 1,
      "[('ohe', OneHotEncoder(handle_unknown='ignore'), categorical), ('scaling', StandardScaler(), numeric)]": 1,
      "[('num', SimpleImputer(strategy='most_frequent'), numeric_columns + ordinal_columns), ('one_hot', OneHotEncoder(), one_hot_columns)]": 1,
      "[('cat', categorical_pipe, categorical_columns), ('num', numerical_pipe, numerical_columns), ('le', ordinal_pipe, ord_columns)]": 1,
      "[('categoricals', cat_processor, get_categorical_columns)]": 1,
      "[('onehot', OrdinalEncoder(), slice(len(cat_features))), ('at', QuantileTransformer(), slice(len(cat_features), len(cat_features) + len(cont_features)))]": 1,
      "[('o', OneHotEncoder(), [0, 1]), ('s', Normalizer(), list(range(3, train.shape[1])))]": 1,
      "[('ohe', OneHotEncoder(handle_unknown='ignore'), cat_idx), ('sc', StandardScaler(), num_idx)]": 1,
      "[('num', num_pipe, num_feat), ('cat', cat_pipe, cat_feat)]": 1,
      "[('num', num_pipe, X_train.select_dtypes(include=['int64', 'float64']).columns), ('cat', cat_pipe, X_train.select_dtypes(include=['object']).columns)]": 1,
      "[('num', numerical_transformer, numerical_cols), ('cat_or', categorical_transformer_ord, cols_encode), ('cat_one', categorical_transformer_onehot, other_encode)]": 1,
      "[('numerical', num_imp, numeric_cols), ('category', cat_imp, category_cols)]": 1,
      "[('regular_num', regular_num_pipeline, ['Lat', 'Long', 'med_age']), ('numbers', num_pipeline, ['population', 'density', 'land_area', 'urban_pop']), ('lags', regular_num_pipeline, [f'ConfirmedCases_{lag}' for lag in lag_list]), ('categorical', categorical_pipeline, ['Country/Region', 'unique_area_key'])]": 1,
      "[('regular_num', regular_num_pipeline, ['Lat', 'Long', 'med_age']), ('numbers', num_pipeline, ['population', 'density', 'land_area', 'urban_pop']), ('lags', regular_num_pipeline, [f'Fatalities_{lag}' for lag in lag_list]), ('categorical', categorical_pipeline, ['Country/Region', 'unique_area_key'])]": 1,
      "imputer": 1,
      "[('No_Imputer', 'passthrough', imputer_cols)]": 1,
      "[('cat', OneHotEncoder(handle_unknown='ignore'), make_column_selector(dtype_include=object))]": 1,
      "[('num', num_transformer, X_train.select_dtypes('number').columns.tolist())]": 1,
      "[('num', num_transformer, X_train.select_dtypes('number').columns.tolist()), ('cat', cat_transformer, X_train.select_dtypes('object').columns.tolist())]": 1,
      "[('oh', oh, ['color']), ('scal', sc, ['bone_length', 'rotting_flesh', 'hair_length', 'has_soul'])]": 1,
      "[('imputation_fare', SimpleImputer(missing_values=np.nan, strategy=hyperpars['imputation']['fare_imputation'], copy=False), ['Fare']), ('imputation_age', KNNImputer(missing_values=np.nan, copy=False), ['Age'])]": 1,
      "[('imputation_fare', SimpleImputer(missing_values=np.nan, strategy=hyperpars['imputation']['fare_imputation'], copy=False), ['Fare']), ('imputation_age', SimpleImputer(missing_values=np.nan, strategy=hyperpars['imputation']['age_imputation'], copy=False), ['Age'])]": 1,
      "[('imputation_fare', SimpleImputer(missing_values=np.nan, strategy=hyperpars['fare_imputation'], copy=False), ['Fare']), ('imputation_age', KNNImputer(missing_values=np.nan, copy=False), ['Age'])]": 1,
      "[('imputation_fare', SimpleImputer(missing_values=np.nan, strategy=hyperpars['fare_imputation'], copy=False), ['Fare']), ('imputation_age', SimpleImputer(missing_values=np.nan, strategy=hyperpars['age_imputation'], copy=False), ['Age'])]": 1,
      "[('tfidf', WordVectorTransformer(), 'excerpt'), ('tfidf_pos', CountVectorizer(), 'pos_tag')]": 1,
      "[(f't_{i}', FeatureHasher(n_features=hash_vector_size, input_type='string'), i) for i in range(n_orig_features)]": 1,
      "[(f't_{i}', FeatureHasher(n_features=hash_vector_size, input_type='string'), i) for i in range(len(hashnominallist))]": 1,
      "[('drop_cols', 'drop', ['id', 'date_first_booking', 'date_account_created', 'signup_method', 'timestamp_first_active', 'signup_app', 'first_device_type', 'first_browser', 'first_affiliate_tracked', 'signup_flow']), ('num_imputer', SimpleImputer(strategy='median'), ['age']), ('cat_imputer', SimpleImputer(strategy='most_frequent'), cat_attrs)]": 1,
      "[('cat_process', cat_pipeline, cat_attrs)]": 1,
      "[('imputer', SimpleImputer(strategy='most_frequent'), cat_attrs)]": 1,
      "[('drop_cols', 'drop', ['street_address', 'listing_id']), ('num_imputer', SimpleImputer(strategy='median'), ['bathrooms', 'bedrooms', 'price', 'latitude', 'longitude']), ('custom_date_attr', CustomDateAttrs(), ['created']), ('custom_num_attrs', CustomNumAttrs(), ['description', 'photos']), ('list_encoder', CustomMultiLabelBinarizer(), ['features']), ('cat_imputer', SimpleImputer(strategy='most_frequent'), cat_attrs)]": 1,
      "[('original', 'passthrough', passthru_features), ('week_minmax', week_minmax, ['Weeks']), ('hundred_minmax', minmax, hundred_features), ('minmax', minmax, minmax_features), ('onehot', oh_enc, onehot_features)]": 1,
      "[('zeros', impute_with_zeros, numerics_should_be_zero), ('median', impute_with_medians, numerics), ('categoricals', categorical_transform, categoricals), ('ordinals', ordinal_transform, ordinals)]": 1,
      "[('zeros', impute_with_zeros, numerics_should_be_zero), ('median', impute_with_medians, numerics_replace_with_median)]": 1,
      "[('num', num_pipeline, num_columns), ('ohe', ohe_pipeline, ohe_columns), ('dict', dict_pipeline, dict_columns), ('other', other_pipeline, oth_columns)]": 1,
      "[('text_length', ApplyFunctionCT(function=text_length), ['question_text']), ('text_words', ApplyFunctionCT(function=text_words), ['question_text']), ('text_density', ApplyFunctionCT(function=text_density), ['question_text']), ('text_title_words', ApplyFunctionCT(function=text_title_words), ['question_text']), ('text_capital_words', ApplyFunctionCT(function=text_capital_words), ['question_text']), ('text_caps_vs_length', ApplyFunctionCT(function=text_caps_vs_length), ['question_text']), ('text_unique', ApplyFunctionCT(function=text_unique), ['question_text']), ('text_words_vs_unique', ApplyFunctionCT(function=text_words_vs_unique), ['question_text'])]": 1,
      "[('CV', TfidfVectorizer(lowercase=True, ngram_range=(1, 1), max_features=max_features_Vectorizer, dtype=np.float32, use_idf=True), 'question_text')]": 1,
      "[('CV', TfidfVectorizer(lowercase=True, ngram_range=(1, 1), max_features=max_features_, dtype=np.float32, use_idf=True), 'question_text')]": 1,
      "[('numerical', num_pipeline, num_attr), ('ordinal', ord_pipeline, ord_attr), ('categorical', cat_pipeline, cat_attr)]": 1,
      "[('num', numerical_transformer, X_train.columns)]": 1,
      "[('num', numeric_transformer, numeric_columns), ('cat', categorical_transformer, categorical_colums)]": 1,
      "[('cat', ohe, cat_vars)]": 1,
      "[('numeric', numeric_transformer, ['Age'])]": 1,
      "[('scaled_continous', Pipeline([('imputer', SimpleImputer()), ('scaler', StandardScaler())]), ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Size', 'Year', 'Day', 'Month', 'WeekOfYear', 'DayOfYear']), ('markdowns', Pipeline([('imputer', SimpleImputer(strategy='constant', fill_value=0)), ('scaler', StandardScaler())]), ['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']), ('categorical', Pipeline([('one_hot', OneHotEncoder(handle_unknown='ignore'))]), ['Store', 'Dept', 'Type', 'HolidayType', 'DayOfWeek']), ('others', 'passthrough', ['IsHoliday'])]": 1,
      "[('labeler', OrdinalEncoder(), ['WeekOfYear', 'Type', 'HolidayType']), ('others', 'passthrough', ['Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'Size', 'Year', 'Day', 'Month', 'DayOfYear', 'Store', 'Dept', 'IsHoliday', 'DayOfWeek'])]": 1,
      "[('num', num_pipeline, num_cols), ('cat', cat_pipeline, cat_cols)]": 1,
      "[('num', numeric_transformer, NUM_FEATURES), ('cat', categorical_transformer, CAT_FEATURES)]": 1,
      "[('num', num_pipe, num_plus), ('ord', StandardScaler(), ords), ('cat', onehot, cat_plus)]": 1,
      "[('num', num_pipe, num_plus), ('ord', StandardScaler(), ords), ('cat', ME_transformer, cat_plus)]": 1,
      "column_list": 1,
      "[('num_pipline', num_pipline, num_attribs), ('cat_pipline', OneHotEncoder(sparse=False, categories='auto'), cat_attribs)]": 1,
      "[('num', numeric_transformer, numeric_col_index), ('cat', categorical_transformer, cat_col_index)]": 1,
      "[('num', numeric_transformer, numeric_columns), ('cat', categorical_transformer, categorical_columns)]": 1,
      "[('Q-T', text_encoder, 'question_title'), ('Q-B', text_encoder, 'question_body'), ('A', text_encoder, 'answer'), ('URL', url_encoder, 'url'), ('Categoty', ohe, 'category'), ('C', counters, ['question_body', 'answer'])]": 1,
      "[num]": 1,
      "[cat]": 1,
      "[('label', label_transformer, label_cols), ('cat', cat_transformer, cat_cols)]": 1,
      "[('num', num_transform, num_cols), ('cat', cat_transform, cat_cols)]": 1,
      "[('num', my_num_preproc, num_col), ('cat', my_cat_preproc, two_cat)]": 1,
      "[('somename', MinMaxScaler(), ['cont0', 'cont1', 'cont2', 'cont3', 'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13'])]": 1,
      "[('someothername', MinMaxScaler(), ['cont0', 'cont1', 'cont2', 'cont3', 'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13'])]": 1,
      "[('num1', numerical_transformer, num_col), ('cat', categorical_transformer, cat_col)]": 1,
      "[('num', numeric_transformer, selector(dtype_exclude='object')), ('cat', categorical_transformer_ord, selector(dtype_include='object'))]": 1,
      "[('ohe', OneHotEncoder(handle_unknown='ignore'), ['keyword'])]": 1,
      "[('cat', categorical_transformer, categorical_features), ('num', numeric_transformer, numeric_features), ('emb', Embarked_transformer, Embarked_features)]": 1,
      "[('num', num_transformer_xgb, num_features_xgb)]": 1,
      "[('cat', categorical_transformer, ['Country_Region', 'Province_State'])]": 1,
      "[('cat', cat_transformer, ['Country_Region', 'Province_State'])]": 1,
      "[('cat', cat_transformer, ['Province_State', 'Date'])]": 1,
      "[('num', numerical_transformer, numerical_cols), ('cat', categorical_transformer, object_cols)]": 1,
      "[('num', numeric_transformer, numeric_features), ('int', integer_transformer, integer_features), ('cat', categorical_transformer, categorical_features)]": 1,
      "[('sbm', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_loading_features), ('fnc', FunctionTransformer(down_scale, kw_args={'factor': 1 / 600}, validate=True), col_fnc_features), ('gm', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_gm_features), ('gm2', FunctionTransformer(square, validate=True), col_gm_features), ('wm', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_wm_features), ('wm2', FunctionTransformer(square, validate=True), col_wm_features), ('csf', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_csf_features), ('csf2', FunctionTransformer(square, validate=True), col_csf_features)]": 1,
      "[('internal_conn', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_internalconn_features), ('external_conn', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_externalconn_features), ('netmat', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_netmat_features)]": 1,
      "[('gm', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_gm_features), ('gm2', FunctionTransformer(square, validate=True), col_gm_features), ('wm', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_wm_features), ('wm2', FunctionTransformer(square, validate=True), col_wm_features), ('csf', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_csf_features), ('csf2', FunctionTransformer(square, validate=True), col_csf_features)]": 1,
      "[('sbm', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_loading_features), ('fnc', FunctionTransformer(down_scale, kw_args={'factor': 1 / 600}, validate=True), col_fnc_features), ('degree', FunctionTransformer(down_scale, kw_args={'factor': optpars['fnc_graph_ridge_degree_scale'][target]}, validate=True), col_degree_features), ('clustering_r', FunctionTransformer(down_scale, kw_args={'factor': optpars['fnc_graph_ridge_clustering_r_scale'][target]}, validate=True), col_clustering_r_features), ('clustering_i', FunctionTransformer(down_scale, kw_args={'factor': optpars['fnc_graph_ridge_clustering_i_scale'][target]}, validate=True), col_clustering_i_features), ('betweenness', FunctionTransformer(down_scale, kw_args={'factor': optpars['fnc_graph_ridge_betweenness_scale'][target]}, validate=True), col_betweenness_centrality_features), ('eigenvec', FunctionTransformer(down_scale, kw_args={'factor': optpars['fnc_graph_ridge_eigenvec_scale'][target]}, validate=True), col_eigenvector_centrality_features), ('gm', FunctionTransformer(down_scale, kw_args={'factor': optpars['fnc_graph_ridge_gm_scale'][target]}, validate=True), col_gm_features), ('csf', FunctionTransformer(down_scale, kw_args={'factor': optpars['fnc_graph_ridge_csf_scale'][target]}, validate=True), col_csf_features)]": 1,
      "[('wm', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_wm_features), ('wm2', FunctionTransformer(square, validate=True), col_wm_features), ('csf', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_csf_features), ('csf2', FunctionTransformer(square, validate=True), col_csf_features), ('gm_all', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_gm_all)]": 1,
      "[('sbm', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_loading_features), ('PNI', FunctionTransformer(down_scale, kw_args={'factor': 1}, validate=True), col_pni)]": 1,
      "[('abc', RobustScaler(), num_columns), ('abc1', OneHotEncoder(), cat_columns)]": 1,
      "[('categorical', transformer_cat, ['Pclass', 'Embarked']), ('numerical', transformer_num, ['Age', 'Fare'])]": 1,
      "[('categorical', transformer_cat, ['Pclass', 'Embarked']), ('numerical', transformer_num, ['Fare']), ('age', transformer_age, ['Age'])]": 1,
      "[('cat', categorical_transformer, categorical_features), ('text', text_to_vector_transformer, 'clean_text')]": 1,
      "[('num', SimpleImputer(), numerical_cols), ('cat', OneHotEncoder(), categorical_cols)]": 1,
      "[('top10_interactions', PolynomialFeatures(2, interaction_only=True, include_bias=False), [44, 45, 41, 42, 43, 62, 5, 60, 63, 6])]": 1,
      "[('num', num_transformer, num_cols), ('cat', cat_transformer, cat_cols)]": 1,
      "[('encoder', OneHotEncoder(), [0, 1, 4])]": 1,
      "[('GENE', gene_variance, GENE), ('CELL', cell_variance, CELL), ('CAT', cat_pipe, CAT)]": 1,
      "[('encoder', OneHotEncoder(), [-1])]": 1,
      "[('numeric', numeric_pipeline, numeric_columns), ('categorical', categorical_pipeline, categorical_columns)]": 1,
      "[('numeric', ppl_num, num_features), ('categorical', ppl_cat, cat_features)]": 1,
      "[('Important', 'passthrough', keep_columns)]": 1,
      "[('cat', OneHotEncoder(), cat_cols), ('num', num_pipeline, numerical_cols)]": 1,
      "[('budget_trans', budget_trans, ['budget']), ('company_trans', company_pipe, ['production_companies']), ('country_trans', country_pipe, ['production_countries']), ('date_trans', date_pipe, ['release_date']), ('genre_trans', genre_pipe, ['genres']), ('keyword_trans', keyword_pipe, ['Keywords']), ('language_trans', language_pipe, ['original_language']), ('log_trans', log_trans, ['budget', 'popularity']), ('missing_trans', missing_trans, ['belongs_to_collection', 'homepage', 'tagline']), ('poly_trans', interaction_trans, ['budget', 'popularity']), ('runtime_imputer', median_imputer, ['runtime']), ('spoken_lang_trans', spoken_language_pipe, ['spoken_languages']), ('title_trans', title_trans, 'original_title')]": 1,
      "[('text_glove', SpacyVectorTransformer(nlp), 'text')]": 1,
      "[('num_log_tf', FunctionTransformer(func=np.log), log_transform_cols), ('cat_encoder', CatEncoderNan(cat_cols), cat_cols)]": 1,
      "[('drop', 'drop', columns_todrop), ('numeric_process', numeric_transformer, numeric_features), ('nominal_process', categorical_transformer, categorical_features), ('ordinal_process', ordinal_transformer, ordinal_features)]": 1,
      "[('cat_transformer', categorical_transformer, ['keyword', 'location']), ('text_transformer', text_transformer, ['text'])]": 1,
      "[('cat', OneHotEncoder(), cat_cols), ('num', MinMaxScaler(), num_cols)]": 1,
      "[('numerical', numerical_transformer, num_features), ('categorical', categorical_transformer, cat_features)]": 1,
      "[('num', num_pipeline, NUM_FEATURES), ('cat', cat_pipeline, CAT_FEATURES)]": 1,
      "[('num', numerical_transfer, numerical_cols), ('cat', catagorical_transfer, catagorical_cols)]": 1,
      "[('num', num_transformer, num_cols), ('cat_with_two_vals', cat_transformer_two_vals, cat_cols_with_two_vals), ('cat_with_more_than_two_vals', cat_transformer_more_vals, cat_cols_with_more_vals)]": 1,
      "[('cat_nominal_encoder', cat_nominal_encoder, Categorical_nominal_columns)]": 1,
      "[('num', numerical_transformer, numerical_columns), ('cat', categorical_transformer, categorical_columns)]": 1,
      "[('mcat', ohe(), mCat_cols), ('num', ss(), num_cols)]": 1,
      "[('impute-onehot', embark_pipeline, ['Embarked']), ('impute-std', age_fare_pipeline, ['Age', 'Fare']), ('onehot', OneHotEncoder(), ['Pclass', 'Sex'])]": 1,
      "[('cat_O', categorical_O_transformer, categorical_cols_O), ('cat_L', categorical_L_transformer, categorical_cols_L), ('num', numerical_transformer, numerical_cols)]": 1,
      "[('original', NoTransformer(), no_transform_attribs), ('StdScaler', StandardScaler(), num_attribs), ('cat_encoder', OneHotEncoder(), cat_attribs)]": 1,
      "[('num', numerical_transformer, continuous_columns), ('cat', categorical_transformer, categorical_columns)]": 1,
      "[('distance', DistanceTransformer(), ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']), ('time', pipe_time, ['pickup_datetime'])]": 1,
      "[('LandContour', OneHotEncoder(drop='first'), ['LandContour']), ('LotConfig', OneHotEncoder(drop='first'), ['LotConfig']), ('MSZoning_filledNaNs', OneHotEncoder(drop='first'), ['MSZoning_filledNaNs']), ('BldgType', OneHotEncoder(drop='first'), ['BldgType']), ('HouseStyle', OneHotEncoder(drop='first'), ['HouseStyle']), ('Neighborhood', OneHotEncoder(drop='first'), ['Neighborhood']), ('LotShape', OneHotEncoder(drop='first'), ['LotShape']), ('ExterQual', OneHotEncoder(drop='first'), ['ExterQual']), ('KitchenQual_filledNaNs', OneHotEncoder(drop='first'), ['KitchenQual_filledNaNs']), ('Functional_filledNaNs', OneHotEncoder(drop='first'), ['Functional_filledNaNs']), ('SaleType_filledNaNs', OneHotEncoder(drop='first'), ['SaleType_filledNaNs']), ('SaleCondition', OneHotEncoder(drop='first'), ['SaleCondition']), ('Electrical_filledNaNs', OneHotEncoder(drop='first'), ['Electrical_filledNaNs']), ('BsmtQual_filledNaNs', OneHotEncoder(drop='first'), ['BsmtQual_filledNaNs'])]": 1,
      "[('onehot', ohe, [0, 1, 2]), ('minmax', scaler, [i + 3 for i in range(cfg['num_features'])])]": 1,
      "[('cat', cat_pipeline, cat_features), ('num', num_pipeline, num_features)]": 1,
      "[('num', numerical_transformer, numericalCols), ('cat', categorical_transformer, categoricalCols)]": 1,
      "[('Q-T', text_encoder, 'question_title'), ('Q-B', text_encoder, 'question_body'), ('A', text_encoder, 'answer'), ('Category', ohe, 'category')]": 1,
      "[('drop_cols', 'drop', ['street_address', 'listing_id']), ('num_imputer', SimpleImputer(strategy='median'), ['bathrooms', 'bedrooms', 'price', 'latitude', 'longitude']), ('custom_date_attr', CustomDateAttrs(), ['created']), ('custom_num_attrs', CustomNumAttrs(), ['description', 'photos', 'building_id', 'manager_id', 'display_address']), ('list_encoder', CustomMultiLabelBinarizer(), ['features'])]": 1,
      "[('nums', Pipeline([('Imputr', simpImp), ('Scalr', sdScaler)]), features_num), ('cats', Pipeline([('OneHot', onehotEncoder)]), features_cat)]": 1,
      "[('nums', Pipeline([('Imputr', simpImp), ('Scalr', sdScaler)]), features_num), ('cats', Pipeline([('targetEnc', targetEncoder)]), features_cat)]": 1
    },
    "sklearn.compose._column_transformer.ColumnTransformer.fit_transform.X": {
      "X_train": 44,
      "X": 29,
      "train": 15,
      "x_train": 8,
      "train_df": 7,
      "train_X": 6,
      "X_treino": 6,
      "test": 5,
      "train_dropped": 4,
      "df": 4,
      "df_train": 3,
      "df_test": 3,
      "housing_X": 3,
      "titanic": 3,
      "x": 3,
      "X_test": 3,
      "data_df": 2,
      "xtest": 2,
      "train_features": 2,
      "data": 2,
      "housing": 2,
      "subset_data": 2,
      "optimization_features": 2,
      "test_df": 2,
      "train_data[features_num]": 2,
      "Xx": 2,
      "X_tr": 2,
      "X_val": 2,
      "train_final": 1,
      "train_validation": 1,
      "df_X_train": 1,
      "df_train[all_features]": 1,
      "X_train[cols]": 1,
      "x[columns]": 1,
      "testing_df_model_one[columns]": 1,
      "testing_df_model_two[columns]": 1,
      "xtrain": 1,
      "t": 1,
      "df_validation": 1,
      "df_to_scale": 1,
      "df_train.iloc[:, 1:-2]": 1,
      "result": 1,
      "X_train_pp_df": 1,
      "X_and_test": 1,
      "train_X_dropped": 1,
      "training_data.iloc[:, :-1]": 1,
      "train_data_filled": 1,
      "X_pca": 1,
      "train_X_df": 1,
      "train_data": 1,
      "all_data2": 1,
      "X_log": 1,
      "log_test": 1,
      "ord345": 1,
      "hashnominal": 1,
      "train.drop(['SalePrice'], axis=1)": 1,
      "data_train[data_train['Pclass'] == 1]": 1,
      "data_train[data_train['Pclass'] == 2]": 1,
      "data_train[data_train['Pclass'] == 3]": 1,
      "housing_train": 1,
      "some_data": 1,
      "housing_test": 1,
      "df.drop('label', axis=1)": 1,
      "X_train1": 1,
      "X_train2": 1,
      "valid_df": 1,
      "test_features": 1,
      "housing1": 1,
      "df_train_store": 1,
      "data_df.loc[:, CAT + GENE + CELL]": 1,
      "data_df.loc[train, CAT + GENE + CELL]": 1,
      "f_data_train": 1,
      "test_set": 1,
      "dataset_training_new": 1
    },
    "sklearn.compose._column_transformer.ColumnTransformer.transform.X": {
      "X_test": 33,
      "test": 13,
      "X": 9,
      "x_test": 8,
      "test_data": 8,
      "X_val": 7,
      "X_valid": 6,
      "test_dropped": 5,
      "validation_x": 5,
      "val_X": 4,
      "X_train": 4,
      "df_test_sub.iloc[:, 1:]": 4,
      "test[features]": 3,
      "test_x": 3,
      "x_train": 3,
      "df_test[used_feats]": 3,
      "x[feature_columns]": 3,
      "test_df": 3,
      "test_X": 2,
      "X_validation": 2,
      "some_data": 2,
      "df[df['Date'] == date]": 2,
      "test_data[features_num]": 2,
      "valid_df": 2,
      "X_pred": 2,
      "x_valid": 1,
      "df_X_valid": 1,
      "df_test[all_features]": 1,
      "X_valid[cols]": 1,
      "X_test[cols]": 1,
      "x_val": 1,
      "housing_df_x": 1,
      "housing_test": 1,
      "train_merged[features]": 1,
      "test_merged[features]": 1,
      "test_features": 1,
      "X_test_pp_df": 1,
      "submit": 1,
      "train": 1,
      "v2_train": 1,
      "v2_test": 1,
      "v5_test": 1,
      "preprocessed_X_test": 1,
      "test_data_filled": 1,
      "train[train_col]": 1,
      "test[train_col]": 1,
      "test_data_engineered": 1,
      "df_test": 1,
      "new_df": 1,
      "submit_np": 1,
      "validation_features": 1,
      "full_test_data.loc[:, features]": 1,
      "test_df[df.drop('label', axis=1).columns]": 1,
      "X_test1": 1,
      "X_test2": 1,
      "data": 1,
      "app_test.drop(['SK_ID_CURR', 'SK_ID_CURR'], axis=1)": 1,
      "X_app_test": 1,
      "data_df.loc[test, CAT + GENE + CELL]": 1,
      "test_df.loc[:, CAT + GENE + CELL]": 1,
      "dataset_test_new": 1,
      "X_submission": 1,
      "Xtest": 1,
      "df_submission1": 1,
      "train[features]": 1
    },
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.max_df": {
      "1.0": 2662,
      "0.9": 163,
      "0.5": 83,
      "500": 51,
      "0.95": 41,
      "0.8": 26,
      "0.25": 22,
      "0.57": 22,
      "0.3": 17,
      "0.7": 17,
      "0.85": 16,
      "0.6": 13,
      "0.4": 13,
      "0.99": 10,
      "1": 7,
      "0.75": 6,
      "max_df": 5,
      "0.999": 4,
      "0.05": 4,
      "0.15": 4,
      "self.max_df": 2,
      "0.65": 2,
      "30": 2,
      "0.98": 2,
      "0.1": 2,
      "0.2": 2,
      "0.82": 1,
      "5": 1,
      "0.625": 1,
      "0.11": 1,
      "0.54": 1,
      "0.995": 1,
      "200": 1,
      "MAX_DF_TF": 1,
      "600": 1,
      "800": 1,
      "0.67": 1,
      "1000": 1,
      "505": 1,
      "0.93": 1,
      "0.001": 1,
      "self.tfidf_max_df": 1,
      "maxdf": 1
    },
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.encoding": {
      "'utf-8'": 3181,
      "'latin-1'": 29,
      "'KOI8-R'": 4,
      "'utf8'": 1
    },
    "sklearn.linear_model._logistic.LogisticRegression.__init__.multi_class": {
      "'auto'": 4689,
      "'multinomial'": 361,
      "'ovr'": 69,
      "'warn'": 10
    },
    "sklearn.linear_model._logistic.LogisticRegression.__init__.max_iter": {
      "100": 4425,
      "1000": 152,
      "500": 98,
      "10000": 97,
      "2000": 59,
      "200": 46,
      "5000": 44,
      "300": 39,
      "400": 18,
      "2020": 14,
      "100000": 12,
      "250": 9,
      "4000": 8,
      "150": 8,
      "20": 6,
      "50": 6,
      "500000": 5,
      "1500": 5,
      "3000": 5,
      "10": 4,
      "800": 4,
      "600": 4,
      "50000": 4,
      "60": 4,
      "20600": 3,
      "200000": 3,
      "80": 3,
      "self.max_iter": 2,
      "iterations": 2,
      "450": 2,
      "max_iter_param": 2,
      "40000": 2,
      "10**5": 2,
      "900": 2,
      "75": 2,
      "set_max_iter": 1,
      "trial.suggest_int('max_iter', 50, 2000, 50)": 1,
      "10**2": 1,
      "int(1000000.0)": 1,
      "8": 1,
      "10000000": 1,
      "2019": 1,
      "params['max_iter']": 1,
      "self.params['max_iter']": 1,
      "8000": 1,
      "25": 1,
      "7888888": 1,
      "10000.0": 1,
      "best_max_iter": 1,
      "max_depth": 1,
      "225": 1,
      "500 * i": 1,
      "model_config['max_iter']": 1,
      "gridcv.best_params_['max_iter']": 1,
      "120000": 1,
      "550": 1,
      "30": 1,
      "96": 1,
      "6": 1,
      "45": 1,
      "100000.0": 1,
      "2500": 1,
      "Max_iter": 1
    },
    "sklearn.linear_model._logistic.LogisticRegression.__init__.verbose": {
      "0": 5055,
      "1": 56,
      "10": 6,
      "False": 4,
      "True": 3,
      "100": 2,
      "5": 2,
      "2": 1
    },
    "sklearn.linear_model._logistic.LogisticRegression.__init__.fit_intercept": {
      "True": 5106,
      "False": 14,
      "all_parameters['fit_intercept'][j]": 4,
      "params_log['fit_intercept']": 2,
      "trial.suggest_categorical('fit_intercept', [True, False])": 1,
      "params['fit_intercept']": 1,
      "self.params['fit_intercept']": 1
    },
    "sklearn.model_selection._split.RepeatedStratifiedKFold.__init__.n_splits": {
      "5": 47,
      "10": 43,
      "n_splits": 8,
      "20": 6,
      "num_folds": 4,
      "3": 4,
      "25": 4,
      "n_folds": 2,
      "n_fold": 2,
      "splits": 2,
      "CV_SPLITS": 2,
      "nr_folds": 1,
      "7": 1,
      "2": 1,
      "N_SPLITS": 1
    },
    "sklearn.model_selection._split.RepeatedStratifiedKFold.__init__.n_repeats": {
      "3": 36,
      "10": 18,
      "5": 18,
      "20": 16,
      "2": 13,
      "n_repeats": 10,
      "1": 5,
      "repeats": 4,
      "REPEATS": 4,
      "CV_REPEATS": 2,
      "nr_runs": 1,
      "N_REPEATS": 1
    },
    "sklearn.model_selection._split.RepeatedStratifiedKFold.__init__.random_state": {
      "42": 37,
      "None": 24,
      "1": 20,
      "SEED": 6,
      "1337": 4,
      "FOLD_RANDOM_SEED": 4,
      "rs": 3,
      "0": 3,
      "10": 3,
      "123": 3,
      "7": 3,
      "2": 2,
      "2019": 2,
      "65": 2,
      "SEED_CV": 2,
      "1234": 2,
      "random_state": 1,
      "34": 1,
      "3": 1,
      "RANDOM_STATE": 1,
      "2434": 1,
      "13": 1,
      "50": 1,
      "16": 1
    },
    "sklearn.preprocessing._data.scale.X": {
      "X": 68,
      "X_train": 22,
      "X_sel": 20,
      "X_test": 18,
      "test": 4,
      "X_train_part1[:, :-4]": 4,
      "X_test_part2[:, :-4]": 4,
      "X_test[:, :-4]": 4,
      "test_data": 4,
      "X_all": 3,
      "mfccs": 3,
      "df_test": 3,
      "list(map(getHourZn, data['Dates'].dt.hour))": 3,
      "list(map(lambda x: x + 122.4194, data.X))": 3,
      "list(map(lambda x: x - 37.7749, data.Y))": 3,
      "X_new": 3,
      "unscaled_inputs_equal_priors": 3,
      "x_train": 3,
      "dftrain_processed": 2,
      "train_x": 2,
      "test_x": 2,
      "X_valid": 2,
      "x": 2,
      "gene_data": 2,
      "cell_via_data": 2,
      "unscaled_sub": 2,
      "x_test": 2,
      "y": 2,
      "g_stats": 2,
      "c_stats": 2,
      "df_train_co_pop[['Population']]": 2,
      "df_test_co_pop[['Population']]": 2,
      "X_transform": 2,
      "np.array(df_merged, dtype='float32')": 2,
      "spectrogram": 2,
      "X_trn": 1,
      "X_tst": 1,
      "data": 1,
      "list(total.loc[nonzero_rows, col])": 1,
      "list(total[col])": 1,
      "df_scaled": 1,
      "X_eda": 1,
      "OH_X_train[numerical_cols]": 1,
      "OH_X_valid[numerical_cols]": 1,
      "df_fe": 1,
      "train.drop(['is_attributed', 'click_time', 'attributed_time'], axis=1)": 1,
      "dataset.drop('target', axis=1).values": 1,
      "X_training": 1,
      "meta_train_X": 1,
      "meta_test_X": 1,
      "X_origin": 1,
      "X_pca": 1,
      "train[train.Response == 0][features].values": 1,
      "test[features].values": 1,
      "df['price'].tolist()": 1,
      "df['price'].as_matrix() / (1 + df['bedrooms'].as_matrix())": 1,
      "df['price'].as_matrix() / (1 + df['bathrooms'].as_matrix())": 1,
      "df['description'].fillna('0').apply(lambda x: np.log(1 + len(x)))": 1,
      "df['description'].apply(len)": 1,
      "df_all_without_survived": 1,
      "train_data": 1,
      "train_signal": 1,
      "val_signal": 1,
      "X_original": 1,
      "test_gene_data": 1,
      "test_cell_via_data": 1,
      "total_df.loc[nonzero_rows, col].values": 1,
      "x_validate": 1,
      "subt_data": 1,
      "train_c": 1,
      "agg_hist['hist_pur_date_ptp']": 1,
      "agg_new['new_pur_date_ptp']": 1,
      "agg_hist['hist_pur_date_max']": 1,
      "agg_new['new_pur_date_max']": 1,
      "agg_hist['hist_pur_date_min']": 1,
      "agg_new['new_pur_date_min']": 1,
      "x_train[:, i]": 1,
      "X_new_test": 1,
      "list(map(lambda x: x + 122.4194, train.X))": 1,
      "list(map(lambda x: x - 37.7749, train.Y))": 1,
      "list(map(lambda x: x + 122.4194, test.X))": 1,
      "list(map(lambda x: x - 37.7749, test.Y))": 1,
      "cluster_data": 1,
      "kmeans_mean_cluster": 1,
      "new_df": 1,
      "features_train[column_numerics]": 1,
      "model_df[['T1_powerrank', 'T2_powerrank', 'T1_seed', 'T2_seed', 'T1_rank', 'T2_rank']]": 1,
      "train_df[['T1_powerrank', 'T2_powerrank', 'T1_seed', 'T2_seed', 'T1_rank', 'T2_rank', 'seed_diff', 'rank_diff', 'powerrank_diff']]": 1,
      "test_df[['T1_powerrank', 'T2_powerrank', 'T1_seed', 'T2_seed', 'T1_rank', 'T2_rank', 'seed_diff', 'rank_diff', 'powerrank_diff']]": 1,
      "dataset[:, :-1]": 1,
      "training_data_scaled[col]": 1,
      "df[scalable_cols]": 1,
      "df_train.GrLivArea.values": 1,
      "df_train.GarageArea.values": 1,
      "total_df.loc[nonzero_rows, col]": 1,
      "df.drop(['species', 'label'], 1)": 1,
      "modeldata.loc[:, :]": 1,
      "train_data['Age']": 1,
      "test_data['Age']": 1,
      "np.where(df_selected[col] != 0, np.log(df_selected[col]), 0)": 1,
      "df_selected[col]": 1,
      "pca.transform(submission_transformed.iloc[:, good_features])": 1,
      "train.iloc[:, 2:]": 1,
      "train.iloc[:, 1:]": 1,
      "data_num.drop(columns={'SalePrice'})": 1,
      "df_model": 1,
      "whole_data": 1,
      "X1": 1,
      "test_X": 1,
      "X_dat_pca": 1,
      "test_data_pca": 1,
      "final_train['Pclass']": 1,
      "final_train['Age']": 1,
      "final_train['Fare']": 1,
      "final_train['Embarked']": 1,
      "target['Pclass']": 1,
      "target['Age']": 1,
      "target['Fare']": 1,
      "target['Embarked']": 1,
      "x.astype(float)": 1,
      "temp.values": 1,
      "mfcc_spec": 1,
      "unscaled_inputs_train": 1,
      "unscaled_inputs_submission": 1,
      "unscaled_inputs_Dig": 1,
      "train": 1,
      "XX": 1,
      "XX_test": 1,
      "test_ds.iloc[:, 1:]": 1,
      "tnt[cols]": 1,
      "data_num": 1,
      "mean_lst[i]['reserve_visitors']": 1,
      "mean_lst[i]['diff_vr']": 1,
      "gFeature": 1,
      "cFeature": 1,
      "shops['total_sales']": 1,
      "shops['avg_monthly_sales']": 1,
      "shops['n_categories_sold']": 1,
      "shops['sales_slope']": 1,
      "shop_data['item_price']": 1
    },
    "sklearn.neighbors._classification.KNeighborsClassifier.predict_proba.X": {
      "X_test": 54,
      "cell_test": 40,
      "df_cell_test.values": 26,
      "test3": 19,
      "train3[test_index, :]": 15,
      "X_valid": 6,
      "X_cv": 5,
      "X_train": 4,
      "X_val": 4,
      "x1": 4,
      "xdat": 4,
      "test[idx_te][col]": 3,
      "test": 3,
      "train3[test_index3, :]": 3,
      "x.loc[valid_index][cols_important]": 3,
      "x_test[cols_important]": 3,
      "feature_frames['test']": 2,
      "X": 2,
      "x_test": 2,
      "X_train[val_idx]": 2,
      "X_test_pca": 2,
      "e__[-len(mtest):]": 2,
      "p": 2,
      "X_tst": 1,
      "X_eval": 1,
      "X_fs_eval": 1,
      "ts": 1,
      "X_te": 1,
      "real_test": 1,
      "probaFeatureTest": 1,
      "test_X_std": 1,
      "valid_x": 1,
      "test[features]": 1,
      "test_s": 1,
      "X_test_scaled": 1,
      "X_test_file_scaled": 1,
      "slim_train_features[test_index, :]": 1,
      "slim_test_features": 1,
      "testfeature": 1,
      "tsiftdatax_test": 1,
      "test_data.values[0:, 1:]": 1,
      "scaler.transform(test[['day_of_week_encoded', 'pd_district_encoded', 'x', 'y', 'hour']])": 1,
      "x_train": 1,
      "test_data": 1,
      "X_test_ol": 1,
      "X_Test_ol": 1,
      "X_valid[cols]": 1,
      "test[cols]": 1,
      "S": 1,
      "[X_test[i]]": 1,
      "train3[valid_index]": 1,
      "X1": 1,
      "transformed_data_predict": 1,
      "val_x": 1,
      "X[:10]": 1,
      "y_pred[:, 96:96 + 20]": 1,
      "ans": 1,
      "testX": 1,
      "test_prep[5].reshape(1, -1)": 1,
      "test_x.multiply(r)": 1,
      "X_train_sub": 1,
      "X_test_sub": 1,
      "test_cell.values": 1,
      "X_new": 1,
      "df_train.iloc[ktrain][cols]": 1,
      "df_train.iloc[ktest][cols]": 1,
      "X_19_colley": 1,
      "X_19": 1,
      "test_X": 1,
      "va_x": 1
    },
    "sklearn.cluster._kmeans.KMeans.__init__.n_jobs": {
      "'deprecated'": 887,
      "-1": 24,
      "None": 6,
      "2": 3,
      "4": 3,
      "n_jobs": 2,
      "-2": 1,
      "8": 1,
      "5": 1
    },
    "sklearn.metrics._regression.r2_score.y_true": {
      "y_test": 560,
      "y_train": 186,
      "y_val": 101,
      "y_valid": 78,
      "model.predict(dtrain)": 55,
      "y": 53,
      "labels": 49,
      "dtrain.get_label()": 37,
      "y_true": 30,
      "Y_test": 27,
      "y_pred": 27,
      "true": 26,
      "y_train_m": 22,
      "val_y": 21,
      "train.y": 18,
      "pred": 16,
      "Y_train": 16,
      "df_joined['target']": 15,
      "y_test_scaled": 14,
      "Y_valida": 13,
      "ytest": 13,
      "test_Y": 13,
      "test_y": 12,
      "label": 12,
      "target": 12,
      "y_train_pred": 11,
      "Y_valid": 11,
      "Y": 10,
      "y_train_level2": 10,
      "yLabelsLog": 10,
      "y_tr": 9,
      "y_germany[-best_size_g:]": 9,
      "y_holdout": 8,
      "ytrain": 8,
      "y[-best_size_n:]": 8,
      "y_train.values.flatten()": 7,
      "y[test_index]": 7,
      "train_price": 6,
      "test_price": 6,
      "y_teste": 6,
      "y_test1": 6,
      "y_test2": 6,
      "df[target_col]": 6,
      "lasso.predict(X)": 5,
      "pred1": 5,
      "dtrain_.get_label()": 5,
      "y_validacao": 4,
      "y_c": 4,
      "y_f": 4,
      "y_test_": 4,
      "y_test_bc": 4,
      "yt": 4,
      "y[test_start:]": 4,
      "model_lgb.predict(X)": 4,
      "model_xgb.predict(X)": 4,
      "cb_model.predict(X)": 4,
      "prediction": 4,
      "y_ts.as_matrix()": 4,
      "y_eval": 4,
      "labels_test2": 4,
      "Model_y_test": 4,
      "train_df['target']": 4,
      "df['rentals']": 4,
      "d_set[3]": 4,
      "Y_Val": 3,
      "joined['target']": 3,
      "pred_df['true']": 3,
      "Y_Test": 3,
      "raw_train_y": 3,
      "testY": 3,
      "np.expm1(y_valid)": 3,
      "np.expm1(y_train)": 3,
      "y_train_b": 3,
      "YVal": 3,
      "y_OfT": 3,
      "y_test_pred": 3,
      "SGD.predict(X)": 3,
      "rcc.predict(X)": 3,
      "KRR.predict(X)": 3,
      "BR.predict(X)": 3,
      "ENet.predict(X)": 3,
      "y2_test": 3,
      "y[:800]": 3,
      "y[800:]": 3,
      "sub_y.values[:int(len(sub_y) * ratio)]": 3,
      "sub_y.values[int(len(sub_y) * ratio):]": 3,
      "actual": 3,
      "y2_train": 3,
      "y_mul": 3,
      "targetb": 3,
      "target_testb": 3,
      "target_test": 3,
      "targetvar": 2,
      "y_val2": 2,
      "predictions": 2,
      "y_test_inv": 2,
      "data['estimated_generation_gwh']": 2,
      "valid": 2,
      "valid_LB1": 2,
      "valid_PB1": 2,
      "valid_LB2": 2,
      "valid_PB2": 2,
      "valid_LB3": 2,
      "valid_PB3": 2,
      "valid_LB4": 2,
      "valid_PB4": 2,
      "valid_LB5": 2,
      "valid_PB5": 2,
      "y_hat": 2,
      "pd.DataFrame(y_test)": 2,
      "test[outcome]": 2,
      "ground_truth": 2,
      "y_test['ConfirmedCases']": 2,
      "y_test['Fatalities']": 2,
      "ln_target": 2,
      "yb.cpu().numpy()": 2,
      "y.cpu().numpy()": 2,
      "part_B_y": 2,
      "part_C_y": 2,
      "y_pred_df['y_val']": 2,
      "self.Y_train['y']": 2,
      "self.Y_test": 2,
      "Y.reshape(-1, 1)": 2,
      "y_train[ktest]": 2,
      "my_list": 2,
      "y1_test": 2,
      "y12_forest_test": 2,
      "validate_y": 2,
      "y_dev": 2,
      "y_pred_rf": 2,
      "Y_train[valid_idx]": 2,
      "y_pred_rf_three": 2,
      "y1": 2,
      "xref['ydat']": 2,
      "total_0.y": 2,
      "Ytest": 2,
      "X.loc[~X['ConfirmedCases'].isna()]['ConfirmedCases']": 2,
      "Y_trainer": 2,
      "Y_train_val": 2,
      "dmat.get_label()": 2,
      "df_train['y']": 2,
      "Confirmed_data_value": 2,
      "y_train_0": 2,
      "y2_xTest_CS": 2,
      "yhat": 2,
      "Y1": 1,
      "Y2": 1,
      "lr_pred": 1,
      "dt_pred": 1,
      "rf_pred": 1,
      "ab_pred": 1,
      "gb_pred": 1,
      "xgb_pred": 1,
      "lgbm_pred": 1,
      "y_val_pred": 1,
      "y_val1": 1,
      "ty_test0": 1,
      "y_train_final_c": 1,
      "y_train_final_f": 1,
      "t_true": 1,
      "t_test_2": 1,
      "t_test_1": 1,
      "t_test_3": 1,
      "Y_predict": 1,
      "test[['Fee']]": 1,
      "x_test['AdoptionSpeed']": 1,
      "Xtest_y": 1,
      "y_monthly_train": 1,
      "y_monthly_test": 1,
      "test_set['wx']": 1,
      "test_set['wy']": 1,
      "test_set['wz']": 1,
      "y_test_std": 1,
      "y_test2_std": 1,
      "y_predict_linreg": 1,
      "y_predict_rf": 1,
      "y_train[:300]": 1,
      "df_train['target']": 1,
      "predicted_values": 1,
      "y_test.astype(int)": 1,
      "y2": 1,
      "x": 1,
      "bgg.predict(x_train)": 1,
      "rf_preds": 1,
      "y_train[train_index]": 1,
      "y_train[test_index]": 1,
      "plays['epa']": 1,
      "regressor.predict(X)": 1,
      "test_y_": 1,
      "original_df.sales[-28:]": 1,
      "val_test": 1,
      "raw_y_valid": 1,
      "train_y": 1,
      "preds": 1,
      "estimator.predict(test_x)": 1,
      "y[test_start_g:]": 1,
      "y[test_start_n:]": 1,
      "y_train_c": 1,
      "df.target": 1,
      "sample_google_distance": 1,
      "t": 1,
      "train_result['PredPrice']": 1,
      "co2eq_test": 1,
      "train_l": 1,
      "val_l": 1,
      "y_oof": 1,
      "X_train.get_label()": 1,
      "validate_y_inv": 1,
      "y_inv": 1,
      "Y_B": 1,
      "Y_C": 1,
      "y_train_Conf": 1,
      "y_test_Conf": 1,
      "y_train_Fat": 1,
      "y_test_Fat": 1,
      "targ": 1,
      "df['target']": 1,
      "train_df.Predict": 1,
      "model.predict(X_test)": 1,
      "x_baseline": 1,
      "y_target": 1,
      "y_validation_RF": 1,
      "y_validation": 1,
      "np.exp(self.Y_train)": 1,
      "train_df['revenue']": 1,
      "y_val.values": 1,
      "gscv.predict(X_pca)": 1,
      "actual_labels": 1,
      "g": 1,
      "df.Fatalities.values": 1,
      "y_train2": 1,
      "Y100_test": 1,
      "Y100_forest_test": 1,
      "y3_test": 1,
      "y4_test": 1,
      "y5_test": 1,
      "y_forest1_test": 1,
      "y_forest2_test": 1,
      "y01_test": 1,
      "y11_forest_test": 1,
      "val_df['target'].values.clip(0, 20)": 1,
      "test_y_ohe": 1,
      "y_true.cpu().numpy()": 1,
      "y_val_rain": 1,
      "y_train_": 1,
      "y_co": 1,
      "y_no": 1,
      "y_benz": 1,
      "val.y": 1,
      "yval": 1,
      "ytrain.y": 1,
      "ytrain.ydiff": 1,
      "yval.ydiff": 1,
      "yval.y": 1,
      "train_eval['linear_pred']": 1,
      "train_eval['rf_pred']": 1,
      "train_eval['xgb_pred']": 1,
      "trueVpredict['true location']": 1,
      "Yvalidation": 1,
      "y_pred_rf_two": 1,
      "y_train_eval": 1,
      "target_train": 1,
      "pred_price": 1,
      "dfValid['scalar_coupling_constant']": 1,
      "testpredi": 1,
      "y_mini_test": 1,
      "y_data": 1,
      "np.exp(y_test)": 1,
      "train_runn['Yards']": 1,
      "predict": 1,
      "Ytrain": 1,
      "y_list[i]": 1,
      "B_test": 1,
      "predicted_true": 1,
      "y1_Train": 1,
      "denormalize(predy)": 1,
      "validate_y_exp": 1,
      "ytest1": 1,
      "np.exp(train.y)": 1,
      "np.exp(y)": 1,
      "train.y[test_index]": 1,
      "test_y_pred": 1,
      "inverse_scale(y_train)": 1,
      "inverse_scale(y_valid)": 1,
      "y1_train": 1,
      "df_a.dropna()['a_true']": 1,
      "pred_trainer": 1,
      "pred_test": 1,
      "y_test_gam": 1,
      "y_test_gam_cc": 1,
      "resp": 1,
      "y_val_exp": 1,
      "y_pred_val_lr": 1,
      "y_pred_val_lasso_reg": 1,
      "y_pred_val_ridge_reg": 1,
      "y_pred_val_decisiontree_reg": 1,
      "y_pred_val_xgb_reg": 1,
      "dead_value": 1,
      "Confirmed_data": 1,
      "val": 1,
      "predicted": 1,
      "y_test[:604]": 1,
      "y_test[604:]": 1,
      "y_test[300:904]": 1,
      "confirmed": 1,
      "fatali": 1,
      "confirmed_ch": 1,
      "fatal_ch": 1,
      "confirmed_ind": 1,
      "fatal_ind": 1,
      "rf_yval": 1,
      "y_valid_new": 1,
      "Y_test.iloc[:, i]": 1,
      "Y_ConfirmedCases": 1,
      "Y_Fatalities": 1,
      "y_test_1": 1,
      "y_test_2": 1,
      "y_test_3": 1,
      "y_test_4": 1,
      "y_test_5": 1,
      "y_test_6": 1,
      "y_train_level2.clip(*target_range)": 1,
      "test_inv[:, i]": 1,
      "y_train0": 1,
      "y1_xTest_CS": 1,
      "cases.iloc[0:13459]": 1,
      "valid[y]": 1
    },
    "sklearn.metrics._regression.r2_score.y_pred": {
      "y_pred": 270,
      "preds": 77,
      "pred": 71,
      "dtrain.get_label()": 55,
      "y_test": 52,
      "predictions": 51,
      "y_train_pred": 37,
      "model.predict(dtrain)": 36,
      "y": 35,
      "y_test_pred": 35,
      "predicted": 30,
      "y_eval": 22,
      "y_predict": 20,
      "y_head": 18,
      "prediction": 17,
      "y_val": 15,
      "y_train": 15,
      "df_joined['pred']": 15,
      "np.mean(preds[:i + 1], axis=0)": 15,
      "train_preds": 15,
      "y_pred_scaled": 14,
      "stacked_pipeline.predict(finaltrainset) * 0.2855 + model.predict(dtrain) * 0.7145": 14,
      "Y_valida_pred": 13,
      "y_predicted": 11,
      "estimator.predict(X_val)": 11,
      "val_preds": 11,
      "y_train_predict": 11,
      "preds_valid": 11,
      "model.predict(train[col])": 11,
      "y_pred_train": 10,
      "model.predict(X_test)": 10,
      "estimator.predict(X_tr)": 9,
      "y_pred_test": 9,
      "y_pred2": 9,
      "pred_lr": 9,
      "X_train_preds": 9,
      "X_test_preds": 9,
      "predict": 8,
      "y_val_predict": 7,
      "pred_Y": 7,
      "RFG.predict(x_test)": 6,
      "y_val_pred": 6,
      "train_pred": 6,
      "y_preds": 6,
      "ytrain": 6,
      "ytest": 6,
      "y_valid": 5,
      "yvaltest": 5,
      "lasso_pred_train": 5,
      "test_y": 5,
      "pred_knn": 5,
      "y_pred1": 5,
      "pred_lgb": 5,
      "mix": 5,
      "y_hat": 5,
      "model.predict(dtrain_)": 5,
      "predictedtest": 5,
      "test_ds_predicted": 5,
      "knn.predict(blind)": 5,
      "cv_pred": 4,
      "y_pred_xgb": 4,
      "np.mean(preds[:, :i + 1], axis=1)": 4,
      "Y_pred": 4,
      "y_c2": 4,
      "y_f2": 4,
      "y_test_predict": 4,
      "ypred": 4,
      "val_y_pred": 4,
      "y_pred_inv": 4,
      "y_poly_pred": 4,
      "pred_train": 4,
      "y_train_pred2": 4,
      "yp": 4,
      "o.cpu().numpy()": 4,
      "pred_xgb": 4,
      "model0.predict(x_ts)": 4,
      "pred_rf": 4,
      "model.predict(df[feature_col].replace(values_dict).values.reshape(-1, 1))[:, 1]": 4,
      "train_ds_predicted": 4,
      "y_predicted_d": 4,
      "grid.best_estimator_.predict(X_Val)": 3,
      "joined['volatility']": 3,
      "rf_predict": 3,
      "Atest_y_": 3,
      "pred_test": 3,
      "ypred_xgb": 3,
      "y_pred_lgb": 3,
      "pred_df['pred']": 3,
      "pred_rfr": 3,
      "y_predicted_r": 3,
      "pred_reg": 3,
      "y_test_pred2": 3,
      "np.expm1(y_valid_pred)": 3,
      "np.expm1(y_train_pred)": 3,
      "test_pred": 3,
      "y_pred_lr": 3,
      "y_predTrain": 3,
      "pred_poly": 3,
      "xgb.predict(XVal.as_matrix())": 3,
      "Y_predict": 3,
      "pred_y": 3,
      "val_pred": 3,
      "Y_valid_pred": 3,
      "train_eval['y']": 3,
      "theta": 3,
      "y_preidct": 3,
      "y_preidct[:800]": 3,
      "y_preidct[800:]": 3,
      "oof": 3,
      "p": 3,
      "predicts": 3,
      "predy": 3,
      "GP(train)": 3,
      "xg_pred": 3,
      "test_pred2": 2,
      "train_pred2": 2,
      "test_pred3": 2,
      "train_pred3": 2,
      "y_pred_dt": 2,
      "pred2": 2,
      "Y_test": 2,
      "xgb_predict": 2,
      "Btest_y_": 2,
      "yhat": 2,
      "y_insample_pred": 2,
      "train_predictions": 2,
      "predictions_test": 2,
      "y_pred_test2": 2,
      "lasso_pred_test": 2,
      "lasso_d_pred_train": 2,
      "lasso_d_pred_test": 2,
      "y_pred2_train": 2,
      "ridge_pred_train": 2,
      "ridge_pred_test": 2,
      "ridge_d_pred_train": 2,
      "ridge_d_pred_test": 2,
      "data['predicted_gwh']": 2,
      "test['prediction']": 2,
      "lgbm.predict(X_test, num_iteration=lgbm.best_iteration_)": 2,
      "SalesPrediction": 2,
      "df_train[t]": 2,
      "reg.predict(X_train.values).clip(0, 20)": 2,
      "lr.predict(X_train_level2).clip(0, 20)": 2,
      "stacked_pipeline.predict(finaltrainset) * 0.1 + model.predict(dtrain) * 0.9": 2,
      "lr_tfidf_predict": 2,
      "rf_pred": 2,
      "estimator.predict(X)": 2,
      "y_c": 2,
      "y_cv": 2,
      "pred_n[test_start:]": 2,
      "pred_all[test_start:]": 2,
      "pred_naive[-best_size_n:]": 2,
      "pred_avg[-best_size_n:]": 2,
      "pred_all[-best_size_g:]": 2,
      "pred_naive[-best_size_g:]": 2,
      "pred_avg[-best_size_g:]": 2,
      "predict_dt1": 2,
      "y_pred_1": 2,
      "pred_i": 2,
      "m1_preds": 2,
      "lasso_train_pred": 2,
      "lasso_val_pred": 2,
      "ridge_train_pred": 2,
      "ridge_val_pred": 2,
      "enet_train_pred": 2,
      "enet_val_pred": 2,
      "huber_train_pred": 2,
      "huber_val_pred": 2,
      "rf_train_pred": 2,
      "rf_val_pred": 2,
      "self.xg_prediction_train": 2,
      "self.xg_prediction_test": 2,
      "lr.predict(X.reshape(-1, 1))": 2,
      "sess.run(scaled_out, feed_dict={x: train[ktest], keep_prob: 1.0})": 2,
      "Y_pred_train": 2,
      "y_train_pred_2": 2,
      "y_test_pred_2": 2,
      "test_features.winPlacePerc": 2,
      "y_pred3": 2,
      "ytrainpred": 2,
      "ytestpred": 2,
      "predictions_fat": 2,
      "prediction_xgbr": 2,
      "y_pred_gb": 2,
      "y_pred_rf": 2,
      "pre": 2,
      "y_pred_xgb_1": 2,
      "gbr_preds": 2,
      "xref['prval']": 2,
      "X.loc[~X['ConfirmedCases'].isna()]['yPred']": 2,
      "x_pred": 2,
      "model.predict(df[feature_col].values.reshape(-1, 1))[:, 1]": 2,
      "GP1(train)": 2,
      "GP2(train)": 2,
      "GP3(train)": 2,
      "GP4(train)": 2,
      "GP5(train)": 2,
      "rf_preds": 2,
      "lir_preds": 2,
      "sgdr_preds": 2,
      "lir_preds2": 2,
      "pred_train_val": 2,
      "y_pred_ridge_train": 2,
      "y_pred_ridge_test": 2,
      "y_pred_lasso_train": 2,
      "y_pred_lasso_test": 2,
      "p_train": 2,
      "reg.predict(xtest)": 2,
      "y_predicted_p": 2,
      "y2_train_pred": 2,
      "gr_predict": 2,
      "stacking_pred": 2,
      "y_pred_lgbR": 2,
      "PredTestSet": 1,
      "PredValSet": 1,
      "regressor1.predict(train_data)": 1,
      "regressor1.predict(test_data)": 1,
      "regressor2.predict(train_data)": 1,
      "regressor2.predict(test_data)": 1,
      "regressor3.predict(train_data)": 1,
      "regressor3.predict(test_data)": 1,
      "regressor4.predict(train_data)": 1,
      "regressor4.predict(test_data)": 1,
      "regressor5.predict(train_data)": 1,
      "regressor5.predict(test_data)": 1,
      "regressor6.predict(train_data)": 1,
      "regressor6.predict(test_data)": 1,
      "xgb_preds": 1,
      "lgbm_preds": 1,
      "y_val1": 1,
      "y_pred_ridge": 1,
      "prd": 1,
      "lr_pred": 1,
      "rfr_pred": 1,
      "xgb_pred": 1,
      "pred_2": 1,
      "pred_1": 1,
      "pred_3": 1,
      "predict_val": 1,
      "rf_predict_bc": 1,
      "lgbm_predict": 1,
      "lgbm_predict_bc": 1,
      "xgb_predict_bc": 1,
      "stacked_": 1,
      "stacked_bc": 1,
      "y_monthly_train_pred": 1,
      "y_monthly_pred": 1,
      "xgb_tahmin": 1,
      "predictions[:, 0]": 1,
      "predictions[:, 1]": 1,
      "predictions[:, 2]": 1,
      "y_test2_predict": 1,
      "stacked_pipeline.predict(final_valid) * 0.2855 + model.predict(dtest) * 0.7145": 1,
      "test_predictions": 1,
      "YHat": 1,
      "predictions_train": 1,
      "ypred_clf": 1,
      "lasso_predict": 1,
      "y_train_pred_rf": 1,
      "y_train_pred_xg": 1,
      "y_train_pred_xg_cv": 1,
      "y_predict_stack_reg": 1,
      "y_pred_final": 1,
      "pred.astype(int)": 1,
      "rf.predict(X_val)": 1,
      "predic": 1,
      "pres": 1,
      "pr": 1,
      "predu": 1,
      "lasso_pred_2": 1,
      "lasso_pred_2_test": 1,
      "y_pred_cat": 1,
      "probs": 1,
      "model_1": 1,
      "model_2": 1,
      "model_1_LB1": 1,
      "model_2_LB1": 1,
      "model_1_PB1": 1,
      "model_2_PB1": 1,
      "model_1_LB2": 1,
      "model_2_LB2": 1,
      "model_1_PB2": 1,
      "model_2_PB2": 1,
      "model_1_LB3": 1,
      "model_2_LB3": 1,
      "model_1_PB3": 1,
      "model_2_PB3": 1,
      "model_1_LB4": 1,
      "model_2_LB4": 1,
      "model_1_PB4": 1,
      "model_2_PB4": 1,
      "model_1_LB5": 1,
      "model_2_LB5": 1,
      "model_1_PB5": 1,
      "model_2_PB5": 1,
      "ypipe": 1,
      "y2pipe": 1,
      "p(cr)": 1,
      "y_predict_x": 1,
      "y_val_sub": 1,
      "prediction_m": 1,
      "model.predict(finaltrainset[train_index])": 1,
      "model.predict(finaltrainset[test_index])": 1,
      "plays['epa_pred']": 1,
      "test_preds": 1,
      "unscaled_df.pred_value[-28:]": 1,
      "A": 1,
      "df_train['tmp'].apply(lambda x: x / s)": 1,
      "df['tmp']": 1,
      "lr.predict(X_train.values).clip(0, 20)": 1,
      "lgb1.predict(X_train.values).clip(0, 20)": 1,
      "test_preds_stacking_lr": 1,
      "lgb1.predict(X_train).clip(0, 20)": 1,
      "_y_predict": 1,
      "model.predict(xgb.DMatrix(X))": 1,
      "y_train_pred4": 1,
      "y_test_pred4": 1,
      "y_train_pred5": 1,
      "y_test_pred5": 1,
      "y_train_pred6": 1,
      "y_test_pred6": 1,
      "y_pred_linreg": 1,
      "y_pred_rs_tree": 1,
      "y_pred_rs_rf": 1,
      "y_pred_ada_tree": 1,
      "y_pred_grad_boost": 1,
      "y_pred_gbm_bs": 1,
      "stacked_pipeline.predict(finaltrainset) * 0.2 + model.predict(dtrain) * 0.8": 1,
      "stacked_pipeline.predict(finaltrainset) * 0.3 + model.predict(dtrain) * 0.7": 1,
      "stacked_pipeline.predict(finaltrainset) * 0.4 + model.predict(dtrain) * 0.6": 1,
      "lin_pred": 1,
      "lasso_pred": 1,
      "ridge_pred": 1,
      "dtr_pred": 1,
      "pred_test_average": 1,
      "oof_preds": 1,
      "stacked_pipeline.predict(finaltrainset) * 0.0 + model.predict(dtrain)": 1,
      "stacked_pipeline.predict(finaltrainset) * 0.05 + model.predict(dtrain) * 0.95": 1,
      "stacked_pipeline.predict(finaltrainset) * 0.15 + model.predict(dtrain) * 0.85": 1,
      "model.predict(train_X)": 1,
      "Y": 1,
      "y_pred_knn": 1,
      "pred_g[test_start_g:]": 1,
      "pred_n[test_start_n:]": 1,
      "pred_n[-best_size_n:]": 1,
      "pred_fusion[-best_size_n:]": 1,
      "pred_fusion_avg[-best_size_n:]": 1,
      "pred_fusion_all[-best_size_n:]": 1,
      "pred_fusion_germany[-best_size_g:]": 1,
      "pred_fusion_germany_avg[-best_size_g:]": 1,
      "pred_fusion_germany_all[-best_size_g:]": 1,
      "y_pred_2": 1,
      "y_pred_3": 1,
      "df.predict": 1,
      "train.distance_easy[:10]": 1,
      "sample_google_distance[8:10]": 1,
      "train_data['SalePrice']": 1,
      "co2eq_pred": 1,
      "train_p": 1,
      "val_p": 1,
      "xgb_tuned.predict(x_train)": 1,
      "xgb_tuned.predict(x_test)": 1,
      "y_predictions": 1,
      "dt_y_pred": 1,
      "Y_train_pred": 1,
      "Y_test_pred": 1,
      "regr.predict(X_test_comps)": 1,
      "predictionsLR": 1,
      "predictionsDTR": 1,
      "predictionsKNNR": 1,
      "rf.predict(y_pred)": 1,
      "clf.predict(X_test)": 1,
      "ln_y_pred": 1,
      "rf_y_pred": 1,
      "gbm_y_pred": 1,
      "ln_y_OfT": 1,
      "rf_y_OfT": 1,
      "gbm_y_OfT": 1,
      "test_y_": 1,
      "y_pred_trai": 1,
      "cbr_pred": 1,
      "house_y_pred": 1,
      "lasso.predict(numerical_input_B)": 1,
      "lasso.predict(numerical_input_C)": 1,
      "ridge.predict(numerical_input_B)": 1,
      "ridge.predict(numerical_input_C)": 1,
      "lr.predict(X_B)": 1,
      "lr.predict(X_C)": 1,
      "clf_Conf.predict(X_train)": 1,
      "clf_Conf.predict(X_test)": 1,
      "clf_Fat.predict(X_train)": 1,
      "clf_Fat.predict(X_test)": 1,
      "act": 1,
      "df[pred_col]": 1,
      "y_pred_en": 1,
      "grid_pred_neural": 1,
      "pred_knnr": 1,
      "lables": 1,
      "lm.predict(y_pred_df[['y_pred_RF', 'y_pred_XGB']])": 1,
      "(y_pred_df['y_pred_RF'] + y_pred_df['y_pred_XGB']) / 2": 1,
      "y_pred_DT": 1,
      "y_pred_RF": 1,
      "y_pred_LGB": 1,
      "train_df.SalePrice": 1,
      "y_target": 1,
      "self.xg_predictions": 1,
      "train_df['predicted_revenue']": 1,
      "reg.predict(X_test)": 1,
      "reg_stack.predict(X_test)": 1,
      "tree_y_pred_tree": 1,
      "tree_y_pred_xgb": 1,
      "tree_y_pred_lgb": 1,
      "tree_y_pred_xgb * 0.5 + tree_y_pred_lgb * 0.5": 1,
      "tree_y_pred_xgb * 0.4 + tree_y_pred_lgb * 0.4 + tree_y_pred_tree * 0.1 + y_pred_lr * 0.1": 1,
      "fitted_values": 1,
      "test_scores": 1,
      "pred_svc": 1,
      "pred_ridge": 1,
      "pred_grad": 1,
      "pred_rand": 1,
      "pred_nn": 1,
      "val": 1,
      "y_pred_GBoost": 1,
      "knn_pred": 1,
      "dt_pred": 1,
      "Y_train_predict": 1,
      "Y_train_random": 1,
      "pred_gr_train": 1,
      "pred_xgb_train": 1,
      "Enet_train_predict": 1,
      "pred_labels": 1,
      "y_train_predicted": 1,
      "y_test_predicted": 1,
      "df.predictions.values": 1,
      "XGB.predict(x_test_std)": 1,
      "final_pred": 1,
      "pr_svr": 1,
      "predictions_xgb": 1,
      "predictions_ada": 1,
      "rez_pred": 1,
      "Y100_pred": 1,
      "Y100_forest_pred": 1,
      "y1_pred": 1,
      "y2_pred": 1,
      "y3_pred": 1,
      "y4_pred": 1,
      "y5_pred": 1,
      "y_forest1_pred": 1,
      "y_forest2_pred": 1,
      "y01_pred": 1,
      "y11_forest_pred": 1,
      "y12_g_pred": 1,
      "y12_r_pred": 1,
      "lr.predict(x[test_index])": 1,
      "lr_mul.predict(x_mul[test_index])": 1,
      "validation_predictions": 1,
      "np.mean(predictions[:i + 1], axis=0)": 1,
      "y_pred.cpu().numpy()": 1,
      "results.predicted_player_rank": 1,
      "results.predicted_team_rank_max.clip(0, 1)": 1,
      "results.predicted_team_rank_mean.clip(0, 1)": 1,
      "y_train_pred_co": 1,
      "y_train_pred_no": 1,
      "y_train_pred_benz": 1,
      "clf.predict(X_valid_scaled)": 1,
      "val_predictions": 1,
      "val_predictions_tree": 1,
      "val_predictions_XG": 1,
      "val_prediction_LSTM": 1,
      "y_predict_test_linear": 1,
      "y_predict_test_Random": 1,
      "y_predict_test_LGB": 1,
      "y_predict_test_XGB": 1,
      "train.ypred": 1,
      "val.ypred": 1,
      "val_vals": 1,
      "train_vals": 1,
      "ytrain.ypred": 1,
      "ytrain.ypred - ytrain.yX0": 1,
      "yval.ypred - yval.yX0": 1,
      "yval.ypred": 1,
      "y_predicted_train1": 1,
      "y_predicted_train2": 1,
      "y_predicted_train3": 1,
      "y_train_prediction4": 1,
      "rf.oob_prediction_": 1,
      "df['rentals']": 1,
      "np.full(rf.oob_prediction_.shape[0], df['rentals'].mean())": 1,
      "np.full(rf.oob_prediction_.shape[0], 10000)": 1,
      "trueVpredict['predicted location']": 1,
      "y_predA": 1,
      "y_predC": 1,
      "y_pred_dtone": 1,
      "y_pred_sv": 1,
      "y_predt": 1,
      "y_predxgb": 1,
      "y_predxgbt": 1,
      "la_sub_preds[:int(len(sub_y) * ratio)]": 1,
      "la_sub_preds[int(len(sub_y) * ratio):]": 1,
      "rf_sub_preds[:int(len(sub_y) * ratio)]": 1,
      "rf_sub_preds[int(len(sub_y) * ratio):]": 1,
      "(rf_sub_preds[:int(len(sub_y) * ratio)] + la_sub_preds[:int(len(sub_y) * ratio)]) / 2": 1,
      "(rf_sub_preds[int(len(sub_y) * ratio):] + la_sub_preds[int(len(sub_y) * ratio):]) / 2": 1,
      "y_train_reg": 1,
      "y_test_reg": 1,
      "target_train_predict": 1,
      "X_test_pred": 1,
      "y_test_price": 1,
      "dfValid['scalar_coupling_constant_pred']": 1,
      "pred_XG": 1,
      "np.exp(predictions)": 1,
      "pred_train_rf": 1,
      "pred_test_rf": 1,
      "train_runn['pred']": 1,
      "lasso_lr.predict(df_test)": 1,
      "y_list[i + 1]": 1,
      "ytrain_pred": 1,
      "ytest_pred": 1,
      "rf.predict(X_train)": 1,
      "y_pred_valid": 1,
      "y_train_pred1": 1,
      "y_train_pred3": 1,
      "pred_cb": 1,
      "pred_cat_boost": 1,
      "a": 1,
      "predicted_y": 1,
      "y1_best_dtr_model.predict(X_Train)": 1,
      "model.predict(train_)": 1,
      "model.predict(train)": 1,
      "denormalize(y_train)": 1,
      "y_pred_exp": 1,
      "y_pred_nn": 1,
      "y_pred_meta": 1,
      "ypred1": 1,
      "knnpreds": 1,
      "np.exp(GP(train))": 1,
      "np.exp(model.predict(dtrain))": 1,
      "regressor.predict(blind)": 1,
      "regressor.predict(train[train.columns[1:-1]])": 1,
      "y_predict_test": 1,
      "y_predict_valid": 1,
      "y1_hat_train": 1,
      "y1_hat_test": 1,
      "y2_hat_train": 1,
      "y2_hat_test": 1,
      "best_model.predict(x_test)": 1,
      "y_test_xg": 1,
      "y_test_xg_ls": 1,
      "y_test_li_ls": 1,
      "df_a.dropna()['pred_fixed']": 1,
      "linmodel_pred": 1,
      "y_test_predd": 1,
      "Y_trainer": 1,
      "Y_train_val": 1,
      "y_lr": 1,
      "y_valid_pred": 1,
      "predictions_rf": 1,
      "predictions_cc": 1,
      "resposta": 1,
      "train_predict": 1,
      "validation_predict": 1,
      "y_pred_val": 1,
      "y_pred_val_exp": 1,
      "pred_lasso": 1,
      "pred_bayesian": 1,
      "rfc_predict": 1,
      "y_pred_LogReg": 1,
      "y_pred_DTR": 1,
      "pred_nb": 1,
      "regression.predict(confirmed_value)": 1,
      "regression2.predict(Deaths_data_poly)": 1,
      "Desicion_regression.predict(Deaths_data_value)": 1,
      "R_regression.predict(Deaths_data_value)": 1,
      "trained_xgb": 1,
      "final_test": 1,
      "actual": 1,
      "lr.predict(X_val)": 1,
      "xgb_model.predict(X_val)": 1,
      "model_lr.predict(df_val)": 1,
      "best_model_lr.predict(X_val_LR)": 1,
      "y_predict_train": 1,
      "valid_pred": 1,
      "p_test1": 1,
      "p_test2": 1,
      "p_test3": 1,
      "p_test": 1,
      "final": 1,
      "previsoes": 1,
      "fit1.fittedvalues": 1,
      "fit2.fittedvalues": 1,
      "fit3.fittedvalues": 1,
      "fit4.fittedvalues": 1,
      "fit5.fittedvalues": 1,
      "fit6.fittedvalues": 1,
      "prediction_for_rf": 1,
      "y_train_pred_lg": 1,
      "y_val_pred_lg": 1,
      "y_train_pred_r": 1,
      "y_val_pred_r": 1,
      "pred_val": 1,
      "Pred_data.iloc[:, i]": 1,
      "model.predict(test_X)": 1,
      "best_model.predict(test_X)": 1,
      "best_lgbm.predict(test_X)": 1,
      "modelcat.predict(test_X)": 1,
      "y_mul_pred": 1,
      "y_lasso": 1,
      "y_mlpReg_pred": 1,
      "pred_xgbrf_ConfirmedCases": 1,
      "pred_xgbrf_Fatalities": 1,
      "pred_train['lgb_pred']": 1,
      "pred_train['xgb_pred']": 1,
      "pred_train['log_pred']": 1,
      "pred_train['lin_pred']": 1,
      "pred_train['mean']": 1,
      "pred_train['total']": 1,
      "model_1.predict(X_test_1)": 1,
      "model_2.predict(X_test_2)": 1,
      "model_3.predict(X_test_3)": 1,
      "model_4.predict(X_test_4)": 1,
      "model_5.predict(X_test_5)": 1,
      "model_6.predict(X_test_6)": 1,
      "pred_lr_val.clip(0, 20)": 1,
      "model_lr_scaled.predict(X_val)": 1,
      "model_lr_scaled.predict(X_val).clip(0, 20)": 1,
      "np.dot(X_train_level2, [alpha, 1 - alpha])": 1,
      "pred_inv[:, i]": 1,
      "y_preed": 1,
      "pred_for": 1,
      "Y_pred_test": 1,
      "alg_y_pred": 1,
      "best_fit": 1,
      "y_pred_class": 1,
      "y_predicted2": 1,
      "y_predicted_clf": 1,
      "rdg_predict": 1,
      "lgb_predict": 1,
      "vote_predict": 1,
      "sr_predict": 1,
      "valid_preds": 1,
      "pred_linear": 1,
      "pred_gd": 1,
      "pred_rf_test": 1,
      "lasso_mod_train": 1,
      "lasso_mod_test": 1,
      "random_for_mod": 1,
      "y_predict_dummy_mean": 1,
      "y_predict_dummy_median": 1,
      "predicted_label": 1,
      "np.where(grid.best_estimator_.predict(X_xTest_CS1) < 0, 0, grid.best_estimator_.predict(X_xTest_CS1))": 1,
      "np.where(grid1.best_estimator_.predict(X_xTest_CS1) < 0, 0, grid1.best_estimator_.predict(X_xTest_CS1))": 1,
      "grid1.best_estimator_.predict(X_xTest_CS1)": 1,
      "cases_pred": 1
    },
    "sklearn.linear_model._coordinate_descent.ElasticNet.fit.X": {
      "X_train": 159,
      "x_train": 45,
      "X": 45,
      "X.values.reshape(-1, 1)": 14,
      "train_X": 11,
      "X_train_scaled": 10,
      "X_tr[i]": 10,
      "train": 6,
      "X_train_cases": 6,
      "X_train_cases_f": 6,
      "X_train_fatal_f": 6,
      "newpipe.transform(Xhetero)": 6,
      "Xhetero": 6,
      "scaler.transform(x_train_store)": 6,
      "x_train[i]": 6,
      "X_train_fatal": 5,
      "X_train2": 4,
      "features": 4,
      "Xs_train_a": 4,
      "trn_data": 4,
      "x": 3,
      "Xtrain": 3,
      "data": 3,
      "training": 3,
      "xtr[i]": 2,
      "X_train_cc": 2,
      "X_train_fat": 2,
      "X_scaled": 2,
      "[[0, 0], [1, 1], [2, 2]]": 2,
      "X2": 2,
      "train_x": 2,
      "self.__training_set[self.__query]": 2,
      "train_train": 2,
      "Xs_train": 2,
      "xtsc": 2,
      "sxtr": 2,
      "tr_data": 2,
      "scale_X": 2,
      "data_tr_x": 2,
      "data[data.date_block_num <= 30].drop(['item_cnt_month'], axis=1)": 2,
      "X_train_norm": 2,
      "newX": 2,
      "X_w": 2,
      "X_train_ohe": 2,
      "X_trainS": 2,
      "train_x_scaled": 2,
      "tr_x": 2,
      "df_X": 2,
      "X_all[:3000]": 2,
      "train[X_cols].values": 1,
      "X_train[rfe_selected]": 1,
      "train[y_is_within_cut].as_matrix()": 1,
      "train[y_is_above_cut].as_matrix()": 1,
      "train[y_is_below_cut].as_matrix()": 1,
      "trainData": 1,
      "df_train.iloc[:, l_best_features_en]": 1,
      "X_train_part": 1,
      "z2[tr_idx]": 1,
      "features_train": 1,
      "df_data[x_cols][mask_base].values": 1,
      "X_final_poly": 1,
      "trs[tr_idx, :]": 1,
      "x_nb": 1,
      "train[cols_to_fit]": 1,
      "train_data": 1,
      "x_total": 1,
      "X_train_df_continuous": 1,
      "train_embeddings1": 1,
      "numerical_input_A": 1,
      "X_train_3": 1,
      "X_all_feature": 1,
      "poly_x_train": 1,
      "train_set['X']": 1,
      "Xt": 1,
      "X_train_fs": 1,
      "poly_first_level": 1,
      "data[data.date_block_num <= 33].drop(['item_cnt_month'], axis=1)": 1,
      "train.iloc[:, :-1]": 1,
      "X_train_t": 1,
      "X_train.values[:, selector.k_feature_idx_]": 1,
      "X_train_SC": 1,
      "X_Train": 1,
      "trn_df.values": 1,
      "scaler.transform(X_train)": 1,
      "df_train": 1,
      "X_": 1,
      "train_": 1,
      "xtrain_val": 1,
      "train_corr.drop(columns='winPlacePerc', axis=1)": 1,
      "X_train_rfe": 1,
      "X_train_final": 1,
      "scaled_features_df_feat": 1,
      "xx_train": 1,
      "train_processed": 1,
      "train[feature_columns]": 1,
      "x_mul": 1,
      "np.array(X_transf)": 1,
      "X_transf": 1,
      "train_features_df": 1
    },
    "sklearn.linear_model._coordinate_descent.ElasticNet.fit.y": {
      "y_train": 212,
      "y": 33,
      "Y_train": 19,
      "Y": 17,
      "train_y": 14,
      "y.values": 14,
      "lnres2": 12,
      "y_train_scaled": 6,
      "y_train_cases": 6,
      "y_train_cases_f": 6,
      "y_train_fatal_f": 6,
      "target": 6,
      "y_train_fatal": 5,
      "y_cc[i]": 5,
      "y_ft[i]": 5,
      "ytr": 4,
      "trn_y": 4,
      "target_1": 4,
      "target_2": 4,
      "target_3": 4,
      "ytraining": 3,
      "train_Y": 2,
      "y_train_cc": 2,
      "y_train_fat": 2,
      "[0, 1, 2]": 2,
      "targets": 2,
      "self.__training_set[self.__predictive_variable]": 2,
      "train_train_y.values.ravel()": 2,
      "data_tr_y.values.ravel()": 2,
      "Ytrain": 2,
      "y_train_store": 2,
      "y_train_store['Customers']": 2,
      "y_train_store['Unit']": 2,
      "data[data.date_block_num <= 30]['item_cnt_month'].clip(0.0, 20.0)": 2,
      "y_con": 2,
      "y_fat": 2,
      "ytrain": 2,
      "tr_y": 2,
      "df_Y": 2,
      "y_all[:3000]": 2,
      "train.log_target.values": 1,
      "ycc[i]": 1,
      "yft[i]": 1,
      "train.loc[y_is_within_cut, 'y']": 1,
      "train.loc[y_is_above_cut, 'y']": 1,
      "train.loc[y_is_below_cut, 'y']": 1,
      "trainTarget": 1,
      "df_train.TARGET": 1,
      "y_true": 1,
      "y_train_part": 1,
      "y[tr_idx]": 1,
      "np.log1p(y_train)": 1,
      "targets_train": 1,
      "df_data[target][mask_base].values": 1,
      "y_final": 1,
      "train[target].iloc[tr_idx]": 1,
      "train[target]": 1,
      "y_train_log": 1,
      "train_label": 1,
      "y_total": 1,
      "target_df_log": 1,
      "part_A_y": 1,
      "train_set['y']": 1,
      "y_label_log": 1,
      "Yt": 1,
      "y1_train[i]": 1,
      "y2_train[i]": 1,
      "y3_train[i]": 1,
      "y4_train[i]": 1,
      "y5_train[i]": 1,
      "y6_train[i]": 1,
      "data.loc[(data.date_block_num > 30) & (data.date_block_num < 33)]['item_cnt_month'].clip(0.0, 20.0)": 1,
      "data[data.date_block_num <= 33]['item_cnt_month'].clip(0.0, 20.0)": 1,
      "train.iloc[:, -1]": 1,
      "y_train_data": 1,
      "np.log(y)": 1,
      "Y_Train": 1,
      "trn_y.values": 1,
      "np.log1p(Y_train)": 1,
      "ytrain_val": 1,
      "train['winPlacePerc']": 1,
      "yy_train": 1,
      "train['revenue']": 1,
      "train['FVC']": 1,
      "y_mul": 1,
      "Y1": 1,
      "train_target_s": 1,
      "Y_train.values.ravel()": 1
    },
    "sklearn.neighbors._regression.KNeighborsRegressor.fit.X": {
      "X_train": 71,
      "x_train": 16,
      "X": 9,
      "train[col]": 5,
      "vis": 5,
      "knn_train": 4,
      "features": 3,
      "imp_train[cols_no_nan]": 3,
      "xtrain": 2,
      "combined2": 2,
      "knn_tmp": 2,
      "sub_train[['year', 'month', 'dayofweek', 'dayofyear', 'weekofyear']]": 2,
      "Train_ADS": 2,
      "X_scaled": 2,
      "Xs_train_a": 2,
      "train[features]": 2,
      "input_data": 2,
      "trn_x": 2,
      "X_train_kneigboards": 2,
      "ans.drop(['target'], axis=1)": 1,
      "X_train1": 1,
      "X_train2": 1,
      "X_train3": 1,
      "X_train_scaled": 1,
      "dtrain[predictors]": 1,
      "x_tr": 1,
      "trainFactors": 1,
      "X_train_pc": 1,
      "price_df.drop(['price'], axis=1)": 1,
      "X_train_lr[-30000:]": 1,
      "X_train_income": 1,
      "X_train_depend": 1,
      "X_Train_new": 1,
      "X_new": 1,
      "scale_X": 1,
      "Xtr": 1,
      "X_train.dropna().drop(columns=[col])": 1,
      "train3p[train_index, :]": 1,
      "train_x": 1,
      "train_nonzero_3pm[['Aspect', 'Slope']]": 1,
      "X_post": 1,
      "training_knn_1.drop('SalePrice', axis=1)": 1,
      "vect_n_train": 1,
      "kX": 1,
      "X_train_SC": 1,
      "values.T": 1,
      "X_train_model": 1,
      "X_trainS": 1,
      "df.index.values[:, np.newaxis]": 1,
      "train_X": 1,
      "fea": 1,
      "x": 1,
      "train": 1,
      "dummy_train[prediction_var]": 1,
      "scaler.transform(X_train)": 1,
      "tr_x": 1,
      "knn_X_train": 1,
      "X_train_knn": 1,
      "X_train_sc": 1,
      "df_X": 1,
      "train_input": 1
    },
    "sklearn.neighbors._regression.KNeighborsRegressor.fit.y": {
      "y_train": 84,
      "Y_train": 14,
      "y": 11,
      "np.log1p(train['visitors'].values)": 5,
      "y[train_index]": 5,
      "Y_train_sampled": 3,
      "imp_train[col]": 3,
      "y1": 2,
      "ytrain": 2,
      "LF": 2,
      "knn_target[indices]": 2,
      "target": 2,
      "train_y": 2,
      "train['revenue']": 2,
      "trn_y": 2,
      "y_train1": 1,
      "y_train2": 1,
      "y_train3": 1,
      "y_train_scaled": 1,
      "dtrain[targets]": 1,
      "x_label": 1,
      "y_label": 1,
      "y_tr": 1,
      "trainResponse": 1,
      "price_df['price']": 1,
      "y_train[-30000:]": 1,
      "y_train_income": 1,
      "y_train_depend": 1,
      "sub_train[['ConfirmedCases']]": 1,
      "sub_train[['Fatalities']]": 1,
      "ytr": 1,
      "X_train.dropna()[col]": 1,
      "y_train_sampled": 1,
      "train2p.loc[train_index]['target']": 1,
      "y2": 1,
      "train_nonzero_3pm['Hillshade_3pm']": 1,
      "ys": 1,
      "training_knn_1['SalePrice']": 1,
      "train.fc.values": 1,
      "y_train[:, i]": 1,
      "targets.T": 1,
      "Y_train_model": 1,
      "y_train['ConfirmedCases']": 1,
      "df.iloc[:, 0]": 1,
      "tar": 1,
      "Y": 1,
      "dummy_train['trip_duration']": 1,
      "tr_y": 1,
      "Y_train[:n_samples]": 1,
      "y_train_knn": 1,
      "np.ravel(y)": 1,
      "df_Y": 1,
      "y_train.values": 1,
      "train_target": 1
    },
    "sklearn.neighbors._regression.KNeighborsRegressor.predict.X": {
      "X_test": 54,
      "x_test": 13,
      "X_train": 9,
      "X_val": 5,
      "test[col]": 5,
      "blind": 5,
      "knn_train": 4,
      "knn_val": 4,
      "knn_test": 4,
      "X_scaled": 4,
      "test[features]": 4,
      "imp_test[cols_no_nan]": 3,
      "train[col]": 3,
      "x_train": 3,
      "X": 2,
      "X_valid": 2,
      "LF_test": 2,
      "x_val": 2,
      "knn_val_data": 2,
      "sub_test[['year', 'month', 'dayofweek', 'dayofyear', 'weekofyear']]": 2,
      "Test_ADS": 2,
      "test_scaled": 2,
      "val_x": 2,
      "X_val_kneigboards": 2,
      "X_test_kneigboards": 2,
      "test_pca": 1,
      "X_val1": 1,
      "X_val2": 1,
      "X_val3": 1,
      "X_train_scaled": 1,
      "X_val_scaled": 1,
      "X_test_scaled": 1,
      "test_df.drop('Id', axis=1)": 1,
      "dtest[predictors]": 1,
      "x_tr": 1,
      "x_te": 1,
      "testFactors": 1,
      "X_test_pc": 1,
      "processed_test_data": 1,
      "price_df.drop(['price'], axis=1)": 1,
      "X_valid_lr": 1,
      "X_test_lr": 1,
      "X_test_income": 1,
      "X_test_depend": 1,
      "x_test[['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']]": 1,
      "X_Test_new": 1,
      "final_test": 1,
      "final_test_new": 1,
      "train_copy": 1,
      "test_copy": 1,
      "test_feature": 1,
      "scale_X": 1,
      "scaler.transform(test.as_matrix())": 1,
      "tfeatures": 1,
      "Xte": 1,
      "X_test.iloc[0].values.reshape(1, -1)": 1,
      "train_na": 1,
      "test_na": 1,
      "x_eval": 1,
      "train3[test_index3, :]": 1,
      "test3": 1,
      "test2": 1,
      "pd.DataFrame({'Aspect': grid_aspect, 'Slope': grid_slope})": 1,
      "x[:, :3]": 1,
      "test_knn_1": 1,
      "vect_n_te": 1,
      "X_pred.iloc[:, 3:].values": 1,
      "X_train_SC": 1,
      "X_test_SC": 1,
      "positions.T": 1,
      "test[['Population', 'Weight', 'Target_val']]": 1,
      "X_train_model": 1,
      "X_test_model": 1,
      "test_data.drop(['Date', 'ForecastId'], axis=1)": 1,
      "X_valS": 1,
      "df.index.values[:, np.newaxis]": 1,
      "test_X": 1,
      "predict": 1,
      "X[:]": 1,
      "train": 1,
      "dummy_test[prediction_var]": 1,
      "df_t": 1,
      "x_pred": 1,
      "scaler.transform(X_test)": 1,
      "test": 1,
      "x": 1,
      "knn_X_train": 1,
      "knn_X_val": 1,
      "knn_X_test": 1,
      "X_test_knn": 1,
      "X_test_sc": 1,
      "test_df_X": 1,
      "X_train.head(5)": 1,
      "df_submit[features]": 1,
      "X_val.to_numpy()": 1
    },
    "sklearn.naive_bayes.GaussianNB.fit.X": {
      "X_train": 171,
      "x_train": 53,
      "X": 18,
      "train_X": 12,
      "train_x": 6,
      "train": 6,
      "X_learn": 5,
      "X_tr": 4,
      "train_merge4": 3,
      "train_data": 3,
      "train[features]": 3,
      "x": 3,
      "X_train.todense()": 2,
      "trainX": 2,
      "x_train[train]": 2,
      "x_train_pca[train]": 2,
      "X_training": 2,
      "train[variables]": 2,
      "xTrain": 2,
      "data[['Elevation', 'Slope']]": 2,
      "trainRI": 2,
      "features_train": 2,
      "trn_x": 2,
      "label_X_train": 2,
      "x_data": 2,
      "normX": 1,
      "X_train1": 1,
      "X_train2": 1,
      "dataset_train[features]": 1,
      "df_cell_train_feats": 1,
      "x_train[used_features].values": 1,
      "trainImage_pca": 1,
      "trainImage": 1,
      "X_test.todense()": 1,
      "X_train.toarray()": 1,
      "data_train[feats]": 1,
      "X_train_pca": 1,
      "train_X.toarray()": 1,
      "train_attrs": 1,
      "train_numeric_part_gauss_X": 1,
      "TrainData": 1,
      "intermediate_output": 1,
      "features": 1,
      "train_data_filtered": 1,
      "xtrain": 1,
      "X_train_std": 1,
      "X[train]": 1,
      "X_tr_full": 1,
      "matrix_train": 1,
      "X_train_nb": 1,
      "x1": 1,
      "X1_train": 1,
      "X2_train": 1,
      "X3_train": 1,
      "X4_train": 1,
      "X5_train": 1,
      "X6_train": 1,
      "X_train_res": 1,
      "X_scaled": 1,
      "train[['day_of_week_encoded', 'pd_district_encoded', 'x', 'y', 'hour']]": 1,
      "X_train_tfidf.toarray()": 1,
      "bag_of_words": 1,
      "Xt": 1,
      "Xtrain": 1,
      "train[features1]": 1,
      "x_res_train": 1,
      "x_train.values": 1,
      "X_train_ol": 1,
      "train_features": 1,
      "new_feature_vector": 1,
      "X.toarray()": 1,
      "x_train_data": 1,
      "xtr": 1,
      "trainer": 1,
      "reduced_data": 1,
      "X_f_train_scaled": 1,
      "train_pcs": 1,
      "trainDtmSvd": 1,
      "x_train_3": 1,
      "self.x_train": 1,
      "train_tfidf": 1,
      "xtrain_cntv": 1,
      "xtreino": 1,
      "x_train_scaled": 1,
      "lootrain[goodfeatures]": 1,
      "val_pred": 1,
      "X_train_vec.todense()": 1,
      "df_train_final.iloc[:, final_selected_features]": 1,
      "train_df": 1,
      "x_train1": 1,
      "X_train[::subsample, :]": 1,
      "trainDataMatrix": 1,
      "X_train_vect": 1,
      "df_X": 1,
      "dftrain[['signal']]": 1,
      "train_features_array": 1,
      "X_trains_b": 1,
      "x_train.to_list()": 1,
      "tr_x": 1
    },
    "sklearn.naive_bayes.GaussianNB.fit.y": {
      "y_train": 187,
      "Y_train": 40,
      "y": 19,
      "train_y": 17,
      "y_train.values.ravel()": 7,
      "target": 7,
      "Y": 5,
      "y_learn": 5,
      "y_tr": 4,
      "y_train[train]": 4,
      "train_Y": 3,
      "y_train1": 2,
      "trainLabel": 2,
      "trainY": 2,
      "train['signal']": 2,
      "labels": 2,
      "yTrain": 2,
      "train_labels": 2,
      "train['target']": 2,
      "data['Cover_Type']": 2,
      "trainRL": 2,
      "target_train": 2,
      "train_target": 2,
      "trn_y": 2,
      "y_data": 2,
      "normY": 1,
      "y_train2": 1,
      "dataset_train['target']": 1,
      "x_train['AdoptionSpeed']": 1,
      "y_test": 1,
      "y_training": 1,
      "data_train['target']": 1,
      "train_numeric_part_gauss.Response": 1,
      "TrainLabel": 1,
      "train_label1": 1,
      "train_label_int": 1,
      "ytrain": 1,
      "Y[train]": 1,
      "train_resp": 1,
      "y_tr_full": 1,
      "train_label.values.ravel()": 1,
      "classes_train": 1,
      "y_train_nb": 1,
      "x2": 1,
      "y1_train": 1,
      "y2_train": 1,
      "y3_train": 1,
      "y4_train": 1,
      "y5_train": 1,
      "y6_train": 1,
      "y_train_res": 1,
      "y_train[label]": 1,
      "train['category_predict']": 1,
      "train[i].values": 1,
      "train['cuisine']": 1,
      "Yt": 1,
      "Ytrain": 1,
      "train[target]": 1,
      "train[target1]": 1,
      "y_res_train": 1,
      "y_train.values": 1,
      "train_df['target']": 1,
      "class_value_vector.ravel()": 1,
      "Y.ravel()": 1,
      "y_train_data": 1,
      "Y_training_actual": 1,
      "ytr": 1,
      "y_train.ravel()": 1,
      "targetselector": 1,
      "Y_Train": 1,
      "y_f_train": 1,
      "train[j]": 1,
      "y_train_3": 1,
      "self.y_train": 1,
      "ytreino": 1,
      "lootrain.outcome": 1,
      "valid_data['validLabel']": 1,
      "train_data.target": 1,
      "y_train_final": 1,
      "y_train[::subsample]": 1,
      "[dish['cuisine'] for dish in trainData]": 1,
      "df_Y": 1,
      "dftrain.open_channels": 1,
      "train_target_array": 1,
      "y_trains_b": 1,
      "tr_y": 1
    },
    "sklearn.preprocessing._data.MinMaxScaler.__init__.feature_range": {
      "(0, 1)": 2045,
      "(-1, 1)": 169,
      "(0, scale_max_val)": 33,
      "(0, 255)": 10,
      "(0, 100)": 8,
      "(1, 2)": 4,
      "(-0.5, 0.5)": 3,
      "(-1, 0)": 2,
      "feature_range": 2,
      "(0.2, 1)": 2,
      "(0.1, 1.1)": 2,
      "(0.01, 0.99)": 2,
      "(0, 2000)": 1,
      "(0.001, 0.999)": 1,
      "(1e-05, 1)": 1,
      "(0, 3)": 1,
      "range_features": 1,
      "(-1 + 1e-06, 1 - 1e-06)": 1,
      "(-8, 8)": 1,
      "(0, 64)": 1,
      "(0, 60)": 1,
      "(20, 400)": 1,
      "(1, 3)": 1,
      "(1, 10)": 1,
      "(1, 20)": 1,
      "minmax": 1,
      "(0, 6)": 1
    },
    "sklearn.preprocessing._label.LabelBinarizer.fit_transform.y": {
      "merge['brand_name']": 56,
      "df['brand_name']": 21,
      "train['brand_name']": 16,
      "train['item_condition_id']": 10,
      "train['shipping']": 10,
      "y0": 7,
      "y": 6,
      "lbls": 6,
      "train['color']": 6,
      "test['color']": 6,
      "y_train": 5,
      "df.label": 4,
      "train['main_cat']": 4,
      "train['sub_cat']": 4,
      "train['item_cat']": 4,
      "df['shipping']": 4,
      "merged_df[feat]": 4,
      "train['type']": 4,
      "labels": 3,
      "df_all['brand_name']": 3,
      "y_valid": 3,
      "tt_combine['brand_name']": 3,
      "df_train['brand_name']": 3,
      "dataset['brand_name']": 3,
      "train_data": 3,
      "data": 3,
      "small_labels": 2,
      "train_labels": 2,
      "train[col]": 2,
      "merge['ip']": 2,
      "merge['app']": 2,
      "merge['device']": 2,
      "merge['os']": 2,
      "merge['channel']": 2,
      "train_df['brand_name']": 2,
      "train_df['item_condition_id']": 2,
      "train_df['shipping']": 2,
      "data['diagnosis'].values": 2,
      "df[mul_var_name]": 2,
      "all_data['brand_name']": 2,
      "dt.brand_name": 2,
      "all_data['Breed1']": 2,
      "train['subcat_1']": 2,
      "train['subcat_2']": 2,
      "train['subcat_3']": 2,
      "train['cat_1']": 2,
      "train['cat_2']": 2,
      "train['cat_3']": 2,
      "y_tr": 2,
      "graphemeLabels": 1,
      "vowelLabels": 1,
      "consonantLabels": 1,
      "train_data[col]": 1,
      "data2['Location']": 1,
      "xtrainq": 1,
      "full_data['brand_name']": 1,
      "full_data['general_cat']": 1,
      "full_data['subcat_1']": 1,
      "full_data['subcat_2']": 1,
      "col": 1,
      "np.array(df[bol]).reshape(-1, 1)": 1,
      "combined_data['brand_name']": 1,
      "train.label": 1,
      "Y_train_root": 1,
      "Y_train_vowel": 1,
      "Y_train_consonant": 1,
      "df_all['name']": 1,
      "y_true": 1,
      "prices_binned": 1,
      "nitems_binned": 1,
      "[sub_states[idx] for idx in train.index]": 1,
      "[sub_grades[idx] for idx in train.index]": 1,
      "[sub_cats[idx] for idx in train.index]": 1,
      "[sub_subcats[idx] for idx in train.index]": 1,
      "train_df['cat_dae']": 1,
      "train_df['cat_jung']": 1,
      "train_df['cat_so']": 1,
      "date_feature": 1,
      "train.word": 1,
      "label_ids": 1,
      "df.Year": 1,
      "input_labels": 1,
      "train_cat_df[col]": 1,
      "df_train['species'].values": 1,
      "['X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X8']": 1,
      "train_data['author']": 1,
      "train_csr_matrix['item_condition_id']": 1,
      "train_csr_matrix['shipping']": 1,
      "df_train['brand_name'].fillna('nan')": 1,
      "train_y": 1,
      "train[i]": 1,
      "test[i]": 1,
      "target": 1,
      "y_j": 1,
      "X_train['brand_name']": 1,
      "X_train['main_category']": 1,
      "X_train['sub_category_1']": 1,
      "X_train['sub_category_2']": 1,
      "train_resources[label]": 1,
      "df.brand_name": 1,
      "train['ClassId']": 1,
      "X": 1,
      "traintest['category1']": 1,
      "traintest['category2']": 1,
      "traintest['category3']": 1,
      "traintest['category4']": 1,
      "traintest['category5']": 1,
      "traintest['brand']": 1,
      "df['item_condition_id']": 1,
      "merged['brand_name']": 1,
      "train['grapheme_root'].values": 1,
      "train['vowel_diacritic'].values": 1,
      "train['consonant_diacritic'].values": 1,
      "all_data['State']": 1,
      "all_data['Color1']": 1,
      "all_data['Color2']": 1,
      "all_data['Color3']": 1,
      "train['cp_dose']": 1,
      "train['cat_top']": 1,
      "train['cat_sub']": 1,
      "train['item']": 1,
      "train_df['cat_1']": 1,
      "train_df['cat_2']": 1,
      "train_df['cat_3']": 1,
      "train['Sex']": 1,
      "data[col]": 1,
      "data['brand_name']": 1,
      "dataset['cat1']": 1,
      "dataset['cat2']": 1,
      "dataset['cat3']": 1,
      "X['Condition1']": 1,
      "X['MasVnrType'].astype(str)": 1,
      "X['BsmtFinType1'].astype(str)": 1,
      "X['BsmtFinType2'].astype(str)": 1,
      "y_test": 1,
      "train_data['brand_name']": 1,
      "train_data['shipping']": 1,
      "train_data['cat_0']": 1,
      "train_data['cat_1']": 1,
      "train_data['cat_2']": 1,
      "all.Breed1": 1,
      "all.Breed2": 1,
      "all.Type": 1,
      "all.Gender": 1,
      "all.Vaccinated": 1,
      "all.Dewormed": 1,
      "all.FurLength": 1,
      "all.Sterilized": 1,
      "all.Health": 1,
      "all.Color1": 1,
      "all.Color2": 1,
      "all.Color3": 1,
      "list(train_y)": 1,
      "list(cv_y)": 1,
      "df_train['gencat_name']": 1,
      "df_train['subcat1_name']": 1,
      "df_train['subcat2_name']": 1,
      "merge_2['brand_name']": 1,
      "electronics['brand_name']": 1,
      "cat_data[:, 0].astype(cat_types[i])": 1,
      "data_train[i]": 1,
      "df['intercept']": 1,
      "train_csv['sex']": 1,
      "test_csv['sex']": 1,
      "train['gencat_name']": 1,
      "train['subcat1_name']": 1,
      "train['subcat2_name']": 1,
      "comb['brand_name']": 1,
      "train_world": 1,
      "train_event_id": 1,
      "train_title": 1,
      "train_args": 1,
      "train_info": 1,
      "full_df['brand_name']": 1,
      "df_train['parent_category_name']": 1,
      "df_train['category_name']": 1,
      "df_train['region']": 1,
      "df_train['city']": 1,
      "df_train['image_top_1']": 1,
      "df_train['user_type']": 1,
      "y['surface']": 1,
      "features_Data.bin_3": 1,
      "features_Data.bin_4": 1,
      "train_set['author']": 1,
      "label_list": 1,
      "person_id": 1,
      "partial_train['has_cactus']": 1,
      "Y3D": 1,
      "Y2D": 1,
      "df[i].fillna(df[i].mode()[0], axis=0)": 1,
      "test['brand_name']": 1,
      "Y_train": 1,
      "train_brand_name": 1,
      "features_data[['Country_Region']]": 1,
      "features_data[['Province_State']]": 1,
      "Combined_data['brand_name']": 1,
      "Combined_data['L0']": 1,
      "Combined_data['L1']": 1,
      "Combined_data['L2']": 1,
      "train['cuisine']": 1,
      "Y": 1,
      "df['user_id'].values": 1,
      "df['city'].values": 1,
      "df['region'].values": 1,
      "df['category_name'].values": 1,
      "df['parent_category_name'].values": 1,
      "df['user_type'].values": 1,
      "df['param_1'].values": 1,
      "df['param_2'].values": 1,
      "df['param_3'].values": 1,
      "data[feature]": 1,
      "app_train.TARGET": 1
    },
    "sklearn.linear_model._coordinate_descent.Lasso.__init__.alpha": {
      "1.0": 311,
      "0.1": 78,
      "0.0005": 68,
      "alpha": 39,
      "0.01": 26,
      "0.001": 24,
      "0.005": 17,
      "0.0001": 15,
      "1": 11,
      "0.05": 9,
      "10": 7,
      "0.5": 6,
      "1e-06": 6,
      "0.031": 5,
      "5": 5,
      "0.3": 4,
      "a": 4,
      "1e-07": 4,
      "0.4": 4,
      "0.03": 4,
      "i": 4,
      "5.5": 4,
      "200000": 4,
      "best_alpha": 4,
      "0.0004": 4,
      "100": 3,
      "alpha_val": 3,
      "199.01": 3,
      "0.9": 3,
      "1e-05": 3,
      "0.2": 2,
      "2": 2,
      "0.0002": 2,
      "lassocv.alpha_": 2,
      "0.75": 2,
      "0.00012609086150256233": 2,
      "0.006": 2,
      "lasso_best_Lambdas": 2,
      "0.0007": 2,
      "0.0009": 2,
      "best_lasso_alpha": 2,
      "25": 1,
      "lasso_regressor.best_params_['alpha']": 1,
      "2.5": 1,
      "0.0008": 1,
      "c": 1,
      "2 * lassocv.alpha_": 1,
      "181": 1,
      "lamb": 1,
      "model.alpha_": 1,
      "0.0002789651831563553": 1,
      "8": 1,
      "0.025": 1,
      "10.0": 1,
      "alpha_use": 1,
      "lmda": 1,
      "_alpha": 1,
      "0.00041398687418613947": 1,
      "0.0": 1,
      "0.04": 1,
      "alpha / div_fac": 1,
      "1.2": 1,
      "0.15": 1,
      "0.02": 1,
      "params['alpha']": 1,
      "0.02945": 1,
      "0.07492": 1,
      "0.005074705239490466": 1,
      "0.25": 1,
      "1500": 1,
      "trial.suggest_float('alpha', 0.01, 1)": 1,
      "10**(-i)": 1,
      "parameter[0]": 1,
      "0.0002144127223451149": 1,
      "225.1066014107722": 1,
      "model_CV.alpha_": 1,
      "0.0004225349823414949": 1,
      "lasso_cv1.alpha_": 1,
      "lasso_cv2.alpha_": 1,
      "lasso_cv3.alpha_": 1,
      "0.00052": 1,
      "2**(-12)": 1,
      "69": 1,
      "50": 1,
      "0.011262757057466669": 1
    },
    "sklearn.linear_model._coordinate_descent.Lasso.__init__.random_state": {
      "None": 566,
      "1": 79,
      "42": 32,
      "seed": 17,
      "0": 15,
      "random_state": 10,
      "32": 4,
      "SEED": 4,
      "2020": 2,
      "RANDOM_STATE": 2,
      "random_seed": 2,
      "123": 2,
      "5": 2,
      "RANDOM_SEED": 2,
      "111": 1,
      "2021": 1,
      "520": 1,
      "3": 1,
      "31": 1,
      "45": 1,
      "198": 1,
      "7": 1,
      "101": 1
    },
    "sklearn.svm._classes.SVC.__init__.random_state": {
      "None": 1419,
      "0": 71,
      "42": 51,
      "1": 32,
      "random_state": 29,
      "seed": 27,
      "2020": 12,
      "SEED": 3,
      "10": 3,
      "30": 3,
      "100": 3,
      "4": 3,
      "80": 2,
      "7": 2,
      "RS": 2,
      "randomState": 1,
      "55": 1,
      "20": 1,
      "108": 1,
      "777": 1,
      "24": 1,
      "2": 1,
      "123456": 1,
      "RANDOM_SEED": 1,
      "314": 1,
      "222": 1,
      "2109": 1,
      "16446054": 1
    },
    "sklearn.model_selection._validation.cross_val_score.estimator": {
      "model": 912,
      "clf": 318,
      "knn": 200,
      "classifier": 115,
      "rf": 102,
      "lr": 69,
      "pipeline": 54,
      "xgb": 45,
      "reg": 39,
      "pipe": 38,
      "svc": 34,
      "rf_model": 28,
      "rfc": 23,
      "xgb_model": 22,
      "logreg": 21,
      "forest": 20,
      "LinearRegression()": 19,
      "ecv": 19,
      "self.stacker": 18,
      "estimator": 17,
      "m": 17,
      "regressor": 16,
      "nb_model": 16,
      "ridge": 16,
      "dt": 15,
      "clf_NB_TFIDF": 14,
      "regr": 14,
      "LogisticRegression()": 14,
      "lasso": 14,
      "clf_NB": 13,
      "random_forest": 13,
      "LR": 13,
      "mnb": 13,
      "my_pipeline": 13,
      "sgd": 12,
      "lm": 12,
      "model1": 11,
      "lin_reg": 11,
      "svm": 11,
      "ovr": 11,
      "clf_tfidf": 10,
      "nb": 10,
      "decision_tree": 10,
      "gnb": 10,
      "sgd_clf": 10,
      "log_reg": 10,
      "model2": 10,
      "log_model": 10,
      "clf_xgb": 9,
      "lr_model": 9,
      "rfr": 9,
      "svr": 9,
      "mod": 9,
      "knn_model": 8,
      "rfc_model": 8,
      "svc_model": 8,
      "gaussian": 8,
      "perceptron": 8,
      "linear_svc": 8,
      "gbr": 8,
      "lasso_reg": 8,
      "clf2": 8,
      "lg": 8,
      "knn_best": 7,
      "clf_xgb_TFIDF": 7,
      "forest_reg": 7,
      "lgbm": 7,
      "tree": 7,
      "clf1": 7,
      "linreg": 7,
      "ridge_reg": 7,
      "ada": 7,
      "svm_clf": 7,
      "dtr": 7,
      "p": 7,
      "gcv": 7,
      "loj_model": 6,
      "rf_clf": 6,
      "dtree_model": 6,
      "tree_model": 6,
      "dtc": 6,
      "clc": 6,
      "clfs[clf]['clf']": 6,
      "nn": 6,
      "model3": 6,
      "xgb_param": 6,
      "xgb_reg": 6,
      "model_xgb": 6,
      "vote": 6,
      "gs": 6,
      "svm_classifier": 6,
      "rfc_best": 5,
      "dtree": 5,
      "voting_clf": 5,
      "ensemble": 5,
      "log_clf": 5,
      "rf_reg": 5,
      "neigh": 5,
      "clf3": 5,
      "xg": 5,
      "reg_CC": 5,
      "reg_Fat": 5,
      "rcv": 5,
      "ompcv": 5,
      "xgbm": 5,
      "xgbr": 5,
      "gridcv": 5,
      "pipe_xg1": 5,
      "logit": 5,
      "svm_best": 4,
      "lgbm_model": 4,
      "alg": 4,
      "enc": 4,
      "forest_clf": 4,
      "voting_clf_hard": 4,
      "voting_clf_soft": 4,
      "voting_clf_all": 4,
      "lsvc": 4,
      "xgd_model": 4,
      "tree_reg": 4,
      "neighbors.KNeighborsClassifier(n_neighbors=i, weights='distance')": 4,
      "clf_log": 4,
      "tree_clf": 4,
      "RandomForestClassifier()": 4,
      "logisticRegr": 4,
      "pipe_vc": 4,
      "rmclassifier": 4,
      "algorithm": 4,
      "model_kfold": 4,
      "DecisionTree": 4,
      "knn_pipe": 4,
      "knn_classifier": 4,
      "rf_classifier": 4,
      "lda_classifier": 4,
      "Ridge()": 3,
      "dt_model": 3,
      "model_one": 3,
      "titanic_pipeline": 3,
      "svm_pipe": 3,
      "et_model": 3,
      "etc": 3,
      "pipe_xgb": 3,
      "clc1": 3,
      "gbr_reg": 3,
      "abc": 3,
      "m1": 3,
      "model4": 3,
      "lgb_a": 3,
      "GBR_model": 3,
      "en": 3,
      "modelo": 3,
      "dtmodel": 3,
      "rfmodel": 3,
      "vclf": 3,
      "gb": 3,
      "lgb_model": 3,
      "x": 3,
      "i": 3,
      "algo_model": 3,
      "regression": 3,
      "GB_clf": 3,
      "Model": 3,
      "xrf_model": 3,
      "logreg_clf": 3,
      "kernel_SVR": 3,
      "ridge_mod": 3,
      "lasso_mod": 3,
      "clf_dt": 3,
      "cb": 3,
      "XGB": 3,
      "GradientBoostingClassifier(random_state=123, **params_gbm)": 3,
      "i[1]": 3,
      "clf_logreg": 3,
      "clf_rfc": 3,
      "lmodel": 2,
      "mdl": 2,
      "Ridge_CV": 2,
      "Lasso_CV": 2,
      "algo": 2,
      "knn_standard": 2,
      "knn_mp": 2,
      "rf_best": 2,
      "etr": 2,
      "xgb_pipeline": 2,
      "cf": 2,
      "cat_regressor": 2,
      "xgb_regressor": 2,
      "rf_regressor": 2,
      "s": 2,
      "m2": 2,
      "Classifier": 2,
      "xgb.XGBRegressor(n_estimators=750, learning_rate=0.02, max_depth=5)": 2,
      "CatBoostRegressor(loss_function='RMSE', verbose=False)": 2,
      "RGFRegressor(max_leaf=500, algorithm='RGF_Sib', test_interval=100, loss='LS')": 2,
      "KNN": 2,
      "lin": 2,
      "ridge_clf": 2,
      "xgb_clf": 2,
      "linear_model": 2,
      "mlp_reg": 2,
      "clf4": 2,
      "clf_gini": 2,
      "logR": 2,
      "ensemble_lin_rbf": 2,
      "sgd_class": 2,
      "model5": 2,
      "tuned_model": 2,
      "clf_bgr_CC": 2,
      "clf_bgr_Fat": 2,
      "best_knn": 2,
      "boosting": 2,
      "clf_lr": 2,
      "svc_wordEmbed": 2,
      "xgb_wordEmbed": 2,
      "lcv": 2,
      "pipe_imp": 2,
      "gbc": 2,
      "et": 2,
      "c": 2,
      "clf_CC": 2,
      "clf_Fat": 2,
      "model_infected": 2,
      "model_deaths": 2,
      "grad": 2,
      "voting": 2,
      "my_pipeline0": 2,
      "knn_clf": 2,
      "elastic": 2,
      "eclf": 2,
      "RFC": 2,
      "lgb": 2,
      "vc": 2,
      "DecisionTreeRegressor(min_samples_split=30000)": 2,
      "IsotonicRegression(3, 140)": 2,
      "grid.best_estimator_": 2,
      "text_clf": 2,
      "svm_temp_all": 2,
      "svm_temp_imp": 2,
      "svm_temp_unimp": 2,
      "knr": 2,
      "rid": 2,
      "knears_neighbors": 2,
      "stack": 2,
      "booster": 2,
      "svm_model": 2,
      "linear": 2,
      "random": 2,
      "sgdreg": 2,
      "RandomForestClassifier(n_estimators=100)": 2,
      "pipe1": 2,
      "pipe2": 2,
      "pipe_1": 2,
      "pipe_2": 2,
      "rf_pipeline": 2,
      "model_lr": 2,
      "modelo_ridge": 2,
      "cls": 2,
      "GBC": 2,
      "lrmodel": 2,
      "pipe_knn": 2,
      "pipe_rfc": 2,
      "pipe_etc": 2,
      "sgd_model": 2,
      "lr_2": 2,
      "logreg0": 2,
      "logreg1": 2,
      "arno_model": 2,
      "model_forestreg": 2,
      "xgclf": 2,
      "knn_from_function": 2,
      "first_tree": 2,
      "first_knn": 2,
      "rg5": 2,
      "logisticPolyRegr": 2,
      "clf_svm": 2,
      "scl": 2,
      "log_bo": 2,
      "KNeighborsClassifier(**params_knn)": 2,
      "DecisionTreeClassifier(random_state=123, **params_dt)": 2,
      "RandomForestClassifier(random_state=123, **params_rf)": 2,
      "lgbm_bo": 2,
      "XGBClassifier(random_state=123, **params_xgb)": 2,
      "NB": 2,
      "est": 2,
      "gbm": 2,
      "items": 2,
      "stacking_cv_reg": 2,
      "ex": 2,
      "lgb20": 2,
      "bagging": 2,
      "clf_SGD": 2,
      "nb_classifier": 2,
      "lr_classifier": 2,
      "en_pipeline": 1,
      "lgbm_pipeline": 1,
      "cat_pipeline": 1,
      "ensemble_pipe": 1,
      "Lmodel": 1,
      "model_lgb": 1,
      "logestic": 1,
      "dTree": 1,
      "randomForest": 1,
      "tuned_voting": 1,
      "lightgbm": 1,
      "svm_reg": 1,
      "multi_nb": 1,
      "ElasticNet_model": 1,
      "avg_mod": 1,
      "training": 1,
      "model_no_smote": 1,
      "model_smote": 1,
      "pipe_lasso": 1,
      "pipe_svr": 1,
      "RF_baseline": 1,
      "abr": 1,
      "SVR(kernel='rbf', C=10)": 1,
      "SVR(kernel='rbf', C=1)": 1,
      "xgb_classifier": 1,
      "SVC(kernel=k)": 1,
      "RF_classifier_kfold": 1,
      "elasticnet": 1,
      "log": 1,
      "RF": 1,
      "model.set_params(**hyperparameters)": 1,
      "sgdc": 1,
      "Pipe_lr": 1,
      "best_grid": 1,
      "hyper_xgboost": 1,
      "classifier_etc": 1,
      "classifier_k_best": 1,
      "clf_con": 1,
      "chosen_pipeline": 1,
      "best_clf": 1,
      "mnb_clf": 1,
      "RandomForestRegressor()": 1,
      "cat": 1,
      "clsf": 1,
      "best_rf": 1,
      "RandomForestClassifier_model": 1,
      "SGDClassifier_model": 1,
      "MultinomialNB_model": 1,
      "lr_bag_reg": 1,
      "nb_pipeline": 1,
      "svm_pipeline": 1,
      "self.level0": 1,
      "ridge_regressor": 1,
      "lgb_reg": 1,
      "clf_svc_cv": 1,
      "pipe9": 1,
      "pipe10": 1,
      "mp": 1,
      "final_pipeline": 1,
      "tree_cls": 1,
      "kNN": 1,
      "gbm_gridsearch": 1,
      "rand_forest_gridsearch": 1,
      "extra_trees_gridsearch": 1,
      "adaboost_gridsearch": 1,
      "RandomForestClassifier(n_estimators=100, n_jobs=-1)": 1,
      "stackers[label]": 1,
      "gbcl": 1,
      "model_test": 1,
      "Bayes": 1,
      "xgb.XGBClassifier()": 1,
      "clf_xgb_CC": 1,
      "clf_xgb_Fat": 1,
      "lm1": 1,
      "lm2": 1,
      "XGBmod": 1,
      "ls": 1,
      "clf_nb": 1,
      "boosting_search.best_estimator_": 1,
      "GBR()": 1,
      "GBR(alpha=alpha)": 1,
      "CountV_NB": 1,
      "base_model": 1,
      "clf_NB_wEmbed": 1,
      "symbRegage": 1,
      "xg_cls": 1,
      "xg_reg": 1,
      "mlpreg": 1,
      "mlpcls": 1,
      "clf_svc": 1,
      "clf_rf": 1,
      "rf_clf_resampled": 1,
      "linear_reg": 1,
      "llrcv": 1,
      "lgbm_reg": 1,
      "gnb_model": 1,
      "dtc_model": 1,
      "averaged": 1,
      "stack_with_feats": 1,
      "stack_retrain": 1,
      "stack_avg": 1,
      "most_frequent": 1,
      "MultinomialNB()": 1,
      "sgdr": 1,
      "classficador": 1,
      "LogisticRegression(random_state=42)": 1,
      "lr_cost": 1,
      "rf_cost": 1,
      "rf_appr": 1,
      "xgb_appr": 1,
      "linr": 1,
      "elas": 1,
      "br": 1,
      "rftree": 1,
      "v": 1,
      "ml_pipeline": 1,
      "my_pipeline1": 1,
      "model_cat": 1,
      "pipe_bi": 1,
      "pipe_tri": 1,
      "ada_reg": 1,
      "Tree": 1,
      "Forest": 1,
      "Boost": 1,
      "Support": 1,
      "model_6": 1,
      "model_8": 1,
      "lgbr": 1,
      "decorated_model": 1,
      "classifierRFC": 1,
      "mymodel_Lin": 1,
      "mymodel_RF": 1,
      "mymodel_LGB": 1,
      "logreg_bow": 1,
      "logreg_tfidf": 1,
      "NB_bow": 1,
      "NB_tfidf": 1,
      "r_clf": 1,
      "clf_HistGradientBoostingClassifier": 1,
      "clf_CatBoostClassifier": 1,
      "rf1": 1,
      "lassocv": 1,
      "el1": 1,
      "modelNB": 1,
      "modelNB_weighted": 1,
      "modelMultiNB": 1,
      "modelMultiNB_weighted": 1,
      "randomforest": 1,
      "stacker": 1,
      "bernoulli_nb": 1,
      "svc_clf": 1,
      "LR_pipe": 1,
      "BNB_pipe": 1,
      "DT_pipe": 1,
      "SVC_pipe": 1,
      "voting_clf_4": 1,
      "voting_clf_LR_DT": 1,
      "voting_clf_SVC_DT": 1,
      "voting_clf_BNB_DT": 1,
      "RFC2": 1,
      "et2": 1,
      "lgb2": 1,
      "BernoulliNB(fit_prior=False)": 1,
      "multinomialnb_classifier": 1,
      "gnb_classifier": 1,
      "logisticreg_classifier": 1,
      "xb1": 1,
      "gb1": 1,
      "catBoost_model": 1,
      "rgf_model": 1,
      "mlp": 1,
      "reg_all": 1,
      "models[model]": 1,
      "svm1_all": 1,
      "svm1_imp": 1,
      "svm1_unimp": 1,
      "svm2_all": 1,
      "svm2_imp": 1,
      "svm2_unimp": 1,
      "svm3_all": 1,
      "svm3_imp": 1,
      "svm3_unimp": 1,
      "lr_imp_1": 1,
      "lr_imp_2": 1,
      "lr_imp_3": 1,
      "ENSTest": 1,
      "GBest": 1,
      "clf_dummy": 1,
      "RandomForestClassifier(n_estimators=int(n_estimators), min_samples_split=int(min_samples_split), max_features=min(max_features, 0.999), max_depth=int(max_depth), random_state=2)": 1,
      "clf_SVC": 1,
      "clf_SVC_TFIDF": 1,
      "clf_voting": 1,
      "rfor_model": 1,
      "extr": 1,
      "clf_stack": 1,
      "clf_stack1": 1,
      "clf_stack2": 1,
      "clf_stack3": 1,
      "clf_no_outliers": 1,
      "smote_clf": 1,
      "rand_up_clf": 1,
      "t_clf": 1,
      "clf_stop": 1,
      "logistic_model": 1,
      "nb_clf": 1,
      "logit_clf": 1,
      "lda_clf": 1,
      "qda_clf": 1,
      "model_rnd_frst": 1,
      "SVC()": 1,
      "MultinomialNB(alpha=1)": 1,
      "BernoulliNB(alpha=1)": 1,
      "xgboost": 1,
      "ex_pipe": 1,
      "xg_pipe": 1,
      "rbf": 1,
      "GaussianNB()": 1,
      "CLR": 1,
      "NB_Vec": 1,
      "CatBoostRegressor(iterations=2000, depth=9, learning_rate=learning_rate, loss_function='RMSE', verbose=False)": 1,
      "CatBoostRegressor(iterations=4000, depth=9, learning_rate=0.5, loss_function='RMSE', early_stopping_rounds=early_stopping_rounds, verbose=False)": 1,
      "CatBoostRegressor(iterations=12000, depth=9, learning_rate=learning_rate, loss_function='RMSE', verbose=False)": 1,
      "logisticRegr_sm": 1,
      "group_RF_classifier": 1,
      "log_classifier": 1,
      "ensemble.AdaBoostRegressor(base_estimator=LinearRegression(normalize=True))": 1,
      "catboost_pandas_clf": 1,
      "gscv": 1,
      "gscv.best_estimator_": 1,
      "model_1": 1,
      "pred_model": 1,
      "lovy": 1,
      "KNNclf": 1,
      "BOW_XGB": 1,
      "forest_model": 1,
      "gbr_model": 1,
      "b2o": 1,
      "rand_clf": 1,
      "model_7": 1,
      "model_rs": 1,
      "XGBRegressor(random_state=SEED)": 1,
      "XGBRegressor(n_estimators=tuned_params['n_estimators'], learning_rate=tuned_params['learning_rate'], random_state=SEED)": 1,
      "my_model_best": 1,
      "lr_mod": 1,
      "baseline": 1,
      "classifier_RF": 1,
      "clfy": 1,
      "selector": 1,
      "casual_model": 1,
      "registered_model": 1,
      "lin_reg_2": 1,
      "logreg01": 1,
      "lass0": 1,
      "lass": 1,
      "lass1": 1,
      "logreg2": 1,
      "logreg3": 1,
      "KNNModel": 1,
      "lr_lassocv": 1,
      "lr_ridgecv": 1,
      "elastic_net": 1,
      "lr_elastic_netcv": 1,
      "model_linreg": 1,
      "model_lassoreg": 1,
      "model_lassoreg_cv": 1,
      "model_ridgereg": 1,
      "model_ridgereg_cv": 1,
      "model_elasticnetreg": 1,
      "model_elasticnetreg_cv": 1,
      "model_kernelridgereg": 1,
      "model_kernelridgereg_cv": 1,
      "model_treereg": 1,
      "xg_clf": 1,
      "svc_cv": 1,
      "lr_1": 1,
      "lr_3": 1,
      "lr_4": 1,
      "knn_1": 1,
      "mt.modelObj": 1,
      "ExtraTreesRegressor(n_estimators=30)": 1,
      "ridge_pipe": 1,
      "stack_gen": 1,
      "model_xgb2": 1,
      "m3": 1,
      "m4": 1,
      "st": 1,
      "lgbmc_clf": 1,
      "ada_clf": 1,
      "slr": 1,
      "best_grid_en.best_estimator_": 1,
      "clf_NB_tfidf": 1,
      "clf_xgb_tfidf": 1,
      "logisticModel": 1,
      "rf_cv": 1,
      "individual": 1,
      "neural_network": 1,
      "xgb_cl": 1,
      "sgd_lin_reg": 1,
      "ridge_lin_reg": 1,
      "lasso_lin_reg": 1,
      "elastic_lin_reg": 1,
      "lin_SVR": 1,
      "dt_reg": 1,
      "model[1]": 1,
      "kn": 1,
      "sv": 1,
      "rf_tuned": 1,
      "DecisionTreeRegressor()": 1,
      "RandomForestRegressor(n_estimators=20)": 1,
      "clf_tree_rnd.best_estimator_": 1,
      "neighgrid.best_estimator_": 1,
      "catb": 1,
      "logistic_regression": 1,
      "gaussianNB": 1,
      "rg": 1,
      "rg2": 1,
      "rg3": 1,
      "rg4": 1,
      "rg6": 1,
      "rg7": 1,
      "rg8": 1,
      "rg9": 1,
      "rg10": 1,
      "clf5": 1,
      "model6": 1,
      "pbf": 1,
      "knc": 1,
      "lgbm_": 1,
      "rdFrt": 1,
      "pca": 1,
      "lda": 1,
      "bnb": 1,
      "lgr": 1,
      "rf_class": 1,
      "KNR_class": 1,
      "GDR_class": 1,
      "LR_class": 1,
      "Lasso_class": 1,
      "Ridge_class": 1,
      "DTR_class": 1,
      "Ridge(alpha=1)": 1,
      "SGDClassifier()": 1,
      "linear1hot": 1,
      "linearlabel": 1,
      "sgd_clone": 1,
      "model_NB": 1,
      "model_clf": 1,
      "model_svc": 1,
      "model_knn": 1,
      "model_rfc": 1,
      "model_abc": 1,
      "clf_dt_prune": 1,
      "bagclf": 1,
      "xbc": 1,
      "cat_boost_reg": 1,
      "GBoost": 1,
      "LogisticRegression(C=5, random_state=42, solver='sag', max_iter=1000, n_jobs=-1)": 1,
      "ftd_clf": 1,
      "randf": 1,
      "lassoCV": 1,
      "ridgecv": 1,
      "elasticNet_cv": 1,
      "logreg_gs": 1,
      "rf_gs": 1,
      "et_gs": 1,
      "dt_gs": 1,
      "sclf": 1,
      "gbm_bo2": 1,
      "Ridge(random_state=123, **params_ridge)": 1,
      "Lasso(random_state=123, **params_lasso)": 1,
      "ElasticNet(random_state=123, **params_net)": 1,
      "KNeighborsRegressor(**params_knn)": 1,
      "SVR(**params_svm)": 1,
      "DecisionTreeRegressor(random_state=123, **params_dt)": 1,
      "RandomForestRegressor(random_state=123, **params_rf)": 1,
      "GradientBoostingRegressor(random_state=123, **params_gbm)": 1,
      "LGBMRegressor(random_state=123, **params_lgbm)": 1,
      "XGBRegressor(random_state=123, **params_xgb)": 1,
      "SDG": 1,
      "model_two": 1,
      "reg[target]": 1,
      "model_Lasso": 1,
      "randomforest2": 1,
      "bagged_classifier": 1,
      "make_pipeline(TfidfVectorizer(stop_words=None, preprocessor=None, max_features=None, ngram_range=(1, 1)), LinearRegression())": 1,
      "make_pipeline(TfidfVectorizer(stop_words=None, preprocessor=None, max_features=None, ngram_range=(1, 2)), LinearRegression())": 1,
      "make_pipeline(TfidfVectorizer(stop_words=None, preprocessor=None, max_features=None, ngram_range=(1, 3)), LinearRegression())": 1,
      "cbc": 1,
      "rf_model_for_test": 1,
      "RClassifier": 1,
      "RandomForestClassifier(n_estimators=1000)": 1,
      "rnd1": 1,
      "ex1": 1,
      "lr_model_best": 1,
      "model_KR": 1,
      "model_pipeline": 1,
      "LogisticRegression(solver='lbfgs')": 1,
      "QuadraticDiscriminantAnalysis()": 1,
      "model_rf": 1,
      "naive_model": 1,
      "ANN_classifier": 1,
      "classifier1": 1,
      "cf2": 1,
      "logModel": 1,
      "DT_model": 1,
      "RF_model": 1,
      "Pipe": 1,
      "pipe_3": 1,
      "pipe_4": 1,
      "pipe_5": 1,
      "pipe_6": 1,
      "pipe_7": 1,
      "RFR": 1,
      "GB": 1,
      "m5": 1,
      "linear_model.LinearRegression()": 1,
      "LogisticRegressionCV(cv=5)": 1,
      "linmodel": 1,
      "final_xgb": 1,
      "knn_pl": 1,
      "rfcla": 1,
      "clf_linear": 1,
      "li_reg": 1,
      "iterclf": 1,
      "method": 1,
      "svm_classifier.best_estimator_": 1,
      "raf_classifier.best_estimator_": 1,
      "xgb_classifier.best_estimator_": 1,
      "ens_classifier": 1,
      "rd": 1,
      "best_pipe": 1,
      "LR_MODEL": 1,
      "DT_MODEL": 1,
      "RF_MODEL": 1,
      "lgbm_classifier": 1,
      "clf_pipe": 1,
      "Lasso(alpha)": 1,
      "Ridge(alpha)": 1,
      "robust_lasso": 1,
      "ENet": 1,
      "robust_ENet": 1,
      "stacking": 1,
      "model_data_pipeline": 1,
      "RidgeCV": 1,
      "value": 1,
      "modelXGB": 1,
      "modellgbm": 1,
      "modelcat": 1,
      "classifier_model": 1,
      "nn_model": 1,
      "smote": 1,
      "DecisionTreeClassifier()": 1,
      "lm_fatal": 1,
      "base_clf": 1,
      "new_clf_SGD": 1,
      "ridreg": 1,
      "lasreg": 1,
      "treereg": 1,
      "model_new": 1,
      "model_enc": 1,
      "rnd": 1,
      "LogisticRegression(C=4, dual=True)": 1,
      "ovrm": 1,
      "rand": 1,
      "low_tree_model": 1,
      "model_RF": 1,
      "model_LRL2": 1,
      "clf_knn": 1,
      "lgbR": 1,
      "reg_LR": 1,
      "reg_SGD": 1,
      "xgbreg": 1,
      "catreg": 1,
      "lgbreg": 1,
      "lgbm_grid": 1,
      "stacking_cv_reg_exclude": 1,
      "rr": 1,
      "GBR": 1,
      "regr_XGB": 1,
      "pipe_cat": 1,
      "model[i]": 1,
      "model_ctb": 1,
      "model_ctb_up": 1,
      "logmodel": 1,
      "classifiers": 1
    },
    "sklearn.model_selection._validation.cross_val_score.X": {
      "X_train": 852,
      "X": 753,
      "x_train": 147,
      "train": 130,
      "train_vectors": 107,
      "x": 97,
      "train_tfidf": 50,
      "train_set": 48,
      "X_test": 47,
      "train.values": 41,
      "train_features": 38,
      "Xtrain": 37,
      "train_data": 32,
      "x_test": 31,
      "X_train_scaled": 31,
      "train_x": 26,
      "X1": 24,
      "XbalTrain": 23,
      "features": 21,
      "norm_train_data": 20,
      "pca_train_data": 20,
      "train_X": 20,
      "S_train": 18,
      "train_vector": 18,
      "data": 18,
      "Xs_train": 17,
      "housing_prepared": 15,
      "X_tr": 14,
      "gmm_train": 13,
      "train_vectorized": 12,
      "self.x_train": 12,
      "Xs_train_a": 12,
      "X_train_transformed": 10,
      "X2": 10,
      "xcosta": 10,
      "X_scaled": 9,
      "xtrain": 9,
      "X_train.values": 9,
      "x_test_Stem": 9,
      "x_test_Lemm": 9,
      "X_trainS": 9,
      "fitted_data1": 9,
      "X_train_word_features": 8,
      "main_train": 8,
      "pca_X": 8,
      "X_train[pred_type][2]": 8,
      "X_val": 8,
      "x_test_count": 8,
      "Xhousehold": 8,
      "X_train_escala_normaliza": 8,
      "X_train_res": 7,
      "x.drop('Patient', 1)": 7,
      "titanic_prepared": 7,
      "train_df_vectors": 6,
      "train_df_tfidf": 6,
      "xTrain": 6,
      "X_new": 6,
      "df_train['excerpt_clean']": 6,
      "X_train[pred_type][0]": 6,
      "X_train[pred_type][1]": 6,
      "train['text']": 6,
      "X_Scaled": 6,
      "X_train_std": 6,
      "train_bow": 6,
      "train[binarias + discretas]": 6,
      "train_tfidf_vectors": 6,
      "x_test_tf_idf_word": 5,
      "test_x": 5,
      "train_df['excerpt_clean']": 5,
      "X_train1": 5,
      "x_train_res": 5,
      "X_training": 5,
      "train_cv": 5,
      "trainSet": 5,
      "training_vectorizer": 5,
      "data_train": 5,
      "train.drop(['count'], axis=1)": 5,
      "x_train_scale": 5,
      "X[:cutoff4sample_size, :]": 4,
      "x_test_tf": 4,
      "trainRI": 4,
      "X_1": 4,
      "train_prep": 4,
      "trainX": 4,
      "clean_df": 4,
      "x_undercv": 4,
      "x_undertfidf": 4,
      "X_train.todense()": 4,
      "XHHI": 4,
      "X_tfidf": 4,
      "train_x_helpful": 4,
      "x_data_generated": 4,
      "x_test_tf_idf": 4,
      "X_train2": 4,
      "x_features": 4,
      "x_test_tf_idf_ngram": 4,
      "x_test_tf_idf_chars": 4,
      "X_test_transformed": 4,
      "X_mtrain": 4,
      "X_train_vect": 4,
      "X_train_vect2": 4,
      "training_x": 4,
      "train_df['excerpt']": 4,
      "feature_2": 4,
      "principal_df": 4,
      "X_train_sc": 4,
      "X_train_array": 4,
      "X_SMOTE": 3,
      "X_std": 3,
      "Xtrn": 3,
      "X_train_full": 3,
      "X_modeled": 3,
      "titanic": 3,
      "train_vec": 3,
      "all_features": 3,
      "X_sparsed": 3,
      "input_data": 3,
      "tfidf_results_cl": 3,
      "Xhouse": 3,
      "x_selected": 3,
      "Xpos1Train": 3,
      "self.X": 3,
      "Xdf": 3,
      "X_train_clean": 3,
      "X_prep": 3,
      "Train": 3,
      "fit_set1.loc[:, :'Target']": 3,
      "fit_norm.loc[:, :'Target']": 3,
      "X_resampled": 3,
      "data.drop('shot_made_flag', 1)": 3,
      "X_train_copy": 3,
      "dtrain": 3,
      "df_X_train": 3,
      "x_data": 3,
      "all_X": 3,
      "x_train_full": 3,
      "trainx": 3,
      "train.drop(targets, axis=1)": 3,
      "x_train.reshape(train_rows, -1)": 3,
      "predictor": 3,
      "train.drop('Cover_Type', axis=1)": 3,
      "c_df.iloc[:-8, :][['Average Word Length', '# Of Sentences', '# Of Different People Mentioned']]": 3,
      "df_upsampled_vectorized": 3,
      "trained": 3,
      "sourcevars": 2,
      "train_word_features": 2,
      "train_x_prepared": 2,
      "X_train[var].to_frame()": 2,
      "X_mms": 2,
      "X_norm": 2,
      "X_std[:, rfecv.support_]": 2,
      "X_train_cv": 2,
      "train_values": 2,
      "data_train_count_tf": 2,
      "X_full": 2,
      "train_df": 2,
      "x_val": 2,
      "train[features]": 2,
      "feat": 2,
      "X_res": 2,
      "X_train_prepared": 2,
      "text1": 2,
      "xTest": 2,
      "X_train_features": 2,
      "data_to_train": 2,
      "train_bag": 2,
      "vector": 2,
      "train_x_": 2,
      "np.array(res)": 2,
      "df": 2,
      "pca10_X": 2,
      "pca20_X": 2,
      "pca50_X": 2,
      "pca100_X": 2,
      "pca200_X": 2,
      "pca300_X": 2,
      "X_dummies": 2,
      "X_row": 2,
      "X_col": 2,
      "X_orig": 2,
      "Xtreino": 2,
      "X2grauTrain": 2,
      "X3grauTrain": 2,
      "X2_train": 2,
      "X3_train": 2,
      "Xtrain2": 2,
      "xdata": 2,
      "X_holdout": 2,
      "numeric_data": 2,
      "train_final": 2,
      "pd.DataFrame(all_data[col])": 2,
      "train_m": 2,
      "train_df.values": 2,
      "data.values": 2,
      "train_f": 2,
      "pd.DataFrame(train_x[['dis', 'year', 'hour', 'passenger_count']])": 2,
      "Xhh": 2,
      "train_count_vectors": 2,
      "train_fid_vectors": 2,
      "x_original": 2,
      "x_hair_soul": 2,
      "nm_X_train": 2,
      "X.flatten()": 2,
      "x_fit": 2,
      "housing_best_poly_25": 2,
      "X_trainval": 2,
      "X_train1_imp": 2,
      "X_train2_imp": 2,
      "X_train3_imp": 2,
      "X_train_temp_all": 2,
      "X_train_temp_imp": 2,
      "X_train_temp_unimp": 2,
      "train_features_st": 2,
      "XhdbTrain": 2,
      "X_data": 2,
      "train_.drop('target', axis=1)": 2,
      "train_X.values": 2,
      "train_vectors_count": 2,
      "X_train_scal": 2,
      "filter_X_train": 2,
      "X_grid5": 2,
      "X_pca": 2,
      "train_df_x": 2,
      "data_train[data_features]": 2,
      "nptrain_xNu": 2,
      "Xtrain_h": 2,
      "adv": 2,
      "trainDataX": 2,
      "XHHItrain": 2,
      "X_valid": 2,
      "X_train_norm": 2,
      "train_joined": 2,
      "bag_train": 2,
      "tfidf_train": 2,
      "X_train_tmp": 2,
      "text_tfidf": 2,
      "X_ts": 2,
      "prepared_housing_train": 2,
      "validation_x_prepared": 2,
      "a": 2,
      "X[features]": 2,
      "df[col_n]": 2,
      "X_Train_CS": 2,
      "X[::step]": 2,
      "x_res": 2,
      "xtr": 2,
      "train_matrix_tfidf": 2,
      "scaled_train_X.values": 2,
      "np.ones((n, 1))": 2,
      "x_train[train_features]": 2,
      "pca_train": 2,
      "train_encoded": 2,
      "univariate_features": 2,
      "recursive_features": 2,
      "model_features": 2,
      "bow_model_train": 2,
      "tfidf_model_train": 2,
      "X_train_tf": 2,
      "en_df": 1,
      "train_matrix": 1,
      "x_nb": 1,
      "train_feats": 1,
      "train_ohe": 1,
      "XTrain": 1,
      "X_": 1,
      "full_x_train.values": 1,
      "train[random_set]": 1,
      "opt_box_cox_train.values": 1,
      "Xtrain_df": 1,
      "train_set_balanced": 1,
      "X[important_cols]": 1,
      "XdataTrain": 1,
      "x_pc1": 1,
      "qtx.fit_transform(df)": 1,
      "qtx_f.fit_transform(df)": 1,
      "experData_X": 1,
      "X_train.toarray()": 1,
      "Train_SS": 1,
      "X_train_df": 1,
      "clf_train": 1,
      "data_train_count": 1,
      "train[cols]": 1,
      "X_proj": 1,
      "train.ingredients": 1,
      "features.iloc[:, feature_idx]": 1,
      "X_train_pc": 1,
      "traindf.drop(['visitors'], axis=1)": 1,
      "X_train_fe": 1,
      "x_train_normalized": 1,
      "X_2": 1,
      "X_3": 1,
      "X_4": 1,
      "X_5": 1,
      "final_prep": 1,
      "train_tfidf_features": 1,
      "X_Train": 1,
      "X_d": 1,
      "Xw_train": 1,
      "self.trainX": 1,
      "text": 1,
      "train.drop('Survived', axis=1)": 1,
      "train_data_features": 1,
      "trainDataVecs": 1,
      "bench_train": 1,
      "Xadult": 1,
      "train_X.toarray()": 1,
      "X_train_sc[selected_features_gb]": 1,
      "x_train_work": 1,
      "train_x[:10000]": 1,
      "train10.values": 1,
      "dataset": 1,
      "test_rows": 1,
      "X_train.select_dtypes(include=[np.number])": 1,
      "X_OH": 1,
      "newCosta.iloc[:, 0:137]": 1,
      "X.drop(['atom_index'], axis=1)": 1,
      "X[['atom_index', 'eem']]": 1,
      "X[:X_train.shape[0]]": 1,
      "train_cp": 1,
      "X_rfe": 1,
      "temp[train_cols]": 1,
      "temp[['FVC_pred', 'Confidence']]": 1,
      "temp[['Base_FVC', 'cum_min_pms', 'cum_max_pms', 'cum_pms']]": 1,
      "x.drop(['Patient', 'FVC', 'Percent', 'Base_FVC', 'Weeks', 'Base_Week'], 1)": 1,
      "x.drop(['Patient', 'FVC', 'Percent', 'Base_Week', 'Weeks'], 1)": 1,
      "temp.drop(to_drop + ['Male', 'Ex-smoker', 'Never smoked', 'Age'], 1)": 1,
      "temp.drop(np.setdiff1d(To_drop, no_drop), 1)": 1,
      "np.hstack([temp.drop(To_drop, 1), cross_val_predict(LinearRegression(), temp[['Base_FVC', 'Base_Percent', 'Week_Offset', 'factor', 'Age', 'Male']], temp[no_drop], cv=GroupKFold(5), groups=temp.Patient)])": 1,
      "pd.concat([temp.drop(To_drop, 1), temp.groupby(['Male'])[no_drop].transform('mean')], axis=1)": 1,
      "audio": 1,
      "X_transformed": 1,
      "new_train_df": 1,
      "train_onehot": 1,
      "X_train_dm_1": 1,
      "train[feature]": 1,
      "pairs[features]": 1,
      "X_toxic": 1,
      "X_attack": 1,
      "X_aggression": 1,
      "Xpos2Train": 1,
      "Xpos3Train": 1,
      "XnoPos1Train": 1,
      "XnoPos2Train": 1,
      "XnoPos3Train": 1,
      "xtrain_glove": 1,
      "X_treino": 1,
      "X_valid_pr": 1,
      "XtrainCR": 1,
      "X_train_out.select_dtypes(exclude=['object'])": 1,
      "xfamilies": 1,
      "Xcosta": 1,
      "_xbase": 1,
      "encoded_data": 1,
      "selected": 1,
      "np.zeros([len(dftrain), 1])": 1,
      "np.array(dftrain[['item_condition_id', 'category_name_0', 'category_name_1', 'category_name_2', 'category_name_3', 'category_name_4', 'brand_name', 'shipping']])": 1,
      "pd.DataFrame(combi[i])": 1,
      "heads2[feats]": 1,
      "Xpov": 1,
      "pd.DataFrame(train_x['dis'])": 1,
      "pd.DataFrame(train_x[['dis', 'year']])": 1,
      "pd.DataFrame(train_x[['dis', 'year', 'hour']])": 1,
      "pd.DataFrame(train_x[['dis', 'year', 'hour', 'passenger_count', 'pickup_longitude', 'pickup_latitude']])": 1,
      "pd.DataFrame(train_x[['dis', 'year', 'hour', 'passenger_count', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']])": 1,
      "X_train_tfidf": 1,
      "tempy": 1,
      "X[:5000]": 1,
      "scale_train_x": 1,
      "Xtf_train": 1,
      "sub_X_train": 1,
      "X_gnb": 1,
      "df[features]": 1,
      "X_train_no_id": 1,
      "fit_data.loc[:, :'Target']": 1,
      "fit_norm0.loc[:, cols]": 1,
      "fit_norm.loc[fit_norm0['target0'] == 0, :'Target']": 1,
      "X_stnd": 1,
      "X.values": 1,
      "X_train1_all": 1,
      "X_train1_unimp": 1,
      "X_train2_all": 1,
      "X_train2_unimp": 1,
      "X_train3_all": 1,
      "X_train3_unimp": 1,
      "b_train": 1,
      "dw[feats]": 1,
      "X_train.sample(frac=1, random_state=0).head(10000)": 1,
      "pca_result": 1,
      "train_stemmed['text']": 1,
      "xpop": 1,
      "X3": 1,
      "x_data_kbest": 1,
      "x_data_varth": 1,
      "train_data_x": 1,
      "x_train.values": 1,
      "X_train_scal_sm": 1,
      "group_X_train": 1,
      "meta_X_train": 1,
      "df.drop(labels=target, axis=1)": 1,
      "X1_val": 1,
      "train.drop(['winPlacePerc', 'matchType', 'Id', 'groupId', 'matchId'], axis=1)": 1,
      "X_train_preprocessed": 1,
      "X_train_bin_vectorized_new": 1,
      "X_train_vectorized_new": 1,
      "X_train_filtered": 1,
      "X.reshape(-1, 1)": 1,
      "xtrain_count": 1,
      "X_trainNu": 1,
      "XX": 1,
      "cr_train_X": 1,
      "Xntrain": 1,
      "bow_train": 1,
      "Xtrainadult": 1,
      "nXtrain": 1,
      "X_train_dtm": 1,
      "X_enc": 1,
      "train_comment_features": 1,
      "train['comment_text']": 1,
      "X[columns]": 1,
      "nn_model.predict([X_processed_f['item_id'], X_processed_f['shop_id'], X_processed_f['date_block_num'], X_processed_f['item_category_id']])": 1,
      "train_vectors_f": 1,
      "X_temp": 1,
      "X_train.T[el_df.index].T": 1,
      "X_train0": 1,
      "X_train3": 1,
      "X_inf_train": 1,
      "X_dth_train": 1,
      "X_post": 1,
      "X_log": 1,
      "scaled_train_lr_1.iloc[:, 0:6]": 1,
      "scaled_train_lr_2.iloc[:, :-1]": 1,
      "train_lr_3[highest_correlated_lr_3]": 1,
      "X_poly_train_lr_4": 1,
      "training_knn_1.drop('SalePrice', axis=1)": 1,
      "proc_train": 1,
      "train['comment_text'].values": 1,
      "X[:]": 1,
      "nn_model.predict([X[f] for f in ['shop_id', 'item_id', 'price_bin', 'month', 2013, 2014, 2015]])": 1,
      "xscale": 1,
      "X_tfid": 1,
      "j.loc[j.index.intersection(train_y[col].dropna().index)]": 1,
      "X_train_selected_fc": 1,
      "X_train_selected_mic": 1,
      "X_train_selected": 1,
      "X_kvar": 1,
      "X_kbest": 1,
      "training_dataset": 1,
      "Xtr[:len(y)]": 1,
      "data.drop('type', axis=1)": 1,
      "data.drop(['type'], axis=1)": 1,
      "X_train1hot_scaled": 1,
      "X_trainlabel_scaled": 1,
      "XCostaRica": 1,
      "X1CostaRica": 1,
      "xndf": 1,
      "X_Test": 1,
      "X_train_reduced": 1,
      "reduced_X_train['item_description']": 1,
      "gau_train": 1,
      "A_train": 1,
      "train_features_matrix": 1,
      "Xcr": 1,
      "dtm_train": 1,
      "dfnona[features]": 1,
      "Xtrain_data": 1,
      "normal_train_zero": 1,
      "normal_train_zero[top_features]": 1,
      "normal_train_mean": 1,
      "normal_train_mean[top_features]": 1,
      "trainx_tfidf": 1,
      "predictors": 1,
      "some_sample_data_to_test[col]": 1,
      "XCR": 1,
      "train[names]": 1,
      "Xcosta_rican": 1,
      "X.drop(columns=['Ticket_alpha', 'Ticket_num', 'Family_members'])": 1,
      "new_df_with_columns_in_both_train": 1,
      "x_scaled": 1,
      "X_stack": 1,
      "X_train[best_variables]": 1,
      "xtr_final": 1,
      "X_test_pca": 1,
      "df_trn": 1,
      "x[x.Where == 'train'].drop('Where', 1)": 1,
      "x_sub_sample": 1,
      "vectors_full": 1,
      "independent_variables": 1,
      "test": 1,
      "train_X_less.values": 1,
      "rescaledX": 1,
      "train_df_casual_x": 1,
      "Train_X": 1,
      "m_train_data": 1,
      "model_train_data2D": 1,
      "X_reduced[:, :i]": 1,
      "X_reduced_train[:, :i]": 1,
      "TrainingFeatures": 1,
      "enc_df": 1,
      "best_feat_df": 1,
      "pca_enc_df": 1,
      "x_train[lgbm14_test_feat].drop(feature_to_remove, axis=1)": 1,
      "x_train[lgb20_test_feat_top]": 1,
      "features[0]": 1,
      "feature": 1,
      "rXtrain": 1,
      "sc_X.fit_transform(pca_train)": 1,
      "mr_train_df": 1,
      "not_mr_train_df": 1,
      "Xpovertytrain": 1,
      "X_many_features": 1,
      "xx_train": 1,
      "train_Vectors": 1,
      "recursive_X_train": 1,
      "pca_fit_transform_train_X_72": 1,
      "X_smote": 1,
      "X_train_prep": 1,
      "train_df[X_cols]": 1,
      "transformed_X": 1,
      "train_X_linear.values": 1,
      "train[feature_columns]": 1,
      "train_char_features": 1,
      "train_df.iloc[:, :-1]": 1,
      "X_smote_v": 1,
      "pd.DataFrame(combine[col])": 1,
      "XHouseHold": 1,
      "self.xtrain": 1,
      "train_features[key]": 1,
      "vect_train": 1,
      "X_prepared": 1,
      "Xncr_train": 1,
      "Xcrica": 1,
      "x_train_sample": 1,
      "train_feature_values": 1,
      "data_prepared": 1,
      "training_examples_transform": 1,
      "valid_x": 1,
      "d_set[8]": 1,
      "X_train[:10000]": 1,
      "X_validation": 1,
      "imputed_X_val": 1,
      "X_val_B": 1,
      "titanic[predictors]": 1,
      "train_numeric_X.values": 1,
      "images": 1
    },
    "sklearn.model_selection._validation.cross_val_score.y": {
      "y_train": 1005,
      "y": 817,
      "Y": 177,
      "Y_train": 173,
      "train_df['target']": 91,
      "y_test": 91,
      "target": 79,
      "label": 62,
      "train_y": 61,
      "train['target']": 60,
      "train_labels.values.ravel()": 50,
      "train_labels": 49,
      "train_target": 43,
      "df_train['target']": 39,
      "YbalTrain": 35,
      "Ytrain": 32,
      "test_y": 22,
      "y_train[pred_type]": 20,
      "train_data['target']": 18,
      "log_y": 17,
      "ytrain": 16,
      "y_tr": 14,
      "labels": 14,
      "housing_labels": 13,
      "y_train_res": 12,
      "Y1": 12,
      "Y_train_CC": 12,
      "Y_train_Fat": 12,
      "self.y_train": 12,
      "y_val": 11,
      "titanic_labels": 10,
      "train_Y": 10,
      "train_data['cat_cuisine']": 10,
      "ycosta": 10,
      "y.ravel()": 10,
      "train[target]": 9,
      "y_test_Stem": 9,
      "y_test_Lemm": 9,
      "target_y": 9,
      "y_train1": 8,
      "y.values.ravel()": 8,
      "main_train_labels": 8,
      "y1": 8,
      "target_train": 8,
      "Yhousehold": 8,
      "y_train.values": 7,
      "yTrain": 6,
      "temp['FVC']": 6,
      "y_train_temp": 6,
      "traindf['target']": 6,
      "y_data_generated": 6,
      "dataset['target']": 6,
      "train['Target']": 6,
      "y_equidistant": 6,
      "y_balanced": 6,
      "y_": 5,
      "np.ravel(target)": 5,
      "y_training": 5,
      "df['target']": 5,
      "trainy": 5,
      "Y2_train": 5,
      "T": 5,
      "train['count']": 5,
      "y[:cutoff4sample_size]": 4,
      "y_boxcox": 4,
      "y_train_full": 4,
      "trainRL": 4,
      "y_res": 4,
      "trainY": 4,
      "y_undercv": 4,
      "y_undertfidf": 4,
      "train['Cover_Type']": 4,
      "train_y.values": 4,
      "YHHI": 4,
      "y_train['ConfirmedCases']": 4,
      "y_train['Fatalities']": 4,
      "target_log": 4,
      "y_train2": 4,
      "y_train3": 4,
      "train_data['SalePrice']": 4,
      "y2": 4,
      "Y[y_col]": 4,
      "y_features": 4,
      "y_mtrain": 4,
      "training_y": 4,
      "yl": 4,
      "np.ravel(y)": 3,
      "trainLabel.values.ravel()": 3,
      "y_SMOTE": 3,
      "y_train_transformed": 3,
      "y_label": 3,
      "y2_train": 3,
      "train[label]": 3,
      "Targete": 3,
      "Yhouse": 3,
      "y_valid": 3,
      "self.y": 3,
      "Ydf": 3,
      "ydata": 3,
      "label_encoded_y": 3,
      "fit_set1.loc[:, 'Target']": 3,
      "fit_norm.loc[:, 'Target']": 3,
      "y_resampled": 3,
      "data.shot_made_flag": 3,
      "y_target": 3,
      "df_Y_train": 3,
      "y_data": 3,
      "all_y": 3,
      "y_1": 3,
      "nptrain_y": 3,
      "y_train['surface']": 3,
      "Target": 3,
      "y_trn": 3,
      "survived": 3,
      "targetvar": 2,
      "train_y_prepared": 2,
      "X_train['target']": 2,
      "y_train_cv": 2,
      "train_classes": 2,
      "df_train.target": 2,
      "train['sentiment']": 2,
      "yTest": 2,
      "y_train_target": 2,
      "trainv['target']": 2,
      "labels_to_use": 2,
      "x['FVC']": 2,
      "y_dummies": 2,
      "y_row": 2,
      "y_col": 2,
      "y_orig": 2,
      "Ytreino": 2,
      "train_y.values.ravel()": 2,
      "y3_train": 2,
      "Ytrain2": 2,
      "y_holdout": 2,
      "yy": 2,
      "numeric_data.Target": 2,
      "encoded_data.Target": 2,
      "Yhh": 2,
      "nm_Y_train": 2,
      "y_fit": 2,
      "dlabels['action']": 2,
      "tweets['target']": 2,
      "YhdbTrain": 2,
      "train_['target'].iloc[:, 0]": 2,
      "y_grid5": 2,
      "train_df_y": 2,
      "data_train['Survived']": 2,
      "Y_train[label]": 2,
      "Ytrain_h": 2,
      "trainDataY": 2,
      "YHHItrain": 2,
      "trainLabels": 2,
      "y_ts": 2,
      "project_is_approved": 2,
      "validation_y": 2,
      "data['type']": 2,
      "YCostaRica": 2,
      "x_target": 2,
      "y[::step]": 2,
      "targets": 2,
      "ytr": 2,
      "y_train.ravel()": 2,
      "pca_test": 2,
      "y_train_cc": 2,
      "y_train.values.ravel()": 2,
      "Y_completo": 2,
      "c_df.iloc[:-8, :][['target']]": 2,
      "y_cases": 2,
      "y_fatal": 2,
      "y_train_tf": 2,
      "output.values.ravel()": 1,
      "YTrain": 1,
      "full_y_train": 1,
      "train_result[random_set]": 1,
      "opt_log_y_train": 1,
      "Xtrain_y": 1,
      "Ytrain_df": 1,
      "train_labels_balanced": 1,
      "YdataTrain": 1,
      "qty.fit_transform(train.LConfirmedCases[train.serd > 70].values.reshape(-1, 1))": 1,
      "qty_f.fit_transform(train.LFatalities[train.serd > 70].values.reshape(-1, 1))": 1,
      "experData_y": 1,
      "y_train_label": 1,
      "train_outcome": 1,
      "y_pred1": 1,
      "y_pred2": 1,
      "y_pred3": 1,
      "y_pred4": 1,
      "train['is_iceberg']": 1,
      "traindf['visitors']": 1,
      "ldf['target']": 1,
      "df_train[target_col]": 1,
      "y_train_log": 1,
      "Y_1": 1,
      "Y_2": 1,
      "Y_3": 1,
      "Y_4": 1,
      "Y_5": 1,
      "y_encode": 1,
      "Y_Train": 1,
      "y_d": 1,
      "yw_train": 1,
      "self.trainY": 1,
      "ravel(y_train)": 1,
      "train['Survived']": 1,
      "combine[0]['target']": 1,
      "bench_train_labels": 1,
      "y1_train": 1,
      "Yadult": 1,
      "train_y[:10000]": 1,
      "train['label']": 1,
      "finalpredict": 1,
      "labels_train": 1,
      "newCosta.iloc[:, 137:138]": 1,
      "train['project_is_approved']": 1,
      "train_target_cp": 1,
      "ys[col]": 1,
      "temp['Best_conf'].astype(int)": 1,
      "is_turkey": 1,
      "y_train_age": 1,
      "train.adoptionspeed": 1,
      "y_train_1": 1,
      "pairs[target].values.ravel()": 1,
      "y_toxic": 1,
      "y_attack": 1,
      "y_aggression": 1,
      "Y_treino": 1,
      "YtrainCR": 1,
      "y_train['confirmed']": 1,
      "y_train['deaths']": 1,
      "yfamilies": 1,
      "Ycosta": 1,
      "np.log1p(train.price)": 1,
      "np.sqrt(y)": 1,
      "_ybase": 1,
      "dftrain['price']": 1,
      "np.array(dftrain['price'])": 1,
      "log_target": 1,
      "heads2['Target']": 1,
      "np.ravel(train_labels)": 1,
      "Ypov": 1,
      "tempy2": 1,
      "y[:5000]": 1,
      "X_test": 1,
      "y_hat": 1,
      "y_train_4": 1,
      "scale_train_y": 1,
      "sub_y_train": 1,
      "Y_train_lab": 1,
      "Y.flatten()": 1,
      "df['age'].astype(int)": 1,
      "y_log": 1,
      "fit_data.loc[:, 'Target']": 1,
      "fit_norm0.loc[:, 'target0']": 1,
      "fit_norm.loc[fit_norm0['target0'] == 0, 'Target']": 1,
      "labels[c]": 1,
      "y.values": 1,
      "y1_trainval": 1,
      "y2_trainval": 1,
      "b_label": 1,
      "dw['Target']": 1,
      "y_train.sample(frac=1, random_state=0).head(10000)": 1,
      "train_stemmed[target]": 1,
      "ypop": 1,
      "Y2": 1,
      "Y3": 1,
      "train_data_y": 1,
      "SalePrice": 1,
      "trainData['target']": 1,
      "group_y_train": 1,
      "df[target]": 1,
      "y1_val": 1,
      "Y_train[category[i]]": 1,
      "train.winPlacePerc": 1,
      "train_y_POS": 1,
      "df_nb.cuisine": 1,
      "df.author": 1,
      "train_score": 1,
      "cr_train_Y": 1,
      "Yntrain": 1,
      "train.sentiment": 1,
      "Ytrainadult": 1,
      "df_tweet_train['target']": 1,
      "y_enc": 1,
      "train['toxic']": 1,
      "y_temp": 1,
      "sp_train": 1,
      "Y_train.iloc[:, i]": 1,
      "y_inf_train['confirmed']": 1,
      "y_dth_train['deaths']": 1,
      "ys": 1,
      "scaled_train_lr_1.iloc[:, -1]": 1,
      "scaled_train_lr_2['SalePrice']": 1,
      "y_train_lr_3": 1,
      "y_train_lr_4": 1,
      "training_knn_1['SalePrice']": 1,
      "np.log(train['SalePrice'])": 1,
      "y_encoded": 1,
      "y[:]": 1,
      "y_train_0": 1,
      "train_y[col].loc[train_y[col].index.intersection(j.index)].dropna()": 1,
      "b": 1,
      "Y_train.values.ravel()": 1,
      "y_value": 1,
      "np.log(y)": 1,
      "yndf": 1,
      "pred": 1,
      "reduced_y_train": 1,
      "B_train": 1,
      "y_train.iloc[:, i]": 1,
      "train_target_result": 1,
      "y1_Train_CS": 1,
      "y2_Train_CS": 1,
      "y_train_ftd": 1,
      "Ycr": 1,
      "dfnona[target].values": 1,
      "Ytrain_data": 1,
      "y_norm.T": 1,
      "some_sample_data_to_test['target']": 1,
      "YCR": 1,
      "Ycosta_rican": 1,
      "y['target']": 1,
      "np.ravel(train_y)": 1,
      "train_y_train": 1,
      "y_stack": 1,
      "ycat": 1,
      "df.target": 1,
      "y_sub_sample": 1,
      "y_full": 1,
      "dependent_variable": 1,
      "df1['target']": 1,
      "Y_test": 1,
      "train": 1,
      "train_df_casual_y": 1,
      "Train_Y": 1,
      "m_train_label": 1,
      "model_train_label": 1,
      "train_df['target_relabeled']": 1,
      "target[0]": 1,
      "result": 1,
      "y_train.reshape(y_train.shape[0])": 1,
      "df_train['domain1_score']": 1,
      "rytrain": 1,
      "sc_Y.fit_transform(pca_test.reshape(-1, 1))": 1,
      "y_pred": 1,
      "mr_y_train": 1,
      "not_mr_y_train": 1,
      "Ypovertytrain": 1,
      "y_many_features": 1,
      "y_train.values.flatten()": 1,
      "yy_train": 1,
      "y_smote": 1,
      "c_df.iloc[:-8, :]['target'].values": 1,
      "train_df['AdoptionSpeed']": 1,
      "train_labels_log": 1,
      "train['FVC']": 1,
      "train_df.iloc[:, -1]": 1,
      "y_smote_v": 1,
      "YHouseHold": 1,
      "self.ytrain": 1,
      "train_targets": 1,
      "vect_y": 1,
      "Yncr_train": 1,
      "Ycrica": 1,
      "y_train_sample": 1,
      "train_target_values": 1,
      "label['surface']": 1,
      "train_['sentiment']": 1,
      "logy": 1,
      "training_targets": 1,
      "valid_y": 1,
      "d_set[9]": 1,
      "y_train[:10000]": 1,
      "y_is9_validation": 1,
      "y_val_B": 1,
      "titanic['Survived']": 1,
      "train_numeric_Y[numeric_features_Y[0]].values": 1
    },
    "sklearn.model_selection._validation.cross_val_score.cv": {
      "5": 1069,
      "10": 978,
      "3": 365,
      "kfold": 265,
      "cv": 210,
      "None": 182,
      "kf": 179,
      "kfolds": 39,
      "k_fold": 38,
      "20": 35,
      "2": 34,
      "skfold": 31,
      "7": 24,
      "skf": 24,
      "folds": 15,
      "4": 13,
      "cv_strategy": 12,
      "rs": 11,
      "StratifiedKFold()": 11,
      "shuffle": 11,
      "GroupKFold(5)": 11,
      "self.cv": 11,
      "6": 10,
      "8": 10,
      "a": 10,
      "15": 9,
      "FOLDS": 9,
      "repfold": 9,
      "RepeatedKFold(n_splits=4, n_repeats=10)": 9,
      "9": 9,
      "tscv": 8,
      "100": 8,
      "inner_cv": 7,
      "kFold": 6,
      "cv_method": 6,
      "fold": 5,
      "KFold(5, shuffle=True)": 5,
      "KFold(n_splits=5)": 5,
      "outer_cv": 5,
      "n_folds": 4,
      "cv_search": 4,
      "CV": 4,
      "kf_3": 4,
      "cv_cr": 4,
      "cv_folds": 3,
      "random_split": 3,
      "GroupKFold(4)": 3,
      "n_cv": 3,
      "cv2": 3,
      "time_splits": 2,
      "rkf": 2,
      "12": 2,
      "tss": 2,
      "KFold(5)": 2,
      "k": 2,
      "cv_": 2,
      "n_splits": 2,
      "300": 2,
      "cross": 2,
      "rskf": 2,
      "SKF": 2,
      "time_split": 2,
      "Lcv": 1,
      "self.n_splits": 1,
      "split_indices": 1,
      "ts_cross_val": 1,
      "ss": 1,
      "skfolds": 1,
      "kf_time": 1,
      "GroupKFold(7)": 1,
      "40": 1,
      "cv_cat": 1,
      "DateSplit()": 1,
      "split": 1,
      "StratifiedKFold(2)": 1,
      "PurgedGroupTimeSeriesSplit(**cv_params)": 1,
      "k_folds": 1,
      "ShuffleSplit(n_splits=5, test_size=0.2)": 1,
      "25": 1,
      "525": 1,
      "splits": 1,
      "k_cv": 1,
      "my_cv": 1,
      "Cv": 1,
      "kf_splits": 1,
      "skf.split(X_train, y_train)": 1,
      "strat_cv_shuffler": 1,
      "StratifiedKFold(n_splits=n_folds)": 1,
      "StratifiedShuffleSplit(5, random_state=1, test_size=0.1)": 1,
      "sfk": 1,
      "StratifiedKFold(3, random_state=21)": 1,
      "StratifiedKFold(n_splits=5)": 1,
      "32": 1,
      "s_fold": 1,
      "17": 1,
      "50": 1,
      "cv_rs": 1,
      "ShuffleSplit(n_splits=3)": 1,
      "cv_space": 1,
      "sp": 1,
      "cv_1": 1,
      "nfolds": 1,
      "cval": 1,
      "folds_iterable": 1
    },
    "sklearn.preprocessing._encoders.OneHotEncoder.__init__.categories": {
      "'auto'": 1474,
      "categories": 8,
      "[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]]": 2,
      "selected_cats": 2,
      "[range(len(labels[i]))]": 2,
      "[range(C)] * 1": 2,
      "[[0, 1, 2], [0, 1, 2, 3, 4, 5, 6]]": 1,
      "[[1, 2]]": 1,
      "[np.arange(10)]": 1,
      "[neighborhoodCategories]": 1,
      "[lotShapeCategories]": 1,
      "[landSlopeCategories]": 1,
      "[saleCondCategories]": 1,
      "[categories]": 1,
      "[val_cats]": 1,
      "[list(bases), list(structs), list(loops)]": 1,
      "[np.arange(1, 8, 1)]": 1,
      "days": 1,
      "dayofweeks": 1,
      "months": 1,
      "hours": 1,
      "self.categories": 1
    },
    "sklearn.dummy.DummyRegressor.fit.X": {
      "X_train": 21,
      "Xs_train": 1,
      "sample_train_df": 1,
      "c_train_df": 1,
      "x": 1
    },
    "sklearn.dummy.DummyRegressor.fit.y": {
      "y_train": 21,
      "y_vec": 2,
      "y": 1,
      "Y_train": 1
    },
    "sklearn.dummy.DummyRegressor.predict.X": {
      "X_test": 16,
      "X_train": 5,
      "Xs_train": 1,
      "sample_test_df[sample_train_df.columns]": 1,
      "out_df[c_train_df.columns]": 1,
      "X_val": 1
    },
    "sklearn.preprocessing._encoders.OneHotEncoder.__init__.drop": {
      "None": 1443,
      "'first'": 61,
      "'if_binary'": 1,
      "most_frequent_values": 1
    },
    "sklearn.preprocessing._encoders.OneHotEncoder.get_feature_names.input_features": {
      "None": 40,
      "col": 26,
      "cat_cols": 5,
      "Correlation_df[category_col].columns": 2,
      "Titanic_train_x[category_col].columns": 2,
      "Titanic_predict_x[category_col].columns": 2,
      "['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9']": 2,
      "['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9', 'cat11', 'cat12', 'cat13', 'cat14', 'cat15', 'cat16', 'cat17', 'cat18']": 2,
      "['CNT_CHILDREN']": 2,
      "['workclass']": 2,
      "df_text.columns": 2,
      "df_text_test.columns": 2,
      "['keyword']": 2,
      "['sentiment']": 2,
      "[col]": 2,
      "cat_col": 2,
      "categorical_feats": 2,
      "feat_group['fea_cat']": 2,
      "categorical_var": 2,
      "hot_columns": 2,
      "categor_col": 1,
      "train_object_cols": 1,
      "store_object_cols": 1,
      "cat_features": 1,
      "categorical_ftrs.columns.to_list()": 1,
      "te_categorical_ftrs.columns.to_list()": 1,
      "score_categorical_ftrs.columns.to_list()": 1,
      "['predicted_loop_type', 'sequence']": 1,
      "self.cat_columns": 1,
      "['DayOfWeek', 'StateHoliday', 'StoreType', 'Assortment']": 1,
      "[feature]": 1,
      "features_to_encode": 1,
      "categorical_data.columns": 1,
      "categorical_data_test.columns": 1,
      "df.columns": 1,
      "categorical_cols": 1,
      "object_cols": 1,
      "string_column_names": 1
    },
    "sklearn.impute._base.SimpleImputer.__init__.missing_values": {
      "np.nan": 1084,
      "-1": 26,
      "NAN_VALUE_INT": 8,
      "np.NaN": 8,
      "missing_default": 6,
      "None": 4,
      "'NaN'": 1,
      "-999": 1,
      "0": 1,
      "nan": 1
    },
    "sklearn.impute._base.SimpleImputer.__init__.strategy": {
      "'mean'": 365,
      "'median'": 278,
      "'most_frequent'": 267,
      "'constant'": 205,
      "strategy": 6,
      "IMPUTING_STRATEGY": 4,
      "self.strategy": 3,
      "hyperpars['imputation']['fare_imputation']": 2,
      "hyperpars['fare_imputation']": 2,
      "impute_method": 2,
      "target_map[col]": 1,
      "method": 1,
      "impute_strategy": 1,
      "imputing_strategy": 1,
      "hyperpars['imputation']['age_imputation']": 1,
      "hyperpars['age_imputation']": 1
    },
    "sklearn.feature_selection._sequential.SequentialFeatureSelector.fit.X": {
      "Titanic_train_x": 2
    },
    "sklearn.feature_selection._sequential.SequentialFeatureSelector.fit.y": {
      "Titanic_train_y": 2
    },
    "sklearn.feature_selection._sequential.SequentialFeatureSelector.__init__.direction": {
      "'backward'": 2
    },
    "sklearn.feature_selection._sequential.SequentialFeatureSelector.__init__.scoring": {
      "'roc_auc'": 2
    },
    "sklearn.feature_selection._sequential.SequentialFeatureSelector.__init__.cv": {
      "5": 2
    },
    "sklearn.feature_selection._sequential.SequentialFeatureSelector.__init__.n_features_to_select": {
      "3": 2
    },
    "sklearn.feature_selection._sequential.SequentialFeatureSelector.__init__.estimator": {
      "LogisticRegression(random_state=0)": 2
    },
    "sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path.X": {
      "Titanic_train_x": 2,
      "Titanic_train_x[SFS_Variable]": 2,
      "X_train": 1
    },
    "sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path.y": {
      "Titanic_train_y": 4,
      "y_train": 1
    },
    "sklearn.model_selection._search.RandomizedSearchCV.__init__.scoring": {
      "None": 233,
      "'roc_auc'": 79,
      "'neg_mean_squared_error'": 42,
      "'accuracy'": 40,
      "'neg_root_mean_squared_error'": 39,
      "'neg_mean_absolute_error'": 27,
      "'f1'": 18,
      "'r2'": 12,
      "'neg_log_loss'": 10,
      "MSE": 8,
      "scoring": 7,
      "'f1_macro'": 5,
      "scorer": 5,
      "my_score": 3,
      "'recall'": 3,
      "make_scorer(msle)": 3,
      "make_scorer(score_func=r2_score, greater_is_better=True)": 3,
      "weight_error": 2,
      "'neg_mean_squared_log_error'": 2,
      "sklearn.metrics.mean_squared_error": 2,
      "acc_score": 2,
      "scores": 2,
      "'roc_auc_ovr'": 2,
      "neg_rmse": 1,
      "scorers": 1,
      "CTL.gridsearch_scoring": 1,
      "'precision'": 1,
      "my_roc_auc_score": 1,
      "'average_precision'": 1,
      "{'accuracy': make_scorer(accuracy_score), 'cohen_kappa': make_scorer(cohen_kappa_score)}": 1,
      "{'accuracy': make_scorer(accuracy_score), 'cohen_kappa_quadratic': QUADRATIC_WEIGHT_SCORER}": 1,
      "score_rmse": 1,
      "kappa_scorer": 1,
      "['roc_auc']": 1,
      "['accuracy']": 1,
      "'neg_median_absolute_error'": 1,
      "make_scorer(rmsle, greater_is_better=False)": 1,
      "new_scorer": 1,
      "['roc_auc', 'accuracy']": 1,
      "rmsle_scorer": 1,
      "make_scorer(mean_squared_error)": 1,
      "root_mean_squared_log_error_scorer": 1,
      "{'f1_score': make_scorer(f1_score), 'roc_auc': make_scorer(roc_auc_score)}": 1,
      "scoring_fnc": 1,
      "mcc_scorer": 1,
      "rmse": 1,
      "'roc_auc_ovr_weighted'": 1
    },
    "sklearn.model_selection._search.RandomizedSearchCV.__init__.n_jobs": {
      "None": 241,
      "-1": 238,
      "4": 33,
      "1": 18,
      "n_jobs": 11,
      "10": 9,
      "2": 9,
      "5": 5,
      "3": 3,
      "8": 2,
      "-2": 1,
      "6": 1,
      "search_njobs": 1,
      "-n_jobs": 1
    },
    "sklearn.model_selection._search.RandomizedSearchCV.__init__.random_state": {
      "None": 316,
      "42": 115,
      "0": 36,
      "1": 33,
      "314": 10,
      "2020": 8,
      "1001": 8,
      "RANDOM_STATE": 6,
      "11": 3,
      "7": 3,
      "54": 3,
      "40": 3,
      "22": 3,
      "100": 2,
      "1456": 2,
      "101": 2,
      "seed": 2,
      "2021": 2,
      "13": 2,
      "CTL.random_state": 1,
      "2017": 1,
      "SEED": 1,
      "rstate": 1,
      "17": 1,
      "random_state": 1,
      "seed_train": 1,
      "21": 1,
      "8": 1,
      "rng": 1,
      "random_seed": 1,
      "rand_seed": 1,
      "RSEED": 1,
      "params['random_state']": 1
    },
    "sklearn.model_selection._search.RandomizedSearchCV.__init__.return_train_score": {
      "False": 499,
      "True": 74
    },
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.class_weight": {
      "None": 4950,
      "'balanced'": 162,
      "'balanced_subsample'": 20,
      "'auto'": 8,
      "class_weight": 7,
      "Best_Parameter['class_weight']": 4,
      "'subsample'": 4,
      "class_weights": 4,
      "{1: 1}": 2,
      "trial.suggest_categorical('class_weight', ['balanced', 'balanced_subsample'])": 2,
      "{1: a, 0: b}": 2,
      "{0: 1, 1: 5}": 1,
      "cw": 1,
      "{0: 1, 1: 6.6}": 1,
      "{0: 1, 1: 25}": 1,
      "{0: 1, 1: 12}": 1,
      "lo_weight": 1,
      "hi_weight": 1,
      "{0: 1, 1: 1.4}": 1,
      "c_weights": 1,
      "test_weight_map": 1,
      "c_weight": 1,
      "{0: 1, 1: np.round(y.value_counts()[0] / y.value_counts()[1], 3)}": 1,
      "{0: 0.5, 1: 0.5}": 1,
      "{0: 1, 1: 1.6}": 1,
      "{0: 1, 1: 9}": 1
    },
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.ccp_alpha": {
      "0.0": 5171,
      "Best_Parameter['ccp_alpha']": 4,
      "0.005": 2,
      "10**(-5.5)": 1,
      "trial.suggest_float('ccp_alpha', 0.0, 0.2)": 1,
      "0.002": 1
    },
    "sklearn.metrics._plot.roc_curve.plot_roc_curve.estimator": {
      "clf": 5,
      "RFC": 4,
      "Support_Vector": 4,
      "model": 4,
      "m": 4,
      "dtree_model": 2,
      "estimator": 2,
      "log_model": 2,
      "best_clf": 2,
      "lgbm": 2,
      "gs_log_reg": 1,
      "clf2": 1,
      "model_svc": 1,
      "classifier": 1,
      "model[k]": 1,
      "lr": 1,
      "model2": 1,
      "log": 1,
      "mdl": 1,
      "clfgs": 1,
      "svm_model": 1,
      "rfc": 1
    },
    "sklearn.metrics._plot.roc_curve.plot_roc_curve.X": {
      "X_test": 15,
      "Titanic_test_x": 4,
      "Titanic_test_x[SFS_Variable]": 4,
      "X.loc[test]": 2,
      "scaled_X_test": 2,
      "vali_x": 2,
      "valid_xs": 2,
      "xs": 2,
      "X_test1": 1,
      "X_train": 1,
      "X_val_bow_df": 1,
      "dataX": 1,
      "X_treino_transf": 1,
      "X_treino_transf.fillna(0)": 1,
      "X.loc[val_idx, :]": 1,
      "X_valid": 1,
      "xtest": 1,
      "X_val": 1
    },
    "sklearn.metrics._plot.roc_curve.plot_roc_curve.y": {
      "y_test": 18,
      "Titanic_test_y": 8,
      "y.loc[test]": 2,
      "y_val": 2,
      "vali_y": 2,
      "y_treino": 2,
      "valid_y": 2,
      "y": 2,
      "y_train": 1,
      "datay": 1,
      "y.loc[val_idx]": 1,
      "y_valid": 1,
      "ytest": 1
    },
    "sklearn.svm._classes.SVC.__init__.class_weight": {
      "None": 1641,
      "'balanced'": 26,
      "Best_Parameter['class_weight']": 4,
      "{1: 2, 2: 1.5, 3: 1, 4: 1}": 1,
      "temp_class_weights": 1,
      "'auto'": 1,
      "class_weight(y_train)": 1
    },
    "sklearn.preprocessing._data.MinMaxScaler.transform.X": {
      "test": 153,
      "train": 105,
      "X_test": 91,
      "inputs": 76,
      "test_df[features]": 55,
      "poly_features_test": 49,
      "domain_features_test": 44,
      "X_train": 36,
      "x_train": 35,
      "X": 35,
      "x_test": 34,
      "ts_indi_df": 33,
      "test_data": 16,
      "ts_cnts": 15,
      "Xo.toarray()": 14,
      "test_features": 14,
      "data": 12,
      "test_df.values": 12,
      "X_val": 12,
      "ts_x_cnts": 12,
      "dftest[['q1len', 'q2len', 'q1_n_words', 'q2_n_words', 'word_share']]": 10,
      "test_df": 10,
      "train_features": 10,
      "df[['q1len', 'q2len', 'q1_n_words', 'q2_n_words', 'word_share']]": 9,
      "df_test": 7,
      "x": 7,
      "test_x": 6,
      "test.values": 6,
      "features": 6,
      "val_features": 6,
      "testing_data.values": 5,
      "test_set": 5,
      "xvalid": 5,
      "dataset[feature_scale]": 4,
      "df_test[['question_body_num_words', 'answer_num_words']].values": 4,
      "train1": 4,
      "test1": 4,
      "lr_train": 4,
      "lr_val": 4,
      "lr_test": 4,
      "knn_train": 4,
      "knn_val": 4,
      "knn_test": 4,
      "X_valid": 4,
      "test[['num_words', 'num_comas', 'num_bangs', 'num_quotas', 'avg_word']]": 4,
      "X1": 4,
      "df": 4,
      "features_test": 4,
      "in_indi_df": 4,
      "out_indi_df": 4,
      "X[training]": 3,
      "X[testing]": 3,
      "eval_diff_series.reshape(-1, 1)": 3,
      "X_test.values": 3,
      "X_val[normalized_features]": 3,
      "test[normalized_features]": 3,
      "x_val": 3,
      "test_df['image_size'].values.reshape(-1, 1)": 3,
      "train_data": 3,
      "train[features]": 3,
      "train_set": 3,
      "validation_df": 3,
      "test_df[num_cols].values": 3,
      "y": 3,
      "self.df.loc[:, num_list]": 3,
      "training['sales'].values.reshape(-1, 1)": 3,
      "X_test.toarray()": 3,
      "val_X_cc": 3,
      "val_y_cc": 3,
      "val_X_ft": 3,
      "val_y_ft": 3,
      "np.array(y_pred_man).reshape(-1, 1)": 3,
      "np.array(y_pred_euc).reshape(-1, 1)": 3,
      "features.values": 3,
      "t": 3,
      "v": 3,
      "df_train": 2,
      "X_test[num_vars]": 2,
      "colors_features": 2,
      "test[col].values.reshape(-1, 1)": 2,
      "initialize": 2,
      "test_data_cc": 2,
      "sales_val.values": 2,
      "test[col]": 2,
      "xTrain": 2,
      "train[feature_scale]": 2,
      "test[feature_scale]": 2,
      "condition.reshape(-1, 1)": 2,
      "test['image_size'].values.reshape(-1, 1)": 2,
      "XT": 2,
      "XV": 2,
      "valSet2": 2,
      "df_train.values": 2,
      "df_test.values": 2,
      "test_X": 2,
      "x_eval": 2,
      "test_clean": 2,
      "_x": 2,
      "_x_test": 2,
      "test[features]": 2,
      "test.iloc[:, 3:]": 2,
      "y_test": 2,
      "img": 2,
      "yy": 2,
      "yyy": 2,
      "test_knn": 2,
      "sub_df[SCALE_COLUMNS]": 2,
      "dataset[feat_scale]": 2,
      "final_test_df": 2,
      "india.iloc[-14:, :]": 2,
      "df_train[['q1len', 'q2len', 'q1_n_words', 'q2_n_words', 'word_share']]": 2,
      "df[scale_features]": 2,
      "new_test[features]": 2,
      "train_feature": 2,
      "test_feature": 2,
      "np.array(y_pred_mink).reshape(-1, 1)": 2,
      "train_df[features]": 2,
      "val_df[features]": 2,
      "test_df_1[features]": 2,
      "test_df_2[features]": 2,
      "test_data['image_size'].values.reshape(-1, 1)": 2,
      "test_textWords.reshape(-1, 1)": 2,
      "test_word_density.reshape(-1, 1)": 2,
      "test_geneCount.reshape(-1, 1)": 2,
      "unmissed": 2,
      "i": 2,
      "np.nan_to_num(df_train[[col]].values)": 2,
      "X_train[X_train.columns]": 2,
      "X_test[X_test.columns]": 2,
      "X_train[col].values.reshape(-1, 1)": 2,
      "X_val[col].values.reshape(-1, 1)": 2,
      "y_train.values.reshape(-1, 1)": 2,
      "y_val.values.reshape(-1, 1)": 2,
      "lr_X_train": 2,
      "lr_X_val": 2,
      "lr_X_test": 2,
      "knn_X_train": 2,
      "knn_X_val": 2,
      "knn_X_test": 2,
      "x_valid": 2,
      "X_test[columns_int]": 2,
      "X_test_arr.reshape(-1, 1)": 2,
      "test_data_v7[numerical_columns]": 2,
      "apptest[[col]]": 1,
      "df_dict_test[file][[col]]": 1,
      "test_app_domain": 1,
      "train[numerical_columns]": 1,
      "df_test[scaling_col]": 1,
      "[[2, 2]]": 1,
      "training_set": 1,
      "np.array(merged_train_df)": 1,
      "np.array(target1).reshape(844392, 1)": 1,
      "train_TDF.toarray()": 1,
      "testData": 1,
      "input_data": 1,
      "features.iloc[0:records, 0:1].values": 1,
      "features.iloc[records:, 0:1].values": 1,
      "test_labels.reshape(-1, 1)": 1,
      "X_train1": 1,
      "X_train2": 1,
      "X_test1": 1,
      "X_test2": 1,
      "submission_test": 1,
      "train_data[x].values.reshape(-1, 1)": 1,
      "test_data[x].values.reshape(-1, 1)": 1,
      "test_data[feature].values.reshape(-1, 1)": 1,
      "X_test[ints_df]": 1,
      "test[ints_df]": 1,
      "X_Fin_test": 1,
      "np.expand_dims(infection_train, axis=1)": 1,
      "np.expand_dims(infection_test, axis=1)": 1,
      "np.expand_dims(fatality_train, axis=1)": 1,
      "np.expand_dims(fatality_test, axis=1)": 1,
      "np.expand_dims(daily_cases_infected, axis=1)": 1,
      "np.expand_dims(daily_cases_fatality, axis=1)": 1,
      "infections": 1,
      "fatality": 1,
      "x_prediction": 1,
      "test_df_copy": 1,
      "train_x": 1,
      "df.iloc[:, 3:]": 1,
      "X_train[num_cols]": 1,
      "X_test[num_cols]": 1,
      "X_test_processed": 1,
      "test_poly": 1,
      "X_validate": 1,
      "data[features_to_scale]": 1,
      "test[features_to_scale]": 1,
      "X[self._vestas_features]": 1,
      "df[data_cols].values": 1,
      "df_final_dummies_test": 1,
      "bench_train": 1,
      "bench_test": 1,
      "main_train": 1,
      "main_test": 1,
      "test_x_num": 1,
      "test[train_x.columns]": 1,
      "df1": 1,
      "dd.train[dd.numeric_features]": 1,
      "dd.test[dd.numeric_features]": 1,
      "submit.loc[:, submit.columns != 'shot_made_flag'].values": 1,
      "app_test_enc_imput_med": 1,
      "train[['question_num_words', 'answer_num_words']].values": 1,
      "test[['question_num_words', 'answer_num_words']].values": 1,
      "X_final": 1,
      "ts.take([2], axis=1)[0:1004]": 1,
      "X[['distance', 'week', 'offense_score', 'defense_score', 'line_of_scrimmage', 'game_clock']]": 1,
      "test.drop('shot_id', axis=1)": 1,
      "df['X'].values.reshape(df.shape[0], 1)": 1,
      "df['Y'].values.reshape(df.shape[0], 1)": 1,
      "df_test1.values": 1,
      "y_valid.values.reshape(-1, 1)": 1,
      "_.loc[:, train_x_col[1:]]": 1,
      "X_teste.loc[:, :]": 1,
      "X_train[feats]": 1,
      "X_valid[feats]": 1,
      "X_test[feats]": 1,
      "titanic_test_2[num_vars]": 1,
      "titanic_test_2[['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']]": 1,
      "train[['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal']]": 1,
      "project_data['price'].values.reshape(-1, 1)": 1,
      "train2[f].fillna(0).astype('float32').values.reshape(-1, 1)": 1,
      "y_trn_cv": 1,
      "y_val_cv": 1,
      "valid_set.drop(columns=['time', 'open_channels'])": 1,
      "df_train[feature_scale]": 1,
      "X_val[non_cat_features]": 1,
      "test[non_cat_features]": 1,
      "validation_df_scaled[wanted_columns]": 1,
      "test_scaled[wanted_columns]": 1,
      "quant": 1,
      "norm": 1,
      "test_data[scale_features]": 1,
      "test_X_df": 1,
      "Y_train": 1,
      "sales[['item_price']]": 1,
      "x_train.values": 1,
      "x_test.values": 1,
      "test.drop(columns=['PetID']).values": 1,
      "temp_x.values": 1,
      "X_validataion_new": 1,
      "testDF_meanENC": 1,
      "X_test[cols_to_scale]": 1,
      "testing[cols_to_scale]": 1,
      "test['fnlwgt'].values.reshape(-1, 1)": 1,
      "test['age'].values.reshape(-1, 1)": 1,
      "X_test_cc": 1,
      "X_test_ft": 1,
      "feat.values": 1,
      "train[['item_price']]": 1,
      "gausian_test[num_feat]": 1,
      "self.hold_out[train_x.columns]": 1,
      "self.test[train_x.columns]": 1,
      "test[num_cols]": 1,
      "data[cat_count]": 1,
      "dtest[cat_count]": 1,
      "source": 1,
      "df_cut.values": 1,
      "X_train_reg": 1,
      "X_test_reg": 1,
      "X_train_f": 1,
      "X_test_f": 1,
      "dataset[num_features].drop(['SalePrice', 'YrSold'], axis=1)": 1,
      "dataset[['SalePrice']]": 1,
      "test1[num_pred]": 1,
      "df_one_hot": 1,
      "np.array([vals])": 1,
      "normalize_train_df[column].as_matrix().reshape(-1, 1)": 1,
      "X_test[:, 1:]": 1,
      "X_submit[:, 1:]": 1,
      "test[[c for c in test.columns if c not in ['path']]]": 1,
      "test_df.values.reshape(-1, 311)": 1,
      "train_data[['Age']]": 1,
      "test_data[['Age']]": 1,
      "train_TS": 1,
      "valid_TS": 1,
      "df_to_reshape[columns_list]": 1,
      "df_final_test": 1,
      "data_to_cluster": 1,
      "train_data[['Fatalities', 'Population_Size', 'Tourism']]": 1,
      "test_data[['Fatalities', 'Population_Size', 'Tourism']]": 1,
      "train[['runtime', 'budget', 'popularity']]": 1,
      "test[['runtime', 'budget', 'popularity']]": 1,
      "test.as_matrix()": 1,
      "tr": 1,
      "trr": 1,
      "inputs_eval": 1,
      "x_test_params": 1,
      "prep_df": 1,
      "predict_data": 1,
      "combined_df[['Weeks_Passed', 'Base_FVC', 'Base_Percent', 'Base_Age']]": 1,
      "df_test.iloc[:, 1:]": 1,
      "X_real_test": 1,
      "pd.concat([X_train, X_val])": 1,
      "train[meta_features]": 1,
      "test[meta_features]": 1,
      "df_final": 1,
      "X_test[cols]": 1,
      "df_test[cols]": 1,
      "alldata2": 1,
      "df_test_features": 1,
      "x_train1_cc": 1,
      "x_train2_cc": 1,
      "x_test_cc": 1,
      "data_gene[GENES]": 1,
      "data_cell[CELLS]": 1,
      "test.drop(columns='sig_id')": 1,
      "tr_X": 1,
      "te_X": 1,
      "testDataX": 1,
      "np.array(X.loc[:, self.column], dtype=float).reshape(-1, 1)": 1,
      "oil[['dcoilwtico']]": 1,
      "np.array(test_data[column]).reshape(-1, 1)": 1,
      "submission.excerpt_len.values.reshape(-1, 1)": 1,
      "val_ds": 1,
      "X_val_multi.loc[:, whichVars]": 1,
      "X_test_multi.loc[:, whichVars]": 1,
      "X_val_multi_y": 1,
      "X_test_multi_y": 1,
      "Y_test": 1,
      "XPred": 1,
      "columns": 1,
      "x_test[col].values.reshape(-1, 1)": 1,
      "df[['q1_word_len', 'q2_word_len', 'q1_char_len', 'q2_char_len', 'common_unigrams_len', 'common_unigrams_ratio', 'common_bigrams_len', 'common_bigrams_ratio', 'common_trigrams_len', 'common_trigrams_ratio']]": 1,
      "df[['q1_word_len', 'q2_word_len', 'q1_char_len', 'q2_char_len', 'common_unigrams_len', 'common_unigrams_ratio', 'common_bigrams_len', 'common_bigrams_ratio', 'common_trigrams_len', 'common_trigrams_ratio', 'q1_q2_intersect', 'q1_freq', 'q2_freq']]": 1,
      "df_test[['q1_word_len', 'q2_word_len', 'q1_char_len', 'q2_char_len', 'common_unigrams_len', 'common_unigrams_ratio', 'common_bigrams_len', 'common_bigrams_ratio', 'common_trigrams_len', 'common_trigrams_ratio', 'q1_q2_intersect', 'q1_freq', 'q2_freq']]": 1,
      "validation_df[scale_cols]": 1,
      "test_df[scale_cols]": 1,
      "feature_data": 1,
      "test_data.values": 1,
      "paraval": 1,
      "paratest": 1,
      "X_train_df": 1,
      "X_test_df": 1,
      "test[:, :-1]": 1,
      "csv[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Title']].to_numpy()": 1,
      "xTest": 1,
      "df_test[num_features]": 1,
      "x_t_knn": 1,
      "x_va": 1,
      "val_X[numerical]": 1,
      "test[numerical]": 1,
      "x_pred": 1,
      "testdata": 1,
      "val[cont_cols]": 1,
      "numeric_data": 1,
      "numeric_test_data": 1,
      "valid_data": 1,
      "np.array(TestX_Diff).reshape(len(TestX_Diff), 1)": 1,
      "data_X_test": 1,
      "x_train_sub_pca": 1,
      "x_val_pca": 1,
      "x_test_pca": 1,
      "arr": 1,
      "x_train_s": 1,
      "x_test_s": 1,
      "np.array(testf_df['cp_time']).reshape(-1, 1)": 1,
      "np.nan_to_num(self.dataframe[RATINGS].iloc[start:end].values)": 1,
      "test_norm[c].values.reshape(-1, 1)": 1,
      "train_poly_fea": 1,
      "test_poly_fea": 1,
      "df[[x]]": 1,
      "df1[[x]]": 1,
      "X_t[['ID']].values": 1,
      "train_X": 1,
      "cv_textWords.reshape(-1, 1)": 1,
      "cv_word_density.reshape(-1, 1)": 1,
      "cv_geneCount.reshape(-1, 1)": 1,
      "train[col]": 1,
      "test_features.drop('cp_type', axis=1)": 1,
      "test_data[['age_approx']]": 1,
      "santander_teste": 1,
      "XtestCr_unscaled": 1,
      "test[i].values.reshape(-1, 1)": 1,
      "df_test[i].values.reshape(-1, 1)": 1,
      "test.drop(columns=['PassengerId'])": 1,
      "test_train": 1,
      "test_test": 1,
      "train[transform_columns]": 1,
      "test[transform_columns]": 1,
      "ntrain": 1,
      "ntest": 1,
      "x_train2[[x]]": 1,
      "x_test2[[x]]": 1,
      "test_cols_df.drop('TransactionID', axis=1).iloc[start_i:end_i].values": 1,
      "test_X[train_columns]": 1,
      "Data": 1,
      "df[columns].values": 1,
      "X_test_kaggle": 1,
      "inputs_df[numeric_cols]": 1,
      "testing_data[numeric_cols]": 1,
      "test_df.drop(test_drops, axis=1)": 1,
      "df_all[other_cols]": 1,
      "embed_test": 1,
      "train_df": 1,
      "test_selected": 1,
      "dataset_y": 1,
      "np.array(x_batch_train['item_price']).reshape(-1, 1)": 1,
      "np.array(x_batch_test['item_price']).reshape(-1, 1)": 1,
      "np.array(y_batch_train).reshape(-1, 1)": 1,
      "np.array(y_batch_test).reshape(-1, 1)": 1,
      "np.array(month_data['item_price']).reshape(-1, 1)": 1,
      "X_submission": 1,
      "train.drop('Cover_Type', axis=1)": 1,
      "k2": 1,
      "test_feature_df.values": 1,
      "col_matrix": 1,
      "test_data[['item_condition_id', 'shipping']]": 1,
      "test_data.astype(np.float64)": 1,
      "test_df[numeric_cols_test_list]": 1,
      "df_test_data": 1,
      "f64": 1,
      "X_test.A": 1,
      "train_df['text_NegScore'].values.reshape(-1, 1)": 1,
      "cv_df['text_NegScore'].values.reshape(-1, 1)": 1,
      "df_test['text_NegScore'].values.reshape(-1, 1)": 1,
      "train_df['text_PosScore'].values.reshape(-1, 1)": 1,
      "cv_df['text_PosScore'].values.reshape(-1, 1)": 1,
      "df_test['text_PosScore'].values.reshape(-1, 1)": 1,
      "train_df['text_NeuScore'].values.reshape(-1, 1)": 1,
      "cv_df['text_NeuScore'].values.reshape(-1, 1)": 1,
      "df_test['text_NeuScore'].values.reshape(-1, 1)": 1,
      "train_df['text_compoundScore'].values.reshape(-1, 1)": 1,
      "cv_df['text_compoundScore'].values.reshape(-1, 1)": 1,
      "df_test['text_compoundScore'].values.reshape(-1, 1)": 1,
      "testing": 1,
      "X_test[col].values.reshape(-1, 1)": 1,
      "df_train[['q1len', 'q2len', 'q1_n_words', 'q2_n_words', 'word_share', 'q1_q2_intersect', 'q1_freq', 'q2_freq']]": 1,
      "test_df[['pickup_longitude']]": 1,
      "testKaggle_clean[['pickup_longitude']]": 1,
      "test_df[['pickup_latitude']]": 1,
      "testKaggle_clean[['pickup_latitude']]": 1,
      "test_df[['dropoff_latitude']]": 1,
      "testKaggle_clean[['dropoff_latitude']]": 1,
      "test_df[['dropoff_longitude']]": 1,
      "testKaggle_clean[['dropoff_longitude']]": 1,
      "test_df[['passenger_count']]": 1,
      "testKaggle_clean[['passenger_count']]": 1,
      "test_df[['manhattan']]": 1,
      "testKaggle_clean[['manhattan']]": 1,
      "test_df[['distance']]": 1,
      "testKaggle_clean[['distance']]": 1,
      "test_df[['latdiff']]": 1,
      "testKaggle_clean[['latdiff']]": 1,
      "test_df[['londiff']]": 1,
      "testKaggle_clean[['londiff']]": 1,
      "test_df[['year']]": 1,
      "testKaggle_clean[['year']]": 1,
      "test_df[['month']]": 1,
      "testKaggle_clean[['month']]": 1,
      "test_df[['day']]": 1,
      "testKaggle_clean[['day']]": 1,
      "test_df[['hour']]": 1,
      "testKaggle_clean[['hour']]": 1,
      "test_df[['minute']]": 1,
      "testKaggle_clean[['minute']]": 1,
      "test_df[['second']]": 1,
      "testKaggle_clean[['second']]": 1,
      "stn_x_valid": 1,
      "stn_x_test": 1,
      "FeaturesData": 1,
      "Xtrain0": 1,
      "SamplesFeatures": 1,
      "TargetFreq": 1,
      "Zenc": 1,
      "AnswersTokFreq": 1,
      "EncAnswers": 1,
      "VolunteersTokFreq": 1,
      "EncVolunteers": 1,
      "test_no_id.values": 1,
      "test_cases_no_id.values": 1,
      "test_fatal_no_id.values": 1,
      "testset": 1,
      "test[col].to_frame()": 1,
      "test_x_new": 1,
      "test[[f]]": 1,
      "X_eval": 1,
      "np.array(X_test_pca_df_final[col]).reshape(-1, 1)": 1,
      "np.array(X_test_pca_dfNewKaggle[col]).reshape(-1, 1)": 1,
      "np.array(X_test[col]).reshape(-1, 1)": 1,
      "np.array(test_data[col]).reshape(-1, 1)": 1,
      "rgb_batch_Y": 1,
      "df_to_scale[c].values.reshape(-1, 1)": 1,
      "ze": 1,
      "test_data_removing_missing[cols]": 1,
      "y_test[columns_int]": 1,
      "scaling_features_data": 1,
      "self.data[scaling_feature]": 1,
      "train_features[numeric_cols]": 1,
      "test_features[numeric_cols]": 1,
      "updatedTestData": 1,
      "train_data[['Age', 'Fare']]": 1,
      "test_data[['Age', 'Fare']]": 1,
      "test_data_preped": 1,
      "dftestx": 1,
      "inputs0": 1,
      "inputs1": 1,
      "inputs2": 1,
      "inputs3": 1,
      "inputs4": 1,
      "test_data.drop(['ID_code'], axis=1)": 1,
      "train_data_1": 1,
      "test_data_1": 1,
      "test_pcs": 1,
      "train['description_length'].reshape(-1, 1)": 1,
      "test['description_length'].reshape(-1, 1)": 1,
      "training_features": 1,
      "testing_features": 1,
      "test_df[numeric_fea].values.astype(np.float64)": 1,
      "test_x_cnts": 1,
      "numeric_train": 1,
      "numeric_test": 1,
      "testFeatures": 1,
      "test_s": 1,
      "test_min": 1,
      "test_s_min": 1,
      "test_max": 1,
      "test_s_max": 1,
      "X_test_sub": 1,
      "df_train['Cover_Type'].values.reshape(-1, 1)": 1,
      "df_validate['Cover_Type'].values.reshape(-1, 1)": 1,
      "app_test[x_num]": 1,
      "np.array(np.round(df_test['Fare'], 2)).reshape(-1, 1)": 1
    },
    "sklearn.preprocessing._encoders.OneHotEncoder.__init__.sparse": {
      "True": 1015,
      "False": 489,
      "'False'": 1,
      "sparse": 1
    },
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.n_estimators": {
      "100": 347,
      "500": 52,
      "1000": 46,
      "10": 28,
      "200": 25,
      "g['ne']": 18,
      "750": 18,
      "50": 14,
      "300": 13,
      "400": 13,
      "850": 11,
      "250": 11,
      "950": 11,
      "25": 10,
      "580": 9,
      "700": 9,
      "2000": 9,
      "1200": 9,
      "350": 8,
      "num_trees": 7,
      "550": 6,
      "n_estimators": 6,
      "20": 6,
      "c - 1": 5,
      "150": 3,
      "600": 3,
      "1050": 3,
      "65": 3,
      "710": 2,
      "195": 2,
      "1500": 2,
      "800": 2,
      "120": 2,
      "900": 2,
      "30": 2,
      "377": 2,
      "851": 1,
      "trees": 1,
      "3000": 1,
      "int(params['n_estimators'])": 1,
      "450": 1,
      "5000": 1,
      "l3_et_n_estimators": 1,
      "int(round(n_estimators))": 1,
      "852": 1,
      "128": 1,
      "375": 1,
      "trial.suggest_int('n_estimators', 10, 1000)": 1,
      "170": 1,
      "47": 1
    },
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.max_features": {
      "'auto'": 537,
      "50": 43,
      "g['mf']": 18,
      "60": 16,
      "'sqrt'": 14,
      "120": 8,
      "168": 7,
      "0.3": 7,
      "num_features": 6,
      "64": 6,
      "26": 5,
      "val": 5,
      "27": 4,
      "55": 4,
      "0.55": 4,
      "0.5": 4,
      "17": 4,
      "0.8": 3,
      "None": 3,
      "20": 3,
      "33": 3,
      "'log2'": 2,
      "30": 2,
      "3": 2,
      "max_fs": 2,
      "max_features": 2,
      "100": 2,
      "9": 2,
      "70": 1,
      "0.25": 1,
      "160": 1,
      "128": 1,
      "500": 1,
      "str(params['max_features'])": 1,
      "29": 1,
      "25": 1,
      "int(round(max_features))": 1,
      "28": 1,
      "trial.suggest_float('max_features', 0.45, 0.6)": 1,
      "48": 1,
      "15": 1,
      "40": 1,
      "112": 1
    },
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.criterion": {
      "'gini'": 560,
      "'entropy'": 173
    },
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.min_samples_split": {
      "2": 573,
      "4": 84,
      "3": 26,
      "10": 16,
      "5": 10,
      "1": 9,
      "25": 3,
      "1000": 2,
      "7": 1,
      "split": 1,
      "int(params['min_samples_split'])": 1,
      "trial.suggest_int('min_samples_split', 3, 5)": 1,
      "13": 1,
      "2 * (n_attributed / (1000 * total_data))": 1,
      "30": 1,
      "20": 1,
      "min_samples_split": 1,
      "12": 1
    },
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.max_depth": {
      "None": 507,
      "35": 41,
      "g['md']": 18,
      "5": 17,
      "30": 15,
      "40": 15,
      "10": 9,
      "4": 8,
      "8": 8,
      "15": 7,
      "6": 6,
      "25": 6,
      "60": 5,
      "50": 5,
      "47": 5,
      "100": 5,
      "23": 5,
      "17": 4,
      "2": 4,
      "1": 4,
      "21": 4,
      "45": 3,
      "20": 3,
      "80": 3,
      "85": 3,
      "7": 2,
      "3": 2,
      "300": 2,
      "12": 2,
      "depth": 1,
      "int(params['max_depth'])": 1,
      "37": 1,
      "38": 1,
      "28": 1,
      "34": 1,
      "l3_et_max_depth": 1,
      "int(round(max_depth))": 1,
      "14": 1,
      "24": 1,
      "22": 1,
      "trial.suggest_int('max_depth', 2, 10)": 1,
      "max_features": 1,
      "42": 1,
      "13": 1
    },
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.min_samples_leaf": {
      "1": 587,
      "2": 91,
      "8": 14,
      "5": 7,
      "120": 7,
      "3": 6,
      "4": 4,
      "10": 3,
      "18": 2,
      "6": 2,
      "100": 2,
      "20": 1,
      "leaves": 1,
      "trial.suggest_int('min_samples_leaf', 6, 10)": 1,
      "40": 1,
      "13": 1,
      "n_attributed / (1000 * total_data)": 1,
      "15": 1,
      "min_samples_split": 1
    },
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.n_jobs": {
      "None": 489,
      "-1": 212,
      "4": 11,
      "3": 9,
      "1": 4,
      "16": 3,
      "2": 3,
      "42": 1,
      "model_njobs": 1
    },
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.__init__.sparse": {
      "True": 199,
      "False": 41
    },
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.fit_transform.X": {
      "train": 125,
      "train_dic": 14,
      "x_cat_data": 12,
      "x_cat_test": 12,
      "dict_train_data": 5,
      "train.append(test).T.to_dict().values()": 4,
      "trainCatX.T.to_dict().values()": 4,
      "testCatX.T.to_dict().values()": 4,
      "data[cols].apply(mkdict, axis=1)": 4,
      "df[cols].to_dict(orient='records')": 3,
      "X_cat.T.to_dict().values()": 3,
      "X": 3,
      "df.T.to_dict().values()": 2,
      "X_train": 2,
      "x_cat_train": 2,
      "train_df_dic": 2,
      "dataframe.iloc[:, 1:94].T.to_dict().values()": 2,
      "X_cat_TEST.T.to_dict().values()": 2,
      "data[cols].to_dict(outtype='records')": 2,
      "catdf.to_dict('records')": 2,
      "geoUpdate": 1,
      "dictFeatureCat": 1,
      "dictFeatureCon": 1,
      "X_dict": 1,
      "X_train.to_dict(orient='record')": 1,
      "categorical_feat_dict": 1,
      "noncategorical_feat_dict": 1,
      "X_dict_train": 1,
      "v": 1,
      "all_df.to_dict('records')": 1,
      "train_df['type'].to_frame().to_dict('records')": 1,
      "g.to_dict('records')": 1,
      "df.drop(['Sales'], axis=1).fillna(0).to_dict('records')": 1,
      "df_cat_train.to_dict('records')": 1,
      "train_features.to_dict(orient='records')": 1,
      "test_features.to_dict(orient='records')": 1
    },
    "sklearn.ensemble._gb.GradientBoostingRegressor.predict.X": {
      "X_test": 153,
      "x_test": 45,
      "X_train": 38,
      "test": 38,
      "X": 23,
      "X_val": 22,
      "X_validation": 13,
      "test_X": 13,
      "dataTrain": 13,
      "dataTest": 13,
      "x_train": 12,
      "test_data": 10,
      "X_evaluation": 9,
      "X_xTest_CS": 8,
      "df_test": 7,
      "test[col]": 7,
      "X_valid": 7,
      "test.values": 7,
      "test_x": 6,
      "X_val_kneigboards": 6,
      "test_df": 5,
      "train": 5,
      "Xtest": 5,
      "data_X": 4,
      "models_df[features].values": 4,
      "test[features]": 4,
      "X_valid_scaled": 4,
      "cyc_data_tst[x_ipts]": 4,
      "test_full": 3,
      "x2[col]": 3,
      "test_df.drop(['id', 'timestamp'], axis=1)": 3,
      "X_test_cases": 3,
      "X_test_deaths": 3,
      "test_pwr": 3,
      "XttC": 3,
      "XttF": 3,
      "testX": 3,
      "val_X": 3,
      "features_train": 3,
      "X_Train": 3,
      "features_validation": 3,
      "train_data": 2,
      "finaltestset": 2,
      "X_test_main": 2,
      "train[ewm_features]": 2,
      "x": 2,
      "x_val.drop(['Weeks', 'Base_Week'], 1)": 2,
      "x_test.drop(['Weeks', 'Base_Week'], 1)": 2,
      "x_val": 2,
      "submission_for_prediction": 2,
      "X_test_scaled": 2,
      "oof_df.values[test_ix]": 2,
      "predictions_df": 2,
      "testdata": 2,
      "tmp_data": 2,
      "data_sub": 2,
      "train_full": 2,
      "self.x_train": 2,
      "train[col]": 2,
      "df_test2.values": 2,
      "features_test": 2,
      "X_val_ohe": 2,
      "test_data_vector": 2,
      "test_Data": 2,
      "x_train3": 2,
      "x_test3": 2,
      "xtest_lng": 2,
      "test[columns_v]": 2,
      "dat_valid": 2,
      "dat_train": 2,
      "test_final": 2,
      "X_test_kneigboards": 2,
      "x_valid": 1,
      "features": 1,
      "X1": 1,
      "TS1": 1,
      "testing_data": 1,
      "testFactors": 1,
      "finalt.drop('air_store_id', axis=1)": 1,
      "test_set_prep": 1,
      "df_train_ohe": 1,
      "df_test_ohe": 1,
      "test_scaled": 1,
      "solo_test_scaled": 1,
      "duo_test_scaled": 1,
      "squad_test_scaled": 1,
      "other_test_scaled": 1,
      "finaltrainset[train_index]": 1,
      "finaltrainset[test_index]": 1,
      "validationX": 1,
      "data_test": 1,
      "test_onehot": 1,
      "X_test_outlier": 1,
      "X_test_main.drop('cluster', axis=1).copy()": 1,
      "X_test_outlier.drop('cluster', axis=1).copy()": 1,
      "X_test.drop('cluster', axis=1)": 1,
      "X_test_outlier.drop(drop_cols, axis=1)": 1,
      "test_ohe": 1,
      "X_teste": 1,
      "test_df[features + ['Total Cases']].values": 1,
      "test_df[features + ['Rate of Spread']].values": 1,
      "np.nan_to_num(val_X)": 1,
      "np.nan_to_num(test_X)": 1,
      "val_X[val_idx, :]": 1,
      "X_dtrain": 1,
      "x1[col]": 1,
      "XdataTest.iloc[:, :2]": 1,
      "df2": 1,
      "X_train_scaled": 1,
      "self.Xtest": 1,
      "x_test_df": 1,
      "test.drop('ID', axis=1)": 1,
      "X_valida": 1,
      "tes2": 1,
      "X_OfT": 1,
      "Xs_test": 1,
      "final_test_trans": 1,
      "X_unseen": 1,
      "test_feature": 1,
      "test_set": 1,
      "dataTrainWithoutOutliers": 1,
      "house_test_data": 1,
      "X_test_data": 1,
      "test_ready": 1,
      "test2": 1,
      "v1_test.drop(['id'], axis=1)": 1,
      "v5_test.drop(['id'], axis=1)": 1,
      "test[best_features]": 1,
      "pred[fb_features]": 1,
      "test[sfs_fatures]": 1,
      "for_features_test": 1,
      "xx": 1,
      "self.proc_train": 1,
      "self.proc_test": 1,
      "new_test": 1,
      "X_pred": 1,
      "bike_test[casual_features]": 1,
      "bike_test[registered_features]": 1,
      "X_tr": 1,
      "X_vld": 1,
      "test_new[num_features]": 1,
      "X_Scaler_test": 1,
      "X_Scaler_train": 1,
      "x_test[columns_to_use]": 1,
      "x_test_0": 1,
      "x_test_1": 1,
      "x_train_0.drop(labels=['price_doc'], axis=1).values": 1,
      "x_train_1.drop(labels=['price_doc'], axis=1).values": 1,
      "rl_test": 1,
      "modified_test": 1,
      "modified_train": 1,
      "tes_X[:, 1:]": 1,
      "allTestData": 1,
      "self.x_validation": 1,
      "test.drop(['id'], axis=1)": 1,
      "test_data.iloc[:, 1:]": 1,
      "test[X.columns]": 1,
      "Xvalidation": 1,
      "extracted_x_features_test": 1,
      "X_kaggle": 1,
      "prepared_housing_test": 1,
      "X_train_model": 1,
      "X_test_model": 1,
      "test[independent_variable]": 1,
      "test_data.drop(['Date', 'ForecastId', 'ConfirmedCases'], axis=1)": 1,
      "high_mi_val_data": 1,
      "test[ewm_features]": 1,
      "teste[variaveis[1:]].fillna(-1)": 1,
      "X_df_test": 1,
      "X_eval_temp": 1,
      "X_train_temp": 1,
      "x_test_f": 1,
      "X_validate": 1,
      "test[names]": 1,
      "count_test3": 1,
      "x_test_competi\u00e7\u00e3o": 1,
      "X_test_1": 1,
      "x_test_competi\u00e7\u00e3o_I": 1,
      "X_test_2": 1,
      "X_test_4": 1,
      "final_X_test": 1,
      "ready_test": 1,
      "test1_data": 1,
      "xTestDataHotEncoded": 1,
      "np.nan_to_num(test)": 1,
      "test_transformed.iloc[:, [3, 4, 5, 6, 7, 8, 9, 12, 14, 17]].fillna(value=0)": 1,
      "test_features.drop(exclusions, axis=1)": 1,
      "xtest": 1,
      "xtest_lat": 1,
      "dfteste": 1,
      "dfteste_d": 1,
      "X_pred[f30]": 1,
      "[X_test.iloc[i]]": 1,
      "data1": 1,
      "copy_test": 1,
      "train_mod": 1,
      "test_mod": 1,
      "X_cv": 1,
      "Test_data": 1,
      "S_test": 1,
      "X_test_sc": 1,
      "test_data_prep": 1,
      "test2model": 1,
      "Z": 1
    },
    "sklearn.neighbors._classification.KNeighborsClassifier.__init__.p": {
      "2": 1708,
      "1": 84,
      "2.9": 23,
      "p": 3,
      "p_": 1,
      "clf.best_params_['p']": 1,
      "chosenP": 1
    },
    "sklearn.neighbors._classification.KNeighborsClassifier.__init__.leaf_size": {
      "30": 1743,
      "15": 41,
      "20": 13,
      "40": 4,
      "10": 4,
      "lsize": 3,
      "1": 2,
      "17": 2,
      "2000": 2,
      "leaf": 1,
      "38": 1,
      "35": 1,
      "12": 1,
      "9": 1,
      "leaf_size": 1,
      "14": 1
    },
    "sklearn.preprocessing._data.binarize.threshold": {
      "threshold": 8,
      "0.0": 4
    },
    "sklearn.preprocessing._data.binarize.X": {
      "preds": 8,
      "prediction.reshape(-1, 1)": 2,
      "xUy": 1,
      "y_pred1": 1
    },
    "sklearn.metrics._classification.classification_report.target_names": {
      "None": 2716,
      "target_names": 107,
      "CLASSES": 32,
      "target": 27,
      "['0', '1']": 17,
      "class_enc.classes_": 9,
      "list(target_names.values())": 9,
      "cm_plot_labels": 8,
      "[x for x in word_encoder.classes_]": 8,
      "classes": 7,
      "['Not Real', 'Real']": 6,
      "['1', '2', '3', '4']": 6,
      "emotions.values()": 5,
      "['sincere', 'insincere']": 4,
      "categories": 4,
      "labels": 4,
      "data.classes": 4,
      "['Sincere', 'Insincere']": 4,
      "['Not Relevant', 'Relevant']": 3,
      "Classes": 3,
      "cuisines": 3,
      "set(list(y_validation))": 3,
      "['no_tumor', 'has_tumor']": 3,
      "diag_text": 3,
      "class_map.values()": 3,
      "list(df.target_name.unique())": 2,
      "label_dict.values()": 2,
      "label_names": 2,
      "testGen.class_indices.keys()": 2,
      "target_str": 2,
      "cat_enc.classes_": 2,
      "names": 2,
      "['Died', 'Survived']": 2,
      "list(map_characters.values())": 2,
      "target_classes": 2,
      "lb_enc.inverse_transform(model.classes_).tolist()": 2,
      "newsgroups_train.target_names": 2,
      "['no_tumor_tissue', 'has_tumor_tissue']": 1,
      "['negative', 'somewhat negative', 'neutral', 'somewhat positive', 'positive']": 1,
      "['Very Good', 'Ideal']": 1,
      "['1', '0']": 1,
      "list(label_dict.values())": 1,
      "class_labels": 1,
      "class_names": 1,
      "['Correct', 'Wrong']": 1,
      "le_category.inverse_transform(np.arange(39))": 1,
      "train['sentiment'].unique()": 1,
      "list(valid_generator.class_indices.keys())": 1,
      "['is_not_attributed', 'is_attributed']": 1,
      "['Toxic', 'Clean']": 1,
      "list(dict_characters.values())": 1,
      "['Positive', 'Negative']": 1,
      "action_set_v1_used": 1,
      "['Not disaster', 'Disaster']": 1,
      "['EAP', 'HPL', 'MWS']": 1,
      "['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferative DR']": 1,
      "food_cat.classes_": 1,
      "sub_columns": 1,
      "['Not Survived', 'Survived']": 1,
      "list(le.classes_)": 1,
      "['fake', 'real']": 1,
      "category_lookup.keys()": 1,
      "np.unique(Y_classes)": 1,
      "['not a disaster', 'disaster']": 1,
      "classes_labels": 1,
      "label_encoder.classes_": 1,
      "['Neutral', 'Entailment', 'Contradiction']": 1,
      "clases_val_ord": 1,
      "['Class: ' + str(i) for i in range(10)]": 1,
      "validation_generator.class_indices": 1,
      "test['school_state'].unique()": 1,
      "['target', 'var_0']": 1,
      "names_list": 1,
      "class_dict.keys()": 1,
      "my_tags": 1,
      "['A', 'B', 'NEITHER']": 1,
      "list_classes": 1,
      "['cat', 'dog']": 1,
      "['Dogs', 'Cats']": 1,
      "['class 0', 'class 1']": 1,
      "['not disaster', 'disaster']": 1,
      "['Atypical Appearance (Class 0)', 'Indeterminate Appearance (Class 1)', 'Negative for Pneumonia (Class 2)', 'Typical Appearance (Class 4)']": 1,
      "cols": 1,
      "[x for x in numstonames.values()]": 1,
      "Exp": 1,
      "['healthy', 'multiple_diseases', 'rust', 'scab']": 1,
      "['Fake', 'Real']": 1,
      "['holiday_log', 'median21_h', 'yearly_log']": 1,
      "cfg['class_names']": 1
    },
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.predict.X": {
      "X_test": 47,
      "test_x": 29,
      "X_train": 6,
      "train_numeric_X": 6,
      "test[feats]": 5,
      "test": 5,
      "testfeature": 5,
      "X_val": 4,
      "tsiftdatax_test": 4,
      "test_merge4": 3,
      "train_merge4": 3,
      "test_data": 3,
      "TestData": 3,
      "x_test": 3,
      "games[col].fillna(-1)": 3,
      "sub[col].fillna(-1)": 3,
      "ttextdataemx_test": 3,
      "TestForPred": 2,
      "test_vectors": 2,
      "train[feats]": 2,
      "X_valid": 2,
      "test_data_features": 2,
      "heads2[feats]": 2,
      "xvalid": 2,
      "xtest": 2,
      "X_validate": 2,
      "val_x": 1,
      "cv_test": 1,
      "x_mod_teste": 1,
      "test_tfidf": 1,
      "test[features]": 1,
      "np.array([dataArr_test[i]])": 1,
      "x_train": 1,
      "subset[['day_of_week_encoded', 'pd_district_encoded', 'x', 'y', 'hour']]": 1,
      "df_test": 1,
      "X_test_val": 1,
      "test_df[[str(x) for x in range(300)]]": 1,
      "val_": 1,
      "df_test_transf2": 1,
      "count_test": 1,
      "xvalid_tfv": 1,
      "xtest_tfv": 1,
      "x_valid": 1,
      "X_test.fillna(0)": 1,
      "X_test_ex.fillna(0)": 1,
      "X_ref_test_vec": 1,
      "embeddings_test": 1,
      "test[feats2]": 1,
      "x_val": 1,
      "self.x_test": 1,
      "test_X": 1,
      "test[binarias + discretas]": 1,
      "X_test_df": 1,
      "data_test.drop(['Id', 'Cover_Type'], axis=1)": 1,
      "dataset.drop(['Id', 'Cover_Type'], axis=1)": 1,
      "selected_data_test": 1,
      "validate_embeddings": 1,
      "test_embeddings": 1,
      "test_data[selected_features]": 1,
      "data_x": 1,
      "x_test.to_list()": 1,
      "va_x": 1
    },
    "sklearn.model_selection._search.GridSearchCV.__init__.return_train_score": {
      "False": 2561,
      "True": 191
    },
    "sklearn.linear_model._coordinate_descent.ElasticNet.__init__.random_state": {
      "None": 275,
      "42": 73,
      "3": 58,
      "seed": 19,
      "0": 17,
      "random_state": 5,
      "1": 4,
      "123": 3,
      "2020": 2,
      "seed_val": 2,
      "RANDOM_SEED": 2,
      "2": 1,
      "777": 1,
      "520": 1,
      "5": 1,
      "19": 1,
      "198": 1,
      "101": 1
    },
    "sklearn.preprocessing._data.PolynomialFeatures.__init__.include_bias": {
      "True": 466,
      "False": 96
    },
    "sklearn.model_selection._validation.cross_val_score.scoring": {
      "None": 1257,
      "'accuracy'": 445,
      "'neg_mean_squared_error'": 391,
      "'roc_auc'": 373,
      "'f1'": 273,
      "'r2'": 125,
      "scoring": 124,
      "'neg_root_mean_squared_error'": 100,
      "'neg_mean_absolute_error'": 96,
      "'neg_mean_squared_log_error'": 76,
      "'neg_log_loss'": 75,
      "scorer": 66,
      "rmsle_scorer": 46,
      "rmse_loss": 43,
      "rmsle": 30,
      "scorerRelu": 19,
      "scorerAbs": 16,
      "l1(70)": 14,
      "'f1_micro'": 12,
      "make_scorer(qwk)": 12,
      "'f1_macro'": 11,
      "r2": 11,
      "acc_sco": 11,
      "f1_sco": 11,
      "acc_score": 10,
      "rmsle_score": 9,
      "gini_scorer": 9,
      "'f1_weighted'": 8,
      "mae_val": 8,
      "accuracy": 8,
      "mse": 6,
      "make_scorer(cohen_kappa_score)": 5,
      "make_scorer(accuracy_score)": 5,
      "make_scorer(mean_squared_error)": 5,
      "'roc_auc_ovr'": 4,
      "msle": 4,
      "make_scorer(median_absolute_error)": 4,
      "wmae_scorer": 4,
      "my_scorer": 3,
      "neg_rmsle": 3,
      "custom_scorer": 3,
      "'recall_weighted'": 3,
      "l1": 3,
      "make_scorer(f1_score)": 2,
      "kappa_scorer": 2,
      "rmse": 2,
      "RMSLE_scorer": 2,
      "metric": 2,
      "score_gini": 2,
      "mcc_scorer": 2,
      "auc_scorer": 2,
      "'precision_weighted'": 2,
      "ndcg_scorer": 2,
      "Matthew": 2,
      "score_acc": 2,
      "sc": 2,
      "model_scoring_type": 2,
      "scorer[scorer_name]": 1,
      "mae_scoring": 1,
      "'precision'": 1,
      "'recall'": 1,
      "eval_metric": 1,
      "make_scorer(f1_score, average='macro')": 1,
      "auroc_scorer": 1,
      "make_scorer(rmsle_score)": 1,
      "make_scorer(measure_performance, needs_proba=True)": 1,
      "make_scorer(r2_score)": 1,
      "chosen_scoring": 1,
      "l1(i)": 1,
      "mae_score": 1,
      "self.scoring": 1,
      "make_scorer(metric_aggregation)": 1,
      "make_scorer(neg_rmsle)": 1,
      "make_scorer(roc_auc_score)": 1,
      "my_score": 1,
      "utility": 1,
      "QUADRATIC_WEIGHT_SCORER": 1,
      "smape_score": 1,
      "ftwo_scorer": 1,
      "fitness_function": 1,
      "log_scorer": 1,
      "make_scorer(metric, greater_is_better=False)": 1,
      "scorer2": 1,
      "'neg_median_absolute_error'": 1,
      "root_mean_squared_log_error_scorer": 1,
      "make_scorer(mean_absolute_error)": 1,
      "gini_sklearn": 1,
      "metrics.make_scorer(log_loss, needs_proba=True, labels=train_y)": 1,
      "make_scorer(mean_squared_error, greater_is_better=False)": 1
    },
    "sklearn.model_selection._validation.cross_val_predict.cv": {
      "10": 47,
      "3": 46,
      "5": 41,
      "cv": 21,
      "None": 21,
      "kf": 10,
      "kfold": 4,
      "StratifiedKFold(n_splits=5, random_state=8)": 4,
      "StratifiedKFold(4)": 3,
      "StratifiedKFold(random_state=8)": 3,
      "6": 2,
      "cvlist": 2,
      "StratifiedKFold(4, random_state=42)": 2,
      "2": 1,
      "ms.StratifiedKFold(n_splits=3, random_state=SEED)": 1,
      "ms.StratifiedKFold(n_splits=3, random_state=seed)": 1,
      "7": 1,
      "GroupKFold(5)": 1,
      "100": 1,
      "20": 1,
      "StratifiedKFold(n_splits=10, shuffle=True, random_state=42)": 1
    },
    "sklearn.model_selection._validation.cross_val_predict.estimator": {
      "model": 20,
      "clf": 15,
      "estimator": 8,
      "sgd_clf": 7,
      "gbr": 7,
      "rf_clf": 6,
      "lr": 6,
      "log_clf": 6,
      "lin_reg": 6,
      "RandomForestRegressor(n_estimators=100)": 6,
      "MultinomialNB(alpha=1.0)": 4,
      "lr_model": 3,
      "rfc": 3,
      "LinearRegression()": 3,
      "algo": 3,
      "ex1": 3,
      "rf": 2,
      "xgb_model": 2,
      "gs.best_estimator_": 2,
      "mlp": 2,
      "svm.SVC(kernel='rbf')": 2,
      "svm.SVC(kernel='linear')": 2,
      "KNeighborsClassifier(n_neighbors=9)": 2,
      "RandomForestClassifier(n_estimators=100)": 2,
      "LogisticRegression()": 2,
      "DecisionTreeClassifier()": 2,
      "GaussianNB()": 2,
      "pip": 2,
      "svm_clf": 2,
      "ada": 2,
      "training_pipeline": 2,
      "regr": 2,
      "svm_classifier": 2,
      "rf_classifier": 2,
      "dr": 2,
      "algorithm": 2,
      "forest_clf": 2,
      "clf_logreg": 2,
      "clf_SGD": 2,
      "clf_rfc": 2,
      "en_pipeline": 1,
      "LR": 1,
      "ls": 1,
      "dt": 1,
      "RF_baseline": 1,
      "SVR(kernel='rbf', C=10)": 1,
      "SVR(kernel='rbf', C=1)": 1,
      "linreg": 1,
      "mnb_clf": 1,
      "vot_clf": 1,
      "stk_clf": 1,
      "rf_reg": 1,
      "knn": 1,
      "xgb_pipeline": 1,
      "calib_pipeline": 1,
      "sig_pipeline": 1,
      "sgd": 1,
      "gnb": 1,
      "knc": 1,
      "best_sgd": 1,
      "best_log_reg": 1,
      "BernoulliNB()": 1,
      "binary_with_obj": 1,
      "upd_binary_with_obj": 1,
      "xgb.XGBRegressor()": 1,
      "pls": 1,
      "pls_opt": 1,
      "rf_model": 1,
      "multinomialnb_classifier": 1,
      "gnb_classifier": 1,
      "logisticreg_classifier": 1,
      "reg": 1,
      "rfModel2": 1,
      "rfModel2_sig": 1,
      "mod": 1,
      "rf_pipeline": 1,
      "classifier": 1,
      "random_forest": 1,
      "nb": 1,
      "xt": 1,
      "xgb": 1,
      "en": 1,
      "tree": 1,
      "gbr_tuned": 1,
      "ExtraTreesClassifier(n_estimators=100, n_jobs=4)": 1,
      "log_classifier": 1,
      "my_pipeline": 1,
      "rfr": 1,
      "logModel": 1,
      "DT_model": 1,
      "RF_model": 1,
      "KNeighborsClassifier()": 1,
      "RandomForestRegressor(n_estimators=10, n_jobs=3)": 1,
      "RFR": 1,
      "regressor_gb": 1,
      "regressor_xgb": 1,
      "smote": 1,
      "extra_base": 1,
      "rf_base": 1,
      "vote_clf": 1
    },
    "sklearn.model_selection._validation.cross_val_predict.X": {
      "X": 51,
      "X_train": 40,
      "data": 13,
      "X_train_transformed": 7,
      "titanic_prepared": 7,
      "x_train": 6,
      "train": 5,
      "X_train_featselection": 4,
      "train_X_tfidf": 4,
      "x": 3,
      "X_val": 3,
      "sourcevars": 2,
      "X_sc": 2,
      "X_std": 2,
      "X_clustered": 2,
      "X_train_prepared": 2,
      "train_prep": 2,
      "inv_stemmatized_data": 2,
      "train[ints]": 2,
      "td": 2,
      "train_x": 2,
      "Features_std": 2,
      "X_time": 2,
      "X_diff": 2,
      "np.hstack([X_time, X_diff])": 2,
      "test_X": 2,
      "X_validation": 2,
      "test_ohe": 1,
      "xtrain": 1,
      "qtx.transform(df)": 1,
      "qtx_f.transform(df)": 1,
      "X_train_processed": 1,
      "X_train_sub": 1,
      "X_original": 1,
      "X_all_rd": 1,
      "X_extended": 1,
      "d[:data_count]": 1,
      "X_selected": 1,
      "inv_lemmatized_data": 1,
      "w2v_data": 1,
      "new_X": 1,
      "train[objs]": 1,
      "X_train.select_dtypes(include=[np.number])": 1,
      "x.drop(['Patient', 'Base_Percent'], 1)": 1,
      "temp[['FVC_pred', 'Confidence']]": 1,
      "temp[['Base_FVC', 'Base_Percent', 'Week_Offset', 'factor', 'Age', 'Male']]": 1,
      "X_gnb": 1,
      "X_train_dtm": 1,
      "data.iloc[:, range(i)]": 1,
      "data[best_finetune.head(225).index]": 1,
      "Xreg": 1,
      "normal_train_zero": 1,
      "X_train[features_list]": 1,
      "train['is_holiday']": 1,
      "predictor": 1,
      "predictor1": 1,
      "predictor2": 1,
      "Train_X": 1,
      "mnist_features_prepared": 1,
      "X_mfcc": 1,
      "xs": 1,
      "train_data.values": 1,
      "X_valid": 1,
      "X_smote_v": 1,
      "X_train_new": 1,
      "X_train_scaled": 1
    },
    "sklearn.model_selection._validation.cross_val_predict.y": {
      "y": 59,
      "y_train": 50,
      "Y": 21,
      "target": 20,
      "train_y": 11,
      "titanic_labels": 7,
      "y_train_transformed": 5,
      "quora_train.target.values": 5,
      "outs": 5,
      "y_val": 3,
      "targetvar": 2,
      "Y_train": 2,
      "y_train_4": 2,
      "Target": 2,
      "test_y": 2,
      "y_is9_validation": 2,
      "target_log": 1,
      "qty.transform(train.LConfirmedCases[train.serd > 70].values.reshape(-1, 1))": 1,
      "qty_f.transform(train.LFatalities[train.serd > 70].values.reshape(-1, 1))": 1,
      "y_train_sub": 1,
      "t[:data_count]": 1,
      "temp['Best_conf'].astype(int)": 1,
      "temp[no_drop]": 1,
      "df_tweet_train['target']": 1,
      "y_train_0": 1,
      "train['weekly_sales']": 1,
      "target2": 1,
      "Train_Y": 1,
      "mnist_labels": 1,
      "ys": 1,
      "y_valid": 1,
      "y_smote_v": 1
    },
    "sklearn.pipeline.Pipeline.fit_transform.X": {
      "X_train": 63,
      "data[cols]": 34,
      "train": 29,
      "train_set": 20,
      "X": 19,
      "train2[cols]": 18,
      "test2[cols]": 18,
      "train_df.drop(['target'], axis=1)": 9,
      "X_test": 8,
      "train['x'].values": 8,
      "test": 6,
      "train['Description_bow']": 6,
      "test_set": 5,
      "data": 5,
      "df": 5,
      "X_val": 4,
      "X[y == 1]['question_text']": 4,
      "train_X": 4,
      "train_df.copy()": 4,
      "alpha": 3,
      "x_train": 3,
      "df_test": 3,
      "train_data": 2,
      "train_x": 2,
      "x_val": 2,
      "X[y == 0]['question_text']": 2,
      "train_final.to_numpy()": 2,
      "num_data": 2,
      "x_train_df": 2,
      "full_predict": 2,
      "X_train_sample": 2,
      "weather_train": 2,
      "df_train.iloc[:, 1:-2]": 2,
      "result": 2,
      "train_data_num": 2,
      "test_df": 2,
      "housing_num": 2,
      "X_prime_all": 2,
      "train['desc']": 2,
      "train['Description']": 2,
      "data1[columns]": 2,
      "df_train": 2,
      "area[['Prev_cases', 'rh', 'temp', 'Elapsed']]": 2,
      "train_data.drop(columns=['ID_code', 'target'])": 1,
      "Y_train_full": 1,
      "test_x": 1,
      "train_dummies": 1,
      "X_prep[y == 1]['question_text']": 1,
      "train_set_balanced": 1,
      "train['features'].values": 1,
      "X_train.select_dtypes(include='number')": 1,
      "x": 1,
      "clean_train_reviews": 1,
      "train.iloc[te]": 1,
      "train.iloc[tr]": 1,
      "outliers_clipped": 1,
      "val_set": 1,
      "outliers_clipped_val": 1,
      "raw_df": 1,
      "train[['Elevation', 'Horizontal_Distance_To_Roadways']]": 1,
      "np.hstack((train.text.values, test.text.values))": 1,
      "market_train": 1,
      "trainDf": 1,
      "feature": 1,
      "train['ingredients_text'].values": 1,
      "X_train_tk": 1,
      "X_train_pr": 1,
      "X_train_clean": 1,
      "train[['question1', 'question2']]": 1,
      "X_train_pp_df": 1,
      "X_test_pp_df": 1,
      "ncaa_temp": 1,
      "ncaa_test_temp": 1,
      "dfn[features].values": 1,
      "all_data['question_title']": 1,
      "all_data['question_body']": 1,
      "all_data['answer']": 1,
      "data_all['product_title']": 1,
      "data_all['search_term']": 1,
      "data_all['prod_desc_merge']": 1,
      "xtrain": 1,
      "XX": 1,
      "data_plot_no_nan[num_features_final]": 1,
      "train_Y_df": 1,
      "num_transformer.fit_transform(data_plot_no_nan[cat_features_final])": 1,
      "data_plot_no_nan[cat_features_final]": 1,
      "struct": 1,
      "train.drop(['scalar_coupling_constant'], axis=1)": 1,
      "train_df": 1,
      "DTrain_F": 1,
      "df['ingredients'].values": 1,
      "train['annots_top_desc_pick']": 1,
      "train['annots_top_desc']": 1,
      "train['sentiment_entities']": 1,
      "gp_dense_first.drop(['PetID'], axis=1)": 1,
      "explore_train[num_columns]": 1,
      "engineered_data": 1,
      "test_data.copy()": 1,
      "train1": 1,
      "pdesc_transformed": 1,
      "train_pipe_before": 1,
      "Xv2_train": 1,
      "Xv18_train": 1,
      "Xrez_train": 1,
      "all_data['product_title']": 1,
      "all_data['search_term']": 1,
      "all_data['prod_desc_merge']": 1,
      "totalA": 1,
      "vgg16_features": 1,
      "vgg19_features": 1,
      "resnet_features": 1,
      "incept_features": 1,
      "train['ingredients'].values": 1,
      "housing_object": 1,
      "x_res": 1,
      "train_text": 1,
      "mnist_features": 1,
      "df_pca": 1,
      "df_app_train": 1,
      "y": 1,
      "df_slct": 1,
      "X_train_num": 1,
      "X_train_cat": 1,
      "X_all": 1,
      "df.comment_text": 1,
      "train.copy()": 1,
      "self.train.copy()": 1,
      "us_va": 1,
      "test_data_num": 1,
      "X_train_base": 1,
      "s_data": 1,
      "train[col].astype(str)": 1,
      "df_train['title']": 1
    },
    "sklearn.pipeline.Pipeline.fit_transform.y": {
      "None": 367,
      "y": 13,
      "y_train": 13,
      "train.target": 7,
      "train['price']": 2,
      "train_y": 2,
      "[]": 1,
      "train['scalar_coupling_constant']": 1,
      "data['Survived']": 1,
      "labelsTrain1": 1,
      "labels": 1,
      "s_labels": 1
    },
    "sklearn.model_selection._validation.cross_val_score.verbose": {
      "0": 3736,
      "1": 28,
      "3": 18,
      "True": 5,
      "False": 5,
      "2": 4,
      "10": 2,
      "15": 1,
      "verbose": 1,
      "20": 1
    },
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.learning_rate": {
      "0.1": 646,
      "0.05": 107,
      "0.01": 69,
      "0.001": 21,
      "0.005": 20,
      "0.8": 13,
      "0.2": 11,
      "0.046": 9,
      "0.0035": 8,
      "0.5": 6,
      "1.0": 5,
      "learning_rate": 4,
      "0.15": 4,
      "0.02": 4,
      "0.03005": 3,
      "0.03": 3,
      "l": 3,
      "0.25": 3,
      "0.06": 3,
      "0.9": 3,
      "2.2227e-13": 2,
      "0.11": 2,
      "0.007": 2,
      "1.5": 2,
      "0.04": 2,
      "0.7": 2,
      "0.008": 2,
      "0.035": 1,
      "0.006": 1,
      "lr": 1,
      "trial.suggest_float('learning_rate', 0.001, 0.01)": 1,
      "float(study.best_trial.params['learning_rate'])": 1,
      "0.013": 1,
      "0.002": 1,
      "0.0001": 1,
      "_learning_rate": 1,
      "0.03603208066350368": 1,
      "0.0161": 1,
      "0.4": 1,
      "rate": 1,
      "i": 1,
      "0.08": 1,
      "0.015": 1,
      "0.14": 1,
      "0.09": 1,
      "trial.suggest_uniform('learning_rate', 1e-05, 1)": 1,
      "0.23500000000000001": 1,
      "0.025": 1,
      "0.03221041191991256": 1,
      "0.115": 1,
      "trial.suggest_uniform('learning_rate', 0.005, 0.01)": 1,
      "0.009": 1,
      "eta": 1,
      "0.0025": 1,
      "1": 1,
      "0.299": 1,
      "0.003": 1
    },
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.max_depth": {
      "3": 628,
      "4": 156,
      "5": 43,
      "6": 24,
      "2": 23,
      "10": 18,
      "9": 16,
      "8": 15,
      "1": 14,
      "7": 12,
      "20": 7,
      "13": 6,
      "15": 5,
      "max_depth": 5,
      "i": 2,
      "depth": 1,
      "trial.suggest_int('max_depth', 10, 15)": 1,
      "study.best_trial.params['max_depth']": 1,
      "80": 1,
      "22": 1,
      "32": 1,
      "30": 1,
      "_max_depth": 1,
      "12": 1,
      "None": 1,
      "trial.suggest_int('max_depth', 2, 10)": 1,
      "gs.best_params_['max_depth']": 1,
      "11": 1,
      "100": 1,
      "trial.suggest_int('max_depth', 3, 11)": 1
    },
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.random_state": {
      "None": 602,
      "42": 103,
      "0": 84,
      "5": 73,
      "1": 25,
      "seed": 15,
      "10": 9,
      "2021": 9,
      "31": 7,
      "random_state": 6,
      "47": 6,
      "23": 4,
      "33": 3,
      "96": 3,
      "ra1": 3,
      "ra2": 3,
      "123": 3,
      "60": 3,
      "11": 2,
      "RANDOM_SEED": 2,
      "69": 2,
      "3": 2,
      "45": 2,
      "RANDOM_STATE": 2,
      "2016": 2,
      "58": 1,
      "17": 1,
      "21": 1,
      "777": 1,
      "2018": 1,
      "1717": 1,
      "520": 1,
      "88": 1,
      "7": 1,
      "51": 1,
      "np.random.randint(1000)": 1,
      "x": 1,
      "49": 1,
      "1818": 1
    },
    "sklearn.preprocessing._encoders.OrdinalEncoder.__init__.dtype": {
      "np.float64": 279,
      "'int'": 34,
      "np.int16": 5,
      "np.int32": 4,
      "int": 2,
      "'uint8'": 1,
      "'float32'": 1
    },
    "sklearn.preprocessing._encoders.OrdinalEncoder.fit.X": {
      "X": 3,
      "df_ordinal_all": 2,
      "train_df[['Province_State', 'Country_Region']]": 2,
      "test_df[['Province_State', 'Country_Region']]": 2,
      "categorical[['Utilities', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'HeatingQC', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence']]": 2,
      "train_X[cols[1]].to_numpy().reshape(-1, 1)": 2,
      "train_X[cols[2]].to_numpy().reshape(-1, 1)": 2,
      "train[['Street', 'CentralAir']]": 1,
      "df['Sex'].values.reshape(-1, 1)": 1,
      "self.train_data_sex": 1,
      "self.train_data_embarked": 1,
      "X[columns]": 1,
      "dd.train[dd.cat_features]": 1,
      "df_train.ord_5.values.reshape(-1, 1)": 1,
      "train[['Sex', 'Ticket', 'Cabin', 'Embarked']]": 1,
      "test[['Sex', 'Ticket', 'Cabin', 'Embarked']]": 1,
      "X[self.columns]": 1,
      "ord_5_matrix": 1,
      "X_train[['Sex', 'Cabin', 'Name', 'Ticket', 'Embarked']]": 1,
      "X_test[['Sex', 'Cabin', 'Name', 'Ticket', 'Embarked']]": 1,
      "X_train[cat_features]": 1,
      "train_df['ord_5'].values.reshape(-1, 1)": 1,
      "X_train_cat": 1,
      "train_df[ordinal_columns]": 1,
      "pd.concat([df['train'][features['cat']], df['test'][features['cat']]])": 1,
      "df['train'][features['cat']]": 1,
      "train.ord_5.values.reshape(-1, 1)": 1,
      "x_train[cat_features]": 1,
      "train['killPlace'].values.reshape(-1, 1)": 1,
      "np.reshape(months, (-1, 1))": 1,
      "np.reshape(days, (-1, 1))": 1
    },
    "sklearn.preprocessing._encoders.OrdinalEncoder.transform.X": {
      "trainpred[['Country_Region', 'Province_State']].fillna('')": 8,
      "np.array(location).reshape(1, -1)": 4,
      "x_test[oe_features]": 3,
      "df_ordinal_all": 2,
      "df[['store_id']]": 2,
      "df[['item_id']]": 2,
      "train_df[['Province_State', 'Country_Region']]": 2,
      "test_df[['Province_State', 'Country_Region']]": 2,
      "test_data[categorical_cols]": 2,
      "pd.DataFrame(X_test_cats, columns=[X_cats_names])[ordinal_features]": 2,
      "X": 2,
      "df[dataset][features['cat']]": 2,
      "categorical[['Utilities', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'HeatingQC', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence']]": 2,
      "np.reshape(X_test['Month'].to_list(), (-1, 1))": 2,
      "np.reshape(X_test['Day'].to_list(), (-1, 1))": 2,
      "train_X[cols[1]].to_numpy().reshape(-1, 1)": 2,
      "train_X[cols[2]].to_numpy().reshape(-1, 1)": 2,
      "test_df[cols[1]].to_numpy().reshape(-1, 1)": 2,
      "test_df[cols[2]].to_numpy().reshape(-1, 1)": 2,
      "train[['Street', 'CentralAir']]": 1,
      "test[['Street', 'CentralAir']]": 1,
      "df['Sex'].values.reshape(-1, 1)": 1,
      "test['Sex'].values.reshape(-1, 1)": 1,
      "new_data_sex": 1,
      "new_data_embarked": 1,
      "X[columns]": 1,
      "X_test[columns]": 1,
      "dd.train[dd.cat_features]": 1,
      "dd.test[dd.cat_features]": 1,
      "df_train.ord_5.values.reshape(-1, 1)": 1,
      "df_test.ord_5.values.reshape(-1, 1)": 1,
      "train[['Sex', 'Ticket', 'Cabin', 'Embarked']]": 1,
      "test[['Sex', 'Ticket', 'Cabin', 'Embarked']]": 1,
      "X[self.columns].fillna(-1)": 1,
      "ord_5_matrix": 1,
      "family_df_test": 1,
      "X_train[['Sex', 'Cabin', 'Name', 'Ticket', 'Embarked']]": 1,
      "X_test[['Sex', 'Cabin', 'Name', 'Ticket', 'Embarked']]": 1,
      "X_train[cat_features]": 1,
      "t[cat_features]": 1,
      "test[var].values.reshape(-1, 1)": 1,
      "X[['Sex']]": 1,
      "X[['Cabin_letter']]": 1,
      "X[['Embarked']]": 1,
      "np.array(test_data['matchType']).reshape(-1, 1)": 1,
      "train_df['ord_5'].values.reshape(-1, 1)": 1,
      "test_df['ord_5'].values.reshape(-1, 1)": 1,
      "X_train_cat": 1,
      "train_df[ordinal_columns]": 1,
      "test_df[ordinal_columns]": 1,
      "train.ord_5.values.reshape(-1, 1)": 1,
      "test.ord_5.values.reshape(-1, 1)": 1,
      "test[['ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5']]": 1,
      "categorical_columns": 1,
      "Prediction[['Country_Region', 'Province_State']].fillna('')": 1,
      "ctei[ordinal]": 1,
      "test_df[cat_FEATURES]": 1,
      "np.reshape(X_train['Month'].to_list(), (-1, 1))": 1,
      "np.reshape(X_train['Day'].to_list(), (-1, 1))": 1,
      "test_cluster[bincol_labeled]": 1,
      "test_cluster[normcol_labeled]": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.alpha": {
      "0.0001": 274,
      "1e-05": 91,
      "0.01": 10,
      "1": 9,
      "0.001": 9,
      "0.1": 7,
      "alpha": 7,
      "0.51": 3,
      "alpha_nn": 2,
      "a": 2,
      "1e-08": 2,
      "3": 2,
      "0.314": 1,
      "0.005": 1,
      "0.0": 1,
      "0.244205309454865": 1,
      "params['alpha']": 1,
      "int(best['alpha'])": 1,
      "0.05": 1,
      "0.008": 1,
      "mlp_alpha": 1,
      "0.003": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.max_iter": {
      "200": 322,
      "1000": 29,
      "500": 11,
      "100": 10,
      "300": 8,
      "400": 5,
      "7": 4,
      "2000": 4,
      "3000": 4,
      "max_iter": 4,
      "20000": 3,
      "14000": 2,
      "800": 2,
      "600000": 2,
      "8000": 2,
      "12000": 2,
      "4000": 1,
      "10": 1,
      "50": 1,
      "250": 1,
      "max_iterations": 1,
      "NB_EPOCH": 1,
      "5000": 1,
      "1": 1,
      "30000": 1,
      "2500": 1,
      "120000": 1,
      "40": 1,
      "10000000": 1,
      "33": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.batch_size": {
      "'auto'": 413,
      "batch_size": 4,
      "1000": 2,
      "256": 1,
      "50": 1,
      "7000": 1,
      "1024": 1,
      "4082": 1,
      "16": 1,
      "bSize": 1,
      "250": 1,
      "128": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.tol": {
      "0.0001": 398,
      "1e-06": 16,
      "1e-09": 4,
      "1e-05": 3,
      "0.001": 2,
      "1e-08": 2,
      "5e-07": 2,
      "1e-10": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.verbose": {
      "False": 365,
      "True": 51,
      "10": 6,
      "1": 2,
      "Tr": 1,
      "verb": 1,
      "0": 1,
      "3": 1
    },
    "sklearn.utils.shuffle.random_state": {
      "None": 468,
      "123": 75,
      "42": 52,
      "0": 42,
      "37": 23,
      "RANDOM_SEED": 22,
      "8": 21,
      "RANDOM_STATE": 11,
      "SEED": 10,
      "2": 9,
      "coefs.seed": 8,
      "666": 5,
      "2019": 5,
      "314": 5,
      "10": 4,
      "2018": 4,
      "1": 4,
      "1234": 3,
      "5": 3,
      "22": 3,
      "r": 2,
      "np.random.randint(1, 123)": 2,
      "27": 2,
      "random_state": 2,
      "21": 2,
      "13": 2,
      "2017": 2,
      "seed": 2,
      "SEED_2": 2,
      "3": 1,
      "1372": 1,
      "895": 1,
      "16": 1,
      "7": 1,
      "rand": 1,
      "2020": 1,
      "rd": 1,
      "43": 1,
      "242": 1,
      "25": 1,
      "142": 1,
      "33": 1,
      "234": 1,
      "1981": 1,
      "random_seed": 1,
      "CFG.seed": 1,
      "5285": 1,
      "x.name + seed + i": 1,
      "24": 1,
      "100293": 1,
      "1000": 1,
      "69": 1,
      "shuffle_random_state": 1,
      "OP_SEED": 1,
      "801": 1
    },
    "sklearn.naive_bayes.BernoulliNB.__init__.binarize": {
      "0.0": 198,
      "0.01": 5,
      "5000": 1,
      "0": 1,
      "None": 1
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet.__init__.alpha": {
      "0.001": 19
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet.__init__.random_state": {
      "42": 17,
      "31": 2
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet.__init__.l1_ratio": {
      "0.5": 19
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet.fit.X": {
      "X_tr": 8,
      "X_train": 8,
      "x_train": 2,
      "X": 1
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet.fit.y": {
      "y_train": 10,
      "y_tr": 8,
      "y": 1
    },
    "sklearn.preprocessing._data.Normalizer.transform.X": {
      "X": 7,
      "dataset[['desc_len', 'name_len']]": 5,
      "test": 5,
      "X_test": 4,
      "train": 4,
      "X_scaled": 3,
      "x_test": 2,
      "test_fill": 2,
      "x_train": 2,
      "x_train['price'].values.reshape(-1, 1)": 1,
      "x_cv['price'].values.reshape(-1, 1)": 1,
      "test_data['price'].values.reshape(-1, 1)": 1,
      "x_train['teacher_number_of_previously_posted_projects'].values.reshape(-1, 1)": 1,
      "x_cv['teacher_number_of_previously_posted_projects'].values.reshape(-1, 1)": 1,
      "test_data['teacher_number_of_previously_posted_projects'].values.reshape(-1, 1)": 1,
      "df.drop('item_cnt_day', axis=1)": 1,
      "test_copy[num_cols]": 1,
      "train_df[num_features]": 1,
      "test_df[num_features]": 1,
      "X_train['price'].values.reshape(-1, 1)": 1,
      "X_cv['price'].values.reshape(-1, 1)": 1,
      "X_test['price'].values.reshape(-1, 1)": 1,
      "X_train['teacher_number_of_previously_posted_projects'].values.reshape(-1, 1)": 1,
      "X_cv['teacher_number_of_previously_posted_projects'].values.reshape(-1, 1)": 1,
      "X_test['teacher_number_of_previously_posted_projects'].values.reshape(-1, 1)": 1,
      "df_train['Lat'].values.reshape(1, -1)": 1,
      "df_test['Lat'].values.reshape(1, -1)": 1,
      "df_train['Long'].values.reshape(1, -1)": 1,
      "df_test['Long'].values.reshape(1, -1)": 1,
      "df_train['Date'].values.reshape(1, -1)": 1,
      "df_test['Date'].values.reshape(1, -1)": 1,
      "df_train['ConfirmedCases'].values.reshape(1, -1)": 1,
      "conf_cased_pred.reshape(1, -1)": 1,
      "train_data[['Age']]": 1,
      "test_data[['Age']]": 1,
      "X_train": 1,
      "y_train": 1,
      "y_test": 1,
      "X2": 1,
      "X2_test": 1,
      "X2_tt": 1,
      "X_scaled_test": 1,
      "df_test": 1,
      "X_train['total_words'].values.reshape(-1, 1)": 1,
      "X_cv['total_words'].values.reshape(-1, 1)": 1,
      "quora_test['total_words'].values.reshape(-1, 1)": 1,
      "X_train['total_chars'].values.reshape(-1, 1)": 1,
      "X_cv['total_chars'].values.reshape(-1, 1)": 1,
      "quora_test['total_chars'].values.reshape(-1, 1)": 1,
      "X_train['total_unique_words'].values.reshape(-1, 1)": 1,
      "X_cv['total_unique_words'].values.reshape(-1, 1)": 1,
      "quora_test['total_unique_words'].values.reshape(-1, 1)": 1,
      "X_train['word_score'].values.reshape(-1, 1)": 1,
      "X_cv['word_score'].values.reshape(-1, 1)": 1,
      "quora_test['word_score'].values.reshape(-1, 1)": 1,
      "X_train['total_stopwords'].values.reshape(-1, 1)": 1,
      "X_cv['total_stopwords'].values.reshape(-1, 1)": 1,
      "quora_test['total_stopwords'].values.reshape(-1, 1)": 1,
      "X_train['total_upper'].values.reshape(-1, 1)": 1,
      "X_cv['total_upper'].values.reshape(-1, 1)": 1,
      "quora_test['total_upper'].values.reshape(-1, 1)": 1,
      "X_train['total_lower'].values.reshape(-1, 1)": 1,
      "X_cv['total_lower'].values.reshape(-1, 1)": 1,
      "quora_test['total_lower'].values.reshape(-1, 1)": 1,
      "X_train['total_word_title'].values.reshape(-1, 1)": 1,
      "X_cv['total_word_title'].values.reshape(-1, 1)": 1,
      "quora_test['total_word_title'].values.reshape(-1, 1)": 1,
      "X_train['median_word_len'].values.reshape(-1, 1)": 1,
      "X_cv['median_word_len'].values.reshape(-1, 1)": 1,
      "quora_test['median_word_len'].values.reshape(-1, 1)": 1,
      "X_train_numeric.values.reshape(1, -1)": 1,
      "X_test_numeric.values.reshape(1, -1)": 1,
      "shape_a": 1,
      "shape_b": 1,
      "X_donor_choose_train['resource_cost'].values.reshape(1, -1)": 1,
      "X_donor_choose_validation['resource_cost'].values.reshape(1, -1)": 1,
      "test_df_pre_processed_original['resource_cost'].values.reshape(1, -1)": 1,
      "X_donor_choose_train['teacher_number_of_previously_posted_projects'].values.reshape(1, -1)": 1,
      "X_donor_choose_validation['teacher_number_of_previously_posted_projects'].values.reshape(1, -1)": 1,
      "test_df_pre_processed_original['teacher_number_of_previously_posted_projects'].values.reshape(1, -1)": 1,
      "test.iloc[:, :3]": 1,
      "train[col]": 1,
      "test[col]": 1,
      "df_val[continuous_features]": 1,
      "Xtest": 1,
      "test_X": 1,
      "data": 1,
      "training_set[training_set.columns[0:5]]": 1,
      "test_cases_fetch_data[test_cases_fetch_data.columns[4:9]]": 1
    },
    "sklearn.decomposition._pca.PCA.fit_transform.X": {
      "X": 126,
      "train.drop(['y'], axis=1)": 106,
      "data[CELLS]": 98,
      "data[GENES]": 96,
      "X_train": 67,
      "data": 45,
      "train": 31,
      "df[cols]": 25,
      "x": 23,
      "data[cols]": 20,
      "normalize(train[features], axis=0)": 20,
      "train_data": 17,
      "train_features[GENES]": 17,
      "train_features[CELLS]": 17,
      "train[:, gs]": 17,
      "train[:, cs]": 17,
      "x_train": 16,
      "df": 14,
      "train_scaled": 14,
      "X_scaled": 13,
      "train[GENES]": 13,
      "train[CELLS]": 13,
      "data_all[GENES]": 12,
      "data_all[CELLS]": 12,
      "X_test": 11,
      "test": 9,
      "fft_all": 9,
      "orig_0": 9,
      "orig_1": 9,
      "resamp_0": 9,
      "resamp_1": 9,
      "data[max_items, :].todense()": 8,
      "X_normalized": 8,
      "train_d[features]": 8,
      "transformation_model[:50]": 8,
      "X_train_std": 7,
      "images_scaled": 6,
      "test_normalized": 6,
      "temp_X_holder": 6,
      "scaled_data": 5,
      "X[genes]": 5,
      "X[cells]": 5,
      "X_train_scaled": 5,
      "sample_data": 5,
      "train[g_cols]": 5,
      "train.drop(['Cover_Type'], axis=1)": 5,
      "data[g_features]": 5,
      "data[c_features]": 5,
      "features": 5,
      "sc.fit_transform(all_data[vcols].fillna(-1))": 5,
      "standardized_data": 5,
      "train[col]": 5,
      "pca_df": 4,
      "X_std": 4,
      "num_df": 4,
      "train_rbst": 4,
      "train.drop(['id', 'target'], axis=1)": 4,
      "X[:, 2:]": 4,
      "x_train_solo_scaled": 4,
      "x_train_duo_scaled": 4,
      "x_train_squad_scaled": 4,
      "x_train_solo_fpp_scaled": 4,
      "x_train_duo_fpp_scaled": 4,
      "x_train_squad_fpp_scaled": 4,
      "x_train_flarefpp_scaled": 4,
      "x_train_flaretpp_scaled": 4,
      "x_train_crashfpp_scaled": 4,
      "x_train_crashtpp_scaled": 4,
      "df[feat_cols].values": 3,
      "X.copy()": 3,
      "X_train_sc": 3,
      "train_df": 3,
      "df_train.drop(['y'], axis=1)": 3,
      "X_gene_e": 3,
      "train[c_cols]": 3,
      "df[var_list]": 3,
      "pr": 3,
      "x_scaler": 3,
      "x_test": 3,
      "X1": 3,
      "X_train0": 3,
      "X_train1": 3,
      "train_data[features]": 3,
      "train_x": 3,
      "transformation_model[:num]": 2,
      "x_train_normalized": 2,
      "pca_test_df": 2,
      "total": 2,
      "train_df.drop(['price_doc'], axis=1)": 2,
      "news_volume": 2,
      "df_train[target_cols]": 2,
      "X_total[:, -100:]": 2,
      "np.concatenate((np.concatenate((tX, tY), 1), np.concatenate((reduced_X, reduced_Y), 1)), 0)": 2,
      "c_not_cat_train": 2,
      "not_cat_train": 2,
      "tfIdf_Matrix": 2,
      "np.concatenate([X, test])": 2,
      "x_cont": 2,
      "subset": 2,
      "StandardScaler(X_Tr[flist], axis=0)": 2,
      "encodeddf": 2,
      "X_train_norm": 2,
      "X_norm": 2,
      "X_cell_gene": 2,
      "clean_train_df[feature_cols]": 2,
      "img_tr": 2,
      "trainX": 2,
      "train.loc[:, mask]": 2,
      "genes_comb": 2,
      "cells_comb": 2,
      "comb": 2,
      "embeds": 2,
      "train_X_scaled": 2,
      "pca_data": 2,
      "pt": 2,
      "X_train_cpy": 2,
      "embedding": 2,
      "train_features_df[features_c]": 2,
      "train_set": 2,
      "train_image_df": 2,
      "x_embed": 2,
      "df[col_list]": 2,
      "X_target": 2,
      "nm_X_v7": 2,
      "X_trainNorm2": 2,
      "Vxxx_plot_train": 2,
      "Vxxx_plot_test": 2,
      "df[['temp', 'atemp']]": 2,
      "ga_list.transpose()": 2,
      "al_list.transpose()": 2,
      "o_list.transpose()": 2,
      "in_list.transpose()": 2,
      "train[train.columns[:-1]]": 2,
      "nan_features": 2,
      "df_train[min_max_cols]": 2,
      "Xtrain": 2,
      "X_ros": 2,
      "data[['bone_length', 'rotting_flesh', 'hair_length', 'has_soul']]": 2,
      "normalize(X_train[flist], axis=0)": 2,
      "data_train": 2,
      "df[features].values": 2,
      "pd.concat((train_features_1[gene], test_features_1[gene])).values": 2,
      "pd.concat((train_features_1[cell], test_features_1[cell])).values": 2,
      "arr.T": 2,
      "train_features": 2,
      "df_num": 2,
      "avec": 2,
      "clusterDistributionHourOfYear": 2,
      "train[num_id_colmns]": 2,
      "test[num_id_colmns]": 2,
      "market": 2,
      "scaled_X": 2,
      "wrongdata": 2,
      "df_all": 2,
      "g_datas[GENES]": 2,
      "e__": 2,
      "train[kolom]": 2,
      "train_trn[vcols].fillna(-1)": 2,
      "df[genes]": 2,
      "df[cells]": 2,
      "pca_x": 2,
      "x_valid": 2,
      "df_train_quant": 2,
      "df_test_quant": 2,
      "coeff": 2,
      "X.toarray()": 2,
      "clean": 2,
      "vectors_train": 2,
      "train_df.drop(['y'], axis=1)": 2,
      "X_train[:, gfeatures]": 2,
      "X_train[:, cfeatures]": 2,
      "standardized_train": 2,
      "preds": 2,
      "data_all_tab[GENES]": 2,
      "data_all_tab[CELLS]": 2,
      "datapoints_sub": 2,
      "transformation_model[:100]": 2,
      "train_X": 2,
      "X_imb_tomek": 2,
      "X_imb_cc": 2,
      "X_imb_nn": 2,
      "X_imb_smote": 2,
      "X_imb_adasyn": 2,
      "X_imb_smotetomek": 2,
      "X_imb_smoteenn": 2,
      "ss.fit_transform(df)": 2,
      "X_trn": 1,
      "scalar_targets": 1,
      "W": 1,
      "dest_df.iloc[:, 1:]": 1,
      "embedding_df.filter(regex='\\\\d')": 1,
      "cosine_distance": 1,
      "train_images_set": 1,
      "pd.concat((train_ohe[g_columns], test_ohe[g_columns])).values": 1,
      "pd.concat((train_ohe[c_columns], test_ohe[c_columns])).values": 1,
      "filtered": 1,
      "Xenc": 1,
      "np.concatenate([X, y], axis=1)": 1,
      "train[feature_list]": 1,
      "fpMtx": 1,
      "features_scaled": 1,
      "my_list.transpose()": 1,
      "generated_raw_data": 1,
      "generated_raw_cat_data": 1,
      "df_g": 1,
      "df_c": 1,
      "features.values": 1,
      "spectrum_std_df.values": 1,
      "df1": 1,
      "normalize(X_Tr[flist], axis=0)": 1,
      "munged_train_df": 1,
      "image_set": 1,
      "x1": 1,
      "X_test_norm": 1,
      "X_resampled": 1,
      "pred": 1,
      "X_cell_v": 1,
      "X_train_gene.reshape(X_train_gene.shape[:-1])": 1,
      "X_train_cell.reshape(X_train_cell.shape[:-1])": 1,
      "X_train.flatten()": 1,
      "train_nums_std": 1,
      "temp.values": 1,
      "temp.T.values": 1,
      "cell_data": 1,
      "data[col]": 1,
      "scaled_features": 1,
      "temp_df": 1,
      "temp_df[d_cols]": 1,
      "diff_dcols_df[_d_cols].fillna(99999)": 1,
      "temp_df[v_cols]": 1,
      "temp_df[id_cols_1]": 1,
      "merged_data": 1,
      "df[g_cols]": 1,
      "df[c_cols]": 1,
      "traindata_normalized": 1,
      "tr1_X": 1,
      "trainN.values": 1,
      "df_pca": 1,
      "xtr": 1,
      "xvl": 1,
      "pivoted": 1,
      "train_features[genes]": 1,
      "train_features[cells]": 1,
      "X_train_tfidf_pd": 1,
      "Xdr": 1,
      "all_data[['temp', 'atemp']]": 1,
      "df[['pickup_latitude', 'pickup_longitude']]": 1,
      "df[['dropoff_latitude', 'dropoff_longitude']]": 1,
      "data_X_train": 1,
      "resize_train": 1,
      "data_X_test": 1,
      "resize_test": 1,
      "X_data": 1,
      "solutions_set_scaled": 1,
      "columns": 1,
      "data_g": 1,
      "data_c": 1,
      "comb3.drop(['ID', 'y', 'Src'], 1)": 1,
      "data[genes]": 1,
      "data[cells]": 1,
      "train_X[col]": 1,
      "train_df_sd": 1,
      "train.values": 1,
      "encoded_train": 1,
      "ds": 1,
      "StandardScaler().fit_transform(temp)": 1,
      "audio": 1,
      "normalize(data_to_cluster.values, axis=0)": 1,
      "columns_std": 1,
      "pcadf": 1,
      "data_scaler": 1,
      "rescaledX": 1,
      "X_flat": 1,
      "concatenated_df[g_features]": 1,
      "concatenated_df[c_features]": 1,
      "united[GENES]": 1,
      "united[CELLS]": 1,
      "data_train.iloc[:, 1:-1]": 1,
      "df_train_scaled": 1,
      "df_test": 1,
      "sc.fit_transform(all_data[vValues].fillna(-1))": 1,
      "Xx.iloc[:, 0:14]": 1,
      "sampled_data.iloc[:, 2:]": 1,
      "x_pca_train": 1,
      "df_train_data": 1,
      "total_scaled.values": 1,
      "data_genes": 1,
      "data_cells": 1,
      "X_org": 1,
      "X_plot": 1,
      "data[columns]": 1,
      "data[gene_expression]": 1,
      "data[cell_viability]": 1,
      "sc.fit_transform(all_data[_vcols].fillna(-1))": 1,
      "array_train": 1,
      "embedding_matrix": 1,
      "X[g_features_train + c_features_train]": 1,
      "dataset_val": 1,
      "train_data_numerical": 1,
      "X_test_new": 1,
      "train_features.iloc[:, 4:776]": 1,
      "train_features.iloc[:, 777:876]": 1,
      "X_n": 1,
      "all_df": 1,
      "all_df[features]": 1,
      "house_train": 1,
      "dataset": 1,
      "train_feat_scale": 1,
      "train_feat_g": 1,
      "train_feat_c": 1,
      "bow_vectors.todense()": 1,
      "tfidf_vectors.todense()": 1,
      "X_predict": 1,
      "X_pca": 1,
      "X_sm": 1,
      "full_extracted_features": 1,
      "X_tot": 1,
      "sentence_vectors": 1,
      "sentence_vectors[qids_to_fit_tsne]": 1,
      "sort_seq": 1,
      "raw_features": 1,
      "spar_f": 1,
      "sum_sparse": 1,
      "training_data[cells].values": 1,
      "training_data[genes].values": 1,
      "categoricas_dummies.drop('SK_ID_PREV', axis=1)": 1,
      "states.cpu().reshape(-1, 192).numpy()": 1,
      "data[G_COLS].values": 1,
      "data[C_COLS].values": 1,
      "data_pca": 1,
      "sclr.fit_transform(train_df[raw_cols])": 1,
      "sclr.fit_transform(data_dict['test'][raw_cols])": 1,
      "comp_df[p_name]": 1,
      "X.T": 1,
      "train[pca_features]": 1,
      "df.iloc[:, 3:470]": 1,
      "dfSatander": 1,
      "coord": 1,
      "scaler.fit_transform(dfn.values)": 1,
      "vecs_tr": 1,
      "vec_df.values": 1,
      "Xtrain_r": 1,
      "standardized_train.set_index(['ID_code', 'target'])": 1,
      "standardized_test.set_index(['ID_code'])": 1,
      "df_cluster": 1,
      "embeddings_df.values": 1,
      "g_data": 1,
      "c_data[c_features]": 1,
      "scaledums": 1,
      "all_data": 1,
      "df_full[p_name]": 1,
      "vec_arr": 1,
      "pca_temp": 1,
      "pca_temp_cat": 1,
      "train_no_y": 1,
      "bin_df_std": 1,
      "bin_df_std2": 1,
      "vector": 1,
      "temp": 1,
      "st_cluster_data": 1,
      "data_train.drop('target', axis=1)": 1,
      "previous_ngc_direct.fillna(0)": 1,
      "previous_nsi_direct.fillna(0)": 1,
      "df_train_features_scaled": 1,
      "ecdf_normalized_df": 1,
      "data_gene[GENES]": 1,
      "data_cell[CELLS]": 1,
      "data_train_fn": 1,
      "X_train_": 1,
      "img_feats": 1,
      "train_df[resp]": 1,
      "train_sc": 1,
      "x_tr": 1,
      "x_ts": 1,
      "payment": 1,
      "x_train_std": 1,
      "std_data": 1,
      "to_pca": 1,
      "test_features": 1,
      "z_df": 1,
      "X5": 1,
      "df.loc[(df['128'] == video) & (df.label == 'FAKE')][np.arange(0, 128).astype(str)]": 1,
      "df.loc[(df['128'] == real_video) & (df.label == 'REAL')][np.arange(0, 128).astype(str)]": 1,
      "np.concatenate((vectorizer.fit_transform(train['name']).toarray(), vectorizer.fit_transform(train['item_description']).toarray(), vectorizer.fit_transform(train['name']).toarray(), enc.fit_transform(train[['brand_name', 'category_name_1', 'category_name_2', 'shipping', 'item_condition_id']].values).toarray()), axis=1)": 1,
      "train2": 1,
      "sc.fit_transform(train_test[v_group].fillna(-1))": 1,
      "matr": 1,
      "x_scale": 1,
      "X.values": 1,
      "x_base": 1,
      "x_emb": 1,
      "X_train2": 1,
      "X_train3": 1,
      "X_test0": 1,
      "X_test1": 1,
      "X_test2": 1,
      "X_test3": 1,
      "dummy": 1,
      "dummy_t": 1,
      "df_train_": 1,
      "df_test_": 1,
      "x_raw": 1,
      "x_scaled": 1,
      "ndf[featcols].values": 1,
      "nndf[featcols[:-2]].values": 1,
      "normalize(nn[ft].values)": 1,
      "train.loc[:, 'V1':'V321']": 1,
      "test.loc[:, 'V1':'V321']": 1,
      "result[idx]": 1,
      "X_train[X_train.columns[4:-2]]": 1,
      "scaled_X_test": 1,
      "numpyMatrix": 1,
      "tsne_preprocessor.transform(X)": 1,
      "test_set": 1,
      "X_transform": 1,
      "x_train1": 1,
      "non_cor_train_df.drop(['y'], axis=1)": 1,
      "non_cor_train_df.drop(['y', 'ID'], axis=1)": 1,
      "train.drop(['sig_id', 'cp_type', 'cp_time', 'cp_dose'], axis=1)": 1,
      "test.drop(['sig_id'], axis=1)": 1,
      "fnc": 1,
      "X_train_pca": 1,
      "X_filt_scale": 1,
      "X_iso_train": 1,
      "X_feature_extraction": 1,
      "df_encoded": 1,
      "df.drop(['y'], axis=1)": 1,
      "X_ss": 1,
      "test_ss": 1,
      "x_subset": 1,
      "df[v_columns]": 1,
      "X_Train": 1,
      "X_Test": 1,
      "StandardScaler().fit_transform(train.loc[:, cols_pca])": 1,
      "train[train.columns[train.columns.str.contains('feature')]].dropna()": 1,
      "keyvectors": 1,
      "xtrain.append(test)": 1,
      "X_train[kolom]": 1,
      "train_for_decomposition_no_y": 1,
      "test_for_decomposition": 1,
      "immatrix": 1,
      "train_bwx": 1,
      "Xstd": 1,
      "X_train_sca": 1,
      "df[PCA_V_Columns]": 1,
      "train.iloc[:, :879]": 1,
      "process_df": 1,
      "trPCA": 1,
      "train.drop([target_col], axis=1)": 1,
      "X_standard_scaled_df": 1,
      "test_standard_scaled_df": 1,
      "ing_vectors": 1,
      "X_test_scaled": 1,
      "splitTrain": 1,
      "output_descriptor": 1,
      "mat": 1,
      "coeff[:, :, 1].T": 1,
      "X_gene_cell": 1,
      "X_gene": 1,
      "X_cell": 1,
      "X_sca_train": 1,
      "xtrain": 1,
      "Xnorm": 1,
      "Xtestnorm": 1,
      "X_train_smote": 1,
      "data[c]": 1,
      "data[g]": 1,
      "ALL": 1,
      "cont_features": 1,
      "sparse_category_features": 1,
      "Xtr_scaled": 1,
      "molecules[feats].values": 1,
      "df_train.loc[:, df_train.columns != 'output'].values": 1,
      "df_test.loc[:, df_test.columns != 'output'].values": 1,
      "train_scans.loc[:, '0':'7395']": 1,
      "test_scans.loc[:, '0':'7395']": 1,
      "train.drop('Cover_Type', axis=1)": 1,
      "normalize(train[col])": 1,
      "train.drop('SalePrice', axis=1)": 1,
      "model_train_data": 1,
      "f": 1,
      "scale(X1)": 1,
      "scale(X_train)": 1,
      "X_sc": 1,
      "test_sc": 1,
      "scaled_df": 1,
      "train_prepared": 1,
      "test_prepared": 1,
      "complete_features[features]": 1,
      "pd.concat((train_features[g_features], test_features[g_features])).values": 1,
      "pd.concat((train_features[c_features], test_features[c_features])).values": 1,
      "df[oth_price]": 1,
      "feat_g": 1,
      "feat_c": 1,
      "dist_mat": 1,
      "sm_data": 1,
      "aug_data[feature_set]": 1,
      "train_df[v_feat]": 1,
      "test_df[v_test_feat]": 1,
      "np.array(df_int.values)": 1,
      "df_int": 1,
      "pd.concat([X_genes, X_test_genes])": 1,
      "pd.concat([X_cells, X_test_cells])": 1,
      "X_train[aa.columns]": 1,
      "df1.drop(['y', 'ID'], axis=1)": 1,
      "all_features[cols]": 1,
      "tags_df.values": 1,
      "df[train_columns]": 1,
      "combined_data": 1,
      "scld_train_features": 1,
      "train_images_features_df": 1,
      "X_train.values": 1,
      "train_no_NaN": 1,
      "train_transformed": 1,
      "test_tranformed": 1,
      "x_develop[g_cols]": 1,
      "x_develop[c_cols]": 1,
      "train[colunm]": 1,
      "x_data": 1,
      "vw_sub": 1,
      "min_max_X_train": 1,
      "TRAIN": 1,
      "qestn_tagsmap_ohe": 1,
      "cor_table": 1,
      "comb_comps": 1,
      "train_X_prep": 1,
      "df[['air_temperature', 'cloud_coverage', 'precip_depth_1_hr', 'wind_speed', 'wind_direction', 'tem_diff']]": 1,
      "train_n": 1,
      "TRAIN_CELL": 1,
      "norm_train": 1,
      "test2": 1,
      "X_scl": 1,
      "encoded_features": 1,
      "X[i].reshape((28, 28))": 1,
      "Test_x": 1,
      "df_wv_new": 1,
      "train_": 1,
      "resp": 1,
      "train_features_scaled[~np.isnan(train_features_scaled).any(axis=1)]": 1,
      "train_wo_mc": 1,
      "train_pca[features]": 1,
      "train[['atemp', 'temp']]": 1,
      "ss.fit_transform(x)": 1,
      "train_features[cl_g]": 1,
      "train_features[cl_c]": 1,
      "test_features[cl_c]": 1,
      "train[cols]": 1,
      "numeric_train_df": 1,
      "scaledTrain": 1,
      "scaledTrainNoF0": 1,
      "X_all_sc": 1,
      "sales_pca": 1,
      "features_std": 1
    },
    "sklearn.mixture._gaussian_mixture.GaussianMixture.aic.X": {
      "x_all": 9,
      "X": 6,
      "X_cell_v": 1,
      "X_gene_e_red": 1,
      "all_train": 1
    },
    "sklearn.linear_model._base.LinearRegression.__init__.fit_intercept": {
      "True": 2795,
      "False": 184,
      "best['fit_intercept']": 2,
      "bool_fit_intercept": 1,
      "fit_intercept": 1,
      "line_grid.best_params_['fit_intercept']": 1
    },
    "sklearn.linear_model._base.LinearRegression.__init__.n_jobs": {
      "None": 2786,
      "-1": 176,
      "4": 11,
      "1": 5,
      "8": 3,
      "6": 1,
      "1000": 1,
      "10": 1
    },
    "sklearn.metrics._classification.accuracy_score.normalize": {
      "True": 7120,
      "False": 7
    },
    "sklearn.tree._classes.DecisionTreeRegressor.__init__.criterion": {
      "'mse'": 874,
      "'friedman_mse'": 12,
      "'mae'": 9,
      "criterion": 1
    },
    "sklearn.tree._classes.DecisionTreeRegressor.__init__.min_impurity_decrease": {
      "0.0": 889,
      "0.002": 3,
      "0.05": 2,
      "0.001": 1,
      "0.1": 1
    },
    "sklearn.tree._export.plot_tree.feature_names": {
      "None": 12,
      "X_train.columns": 6,
      "features": 3,
      "our_features": 2,
      "X.columns": 2,
      "to.x_names": 2,
      "var_columns": 2,
      "train.drop('Survived', axis=1).columns": 2,
      "labels": 2,
      "names": 1,
      "train.columns": 1,
      "train_X.columns": 1,
      "x_ls": 1,
      "fn": 1,
      "lables": 1,
      "transformed_cols": 1,
      "['country_avg_score', 'city']": 1,
      "feat": 1
    },
    "sklearn.tree._export.plot_tree.filled": {
      "True": 34,
      "False": 8
    },
    "sklearn.tree._export.plot_tree.decision_tree": {
      "tree": 5,
      "clf": 4,
      "dt": 3,
      "model": 3,
      "dtmodel": 3,
      "m": 2,
      "model_tree": 2,
      "dtree": 2,
      "decision_tree_model": 2,
      "clf.estimators_[2]": 1,
      "rf_cls.estimators_[0]": 1,
      "dec_tree_model": 1,
      "decisiontree": 1,
      "dr_classifier": 1,
      "modelo_arvore": 1,
      "RF.estimators_[0]": 1,
      "clf_dt": 1,
      "clf_dt_prune": 1,
      "dtc": 1,
      "ensemble_model": 1,
      "rfclf.estimators_[0]": 1,
      "decision_tree_prune": 1,
      "best_estimator.named_steps['decisiontreeclassifier']": 1,
      "tree_model": 1,
      "clf.estimators_[0][0]": 1
    },
    "sklearn.svm._classes.SVR.__init__.kernel": {
      "'rbf'": 378,
      "'linear'": 48,
      "'poly'": 23,
      "kernel": 14,
      "'precomputed'": 2,
      "result.best_params_['kernel']": 1,
      "kernel_use": 1,
      "best_settings['kernel']": 1,
      "'sigmoid'": 1,
      "trial.suggest_categorical('kernel', svr_kernels)": 1,
      "args['kernel']": 1
    },
    "sklearn.svm._classes.SVR.__init__.C": {
      "1.0": 315,
      "C": 30,
      "20": 18,
      "100": 16,
      "1": 12,
      "10": 10,
      "0.1": 5,
      "1000000": 4,
      "2": 4,
      "1000.0": 3,
      "1000": 3,
      "0.5": 3,
      "0.01": 2,
      "0.7682824405204463": 2,
      "c": 2,
      "5": 2,
      "50": 2,
      "0.75": 2,
      "c_value": 2,
      "0.001": 1,
      "result.best_params_['C']": 1,
      "3.0": 1,
      "i": 1,
      "best_C": 1,
      "25": 1,
      "0.23086859625727427": 1,
      "8": 1,
      "1.4": 1,
      "best_settings['C']": 1,
      "1.5": 1,
      "_C": 1,
      "1.5959075672900394": 1,
      "21": 1,
      "8.0": 1,
      "2.8": 1,
      "0.3146360056513227": 1,
      "80.0": 1,
      "10.0": 1,
      "300": 1,
      "trial.suggest_uniform('C', 0.5, 10)": 1,
      "parameter[0]": 1,
      "80000": 1,
      "10000.0": 1,
      "optpars['sbm+funcdeweighted_win_svr'][target]": 1,
      "46": 1,
      "5.0": 1,
      "20.0": 1,
      "gridsearch.best_params_['C']": 1,
      "math.pow(2, log2C)": 1,
      "math.pow(2, C)": 1,
      "15.0": 1,
      "0.6": 1,
      "70.8461395955645": 1
    },
    "sklearn.svm._classes.SVR.__init__.gamma": {
      "'scale'": 370,
      "'auto'": 31,
      "0.0003": 16,
      "0.1": 13,
      "0.001": 6,
      "0.0": 5,
      "0.005": 3,
      "0.0042151786393578635": 2,
      "1": 2,
      "gamma_value": 2,
      "0.01": 2,
      "gamma": 2,
      "0.00015": 1,
      "0.0004": 1,
      "0.007": 1,
      "best_settings['gamma']": 1,
      "1e-07": 1,
      "0.00017": 1,
      "0.0011": 1,
      "0.00043333333333333337": 1,
      "100": 1,
      "0.5": 1,
      "0.0003434802243340735": 1,
      "0.0001": 1,
      "0.00035": 1,
      "math.pow(2, log2gamma)": 1,
      "math.pow(2, gamma)": 1,
      "0.02": 1,
      "0.0024348987081239675": 1
    },
    "sklearn.svm._classes.SVR.__init__.epsilon": {
      "0.1": 395,
      "0.008": 17,
      "0.2": 15,
      "0.05": 9,
      "0.001": 4,
      "0.0001": 4,
      "0.01": 3,
      "epsilon": 3,
      "0.6": 2,
      "5.0": 2,
      "1.5": 2,
      "0.006673842511350357": 1,
      "best_settings['epsilon']": 1,
      "_epsilon": 1,
      "1.1567830632624725": 1,
      "0.0099": 1,
      "0.010198286623541677": 1,
      "0.5": 1,
      "1e-08": 1,
      "trial.suggest_uniform('epsilon', 0.01, 1)": 1,
      "0.009019504329938493": 1,
      "0.005": 1,
      "1": 1,
      "0.006": 1,
      "gridsearch.best_params_['epsilon']": 1,
      "0.023807407289868687": 1
    },
    "sklearn.svm._classes.SVR.__init__.degree": {
      "3": 454,
      "2": 9,
      "4": 2,
      "result.best_params_['degree']": 1,
      "10": 1,
      "9": 1,
      "1": 1,
      "trial.suggest_int('degree', 2, 5)": 1,
      "8": 1
    },
    "sklearn.svm._classes.SVR.__init__.coef0": {
      "0.0": 460,
      "0.0001": 4,
      "1": 3,
      "0.8994782389230459": 1,
      "0": 1,
      "0.4841022473611773": 1,
      "0.9829844203739042": 1
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.n_estimators": {
      "100": 547,
      "200": 49,
      "50": 41,
      "1000": 29,
      "300": 25,
      "20": 23,
      "500": 22,
      "10": 20,
      "30": 14,
      "250": 10,
      "80": 6,
      "n_estimators": 5,
      "150": 5,
      "400": 5,
      "c - 1": 5,
      "90": 5,
      "40": 4,
      "489": 4,
      "120": 3,
      "5": 3,
      "5000": 3,
      "600": 3,
      "2000": 2,
      "estimator": 2,
      "70": 2,
      "95": 2,
      "3000": 2,
      "32": 2,
      "8000": 2,
      "25": 1,
      "35": 1,
      "search.best_params_['n_estimators']": 1,
      "n_estimator": 1,
      "190": 1,
      "nTrees": 1,
      "1500": 1,
      "700": 1,
      "best_n_estimator": 1,
      "180": 1,
      "num_trees": 1,
      "41": 1,
      "params['n_estimators']": 1,
      "int(e)": 1,
      "9500": 1,
      "800": 1,
      "best_params[2]": 1,
      "trial.suggest_int('n_estimators', 10, 1000)": 1,
      "377": 1,
      "best_n": 1
    },
    "sklearn.ensemble._stacking.StackingClassifier.__init__.estimators": {
      "estimators": 28,
      "level0": 4,
      "stacking_estimators": 3,
      "[('model0', model0), ('model1', model1), ('model2', model2), ('model3', model3), ('model4', model4), ('model5', model5)]": 2,
      "estimator_list": 2,
      "base_learners": 2,
      "est": 1,
      "1000": 1,
      "estimators + [('svm', model_sgd_hinge)]": 1,
      "[('svc', svc), ('lr', lr), ('xgb', xgb), ('d_tree', tree), ('ada', ada), ('gb', gb), ('etc', etc)]": 1,
      "[myclf1, myclf2, myclf3]": 1,
      "step0": 1,
      "models": 1
    },
    "sklearn.ensemble._stacking.StackingClassifier.__init__.final_estimator": {
      "None": 7,
      "LogisticRegression()": 5,
      "level1": 4,
      "XGBClassifier(n_estimators=10, n_jobs=-1)": 2,
      "LinearSVC(C=0.1, random_state=42)": 2,
      "LogisticRegression(max_iter=300)": 2,
      "my_final_estimator": 2,
      "LGBMClassifier()": 2,
      "final_estimator": 2,
      "MLPClassifier(hidden_layer_sizes=hid_lay_siz, random_state=0)": 1,
      "MLPClassifier(hidden_layer_sizes=best_l, random_state=0)": 1,
      "model_kn": 1,
      "LogisticRegression(C=1, random_state=42, solver='newton-cg')": 1,
      "RandomForestClassifier(random_state=42, n_jobs=4)": 1,
      "LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial', max_iter=3000)": 1,
      "RandomForest()": 1,
      "model_lr": 1,
      "make_pipeline(QuantileTransformer(**params_quantile_final), KNeighborsClassifier(**params_knn))": 1,
      "final": 1,
      "LogisticRegression(C=0.09, max_iter=150, random_state=65, solver='liblinear', n_jobs=-1)": 1,
      "XGBClassifier()": 1,
      "log_reg_quantile": 1,
      "LogisticRegression(C=C_lr, random_state=42)": 1,
      "LogisticRegression(C=res.x[1], random_state=42)": 1,
      "mylr": 1,
      "step1": 1,
      "XGBClassifier(n_estimators=15, n_jobs=-1, random_state=0)": 1,
      "rfclf": 1,
      "LogisticRegression(C=0.5, max_iter=75)": 1
    },
    "sklearn.ensemble._stacking.StackingClassifier.__init__.cv": {
      "None": 34,
      "5": 4,
      "3": 2,
      "4": 2,
      "KFold(n_splits=5, shuffle=True, random_state=42)": 2,
      "sk_fold": 1,
      "outer_cv": 1,
      "cv": 1,
      "2": 1
    },
    "sklearn.ensemble._stacking.StackingClassifier.__init__.passthrough": {
      "False": 45,
      "pass_throu": 1,
      "best_pt": 1,
      "True": 1
    },
    "sklearn.ensemble._stacking.StackingClassifier.fit.X": {
      "X_train": 12,
      "x_train": 6,
      "X": 3,
      "feat": 2,
      "x_train_sub_norm": 2,
      "train_text_vect": 2,
      "X_train_transformed": 1,
      "X_transformed": 1,
      "X_learn": 1,
      "X_train_std": 1,
      "X.loc[trn_idx, :]": 1,
      "X_train_res": 1,
      "X2f": 1,
      "np.vstack((x_train_sub_norm, x_val_norm))": 1,
      "X_train_vec": 1,
      "X_tr": 1,
      "np.asarray(x_train.to_list())": 1,
      "np.asarray(final_train_embedding['text'].to_list())": 1,
      "feats": 1
    },
    "sklearn.ensemble._stacking.StackingClassifier.fit.y": {
      "y_train": 22,
      "target": 2,
      "y_train_sub": 2,
      "y": 2,
      "y_train_transformed": 1,
      "y_transformed": 1,
      "y_learn": 1,
      "df_train['target']": 1,
      "y.loc[trn_idx]": 1,
      "y_train_res": 1,
      "yf": 1,
      "pd.concat([y_train_sub, y_val])": 1,
      "y_ref_train": 1,
      "y_tr": 1,
      "final_train_embedding['target']": 1,
      "targets": 1
    },
    "sklearn.ensemble._stacking.StackingClassifier.predict.X": {
      "X_test": 7,
      "X_train": 4,
      "x_test": 3,
      "df_test": 2,
      "feat": 2,
      "test": 2,
      "x_val": 1,
      "X_test_std": 1,
      "X_val_std": 1,
      "X": 1,
      "test_Scaled": 1,
      "test3": 1,
      "X_ref_test_vec": 1,
      "X_test_vec": 1,
      "test_text_vect": 1,
      "X_val": 1,
      "X_test_copy": 1,
      "np.asarray(x_test.to_list())": 1,
      "np.asarray(test_embedding_df['text'].to_list())": 1,
      "null": 1
    },
    "sklearn.model_selection._split.ShuffleSplit.__init__.n_splits": {
      "1": 149,
      "10": 42,
      "5": 29,
      "3": 16,
      "4": 14,
      "50": 8,
      "100": 6,
      "11": 3,
      "2": 2,
      "20": 2,
      "30": 2,
      "7": 2,
      "6": 1,
      "n_folds": 1,
      "15": 1,
      "n_splits": 1
    },
    "sklearn.model_selection._split.ShuffleSplit.__init__.test_size": {
      "0.2": 60,
      "None": 60,
      "0.15 / 0.85": 34,
      "0.1": 23,
      "0.3": 21,
      "holdout_frac": 20,
      "0.15": 16,
      "0.25": 11,
      "0.01": 6,
      "0.05": 5,
      "test_size": 3,
      "0.12": 3,
      "400": 3,
      "0.6": 2,
      "0.5": 2,
      "0.4": 2,
      "0.7": 1,
      "0.99": 1,
      "0.8": 1,
      "0.35": 1,
      "0.19": 1,
      "0.33": 1,
      "0.0": 1,
      "0.02": 1
    },
    "sklearn.model_selection._split.ShuffleSplit.__init__.train_size": {
      "None": 191,
      "0.8": 21,
      "train_size": 20,
      "0.9": 12,
      "0.1": 7,
      "0.6": 7,
      "0.02": 4,
      "0.25": 4,
      "0.3": 2,
      "0.4": 2,
      "0.12": 2,
      "0.2": 2,
      "0.7": 2,
      "0.5": 2,
      "0.75": 1
    },
    "sklearn.linear_model._ridge.Ridge.__init__.fit_intercept": {
      "True": 1131,
      "False": 86,
      "intercept": 2,
      "ridge_regressor.best_params_['fit_intercept']": 1,
      "fit_intercept_dict[fit_intercept]": 1,
      "params['fit_intercept']": 1,
      "self.params['fit_intercept']": 1,
      "'True'": 1,
      "trial.suggest_categorical('fit_intercept', [True, False])": 1
    },
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.min_df": {
      "1": 2243,
      "3": 323,
      "5": 216,
      "2": 172,
      "10": 77,
      "0": 41,
      "0.0": 13,
      "100": 12,
      "0.01": 12,
      "9e-05": 10,
      "min_df": 10,
      "150": 9,
      "20": 9,
      "4": 7,
      "0.001": 6,
      "200": 6,
      "50": 6,
      "15": 4,
      "0.2": 4,
      "self.min_df": 3,
      "30": 3,
      "np.int(min_df * texts.shape[0])": 2,
      "0.005": 2,
      "0.1": 2,
      "0.05": 2,
      "MIN_DOCUMENT_FREQUENCY": 2,
      "7": 2,
      "25": 1,
      "9": 1,
      "1e-07": 1,
      "0.009": 1,
      "noOfocurance": 1,
      "23": 1,
      "0.15": 1,
      "model_question.vocabulary.min_count": 1,
      "0.0005": 1,
      "6": 1,
      "0.0001": 1,
      "MIN_DF_TF": 1,
      "NAME_MIN_DF": 1,
      "0.0025": 1,
      "min_df_opt": 1,
      "self.tfidf_min_df": 1,
      "mindf": 1
    },
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.max_features": {
      "None": 2137,
      "10000": 114,
      "50000": 104,
      "100000": 71,
      "5000": 66,
      "1000": 60,
      "30000": 50,
      "20000": 43,
      "MAX_FEATURES_ITEM_DESCRIPTION": 42,
      "max_features": 27,
      "2000": 25,
      "MAX_FEAT_DESCP": 24,
      "100": 20,
      "200000": 19,
      "17000": 19,
      "500": 17,
      "60000": 15,
      "15000": 14,
      "feature_cnt": 14,
      "8000": 13,
      "2500": 12,
      "80000": 11,
      "256": 11,
      "N": 11,
      "300": 10,
      "feature_count": 10,
      "180000": 9,
      "25000": 9,
      "16000": 9,
      "55000": 8,
      "250000": 7,
      "n_features[c_i]": 6,
      "dimension": 6,
      "50": 6,
      "40000": 6,
      "limit_word": 6,
      "limit_char": 6,
      "1500": 5,
      "450": 5,
      "500000": 5,
      "18000": 5,
      "4000": 4,
      "300000": 4,
      "9000": 4,
      "200": 4,
      "5500": 4,
      "150": 4,
      "max_vec_features": 4,
      "maxFeats": 3,
      "MAX_FEATURES_ITEM_DESCR": 3,
      "n_features": 3,
      "tfidf_max_features": 3,
      "3500": 3,
      "5": 3,
      "24939": 3,
      "35000": 3,
      "3000": 2,
      "660000": 2,
      "2048": 2,
      "MAX_FEATURES": 2,
      "10": 2,
      "max_feat": 2,
      "20": 2,
      "num_features": 2,
      "td": 2,
      "90000": 2,
      "6000": 2,
      "vocab_size": 2,
      "no_features": 2,
      "1600": 2,
      "12000": 2,
      "6500": 2,
      "150000": 2,
      "11000": 2,
      "3000000": 2,
      "6706": 2,
      "7000": 2,
      "23000": 2,
      "13000": 1,
      "49748": 1,
      "MAX_FEATURES_NAME": 1,
      "MAX_FEATURES_DESC": 1,
      "32000": 1,
      "features": 1,
      "size_tfidf": 1,
      "800000": 1,
      "45000": 1,
      "700000": 1,
      "MAX_FEATURES_NM": 1,
      "5004": 1,
      "max_vocab": 1,
      "tfidf_features": 1,
      "vocab_sz": 1,
      "MAX_TF_IDF": 1,
      "nfeats": 1,
      "n_words": 1,
      "75000": 1,
      "36000": 1,
      "60": 1,
      "DICT_SIZE": 1,
      "maxfeats": 1,
      "max_item_description_features": 1,
      "_max_features": 1,
      "description_max_features": 1,
      "MAX_NB_WORDS": 1,
      "self.max_features": 1,
      "13460": 1,
      "self.num_words": 1,
      "8200": 1,
      "12500": 1,
      "MAX_FEATURES_TF": 1,
      "m1": 1,
      "m2": 1,
      "m3": 1,
      "2400": 1,
      "max_features_Vectorizer": 1,
      "max_features_": 1,
      "FEATURE_TEXTS_DIM": 1,
      "max_features_opt": 1,
      "12970": 1,
      "70000": 1,
      "4500": 1,
      "max_feature": 1,
      "7500": 1,
      "MAX_LEN": 1,
      "nb_features": 1,
      "600": 1,
      "maxx_features": 1,
      "f_n": 1,
      "n_word_bins": 1,
      "31000": 1,
      "maxNumFeatures": 1,
      "3400": 1,
      "2**15": 1,
      "1000000": 1,
      "450000": 1,
      "NR_MAX_TEXT_FEATURES": 1,
      "self.tfidf_max_features": 1,
      "maxfeat": 1,
      "project_tfidf_features": 1
    },
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.strip_accents": {
      "None": 2421,
      "'unicode'": 773,
      "'ascii'": 20,
      "ascii": 1
    },
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.smooth_idf": {
      "True": 2788,
      "1": 349,
      "False": 77,
      "0": 1
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.max_depth": {
      "3": 629,
      "4": 45,
      "5": 33,
      "1": 33,
      "8": 29,
      "7": 15,
      "2": 13,
      "6": 10,
      "10": 7,
      "max_depth": 6,
      "9": 5,
      "15": 4,
      "None": 3,
      "84": 3,
      "90": 3,
      "150": 2,
      "30": 2,
      "int(round(7.18465375161774))": 2,
      "12": 2,
      "20": 2,
      "13": 2,
      "search.best_params_['max_depth']": 1,
      "11": 1,
      "100": 1,
      "int(round(max_depth))": 1,
      "500": 1,
      "best_depth": 1,
      "16": 1,
      "params['max_depth']": 1,
      "int(d)": 1,
      "best_params[8]": 1,
      "trial.suggest_int('max_depth', 2, 10)": 1,
      "31": 1,
      "depth": 1,
      "best_m": 1,
      "50": 1
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.random_state": {
      "None": 521,
      "0": 100,
      "42": 46,
      "1": 42,
      "seed": 34,
      "10": 20,
      "random_state": 18,
      "112": 11,
      "rnd": 6,
      "20190325": 6,
      "123": 5,
      "11": 4,
      "55": 4,
      "random_seed": 4,
      "241": 4,
      "100": 3,
      "3": 3,
      "21": 3,
      "2": 2,
      "22": 2,
      "SEED": 2,
      "40": 2,
      "1729": 2,
      "369": 1,
      "20190301": 1,
      "RANDOM_STATE": 1,
      "817": 1,
      "2016": 1,
      "33": 1,
      "2589": 1,
      "144": 1,
      "432": 1,
      "RS": 1,
      "5039": 1,
      "20199": 1,
      "99": 1,
      "45": 1,
      "111": 1,
      "5": 1,
      "8": 1,
      "self.randomSeed": 1,
      "RANDOM_SEED": 1,
      "50": 1,
      "14": 1
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.predict.X": {
      "X_test": 79,
      "test": 21,
      "x_test": 9,
      "test_feature": 8,
      "X_val": 7,
      "X_train": 6,
      "X_train_sc[selected_features_gb]": 5,
      "X_test_sc[selected_features_gb]": 5,
      "test[feats]": 4,
      "clfX_test": 4,
      "X_valid": 4,
      "test_x": 3,
      "test_merge4": 3,
      "train_merge4": 3,
      "test_features": 3,
      "test_df.drop(['id', 'timestamp'], axis=1)": 3,
      "x_val": 3,
      "df_test": 3,
      "X_submission": 3,
      "val_x": 2,
      "testdata": 2,
      "X_vtest": 2,
      "TestData": 2,
      "test_X": 2,
      "x_train": 2,
      "test1": 2,
      "trainFactors": 2,
      "df2": 2,
      "X_Test_CS": 2,
      "label_X_valid": 2,
      "xtest_tfv": 2,
      "[feats]": 2,
      "week": 1,
      "x_mod_teste": 1,
      "pd.DataFrame(test_features)": 1,
      "X_test2": 1,
      "test[features]": 1,
      "adj_X[adj_features]": 1,
      "test_features.toarray()": 1,
      "test_sel": 1,
      "clfdata_X": 1,
      "X_fin": 1,
      "x_validation": 1,
      "test_count1": 1,
      "prepared_test": 1,
      "test.drop(['PetID'], axis=1)": 1,
      "te_X": 1,
      "dog_X_val": 1,
      "dog_X_train": 1,
      "cat_X_val": 1,
      "test_data": 1,
      "test.drop('PassengerId', axis=1)": 1,
      "feats_exp": 1,
      "trainHFactors": 1,
      "testHousehold": 1,
      "X_test_val": 1,
      "X_grid5": 1,
      "X_test_original": 1,
      "X_val_second_level": 1,
      "test_df[[str(x) for x in range(300)]]": 1,
      "val_": 1,
      "x_test_umap_2": 1,
      "x_test_add_umap2": 1,
      "x_test_umap6": 1,
      "x_test_add_umap6": 1,
      "testdf": 1,
      "test.drop(['Id'], axis=1)": 1,
      "label_test_data": 1,
      "X_test_std": 1,
      "bow_train": 1,
      "bow_test": 1,
      "xvalid_tfv": 1,
      "x_valid": 1,
      "Xdt_test": 1,
      "test[feats2]": 1,
      "X_validation": 1,
      "X_test_new": 1,
      "X_test_reduced": 1,
      "self.x_test": 1,
      "X_test_norm": 1,
      "featuresPredict": 1,
      "test[binarias + discretas]": 1,
      "xvalid_tfidf.tocsc()": 1,
      "xvalid_cv.tocsc()": 1,
      "xvalid_svd": 1,
      "xcvalid_tfv": 1,
      "test_tfv": 1,
      "mr_multi_model_submission_df": 1,
      "not_mr_multi_model_submission_df": 1,
      "train_use": 1,
      "test_std": 1,
      "r_test_std": 1,
      "test_main": 1,
      "predictors_ts": 1,
      "test.values": 1,
      "Xtest": 1,
      "testdeneme": 1,
      "test[numerical_features]": 1,
      "inputTestingData": 1,
      "x_test.values": 1,
      "va_x": 1
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.predict_proba.X": {
      "X_test": 44,
      "X_train": 30,
      "validInputFeature": 13,
      "W": 13,
      "validInputFeatures": 12,
      "test": 9,
      "x_test": 7,
      "X_train_last": 6,
      "trainInputFeature": 5,
      "trainInputFeatures": 5,
      "X_valid": 5,
      "X": 4,
      "X_val": 4,
      "test[features]": 2,
      "cv_feat": 2,
      "train_feat": 2,
      "df": 2,
      "test_x": 2,
      "X_test_last": 2,
      "np.nan_to_num(val_X[val_universe == 1, :])": 2,
      "df_train_naive[cat_cols]": 2,
      "df_test_naive[cat_cols]": 2,
      "Xte": 2,
      "x_mod_teste": 1,
      "pd.DataFrame(test_features)": 1,
      "row": 1,
      "test[features[0:-1]]": 1,
      "lootrain[['group_1', 'activity_category', 'date', 'char_2', 'char_38']]": 1,
      "lootest[['group_1', 'activity_category', 'date', 'char_2', 'char_38']]": 1,
      "test.drop('id', axis=1)": 1,
      "tfeat": 1,
      "all_data[train_size:]": 1,
      "test_d": 1,
      "x_validation": 1,
      "X_tr": 1,
      "X_cr": 1,
      "X_te": 1,
      "X[10000:LINES, :]": 1,
      "np.nan_to_num(X)": 1,
      "train_onehot": 1,
      "test_onehot": 1,
      "df_train_smooth[cat_cols]": 1,
      "df_test_smooth[cat_cols]": 1,
      "df_train_cv[cat_cols]": 1,
      "df_test_cv[cat_cols]": 1,
      "dog_X_val": 1,
      "dog_X_train": 1,
      "cat_X_val": 1,
      "dog_test": 1,
      "cat_test": 1,
      "submission_data.values": 1,
      "test_users_scaled": 1,
      "dtest": 1,
      "test_df[cols]": 1,
      "X_encoded_test": 1,
      "actualIgX": 1,
      "actualEgX": 1,
      "Xtest1": 1,
      "bayes_x_test": 1,
      "test_df": 1,
      "test.drop('shot_id', axis=1)": 1,
      "test_term_doc": 1,
      "xtest": 1,
      "X_test[row, :].toarray()": 1,
      "yet_to_complete[3321:]": 1,
      "x": 1,
      "XT": 1,
      "merge_df_test": 1,
      "test_X": 1,
      "pd.DataFrame(val_x_)": 1,
      "train_x": 1,
      "mytest": 1,
      "va_x": 1
    },
    "sklearn.neighbors._classification.KNeighborsClassifier.__init__.weights": {
      "'uniform'": 1622,
      "'distance'": 108,
      "calculate_distance": 74,
      "weights": 11,
      "weight": 3,
      "wei": 1,
      "w": 1,
      "clf.best_params_['weights']": 1
    },
    "sklearn.neighbors._classification.KNeighborsClassifier.__init__.algorithm": {
      "'auto'": 1773,
      "'ball_tree'": 31,
      "'brute'": 11,
      "algorithm": 3,
      "'kd_tree'": 2,
      "algo": 1
    },
    "sklearn.metrics._regression.explained_variance_score.y_true": {
      "y_test": 25,
      "predictions": 18,
      "y": 9,
      "y_val": 4,
      "y_eval": 4,
      "d_set[3]": 4,
      "predict_dt1": 2,
      "predictions_xg": 2,
      "y_true": 2,
      "Y1": 1,
      "Y2": 1,
      "y_train[:300]": 1,
      "y_pred": 1,
      "y_train": 1,
      "target_train": 1,
      "np.array(np.exp(Y_test) - 1)": 1,
      "y_test_CC": 1,
      "y_test_Fa": 1
    },
    "sklearn.metrics._regression.explained_variance_score.y_pred": {
      "y_pred": 17,
      "y_test1": 10,
      "y_test2": 8,
      "pred": 4,
      "preds": 3,
      "y_pred_lr": 2,
      "y_pred_rf": 2,
      "predict_dt1": 2,
      "test_features.winPlacePerc": 2,
      "y_pred_lgbR": 2,
      "PredTestSet": 1,
      "PredValSet": 1,
      "predictions_train": 1,
      "predictions_test": 1,
      "ypred_clf": 1,
      "y_pred_cat": 1,
      "probs": 1,
      "predict_y": 1,
      "prediction": 1,
      "rf_pred": 1,
      "knn_pred": 1,
      "dt_pred": 1,
      "ypred": 1,
      "y_train_reg": 1,
      "y_test_reg": 1,
      "target_train_predict": 1,
      "y_pred_2": 1,
      "predictions": 1,
      "predict": 1,
      "y_1": 1,
      "y_2": 1,
      "y_pred_lreg": 1,
      "y_pred_dtree": 1,
      "y_pred_rforest": 1,
      "y_test": 1,
      "prediction_CC": 1,
      "prediction_Fa": 1
    },
    "sklearn.preprocessing._data.StandardScaler.inverse_transform.X": {
      "y_train": 15,
      "test_y": 12,
      "y_valid_pred": 10,
      "[model.predict(test_data)[0] for model in models]": 9,
      "y_test": 8,
      "predicted_std": 8,
      "Y_test": 8,
      "predict_test": 7,
      "y_pred.reshape(-1, 1)": 7,
      "data_in": 6,
      "preds": 6,
      "y_pred": 5,
      "reg_cc.predict(poly_reg_cc.fit_transform(test_temp_X))": 4,
      "reg_ft.predict(poly_reg_ft.fit_transform(test_temp_X))": 4,
      "train_temp_cc": 4,
      "train_temp_ft": 4,
      "X_test": 4,
      "np.array(confirmedCases_pred).reshape(313 * 43)": 3,
      "[i[0] for i in np.array(fatalities_pred).reshape(313 * 43, 2)]": 3,
      "predictions": 3,
      "model.predict(test_X)": 3,
      "test_y[-20:]": 3,
      "scaled_preds": 2,
      "rc.predict(qtx.transform(trainpred.loc[trainpred.serd == serd, ['LConfirmedCases', 'LARIMApred']])).reshape(-1, 1)": 2,
      "rc_f.predict(qtx_f.transform(trainpred.loc[trainpred.serd == serd, ['LConfirmedCases', 'LARIMApred', 'LFatalities', 'LFARIMApred', 'LDConfirmedCases', 'LDFatalities']])).reshape(-1, 1)": 2,
      "Predictions": 2,
      "predict": 2,
      "pred": 2,
      "Y_train": 2,
      "x": 2,
      "outs": 2,
      "y_pred1": 1,
      "cross_val_predict(SVR(kernel='rbf', C=10), qtx.transform(df), qty.transform(train.LConfirmedCases[train.serd > 70].values.reshape(-1, 1)), cv=10).reshape(-1, 1)": 1,
      "cross_val_predict(SVR(kernel='rbf', C=1), qtx_f.transform(df), qty_f.transform(train.LFatalities[train.serd > 70].values.reshape(-1, 1)), cv=10).reshape(-1, 1)": 1,
      "pd.DataFrame(test_preds[0].reshape(1, -1)[0])": 1,
      "pred1.reshape(-1, 1)": 1,
      "pred2.reshape(-1, 1)": 1,
      "pred3.reshape(-1, 1)": 1,
      "pred4.reshape(-1, 1)": 1,
      "test_pred.reshape(-1, 1)": 1,
      "results": 1,
      "tt_cc": 1,
      "tt_ft": 1,
      "X_test_soft[worst]": 1,
      "X_test_normal[worst]": 1,
      "X_test_press[worst]": 1,
      "d_train_pred3": 1,
      "d_test['revenue3']": 1,
      "np.reshape(pred_train, (-1, 1))": 1,
      "np.reshape(pred_test, (-1, 1))": 1,
      "np.reshape(pred, (-1, 1))": 1,
      "[model.predict(test_data) for model in models]": 1,
      "train_features": 1,
      "test_features": 1,
      "val_train_features": 1,
      "model.predict(X[i_val])": 1,
      "model.predict(X_tst)": 1,
      "model.predict(Xte)": 1,
      "regressor.predict(X_test)": 1,
      "[model.predict(test_df)[0] for model in models]": 1,
      "test_pred": 1,
      "predicted_c_std": 1,
      "Y_c_test": 1,
      "predicted_f_std": 1,
      "Y_f_test": 1,
      "np.array(c_pred).reshape(region_count * test_date_count)": 1,
      "np.array(f_pred).reshape(region_count * test_date_count)": 1,
      "np.array(confirmedCases_pred).reshape(294 * 43)": 1,
      "[i[0] for i in np.array(fatalities_pred).reshape(294 * 43, 2)]": 1,
      "predicted_std - abs(confirmedCase_std_min)": 1,
      "Y_test - abs(confirmedCase_std_min)": 1,
      "np.array(confirmedCases_pred).reshape(306 * 43) - abs(confirmedCase_std_min)": 1,
      "predicted_std - abs(fatalities_std_min)": 1,
      "Y_test - abs(fatalities_std_min)": 1,
      "X_test - abs(fatalities_std_min)": 1,
      "[i[0] - abs(fatalities_std_min) for i in np.array(fatalities_pred).reshape(306 * 43, 2)]": 1,
      "prediction['target']": 1,
      "predict_2": 1,
      "y_te_pred": 1,
      "pred_valid_all": 1,
      "y_valid": 1,
      "pred_test_all": 1,
      "raw_pred": 1,
      "[model.predict(test)[0] for model in models]": 1,
      "testInput": 1,
      "cluster_centers[2]['cluster_center']": 1,
      "cluster_centers[5]['cluster_center']": 1,
      "cluster_centers[8]['cluster_center']": 1,
      "cluster_centers[i]['cluster_center']": 1,
      "modelC.predict(pfC.fit_transform(X_Test_CS_SS))": 1,
      "modelF.predict(pfF.fit_transform(X_Test_CS_SS))": 1,
      "pls.predict(x_train_valid)": 1,
      "y_train_valid_scaled": 1,
      "estimator.predict(x_train_valid)": 1,
      "estimator.predict(x_test_scaled)": 1,
      "model.predict(train_X)": 1,
      "train_y": 1,
      "train_y[-20:]": 1,
      "y_test['Hazard'].values": 1,
      "y_train['Hazard'].values": 1,
      "y_val_pred": 1,
      "[model.predict(test_data.reshape(1, -1))[0] for model in models]": 1,
      "points_pca": 1,
      "previsoes": 1,
      "lr.predict(x_train.toarray())": 1,
      "lr.predict(x_test.toarray())": 1,
      "lr_ridge.predict(x_train.toarray())": 1,
      "lr_ridge.predict(x_test.toarray())": 1,
      "lr_lasso.predict(x_train.toarray())": 1,
      "lr_lasso.predict(x_test.toarray())": 1,
      "gbr_cv.predict(x_train.toarray())": 1,
      "gbr_cv.predict(x_test.toarray())": 1,
      "gbr_cv.predict(submit2.toarray())": 1,
      "Conf_predictions": 1,
      "Fata_predictions": 1,
      "forecasts": 1,
      "gbm.predict(scaled_test)": 1,
      "x.reshape(-1, 1)": 1
    },
    "sklearn.linear_model._logistic.LogisticRegression.__init__.tol": {
      "0.0001": 5035,
      "0.1": 18,
      "0.001": 12,
      "1e-05": 8,
      "trial.suggest_uniform('tol', 1e-06, 0.001)": 8,
      "1e-06": 6,
      "0.02": 5,
      "all_parameters['tol'][j]": 4,
      "0.01": 4,
      "tol": 4,
      "1e-08": 3,
      "0.0003": 2,
      "lr_study.best_params['tol']": 2,
      "8.48578916594731e-05": 2,
      "0.0005028269911647464": 2,
      "0.0005335002526146307": 2,
      "0.00012534268581491389": 2,
      "trial.suggest_float('tol', 1e-05, 0.1, log=True)": 1,
      "grid_search_lr.best_params_['tol']": 1,
      "best_tol": 1,
      "0.8": 1,
      "1e-07": 1,
      "0.003": 1,
      "0.002": 1,
      "5e-05": 1,
      "1": 1,
      "0.0001738334848471753": 1
    },
    "sklearn.naive_bayes.BernoulliNB.__init__.alpha": {
      "1.0": 174,
      "0": 5,
      "0.1": 4,
      "0.2": 3,
      "alpha": 3,
      "1": 2,
      "0.03": 2,
      "0.01": 2,
      "nbBer_grid.best_params_['alpha']": 2,
      "2": 2,
      "0.011": 1,
      "f": 1,
      "0.0001": 1,
      "0.00015": 1,
      "2.0": 1,
      "4.0": 1,
      "7.0": 1
    },
    "sklearn.model_selection._split.train_test_split.train_size": {
      "None": 15806,
      "0.8": 423,
      "0.7": 101,
      "0.75": 88,
      "0.95": 82,
      "0.9": 76,
      "0.6": 40,
      "0.85": 33,
      "0.5": 25,
      "0.99": 24,
      "train_size": 14,
      "0.1": 13,
      "TRAINING_RATIO": 9,
      "0.2": 8,
      "199998": 6,
      "1 - validation_split": 4,
      "0.98": 4,
      "0.3": 4,
      "0.4": 3,
      "0.25": 3,
      "0.65": 3,
      "train_fraction": 3,
      "1": 3,
      "train_sample_size": 3,
      "0.66": 2,
      "TRAIN_SHARE": 2,
      "0.01": 2,
      "0.82": 2,
      "self.fraction": 2,
      "0.35": 2,
      "TRAIN_SIZE": 2,
      "i": 1,
      "1284": 1,
      "5000": 1,
      "36000": 1,
      "TRAIN_IDXS": 1,
      "0.33": 1,
      "SPLITRATIO": 1,
      "ML_max_samples": 1,
      "0.69 if len(X_ml) < ML_max_samples else ML_max_samples // 2": 1,
      "0.69": 1,
      "1 - va_ratio": 1,
      "100000": 1,
      "config.TRAIN_SIZE": 1,
      "FRACTION_TRAINING": 1,
      "len_train": 1,
      "0.741": 1,
      "0.67": 1,
      "0.7274": 1,
      "0.73": 1,
      "int(sample_size)": 1,
      "13": 1,
      "train_set_ratio": 1,
      "7000": 1,
      "0.05": 1,
      "TRAIN_SPLIT": 1,
      "conf['train_size']": 1,
      "len(train_features)": 1,
      "tt_ratio": 1,
      "0.03": 1,
      "train_examples": 1,
      "train_to_val_ratio": 1,
      "cfg.trainsize": 1,
      "cfg.valsize": 1,
      "SPLIT_RATIO": 1,
      "1 - size_test": 1,
      "1 - frac": 1,
      "int(np.mean(df.ebird_code_cat.value_counts().values)) / int(np.max(df.ebird_code_cat.value_counts().values))": 1
    },
    "sklearn.dummy.DummyRegressor.__init__.strategy": {
      "'median'": 36,
      "'mean'": 16
    },
    "sklearn.metrics._regression.mean_squared_error.squared": {
      "True": 7455,
      "False": 1007
    },
    "sklearn.linear_model._coordinate_descent.Lasso.__init__.fit_intercept": {
      "True": 731,
      "False": 16,
      "lasso_regressor.best_params_['fit_intercept']": 1
    },
    "sklearn.feature_selection._rfe.RFE.__init__.estimator": {
      "model": 32,
      "LogisticRegression()": 13,
      "lm": 13,
      "lr": 7,
      "logreg": 7,
      "model1": 5,
      "log_clf": 5,
      "clf1": 4,
      "xgb.XGBRegressor(tree_method='gpu_hist', random_state=11, n_jobs=-1)": 3,
      "lrModel_FE": 3,
      "rfc": 3,
      "DecisionTreeClassifier(random_state=666)": 3,
      "clf": 3,
      "XGBClassifier(max_depth=2, gamma=2, eta=0.8, reg_alpha=0.5, reg_lambda=0.5)": 2,
      "RandomForestClassifier(n_estimators=n_estimators, random_state=1)": 2,
      "DecisionTreeRegressor(random_state=666)": 2,
      "DecisionTreeRegressor()": 2,
      "regr_all": 2,
      "Tree": 2,
      "LR": 2,
      "linreg": 2,
      "modelXGB": 1,
      "RandomForestClassifier(n_estimators=100)": 1,
      "regressor": 1,
      "RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1, class_weight='balanced')": 1,
      "RandomForestRegressor(n_estimators=trees)": 1,
      "SVC(kernel='linear', C=1)": 1,
      "LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced', C=0.1)": 1,
      "modelo": 1,
      "RandomForestRegressor(n_estimators=100, random_state=42)": 1,
      "xgb_classifier": 1,
      "xgb.XGBClassifier(random_state=11, eval_metric='auc', tree_method='gpu_hist', n_jobs=-1, use_label_encoder=False, scale_pos_weight=2.8)": 1,
      "Ridge(alpha=a)": 1,
      "Ridge(alpha=1)": 1,
      "gradient_model": 1,
      "xgb_model": 1,
      "gbm": 1,
      "clf_logit": 1,
      "XGBClassifier(n_jobs=-1, random_state=1)": 1,
      "grid_search.best_estimator_": 1,
      "GradientBoostingRegressor(random_state=0)": 1,
      "model2": 1,
      "model_lasso": 1,
      "estimator": 1,
      "RandomForestClassifier()": 1,
      "best_pipeline": 1
    },
    "sklearn.feature_selection._rfe.RFE.fit.X": {
      "X_train": 30,
      "X": 28,
      "X_norm": 4,
      "x_train": 3,
      "train": 3,
      "xtrain": 2,
      "new_feature1": 2,
      "rfe_feature": 2,
      "rfe_feature2": 2,
      "rfe_feature3": 2,
      "X_data": 2,
      "normX": 1,
      "X_train.fillna(0)": 1,
      "X_train_4": 1,
      "df": 1,
      "train_feat": 1,
      "train_df": 1,
      "train_1": 1,
      "train_data.loc[:, train_data.columns != 'Weekly_Sales']": 1,
      "train_feature": 1,
      "X_ohe": 1,
      "train_df[features]": 1,
      "select_num_cols": 1,
      "select_num_cols_sm": 1,
      "X_resampled": 1,
      "x_features": 1,
      "encoded[X]": 1,
      "xtrain_stra": 1,
      "dataframe_trn": 1,
      "train[labels]": 1,
      "X_train_scaled": 1,
      "X_train_pca": 1,
      "features": 1,
      "X_scaled": 1,
      "train_feature_values": 1
    },
    "sklearn.feature_selection._rfe.RFE.fit.y": {
      "y_train": 36,
      "y": 18,
      "Y": 13,
      "train.iloc[:, 1]": 8,
      "Y_train": 3,
      "y_train.values.ravel()": 2,
      "labels": 2,
      "ytrain": 2,
      "target": 2,
      "Y_data": 2,
      "normY": 1,
      "y_train_4": 1,
      "train.TARGET": 1,
      "train_ans.values.ravel()": 1,
      "train_data['Weekly_Sales']": 1,
      "train_target": 1,
      "train_df[target]": 1,
      "y_resampled": 1,
      "y_price": 1,
      "encoded[y]": 1,
      "label": 1,
      "ytrain_stra": 1,
      "labels_trn_numeric": 1,
      "train['target']": 1,
      "train_df[target_column]": 1,
      "train_target_values": 1
    },
    "sklearn.feature_selection._from_model.SelectFromModel.__init__.threshold": {
      "None": 148,
      "'median'": 21,
      "'1.25*median'": 10,
      "thresh": 7,
      "'2*median'": 4,
      "threshold": 4,
      "0.2": 3,
      "0.001": 3,
      "-np.inf": 3,
      "0.002": 2,
      "0.005": 2,
      "0.05": 1,
      "th_list[i]": 1,
      "0.023": 1,
      "self.threshold": 1,
      "0.01": 1,
      "thres / 100": 1,
      "'1.25 *median'": 1,
      "1e-05": 1
    },
    "sklearn.feature_selection._from_model.SelectFromModel.__init__.prefit": {
      "True": 118,
      "False": 97
    },
    "sklearn.feature_selection._from_model.SelectFromModel.__init__.estimator": {
      "clf": 36,
      "selector": 24,
      "model": 22,
      "rf": 19,
      "perm": 7,
      "RandomForestClassifier(n_estimators=100)": 6,
      "Lasso(alpha=0.005, random_state=0)": 5,
      "lsvc": 5,
      "LogisticRegression(C=1, penalty='l1')": 5,
      "LogisticRegression(penalty='l1')": 4,
      "LogisticRegression(C=1, penalty='l2')": 4,
      "rfc": 3,
      "RandomForestClassifier()": 3,
      "lgbc": 3,
      "feature_model": 2,
      "LogisticRegression(C=1, penalty='l1', solver='liblinear')": 2,
      "logistic": 2,
      "dtc": 2,
      "lrc": 2,
      "RandomForestRegressor(n_estimators=300, random_state=1)": 2,
      "clf_stra_xgb": 2,
      "lr": 2,
      "lsvr": 2,
      "LGBMClassifier(n_estimators=200, objective='binary', class_weight='balanced')": 1,
      "ExtraTreesClassifier(bootstrap=True, criterion='gini', max_depth=10, max_features='auto', class_weight='balanced', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=20, min_samples_split=7, min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1, oob_score=False, random_state=42, verbose=0, warm_start=False)": 1,
      "XGBClassifier(objective='binary:logistic', random_state=42, n_estimators=200, reg_alpha=1, colsample_bylevel=0.7, colsample_bytree=0.7, gamma=5)": 1,
      "CatBoostRegressor()": 1,
      "xgb_model_for_selection": 1,
      "xg_cl": 1,
      "ExtraTreesClassifier(max_features='log2')": 1,
      "ExtraTreesClassifier(max_features='auto')": 1,
      "RandomForestClassifier(max_features='log2')": 1,
      "RandomForestClassifier(max_features='auto')": 1,
      "xgbc": 1,
      "RandomForestRegressor(max_depth=5, n_estimators=100)": 1,
      "forest": 1,
      "self.model": 1,
      "LassoCV(cv=5, fit_intercept=False)": 1,
      "LassoCV()": 1,
      "Lasso(alpha=0.03)": 1,
      "RandomForestRegressor(n_estimators=100, random_state=42)": 1,
      "LogisticRegression(solver='liblinear')": 1,
      "XGBClassifier(n_estimators=500, max_depth=3)": 1,
      "LassoCV(cv=5)": 1,
      "model_logit": 1,
      "estimator": 1,
      "lgbr": 1,
      "RandomForestRegressor(n_estimators=100)": 1,
      "Lasso()": 1,
      "Lasso_log_reg2": 1,
      "Lasso_log_reg4": 1,
      "lgb.LGBMRegressor()": 1,
      "rdFrt": 1,
      "lnSVC": 1,
      "Lasso(alpha=100)": 1,
      "model_lgb": 1,
      "LogisticRegression(C=0.05, penalty='l1', solver='liblinear')": 1,
      "LogisticRegression(C=0.05, penalty='l2', solver='liblinear')": 1,
      "m.fit(x_train, y_train)": 1,
      "log_reg": 1,
      "RandomForestClassifier(n_estimators=20)": 1,
      "model_XGBC": 1,
      "GradientBoostingClassifier()": 1,
      "RandomForestClassifier(n_estimators=200)": 1,
      "lasso": 1,
      "logistic_fit": 1,
      "Lasso(alpha=0.01)": 1,
      "xgb_reg": 1,
      "LinearSVC(penalty='l1', dual=False, tol=0.001)": 1,
      "lgb_all": 1,
      "lgb_ex": 1,
      "linear_model.Lasso(alpha=0.05)": 1,
      "RandomForestClassifier(n_estimators=59, max_depth=44, min_samples_split=9, min_samples_leaf=19, class_weight=class_weights)": 1,
      "feature_selection_model": 1
    },
    "sklearn.tree._classes.DecisionTreeClassifier.__init__.min_samples_split": {
      "2": 1505,
      "5": 11,
      "200": 4,
      "500": 2,
      "4": 2,
      "30": 2,
      "330": 2,
      "100": 2,
      "818": 2,
      "150": 1,
      "250": 1,
      "400": 1,
      "3": 1,
      "20": 1,
      "10": 1,
      "split": 1,
      "19": 1,
      "1": 1,
      "9": 1,
      "7": 1,
      "i": 1,
      "50": 1,
      "dt_grid.best_params_.get('min_samples_split')": 1,
      "6": 1,
      "2000": 1
    },
    "sklearn.tree._classes.DecisionTreeClassifier.__init__.max_features": {
      "None": 1512,
      "'sqrt'": 7,
      "'auto'": 7,
      "'log2'": 6,
      "0.7": 3,
      "10": 2,
      "25": 2,
      "0.1": 2,
      "2": 2,
      "200": 1,
      "5": 1,
      "100": 1,
      "0.5": 1,
      "0.48": 1
    },
    "sklearn.ensemble._iforest.IsolationForest.__init__.n_jobs": {
      "None": 36,
      "-1": 6,
      "1": 1,
      "3": 1
    },
    "sklearn.ensemble._iforest.IsolationForest.__init__.random_state": {
      "None": 12,
      "42": 8,
      "1": 5,
      "0": 3,
      "101": 2,
      "777": 2,
      "111": 2,
      "rng": 2,
      "22": 1,
      "31": 1,
      "np.random.RandomState(42)": 1,
      "3": 1,
      "seed": 1,
      "1729": 1,
      "rs": 1,
      "1001": 1
    },
    "sklearn.ensemble._iforest.IsolationForest.fit.X": {
      "X": 3,
      "user_reduced_scaled": 2,
      "data": 2,
      "continuous_df": 2,
      "X_train": 2,
      "train[cols]": 1,
      "data_IF": 1,
      "train_df": 1,
      "X_train[NO_NAN_COLS].loc[y_train == 1].values": 1,
      "X_train.loc[y_train == 1].values": 1,
      "final_features": 1,
      "ohe_reduced_transaction_df": 1,
      "site_1_2": 1,
      "train[cols_float]": 1,
      "sales_train[['shop_id', 'item_id', 'item_price', 'item_cnt_day']]": 1,
      "dataset": 1,
      "train.drop(['id', 'target'], axis=1)": 1,
      "train_PUBG[X_cols]": 1,
      "train": 1,
      "train[labels]": 1,
      "imputed_total": 1,
      "train_data.values": 1
    },
    "sklearn.ensemble._iforest.IsolationForest.fit.y": {
      "None": 25,
      "Y": 1,
      "train['target']": 1,
      "target": 1
    },
    "sklearn.ensemble._iforest.IsolationForest.score_samples.X": {
      "X": 1,
      "train[labels]": 1
    },
    "sklearn.ensemble._iforest.IsolationForest.predict.X": {
      "X": 2,
      "user_reduced_scaled": 2,
      "data": 2,
      "df[continuous_df.columns]": 2,
      "X_train": 2,
      "train[cols]": 1,
      "data_IF": 1,
      "train_df": 1,
      "final_features": 1,
      "ohe_reduced_transaction_df": 1,
      "site_unknown": 1,
      "test_df": 1,
      "train[cols_float]": 1,
      "sales_train[['shop_id', 'item_id', 'item_price', 'item_cnt_day']]": 1,
      "dataset": 1,
      "train_PUBG[X_cols]": 1,
      "train": 1,
      "train[labels]": 1,
      "imputed_total": 1,
      "train_data.values": 1,
      "test_data.values": 1
    },
    "sklearn.model_selection._split.RepeatedKFold.__init__.n_splits": {
      "10": 50,
      "5": 46,
      "n_splits": 19,
      "3": 13,
      "4": 11,
      "2": 9,
      "8": 4,
      "6": 3,
      "nfolds": 2,
      "NFOLDS": 2,
      "7": 1,
      "n_fold": 1,
      "int(cv_folds / repeats)": 1,
      "folds": 1,
      "num_cv_folds": 1,
      "20": 1,
      "k": 1
    },
    "sklearn.model_selection._split.RepeatedKFold.__init__.random_state": {
      "1": 37,
      "None": 37,
      "0": 28,
      "42": 16,
      "seed": 9,
      "4520": 6,
      "4590": 6,
      "4950": 5,
      "random_state": 3,
      "10": 3,
      "15": 3,
      "2019": 2,
      "11": 2,
      "SEED": 2,
      "19": 1,
      "33": 1,
      "28": 1,
      "47": 1,
      "288490": 1,
      "684": 1,
      "376": 1
    },
    "sklearn.linear_model._coordinate_descent.Lasso.__init__.normalize": {
      "False": 722,
      "True": 25,
      "lasso_regressor.best_params_['normalize']": 1
    },
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.alphas": {
      "None": 61,
      "[1, 0.1, 0.001, 0.0005]": 10,
      "alphas": 7,
      "alphas2": 6,
      "arange(0, 1, 0.01)": 3,
      "lamdbalar": 3,
      "alphas_lasso": 2,
      "[0.0001, 0.0003, 0.0006, 0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1]": 2,
      "Lambdas": 2,
      "alphas_alt": 2,
      "np.logspace(0.1, 10, 30)": 2,
      "(1, 0.1, 0.01, 0.001, 0.0005)": 1,
      "[1, 0.1, 0.001, 0.0001, 0.0005]": 1,
      "alpha": 1,
      "[alpha * 0.3, alpha * 0.35, alpha * 0.7, alpha * 0.75, alpha * 0.8, alpha * 0.85, alpha * 0.9, alpha * 0.95, alpha, alpha * 1.05, alpha * 1.1, alpha * 1.15, alpha * 1.25, alpha * 1.3, alpha * 1.35, alpha * 1.4]": 1,
      "[0.0005]": 1,
      "(0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0)": 1,
      "[0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75]": 1,
      "[0.001, 0.01, 0.1, 1]": 1,
      "[0.0002, 0.0003, 0.0004, 0.0005, 0.1, 0.3, 0.4, 0.6, 0.8, 1.0]": 1,
      "(0.0001, 0.0005, 0.001, 0.01, 0.05, 0.1, 0.3, 1, 3, 5, 10)": 1,
      "alpha2": 1,
      "np.logspace(-6, 6, 13)": 1,
      "[1, 0.1, 0.001, 0.01, 1e-05]": 1,
      "np.arange(0.0005, 0.0015, 0.0001)": 1,
      "[0.001, 0.1, 1.0, 10.0, 100.0, 1000.0]": 1,
      "[0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]": 1,
      "[alpha * 0.6, alpha * 0.65, alpha * 0.7, alpha * 0.75, alpha * 0.8, alpha * 0.85, alpha * 0.9, alpha * 0.95, alpha, alpha * 1.05, alpha * 1.1, alpha * 1.15, alpha * 1.25, alpha * 1.3, alpha * 1.35, alpha * 1.4]": 1,
      "10**np.arange(-6, 2, 0.1)": 1,
      "alpha_las": 1,
      "[0.01]": 1
    },
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.cv": {
      "None": 65,
      "5": 13,
      "10": 12,
      "kfolds": 10,
      "cv": 9,
      "tscv": 4,
      "kf": 2,
      "20": 1,
      "kfold": 1,
      "12": 1,
      "k_folds": 1,
      "_cv": 1
    },
    "sklearn.tree._classes.DecisionTreeRegressor.__init__.min_samples_split": {
      "2": 860,
      "50": 5,
      "5": 4,
      "30000": 4,
      "3": 3,
      "4": 3,
      "25": 3,
      "20": 2,
      "10": 2,
      "500": 1,
      "0.1": 1,
      "200": 1,
      "12": 1,
      "i": 1,
      "32": 1,
      "min_samples_split": 1,
      "x": 1,
      "8": 1,
      "100": 1
    },
    "sklearn.tree._classes.DecisionTreeRegressor.__init__.min_samples_leaf": {
      "1": 857,
      "5": 8,
      "25": 5,
      "3": 3,
      "40": 3,
      "15": 3,
      "12": 2,
      "2": 2,
      "4": 1,
      "100": 1,
      "10": 1,
      "0.00043": 1,
      "i": 1,
      "9": 1,
      "20": 1,
      "32": 1,
      "11": 1,
      "msl": 1,
      "7": 1,
      "args['min_samples_leaf']": 1,
      "8": 1
    },
    "sklearn.model_selection._split.RepeatedKFold.__init__.n_repeats": {
      "3": 41,
      "1": 28,
      "2": 27,
      "10": 22,
      "n_repeats": 19,
      "5": 15,
      "6": 3,
      "4": 2,
      "nrepeats": 2,
      "NREPEATS": 2,
      "8": 1,
      "n_rep": 1,
      "repeats": 1,
      "REPEATS": 1,
      "num_repeats": 1
    },
    "sklearn.model_selection._validation.cross_val_score.n_jobs": {
      "None": 3377,
      "-1": 313,
      "1": 48,
      "n_jobs": 21,
      "2": 14,
      "4": 8,
      "processors": 8,
      "8": 4,
      "3": 4,
      "multiprocessing.cpu_count() - 1": 3,
      "5": 1
    },
    "sklearn.model_selection._validation.cross_val_score.error_score": {
      "np.nan": 3773,
      "'raise'": 22,
      "'neg_root_mean_squared_error'": 3,
      "0": 2,
      "-1.0": 1
    },
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.subsample": {
      "1.0": 907,
      "0.7": 26,
      "0.8": 14,
      "0.5": 13,
      "0.9": 4,
      "0.95": 4,
      "0.85": 4,
      "0.75": 3,
      "0.6": 3,
      "0.65": 2,
      "1": 2,
      "trial.suggest_categorical('subsample', [0.9, 1.0])": 1,
      "study.best_trial.params['subsample']": 1,
      "0.4": 1,
      "0.63": 1,
      "trial.suggest_categorical('subsample', [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])": 1,
      "0.83": 1,
      "0.1": 1
    },
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.loss": {
      "'ls'": 795,
      "'huber'": 154,
      "'quantile'": 28,
      "'lad'": 9,
      "loss": 3
    },
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.verbose": {
      "0": 960,
      "1": 19,
      "2": 6,
      "False": 2,
      "True": 1,
      "10": 1
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet.__init__.selection": {
      "'cyclic'": 17,
      "'random'": 2
    },
    "sklearn.model_selection._split.GroupShuffleSplit.__init__.n_splits": {
      "1": 38,
      "4": 8,
      "5": 5,
      "2": 3,
      "n_fold": 2,
      "self.n_splits": 2,
      "13": 1,
      "NUM_FOLD": 1,
      "N_FOLDS": 1,
      "10": 1,
      "config.N_FOLD": 1,
      "100": 1
    },
    "sklearn.model_selection._split.GroupShuffleSplit.__init__.random_state": {
      "oof_seed * 1000000": 30,
      "None": 13,
      "8": 3,
      "42": 3,
      "0": 3,
      "11": 2,
      "314": 2,
      "self.seed": 2,
      "513131": 1,
      "SEED": 1,
      "7": 1,
      "RANDOM_STATE": 1,
      "13": 1,
      "config.SEED": 1
    },
    "sklearn.model_selection._split.GroupShuffleSplit.__init__.test_size": {
      "0.15": 30,
      "0.2 + 0.1 * np.random.rand()": 8,
      "0.2": 7,
      "test_size": 6,
      "None": 5,
      "0.1": 4,
      "my_test_pct": 3,
      "config.TEST_RATIO": 1
    },
    "sklearn.model_selection._split.GroupShuffleSplit.split.groups": {
      "tr_selector[id_col]": 29,
      "groups": 5,
      "df_x['patient_id']": 3,
      "self.train_df[self.group]": 2,
      "train_y.group_id": 1,
      "Y_strat": 1,
      "df['GameId']": 1,
      "train_df['user_id']": 1,
      "train['Patient']": 1,
      "df_input['row_id']": 1,
      "plays['GameId']": 1,
      "train['SentenceId']": 1,
      "train_data['SentenceId']": 1,
      "features['Patient']": 1,
      "train['group_id']": 1,
      "train['user_id']": 1,
      "train.user_id": 1,
      "cluster_ID_array": 1,
      "train_df[id_col]": 1
    },
    "sklearn.model_selection._split.GroupShuffleSplit.split.X": {
      "tr_selector": 29,
      "dataset.raw": 4,
      "train": 4,
      "indices": 3,
      "train_df": 2,
      "np.zeros((segments, ))": 1,
      "X": 1,
      "df": 1,
      "df_input": 1,
      "plays[FEATURES]": 1,
      "train['PhraseId']": 1,
      "train_data['PhraseId']": 1,
      "features": 1,
      "self.raw": 1,
      "self.train_df[self.features]": 1,
      "self.train_df[self.features + self.categoricals]": 1,
      "np.zeros((len(cluster_ID_array), 1))": 1
    },
    "sklearn.model_selection._split.ShuffleSplit.__init__.random_state": {
      "0": 71,
      "tv_seed": 34,
      "None": 29,
      "42": 22,
      "random_state": 19,
      "random_state + i": 19,
      "oof_seed * 10000": 13,
      "oof_seed * 1000000": 10,
      "7": 8,
      "853": 6,
      "3": 5,
      "85": 5,
      "seed": 4,
      "58": 4,
      "123": 3,
      "53": 3,
      "2000": 3,
      "1": 2,
      "200": 2,
      "456": 2,
      "22": 2,
      "314": 1,
      "RANDOM_STATE": 1,
      "SEED": 1,
      "4": 1,
      "random_seed": 1,
      "8": 1,
      "99": 1,
      "12": 1,
      "50": 1,
      "253": 1,
      "1009": 1,
      "1008": 1,
      "2000 + i": 1
    },
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.transform.X": {
      "test": 125,
      "test_dic": 14,
      "words_dict": 12,
      "dict_test_data": 5,
      "test_df_dic": 2,
      "tcatdf.to_dict('records')": 2,
      "X_test.to_dict(orient='record')": 1,
      "X_dict_test": 1,
      "x_cat_test": 1,
      "df_pred.fillna(0).to_dict('records')": 1,
      "df_cat_test.to_dict('records')": 1,
      "X": 1
    },
    "sklearn.dummy.DummyRegressor.score.X": {
      "Xs_train": 1
    },
    "sklearn.dummy.DummyRegressor.score.y": {
      "y_train": 1
    },
    "sklearn.preprocessing._data.normalize.axis": {
      "1": 244,
      "0": 184,
      "normalize_axis": 1
    },
    "sklearn.preprocessing._data.normalize.X": {
      "X": 26,
      "test_text_feature_onehotCoding": 24,
      "train_text_feature_onehotCoding": 23,
      "cv_text_feature_onehotCoding": 22,
      "train[features]": 21,
      "test[features]": 21,
      "X_test": 17,
      "X_train": 14,
      "np.random.random(shape)": 12,
      "imagefeat": 11,
      "A": 7,
      "test": 6,
      "df_train[cols_to_normalize]": 5,
      "df_test[cols_to_normalize]": 5,
      "data": 5,
      "train[cols_to_normalize]": 5,
      "test[cols_to_normalize]": 5,
      "[depth_array]": 5,
      "[feat_values]": 5,
      "X_train_init": 4,
      "X_test_init": 4,
      "text_embeddings": 4,
      "[np.array(df['PCA1'])]": 4,
      "[np.array(df['PCA2'])]": 4,
      "[np.array(df[f'{col}'])]": 4,
      "embeddings": 3,
      "[x_array]": 3,
      "test_data": 3,
      "df[feature_columns]": 3,
      "X_t": 3,
      "df_test": 3,
      "x_train": 2,
      "train_df[['sex', 'age', 'anatomy']]": 2,
      "test_df[['sex', 'age', 'anatomy']]": 2,
      "[trainimg]": 2,
      "[testimg]": 2,
      "train_transaction": 2,
      "test_transaction": 2,
      "aei1[['Estimated reducable water withdrawal (m3/MWh)', 'Residential building emissions - carbon intensity in metric tonnes of CO2e generated, for each million Btu of energy consumed, per capita', 'Commercial building emissions - carbon intensity in metric tonnes of CO2e generated, for each million Btu of energy consumed, per capita', 'Transport emissions - carbon intensity in metric tonnes of CO2e generated, for each million Btu of energy consumed, per capita']]": 2,
      "aei2[['Estimated reducable water withdrawal (m3/MWh)', 'Direct emissions per capita(metric tonnes CO2e),excluding generation of grid-supplied energy)']]": 2,
      "text_old_onehotCoding": 2,
      "text_onehotCoding": 2,
      "tt": 2,
      "X_train[flist]": 2,
      "X_test[flist]": 2,
      "plays": 2,
      "songrating": 2,
      "np.append(image, spec_centroid.reshape(1, 207), axis=0)": 2,
      "spec_bw": 2,
      "spec_centroid": 2,
      "X_valid": 2,
      "train_text_feature_onehotCoding[:, top_1k_index]": 2,
      "test_text_feature_onehotCoding[:, top_1k_index]": 2,
      "cv_text_feature_onehotCoding[:, top_1k_index]": 2,
      "np.array(timestamps).reshape(-1, 1)": 1,
      "train_data.drop(columns=['ID_code', 'target'])": 1,
      "test_data.drop(columns=['ID_code'])": 1,
      "train": 1,
      "professional_question_strengths_weighted_avg": 1,
      "X_scaled": 1,
      "test_df": 1,
      "testing": 1,
      "x_train_price": 1,
      "x_test_price": 1,
      "traindata": 1,
      "image_features": 1,
      "X_sel": 1,
      "train_data": 1,
      "X_train_val_gene_cv": 1,
      "X_train_val_var_cv": 1,
      "X_train_val_text_cv": 1,
      "training_data_2": 1,
      "X_train_val_len": 1,
      "X_test_val_gene_cv": 1,
      "X_test_val_var_cv": 1,
      "X_test_val_text_cv": 1,
      "X_test_val_len": 1,
      "X_test_gene_cv": 1,
      "X_test_var_cv": 1,
      "X_test_text_cv": 1,
      "X_test_len": 1,
      "df_X": 1,
      "chrome[:, np.newaxis]": 1,
      "firefox[:, np.newaxis]": 1,
      "ie[:, np.newaxis]": 1,
      "city_metadata['density'].values.reshape(1, -1)": 1,
      "data_to_cluster.values": 1,
      "aei1[['Long-term Environment Risk  1', 'derived SVI score']]": 1,
      "adaptation_action_kpi[kpis_to_be_normalized]": 1,
      "train.values[:, :405]": 1,
      "data.reshape(1, -1)": 1,
      "im_features": 1,
      "reduce_train": 1,
      "reduce_test": 1,
      "x_w_0": 1,
      "x_w": 1,
      "df_all": 1,
      "outs": 1,
      "features": 1,
      "test_X": 1,
      "sub": 1,
      "temp_on - np.matmul(W_on, H_off)": 1,
      "image_on - image_off": 1,
      "distances": 1,
      "X_pred": 1,
      "train[['num_word', 'num_char', 'avg_word_length']].values": 1,
      "test[['num_word', 'num_char', 'avg_word_length']].values": 1,
      "df[featcols].fillna(-1)": 1,
      "nn[ft].values": 1,
      "nn[ft]": 1,
      "result": 1,
      "train_text_feature_onehotCoding_bigram": 1,
      "test_text_feature_onehotCoding_bigram": 1,
      "cv_text_feature_onehotCoding_bigram": 1,
      "train_text_feature_onehotCoding_fe": 1,
      "test_text_feature_onehotCoding_fe": 1,
      "cv_text_feature_onehotCoding_fe": 1,
      "np.nan_to_num(pop_map)": 1,
      "train.drop('label', axis=1)": 1,
      "test.drop('id', axis=1)": 1,
      "np.array([spec_bw]).reshape(1, 207)": 1,
      "np.append(image, spec_bw.reshape(1, 207), axis=0)": 1,
      "np.append(image, chroma_stft.reshape(12, 207), axis=0)": 1,
      "chroma_stft": 1,
      "image_embedding": 1,
      "image_embeddings": 1,
      "bert_embeddings2": 1,
      "bert_embeddings": 1,
      "feats": 1,
      "y.reshape(1, -1)": 1,
      "Xtest": 1,
      "train_features": 1,
      "test_features": 1,
      "counts": 1,
      "training1985x": 1,
      "training2003x": 1,
      "training2010x": 1,
      "whole_data": 1,
      "train[col]": 1,
      "test[col]": 1,
      "X_dat_pca": 1,
      "test_data_pca": 1,
      "xtrain_text_feature": 1,
      "xtest_text_feature": 1,
      "testData_text_feature": 1,
      "stacked_image_features": 1,
      "W": 1,
      "pr_sgmd": 1,
      "train.iloc[:, 2:]": 1,
      "test.iloc[:, 1:]": 1,
      "train.NET_PRICE.reshape(-1, 1)": 1,
      "df_train[colstoNormalize]": 1,
      "df_test[colstoNormalize]": 1,
      "tnt[cols]": 1,
      "text_embed": 1,
      "X_all": 1
    },
    "sklearn.linear_model._base.LinearRegression.__init__.normalize": {
      "False": 2813,
      "True": 168,
      "best['normalize']": 2,
      "normalize": 1
    },
    "sklearn.base.TransformerMixin.fit_transform.y": {
      "None": 7938,
      "y": 88,
      "y_train": 56,
      "target": 10,
      "y_train.values.astype(int)": 9,
      "Y": 7,
      "train_target": 5,
      "df[target]": 5,
      "targets": 4,
      "y_train_o": 3,
      "y_tr": 3,
      "train['price']": 3,
      "train['TARGET']": 3,
      "Y_completo": 3,
      "labels": 2,
      "clean_df['SalePrice']": 2,
      "y_train.toxic": 2,
      "y_ca": 2,
      "x.astype('float64')": 2,
      "np.log1p(y)": 2,
      "train_set['item_cnt_month']": 2,
      "yy": 2,
      "y_train[idx_train]": 2,
      "y_train.values": 2,
      "train_df['interest_level']": 2,
      "train['target']": 2,
      "binary_log['target']": 2,
      "binary_log_NO['target']": 2,
      "binary_log_NO_TNO['target']": 2,
      "binary_num['target']": 2,
      "binary_num_NO['target']": 2,
      "binary_num_NO_TNO['target']": 2,
      "ordinal_num['target']": 2,
      "ordinal_num_NO['target']": 2,
      "ordinal_num_NO_TNO['target']": 2,
      "ordinal_log['target']": 2,
      "ordinal_log_NO['target']": 2,
      "ordinal_log_NO_TNO['target']": 2,
      "freq_num['target']": 2,
      "freq_num_NO['target']": 2,
      "freq_num_NO_TNO['target']": 2,
      "freq_log['target']": 2,
      "freq_log_NO['target']": 2,
      "freq_log_NO_TNO['target']": 2,
      "train_sub.target": 2,
      "y_enc": 1,
      "news_sentiment_Y": 1,
      "y_ph": 1,
      "y_soc": 1,
      "y_sand": 1,
      "y_t": 1,
      "ytrain": 1,
      "encoded_data.Target": 1,
      "train['is_attributed']": 1,
      "range(-1, 1)": 1,
      "train_tgt": 1,
      "y_data_generated": 1,
      "Y[y_col]": 1,
      "df_train['target']": 1,
      "df_undersampled_ytr": 1,
      "y_train_data": 1,
      "trainLabels": 1,
      "train_df[target_cols]": 1,
      "X_scale_param": 1,
      "Time_scale_param": 1,
      "df['action']": 1,
      "label": 1,
      "train_y": 1,
      "age_scaler_param": 1,
      "fare_scaler_param": 1,
      "age_scaler_param2": 1,
      "fare_scaler_param2": 1,
      "y_cv": 1,
      "y_test": 1,
      "train_Y": 1,
      "YYYtrain": 1,
      "pd.DataFrame(d['ConfirmedCases'])": 1,
      "[[m]]": 1
    },
    "sklearn.manifold._t_sne.TSNE.fit_transform.X": {
      "X": 42,
      "mean_rgb_top_n": 37,
      "tokens": 19,
      "img_mat": 16,
      "data": 11,
      "diff_encodings.toarray()": 10,
      "svd_tfidf": 9,
      "gray_imgs_mat": 9,
      "kmeans_distances": 8,
      "x": 7,
      "X_train": 7,
      "test_data": 6,
      "node_pos": 6,
      "X_topics": 6,
      "pca_result": 6,
      "X.values.reshape(-1, 1)": 6,
      "lsa_topic_matrix": 5,
      "lda_topic_matrix": 5,
      "data_1000": 5,
      "X_train0": 5,
      "X_train1": 5,
      "X_train2": 5,
      "X_train3": 5,
      "df": 4,
      "standardized_data": 4,
      "X[:100, :]": 4,
      "np.abs(cov)": 4,
      "PCA(n_components=100).fit_transform(data[max_items, :].todense())": 3,
      "intermediates": 3,
      "arr": 3,
      "X_embedded": 3,
      "Target": 3,
      "trainX": 3,
      "train": 3,
      "embeddings": 3,
      "train[:500]": 3,
      "pca_result_50": 3,
      "X_rep": 3,
      "x1": 2,
      "df[feat_cols].values": 2,
      "final_embeddings[:plot_only, :]": 2,
      "np.vstack(filtered.values())": 2,
      "features.values": 2,
      "g": 2,
      "word_vectors": 2,
      "X_test": 2,
      "df_train_pixels[:10000].to_numpy()": 2,
      "country_embeddings": 2,
      "final_embeddings[1:num_points + 1, :]": 2,
      "feature_vector": 2,
      "ngs_scaled": 2,
      "Z": 2,
      "vectors": 2,
      "vector_out": 2,
      "z_train": 2,
      "embedding.asnumpy()": 2,
      "images.reshape(-1, img_width * img_height * img_channels)": 2,
      "embedding_model.predict(images)": 2,
      "nan_features": 2,
      "news_topics": 2,
      "X_train.sample(5000)": 2,
      "train_df.drop(['label'], axis=1)[::5]": 2,
      "X_tsne": 2,
      "pre_X": 2,
      "tsne_input.values": 2,
      "train_data_probabilities": 2,
      "test_data_probabilities": 2,
      "w2v_vectors": 2,
      "intermediate_output": 2,
      "StandardScaler().fit_transform(train_sub.drop('target', axis=1).astype(float))": 2,
      "X.toarray()": 2,
      "pd.concat([train[features], test[features]])": 2,
      "tsvd": 2,
      "concated[cols].values": 2,
      "total": 1,
      "X_eda": 1,
      "train_sample": 1,
      "X_valid[:5000]": 1,
      "inputtsne": 1,
      "X_std": 1,
      "features_pca": 1,
      "all_arr": 1,
      "image_PCA": 1,
      "principalComponents_50": 1,
      "NN_rep1": 1,
      "w": 1,
      "X_prj": 1,
      "temp_df[c_cols]": 1,
      "temp_df[d_cols]": 1,
      "_temp_df[_d_cols].fillna(99999)": 1,
      "data_all[GENES]": 1,
      "data_all[CELLS]": 1,
      "scaled": 1,
      "images[:2000]": 1,
      "images": 1,
      "Xdr": 1,
      "train_data_TSNE.iloc[0:n_samples]": 1,
      "test_data_TSNE.iloc[0:n_samples]": 1,
      "tfidf_char_features.toarray()": 1,
      "fasttext_features": 1,
      "X[:1000, :]": 1,
      "X[i * 1000:(i + 1) * 1000, :]": 1,
      "X[50000:, :]": 1,
      "df_hist.values": 1,
      "np.array(data)": 1,
      "sampled_data.iloc[:, 2:]": 1,
      "images_scaled": 1,
      "pca_result_10": 1,
      "sample": 1,
      "X_plot": 1,
      "X_reduced": 1,
      "reduced_train_image_df": 1,
      "X_scaled": 1,
      "gene_expression.values": 1,
      "rnn_res": 1,
      "X_vectors": 1,
      "dataset_val": 1,
      "X[:, :300]": 1,
      "train_df[feature_cols].T.values": 1,
      "features_last": 1,
      "xCompressed": 1,
      "all_z": 1,
      "train.values": 1,
      "new_trans_x": 1,
      "layer_weights": 1,
      "model.layers[11].get_weights()[0]": 1,
      "model.layers[12].get_weights()[0]": 1,
      "model.layers[9].get_weights()[0]": 1,
      "X.values": 1,
      "pca_result_200": 1,
      "train_lda": 1,
      "np.concatenate((centers, df_labels.values), axis=0)": 1,
      "features": 1,
      "pca_50": 1,
      "embeddings_df.values": 1,
      "hist_list": 1,
      "X_raw": 1,
      "histo_list": 1,
      "fine_tuned_embeddings": 1,
      "unet_embeddings": 1,
      "latent_features": 1,
      "doctopic": 1,
      "tot_adv.drop(['target_points', 'tourney', 'target'], axis=1)": 1,
      "men_train.drop(['ID', 'DayNum', 'Team1', 'Team2', 'Season'] + ['target'], axis=1)": 1,
      "women_train.drop(['ID', 'DayNum', 'Team1', 'Team2', 'Season'] + ['target'], axis=1)": 1,
      "adv": 1,
      "df[features].values": 1,
      "prod_vec_df[prod_vec_names]": 1,
      "train_df.drop(['label'], axis=1)": 1,
      "audience_embeddings": 1,
      "audience_embeddings_using_sub": 1,
      "X_train[0:1500]": 1,
      "X1": 1,
      "X5": 1,
      "X_train_sc": 1,
      "education[platforms].values": 1,
      "x_train_s": 1,
      "X_test0[:5000]": 1,
      "X_test1[:5000]": 1,
      "X_test2[:5000]": 1,
      "X_test3[:5000]": 1,
      "X_test0[5000:10000]": 1,
      "X_test1[5000:10000]": 1,
      "X_test2[5000:10000]": 1,
      "X_test3[5000:10000]": 1,
      "X_test0": 1,
      "X_test1": 1,
      "X_test2": 1,
      "X_test3": 1,
      "df2_std": 1,
      "ndf[[col for col in list(df) if 'cafe' in col]]": 1,
      "diff_ecoding.toarray()": 1,
      "pca_df": 1,
      "train_data_TSNE": 1,
      "X_val": 1,
      "np.concatenate([tsne_preprocessor.transform(df) for df in (X_train, X_test, test)])": 1,
      "df_all": 1,
      "_df.drop(['target'], axis=1)": 1,
      "_df.drop(['SalePrice', 'SalePrice_transformed'], axis=1)": 1,
      "train.drop(['sig_id', 'cp_type', 'cp_time', 'cp_dose'], axis=1)": 1,
      "df.drop(['y'], axis=1)": 1,
      "x_subset": 1,
      "train_df_for_tsne": 1,
      "mnist_df_without_label": 1,
      "df_store.fillna(0)": 1,
      "df_store.fillna(1)": 1,
      "PCA(n_components=20).fit_transform(data[max_items, :].todense())": 1,
      "e_": 1,
      "X_train[:300]": 1,
      "X_data": 1,
      "df[col_n]": 1,
      "X_PCA_train": 1,
      "output_descriptor": 1,
      "pca_result_train": 1,
      "pca_result_test": 1,
      "embed_array": 1,
      "mat_32": 1,
      "X[:2000]": 1,
      "scaled_data": 1,
      "x_arr": 1,
      "self.w2vecarrays": 1,
      "total_features": 1,
      "train_df.drop('label', axis=1)": 1,
      "pixel_values.iloc[:10000, :]": 1,
      "X_train_eval": 1,
      "gp": 1,
      "predictions[predictions.columns[1:]]": 1,
      "grppreds": 1,
      "alldata[features]": 1,
      "np.vstack((X_rep, templates_rep))": 1,
      "X_svd": 1,
      "df[dot_mask]": 1,
      "train.iloc[2:20, 21:30]": 1,
      "scaler.fit_transform(x_train)": 1,
      "scaler.fit_transform(x_test)": 1,
      "X_ss": 1,
      "selected_features": 1,
      "tag_vecs": 1,
      "culture_vecs": 1,
      "test_emb": 1,
      "block4_pool_features": 1,
      "X_train.values": 1,
      "train_norm": 1,
      "all_data": 1,
      "X_arr": 1,
      "X_pca[:, :]": 1,
      "distance_matrix": 1,
      "train_X_svd": 1,
      "train_X_svd_tfv": 1,
      "embds": 1,
      "xtrain_scaled": 1,
      "x_pca": 1,
      "tm": 1,
      "vectors[:500]": 1,
      "df_sample[['cwc_min', 'cwc_max', 'csc_min', 'csc_max', 'ctc_min', 'ctc_max', 'las_word_eq', 'fir_word_eq', 'absdiff_token', 'mean_token', 'fuzz_ratio', 'fuzz_partial_ratio', 'fuzz_sort_ratio', 'fuzz_set_ratio', 'lcs_ratio']]": 1,
      "precomp_cosine": 1,
      "np.concatenate((Gallery_embedding_matrix_Text, Probe_embedding_matrix_Text), axis=0)": 1,
      "np.concatenate((Gallery_embedding_matrix_Image, Probe_embedding_matrix_Image), axis=0)": 1,
      "np.concatenate((Gallery_embedding_matrix_Full, Probe_embedding_matrix_Full), axis=0)": 1,
      "autoencoder_df": 1,
      "train_numeric_X": 1
    },
    "sklearn.manifold._t_sne.TSNE.__init__.n_components": {
      "2": 435,
      "3": 87,
      "n_components": 8,
      "ncompo_genes": 1,
      "ncompo_cells": 1,
      "compnum": 1,
      "comp_num": 1,
      "dim": 1,
      "1": 1
    },
    "sklearn.manifold._t_sne.TSNE.__init__.init": {
      "'random'": 432,
      "'pca'": 104
    },
    "sklearn.manifold._t_sne.TSNE.__init__.random_state": {
      "None": 186,
      "0": 117,
      "101": 55,
      "42": 51,
      "RANDOM_STATE": 36,
      "23": 20,
      "self.random_state": 10,
      "1": 7,
      "RANDOM_SEED": 5,
      "seed": 4,
      "rand_seed": 4,
      "2020": 4,
      "random_state": 3,
      "51": 3,
      "4": 3,
      "17": 2,
      "222": 2,
      "univ_seed": 2,
      "32": 2,
      "529": 2,
      "4422": 2,
      "2016": 2,
      "172": 2,
      "1234": 2,
      "1003": 1,
      "6": 1,
      "314": 1,
      "RS": 1,
      "50": 1,
      "41": 1,
      "1001": 1,
      "SEED": 1,
      "state": 1,
      "2017": 1
    },
    "sklearn.manifold._t_sne.TSNE.__init__.method": {
      "'barnes_hut'": 518,
      "'exact'": 18
    },
    "sklearn.manifold._t_sne.TSNE.__init__.n_iter": {
      "1000": 395,
      "500": 45,
      "200": 19,
      "2500": 18,
      "300": 16,
      "2000": 14,
      "5000": 9,
      "12000": 3,
      "250": 3,
      "900": 2,
      "n_iter": 2,
      "400": 2,
      "3000": 2,
      "4000": 1,
      "1600": 1,
      "1500": 1,
      "100000": 1,
      "251": 1,
      "N_ITER": 1
    },
    "sklearn.manifold._t_sne.TSNE.__init__.verbose": {
      "0": 405,
      "1": 66,
      "2": 63,
      "20": 1,
      "10": 1
    },
    "sklearn.manifold._t_sne.TSNE.__init__.angle": {
      "0.5": 524,
      "0.75": 11,
      "0.99": 1
    },
    "sklearn.metrics._classification.confusion_matrix.labels": {
      "None": 4043,
      "range(len(CLASSES))": 207,
      "labels": 70,
      "np.unique(y_true)": 31,
      "[0, 1]": 19,
      "[1, 0]": 15,
      "range(N_LABELS)": 13,
      "[0, 1, 2, 3, 4]": 6,
      "classes": 4,
      "['EAP', 'HPL', 'MWS']": 4,
      "[True, False]": 3,
      "range(len(LABELS))": 3,
      "range(len(classes))": 3,
      "['EAP', 'MWS', 'HPL']": 3,
      "cuisines": 2,
      "y_test.unique().tolist()": 2,
      "range(10)": 2,
      "range(num_of_classes)": 2,
      "['bird', 'cat', 'dog', 'hen', 'pig']": 2,
      "[0, 1, 2, 3, 4, 5]": 2,
      "train_new.target_ord.unique().tolist()": 2,
      "model1.classes_": 2,
      "model2.classes_": 2,
      "[1, 2, 3, 4]": 2,
      "model.classes_": 2,
      "range(classes_num)": 1,
      "[0, 1, 2, 3]": 1,
      "np.arange(14)": 1,
      "np.arange(15)": 1,
      "train_df['cuisine'].unique()": 1,
      "[0, 1, 2]": 1,
      "gbc.classes_": 1,
      "collist": 1,
      "['ant', 'bird', 'cat']": 1,
      "list(set(y_test))": 1,
      "breeds_in_set": 1,
      "[0, 1, 2, 3, 4, 5, 6, 7]": 1,
      "range(9)": 1,
      "[i for i in range(9)]": 1
    },
    "sklearn.pipeline.FeatureUnion.fit.X": {
      "df.to_dict('records')": 19,
      "X": 9,
      "all_text": 7,
      "df.loc[traindex, :].to_dict('records')": 5,
      "fold1": 1,
      "fold0": 1,
      "train_comments": 1,
      "train_vect": 1,
      "df_all": 1
    },
    "sklearn.pipeline.FeatureUnion.transform.X": {
      "df.to_dict('records')": 24,
      "X": 10,
      "preprocess(valid)": 8,
      "test_df": 7,
      "test": 5,
      "test_X_df.iloc[offset:slice_upper_bound]": 5,
      "X_test": 5,
      "train_text": 3,
      "test_text": 3,
      "train['comment_text']": 2,
      "test['comment_text']": 2,
      "x_test": 2,
      "test.Phrase": 2,
      "preprocess(test)": 2,
      "train_df": 2,
      "dev": 2,
      "corpusts": 2,
      "X_predict": 1,
      "preprocess(test.iloc[i:i + 500000].copy())": 1,
      "test.ingredients.str.join(' ')": 1,
      "test.cleaned": 1,
      "test_set": 1,
      "train_comments": 1,
      "test_comments": 1,
      "batch": 1,
      "test_X": 1,
      "dev_df.values": 1,
      "test_df.values": 1,
      "test_processed": 1,
      "test_vect": 1
    },
    "sklearn.linear_model._logistic.LogisticRegression.__init__.dual": {
      "False": 5048,
      "True": 66,
      "self.dual": 15
    },
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.__init__.learning_rate": {
      "1.0": 424,
      "0.01": 23,
      "0.1": 17,
      "1": 11,
      "0.05": 11,
      "0.5": 6,
      "l": 5,
      "1.5": 4,
      "0.75": 3,
      "1.4": 3,
      "0.2": 3,
      "0.3": 2,
      "0.7": 2,
      "gridcv.best_params_['learning_rate']": 2,
      "0.6": 2,
      "adaparam['learning_rate']": 1,
      "learning_rate": 1,
      "1.8": 1,
      "0.25": 1,
      "0.098643": 1,
      "0.12": 1,
      "trial.suggest_float('learning_rate', 0.01, 5)": 1,
      "1.3": 1,
      "1.54": 1
    },
    "sklearn.preprocessing._encoders.OneHotEncoder.__init__.dtype": {
      "np.float64": 1447,
      "'uint8'": 15,
      "np.int8": 9,
      "np.int": 7,
      "'uint16'": 6,
      "np.float32": 6,
      "'int'": 5,
      "'float64'": 4,
      "np.bool": 2,
      "np.uint8": 1,
      "float": 1,
      "'int32'": 1,
      "'int8'": 1,
      "int": 1
    },
    "sklearn.linear_model._coordinate_descent.ElasticNet.__init__.alpha": {
      "1.0": 212,
      "0.0005": 66,
      "best_alpha": 31,
      "0.001": 22,
      "alpha": 15,
      "0.1": 15,
      "1": 13,
      "1.4": 9,
      "0.01": 9,
      "alpha1": 7,
      "0.0002": 6,
      "1e-06": 4,
      "EnetRegressor.best_params_['alpha']": 4,
      "0.0001": 4,
      "a": 3,
      "0.5": 3,
      "0.085": 3,
      "0.0002286518512853544": 2,
      "0.006": 2,
      "0": 2,
      "0.014": 2,
      "0.02": 2,
      "0.2": 1,
      "100": 1,
      "13": 1,
      "400": 1,
      "0.3": 1,
      "opt_params['alpha']": 1,
      "0.091": 1,
      "cv_model.alpha_": 1,
      "0.025": 1,
      "0.00065": 1,
      "_alpha": 1,
      "0.00048679709811971084": 1,
      "1.5": 1,
      "i": 1,
      "0.198": 1,
      "1.2": 1,
      "params['alpha']": 1,
      "0.3077": 1,
      "0.2426": 1,
      "0.04738": 1,
      "elastic_netcv.alpha_": 1,
      "0.009461323755890769": 1,
      "parameter[0]": 1,
      "0.0010936129372972772": 1,
      "0.0003": 1,
      "0.0005033042674715873": 1,
      "en_cv1.alpha_": 1,
      "en_cv2.alpha_": 1,
      "en_cv3.alpha_": 1,
      "0.00039": 1,
      "model_elnet.alpha_": 1
    },
    "sklearn.linear_model._coordinate_descent.ElasticNet.__init__.l1_ratio": {
      "0.5": 258,
      "0.1": 71,
      "0.9": 68,
      "l1s": 7,
      "0.8": 6,
      "EnetRegressor.best_params_['l1_ratio']": 4,
      "0": 4,
      "0.7": 4,
      "1": 3,
      "l1_ratio": 3,
      "0.01": 3,
      "0.75": 3,
      "l1r": 2,
      "0.001": 2,
      "0.6510386358323069": 2,
      "0.65": 2,
      "0.99999999": 2,
      "0.15": 2,
      "0.31": 1,
      "0.09": 1,
      "opt_params['l1_ratio']": 1,
      "0.25": 1,
      "0.33": 1,
      "0.66": 1,
      "cv_model.l1_ratio_": 1,
      "_l1_ratio": 1,
      "0.5791344072946181": 1,
      "0.3": 1,
      "elastic_netcv.l1_ratio_": 1,
      "best_ratio": 1,
      "parameter[1]": 1,
      "0.21322431030386174": 1,
      "0.8201479505715717": 1,
      "0.944": 1,
      "0.93": 1,
      "model_elnet.l1_ratio_": 1,
      "0.2": 1,
      "0.4": 1,
      "0.6": 1
    },
    "sklearn.linear_model._coordinate_descent.ElasticNet.__init__.precompute": {
      "False": 462,
      "True": 5
    },
    "sklearn.linear_model._coordinate_descent.ElasticNet.__init__.selection": {
      "'cyclic'": 451,
      "'random'": 16
    },
    "sklearn.linear_model._coordinate_descent.ElasticNet.__init__.tol": {
      "0.0001": 460,
      "0.001": 3,
      "0.11": 2,
      "1e-05": 1,
      "0.01": 1
    },
    "sklearn.metrics._ranking.roc_auc_score.average": {
      "'macro'": 8198,
      "'micro'": 63,
      "'weighted'": 21,
      "None": 6,
      "average": 6,
      "self.average": 3
    },
    "sklearn.ensemble._bagging.BaggingClassifier.predict.X": {
      "X_test": 24,
      "X_validate": 2,
      "test_X": 2,
      "te_X": 1,
      "train_X": 1,
      "test_X_": 1,
      "val_x": 1,
      "ds[feats]": 1,
      "X_test_val": 1,
      "test": 1,
      "X_check": 1,
      "X_val_scaled": 1,
      "test.drop(['Id'], axis=1)": 1,
      "x_valid": 1,
      "self.x_test": 1,
      "X_test_vec": 1,
      "test_df[features]": 1,
      "pX": 1,
      "tpX": 1,
      "ppX": 1,
      "selected_data_test": 1,
      "testx": 1,
      "test_cv": 1,
      "test_tv": 1,
      "df1": 1,
      "X_train": 1
    },
    "sklearn.cluster._kmeans.KMeans.__init__.init": {
      "'k-means++'": 900,
      "'random'": 19,
      "init": 5,
      "kmeans_pretrain.cluster_centers_[:, :2]": 1,
      "centers": 1,
      "start": 1,
      "pca.components_": 1
    },
    "sklearn.cluster._kmeans.KMeans.__init__.n_init": {
      "10": 851,
      "50": 20,
      "20": 18,
      "1": 16,
      "5": 9,
      "30": 4,
      "3": 3,
      "4": 2,
      "100": 2,
      "6": 1,
      "500": 1,
      "12": 1
    },
    "sklearn.cluster._kmeans.KMeans.__init__.tol": {
      "0.0001": 925,
      "1e-06": 1,
      "0.001": 1,
      "0.01": 1
    },
    "sklearn.cluster._kmeans.KMeans.__init__.verbose": {
      "0": 922,
      "1": 4,
      "verbose": 1,
      "True": 1
    },
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.tol": {
      "0.0001": 986,
      "0.001": 1,
      "0.0005": 1,
      "1e-07": 1
    },
    "sklearn.ensemble._weight_boosting.AdaBoostRegressor.__init__.random_state": {
      "None": 149,
      "42": 32,
      "seed": 12,
      "0": 8,
      "1": 7,
      "random_state": 6,
      "123": 3,
      "2019": 2,
      "40": 2,
      "11": 1,
      "369": 1,
      "520": 1,
      "7": 1,
      "24": 1,
      "5": 1,
      "SEED": 1,
      "3": 1,
      "456": 1,
      "789": 1,
      "17": 1,
      "10": 1
    },
    "sklearn.ensemble._weight_boosting.AdaBoostRegressor.__init__.n_estimators": {
      "50": 144,
      "100": 12,
      "5000": 12,
      "n_estimators": 10,
      "200": 6,
      "1000": 5,
      "300": 5,
      "500": 4,
      "5": 3,
      "10": 3,
      "20": 3,
      "ITERATIONS": 2,
      "80": 2,
      "25": 2,
      "971": 2,
      "400": 2,
      "n_trees": 2,
      "4000": 1,
      "13": 1,
      "estimator": 1,
      "num_trees": 1,
      "125": 1,
      "estimators": 1,
      "70": 1,
      "35": 1,
      "90": 1,
      "15": 1,
      "trial.suggest_int('n_estimators', 25, 100)": 1,
      "120": 1,
      "3000": 1,
      "2200": 1
    },
    "sklearn.ensemble._weight_boosting.AdaBoostRegressor.__init__.learning_rate": {
      "1.0": 180,
      "0.01": 17,
      "1": 7,
      "0.1": 7,
      "0.05": 5,
      "0.007": 2,
      "0.8": 2,
      "0.005": 2,
      "0.2": 2,
      "0.162163403819552": 2,
      "0.5": 2,
      "0.3": 1,
      "1.4": 1,
      "0.6": 1,
      "0.08": 1,
      "trial.suggest_uniform('learning_rate', 0.01, 1)": 1
    },
    "sklearn.ensemble._weight_boosting.AdaBoostRegressor.fit.X": {
      "X_train": 29,
      "x_train": 9,
      "X": 3,
      "train_x": 3,
      "train": 3,
      "xtrain": 2,
      "X_train_pc": 2,
      "X_train_ohe": 2,
      "train_data": 1,
      "train_x_2016": 1,
      "features_train": 1,
      "X_treino": 1,
      "train[features]": 1,
      "self.Xtrain": 1,
      "housing_prepared": 1,
      "new_train": 1,
      "xtsc": 1,
      "sxtr": 1,
      "x_trainFixed": 1,
      "x_train_imp": 1,
      "X_train_scaled": 1,
      "train_X": 1,
      "X_train_selected": 1,
      "train_no_na_encoded.values": 1,
      "data": 1,
      "x_tr": 1,
      "x0": 1,
      "train_feat": 1,
      "train_df": 1,
      "train_features": 1,
      "X_train1": 1,
      "X_train2": 1,
      "dat_train": 1
    },
    "sklearn.ensemble._weight_boosting.AdaBoostRegressor.fit.y": {
      "y_train": 42,
      "train_y": 4,
      "target": 4,
      "y": 3,
      "Y_train": 3,
      "ytrain": 2,
      "ytr": 2,
      "train_price": 1,
      "train_y_2016": 1,
      "targets_train": 1,
      "y_treino": 1,
      "Y": 1,
      "train['signal']": 1,
      "self.Ytrain": 1,
      "housing_labels": 1,
      "target_scaled": 1,
      "train_Y": 1,
      "np.log(Y.values)": 1,
      "y0": 1,
      "xtrain['target']": 1,
      "np.ravel(y_train)": 1,
      "train_targets": 1,
      "y_train1": 1,
      "y_train2": 1,
      "tar_train": 1
    },
    "sklearn.ensemble._weight_boosting.AdaBoostRegressor.predict.X": {
      "X_test": 11,
      "x_test": 5,
      "test": 4,
      "X_val": 3,
      "train_data": 2,
      "test_data": 2,
      "x_val": 2,
      "xtest": 2,
      "X_test_pc": 2,
      "test_x": 2,
      "X_val_ohe": 2,
      "ada_test_df[features]": 1,
      "test_x_2016": 1,
      "x_train": 1,
      "features_test": 1,
      "X_teste": 1,
      "Xtest": 1,
      "test[features]": 1,
      "self.Xtest": 1,
      "housing_prepared": 1,
      "new_test_scaled": 1,
      "xtsc": 1,
      "sxtr": 1,
      "valid_x": 1,
      "test_X": 1,
      "X_valid": 1,
      "test_df": 1,
      "x_testFixed": 1,
      "x_test_imp": 1,
      "X_test_selected": 1,
      "x_tr": 1,
      "x_va": 1,
      "x1": 1,
      "test_vectors": 1,
      "X_train": 1,
      "pca_test_dataset": 1,
      "test_features": 1,
      "dat_valid": 1,
      "dat_train": 1,
      "X": 1
    },
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.token_pattern": {
      "'(?u)\\\\b\\\\w\\\\w+\\\\b'": 2488,
      "'\\\\w{1,}'": 459,
      "'\\\\w+'": 87,
      "'(?u)\\\\b\\\\w+\\\\b'": 62,
      "None": 24,
      "'(?u)\\\\w+|[^\\\\w\\\\s]'": 20,
      "'\\\\w{2,}'": 10,
      "'.+'": 10,
      "'\\\\d+'": 6,
      "'\\\\S+'": 5,
      "'(\\\\S+)'": 4,
      "'[a-zA-Z]+'": 4,
      "\"'name': '(.*?)'\"": 4,
      "'[\\\\w@]{1,}'": 3,
      "'\\\\w{16,}'": 3,
      "'(\\\\w+?)(?:,\\\\s|\\\\s|$)'": 2,
      "'\\\\b[\\\\w ]+\\\\b'": 2,
      "'(?u)\\\\b[A-Za-z]{3,}\\\\b'": 2,
      "'\\\\w{3,}'": 2,
      "'(?u)\\x08\\\\w\\\\w+\\x08'": 2,
      "tokens": 2,
      "'(?u)\\\\b\\\\w\\\\w+\\\\b\\\\w{,1}'": 2,
      "'[a-zA-Z]{1,}'": 1,
      "'(?u)\\\\b\\\\w\\\\w*\\\\b'": 1,
      "'[a-zA-Z]{2,20}'": 1,
      "'[\\\\w`]+'": 1,
      "'\\\\b[a-zA-Z]\\\\w+\\\\b'": 1,
      "'\\\\w{4,}'": 1,
      "\"\\\\b\\\\w[\\\\w']+\\\\b\"": 1,
      "'(?u)\\\\b(?:\\\\w\\\\w+)|(?:\\\\d+\\\\.|/\\\\d+)\\\\b'": 1,
      "'(?u)\\\\b[A-Za-z]+\\\\b'": 1,
      "'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b'": 1,
      "'[0-9a-z_\\\\$\\\\+]{1,}'": 1,
      "'[A-Za-z]+'": 1
    },
    "sklearn.feature_extraction.text.CountVectorizer.__init__.token_pattern": {
      "'(?u)\\\\b\\\\w\\\\w+\\\\b'": 2585,
      "'.+'": 133,
      "'\\\\w{1,}'": 48,
      "'(?u)\\\\w+|[^\\\\w\\\\s]'": 48,
      "'\\\\d+'": 46,
      "'\\\\w+'": 14,
      "'(?u)\\\\b\\\\w+\\\\b'": 12,
      "'\\\\w+|\\\\,'": 5,
      "token_pattern": 5,
      "'\\\\b[a-zA-Z]{3,}\\\\b'": 5,
      "'\\\\S+'": 4,
      "None": 4,
      "'[a-zA-Z0-9\\\\-\\\\.:_]+'": 4,
      "'https?://\\\\S+'": 3,
      "'[^/]+'": 3,
      "'\\\\b\\\\w+\\\\b'": 2,
      "pattern": 2,
      "'r\\\\w{1,}'": 1,
      "'\\\\w{2,}'": 1,
      "'(.+?)(?:,\\\\s|$)'": 1,
      "'(\\\\w+?)(?:,\\\\s|\\\\s|$)'": 1,
      "\"\\\\w{1,}'?[t]?\"": 1,
      "'[\\\\w`]+'": 1,
      "'(?u)\\\\b(?:\\\\w\\\\w+)|(?:\\\\d+\\\\.|/\\\\d+)\\\\b'": 1,
      "'\\\\w{3,}'": 1,
      "'(?u)\\\\b\\\\w+\\\\b|\\\\,|\\\\.|\\\\;|\\\\:'": 1,
      "'[a-zA-Z0-9\\\\-\\\\.:]+'": 1,
      "tks": 1,
      "'\\\\w\\\\w+|!|\\\\?|#|@'": 1,
      "'\\\\w{3,10}'": 1,
      "'[a-z|A-Z|**]{3,10}'": 1
    },
    "sklearn.decomposition._truncated_svd.TruncatedSVD.transform.X": {
      "test": 77,
      "X_test": 47,
      "train_tfidf": 43,
      "test_tfidf": 43,
      "X": 41,
      "xtrain_tfv": 17,
      "xvalid_tfv": 16,
      "test_data": 13,
      "test_df": 6,
      "tfquestion_body_test": 5,
      "tfanswer_test": 5,
      "tfidf_question_title_test": 5,
      "tfidf_question_body_test": 5,
      "tfidf_answer_test": 5,
      "question_title_test": 5,
      "question_body_test": 5,
      "answer_test": 5,
      "test[col]": 5,
      "vectorizer.transform(df_test.description)": 5,
      "tfquestion_title_test": 4,
      "X_tfv": 4,
      "df_num": 4,
      "vectorizer.transform(df_val.description)": 4,
      "train": 3,
      "test_x_tfidf": 3,
      "X_train": 3,
      "embeddings": 3,
      "desc": 2,
      "tfidf_col": 2,
      "temp_tfidf": 2,
      "x_train": 2,
      "x_test": 2,
      "train_vectors": 2,
      "test_vectors": 2,
      "x_test_tfidf": 2,
      "X_train_tfv": 2,
      "X_test_tfv": 2,
      "transform_data": 2,
      "V": 2,
      "X_train_feats": 2,
      "s_data": 2,
      "t_data": 2,
      "train_count.asfptype()": 2,
      "test_count.asfptype()": 2,
      "train_tfidf.asfptype()": 2,
      "test_tfidf.asfptype()": 2,
      "testDtm": 2,
      "xtrain_ctv": 2,
      "xvalid_ctv": 2,
      "title_vec_test": 1,
      "question_vec_test": 1,
      "answer_vec_test": 1,
      "trainig[trainig.columns[2:]]": 1,
      "testing[testing.columns[1:]]": 1,
      "TestMatrix": 1,
      "y": 1,
      "ts_X": 1,
      "X_test_tfidf": 1,
      "features_test.drop('PetID', axis=1)": 1,
      "features_test_dense.drop('PetID', axis=1)": 1,
      "test_result_df.drop(['PetID'], axis=1)": 1,
      "df_tfidf": 1,
      "onehot_df": 1,
      "desc_tfidf_all_te": 1,
      "join_te": 1,
      "train_x_tfidf": 1,
      "X_breeds_transformed": 1,
      "features_df.loc[pet_ids_or_filenames, :]": 1,
      "corpus_transformed": 1,
      "test_X[col]": 1,
      "tfidf.transform(test_df[col])": 1,
      "tfidf_vector": 1,
      "qs_tfidf": 1,
      "tfidf_vectorizer.transform([q_p])": 1,
      "word_eval_mid": 1,
      "word_test_mid": 1,
      "word_eval_rare": 1,
      "word_test_rare": 1,
      "x_valid": 1,
      "final_test_tfidf": 1,
      "X_test_text": 1,
      "freq_matrix": 1,
      "test2": 1,
      "transformed": 1,
      "trainSVD": 1,
      "testSVD": 1,
      "txt_trasf": 1,
      "des_trasf": 1,
      "jlad_trasf": 1,
      "x_train_copy": 1,
      "x_test_copy": 1,
      "data": 1,
      "X_test_feats": 1,
      "test_vec": 1,
      "X_tr_names": 1,
      "X_te_names": 1,
      "vectorizer.transform(test.Description.fillna(''))": 1,
      "X_Test": 1,
      "desc_X_train": 1,
      "desc_X_test": 1,
      "train_des_tfidf": 1,
      "test_des_tfidf": 1,
      "train_title_tfidf": 1,
      "test_title_tfidf": 1,
      "test.drop(['y'], axis=1)": 1,
      "test[kolom]": 1,
      "test_idf": 1,
      "cv[list_test[index]]": 1,
      "X_tfidf": 1,
      "X_tfidf_test": 1,
      "des_tfidf": 1,
      "title_tfidf": 1,
      "train_count": 1,
      "test_count": 1,
      "new_embed[new_vocab_indexes]": 1,
      "question_title_bov_test": 1,
      "question_bov_test": 1,
      "answer_bov_test": 1,
      "test_question_title_doc": 1,
      "test_question_body_doc": 1,
      "test_answer_doc": 1,
      "xtrain_tfidf": 1,
      "xvalid_tfidf": 1,
      "xcvalid_tfv": 1,
      "xtest_tfv": 1,
      "standardized_test": 1,
      "testf": 1,
      "allrIdy": 1,
      "Q": 1,
      "test_x_cv": 1,
      "tfidf_output_csr": 1,
      "_x_test": 1,
      "bow_x_train": 1,
      "bow_x_test": 1,
      "prof_dtm": 1,
      "val_X_cv": 1,
      "val_X_tfv": 1,
      "vectorizer.transform(df_train.description)": 1
    },
    "sklearn.svm._classes.SVC.__init__.probability": {
      "False": 1273,
      "True": 402
    },
    "sklearn.metrics._scorer.make_scorer.greater_is_better": {
      "False": 423,
      "True": 377
    },
    "sklearn.metrics._scorer.make_scorer.needs_proba": {
      "False": 735,
      "True": 65
    },
    "sklearn.metrics._scorer.make_scorer.score_func": {
      "fmean_squared_error": 215,
      "rmsle": 59,
      "roc_auc_score": 50,
      "f1_score": 43,
      "quadratic_weighted_kappa": 41,
      "mean_squared_error": 32,
      "accuracy_score": 30,
      "cohen_kappa_score": 24,
      "mean_absolute_error": 22,
      "flog_loss": 18,
      "multiclass_logloss": 16,
      "log_loss": 16,
      "r2_score": 13,
      "Gini": 11,
      "normalized_gini": 10,
      "rmse": 9,
      "mean_squared_log_error": 6,
      "gini_normalized": 6,
      "scoring_roc_auc": 5,
      "metrics.accuracy_score": 5,
      "fbeta_score": 5,
      "spearman_corr": 4,
      "metric": 4,
      "ndcg_score": 4,
      "RMSE": 4,
      "median_absolute_error": 4,
      "rmspe": 3,
      "MAPE": 3,
      "smape": 3,
      "performance_metric": 3,
      "neg_rmsle": 3,
      "kappa_score": 3,
      "my_scorer": 3,
      "precision_score": 3,
      "recall_score": 3,
      "scorer_func": 3,
      "RMSLE": 3,
      "func_metric": 3,
      "matthews_corrcoef": 3,
      "neg_rmspe": 3,
      "msle": 3,
      "score_func": 2,
      "WMAE": 2,
      "log_mae": 2,
      "gini_sklearn": 2,
      "baseline_loss_metric": 2,
      "rmsle_score": 2,
      "kappa": 2,
      "rmse_fun": 2,
      "gini_normalized_score": 2,
      "rmse_score": 2,
      "average_precision_score": 2,
      "score": 2,
      "scorer": 2,
      "metrics.roc_auc_score": 2,
      "mcrmse_loss": 2,
      "lambda y_test, predictions: np.sqrt(mean_squared_error(y_test, predictions))": 2,
      "model_metric": 2,
      "robust_roc_auc_score": 2,
      "custom_scorer": 2,
      "RMSLError": 2,
      "metrics.mean_squared_error": 2,
      "metrics.f1_score": 2,
      "logged_rmsle": 1,
      "moa_metric": 1,
      "weighted_mae_custom": 1,
      "log_loss_wrapper": 1,
      "cls.quadratic_weighted_kappa": 1,
      "scorer_helper": 1,
      "rmse_func": 1,
      "nrmse": 1,
      "lambda y_true, y_pred: laplace_log_likelihood(y_true, y_pred, 210)": 1,
      "root_mean_squared_error": 1,
      "measure_performance": 1,
      "sk.metrics.log_loss": 1,
      "qwk_score": 1,
      "wmae_train": 1,
      "lambda y, y_pred: mean_squared_error(y, y_pred, squared=False)": 1,
      "qwk": 1,
      "rmsle_func": 1,
      "RMSLErelu": 1,
      "RMSLEabs": 1,
      "metric_aggregation": 1,
      "metrics": 1,
      "scorer_rmse": 1,
      "my_custom_loss_func": 1,
      "metrics.mean_absolute_error": 1,
      "utility_gain": 1,
      "explained_variance_score": 1,
      "WMAE_Func": 1,
      "WMAE_Func2": 1,
      "calc_RMSLE": 1,
      "the_score": 1,
      "my_own_score": 1,
      "metrics.log_loss": 1,
      "neg_rmlse": 1,
      "rmle": 1,
      "normalized_gini_score": 1,
      "rmsle_error": 1,
      "wmae": 1,
      "self.rmsle": 1,
      "MSE": 1,
      "_rmse": 1,
      "balanced_accuracy_score": 1,
      "lambda X, y: laplace_log_likelihood(X, y, sigma=sigma).numpy()": 1,
      "average_log_loss": 1,
      "root_mean_squared_log_error": 1,
      "two_score": 1,
      "gini_normalizedc": 1,
      "'roc_auc'": 1,
      "wmae_score": 1,
      "NegRMSE": 1,
      "svm_r2_score": 1,
      "mcc": 1,
      "log_rmse": 1,
      "rmspe_log1p": 1,
      "loss_func": 1,
      "custom_rmse": 1
    },
    "sklearn.model_selection._search.GridSearchCV.__init__.refit": {
      "True": 2693,
      "'True'": 20,
      "False": 9,
      "'AUC'": 4,
      "'Accuracy'": 3,
      "refit": 3,
      "opt_scoring": 3,
      "metric": 3,
      "'ftwo'": 3,
      "'roc_auc'": 2,
      "'f1_micro'": 2,
      "'R2'": 1,
      "get_best_qwk_params": 1,
      "'TRUE'": 1,
      "'f1_macro'": 1,
      "'accuracy'": 1,
      "'f1_score'": 1,
      "'r2'": 1
    },
    "sklearn.naive_bayes.MultinomialNB.__init__.alpha": {
      "1.0": 694,
      "alpha[best_alpha]": 39,
      "0.1": 29,
      "i": 23,
      "0.01": 22,
      "0.001": 20,
      "1": 17,
      "alpha": 12,
      "0.7": 7,
      "2.0": 5,
      "best_alpha": 4,
      "0.5": 4,
      "0.05": 3,
      "0.03": 3,
      "0.07": 2,
      "1.5": 2,
      "value": 2,
      "0.0001": 2,
      "0.6": 2,
      "1.6": 1,
      "0.08": 1,
      "alphas[k]": 1,
      "0.003": 1,
      "0": 1,
      "0.8": 1,
      "0.005": 1,
      "1.8": 1,
      "0.0003": 1,
      "1.3": 1,
      "nb_alpha": 1,
      "nb_alpha_opt": 1,
      "best_alpha_1_bow": 1,
      "0.3": 1,
      "0.35": 1,
      "2": 1,
      "0.09": 1
    },
    "sklearn.decomposition._truncated_svd.TruncatedSVD.__init__.n_iter": {
      "5": 909,
      "7": 23,
      "10": 17,
      "25": 17,
      "20": 9,
      "Gene_INPUT_DIM": 4,
      "100": 3,
      "6": 3,
      "n_ittr": 2,
      "500": 2,
      "30": 2,
      "n_iter": 1,
      "3": 1,
      "iters": 1,
      "40": 1,
      "15": 1
    },
    "sklearn.decomposition._truncated_svd.TruncatedSVD.fit_transform.X": {
      "train.drop(['y'], axis=1)": 61,
      "tfidf_col": 59,
      "X": 23,
      "features": 19,
      "train": 14,
      "sent_vectors": 14,
      "one_hot_gene.values": 7,
      "one_hot_variation.values": 7,
      "test_data": 6,
      "vz_sample": 6,
      "data[GENES]": 6,
      "data[CELLS]": 6,
      "data_X": 6,
      "tfquestion_title": 5,
      "tfquestion_body": 5,
      "tfanswer": 5,
      "X_train": 5,
      "tfidf_question_title": 5,
      "tfidf_question_body": 5,
      "tfidf_answer": 5,
      "small_document_term_matrix": 5,
      "question_title": 5,
      "question_body": 5,
      "answer": 5,
      "train[col]": 5,
      "concat_df[features]": 5,
      "data": 4,
      "vectorizer.transform(df_train.description)": 4,
      "sparse_matrix": 3,
      "vector": 3,
      "X_tfidf": 3,
      "X_tfidf_text": 3,
      "e_.fillna(0)": 3,
      "X_std": 3,
      "tfidf": 3,
      "fboth": 3,
      "df_norm": 3,
      "questionI_tfidf": 3,
      "questionD_tfidf": 3,
      "train_features": 2,
      "test_features": 2,
      "user_product_sparse": 2,
      "df[feat_cols].values": 2,
      "data[cols]": 2,
      "tfidf.transform(trainText2)": 2,
      "combined.clip(0).T": 2,
      "matrix": 2,
      "train_df": 2,
      "tfidfeats": 2,
      "tfidfeats2": 2,
      "x_train": 2,
      "p_train": 2,
      "d_train": 2,
      "p_test": 2,
      "d_test": 2,
      "bag_of_words": 2,
      "x_train_tfidf": 2,
      "vz": 2,
      "CSR[idx][:, feats]": 2,
      "matrixTFIDF": 2,
      "e_": 2,
      "question1_tfidf": 2,
      "question2_tfidf": 2,
      "trainDtm": 2,
      "train_df.drop(['y'], axis=1)": 2,
      "summary_df_tfidf": 2,
      "train_x_tfidf_full": 2,
      "tf_matrix": 2,
      "total": 1,
      "title_vec_train": 1,
      "question_vec_train": 1,
      "answer_vec_train": 1,
      "x_train_tfidf_vec": 1,
      "x_test_tfidf_vec": 1,
      "descriptions": 1,
      "TrainMatrix": 1,
      "tv_feats": 1,
      "hv_features": 1,
      "generated_raw_data": 1,
      "generated_raw_cat_data": 1,
      "vecText": 1,
      "X[genes]": 1,
      "X[cells]": 1,
      "tr_X": 1,
      "features_train.drop('PetID', axis=1)": 1,
      "features_train_dense.drop('PetID', axis=1)": 1,
      "result_df.drop(['PetID', 'AdoptionSpeed'], axis=1)": 1,
      "emb_feat": 1,
      "desc_tfidf_all_tr": 1,
      "join_tr": 1,
      "images": 1,
      "diff_combined.T": 1,
      "np.concatenate([train_x_image_array, test_x_image_array], axis=0)": 1,
      "h_sent": 1,
      "train_X[col]": 1,
      "train1": 1,
      "test1": 1,
      "tr": 1,
      "tfidf.transform(train_df[col])": 1,
      "X_features_std": 1,
      "data_scaler": 1,
      "desc_embd": 1,
      "X_descp": 1,
      "df[col_list]": 1,
      "X_w2v": 1,
      "fulldf_word_features": 1,
      "text_data": 1,
      "words_vectors": 1,
      "word_train_mid": 1,
      "word_train_rare": 1,
      "text_data_tfidf": 1,
      "X_train_text": 1,
      "sentence_vectors": 1,
      "train2": 1,
      "train_vect": 1,
      "test_vect": 1,
      "vec_arr": 1,
      "tf_idf": 1,
      "breed_text": 1,
      "doctopic": 1,
      "cat_transformed": 1,
      "X_train_sc": 1,
      "vectors": 1,
      "train_features_tfidf": 1,
      "test_features_tfidf": 1,
      "tfidf_features": 1,
      "count_features": 1,
      "x": 1,
      "train_vec": 1,
      "gp_dense_first.drop(['PetID'], axis=1)": 1,
      "df": 1,
      "vectorizer.fit_transform(train.Description.fillna(''))": 1,
      "embeddings": 1,
      "fnc": 1,
      "train_df.drop(['isFraud'], axis=1)": 1,
      "normalized(datatot)": 1,
      "totaal": 1,
      "X - Eupdate + 1 / mu * Y": 1,
      "PolQ": 1,
      "X.T": 1,
      "Normalizer().fit_transform(e_)": 1,
      "train[kolom]": 1,
      "dfidf": 1,
      "dfidfw": 1,
      "questionQ1D_tfidf": 1,
      "questionQ2D_tfidf": 1,
      "train_idf": 1,
      "cv[list_train[index]]": 1,
      "mod_TD": 1,
      "train.drop([target_col], axis=1)": 1,
      "tfquestion_title_test": 1,
      "embedding_matrix[new_vocab_indexes]": 1,
      "question_title_bov": 1,
      "question_bov": 1,
      "answer_bov": 1,
      "train_question_title_doc": 1,
      "train_question_body_doc": 1,
      "train_answer_doc": 1,
      "a": 1,
      "tfidf_weights": 1,
      "tfidf_obj": 1,
      "test": 1,
      "standardized_train": 1,
      "f": 1,
      "train_tfidf": 1,
      "test_tfidf": 1,
      "train_name_tfidf": 1,
      "test_name_tfidf": 1,
      "description_text": 1,
      "df[train_columns]": 1,
      "combined_data": 1,
      "text": 1,
      "train_x_cv": 1,
      "cv_df": 1,
      "X_train.values": 1,
      "_x_train": 1,
      "image": 1,
      "image_test": 1,
      "train[cols]": 1,
      "train_X_cv": 1,
      "train_X_tfv": 1,
      "res50_array": 1,
      "res34_array": 1,
      "dense121_array": 1,
      "dense_array": 1,
      "np.hstack([res50_array, dense_array, dense121_array, res34_array])": 1,
      "df_con": 1,
      "data_tfidf": 1
    },
    "sklearn.multioutput.MultiOutputRegressor.__init__.estimator": {
      "xgb.XGBRegressor()": 3,
      "base_model": 3,
      "xgb": 3,
      "model.predict(x_test)": 3,
      "xgbrModel": 2,
      "KNeighborsRegressor()": 2,
      "GradientBoostingRegressor(random_state=1)": 2,
      "RandomForestRegressor(n_estimators=100, max_depth=max_depth, random_state=0)": 2,
      "xgr_mae": 2,
      "linear_regressor_2": 2,
      "LinearRegression()": 2,
      "estimator": 2,
      "linear_model.BayesianRidge(n_iter=10000)": 2,
      "LGBMRegressor(boosting_type='gbdt', num_leaves=31, max_depth=5, learning_rate=0.1, n_estimators=100, min_child_samples=20, subsample=0.8, subsample_freq=0, colsample_bytree=0.8, reg_alpha=1.0, reg_lambda=1.0, random_state=42, silent=False)": 1,
      "bt": 1,
      "svr": 1,
      "BayesianRidge(normalize=True)": 1,
      "ridge": 1,
      "GradientBoostingRegressor(n_estimators=5)": 1,
      "AdaBoostRegressor(n_estimators=5)": 1,
      "tf_estimator": 1,
      "GradientBoostingRegressor(random_state=0)": 1,
      "LinearRegression(n_jobs=1)": 1,
      "DecisionTreeRegressor(max_depth=50, random_state=1)": 1,
      "RandomForestRegressor(n_estimators=50, max_depth=3, random_state=43, min_samples_split=10)": 1,
      "clf_cbr": 1,
      "lgb.LGBMRegressor(random_state=i * 101)": 1,
      "RandomForestRegressor(max_depth=6, n_estimators=200, criterion='mse', oob_score=True)": 1,
      "RidgeCV(alphas=alphas)": 1,
      "LassoCV(alphas=None, cv=10)": 1,
      "ElasticNet(alpha=0.01, l1_ratio=0.5)": 1,
      "RandomForestRegressor(max_depth=2, random_state=0)": 1,
      "AdaBoostRegressor(random_state=0, n_estimators=100)": 1,
      "SVR(C=1.0, epsilon=0.2)": 1,
      "DecisionTreeRegressor(max_depth=3, random_state=0)": 1,
      "xgb_model": 1,
      "DecisionTreeRegressor()": 1,
      "XGBRegressor(n_estimators=1500, max_depth=20, random_state=0)": 1,
      "model": 1,
      "XGBRegressor(n_estimators=estimator, random_state=0, max_depth=20)": 1,
      "XGBRegressor(n_estimators=estimator, random_state=42, max_depth=40)": 1,
      "reg": 1,
      "XGBRegressor()": 1,
      "AdaBoostRegressor(random_state=17)": 1,
      "xgb.XGBRegressor(random_state=17)": 1,
      "AdaBoostRegressor()": 1,
      "LinearSVC()": 1,
      "LogisticRegression(solver='lbfgs')": 1,
      "VotingClassifier(estimators=[('lr', clf1), ('rf', clf2)], voting='hard')": 1,
      "GradientBoostingRegressor(n_estimators=50)": 1,
      "lightgbm.LGBMRegressor()": 1,
      "xgb.XGBRegressor(n_estimators=100)": 1,
      "LinearSVR(random_state=1)": 1,
      "HistGradientBoostingRegressor(random_state=1, max_iter=10000)": 1,
      "linear_model.LinearRegression()": 1,
      "lgb.LGBMRegressor(num_leaves=100, max_depth=-1, n_estimators=200, learning_rate=0.01)": 1,
      "HistGradientBoostingRegressor(max_iter=1750, max_depth=15, early_stopping=True, n_iter_no_change=10, learning_rate=0.0025, tol=1e-06, validation_fraction=0.2, verbose=2, max_leaf_nodes=64)": 1,
      "GradientBoostingRegressor(loss='huber', n_estimators=1000, max_depth=15, learning_rate=0.0025, tol=1e-07, validation_fraction=0.2, n_iter_no_change=15, verbose=2)": 1,
      "RandomForestRegressor(n_estimators=100, random_state=1)": 1,
      "model1": 1,
      "model2": 1,
      "VotingRegressor([('lg', model2), ('CAT', model1), ('RF', RF)])": 1,
      "RandomForestRegressor(n_estimators=98, max_depth=max_depth, random_state=0)": 1,
      "DecisionTreeRegressor(min_samples_split=3, max_depth=max_depth, min_samples_leaf=3)": 1
    },
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.min_impurity_decrease": {
      "0.0": 5145,
      "0.001": 23,
      "0.0001": 3,
      "trial.suggest_float('min_impurity_decrease', 0.0, 0.2)": 2,
      "1e-06": 2,
      "3e-07": 1,
      "0.01122129357981094": 1,
      "0.00010583321874846287": 1,
      "0.004519625185607378": 1,
      "0.0007": 1
    },
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.min_impurity_split": {
      "None": 5178,
      "1e-07": 2
    },
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.min_weight_fraction_leaf": {
      "0.0": 5165,
      "0.1": 9,
      "0": 2,
      "1e-10": 2,
      "0.0001": 1,
      "0.001": 1
    },
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.warm_start": {
      "False": 5156,
      "True": 22,
      "trial.suggest_categorical('warm_start', [True, False])": 2
    },
    "sklearn.model_selection._validation.cross_val_predict.verbose": {
      "0": 194,
      "2": 7,
      "1": 6,
      "3": 4,
      "5": 1,
      "VERBOSE": 1,
      "verbose": 1
    },
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.random_state": {
      "None": 143,
      "42": 32,
      "0": 31,
      "1": 6,
      "Seed": 6,
      "5": 5,
      "RS": 5,
      "seed": 4,
      "666": 4,
      "RANDOM_SEED": 3,
      "self.random_state": 2,
      "2020": 2,
      "12": 2,
      "random_state": 2,
      "RANDOM_STATE": 2,
      "seed_gm + i": 2,
      "66": 2,
      "seeds[m - start_components]": 1,
      "best_seed": 1,
      "123": 1,
      "1196": 1,
      "69": 1,
      "17": 1,
      "3": 1,
      "2": 1,
      "12345": 1,
      "43": 1,
      "44": 1,
      "SEED": 1,
      "random_seed": 1
    },
    "sklearn.cluster._birch.Birch.__init__.n_clusters": {
      "NK": 12,
      "n_clusters": 6,
      "3": 5,
      "2": 4,
      "None": 3,
      "14": 1,
      "4": 1,
      "N_CLUSTERS": 1,
      "25": 1,
      "7": 1
    },
    "sklearn.cluster._birch.Birch.fit.X": {
      "coords": 6,
      "x": 1,
      "x1": 1,
      "x2": 1,
      "x3": 1,
      "x4": 1,
      "x5": 1,
      "x6": 1,
      "x7": 1,
      "x8": 1,
      "x9": 1,
      "x10": 1,
      "x11": 1,
      "x12": 1,
      "x13": 1,
      "x14": 1,
      "x15": 1,
      "x16": 1,
      "x17": 1,
      "x18": 1,
      "x19": 1,
      "x20": 1,
      "x21": 1,
      "x22": 1,
      "x23": 1,
      "x24": 1,
      "x25": 1,
      "x26": 1,
      "x27": 1,
      "x28": 1,
      "x29": 1,
      "x30": 1,
      "x31": 1,
      "x32": 1,
      "x33": 1,
      "x34": 1,
      "train.drop(['id', 'target'], axis=1).iloc[:len(train) * 8 // 10]": 1,
      "train.drop(['id', 'target'], axis=1)": 1,
      "concat": 1,
      "concat[['pickup_latitude', 'pickup_longitude']]": 1,
      "concat[['dropoff_latitude', 'dropoff_longitude']]": 1,
      "X": 1
    },
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.bootstrap": {
      "False": 700,
      "True": 33
    },
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.class_weight": {
      "None": 710,
      "'balanced'": 14,
      "'auto'": 4,
      "'balanced_subsample'": 3,
      "test_weight_map": 1,
      "class_weights": 1
    },
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.max_leaf_nodes": {
      "None": 732,
      "270": 1
    },
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.min_impurity_decrease": {
      "0.0": 728,
      "1e-07": 2,
      "0.0001": 1,
      "1e-10": 1,
      "1e-08": 1
    },
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.min_impurity_split": {
      "None": 733
    },
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.min_weight_fraction_leaf": {
      "0.0": 727,
      "1e-05": 4,
      "1e-10": 2
    },
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.oob_score": {
      "False": 721,
      "True": 12
    },
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.random_state": {
      "None": 448,
      "0": 70,
      "42": 35,
      "rnd": 30,
      "random_state": 19,
      "10": 19,
      "g['rs']": 18,
      "1": 12,
      "1729": 10,
      "seed": 9,
      "randomSeed": 9,
      "rand_state": 6,
      "14": 5,
      "12": 4,
      "123": 4,
      "SEED": 3,
      "314": 3,
      "1000": 3,
      "6713": 2,
      "5436": 2,
      "2": 2,
      "99": 1,
      "np.random.RandomState(1)": 1,
      "2018": 1,
      "11": 1,
      "202": 1,
      "201": 1,
      "369": 1,
      "5": 1,
      "rs": 1,
      "432": 1,
      "3": 1,
      "100": 1,
      "RS": 1,
      "random_seed": 1,
      "57": 1,
      "rnd_seed": 1,
      "RANDOM_STATE": 1,
      "20": 1,
      "8": 1,
      "13": 1
    },
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.verbose": {
      "0": 717,
      "1": 13,
      "3": 1,
      "True": 1,
      "2": 1
    },
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.warm_start": {
      "False": 731,
      "True": 2
    },
    "sklearn.feature_selection._from_model.SelectFromModel.fit.X": {
      "X": 18,
      "X_train": 13,
      "scaler.transform(X_train)": 8,
      "x_t": 4,
      "X_norm": 4,
      "data[feature_columns]": 4,
      "x_train": 2,
      "train": 2,
      "scaler.transform(X_train.fillna(0))": 2,
      "X_train.fillna(0)": 2,
      "X_transf": 2,
      "stage_1[objs]": 1,
      "X.drop(columns=['TransactionID', 'TransactionDT'])": 1,
      "x": 1,
      "X_f_train": 1,
      "inpX": 1,
      "train_feature": 1,
      "scaler.transform(x_train.fillna(0))": 1,
      "X_to_select": 1,
      "final_df": 1,
      "xtrain": 1,
      "new_train_dataset": 1,
      "features": 1,
      "dfe": 1,
      "X_prepared": 1,
      "train_x_std_scalled": 1
    },
    "sklearn.feature_selection._from_model.SelectFromModel.fit.y": {
      "y_train": 24,
      "y": 16,
      "Y_train": 7,
      "Y": 4,
      "y_t": 4,
      "data.type": 4,
      "y_cases": 2,
      "y_fatal": 2,
      "y_1": 1,
      "y_f_train": 1,
      "train_labels": 1,
      "inpy": 1,
      "train_target": 1,
      "y_to_select": 1,
      "y_train['surface']": 1,
      "y_tr": 1,
      "labels.values.ravel()": 1,
      "label": 1,
      "target_fe": 1,
      "Y1": 1,
      "train_y": 1
    },
    "sklearn.model_selection._validation.cross_val_predict.method": {
      "'predict'": 159,
      "'predict_proba'": 48,
      "'decision_function'": 6,
      "method": 1
    },
    "sklearn.metrics._ranking.precision_recall_curve.y_true": {
      "y_test": 27,
      "y_true[:, class_i]": 24,
      "y_true": 16,
      "y_train": 10,
      "y_": 9,
      "y_real": 8,
      "y": 7,
      "labels": 6,
      "Y_train": 5,
      "error_df.true_class": 5,
      "TARGET": 5,
      "train_label": 4,
      "test_labels": 4,
      "train_df.iloc[valid_idx][target].values": 4,
      "y_valid[:, 1]": 3,
      "val_targ[:, i]": 3,
      "val_targ.ravel()": 3,
      "y_valid": 3,
      "y_val": 2,
      "Y_valid": 2,
      "target": 2,
      "true": 2,
      "y.iloc[val_idx].values": 2,
      "error_df.True_class": 2,
      "target[val_idx]": 2,
      "targets_val": 2,
      "df_y_valid": 1,
      "val_targets": 1,
      "y_valid_l": 1,
      "label >= threshold": 1,
      "y_test[:, i]": 1,
      "y_test.ravel()": 1,
      "y['test']": 1,
      "y3_valid": 1,
      "y_label.values": 1,
      "titanic_labels": 1,
      "valid_y[:, i]": 1,
      "y_train_4": 1,
      "val_labels.values": 1,
      "result_flg": 1,
      "train_y": 1,
      "original_ytest": 1,
      "ts": 1,
      "Ytest": 1,
      "y_target": 1,
      "error_df.Converted": 1,
      "test_Y": 1,
      "preds['trueLabel']": 1,
      "np.where(y_true >= 0.5, 1, 0)": 1,
      "cls_labels": 1,
      "y_true[:, i]": 1,
      "y_true2[:, i]": 1,
      "y_true2.ravel()": 1,
      "y[val_idx, 4]": 1,
      "y_t": 1,
      "y_train[v_idx]": 1,
      "Y_ValidData": 1,
      "lb": 1,
      "Y_test": 1,
      "Y2_test": 1,
      "y_list": 1,
      "test_y": 1,
      "train_eval['signal']": 1,
      "y_is9_validation": 1,
      "val_targets[:, i]": 1
    },
    "sklearn.metrics._ranking.precision_recall_curve.probas_pred": {
      "y_proba": 24,
      "y_pred[:, class_i]": 24,
      "cv.best_estimator_.predict_proba(X_test)[:, 1]": 10,
      "oof_preds_": 9,
      "y_scores": 9,
      "y_pred": 7,
      "error_df.reconstruction_error": 6,
      "predictions": 5,
      "Y_train_pred[:, 1]": 4,
      "oof_preds": 4,
      "predict_proba[:, 1]": 4,
      "oof[valid_idx]": 4,
      "train_pred_prob": 4,
      "y_scores_rf": 3,
      "y_prob_val[:, 1]": 3,
      "val_preds[:, i]": 3,
      "val_preds.ravel()": 3,
      "probs": 3,
      "scores": 2,
      "Y_valid_pred[:, 1]": 2,
      "pred_probas": 2,
      "y_oof[val_idx]": 2,
      "error_df.Reconstruction_error": 2,
      "oof[val_idx]": 2,
      "y_pred[:, 1]": 2,
      "y_score": 2,
      "y_svc": 1,
      "y_pred_score": 1,
      "y_train_probs[:, 1]": 1,
      "y_val_probs[:, 1]": 1,
      "val_predictions[:, 0]": 1,
      "valid_preds_lgb": 1,
      "predict": 1,
      "y_score[:, i]": 1,
      "y_score.ravel()": 1,
      "pred_proba_c1": 1,
      "y_predict_proba['test']": 1,
      "y3_pred": 1,
      "y_proba_pred": 1,
      "prediction_scores": 1,
      "preds": 1,
      "logipp[:, 1]": 1,
      "knnpp[:, 1]": 1,
      "DTCpp[:, 1]": 1,
      "rmpp[:, 1]": 1,
      "preds[:, i]": 1,
      "network_pred": 1,
      "y_predict": 1,
      "log_reg_pred": 1,
      "undersample_y_score": 1,
      "train_predict_prob[:, 1]": 1,
      "ys": 1,
      "val": 1,
      "y_pred_proba_df": 1,
      "y_predicted": 1,
      "probs[:, 1]": 1,
      "clf.predict_proba(X_test)[:, 1]": 1,
      "yhat_probs": 1,
      "predicted_proba[:, -1]": 1,
      "train_prob_nn": 1,
      "preds['anomalyScore']": 1,
      "cls_preds": 1,
      "pred": 1,
      "y_pred[:, i]": 1,
      "y_pred2[:, i]": 1,
      "y_pred2.ravel()": 1,
      "oof_weighted_resp": 1,
      "oof_zero": 1,
      "oof_probas[val_idx, 4]": 1,
      "y_p": 1,
      "Predict_ValidData": 1,
      "y_probability[:, 1]": 1,
      "op": 1,
      "y_pred_proba": 1,
      "y_score_rf": 1,
      "y_score_rf2": 1,
      "grid.best_estimator_.decision_function(X_test)": 1,
      "y_pred_prob_logreg_class1": 1,
      "predict[:, 1]": 1,
      "pred_binary": 1,
      "train_eval_probs": 1,
      "val_probs[:, i]": 1
    },
    "sklearn.decomposition._truncated_svd.TruncatedSVD.__init__.algorithm": {
      "'randomized'": 915,
      "'arpack'": 79,
      "algorithm": 2
    },
    "sklearn.decomposition._sparse_pca.SparsePCA.__init__.n_components": {
      "2": 6,
      "n_comp": 2,
      "3": 1,
      "embedding_comps": 1,
      "n_col": 1
    },
    "sklearn.decomposition._sparse_pca.SparsePCA.__init__.random_state": {
      "42": 7,
      "420": 2,
      "None": 2
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.learning_rate": {
      "0.1": 673,
      "0.05": 46,
      "0.01": 40,
      "1.0": 23,
      "0.5": 13,
      "0.3": 12,
      "1": 9,
      "learning_rate": 5,
      "0.005": 5,
      "0.001": 5,
      "0.2": 4,
      "0.15": 3,
      "0.03": 2,
      "0.095": 2,
      "k": 2,
      "1.2": 2,
      "0.1058986682719916": 1,
      "0.26": 1,
      "0.256": 1,
      "search.best_params_['learning_rate']": 1,
      "eta": 1,
      "0.17": 1,
      "0.65": 1,
      "0.0018069834369607075": 1,
      "0.9": 1,
      "0.25": 1,
      "0.6": 1,
      "params['learning_rate']": 1,
      "0.12": 1,
      "0.08": 1,
      "0.02": 1,
      "best_params[1]": 1,
      "trial.suggest_float('learning_rate', 0.0001, 1, log=True)": 1,
      "0.06": 1,
      "0.3322": 1
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.loss": {
      "'deviance'": 851,
      "'exponential'": 12,
      "loss": 1,
      "best_params[0]": 1
    },
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.__init__.algorithm": {
      "'SAMME.R'": 503,
      "'SAMME'": 22,
      "gridcv.best_params_['algorithm']": 2
    },
    "sklearn.ensemble._bagging.BaggingClassifier.__init__.max_samples": {
      "1.0": 154,
      "0.5": 12,
      "0.8": 5,
      "0.1": 2,
      "5": 2,
      "0.98": 2,
      "0.3": 2,
      "0.2": 1,
      "20": 1,
      "10000": 1,
      "trial.suggest_float('max_samples', 0.2, 1.0)": 1,
      "max_samples_model_1": 1,
      "max_samples_model_3": 1,
      "max_samples_model_5": 1
    },
    "sklearn.ensemble._bagging.BaggingClassifier.__init__.max_features": {
      "1.0": 165,
      "0.5": 10,
      "0.8": 3,
      "0.7": 2,
      "5": 2,
      "0.25": 1,
      "0.2": 1,
      "30": 1,
      "0.95": 1
    },
    "sklearn.ensemble._bagging.BaggingClassifier.__init__.base_estimator": {
      "None": 77,
      "DecisionTreeClassifier()": 31,
      "KNeighborsClassifier()": 7,
      "cart": 7,
      "clf": 6,
      "base_estimator": 4,
      "neighbors.KNeighborsClassifier()": 3,
      "DecisionTreeClassifier(random_state=random_state)": 3,
      "LogisticRegression(random_state=1, n_jobs=-1)": 2,
      "tree.DecisionTreeClassifier(random_state=1)": 2,
      "lr": 2,
      "clf_qda": 2,
      "clf_knn": 2,
      "base_clf": 2,
      "rf": 2,
      "model_3": 2,
      "LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')": 2,
      "LogisticRegression(random_state=1)": 2,
      "BernoulliNB()": 2,
      "dt": 1,
      "LogisticRegression(C=0.1, penalty='l1', class_weight='balanced', solver='liblinear', random_state=0)": 1,
      "Classifier1": 1,
      "base_estimator_bag": 1,
      "LogisticRegression()": 1,
      "KNeighborsClassifier(n_neighbors=1)": 1,
      "KNeighborsClassifier(n_neighbors=3)": 1,
      "model_logit": 1,
      "Cat": 1,
      "SGDClassifier(random_state=42, alpha=0.01, l1_ratio=0.25, loss='log', penalty='elasticnet')": 1,
      "DecisionTreeClassifier(random_state=42, max_leaf_nodes=91, min_samples_leaf=7, min_weight_fraction_leaf=0.01)": 1,
      "make_pipeline(QuantileTransformer(**params_quantile), LogisticRegression(**params_logreg))": 1,
      "make_pipeline(QuantileTransformer(**params_quantile_second), LogisticRegression(**params_logreg_second))": 1,
      "svm.SVC(kernel='rbf')": 1,
      "dtclf": 1,
      "DecisionTreeClassifier(max_depth=max_depth)": 1,
      "dTree": 1,
      "GaussianNB(var_smoothing=1e-15)": 1,
      "knn3": 1,
      "lightgbm.LGBMClassifier(silent=False, class_weight='balanced', objective='binary')": 1,
      "ComplementNB()": 1,
      "LogisticRegression(C=0.1)": 1,
      "log_reg": 1,
      "svc_best": 1,
      "LogisticRegression(C=1.0)": 1,
      "knn": 1
    },
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit.X": {
      "X_train": 57,
      "x_train": 10,
      "pca_X_train": 2,
      "X": 2,
      "X_train_norm": 2,
      "X[train_index]": 2,
      "df_train[predictors]": 2,
      "X[:, i_cols_list]": 2,
      "X1_train": 1,
      "TrainData": 1,
      "Stacked": 1,
      "Xp_data_img": 1,
      "data": 1,
      "train_data": 1,
      "bert_selected_embed": 1,
      "total_df.values[train_idx]": 1,
      "X_train.todense()": 1,
      "X_train_ohe": 1,
      "self.x_train": 1,
      "train": 1,
      "X_train_sub": 1,
      "rescaledX": 1,
      "train_data[features]": 1,
      "tr_x": 1
    },
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit.y": {
      "y_train": 72,
      "Y_train": 4,
      "y": 3,
      "y[train_index]": 2,
      "train_y": 1,
      "Y": 1,
      "TrainLabel": 1,
      "train2.loc[test_index]['target']": 1,
      "data_y_train": 1,
      "target": 1,
      "train_label.values.ravel()": 1,
      "embed_target": 1,
      "labels": 1,
      "self.y_train": 1,
      "levels": 1,
      "Y_train_sub": 1,
      "train_data['action']": 1,
      "tr_y": 1
    },
    "sklearn.metrics._classification.multilabel_confusion_matrix.labels": {
      "None": 34,
      "lst_classes": 19,
      "y_unique": 2,
      "[0, 1, 2, 3, 4]": 1,
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]": 1
    },
    "sklearn.metrics._classification.multilabel_confusion_matrix.y_true": {
      "lst_actual_class": 19,
      "y_true": 10,
      "y_test": 6,
      "yval": 6,
      "y_val": 2,
      "test_lbls": 2,
      "val_targ": 2,
      "np.array(tl)": 2,
      "truth": 1,
      "valid_df['class_labels'][:928].to_list()": 1,
      "y_train": 1,
      "set_validacion_ordenado.classes": 1,
      "ytest": 1,
      "y_eval": 1,
      "actual": 1,
      "y_test_v": 1
    },
    "sklearn.metrics._classification.multilabel_confusion_matrix.y_pred": {
      "lst_predicted_class": 19,
      "y_pred": 14,
      "predictions": 5,
      "prediction": 3,
      "preds": 3,
      "val_preds": 2,
      "np.array(pr)": 2,
      "predictionc": 2,
      "pred": 1,
      "output_other": 1,
      "predictions_train": 1,
      "predictions_test": 1,
      "predicciones_val": 1,
      "ypred_class": 1,
      "y_pred_colTot": 1
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.min_samples_split": {
      "2": 809,
      "1000": 8,
      "10": 6,
      "500": 5,
      "3": 5,
      "30": 5,
      "5": 4,
      "int(round(8.386778166939953))": 2,
      "40": 2,
      "8": 1,
      "0.1": 1,
      "min_samples": 1,
      "100": 1,
      "17": 1,
      "150": 1,
      "800": 1,
      "5000": 1,
      "4": 1,
      "389": 1,
      "int(round(min_samples_split))": 1,
      "16": 1,
      "0.5": 1,
      "19": 1,
      "6": 1,
      "20": 1,
      "45": 1,
      "min_samples_split": 1,
      "best_params[5]": 1
    },
    "sklearn.decomposition._fastica.FastICA.__init__.n_components": {
      "n_comp": 127,
      "N_COMP": 13,
      "n_components": 6,
      "COMPONENTS": 5,
      "10": 4,
      "None": 4,
      "300": 3,
      "komponent": 3,
      "2": 2,
      "50": 2,
      "5": 2,
      "n_col": 2,
      "num_ICA_components": 2,
      "n_compute": 2,
      "150": 1,
      "3": 1,
      "20": 1,
      "ncompo_genes": 1,
      "ncompo_cells": 1,
      "25": 1,
      "n_com": 1,
      "n_comp_ICA": 1,
      "500": 1,
      "30": 1,
      "12": 1,
      "ncomp": 1,
      "4": 1
    },
    "sklearn.decomposition._fastica.FastICA.__init__.random_state": {
      "42": 66,
      "420": 57,
      "None": 32,
      "17": 11,
      "seed": 4,
      "random_seed": 3,
      "4": 2,
      "rng": 2,
      "1": 2,
      "0": 1,
      "12": 1,
      "2273": 1,
      "100": 1,
      "RANDOM_STATE": 1,
      "15": 1,
      "421": 1,
      "rstate": 1,
      "56": 1,
      "rs": 1,
      "98": 1
    },
    "sklearn.decomposition._fastica.FastICA.fit_transform.X": {
      "train.drop(['y'], axis=1)": 97,
      "train": 15,
      "train[col]": 5,
      "X_train": 3,
      "df_norm": 3,
      "total": 2,
      "train_df.drop(['price_doc'], axis=1)": 2,
      "df_train.drop(['y'], axis=1)": 2,
      "train_df": 2,
      "VT_ALL": 2,
      "train[kolom]": 2,
      "X_pca": 2,
      "train_df.drop(['y'], axis=1)": 2,
      "df[feat_cols].values": 1,
      "munged_train_df": 1,
      "train_tv_X": 1,
      "data_all[GENES]": 1,
      "data_all[CELLS]": 1,
      "train_X[col]": 1,
      "train.values": 1,
      "data_scaler": 1,
      "x_train": 1,
      "train_scaled": 1,
      "cells_df": 1,
      "genes_df": 1,
      "train_no_y": 1,
      "train_df.drop(['isFraud'], axis=1)": 1,
      "X": 1,
      "qhighvf_arr": 1,
      "xtrain.append(test)": 1,
      "train_x.values.reshape(-1, 28 * 28)": 1,
      "train.drop([target_col], axis=1)": 1,
      "df_all": 1,
      "standardized_train": 1,
      "f": 1,
      "imp_qcols": 1,
      "df[train_columns]": 1
    },
    "sklearn.decomposition._fastica.FastICA.transform.X": {
      "test": 114,
      "test_df": 7,
      "test[col]": 5,
      "X_test": 3,
      "X": 2,
      "test[kolom]": 2,
      "munged_test_df": 1,
      "test_": 1,
      "val_tv_X": 1,
      "df_test": 1,
      "train_scaled": 1,
      "test_X[col]": 1,
      "test_scaled": 1,
      "X_Test": 1,
      "test.drop(['y'], axis=1)": 1,
      "xdat": 1,
      "train": 1,
      "standardized_test": 1,
      "testf": 1
    },
    "sklearn.linear_model._coordinate_descent.Lasso.__init__.max_iter": {
      "1000": 683,
      "50000": 9,
      "10000": 9,
      "100000": 7,
      "3000": 7,
      "1000000.0": 5,
      "5000": 5,
      "2000": 4,
      "10000000.0": 2,
      "500": 2,
      "200000": 2,
      "100": 2,
      "100000.0": 2,
      "14000": 1,
      "20000": 1,
      "2500": 1,
      "it": 1,
      "8000": 1,
      "60": 1,
      "300": 1,
      "trial.suggest_int('max_iter', 10000, 50000)": 1,
      "1000000000": 1
    },
    "sklearn.neighbors._classification.KNeighborsClassifier.__init__.n_jobs": {
      "None": 1655,
      "-1": 80,
      "2": 73,
      "4": 7,
      "1": 3,
      "-2": 1,
      "model_njobs": 1,
      "3": 1
    },
    "sklearn.multiclass.OneVsRestClassifier.__init__.estimator": {
      "model": 23,
      "LogisticRegression()": 18,
      "classifier": 17,
      "rfr": 15,
      "logreg": 14,
      "estimator": 12,
      "SGDClassifier(loss='log', alpha=1e-05, penalty='l1')": 7,
      "GaussianNB()": 6,
      "ExtraTreesClassifier(n_estimators=10)": 6,
      "LinearSVC()": 5,
      "LogisticRegression(C=10, penalty='l2')": 5,
      "clf": 5,
      "lr": 4,
      "MultinomialNB()": 4,
      "xgbc": 4,
      "SGDClassifier(loss='log', alpha=1e-05, penalty='l2')": 4,
      "svm_clf": 3,
      "svc": 3,
      "svm.SVC(kernel='rbf', gamma=c)": 3,
      "AdaBoostClassifier()": 3,
      "LinearSVC(random_state=0)": 3,
      "SVC(kernel='linear')": 3,
      "LogisticRegression(solver='sag')": 3,
      "LGBMClassifier()": 2,
      "LogisticRegression(penalty='l1')": 2,
      "XGBClassifier()": 2,
      "XGBClassifier(n_jobs=-1, max_depth=30)": 2,
      "logistic": 2,
      "LogisticRegression(C=10)": 2,
      "LogisticRegression(multi_class='auto', n_jobs=-1)": 2,
      "OneVsRestClassifier(LinearDiscriminantAnalysis(), n_jobs=-1)": 2,
      "LinearDiscriminantAnalysis()": 2,
      "QuadraticDiscriminantAnalysis()": 2,
      "KNeighborsClassifier(7, n_jobs=-1)": 2,
      "DecisionTreeClassifier(max_depth=10)": 2,
      "RandomForestClassifier(n_estimators=100, n_jobs=-1)": 2,
      "MLPClassifier(alpha=0.0001)": 2,
      "SVC(probability=True)": 2,
      "et": 2,
      "MultinomialNB(fit_prior=True, class_prior=None)": 2,
      "dt": 1,
      "LGBMClassifier(colsample_bytree=0.6, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.5)": 1,
      "LogisticRegression(n_jobs=-1)": 1,
      "dtc": 1,
      "NbSvmClassifier()": 1,
      "XGBClassifier(tree_method='gpu_hist', n_jobs=-1, colsample_bytree=0.6746045225305067, gamma=8.717282170474643, learning_rate=0.0676566413896137, max_depth=15, min_child_weight=10, n_estimators=199, subsample=0.8772601635382853)": 1,
      "grid_search": 1,
      "RandomForestClassifier()": 1,
      "BernoulliNB()": 1,
      "RidgeClassifier(normalize=True)": 1,
      "LogisticRegression(multi_class='ovr')": 1,
      "LinearSVC(multi_class='ovr')": 1,
      "LogisticRegression(penalty='l2')": 1,
      "SGDClassifier(loss='hinge', alpha=i, penalty='l1')": 1,
      "SGDClassifier(loss='hinge', alpha=10**(-4), penalty='l1')": 1,
      "lsvc": 1,
      "etc": 1,
      "mlp": 1,
      "SVC(kernel='sigmoid', probability=True)": 1,
      "linear_model.LogisticRegression(C=alpha, multi_class='multinomial', solver='saga', penalty=reg)": 1,
      "linear_model.LogisticRegression(C=1.0, multi_class='multinomial', solver='saga', penalty='l1')": 1,
      "LinearSVC(random_state=32)": 1,
      "classifier_SVC": 1,
      "SGD": 1,
      "Linear_SVC": 1,
      "LogisticRegression": 1,
      "SGDClassifier(loss='hinge', alpha=1e-05, penalty='l1')": 1,
      "LogisticRegression(penalty='l2', max_iter=1000)": 1,
      "LogisticRegression(penalty='l2', C=0.1, multi_class='ovr', solver='newton-cg')": 1,
      "RandomForestClassifier(n_estimators=100)": 1,
      "SGDClassifier(loss='log', max_iter=25000, n_jobs=-1, random_state=34, learning_rate='constant', eta0=0.002, alpha=0.004, shuffle=True)": 1,
      "svm.SVC(kernel='rbf', probability=True)": 1,
      "clf_no_outliers": 1,
      "smote_clf": 1,
      "rand_up_clf": 1,
      "t_clf": 1,
      "clf_stop": 1,
      "LogisticRegression(solver='lbfgs', penalty='l2')": 1,
      "RandomForestClassifier(n_estimators=200, random_state=11, class_weight='balanced')": 1,
      "XGBClassifier(tree_method='gpu_hist', gpu_id=0, objective='binary:logistic', random_state=SEED, scale_pos_weight=1400, **PARAMS)": 1,
      "GBC": 1,
      "LogisticRegression(random_state=123, max_iter=model_config['max_iter'], solver=model_config['solver'], C=model_config['C'])": 1,
      "XGBClassifier(max_depth=model_config['max_depth'], learning_rate=model_config['learning_rate'], n_estimators=model_config['n_estimators'], objective='binary:logistic', booster=model_config['booster'], n_jobs=-1)": 1,
      "CatBoostClassifier(iterations=model_config['iterations'], random_state=123, logging_level='Silent')": 1,
      "svm.SVC(kernel='linear', probability=True, random_state=random_state)": 1,
      "gbc": 1,
      "knn": 1,
      "LogisticRegression(solver='saga', max_iter=500, random_state=42)": 1,
      "LogisticRegression(random_state=1812, solver='saga', class_weight='balanced', max_iter=100, C=1291.54966501)": 1,
      "svm.SVC(gamma=0.01, C=100.0, probability=True, class_weight='balanced', kernel='linear')": 1,
      "CatBoostClassifier(objective='MultiClass', task_type='GPU', l2_leaf_reg=50, bootstrap_type='Bernoulli', leaf_estimation_iterations=10, subsample=0.9, random_seed=10)": 1,
      "SGDClassifier(loss='log', alpha=0.001, penalty='l2', max_iter=10000, tol=1e-05, eta0=0.002)": 1,
      "SVC(**BEST_PARAMS)": 1,
      "svm": 1,
      "xgb": 1,
      "KNeighborsClassifier()": 1,
      "SVC(kernel='rbf')": 1,
      "SVC()": 1,
      "svm.SVC()": 1,
      "LogisticRegression(multi_class='multinomial')": 1,
      "LogisticRegression(C=0.9, penalty='l1', solver='saga')": 1,
      "MultinomialNB(alpha=0.35)": 1,
      "SVC(kernel='linear', probability=True)": 1,
      "SGDClassifier(loss='hinge', penalty='l2')": 1,
      "_SVC": 1,
      "modelchain4grid": 1,
      "GradientBoostingClassifier(n_estimators=500)": 1,
      "CatBoostClassifier()": 1,
      "p_svm_clf": 1,
      "text_clf": 1,
      "sgd": 1,
      "XGBClassifier(num_class=len(classes), gamma=0.024, learning_rate=0.3, max_depth=20, nthread=4, n_estimators=1000, objective='multi:softmax')": 1,
      "XGBClassifier(num_class=len(classes), base_score=0.5, colsample_bytree=0.5, gamma=0.017, learning_rate=0.15, max_delta_step=0, max_depth=mx_depth, min_child_weight=3, n_estimators=3000, nthread=-1, objective='multi:softmax', seed=0, silent=1, subsample=0.8, eta=0.3)": 1,
      "SGDClassifier(loss='log', alpha=0.001, penalty='l1')": 1,
      "LogisticRegression(C=1, penalty='l2')": 1,
      "DecisionTreeClassifier()": 1
    },
    "sklearn.multiclass.OneVsRestClassifier.fit.X": {
      "X_train": 45,
      "X": 14,
      "x_train": 13,
      "train_vectorized": 9,
      "X_train_multilabel": 9,
      "X_train_tf": 6,
      "X_train_tfidf": 6,
      "x_train_multilabel": 5,
      "temp_train": 3,
      "e_[:len(mtrain)]": 3,
      "X_train_fold": 2,
      "train_tfidf_features": 2,
      "train_data": 2,
      "xtrain": 2,
      "U1": 2,
      "FinalTrain": 2,
      "x": 2,
      "X_train_df": 1,
      "trainData": 1,
      "X_train_val": 1,
      "features": 1,
      "text": 1,
      "df_train": 1,
      "x_train_vectors": 1,
      "filt_data": 1,
      "X_train_res": 1,
      "X_train_vec": 1,
      "sentences_tf_idf": 1,
      "x_train_tf_idf_word": 1,
      "trainp[:len(train_x)]": 1,
      "X_train_n": 1,
      "X_train_": 1,
      "Xtrain": 1,
      "train_features": 1,
      "X[:5000]": 1,
      "X_tr": 1
    },
    "sklearn.multiclass.OneVsRestClassifier.fit.y": {
      "y_train": 83,
      "y": 24,
      "ytrain": 4,
      "temp_label_train": 3,
      "label": 3,
      "y_target": 3,
      "Y_train": 3,
      "Y_train_fold": 2,
      "Y": 2,
      "FinalTrainLabels": 2,
      "y_tr": 2,
      "y_value": 1,
      "y_train_label": 1,
      "trainTarget": 1,
      "y_train_val": 1,
      "np.array(trainy)": 1,
      "best_models": 1,
      "y_train_res": 1,
      "dataframe['author']": 1,
      "y1": 1,
      "train_y": 1,
      "Y_train_n": 1,
      "Y_train_": 1,
      "Ym_train": 1,
      "y_train_tf": 1,
      "y[:5000]": 1
    },
    "sklearn.multiclass.OneVsRestClassifier.predict.X": {
      "X_test": 38,
      "x_test": 13,
      "X_test_multilabel": 10,
      "x_test_multilabel": 6,
      "x_train": 6,
      "X_sub": 6,
      "x_val": 5,
      "X_train_tfidf": 5,
      "X_val": 5,
      "df_test": 4,
      "test_data": 3,
      "e_[:len(mtrain)]": 3,
      "U1": 3,
      "test_tfidf_features": 2,
      "X": 2,
      "test_vectorized": 2,
      "xval": 2,
      "U2": 2,
      "FinalTest": 2,
      "FinalTrain": 2,
      "test": 2,
      "test_text_df": 1,
      "test_documents": 1,
      "testData": 1,
      "features3": 1,
      "textpre": 1,
      "X_validation": 1,
      "df_train": 1,
      "x_test_vectors": 1,
      "X_valid": 1,
      "X_submission": 1,
      "row": 1,
      "X_test.loc[:, ind]": 1,
      "test.drop(['installation_id'], axis=1).fillna(0)": 1,
      "X_test_res": 1,
      "X_test_vec": 1,
      "x_test_tf_idf_word": 1,
      "X_test_subm_vects": 1,
      "trainp[:len(train_x)]": 1,
      "trainp[len(train_x):]": 1,
      "test_data_features": 1,
      "X_train": 1,
      "testset['text']": 1,
      "X_test_tfidf": 1,
      "X_test_data_tfidf": 1,
      "X_test_": 1,
      "Xtest": 1,
      "test_features": 1,
      "test_df_flags": 1,
      "null": 1
    },
    "sklearn.metrics._ranking.roc_curve.sample_weight": {
      "None": 1403,
      "weights": 8
    },
    "sklearn.metrics.pairwise.cosine_similarity.X": {
      "i": 6,
      "s_embeds": 5,
      "tfidf_matrix": 4,
      "corpus_tfidf": 4,
      "wiki.loc[['cat', 'dog']]": 4,
      "topic_corpus.fillna(0)": 3,
      "df.loc[:, SELECTED_SKILLS]": 3,
      "val_y.values.reshape(1, -1)": 3,
      "U1[:, :rank]": 3,
      "[embeddings['camera'], embeddings['quality']]": 2,
      "a": 2,
      "temp.drop('Patient', 1)": 2,
      "features_arr[idx_1]": 2,
      "img_features_arr[idx_1]": 2,
      "np.array(row).reshape(1, -1)": 2,
      "row.reshape(1, -1)": 2,
      "X": 2,
      "v.T": 2,
      "v.T[vectorizer.vocabulary_[xi]].reshape(1, -1)": 2,
      "uniform.loc[['cat', 'dog']]": 2,
      "photo_vecs": 2,
      "[df_dtm['kindl'], df_dtm['book']]": 2,
      "[embeddings['kindle'], embeddings['book']]": 2,
      "df_dtm.T": 2,
      "feature_matrix": 1,
      "professional_profiles[professional_id]": 1,
      "df.loc[:, SELECTED_SKILLS].T": 1,
      "items_tfidf": 1,
      "ar1": 1,
      "df[embedding_cols]": 1,
      "description": 1,
      "new": 1,
      "embeddings": 1,
      "embeddings1": 1,
      "data.drop('target', axis=1).values": 1,
      "test_embeds": 1,
      "features[query_start_idx:query_end_idx]": 1,
      "count_vec_matrix": 1,
      "[row['question1_sent_embeddings']]": 1,
      "vectorized_names": 1,
      "query_tfidf": 1,
      "question_embeddings": 1,
      "[factor]": 1,
      "qs_transformed": 1,
      "Qs_transformed[-1].reshape(1, -1)": 1,
      "embeddings[word_index].reshape(1, -1)": 1,
      "ngram": 1,
      "vi": 1,
      "premise[n].reshape(1, -1)": 1,
      "duties_vectors[index]": 1,
      "imgs_features_pkl111": 1,
      "[A]": 1,
      "tfidf_matrix.T": 1,
      "alpha_df.iloc[:, 1:]": 1,
      "train_tf_df": 1,
      "sample[0].numpy()": 1,
      "output": 1,
      "embedding": 1,
      "feature": 1,
      "quora_vectors_emb": 1,
      "train_data_features1td": 1,
      "image1": 1,
      "vec": 1,
      "Ux2": 1,
      "TRu_[:len(train) + len(test)]": 1,
      "TRu_[:len(train)]": 1,
      "u": 1,
      "songrating": 1,
      "question1_tfidf": 1,
      "aw.dot(wordnet_mat)": 1,
      "SongsU": 1,
      "np.hstack((dfidf, dfidfw))": 1,
      "ratings": 1,
      "ratings.T": 1,
      "[sent_emb[0]]": 1,
      "document_embeddings": 1,
      "[y_pred]": 1,
      "chunk": 1,
      "q_total_tfidf": 1,
      "corpus[ind]": 1,
      "first_embed": 1,
      "op_vectors": 1,
      "word_embeddings_test": 1,
      "clit_tf": 1,
      "X_corpus": 1,
      "prof_dtm[0:1]": 1,
      "base_doc": 1,
      "wv1.reshape(1, -1)": 1,
      "query_score": 1,
      "t_p_scores[curr_p_idx].reshape(1, -1)": 1,
      "f_p_scores[curr_p_idx].reshape(1, -1)": 1,
      "g_p_scores[curr_p_idx].reshape(1, -1)": 1,
      "[vec1]": 1
    },
    "sklearn.linear_model._ridge.RidgeClassifier.__init__.random_state": {
      "None": 127,
      "0": 8,
      "random_state": 7,
      "42": 2,
      "1": 2,
      "123": 2,
      "2021": 1,
      "RANDOM_STATE": 1,
      "SEED": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.random_state": {
      "42": 446,
      "None": 293,
      "0": 49,
      "25": 19,
      "1": 7,
      "123": 4,
      "171": 3,
      "seed": 2,
      "910": 2,
      "2018": 1,
      "random_state": 1,
      "14": 1,
      "55": 1,
      "69": 1,
      "34": 1,
      "5": 1,
      "101": 1,
      "31": 1,
      "RND_ST": 1,
      "RS": 1,
      "99": 1,
      "RANDOM_STATE": 1,
      "10": 1,
      "9": 1,
      "20": 1
    },
    "sklearn.calibration.CalibratedClassifierCV.__init__.method": {
      "'sigmoid'": 720,
      "'isotonic'": 62
    },
    "sklearn.calibration.CalibratedClassifierCV.__init__.base_estimator": {
      "clf": 582,
      "model": 25,
      "clf1": 19,
      "clf2": 19,
      "clf3": 19,
      "enA": 12,
      "enB": 12,
      "RidgeClassifier(random_state=random_state)": 7,
      "est": 6,
      "classifier": 6,
      "rfc": 3,
      "m2_xgb": 3,
      "XGBClassifier()": 3,
      "LinearDiscriminantAnalysis()": 3,
      "self.clf": 3,
      "Model": 3,
      "sgd": 2,
      "model_final_Ridge": 2,
      "model_final_LGB": 2,
      "model_final_NN": 2,
      "rf_model": 2,
      "svm": 2,
      "xgb": 2,
      "RidgeClassifier()": 2,
      "best_model": 2,
      "gs.best_estimator_": 2,
      "nb": 1,
      "mlp": 1,
      "lgbc": 1,
      "kn": 1,
      "bc": 1,
      "r_cfl": 1,
      "model3": 1,
      "RandomForestClassifier()": 1,
      "knn_clf": 1,
      "SGDClassifier(random_state=random_state, n_jobs=-1, loss='squared_hinge')": 1,
      "GaussianNB()": 1,
      "base_model": 1,
      "rf": 1,
      "lsvc": 1,
      "LinearSVC()": 1,
      "RidgeClassifier(random_state=RANDOM_STATE)": 1,
      "MultinomialNB(alpha=0.03)": 1,
      "BernoulliNB(alpha=0.03)": 1,
      "SGDClassifier(loss='modified_huber', alpha=0.0001, max_iter=10000, tol=0.0001)": 1,
      "LinearSVC(C=1.0, random_state=seed)": 1,
      "lg": 1,
      "base_xgb": 1,
      "base_lgbm": 1,
      "lgbm_model_weighted": 1,
      "RidgeClassifier(random_state=SEED, class_weight='balanced')": 1,
      "LogisticRegression()": 1,
      "lr": 1,
      "clfLR": 1,
      "mnb": 1,
      "LinearSVC(C=0.1)": 1,
      "xgb_classifier": 1,
      "logreg": 1,
      "svc": 1,
      "clf_SGD": 1,
      "voting": 1,
      "model_fix": 1,
      "None": 1
    },
    "sklearn.calibration.CalibratedClassifierCV.fit.X": {
      "train_x_onehotCoding": 282,
      "train_x_responseCoding": 109,
      "train_x": 53,
      "train_text_feature_onehotCoding": 42,
      "train_gene_feature_onehotCoding": 41,
      "train_variation_feature_onehotCoding": 40,
      "X_train": 32,
      "XV": 24,
      "x_train": 15,
      "training_data_final": 12,
      "train": 10,
      "train_df": 9,
      "X": 7,
      "Xtrain": 6,
      "vector_tr": 5,
      "train_x_onehotCoding_count": 4,
      "train_gene_var_text": 4,
      "filt_data": 3,
      "train_feat_hotencode": 3,
      "old_onehotCoding": 3,
      "X_eval": 3,
      "ridge_x_train": 2,
      "train_x_tf": 2,
      "train_X_hotencode": 2,
      "train_tfidf": 2,
      "train_gene_feature_onehotCoding[0:len(y_train)]": 2,
      "train_variation_feature_onehotCoding[0:len(y_train)]": 2,
      "train_text_feature_onehotCoding[0:len(y_train)]": 2,
      "train_gene_feature_onehotCoding_onehot": 2,
      "train_variation_feature_onehotCoding_bigram": 2,
      "train_text_feature_onehotCoding_bigram": 2,
      "train_x_onehotCoding_count_fe": 2,
      "xcT": 1,
      "data_tr": 1,
      "tr_X": 1,
      "X_train_tf": 1,
      "train_s": 1,
      "X_train_cv_temp": 1,
      "X_train_RID": 1,
      "X_train_LGB": 1,
      "X_train_NN": 1,
      "sgd_x_train": 1,
      "X2": 1,
      "train_vec": 1,
      "X_tr": 1,
      "X_train_scaled": 1,
      "train_X_scaled": 1,
      "np.array(train.values)": 1,
      "np.vstack(trainfeat.values)": 1,
      "trainX": 1,
      "blend_train": 1,
      "xtrain": 1,
      "X_upsample_train": 1,
      "valid_predictions": 1,
      "X1": 1,
      "app_train[x_calls]": 1
    },
    "sklearn.calibration.CalibratedClassifierCV.fit.y": {
      "train_y": 458,
      "y_train": 209,
      "y_valid": 24,
      "y_train_val": 12,
      "ytrain": 7,
      "y": 7,
      "Y_tr": 6,
      "labels": 4,
      "Y_train": 3,
      "levels": 3,
      "y_eval": 3,
      "ycT": 1,
      "target": 1,
      "tr_y": 1,
      "y_train[label_name]": 1,
      "train_y_s": 1,
      "y_train_cv": 1,
      "y2": 1,
      "train_lbl[categ]": 1,
      "y_tr": 1,
      "np.array(train_labels.values)": 1,
      "trainlabel.values": 1,
      "trainY": 1,
      "y_valids[i][0].values": 1,
      "y_upsample_train": 1,
      "val_y_raveled": 1,
      "Y1": 1,
      "app_train.TARGET": 1
    },
    "sklearn.calibration.CalibratedClassifierCV.predict_proba.X": {
      "cv_x_onehotCoding": 264,
      "test_x_onehotCoding[test_point_index]": 149,
      "test_x_onehotCoding": 100,
      "train_x_onehotCoding": 99,
      "cv_x_responseCoding": 66,
      "test_x": 47,
      "cv_text_feature_onehotCoding": 42,
      "cv_variation_feature_onehotCoding": 40,
      "cv_gene_feature_onehotCoding": 39,
      "train_x_responseCoding": 34,
      "test_x_responseCoding": 34,
      "X_test": 27,
      "XT": 24,
      "train_text_feature_onehotCoding": 21,
      "test_text_feature_onehotCoding": 21,
      "train_gene_feature_onehotCoding": 20,
      "test_gene_feature_onehotCoding": 20,
      "train_variation_feature_onehotCoding": 20,
      "test_variation_feature_onehotCoding": 20,
      "test_x_responseCoding[test_point_index].reshape(1, -1)": 19,
      "test": 15,
      "x_test": 8,
      "validation_data_final": 6,
      "cv_df": 6,
      "X_rtest": 5,
      "vector_tr": 5,
      "vector_cv": 5,
      "x_valid": 5,
      "val_x": 5,
      "Xtest": 5,
      "X_train": 4,
      "cv_x_onehotCoding_count": 4,
      "test_x_onehotCoding_count[test_point_index]": 4,
      "train_gene_var_text": 4,
      "test_gene_var_text": 4,
      "x_train": 4,
      "l1_test[features]": 3,
      "dft": 3,
      "df": 3,
      "testing_data_final": 3,
      "cv_feat_hotencode": 3,
      "sub_test_onehotCoding": 3,
      "train_df": 3,
      "X_eval": 3,
      "ridge_x_valid": 2,
      "cv_x_tf": 2,
      "train_X_hotencode": 2,
      "cv_X_hotencode": 2,
      "test_X_hotencode": 2,
      "train": 2,
      "cv_gene_feature_onehotCoding_onehot": 2,
      "cv_variation_feature_onehotCoding_bigram": 2,
      "cv_text_feature_onehotCoding_bigram": 2,
      "train_x_onehotCoding_count": 2,
      "test_x_onehotCoding_count": 2,
      "cv_x_onehotCoding_count_fe": 2,
      "cv_x": 2,
      "test[X.columns]": 2,
      "crossval_gene_feature_onehotCoding": 2,
      "xcV": 1,
      "vector_test": 1,
      "data_test": 1,
      "test_df[ridge_features]": 1,
      "aml_test_preds_df[features]": 1,
      "x_cv": 1,
      "dft1": 1,
      "df1": 1,
      "dft2": 1,
      "df2": 1,
      "ts_X": 1,
      "X_train_tf": 1,
      "X_val_tf": 1,
      "X_test_tf": 1,
      "X": 1,
      "test_pre": 1,
      "X_val_cv_temp": 1,
      "X_test_temp": 1,
      "X_test_RID": 1,
      "X_test_LGB": 1,
      "X_test_NN": 1,
      "test[ridge_features]": 1,
      "sgd_x_valid": 1,
      "test[sgd_features]": 1,
      "train_x_tf": 1,
      "test_x_tf": 1,
      "X_test.loc[:, ind]": 1,
      "train_feat_hotencode": 1,
      "test_feat_hotencode": 1,
      "train_tfidf": 1,
      "cv_tfidf": 1,
      "test_tfidf": 1,
      "test_gene_feature_onehotCoding[0:len(y_cv)]": 1,
      "train_gene_feature_onehotCoding[0:len(y_train)]": 1,
      "test_gene_feature_onehotCoding[0:len(y_test)]": 1,
      "test_variation_feature_onehotCoding[0:len(y_cv)]": 1,
      "train_variation_feature_onehotCoding[0:len(y_train)]": 1,
      "test_variation_feature_onehotCoding[0:len(y_test)]": 1,
      "test_text_feature_onehotCoding[0:len(y_cv)]": 1,
      "train_text_feature_onehotCoding[0:len(y_train)]": 1,
      "test_text_feature_onehotCoding[0:len(y_test)]": 1,
      "test_x_onehotCoding[0:len(train_y)]": 1,
      "test_x_onehotCoding[0:len(y_train)]": 1,
      "X_val": 1,
      "X2_test": 1,
      "X2_tt": 1,
      "X2": 1,
      "test_vec": 1,
      "X_vl": 1,
      "X_val_scaled": 1,
      "test_X_scaled": 1,
      "np.array(test.values)": 1,
      "train_gene_feature_onehotCoding_onehot": 1,
      "test_gene_feature_onehotCoding_onehot": 1,
      "train_variation_feature_onehotCoding_bigram": 1,
      "test_variation_feature_onehotCoding_bigram": 1,
      "train_text_feature_onehotCoding_bigram": 1,
      "test_text_feature_onehotCoding_bigram": 1,
      "train_x_onehotCoding_count_fe": 1,
      "test_x_onehotCoding_count_fe": 1,
      "testX": 1,
      "test_predictions": 1,
      "l1_test": 1,
      "train_x": 1,
      "blend_train": 1,
      "blend_test": 1,
      "xtrain": 1,
      "xval": 1,
      "test_data_hv_co": 1,
      "market_prediction": 1,
      "Xval": 1,
      "Xt": 1,
      "app_test[x_calls]": 1
    },
    "sklearn.calibration.CalibratedClassifierCV.predict.X": {
      "test_x_onehotCoding[test_point_index]": 149,
      "test_x_responseCoding[test_point_index].reshape(1, -1)": 35,
      "test_x": 25,
      "cv_x_onehotCoding": 25,
      "cv_x_onehotCoding.toarray()": 19,
      "test_x_responseCoding[0].reshape(1, -1)": 16,
      "X_test": 12,
      "test_x_onehotCoding_count[test_point_index]": 4,
      "val_x": 3,
      "validation_data_final": 3,
      "testing_data_final": 3,
      "test_X_hotencode": 2,
      "X_train": 2,
      "cv_x_responseCoding": 2,
      "test": 2,
      "data_test": 1,
      "top16features_testgroup": 1,
      "X_test.loc[:, ind]": 1,
      "test_x_onehotCoding": 1,
      "X2_test": 1,
      "X2_tt": 1,
      "np.vstack(testfeat.values)": 1,
      "np.vstack(fea.values)": 1,
      "test_x_onehotCoding[0].reshape(1, -1)": 1,
      "test_x_onehotCoding[test_point_index].reshape(1, -1)": 1,
      "testData_gene_var_text": 1,
      "X2": 1
    },
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.n_jobs": {
      "-1": 153,
      "None": 137,
      "1": 12,
      "4": 7,
      "N_THREADS": 2,
      "30": 1,
      "n_jobs": 1,
      "8": 1
    },
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.n_estimators": {
      "100": 130,
      "25": 36,
      "200": 19,
      "g['ne']": 17,
      "50": 13,
      "500": 11,
      "n_estimators": 11,
      "10": 8,
      "1000": 8,
      "5": 6,
      "30": 5,
      "120": 5,
      "150": 5,
      "n_trees * 2": 4,
      "300": 3,
      "75": 3,
      "225": 3,
      "250": 3,
      "trees": 2,
      "400": 2,
      "18": 2,
      "222": 2,
      "n_trees": 2,
      "20": 1,
      "70": 1,
      "8": 1,
      "1200": 1,
      "num_trees": 1,
      "700": 1,
      "m[0]": 1,
      "512": 1,
      "15": 1,
      "29": 1,
      "l1_et_n_estimators": 1,
      "40": 1,
      "result_extra_trees.best_params_['n_estimators']": 1,
      "rand_est": 1
    },
    "sklearn.multiclass.OneVsRestClassifier.__init__.n_jobs": {
      "None": 165,
      "-1": 90,
      "4": 16,
      "1": 9
    },
    "sklearn.feature_extraction.image.PatchExtractor.__init__.patch_size": {
      "(7, 7)": 5,
      "(10, 10)": 3
    },
    "sklearn.feature_extraction.image.PatchExtractor.__init__.max_patches": {
      "20": 5,
      "10": 3
    },
    "sklearn.feature_extraction.image.PatchExtractor.__init__.random_state": {
      "2016": 8
    },
    "sklearn.pipeline.FeatureUnion.__init__.transformer_list": {
      "[('cst', cust_regression_vals()), ('txt1', pipeline.Pipeline([('s1', cust_txt_col(key='search_term')), ('tfidf1', tfidf), ('tsvd1', tsvd)])), ('txt2', pipeline.Pipeline([('s2', cust_txt_col(key='product_title')), ('tfidf2', tfidf), ('tsvd2', tsvd)])), ('txt3', pipeline.Pipeline([('s3', cust_txt_col(key='product_description')), ('tfidf3', tfidf), ('tsvd3', tsvd)])), ('txt4', pipeline.Pipeline([('s4', cust_txt_col(key='brand')), ('tfidf4', tfidf), ('tsvd4', tsvd)]))]": 89,
      "[('svd', svd), ('dense_features', FeatureInserter())]": 25,
      "[('cst', cust_img_features())]": 15,
      "[('description', TfidfVectorizer(ngram_range=(1, 2), max_features=17000, **tfidf_para, preprocessor=get_col('description'))), ('title', CountVectorizer(ngram_range=(1, 2), stop_words=russian_stop, preprocessor=get_col('title')))]": 14,
      "tfhash": 8,
      "transformer_list": 8,
      "[('cst', cust_regression_vals()), ('txt1', pipeline.Pipeline([('s1', cust_txt_col(key='search_term')), ('tfidf1', tfidf), ('tsvd1', tsvd)])), ('txt2', pipeline.Pipeline([('s2', cust_txt_col(key='product_title')), ('tfidf2', tfidf), ('tsvd2', tsvd)])), ('txt4', pipeline.Pipeline([('s4', cust_txt_col(key='brand')), ('tfidf4', tfidf), ('tsvd4', tsvd)]))]": 6,
      "[('features', SimpleImputer(strategy='mean')), ('indicators', MissingIndicator())]": 6,
      "[('name', Pipeline([('select', ItemSelector('name', start_time=start_time)), ('transform', HashingVectorizer(ngram_range=(1, 2), n_features=2**27, norm='l2', lowercase=False, stop_words=stopwords)), ('drop_cols', DropColumnsByDf(min_df=2))])), ('category_name', Pipeline([('select', ItemSelector('category_name', start_time=start_time)), ('transform', HashingVectorizer(ngram_range=(1, 1), token_pattern='.+', tokenizer=split_cat, n_features=2**27, norm='l2', lowercase=False)), ('drop_cols', DropColumnsByDf(min_df=2))])), ('brand_name', Pipeline([('select', ItemSelector('brand_name', start_time=start_time)), ('transform', CountVectorizer(token_pattern='.+', min_df=2, lowercase=False))])), ('gencat_cond', Pipeline([('select', ItemSelector('gencat_cond', start_time=start_time)), ('transform', CountVectorizer(token_pattern='.+', min_df=2, lowercase=False))])), ('subcat_1_cond', Pipeline([('select', ItemSelector('subcat_1_cond', start_time=start_time)), ('transform', CountVectorizer(token_pattern='.+', min_df=2, lowercase=False))])), ('subcat_2_cond', Pipeline([('select', ItemSelector('subcat_2_cond', start_time=start_time)), ('transform', CountVectorizer(token_pattern='.+', min_df=2, lowercase=False))])), ('has_brand', Pipeline([('select', ItemSelector('has_brand', start_time=start_time)), ('ohe', OneHotEncoder())])), ('shipping', Pipeline([('select', ItemSelector('shipping', start_time=start_time)), ('ohe', OneHotEncoder())])), ('item_condition_id', Pipeline([('select', ItemSelector('item_condition_id', start_time=start_time)), ('ohe', OneHotEncoder())])), ('item_description', Pipeline([('select', ItemSelector('item_description', start_time=start_time)), ('hash', HashingVectorizer(ngram_range=(1, 3), n_features=2**27, dtype=np.float32, norm='l2', lowercase=False, stop_words=stopwords)), ('drop_cols', DropColumnsByDf(min_df=2))]))]": 5,
      "[('numeric_features', Pipeline([('selector', get_numeric_data)])), ('text_features', Pipeline([('selector', get_text_data), ('vectorizer', TfidfVectorizer(stop_words='english', strip_accents='unicode', token_pattern='\\\\w{2,}', analyzer='word', ngram_range=(1, 1), min_df=5))]))]": 4,
      "features": 4,
      "[('num_pipeline', num_pipeline), ('cat_pipeline', cat_pipeline)]": 4,
      "estimators": 4,
      "[('number', number_pipe), ('datetime', datetime_pipe), ('object', object_pipe)]": 3,
      "[('cst', cust_regression_vals()), ('txt1', pipeline.Pipeline([('s1', cust_txt_col(key='search_term')), ('tfidf1', tfidf), ('tsvd1', tsvd)])), ('txt2', pipeline.Pipeline([('s2', cust_txt_col(key='product_title')), ('tfidf2', tfidf), ('tsvd2', tsvd)]))]": 3,
      "[('cst', cust_regression_vals()), ('txt1', pipeline.Pipeline([('s1', cust_txt_col(key='xdescription')), ('tfidf1', tfidf), ('tsvd1', tsvd)])), ('txt2', pipeline.Pipeline([('s2', cust_txt_col(key='ydescription')), ('tfidf2', tfidf), ('tsvd2', tsvd)]))]": 3,
      "[('description', TfidfVectorizer(ngram_range=(1, 2), max_features=18000, **tfidf_para, preprocessor=get_col('description'))), ('text_feat', CountVectorizer(ngram_range=(1, 2), preprocessor=get_col('text_feat'))), ('title', TfidfVectorizer(ngram_range=(1, 2), **tfidf_para, preprocessor=get_col('title')))]": 3,
      "feature_list": 3,
      "[('text_features', Pipeline([('selector', get_text_data), ('vectorizer', CountVectorizer(analyzer='word', ngram_range=[1, 3], stop_words=nltk.corpus.stopwords.words('english')))])), ('tfidf', Pipeline([('selector', get_text_data), ('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=[1, 3], stop_words=nltk.corpus.stopwords.words('english')))])), ('char_features', Pipeline([('selector', get_text_data), ('vectorizer', TfidfVectorizer(analyzer='char', ngram_range=[3, 5], stop_words=nltk.corpus.stopwords.words('english')))]))]": 3,
      "[('textcounts', ColumnExtractor(cols=textcountscols)), ('w2v', ColumnExtractor(cols=w2vcols))]": 2,
      "[('textcounts', ColumnExtractor(cols=textcountscols)), ('pipe', Pipeline([('cleantext', ColumnExtractor(cols='clean_text')), ('vect', vect)]))]": 2,
      "[('onehot_cat_pipeline', onehot_cat_pipeline), ('num_pipeline', num_pipeline)]": 2,
      "[('name', Pipeline([('select', ItemSelector('name')), ('transform', HashingVectorizer(ngram_range=(1, 2), n_features=2**27, norm='l2', lowercase=False, stop_words=stopwords)), ('drop_cols', DropColumnsByDf(min_df=2))])), ('category_name', Pipeline([('select', ItemSelector('category_name')), ('transform', HashingVectorizer(ngram_range=(1, 1), token_pattern='.+', tokenizer=split_cat, n_features=2**27, norm='l2', lowercase=False)), ('drop_cols', DropColumnsByDf(min_df=2))])), ('brand_name', Pipeline([('select', ItemSelector('brand_name')), ('transform', CountVectorizer(token_pattern='.+', min_df=2, lowercase=False))])), ('gencat_cond', Pipeline([('select', ItemSelector('gencat_cond')), ('transform', CountVectorizer(token_pattern='.+', min_df=2, lowercase=False))])), ('subcat_1_cond', Pipeline([('select', ItemSelector('subcat_1_cond')), ('transform', CountVectorizer(token_pattern='.+', min_df=2, lowercase=False))])), ('subcat_2_cond', Pipeline([('select', ItemSelector('subcat_2_cond')), ('transform', CountVectorizer(token_pattern='.+', min_df=2, lowercase=False))])), ('has_brand', Pipeline([('select', ItemSelector('has_brand')), ('ohe', OneHotEncoder())])), ('shipping', Pipeline([('select', ItemSelector('shipping')), ('ohe', OneHotEncoder())])), ('item_condition_id', Pipeline([('select', ItemSelector('item_condition_id')), ('ohe', OneHotEncoder())])), ('item_description', Pipeline([('select', ItemSelector('item_description')), ('hash', HashingVectorizer(ngram_range=(1, 3), n_features=2**27, dtype=np.float32, norm='l2', lowercase=False, stop_words=stopwords)), ('drop_cols', DropColumnsByDf(min_df=2))]))]": 2,
      "[('cat_pipeline', cat_pipeline), ('num_pipeline', num_pipeline)]": 2,
      "[('name', Pipeline([('select', ItemSelector('name', start_time=start_time)), ('transform', HashingVectorizer(ngram_range=(1, 2), n_features=2**28, norm='l2', lowercase=False, stop_words=stopwords)), ('drop_cols', DropColumnsByDf(min_df=2))])), ('category_name', Pipeline([('select', ItemSelector('category_name', start_time=start_time)), ('transform', HashingVectorizer(ngram_range=(1, 1), token_pattern='.+', tokenizer=split_cat, n_features=2**28, norm='l2', lowercase=False)), ('drop_cols', DropColumnsByDf(min_df=2))])), ('brand_name', Pipeline([('select', ItemSelector('brand_name', start_time=start_time)), ('transform', CountVectorizer(token_pattern='.+', min_df=2, lowercase=False))])), ('gencat_cond', Pipeline([('select', ItemSelector('gencat_cond', start_time=start_time)), ('transform', CountVectorizer(token_pattern='.+', min_df=2, lowercase=False))])), ('subcat_1_cond', Pipeline([('select', ItemSelector('subcat_1_cond', start_time=start_time)), ('transform', CountVectorizer(token_pattern='.+', min_df=2, lowercase=False))])), ('subcat_2_cond', Pipeline([('select', ItemSelector('subcat_2_cond', start_time=start_time)), ('transform', CountVectorizer(token_pattern='.+', min_df=2, lowercase=False))])), ('has_brand', Pipeline([('select', ItemSelector('has_brand', start_time=start_time)), ('ohe', OneHotEncoder())])), ('shipping', Pipeline([('select', ItemSelector('shipping', start_time=start_time)), ('ohe', OneHotEncoder())])), ('item_condition_id', Pipeline([('select', ItemSelector('item_condition_id', start_time=start_time)), ('ohe', OneHotEncoder())])), ('item_description', Pipeline([('select', ItemSelector('item_description', start_time=start_time)), ('hash', HashingVectorizer(ngram_range=(1, 3), n_features=2**27, dtype=np.float32, norm='l2', lowercase=False, stop_words=stopwords)), ('drop_cols', DropColumnsByDf(min_df=2))]))]": 2,
      "[('categorical_pipeline', categorical_pipeline), ('numerical_pipeline', numerical_pipeline)]": 2,
      "[('preprocessing', preprocessor), ('feature_engineering', feature_engineer)]": 2,
      "[('name', CountVectorizer(ngram_range=(1, 2), max_features=50000, preprocessor=preprocessor('name'))), ('general_cat', CountVectorizer(token_pattern='\\\\d+', preprocessor=preprocessor('general_cat'))), ('subcat_1', CountVectorizer(token_pattern='\\\\d+', preprocessor=preprocessor('subcat_1'))), ('subcat_2', CountVectorizer(token_pattern='\\\\d+', preprocessor=preprocessor('subcat_2'))), ('brand_name', CountVectorizer(token_pattern='\\\\d+', preprocessor=preprocessor('brand_name'))), ('shipping', CountVectorizer(token_pattern='\\\\d+', preprocessor=preprocessor('shipping'))), ('item_condition_id', CountVectorizer(token_pattern='\\\\d+', preprocessor=preprocessor('item_condition_id'))), ('item_description', TfidfVectorizer(ngram_range=(1, 3), max_features=100000, preprocessor=preprocessor('item_description')))]": 2,
      "[('word_vect', word_vectorizer), ('char_vect', char_vectorizer)]": 2,
      "[('datetime', Pipeline([('separator', DTypeSelector(key='datetime')), ('filter', SelectPercentile(f_classif, percentile=14))])), ('object', Pipeline([('separator', DTypeSelector(key='object')), ('encoder', FeatureHasher(input_type='string')), ('filter', VarianceThreshold(threshold=2))])), ('number', Pipeline([('separator', DTypeSelector(key='number')), ('filter', SelectFpr(f_classif, alpha=0.02))]))]": 1,
      "[('binary_variables_processing', preprocessing.FunctionTransformer(lambda data: data.iloc[:, get_ind(binary_col)])), ('numeric_variables_processing', pipeline.Pipeline(steps=[('selecting', preprocessing.FunctionTransformer(lambda data: data.iloc[:, get_ind(numeric_col)])), ('scaling', preprocessing.StandardScaler(with_mean=0.0))])), ('categorical_variables_processing', pipeline.Pipeline(steps=[('selecting', preprocessing.FunctionTransformer(lambda data: data.iloc[:, get_ind(categor_col)])), ('hot_encoding', preprocessing.OneHotEncoder(handle_unknown='ignore'))]))]": 1,
      "[('binary_variables_processing', preprocessing.FunctionTransformer(lambda data: data.iloc[:, get_ind(binary_col)])), ('numeric_variables_processing', pipeline.Pipeline(steps=[('selecting', preprocessing.FunctionTransformer(lambda data: data.iloc[:, get_ind(numeric_col)])), ('scaling', preprocessing.StandardScaler(with_mean=0.0))])), ('categorical_variables_processing', pipeline.Pipeline(steps=[('selecting', preprocessing.FunctionTransformer(lambda data: data.iloc[:, get_ind(categor_col)])), ('hot_encoding', preprocessing.OneHotEncoder(handle_unknown='ignore', sparse=False))]))]": 1,
      "[('numeric_features', num_pipeline), ('text_features', text_pipeline)]": 1,
      "[('num_pipeline', num_pipeline), ('text_pipeline', text_pipeline)]": 1,
      "[('num_words', num_words), ('num_non_stopwords', num_non_stopwords), ('avg_word_length', avg_word_length), ('message_processing', message_processing), ('length', length), ('counter', counter)]": 1,
      "[('description', TfidfVectorizer(ngram_range=(1, 2), max_features=16000, **tfidf_para, preprocessor=get_col('description'))), ('text_feat', CountVectorizer(ngram_range=(1, 2), preprocessor=get_col('text_feat'))), ('title', TfidfVectorizer(ngram_range=(1, 2), **tfidf_para, preprocessor=get_col('title')))]": 1,
      "[('text', text), ('length', length), ('words', words), ('words_not_stopword', words_not_stopword), ('avg_word_length', avg_word_length), ('commas', commas)]": 1,
      "[('svd', TruncatedSVD(n_components=50, random_state=100)), ('ica', FastICA(n_components=20, random_state=100))]": 1,
      "[('pp', ProphetTransformer()), ('dates', DatesTransformer())]": 1,
      "[('imputer', simple_imputer), ('indicator', MissingIndicator())]": 1,
      "[('imputer', SimpleImputer(strategy='constant', fill_value=-1)), ('indicator', MissingIndicator())]": 1,
      "[('description', TfidfVectorizer(ngram_range=(1, 2), max_features=50000, **tfidf_para, preprocessor=get_col('description'))), ('text_feat', CountVectorizer(ngram_range=(1, 2), preprocessor=get_col('text_feat'))), ('title', TfidfVectorizer(ngram_range=(1, 2), **tfidf_para, preprocessor=get_col('title')))]": 1,
      "[('description', TfidfVectorizer(ngram_range=(1, 2), max_features=45000, **tfidf_para, preprocessor=get_col('description'))), ('title', TfidfVectorizer(ngram_range=(1, 2), **tfidf_para, preprocessor=get_col('title'))), ('text_feat', CountVectorizer(ngram_range=(1, 2), preprocessor=get_col('text_feat')))]": 1,
      "[('standard', cust_regression_vals()), ('pip1', pipeline.Pipeline([('newText', cust_txt_col('newText')), ('counts', cvec), ('tsvdCountText', tsvdCount)])), ('pip2', pipeline.Pipeline([('nmf_Text', cust_txt_col('newText')), ('tfidf_Text', tfidf), ('nmfText', nmf)])), ('pip3', pipeline.Pipeline([('lda_Text', cust_txt_col('newText')), ('tfidf_Text', tfidf), ('ldaText', lda)])), ('pip4', pipeline.Pipeline([('newText', cust_txt_col('newText')), ('tfidf_Text', tfidf), ('tsvdText', tsvdText)]))]": 1,
      "[('pca', pca), ('univ_select', selection)]": 1,
      "[('name', CountVectorizer(ngram_range=(1, 2), max_features=MAX_FEATURES_NM, preprocessor=build_preprocessor('name', arr))), ('nameD', CountVectorizer(token_pattern='\\\\d+', preprocessor=build_preprocessor('name', arr))), ('nameC', TfidfVectorizer(token_pattern='[a-zA-Z]+', max_features=700000, preprocessor=build_preprocessor('name', arr))), ('nameL', TfidfVectorizer(max_features=1000, preprocessor=build_preprocessor('nameL', arr))), ('nameWL', TfidfVectorizer(token_pattern='\\\\d+', max_features=100, preprocessor=build_preprocessor('nameWL', arr))), ('category_name', CountVectorizer(token_pattern='.+', preprocessor=build_preprocessor('category_name', arr))), ('brand_name', TfidfVectorizer(token_pattern='.+', preprocessor=build_preprocessor('brand_name', arr))), ('bmcn', TfidfVectorizer(token_pattern='.+', preprocessor=build_preprocessor('bmcn', arr))), ('cnbm_max', TfidfVectorizer(token_pattern='.+', preprocessor=build_preprocessor('cnbm_max', arr))), ('cnbm_min', TfidfVectorizer(token_pattern='.+', preprocessor=build_preprocessor('cnbm_min', arr))), ('maxs', TfidfVectorizer(token_pattern='.+', preprocessor=build_preprocessor('maxs', arr))), ('shipping', CountVectorizer(token_pattern='\\\\d+', preprocessor=build_preprocessor('shipping', arr))), ('item_condition_id', CountVectorizer(token_pattern='\\\\d+', preprocessor=build_preprocessor('item_condition_id', arr))), ('item_description', TfidfVectorizer(ngram_range=(1, 3), max_features=MAX_FEATURES_ITEM_DESCR, preprocessor=build_preprocessor('item_description', arr))), ('item_descriptionD', TfidfVectorizer(token_pattern='\\\\d+', max_features=100000, preprocessor=build_preprocessor('item_description', arr))), ('item_descriptionC', TfidfVectorizer(token_pattern='[a-zA-Z]+', max_features=MAX_FEATURES_ITEM_DESCR, preprocessor=build_preprocessor('item_description', arr))), ('item_descriptionL', TfidfVectorizer(max_features=1000, preprocessor=build_preprocessor('item_descriptionL', arr))), ('item_descriptionWL', TfidfVectorizer(token_pattern='\\\\d+', max_features=100, preprocessor=build_preprocessor('item_descriptionWL', arr)))]": 1,
      "[('nameD', CountVectorizer(token_pattern='\\\\d+', preprocessor=build_preprocessor('name', arr))), ('nameC', TfidfVectorizer(token_pattern='[a-zA-Z]+', max_features=MAX_FEATURES_NM, preprocessor=build_preprocessor('name', arr))), ('nameL', TfidfVectorizer(max_features=1000, preprocessor=build_preprocessor('nameL', arr))), ('nameWL', TfidfVectorizer(token_pattern='\\\\d+', max_features=100, preprocessor=build_preprocessor('nameWL', arr))), ('category_name', CountVectorizer(token_pattern='.+', max_features=1000, preprocessor=build_preprocessor('category_name', arr))), ('brand_name', TfidfVectorizer(token_pattern='.+', max_features=5004, preprocessor=build_preprocessor('brand_name', arr))), ('bmcn', TfidfVectorizer(token_pattern='.+', preprocessor=build_preprocessor('bmcn', arr))), ('cnbm_max', TfidfVectorizer(token_pattern='.+', preprocessor=build_preprocessor('cnbm_max', arr))), ('cnbm_min', TfidfVectorizer(token_pattern='.+', preprocessor=build_preprocessor('cnbm_min', arr))), ('maxs', TfidfVectorizer(token_pattern='.+', preprocessor=build_preprocessor('maxs', arr))), ('shipping', CountVectorizer(token_pattern='\\\\d+', preprocessor=build_preprocessor('shipping', arr))), ('item_condition_id', CountVectorizer(token_pattern='\\\\d+', preprocessor=build_preprocessor('item_condition_id', arr))), ('item_descriptionD', TfidfVectorizer(token_pattern='\\\\d+', max_features=1000, preprocessor=build_preprocessor('item_description', arr))), ('item_descriptionC', TfidfVectorizer(token_pattern='[a-zA-Z]+', max_features=MAX_FEATURES_ITEM_DESCR, preprocessor=build_preprocessor('item_description', arr))), ('item_descriptionL', TfidfVectorizer(max_features=1000, preprocessor=build_preprocessor('item_descriptionL', arr))), ('item_descriptionWL', TfidfVectorizer(token_pattern='\\\\d+', max_features=100, preprocessor=build_preprocessor('item_descriptionWL', arr)))]": 1,
      "[('xy', xy_pipe), ('date', date_pipe), ('count_feat', count_feat_pipe), ('cocrime', cocrime_pipe)]": 1,
      "[('name', Pipeline([('col_select', ColumnSelector('name')), ('tf_idf', TfidfVectorizer(stop_words='english', sublinear_tf=True))])), ('item_description', Pipeline([('col_select', ColumnSelector('item_description')), ('tf_idf', TfidfVectorizer(stop_words='english', sublinear_tf=True))])), ('category_name', Pipeline([('col_select', ColumnSelector('category_name')), ('tf_idf', TfidfVectorizer(stop_words='english', sublinear_tf=True))])), ('brand_name', Pipeline([('col_select', ColumnSelector('brand_name')), ('tf_idf', TfidfVectorizer(stop_words='english', sublinear_tf=True))])), ('is_shipping', ColumnSelector('shipping')), ('item_condition_id', Pipeline([('col_select', ColumnSelector('item_condition_id', is_ordinal=True)), ('one_binary', CountVectorizer(lowercase=False, binary=True))]))]": 1,
      "[('standard', cust_regression_vals()), ('pi1', Pipeline([('Gene', cust_txt_col('Gene')), ('vect_Gene', CountVectorizer(analyzer='char', max_df=0.5, ngram_range=(1, 2), max_features=None)), ('tsvd1', TruncatedSVD(n_iter=25, random_state=12, n_components=10))]))]": 1,
      "[('f_poly', Pipeline([('poly', PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)), ('scaler', StandardScaler())])), ('f_kpca', Pipeline([('scaler', StandardScaler()), ('kpca', KernelPCA(n_components=15, kernel='rbf', fit_inverse_transform=True, gamma=1))]))]": 1,
      "[('cont_portal', Pipeline([('selector', PortalToColDimension(contVars)), ('cont_imp', Imputer(missing_values='NaN', strategy='median', axis=0)), ('scaler', StandardScaler())])), ('tax_portal', Pipeline([('selector', PortalToColDimension(taxVars)), ('tax_imp', Imputer(missing_values='NaN', strategy='most_frequent', axis=0)), ('scaler', MinMaxScaler(copy=True, feature_range=(0, 3)))]))]": 1,
      "[('pca', PCA(n_components=100)), ('ct-2', ClassifierTransformer(get_rfc(), n_classes=2, cv=5)), ('ct-3', ClassifierTransformer(get_rfc(), n_classes=3, cv=5)), ('ct-4', ClassifierTransformer(get_rfc(), n_classes=4, cv=5)), ('ct-5', ClassifierTransformer(get_rfc(), n_classes=5, cv=5)), ('st', StatsTransformer(stat_funs=get_stat_funs()))]": 1,
      "[('numbers', numbers_pipeline), ('labels', labels_pipeline)]": 1,
      "[('building_high', CategoricalAverage('building_id', 'high')), ('building_medium', CategoricalAverage('building_id', 'medium')), ('manager_high', CategoricalAverage('manager_id', 'high')), ('manager_medium', CategoricalAverage('manager_id', 'medium'))]": 1,
      "[('assetCodeEncoder', Pipeline([('selector', FunctionTransformer(lambda X: X['assetCode'], validate=False)), ('label', LabelBinarizerPipelineFriendly(sparse_output=True)), ('t-svd', TruncatedSVD(10)), ('repeater', Repeater())])), ('numericFeatures', Pipeline([('selector', FunctionTransformer(lambda X: X[market_numeric_features], validate=False)), ('fillNa', FunctionTransformer(lambda X: X.fillna(0), validate=False)), ('scale', StandardScaler()), ('repeater', Repeater())]))]": 1,
      "[('num_pipeline', num_pipeline), ('cat_pipeline', cat_pipeline), ('date_pipeline', date_pipeline)]": 1,
      "[('name_trigram', Pipeline([('selector', ItemSelector(key='name')), ('preprocessor', DataPreprocessor()), ('normalizer', DataNormalizer()), ('tfidf', TfidfVectorizer(ngram_range=(1, 3), max_features=75000, lowercase=False, min_df=2))])), ('name_bigram_hash', Pipeline([('selector', ItemSelector(key='name')), ('preprocessor', DataPreprocessor()), ('normalizer', DataNormalizer()), ('hv', HashingVectorizer(ngram_range=(1, 2), lowercase=False, stop_words='english', norm='l2'))])), ('name_stats', Pipeline([('selector', ItemSelector(key='name')), ('stats', TextStats()), ('vect', DictVectorizer())])), ('category_name', Pipeline([('selector', ItemSelector(key='category_name')), ('preprocessor', DataPreprocessor()), ('cv', CountVectorizer(token_pattern='.+'))])), ('general_cat', Pipeline([('selector', ItemSelector(key='general_cat')), ('preprocessor', DataPreprocessor()), ('cv', CountVectorizer(token_pattern='.+', min_df=2))])), ('subcat_1', Pipeline([('selector', ItemSelector(key='subcat_1')), ('preprocessor', DataPreprocessor()), ('cv', CountVectorizer(token_pattern='.+', min_df=2))])), ('subcat_2', Pipeline([('selector', ItemSelector(key='subcat_2')), ('preprocessor', DataPreprocessor()), ('cv', CountVectorizer(token_pattern='.+', min_df=2))])), ('brand_name', Pipeline([('selector', ItemSelector(key='brand_name')), ('preprocessor', DataPreprocessor()), ('cv', CountVectorizer(token_pattern='.+', min_df=2))])), ('shipping', Pipeline([('selector', ItemSelector(key='shipping')), ('preprocessor', DataPreprocessor()), ('cv', CountVectorizer(token_pattern='\\\\d+'))])), ('item_condition_id', Pipeline([('selector', ItemSelector(key='item_condition_id')), ('preprocessor', DataPreprocessor()), ('cv', CountVectorizer(token_pattern='\\\\d+'))])), ('item_description_trigram', Pipeline([('selector', ItemSelector(key='item_description')), ('preprocessor', DataPreprocessor()), ('normalizer', DataNormalizer()), ('tfidf', TfidfVectorizer(ngram_range=(1, 3), max_features=100000, lowercase=False))])), ('item_description_bigram_hash', Pipeline([('selector', ItemSelector(key='item_description')), ('preprocessor', DataPreprocessor()), ('normalizer', DataNormalizer()), ('hv', HashingVectorizer(ngram_range=(1, 2), lowercase=False, stop_words='english', norm='l2'))])), ('item_description_stats', Pipeline([('selector', ItemSelector(key='item_description')), ('stats', TextStats()), ('vect', DictVectorizer())]))]": 1,
      "[('text', text), ('num_feats', num_feats)]": 1,
      "[('scaled', XScaler(select_columns=lr_num_vars, transformer=StandardScaler(), return_is_none_vars=False)), ('binary', XVarSelector(lr_bin_vars))]": 1,
      "[('scaled', XScaler(select_columns=gb_num_vars, transformer=MinMaxScaler(), none_value=-100, return_is_none_vars=False)), ('nominal', XVarSelector(gb_cat_vars))]": 1,
      "[('cst', Pipeline([('cst1', cust_regression_vals())])), ('txt1', Pipeline([('s1', cust_txt_col(key='question1')), ('tfidf1', tfidf)])), ('txt2', Pipeline([('s2', cust_txt_col(key='question2')), ('tfidf2', tfidf)]))]": 1,
      "[('preprocess', preprocess), ('feature_engineer', feature_engineering(feature_engineer))]": 1,
      "[('project_title', CountVectorizer(ngram_range=(1, 2), max_features=5000, preprocessor=lambda x: x['project_title'])), ('project_resource_summary', TfidfVectorizer(ngram_range=(1, 2), max_features=10000, preprocessor=lambda x: x['project_resource_summary'])), ('student_description', TfidfVectorizer(ngram_range=(1, 2), max_features=40000, preprocessor=lambda x: x['student_description'])), ('project_description', TfidfVectorizer(ngram_range=(1, 2), max_features=40000, preprocessor=lambda x: x['project_description'])), ('collated_description', TfidfVectorizer(ngram_range=(1, 2), max_features=30000, preprocessor=lambda x: x['collated_description'])), ('Non_text', DictVectorizer())]": 1,
      "[('Categorical_Pipeline', cat_pipeline), ('Quantitative_Pipeline', cont_pipeline)]": 1,
      "[('text', text), ('length', length), ('words', words), ('num_unique_words', num_unique_words), ('num_chars', num_chars), ('num_words_upper', num_words_upper), ('num_words_title', num_words_title), ('words_not_stopword', words_not_stopword), ('avg_word_length', avg_word_length), ('commas', commas)]": 1,
      "[('cst', cust_regression_vals()), ('txt1', pipeline.Pipeline([('s1', cust_txt_col(key='search_term')), ('tfidf1', tfidf), ('tsvd1', tsvd)])), ('txt2', pipeline.Pipeline([('s2', cust_txt_col(key='product_title')), ('tfidf2', tfidf), ('tsvd2', tsvd)])), ('txt3', pipeline.Pipeline([('s3', cust_txt_col(key='product_description')), ('tfidf3', tfidf), ('tsvd3', tsvd)])), ('txt4', pipeline.Pipeline([('s4', cust_txt_col(key='brand')), ('tfidf4', tfidf), ('tsvd4', tsvd)])), ('txt5', pipeline.Pipeline([('s5', cust_txt_col(key='material')), ('tfidf5', tfidf), ('tsvd5', tsvd)])), ('txt6', pipeline.Pipeline([('s6', cust_txt_col(key='color')), ('tfidf6', tfidf), ('tsvd6', tsvd)]))]": 1,
      "[('transform_text', Pipeline([('select_column', ColumnSelector(key='Text')), ('tfidf', TfidfVectorizer(analyzer='word', max_df=0.9, stop_words='english', norm='l2', sublinear_tf=True, use_idf=True)), ('svd', TruncatedSVD(algorithm='randomized', n_components=100))])), \"\\n            ('transform_categories',\\n             Pipeline([\\n                 ('select_columns', ColumnSelector(key=['Gene', 'Variation'])),\\n                 ('dummy_mca', DummyMCA(n_factors=207)),\\n             ]),\\n             ),\\n             \"('transform_categories', Pipeline([('select_columns', ColumnSelector(key=['Gene', 'Variation'])), ('get_dummy', GetDummies())]))]": 1,
      "[('name', Pipeline([('selector', ItemSelector('name')), ('transformer', FillNa('Unknown')), ('vectorizer', TfidfVectorizer(use_idf=False, min_df=3, token_pattern='(?u)\\\\b\\\\w+\\\\b', analyzer='word', ngram_range=(1, 3), strip_accents='ascii', stop_words=stopwords.words('english'))), ('log', LoggingTransformer('End of name')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log2', LoggingTransformer('End of name vt'))])), ('name2', Pipeline([('selector', ItemSelector('name')), ('transformer', FillNa('null')), ('lowalphanum', LowAlphaNum()), ('vectorizer', TfidfVectorizer(use_idf=False, min_df=3, analyzer='char', ngram_range=(2, 6), strip_accents='ascii')), ('log', LoggingTransformer('End of name char')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log2', LoggingTransformer('End of name char vt'))])), ('item_description', Pipeline([('selector', ItemSelector('item_description')), ('transformer', FillNa('No description yet')), ('vectorizer', TfidfVectorizer(use_idf=False, min_df=3, token_pattern='(?u)\\\\b\\\\w+\\\\b', analyzer='word', ngram_range=(1, 3), strip_accents='ascii', stop_words=stopwords.words('english'))), ('log', LoggingTransformer('End of item_description')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log2', LoggingTransformer('End of item_description vt'))])), ('item_condition_id', Pipeline([('selector', ItemSelector(['item_condition_id'])), ('transformer', FillNa(9999)), ('ohe', OneHotEncoder(handle_unknown='ignore')), ('log', LoggingTransformer('End of item_condition_id'))])), ('item_condition_id_2', Pipeline([('selector', ItemSelector(['item_condition_id'])), ('log', LoggingTransformer('End of item_condition_id_2'))])), ('category_name', Pipeline([('selector', ItemSelector('category_name')), ('transformer', FillNa('Unknown')), ('vectorizer', CountVectorizer(token_pattern='[^/]+', min_df=3, binary=True, analyzer='word', ngram_range=(1, 5), strip_accents='ascii')), ('log', LoggingTransformer('End of category_name'))])), ('category_name_2', Pipeline([('selector', ItemSelector('category_name')), ('transformer', FillNa('Unknown')), ('vectorizer', CountVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b', min_df=3, binary=True, analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of category_name 2'))])), ('brand_name', Pipeline([('be', BrandExtractor()), ('vectorizer', CountVectorizer(token_pattern='.+', min_df=3, binary=True, analyzer='word', ngram_range=(1, 1), strip_accents='ascii')), ('log', LoggingTransformer('End of brand'))])), ('brand_name_2', Pipeline([('selector', ItemSelector('brand_name')), ('transformer', FillNa('Unknown')), ('vectorizer', CountVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b', min_df=3, binary=True, analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of brand 2'))])), ('shipping', Pipeline([('selector', ItemSelector(['shipping'])), ('log', LoggingTransformer('End of shipping'))]))]": 1,
      "[('name', Pipeline([('selector', ItemSelector('name')), ('transformer', FillNa('Unknown')), ('vectorizer', TfidfVectorizer(use_idf=False, min_df=10, token_pattern='(?u)\\\\b\\\\w+\\\\b', analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of name')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log2', LoggingTransformer('End of name vt'))])), ('name2', Pipeline([('selector', ItemSelector('name')), ('transformer', FillNa('Unknown')), ('vectorizer', MixedTfidfVectorizer(use_idf=False, min_df=10, token_pattern='(?u)\\\\b\\\\w+\\\\b', analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of name2')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log2', LoggingTransformer('End of name2 vt'))])), ('item_description', Pipeline([('selector', ItemSelector('item_description')), ('transformer', FillNa('No description yet')), ('vectorizer', TfidfVectorizer(use_idf=False, min_df=10, token_pattern='(?u)\\\\b\\\\w+\\\\b', analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of item_description')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log2', LoggingTransformer('End of item_description vt'))])), ('item_condition_id', Pipeline([('selector', ItemSelector(['item_condition_id'])), ('transformer', FillNa(9999)), ('ohe', OneHotEncoder(handle_unknown='ignore')), ('log', LoggingTransformer('End of item_condition_id'))])), ('item_condition_id_2', Pipeline([('selector', ItemSelector(['item_condition_id'])), ('log', LoggingTransformer('End of item_condition_id_2'))])), ('category_name', Pipeline([('selector', ItemSelector('category_name')), ('transformer', FillNa('Unknown')), ('vectorizer', CountVectorizer(token_pattern='[^/]+', min_df=3, binary=True, analyzer='word', ngram_range=(1, 5), strip_accents='ascii')), ('log', LoggingTransformer('End of category_name'))])), ('category_name_2', Pipeline([('selector', ItemSelector('category_name')), ('transformer', FillNa('Unknown')), ('vectorizer', CountVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b', min_df=3, binary=True, analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of category_name 2'))])), ('brand_name', Pipeline([('selector', ItemSelector('brand_name')), ('transformer', FillNa('Unknown')), ('vectorizer', CountVectorizer(token_pattern='.+', min_df=3, binary=True, analyzer='word', ngram_range=(1, 1), strip_accents='ascii')), ('log', LoggingTransformer('End of brand'))])), ('brand_name_2', Pipeline([('selector', ItemSelector('brand_name')), ('transformer', FillNa('Unknown')), ('vectorizer', CountVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b', min_df=3, binary=True, analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of brand 2'))])), ('shipping', Pipeline([('selector', ItemSelector(['shipping'])), ('log', LoggingTransformer('End of shipping'))]))]": 1,
      "[('name', Pipeline([('selector', ItemSelector('name')), ('transformer', FillNa('Unknown')), ('vectorizer', TfidfVectorizer(use_idf=False, min_df=3, token_pattern='(?u)\\\\b\\\\w+\\\\b', analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of name')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log2', LoggingTransformer('End of name vt'))])), ('name2', Pipeline([('selector', ItemSelector('name')), ('transformer', FillNa('null')), ('lowalphanum', LowAlphaNum()), ('vectorizer', TfidfVectorizer(use_idf=False, min_df=3, analyzer='char', ngram_range=(2, 6), strip_accents='ascii')), ('log', LoggingTransformer('End of name char')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log2', LoggingTransformer('End of name char vt'))])), ('item_description', Pipeline([('selector', ItemSelector('item_description')), ('transformer', FillNa('No description yet')), ('vectorizer', TfidfVectorizer(use_idf=False, min_df=3, token_pattern='(?u)\\\\b\\\\w+\\\\b', analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of item_description')), ('vt', VarianceThreshold(VARIANCE_THRESHOLD)), ('log2', LoggingTransformer('End of item_description vt'))])), ('item_condition_id', Pipeline([('selector', ItemSelector(['item_condition_id'])), ('transformer', FillNa(9999)), ('ohe', OneHotEncoder(handle_unknown='ignore')), ('log', LoggingTransformer('End of item_condition_id'))])), ('item_condition_id_2', Pipeline([('selector', ItemSelector(['item_condition_id'])), ('imputer', Imputer()), ('log', LoggingTransformer('End of item_condition_id_2'))])), ('category_name', Pipeline([('selector', ItemSelector('category_name')), ('transformer', FillNa('Unknown')), ('vectorizer', CountVectorizer(token_pattern='[^/]+', min_df=3, binary=True, analyzer='word', ngram_range=(1, 5), strip_accents='ascii')), ('log', LoggingTransformer('End of category_name'))])), ('category_name_2', Pipeline([('selector', ItemSelector('category_name')), ('transformer', FillNa('Unknown')), ('vectorizer', CountVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b', min_df=3, binary=True, analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of category_name 2'))])), ('brand_name', Pipeline([('selector', ItemSelector('brand_name')), ('transformer', FillNa('Unknown')), ('vectorizer', CountVectorizer(token_pattern='.+', min_df=3, binary=True, analyzer='word', ngram_range=(1, 1), strip_accents='ascii')), ('log', LoggingTransformer('End of brand'))])), ('brand_name_2', Pipeline([('selector', ItemSelector('brand_name')), ('transformer', FillNa('Unknown')), ('vectorizer', CountVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b', min_df=3, binary=True, analyzer='word', ngram_range=(1, 2), strip_accents='ascii')), ('log', LoggingTransformer('End of brand 2'))])), ('shipping', Pipeline([('selector', ItemSelector(['shipping'])), ('imputer', Imputer()), ('log', LoggingTransformer('End of shipping'))]))]": 1,
      "[('name_select', name_pipeline)]": 1,
      "[('Text_Feature', text), ('propn_count', propn_count)]": 1,
      "[('name', CountVectorizer(ngram_range=(1, 2), max_features=50000, preprocessor=build_preprocessor('name'))), ('subcat_0', CountVectorizer(token_pattern='.+', preprocessor=build_preprocessor('subcat_0'))), ('subcat_1', CountVectorizer(token_pattern='.+', preprocessor=build_preprocessor('subcat_1'))), ('subcat_2', CountVectorizer(token_pattern='.+', preprocessor=build_preprocessor('subcat_2'))), ('brand_name', CountVectorizer(token_pattern='.+', preprocessor=build_preprocessor('brand_name'))), ('shipping', CountVectorizer(token_pattern='\\\\d+', preprocessor=build_preprocessor('shipping'))), ('item_condition_id', CountVectorizer(token_pattern='\\\\d+', preprocessor=build_preprocessor('item_condition_id'))), ('desc_len', CountVectorizer(token_pattern='\\\\d+', preprocessor=build_preprocessor('desc_len'))), ('name_len', CountVectorizer(token_pattern='\\\\d+', preprocessor=build_preprocessor('name_len'))), ('item_description', TfidfVectorizer(ngram_range=(1, 3), max_features=100000, preprocessor=build_preprocessor('item_description')))]": 1,
      "[('category', Pipeline([('selector', get_category_data)])), ('numeric', Pipeline([('selector', get_numeric_data), ('scale', MinMaxScaler())])), ('text', Pipeline([('selector', get_text_data), ('vect', CountVectorizer(tokenizer=tokenize)), ('tfidf', TfidfTransformer())]))]": 1,
      "[('num_mapper', numeric_imputation_mapper), ('cat_mapper', categorical_imputation_mapper)]": 1,
      "[('standard', cust_regression_vals()), ('pi1', pipeline.Pipeline([('Gene', cust_txt_col('Gene')), ('count_Gene', feature_extraction.text.CountVectorizer(analyzer='char', ngram_range=(1, 8))), ('tsvd1', decomposition.TruncatedSVD(n_components=20, n_iter=25, random_state=12))])), ('pi2', pipeline.Pipeline([('Variation', cust_txt_col('Variation')), ('count_Variation', feature_extraction.text.CountVectorizer(analyzer='char', ngram_range=(1, 8))), ('tsvd2', decomposition.TruncatedSVD(n_components=20, n_iter=25, random_state=12))]))]": 1,
      "[('tfdif_features', Pipeline([('cv', CountVectorizer()), ('tfidf', TfidfTransformer())])), ('pos_features', Pipeline([('pos', PosTagMatrix(tokenizer=nltk.word_tokenize))]))]": 1,
      "[('tfdif_features', Pipeline([('cv', CountVectorizer()), ('tfidf', TfidfTransformer()), ('tfidf_logit', ClassifierWrapper(LogisticRegression()))])), ('pos_features', Pipeline([('pos', PosTagMatrix(tokenizer=nltk.word_tokenize)), ('pos_logit', ClassifierWrapper(LogisticRegression()))]))]": 1,
      "[('tfdif_features', Pipeline([('cv', CountVectorizer()), ('tfidf', TfidfTransformer()), ('tfidf_logit', ClassifierWrapper(LogisticRegression()))], memory='/tmp')), ('pos_features', Pipeline([('pos', PosTagMatrix(tokenizer=nltk.word_tokenize)), ('pos_logit', ClassifierWrapper(LogisticRegression()))], memory='/tmp'))]": 1,
      "[('words', TfidfVectorizer(ngram_range=(1, 3), analyzer='word')), ('chars', TfidfVectorizer(ngram_range=(1, 3), analyzer='char'))]": 1,
      "[('comment_text_2', Pipeline([('select', ItemSelector('comment_text', start_time=start_time)), ('transform', TfidfVectorizer(sublinear_tf=True, strip_accents='unicode', analyzer='word', stop_words='english', token_pattern='\\\\w{1,}', ngram_range=(1, 1), max_features=15000)), ('drop_cols', DropColumnsByDf(min_df=2))])), ('comment_text_3', Pipeline([('select', ItemSelector('comment_text', start_time=start_time)), ('transform', TfidfVectorizer(sublinear_tf=True, strip_accents='unicode', analyzer='char', stop_words='english', ngram_range=(2, 6), max_features=20000)), ('drop_cols', DropColumnsByDf(min_df=2))])), ('abuse_list', Pipeline([('select', ItemSelector('abuse_list', start_time=start_time)), ('ohe', MyLabelEncoder())])), ('num_abuses', Pipeline([('select', ItemSelector('num_abuses', start_time=start_time)), ('ohe', OneHotEncoder())]))]": 1,
      "[('cat_pipeline', old_cat_pipeline), ('num_pipeline', old_num_pipeline), ('skew_pipeline', skew_num_pipeline)]": 1,
      "[('margin_pipeline', margin_pipeline), ('shape_pipeline', shape_pipeline), ('texture_pipeline', texture_pipeline)]": 1,
      "[('pip,num', pipeline_num), ('pip_cat', pipeline_cat)]": 1,
      "[('text', TfidfVectorizer(ngram_range=(1, 2), max_features=20000, **tfidf_para, preprocessor=get_col('text'))), ('project_resource_summary', TfidfVectorizer(ngram_range=(1, 2), **tfidf_para, max_features=2000, preprocessor=get_col('project_resource_summary'))), ('project_title', TfidfVectorizer(ngram_range=(1, 2), **tfidf_para, max_features=1500, preprocessor=get_col('project_title'))), ('project_title_count', CountVectorizer(ngram_range=(1, 2), max_features=1500, preprocessor=get_col('project_title_count'))), ('description', TfidfVectorizer(ngram_range=(1, 2), **tfidf_para, max_features=2400, preprocessor=get_col('description')))]": 1,
      "[('JOB_DUTIES', TfidfVectorizer(stop_words='english', preprocessor=build_preprocessor('JOB_DUTIES'))), ('REQUIREMENTS', TfidfVectorizer(stop_words='english', preprocessor=build_preprocessor('REQUIREMENTS'))), ('EXP_JOB_CLASS_FUNCTION', TfidfVectorizer(preprocessor=build_preprocessor('EXP_JOB_CLASS_FUNCTION')))]": 1,
      "[('name', CountVectorizer(ngram_range=(1, 2), max_features=50000, token_pattern='(?u)\\\\b(?:\\\\w\\\\w+)|(?:\\\\d+\\\\.|/\\\\d+)\\\\b', preprocessor=build_preprocessor('name'))), ('category_name', CountVectorizer(token_pattern='.+', preprocessor=build_preprocessor('category_name'))), ('brand_name', CountVectorizer(token_pattern='.+', preprocessor=build_preprocessor('brand_name'))), ('shipping', CountVectorizer(token_pattern='\\\\d+', preprocessor=build_preprocessor('shipping'))), ('item_condition_id', CountVectorizer(token_pattern='\\\\d+', preprocessor=build_preprocessor('item_condition_id'))), ('item_description', TfidfVectorizer(ngram_range=(1, 3), max_features=100000, token_pattern='(?u)\\\\b(?:\\\\w\\\\w+)|(?:\\\\d+\\\\.|/\\\\d+)\\\\b', preprocessor=build_preprocessor('item_description')))]": 1,
      "transforms": 1,
      "[('features', SimpleImputer(strategy='median')), ('indicators', MissingIndicator())]": 1,
      "[('description', TfidfVectorizer(ngram_range=(1, 2), max_features=70000, **tfidf_para, preprocessor=get_col('description'))), ('text_feat', CountVectorizer(ngram_range=(1, 2), preprocessor=get_col('text_feat'))), ('title', TfidfVectorizer(ngram_range=(1, 2), **tfidf_para, preprocessor=get_col('title')))]": 1,
      "[('ct', CountVectorizer(analyzer='char', ngram_range=(1, 5), max_df=0.9)), ('ct2', CountVectorizer(analyzer='word', ngram_range=(1, 4), max_df=0.9))]": 1,
      "[('name', CountVectorizer(ngram_range=(1, 2), max_features=50000, preprocessor=build_preprocessor('name'))), ('category_name', CountVectorizer(token_pattern='.+', preprocessor=build_preprocessor('category_name'))), ('brand_name', CountVectorizer(token_pattern='.+', preprocessor=build_preprocessor('brand_name'))), ('shipping', CountVectorizer(token_pattern='\\\\d+', preprocessor=build_preprocessor('shipping'))), ('item_condition_id', CountVectorizer(token_pattern='\\\\d+', preprocessor=build_preprocessor('item_condition_id'))), ('item_description', TfidfVectorizer(ngram_range=(1, 2), max_features=55000, stop_words='english', preprocessor=build_preprocessor('item_description')))]": 1,
      "pipeline": 1,
      "[('x', IdentityTransformer()), ('x2_interactions', ColumnTransformer([('top10_interactions', PolynomialFeatures(2, interaction_only=True, include_bias=False), [44, 45, 41, 42, 43, 62, 5, 60, 63, 6])]))]": 1,
      "[('pca', PCA(n_components=100)), ('ct-2', ClassifierTransformer(get_rfc(), n_classes=2, cv=5)), ('ct-3', ClassifierTransformer(get_rfc(), n_classes=3, cv=5)), ('ct-4', ClassifierTransformer(get_rfc(), n_classes=4, cv=5)), ('ct-5', ClassifierTransformer(get_rfc(), n_classes=5, cv=5)), ('st', StatsTransformer(stat_funs=get_stat_funs(), verbose=2))]": 1,
      "[('pca', gene_pipe), ('qt', QuantileTransformer(output_distribution='normal'))]": 1,
      "[('pca', cell_pipe), ('qt', QuantileTransformer(output_distribution='normal'))]": 1,
      "[('text_features', Pipeline([('selector', get_text_data), ('vectorizer', CountVectorizer(analyzer='word', ngram_range=[1, 3], stop_words=nltk.corpus.stopwords.words('english')))]))]": 1,
      "[('comment_text', TfidfVectorizer(ngram_range=(1, 2), tokenizer=tokenize, min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1, smooth_idf=1, sublinear_tf=1, preprocessor=build_preprocessor('comment_text'))), ('comment_text_char', TfidfVectorizer(sublinear_tf=True, strip_accents='unicode', analyzer='char', stop_words='english', ngram_range=(2, 6), max_features=20000, preprocessor=build_preprocessor('comment_text_char')))]": 1,
      "[('tfidf_w', tfidf_w), ('tfidf_c', tfidf_c)]": 1,
      "[('pca', PCA(n_components=100)), ('ct-2', ClassifierTransformer(get_rfc(), n_classes=2, cv=5)), ('ct-3', ClassifierTransformer(get_rfc(), n_classes=3, cv=5)), ('ct-5', ClassifierTransformer(get_rfc(), n_classes=5, cv=5)), ('ct-auto', ClassifierTransformer(get_rfc(), n_classes='auto', cv=5)), ('st', StatsTransformer(stat_funs=get_stat_funs(), verbose=2))]": 1,
      "[('binary_variables_processing', FunctionTransformer(lambda data: data.iloc[:, binary_data_indices])), ('numeric_variables_processing', Pipeline(steps=[('selecting', FunctionTransformer(lambda data: data.iloc[:, numeric_data_indices])), ('scaling', StandardScaler(with_mean=True))])), ('numeric_variables_log_processing', Pipeline(steps=[('selecting', FunctionTransformer(lambda data: data.iloc[:, numeric_data_indices_log])), ('scaling', PowerTransformer(standardize=True))])), ('categorical_variables_processing', Pipeline(steps=[('selecting', FunctionTransformer(lambda data: data.iloc[:, categorical_data_indices])), ('hot_encoding', OneHotEncoder(handle_unknown='ignore'))]))]": 1,
      "[('description', TfidfVectorizer(ngram_range=(1, 2), max_features=17000, **tfidf_para, preprocessor=get_col('description'))), ('title', CountVectorizer(ngram_range=(1, 2), stop_words=russian_stop, max_features=130000, preprocessor=get_col('title')))]": 1,
      "[('onehot_features', ItemSelector(['brand_condition', 'brand_shipping', 'item_condition_id', 'gencat_name', 'subcat1_name', 'subcat2_name', 'brand_name', 'imputed_brand', 'shipping', 'has_missing'])), ('numeric_features', Pipeline([('selector', ItemSelector(fields=['len_name', 'len_desc', 'max_word_desc', 'nsents_desc', 'fstartcaps_desc', 'fcaps_name', 'fstartcaps_name'])), ('minmaxscaler', MinMaxScaler())])), ('name_cv', Pipeline([('selector', ItemSelector(fields='name')), ('cv', MPCountVectorizer(ngram_weight=[1.5, 1.0], seq_l=20, analyzer=analyzer, min_df=4))])), ('item_desc_cv', Pipeline([('selector', ItemSelector(fields='item_description')), ('cv', MPCountVectorizer(ngram_weight=[1.0, 1.0], seq_l=75, analyzer=analyzer, min_df=9)), ('tfidf', TfidfTransformer(sublinear_tf=True))]))]": 1,
      "[('nonlinear_predictors', Pipeline([('interaction_remover', FeatureRemover(np.array([0, 1, 9]))), ('feature_filter', FeatureFilter(100)), ('lgbm', LGBMWrapper(params={'learning_rate': 0.6, 'application': 'regression', 'max_depth': 3, 'num_leaves': 60, 'verbosity': -1, 'metric': 'RMSE', 'data_random_seed': 1, 'bagging_fraction': 0.5, 'nthread': 4, 'min_data_in_leaf': 200, 'max_bin': 30}, num_boost_round=5000, early_stopping_rounds=250, verbose_eval=1000, categorical_feature=list(range(6))))])), ('linear_predictors', Pipeline([('ohe', SparseOneHotEncoder(categorical_features=np.arange(8))), ('feature_filter', FeatureFilter(2)), ('linear_regressors', FeatureUnion([('fm_ftrl', FM_FTRLWrapper(alpha=0.015123039358983292, beta=0.003696159595914427, L1=0.0001071848083393167, L2=0.15063815187520505, alpha_fm=0.009424503125353001, L2_fm=0.0, init_fm=0.01, D_fm=157, e_noise=0.00011964508569471388, iters=18, inv_link='identity', threads=4))]))]))]": 1,
      "[('fm_ftrl', FM_FTRLWrapper(alpha=0.015123039358983292, beta=0.003696159595914427, L1=0.0001071848083393167, L2=0.15063815187520505, alpha_fm=0.009424503125353001, L2_fm=0.0, init_fm=0.01, D_fm=157, e_noise=0.00011964508569471388, iters=18, inv_link='identity', threads=4))]": 1,
      "[('description', TfidfVectorizer(ngram_range=(1, 2), max_features=17000, **tfidf_para, preprocessor=get_col('description'))), ('title', CountVectorizer(ngram_range=(1, 2), stop_words=russian_stop, max_features=7000, preprocessor=get_col('title')))]": 1,
      "[('num_pipeline', num_pipeline), ('cat_pipeline', cat_pipeline), ('bincat', bin_cat)]": 1,
      "[('description_tdfidf', Pipeline([('selector', ItemSelector(key='item_description')), ('tfidf', TfidfVectorizer(max_df=0.95, min_df=2, max_features=5000, stop_words='english', ngram_range=(1, 3))), ('svd', TruncatedSVD(n_components=100))])), ('the_rest_of_the_data_frame', Pipeline([('selector_2', ItemSelector(['item_condition_id', 'cat0', 'cat1', 'cat2', 'brand_name', 'shipping'])), ('encode_cat', DataFrameLabelEncoder(['cat0', 'cat1', 'cat2', 'brand_name'])), ('onehot_encode', OneHotEncoder(categorical_features=[1, 2, 3, 4]))]))]": 1,
      "[('description', TfidfVectorizer(ngram_range=(1, 2), max_features=1000, **tfidf_para, preprocessor=get_col('description'))), ('title', CountVectorizer(ngram_range=(1, 2), stop_words=russian_stop, max_features=100, preprocessor=get_col('title')))]": 1,
      "[('text_length', LengthTransformer()), ('word_count', WordCountTransformer()), ('mean_length', MeanLengthTransformer()), ('punctuation_count', PunctuationCountTransformer()), ('stop_words_count', StopWordsCountTransformer()), ('count_vect', CountVectorizer(lowercase=False)), ('tf_idf', TfidfVectorizer())]": 1,
      "[('number', number_pipe), ('semi-number', semi_number_pipe), ('datetime', datetime_pipe), ('object', object_pipe)]": 1,
      "[('numerical_pipe', numerical_pipe), ('categorical_pipe', categorical_pipe), ('text_pipe', text_pipe)]": 1,
      "[('gt_min', FunctionTransformer(lambda x: x > x.min())), ('gt_0', FunctionTransformer(lambda x: x > 0)), ('inverse', FunctionTransformer(lambda x: 1 / (x + 0.01))), ('idenity', FunctionTransformer(lambda x: x)), ('squared-polynomial', FunctionTransformer(lambda x: x**2)), ('cubed-polynomial', FunctionTransformer(lambda x: x**3)), ('quartic-polynomial', FunctionTransformer(lambda x: x**4)), ('piecewise-0-25-percentiles', FunctionTransformer(lambda x: np.clip(x, -np.Inf, -0.68))), ('piecewise-25-50-percentiles', FunctionTransformer(lambda x: np.clip(x, -0.68, 0))), ('piecewise-50-75-percentiles', FunctionTransformer(lambda x: np.clip(x, 0, 0.68))), ('piecewise-75-100-percentiles', FunctionTransformer(lambda x: np.clip(x, 0.68, np.Inf)))]": 1,
      "[('idenity', FunctionTransformer(lambda x: x)), ('squared-polynomial', FunctionTransformer(lambda x: x**2)), ('cubed-polynomial', FunctionTransformer(lambda x: x**3)), ('piecewise-0-25-percentiles', FunctionTransformer(lambda x: np.clip(x, -np.Inf, -0.68))), ('piecewise-25-50-percentiles', FunctionTransformer(lambda x: np.clip(x, -0.68, 0))), ('piecewise-50-75-percentiles', FunctionTransformer(lambda x: np.clip(x, 0, 0.68))), ('piecewise-75-100-percentiles', FunctionTransformer(lambda x: np.clip(x, 0.68, np.Inf)))]": 1,
      "[('kbest', MajorityVotingSelectKBest(k=40)), ('pca', PCAModifier(n_components=10))]": 1,
      "[('tf_idf', Pipeline([('extract_field', description_selector), ('tfidf', tf_idf), ('lda', lda)])), ('no_tfidf', nodescription_selector)]": 1,
      "[('category_name', CountVectorizer(token_pattern='.+', preprocessor=build_preprocessor('category_name'))), ('brand_name', CountVectorizer(token_pattern='.+', preprocessor=build_preprocessor('brand_name'))), ('shipping', CountVectorizer(token_pattern='\\\\d+', preprocessor=build_preprocessor('shipping'))), ('item_condition_id', CountVectorizer(token_pattern='\\\\d+', preprocessor=build_preprocessor('item_condition_id'))), ('item_description', TfidfVectorizer(ngram_range=(1, 3), max_features=100000, preprocessor=build_preprocessor('item_description')))]": 1,
      "[('categories', Pipeline([('filter', FunctionTransformer(lambda X: X[:, [0]], validate=False)), ('binarizer', OneHotEncoder()), ('shape1', FunctionTransformer(_print_shape, validate=False))])), ('parentCategories', Pipeline([('filter', FunctionTransformer(lambda X: X[:, [1]], validate=False)), ('binarizer', OneHotEncoder()), ('shape1', FunctionTransformer(_print_shape, validate=False))])), ('titles', Pipeline([('filter', FunctionTransformer(lambda X: X[:, [2, 3]], validate=False)), ('titleswitch', TextTransformer(CountVectorizer(binary=True))), ('logreg', SupervisedTransformer(LogisticRegression(C=0.01), 'predict_proba')), ('selector', FunctionTransformer(lambda X: X[:, [1]])), ('shape1', FunctionTransformer(_print_shape, validate=False))])), ('locationID', Pipeline([('filter', FunctionTransformer(lambda X: X[:, [4, 5]].astype(int), validate=False)), ('binarizer', EqNotEqBinarizer()), ('threshold', VarianceThreshold(0.0001)), ('shape1', FunctionTransformer(_print_shape, validate=False))])), ('regionID', Pipeline([('filter', FunctionTransformer(lambda X: X[:, [6, 7]].astype(int), validate=False)), ('binarizer', EqNotEqBinarizer()), ('threshold', VarianceThreshold(0.0001)), ('shape1', FunctionTransformer(_print_shape, validate=False))])), ('metroID', Pipeline([('filter', FunctionTransformer(lambda X: X[:, [8, 9]].astype(int), validate=False)), ('binarizer', EqNotEqBinarizer()), ('threshold', VarianceThreshold(0.0001)), ('shape1', FunctionTransformer(_print_shape, validate=False))]))]": 1,
      "[('textcounts', ColumnExtractor(cols=textcountscols)), ('pipe', Pipeline([('cleantext', ColumnExtractor(cols='clean_text')), ('vect', CountVectorizer(max_df=0.5, min_df=1, ngram_range=(1, 2)))]))]": 1,
      "[('label', label_pipeline), ('label_pipeline_weather', label_pipeline_weather), ('label_pipeline_season', label_pipeline_season), ('windspeed', windspeed_pipline), ('min_max', min_max_pipeline), ('temp', temp_pipeline)]": 1,
      "[('one_hot', one_hot_pipeline), ('min_max', min_max_pipeline)]": 1
    },
    "sklearn.pipeline.FeatureUnion.__init__.transformer_weights": {
      "None": 204,
      "{'cst': 1.0, 'txt1': 0.5, 'txt2': 0.25, 'txt3': 0.0, 'txt4': 0.5}": 81,
      "{'cst': 1.0}": 15,
      "{'cst': 1.0, 'txt1': 1.0, 'txt2': 1.0}": 7,
      "{'cst': 1.0, 'txt1': 0.5, 'txt2': 0.25, 'txt4': 0.5}": 5,
      "{'cst': 1.0, 'txt1': 0.5, 'txt2': 0.28, 'txt3': 0.0, 'txt4': 0.6}": 4,
      "{'cst': 1.0, 'txt1': 0.5, 'txt2': 0.25, 'txt3': 0.01, 'txt4': 0.5}": 3,
      "{'tfidf': 4, 'hash': 5}": 2,
      "{'cst': 1.0, 'txt1': 1.0, 'txt2': 1.0, 'txt4': 1.0}": 1,
      "{'cst': 0.9, 'txt1': 0.5, 'txt2': 0.25, 'txt3': 0.0, 'txt4': 0.5}": 1,
      "{'cst': 1.0, 'txt1': 0.5, 'txt2': 0.25, 'txt3': 0.0, 'txt4': 0.5, 'txt5': 0.5, 'txt6': 0.5}": 1
    },
    "sklearn.pipeline.FeatureUnion.__init__.n_jobs": {
      "None": 198,
      "-1": 112,
      "1": 14
    },
    "sklearn.feature_selection._univariate_selection.SelectPercentile.__init__.percentile": {
      "p": 102,
      "10": 17,
      "23": 9,
      "70": 7,
      "i": 6,
      "100": 6,
      "50": 4,
      "val * 100": 4,
      "int(n_features * 100)": 4,
      "40": 2,
      "14": 1,
      "75": 1,
      "1": 1,
      "percentile": 1,
      "25": 1,
      "28": 1,
      "15": 1,
      "20": 1
    },
    "sklearn.feature_selection._univariate_selection.SelectPercentile.__init__.score_func": {
      "f_classif": 80,
      "chi2": 58,
      "f_regression": 9,
      "feature_selection.f_classif": 7,
      "mutual_info_classif": 6,
      "mutual_info_regression": 4,
      "valid_scoring[scoring]": 4,
      "lambda X, y: np.mean(np.abs(shap_values[:, :dev_X.shape[1]]), axis=0)": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.hidden_layer_sizes": {
      "(100, )": 163,
      "(30, 10)": 34,
      "(5, 2)": 14,
      "(250, )": 13,
      "(32, 64, 128, 64, 32)": 13,
      "(100, 100, 100)": 8,
      "100": 8,
      "(100, 10)": 7,
      "(20, 10, 2)": 7,
      "(5, )": 6,
      "(10, 10, 10)": 5,
      "hidden_layer_sizes": 5,
      "(10, )": 5,
      "(64, 64)": 4,
      "[z]": 4,
      "(32, 32, 32, 32, 32)": 4,
      "(150, 100, 50)": 3,
      "(64, 128)": 3,
      "(50, )": 3,
      "(64, 32, 64, 8)": 3,
      "(192, 512, 128)": 2,
      "(600, 500, 400, 206)": 2,
      "50": 2,
      "(10, 10)": 2,
      "(100, 100, 50)": 2,
      "size": 2,
      "(100, 3)": 2,
      "(4, 4)": 2,
      "(500, 150)": 2,
      "mlp_clf.best_params_['hidden_layer_sizes']": 2,
      "(350, )": 2,
      "(13, 13, 13)": 2,
      "(150, )": 2,
      "(512, 256, 128)": 2,
      "(23, 10, 5)": 1,
      "[40, 40, 40]": 1,
      "(200, 100, 50)": 1,
      "(5, 4)": 1,
      "(10, 8, 3)": 1,
      "10": 1,
      "70": 1,
      "(1000, )": 1,
      "(100, 55)": 1,
      "15": 1,
      "(400, 200, 200, 100)": 1,
      "(100, 100)": 1,
      "(18, 5)": 1,
      "(50, 30, 10)": 1,
      "l": 1,
      "2": 1,
      "hid_lay_siz": 1,
      "best_l": 1,
      "(50, 50, 50)": 1,
      "hidden_layer": 1,
      "int(d / 2)": 1,
      "params['hidden_layer_sizes']": 1,
      "tuple(space_eval(space, best)['hidden_layer_sizes'])": 1,
      "(15, 2)": 1,
      "(40, 100)": 1,
      "(15, 100)": 1,
      "(35, 35)": 1,
      "(neuron_n1, 10)": 1,
      "(neuron_n2, 10)": 1,
      "(70, 70)": 1,
      "layer": 1,
      "(40, )": 1,
      "6": 1,
      "(32, )": 1,
      "(32, 32)": 1,
      "(16, 16)": 1,
      "(20, 20)": 1,
      "(20, 30)": 1,
      "(1024, 512)": 1,
      "(100, 5)": 1,
      "[20, 20]": 1,
      "(8, 16, 8)": 1,
      "(10, 120, 10)": 1,
      "(50, 100, 50)": 1,
      "(15, )": 1,
      "[10, 6]": 1,
      "(20, 100, 150, 200)": 1,
      "(5, 7)": 1,
      "(96, 36, 72, 6)": 1,
      "(100, ytrain.shape[1])": 1,
      "(30, 35)": 1,
      "(96, 96, 48, 48, 24, 12, 6, 3, 1)": 1,
      "350": 1,
      "[16]": 1,
      "(18, 9, 5)": 1,
      "(50, 30, 50)": 1,
      "(50, 30, 30)": 1,
      "(50, 30, 30, 30)": 1,
      "(100, 100, 100, 10)": 1,
      "(15, 6)": 1,
      "layers_sizes": 1,
      "(numcols, numcols, numcols, numcols)": 1,
      "(300, 150, 75, 40)": 1,
      "(200, )": 1,
      "mlp_hl": 1,
      "(130, 60, 10, 4)": 1,
      "(10, 5)": 1,
      "[100, 100]": 1,
      "hiddenLayersShape": 1,
      "(256, 128)": 1,
      "(15, 15)": 1,
      "(7, 2)": 1,
      "(i, )": 1,
      "(i, i)": 1,
      "(num_perceptron, num_perceptron)": 1,
      "(500, 500, 500)": 1,
      "(12, )": 1,
      "(600, 300)": 1,
      "(50, 50, 10)": 1,
      "[50, 25]": 1,
      "(5, 5, 5, 5, 5)": 1,
      "(200, 200, 200, 200)": 1,
      "(9, 9, 9)": 1,
      "(30, 30, 30)": 1,
      "(3500, )": 1,
      "200": 1,
      "(50, 50)": 1,
      "(240, )": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.activation": {
      "'relu'": 377,
      "'logistic'": 22,
      "'tanh'": 18,
      "activation": 4,
      "act": 3,
      "'identity'": 1,
      "params['activation']": 1,
      "str(space_eval(space, best)['activation'])": 1,
      "mlp_act": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.early_stopping": {
      "False": 404,
      "True": 24
    },
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.learning_rate": {
      "'constant'": 377,
      "'adaptive'": 41,
      "'invscaling'": 5,
      "rate": 3,
      "params['learning_rate']": 1,
      "str(space_eval(space, best)['learning_rate'])": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.random_state": {
      "None": 214,
      "1": 99,
      "42": 26,
      "0": 22,
      "3": 15,
      "random_state": 12,
      "65": 7,
      "21": 5,
      "1235": 4,
      "2": 3,
      "720": 3,
      "111": 3,
      "159": 2,
      "17": 1,
      "20": 1,
      "31": 1,
      "randomState": 1,
      "123": 1,
      "2019": 1,
      "222": 1,
      "9996": 1,
      "8123": 1,
      "47": 1,
      "RANDOM_SEED": 1,
      "102": 1,
      "10": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.predict_proba.X": {
      "Xtest": 25,
      "X_test": 17,
      "test3": 10,
      "X_train": 9,
      "train3[test_index, :]": 8,
      "X_cv": 3,
      "test_X": 3,
      "testdata": 3,
      "Scale.transform(test)": 2,
      "test": 2,
      "train3[test_index3, :]": 2,
      "val_features": 2,
      "test[test.columns[1:]].values": 2,
      "X": 2,
      "x_t": 1,
      "x_opt": 1,
      "x_test_sc": 1,
      "x_test_pca": 1,
      "X_te": 1,
      "process_image(img).flatten().reshape(1, -1)": 1,
      "X_test_date": 1,
      "X_val_std": 1,
      "X_valid": 1,
      "test_x_": 1,
      "x_test": 1,
      "test1": 1,
      "test1_b": 1,
      "train5[test_index3, :]": 1,
      "test5": 1,
      "X_test_mlp": 1,
      "data_test[columns[:]]": 1,
      "X_out": 1,
      "test_vect": 1,
      "test_df.drop('Season', axis=1)": 1,
      "X_train[test_index, :]": 1,
      "X_test_ol": 1,
      "xvalid_scale": 1,
      "xtest": 1,
      "test.iloc[:, 1:]": 1,
      "xValidStack": 1,
      "xTestStack": 1,
      "vl_x": 1,
      "_test": 1,
      "test[features]": 1,
      "test_df": 1,
      "feature_test": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.predict.X": {
      "X_test": 37,
      "X": 36,
      "x_test": 8,
      "test": 7,
      "X_train": 6,
      "test_data": 4,
      "X_test_pixels": 4,
      "test_X": 4,
      "test_df": 2,
      "x_train": 2,
      "x_valid": 2,
      "big_data_matrix": 2,
      "val_X": 2,
      "X_testing": 2,
      "X_trainS": 2,
      "X_testS": 2,
      "x_t": 1,
      "x_opt_sc": 1,
      "x_test_pca": 1,
      "data_train": 1,
      "data_valid": 1,
      "X_cv": 1,
      "STDTest": 1,
      "STDTdata": 1,
      "X_test_source": 1,
      "test.drop(['PassengerId'], axis=1)": 1,
      "X_submission": 1,
      "df2": 1,
      "[random_image_resized]": 1,
      "test_images_resized": 1,
      "x_sets[i]": 1,
      "X_text_tfidf_vectorizer_test": 1,
      "[[2.0, 2.0], [-1.0, -2.0]]": 1,
      "train1test1": 1,
      "train3[test_index, :]": 1,
      "test3": 1,
      "train_X": 1,
      "Xtest": 1,
      "y[Features]": 1,
      "X_testf": 1,
      "dev_data": 1,
      "image_embeddings": 1,
      "train_features": 1,
      "train_features[0]": 1,
      "df_test": 1,
      "pre.iloc[:, 1:]": 1,
      "predictor_matrix_test": 1,
      "x_val": 1,
      "mask": 1,
      "testing": 1,
      "X_test_norm": 1,
      "X_testing_scaled": 1,
      "X_training_scaled": 1,
      "X_std_test": 1,
      "model_df": 1,
      "monster_train_B[features]": 1,
      "test_features": 1,
      "normalize2": 1,
      "xTrainScaled": 1,
      "xTestScaled": 1,
      "test_scaled": 1,
      "predictors_ts": 1,
      "big_test_matrix": 1,
      "xtest_tf": 1,
      "xts": 1,
      "test_data.drop('id', axis=1)": 1,
      "test1": 1,
      "pred_test": 1,
      "dftestx": 1,
      "Xp": 1,
      "PCtrain.drop('label', axis=1)[20001:42000]": 1,
      "PCtest": 1,
      "house_test_data": 1
    },
    "sklearn.linear_model._bayes.BayesianRidge.fit.X": {
      "trn_data": 17,
      "X": 15,
      "X_train": 11,
      "x_train": 5,
      "x_poly": 4,
      "X_train[train_idx]": 3,
      "train_X": 2,
      "home_train.drop('relevance', 1)": 2,
      "X_train_br": 2,
      "X_train_kneigboards[X_train_kneigboards.columns.tolist()[:]]": 2,
      "trs[tr_idx, :]": 1,
      "Xtrain": 1,
      "X_train_rf1": 1,
      "X_train_rf2": 1,
      "train_cross_x": 1,
      "train_x": 1,
      "X_train.toarray()": 1,
      "X.toarray()": 1,
      "embedding_train": 1,
      "xTrain": 1,
      "train[feature_columns]": 1,
      "train.drop(columns_to_drop, axis=1).values": 1
    },
    "sklearn.linear_model._bayes.BayesianRidge.fit.y": {
      "trn_y": 17,
      "y_train": 17,
      "y": 8,
      "Y_train": 4,
      "train_df.target[train_idx]": 3,
      "train_y": 3,
      "sample_train_y": 2,
      "home_train['relevance']": 2,
      "y_train_br": 2,
      "Y": 2,
      "train[target].iloc[tr_idx]": 1,
      "Ytrain": 1,
      "y_train_rf1": 1,
      "y_train_rf2": 1,
      "y1": 1,
      "y2": 1,
      "y3": 1,
      "y4": 1,
      "y5": 1,
      "y6": 1,
      "train_cross_y": 1,
      "df_train['target']": 1,
      "yTrain": 1,
      "train['FVC']": 1,
      "labels": 1
    },
    "sklearn.linear_model._bayes.BayesianRidge.predict.X": {
      "val_data": 17,
      "X_test": 15,
      "test_stack": 12,
      "testX": 6,
      "x_train": 4,
      "X": 4,
      "Z[comment_id, :]": 4,
      "x_test": 3,
      "X_train[val_idx]": 3,
      "X_train": 3,
      "polynomial_features.transform(sample_test_x)": 2,
      "test_X": 2,
      "home_test.drop('relevance', 1)": 2,
      "test[home_train.columns[1:27]]": 2,
      "X_test_br": 2,
      "test_first_result[['country_id', 'month', 'dates', 'days_since_first_outbreak']]": 2,
      "test_set[xlabels]": 2,
      "test_data": 2,
      "Z": 2,
      "X_val": 2,
      "X_val_kneigboards[X_val_kneigboards.columns.tolist()[:]]": 2,
      "X_test_kneigboards[X_test_kneigboards.columns.tolist()[:]]": 2,
      "polynomial_features.fit_transform(x_test[:, np.newaxis])": 1,
      "polynomial_features1.fit_transform(x_test[:, np.newaxis])": 1,
      "test.drop(['test_id'], axis=1)": 1,
      "tst_data": 1,
      "test_X2": 1,
      "trs[val_idx, :]": 1,
      "tes": 1,
      "X_train[train_idx]": 1,
      "test": 1,
      "Xtest": 1,
      "test_final": 1,
      "X_test_rf1": 1,
      "X_test_rf2": 1,
      "x_hold": 1,
      "train_cross_test_x[plot_offset:plot_offset + 20]": 1,
      "test_x": 1,
      "test_stack_LGB": 1,
      "test_stack_XGB": 1,
      "test_stack_NN": 1,
      "test_stack_cat": 1,
      "embedding_test": 1,
      "test.drop('ID', axis=1)": 1,
      "train[feature_columns]": 1,
      "submission[feature_columns]": 1,
      "train.drop(columns_to_drop, axis=1).values": 1,
      "test.drop(columns_to_drop, axis=1).values": 1
    },
    "sklearn.feature_extraction.text.CountVectorizer.__init__.min_df": {
      "1": 2300,
      "2": 148,
      "3": 87,
      "5": 79,
      "10": 60,
      "NAME_MIN_DF": 59,
      "30": 55,
      "min_df": 19,
      "0": 13,
      "50": 12,
      "1000": 11,
      "4": 10,
      "20": 8,
      "0.0001": 7,
      "0.1": 7,
      "25": 5,
      "0.6": 4,
      "200": 4,
      "1e-05": 4,
      "max_df": 4,
      "df": 3,
      "100": 2,
      "0.05": 2,
      "1e-06": 2,
      "0.0": 2,
      "0.01": 2,
      "0.001": 2,
      "7": 2,
      "mindf": 2,
      "LGBM_NAME_MIN_DF": 2,
      "0.3": 1,
      "MIN_DF": 1,
      "0.8": 1,
      "min_d": 1,
      "157": 1,
      "0.02": 1,
      "name_min_df": 1,
      "display_address_min_df": 1,
      "street_address_min_df": 1,
      "MIN_NAME_DF": 1,
      "MIN_DF_COUNT": 1,
      "0.00125": 1,
      "8": 1,
      "0.5": 1,
      "6": 1,
      "300": 1,
      "75": 1,
      "minDF": 1,
      "min_count": 1,
      "40": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.max_iter": {
      "1000": 778,
      "5": 20,
      "100": 10,
      "10000": 8,
      "200": 4,
      "2000": 3,
      "2": 2,
      "5000": 2,
      "13": 2,
      "50": 2,
      "10": 2,
      "180": 2,
      "None": 1,
      "6": 1,
      "25000": 1,
      "800": 1,
      "max_iter": 1,
      "20": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.tol": {
      "0.001": 811,
      "None": 16,
      "0.0001": 8,
      "1e-05": 2,
      "0.01": 2,
      "np.exp(-5)": 1,
      "-np.infty": 1
    },
    "sklearn.metrics._classification.f1_score.labels": {
      "None": 3765,
      "range(len(CLASSES))": 218,
      "labels": 61,
      "range(104)": 14,
      "list(range(11))": 8,
      "np.unique(y_true)": 6,
      "np.unique(predIdxs_VGG)": 4,
      "ulabels": 2,
      "range(num_of_classes)": 2,
      "np.unique(tgts)": 2,
      "range(len(classes))": 2,
      "range(classes_num)": 1,
      "np.unique(y_pred)": 1,
      "np.unique(model13.predict(selected_data_test))": 1
    },
    "sklearn.metrics._classification.precision_score.labels": {
      "None": 904,
      "range(len(CLASSES))": 179,
      "labels": 60,
      "range(num_of_classes)": 2,
      "np.unique(tgts)": 2,
      "range(len(classes))": 2,
      "range(classes_num)": 1,
      "['A', 'B', 'NEITHER']": 1,
      "range(104)": 1,
      "[1, 0]": 1
    },
    "sklearn.metrics._classification.recall_score.labels": {
      "None": 876,
      "range(len(CLASSES))": 179,
      "labels": 60,
      "range(num_of_classes)": 2,
      "np.unique(tgts)": 2,
      "range(len(classes))": 2,
      "range(classes_num)": 1,
      "range(104)": 1,
      "[1, 0]": 1
    },
    "sklearn.preprocessing._label.LabelBinarizer.__init__.sparse_output": {
      "True": 253,
      "False": 237
    },
    "sklearn.linear_model._ridge.Ridge.__init__.solver": {
      "'auto'": 1095,
      "'sag'": 72,
      "'lsqr'": 34,
      "'cholesky'": 8,
      "'saga'": 7,
      "'sparse_cg'": 3,
      "'svd'": 3,
      "solver": 2,
      "ridge_regressor.best_params_['solver']": 1
    },
    "sklearn.neighbors._regression.KNeighborsRegressor.__init__.n_neighbors": {
      "5": 184,
      "10": 21,
      "n_neighbors": 16,
      "3": 15,
      "k": 14,
      "4": 10,
      "9": 10,
      "1": 8,
      "2": 8,
      "100": 8,
      "11": 8,
      "i": 5,
      "n": 4,
      "80": 4,
      "6": 3,
      "50": 3,
      "15": 3,
      "7": 3,
      "n_neighbor": 2,
      "25": 2,
      "20": 2,
      "19": 2,
      "500": 2,
      "252": 2,
      "150": 1,
      "knn_regressor.best_params_['n_neighbors']": 1,
      "12": 1,
      "75": 1,
      "300": 1,
      "128": 1,
      "95": 1,
      "14": 1,
      "8": 1,
      "13": 1,
      "17": 1,
      "tuning_parameter": 1,
      "30": 1,
      "99": 1,
      "29": 1,
      "k_range[i]": 1,
      "55": 1
    },
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.max_features": {
      "'auto'": 243,
      "0.3": 30,
      "g['mf']": 17,
      "0.5": 11,
      "150": 5,
      "0.8": 2,
      "0.7": 1,
      "10": 1,
      "164": 1,
      "XX.shape[1]": 1,
      "47": 1,
      "0.49": 1
    },
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.verbose": {
      "0": 303,
      "1": 8,
      "2": 1,
      "verbose": 1,
      "False": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.hidden_layer_sizes": {
      "(100, )": 56,
      "(10, )": 7,
      "(100, 50)": 5,
      "(100, 100)": 4,
      "(50, 50)": 3,
      "100": 2,
      "(800, 400, 200)": 2,
      "[6]": 2,
      "hidden_layer_sizes": 2,
      "(600, )": 2,
      "(3, 5, 3)": 2,
      "(10, 20, 5)": 2,
      "(4, )": 2,
      "(50, )": 1,
      "(10, 4)": 1,
      "(10, 10)": 1,
      "(400, 1)": 1,
      "(20, 15, 10, 5)": 1,
      "(1500, 1500, 1500)": 1,
      "(12, 4)": 1,
      "(512, 256, 128, 64)": 1,
      "(45, 30, 20, 15, 7)": 1,
      "(400, 2)": 1,
      "(100, 100, 100)": 1,
      "h_l_sizes": 1,
      "(5, 5, 5, 5)": 1,
      "(200, 100, 100)": 1,
      "(100, 100, 25)": 1,
      "(3, )": 1,
      "[60, 60]": 1,
      "(100, 300, 100)": 1,
      "[100]": 1,
      "(60, 60, 28)": 1,
      "(4, 4)": 1,
      "(200, )": 1,
      "(80, 80, 20)": 1,
      "(50, 20, 15)": 1,
      "(30, 30, 30)": 1,
      "200": 1,
      "(8, )": 1,
      "(300, )": 1,
      "trial.suggest_int('hidden_layer_sizes', 8, 126)": 1,
      "(20, 20, 20, 20, 20)": 1,
      "(20, 20, 20, 20)": 1,
      "(170, 80, 80, 80, 80, 50, 1)": 1,
      "(600, 300)": 1,
      "(2, )": 1,
      "(3, 3)": 1,
      "(256, 128)": 1,
      "(80, 50, 20)": 1,
      "layers": 1,
      "(10, 15)": 1,
      "(100, 50, 25, 12, 6, 3)": 1,
      "(35, 20, 15)": 1,
      "(16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16)": 1,
      "(37, 37)": 1,
      "(350, 200, 120)": 1,
      "(10, 2)": 1,
      "i": 1,
      "(100, 100, 100, 100, 100, 100)": 1,
      "(5, 4, 3)": 1,
      "(100, 100, 100, 100, 100)": 1,
      "(80, 80, 60, 60, 40)": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.activation": {
      "'relu'": 123,
      "'logistic'": 10,
      "'tanh'": 5,
      "activation": 2,
      "'identity'": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.verbose": {
      "False": 117,
      "True": 13,
      "'True'": 4,
      "3": 3,
      "1": 2,
      "2": 2
    },
    "sklearn.linear_model._coordinate_descent.ElasticNet.__init__.fit_intercept": {
      "True": 463,
      "False": 3,
      "fit_intercept_dict[fit_intercept]": 1
    },
    "sklearn.metrics._regression.mean_absolute_error.sample_weight": {
      "None": 2895,
      "weights": 10,
      "validation_weights": 5,
      "optimization_weights": 5,
      "w_val": 5
    },
    "sklearn.utils.validation.check_is_fitted.estimator": {
      "self": 50
    },
    "sklearn.utils.validation.check_is_fitted.attributes": {
      "['_r', '_clf']": 30,
      "'estimator_'": 5,
      "'interp_func_'": 4,
      "['_clf']": 3,
      "'_idf_diag'": 2,
      "'columns_'": 1,
      "'_optim_results'": 1,
      "'support_'": 1,
      "'bin_edges_'": 1,
      "['_categories', '_brand_words']": 1,
      "'classes_'": 1
    },
    "sklearn.utils.validation.check_X_y.accept_sparse": {
      "True": 16,
      "False": 3,
      "'csc'": 1,
      "'csr'": 1
    },
    "sklearn.utils.validation.check_X_y.X": {
      "x": 16,
      "X": 5
    },
    "sklearn.utils.validation.check_X_y.y": {
      "y": 21
    },
    "sklearn.preprocessing._data.PolynomialFeatures.fit.X": {
      "poly_features": 72,
      "X_poly": 12,
      "poly_features_train": 4,
      "poly_train": 3,
      "X[self.interacting_features]": 2,
      "train3p": 2,
      "poly": 1,
      "poly_test": 1,
      "X_train": 1,
      "train_poly_fea": 1,
      "df_train": 1,
      "table_train[corr_featu]": 1,
      "poly_ft_train": 1,
      "train_test.loc[:, features_40]": 1,
      "full_train_w_features.drop(['stock_id', 'time_id'], axis=1)": 1
    },
    "sklearn.preprocessing._data.PolynomialFeatures.transform.X": {
      "poly_features_test": 75,
      "poly_features": 72,
      "X_test": 9,
      "poly_test": 4,
      "poly_features_train": 4,
      "poly_train": 3,
      "sample_test_x": 2,
      "X[self.interacting_features]": 2,
      "train3p": 2,
      "train3": 2,
      "test3": 2,
      "x_test_c": 2,
      "x_test_f": 2,
      "xx.reshape(xx.shape[0], 1)": 2,
      "X_stack_test": 1,
      "x_test.reshape(-1, 1)": 1,
      "poly": 1,
      "x_test": 1,
      "test_df[features_names_upd]": 1,
      "train[real_cols]": 1,
      "np.array(testSet[regressors])": 1,
      "X_train": 1,
      "test.iloc[:, 1:]": 1,
      "val_X": 1,
      "logreg_test.iloc[:, 1:]": 1,
      "train_poly_fea": 1,
      "test_poly_fea": 1,
      "df_train": 1,
      "df_test": 1,
      "poly_ft_train": 1,
      "poly_ft_test": 1,
      "train_test.loc[:, features_40]": 1,
      "full_train_w_features.drop(['stock_id', 'time_id'], axis=1)": 1,
      "X_val": 1
    },
    "sklearn.preprocessing._data.PolynomialFeatures.get_feature_names.input_features": {
      "['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']": 222,
      "v": 19,
      "list(inter_features)": 3,
      "list(PF_list['name'])": 3,
      "['walkDistance', 'killPlace', 'boosts', 'weaponsAcquired']": 3,
      "['escolari', 'cielorazo', 'meaneduc', 'hogar_nin', 'r4t1', 'SQBhogar_nin']": 3,
      "real_cols": 2,
      "['EXT_SOURCE_3', 'EXT_SOURCE_2', 'EXT_SOURCE_1', 'DAYS_BIRTH', 'DAYS_EMPLOYED']": 2,
      "float_cols": 1,
      "var": 1,
      "X_final.columns": 1,
      "poly.columns": 1,
      "poly_test.columns": 1,
      "Interval": 1,
      "cols_corr_15[:-1]": 1,
      "['ps_car_13', 'ps_car_12', 'ps_ind_17_bin', 'ps_car_07_cat', 'ps_reg_02']": 1,
      "dataframe.columns": 1,
      "None": 1
    },
    "sklearn.ensemble._voting.VotingClassifier.predict.X": {
      "X_test": 64,
      "test_x_onehotCoding": 29,
      "test[X_train.columns]": 18,
      "x_test": 17,
      "test": 11,
      "X_test.drop(et_drop_cols, axis=1)": 10,
      "X_test_scaled": 8,
      "test_feature": 8,
      "X_train": 7,
      "ttextdataemx_test": 6,
      "testfeature": 6,
      "tsiftdatax_test": 6,
      "x_val": 5,
      "test_x": 5,
      "x_train": 4,
      "test_X": 4,
      "test_data": 4,
      "xtest": 4,
      "X_test.drop(xgb_drop_cols, axis=1)": 4,
      "Result_transformed": 3,
      "X": 3,
      "X_val": 3,
      "x_valid": 2,
      "test_df": 2,
      "df_test": 2,
      "X_valid": 2,
      "y_test": 2,
      "X_stp": 2,
      "test3": 2,
      "X_test.drop(lgb_drop_cols, axis=1)": 2,
      "test.drop(xgb_drop_cols, axis=1)": 2,
      "test.drop(et_drop_cols, axis=1)": 2,
      "xTest": 1,
      "X_test.toarray()": 1,
      "test_data.drop('id', axis=1)": 1,
      "test_vectorized": 1,
      "data1": 1,
      "x": 1,
      "selected_x_test": 1,
      "df_test.values": 1,
      "dtest.drop(['id', 'color'], axis=1)": 1,
      "ds[feats]": 1,
      "predictors_ts": 1,
      "X_test_final": 1,
      "X_test_std": 1,
      "X_val_std": 1,
      "X_pred_preprocessed": 1,
      "X_valid_tfidf1": 1,
      "X_test_prepared": 1,
      "X_test[:]": 1,
      "xvalid": 1,
      "X_test_boruta": 1,
      "X_testdata_boruta": 1,
      "bow_test_data": 1,
      "self.x_test": 1,
      "to_predict": 1,
      "test1": 1,
      "scaled": 1,
      "X_test_scaled_pca": 1,
      "selected_data_test": 1,
      "data.drop(xgb_drop_cols, axis=1)": 1,
      "data.drop(et_drop_cols, axis=1)": 1,
      "data.drop(lgb_drop_cols, axis=1)": 1,
      "test.drop(lgb_drop_cols, axis=1)": 1,
      "X_cv.drop(lgb_drop_cols, axis=1)": 1,
      "train_feature_vectors": 1,
      "test_feature_vectors": 1,
      "X_tr": 1,
      "X_new": 1,
      "data_x": 1,
      "Xtest": 1,
      "X_test_array": 1,
      "test_data_tr.values": 1,
      "new_test": 1
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.ccp_alpha": {
      "0.0": 863,
      "ccp_alpha": 1,
      "best_params[12]": 1
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.criterion": {
      "'friedman_mse'": 862,
      "'mse'": 1,
      "criterion": 1,
      "best_params[4]": 1
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.init": {
      "None": 865
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.max_features": {
      "None": 727,
      "'sqrt'": 25,
      "0.2": 15,
      "2": 13,
      "1": 13,
      "'auto'": 6,
      "15": 6,
      "'log2'": 5,
      "val": 5,
      "0.5": 4,
      "11": 4,
      "0.8": 4,
      "0.6": 4,
      "5": 4,
      "4": 3,
      "0.7": 3,
      "7": 2,
      "34": 2,
      "3": 2,
      "0.4861929134696539": 2,
      "0.7000000000000001": 2,
      "max_features": 2,
      "9": 2,
      "max_feature": 1,
      "28": 1,
      "80": 1,
      "64": 1,
      "0.1": 1,
      "params['max_features']": 1,
      "6": 1,
      "best_params[10]": 1,
      "100": 1,
      "29": 1
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.max_leaf_nodes": {
      "None": 860,
      "max_leaf_nodes": 2,
      "4": 1,
      "best_max_leaf_nodes": 1,
      "best_params[11]": 1
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.min_impurity_decrease": {
      "0.0": 862,
      "0": 1,
      "min_impurity_decrease": 1,
      "best_params[9]": 1
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.min_impurity_split": {
      "None": 865
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.min_samples_leaf": {
      "1": 759,
      "100": 23,
      "2": 16,
      "4": 16,
      "10": 6,
      "80": 5,
      "50": 4,
      "90": 3,
      "30": 3,
      "5": 3,
      "20": 3,
      "int(round(113.13022692803058))": 2,
      "15": 2,
      "200": 2,
      "24": 2,
      "3": 2,
      "0.001": 2,
      "35": 2,
      "min_samples": 1,
      "1000": 1,
      "40": 1,
      "47": 1,
      "min_node_size": 1,
      "int(round(min_samples_leaf))": 1,
      "6": 1,
      "0.15714285714285714": 1,
      "min_samples_leaf": 1,
      "best_params[6]": 1
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.min_weight_fraction_leaf": {
      "0.0": 856,
      "0.0484": 3,
      "1e-10": 2,
      "0.4": 1,
      "min_weight_fraction_leaf": 1,
      "best_params[7]": 1,
      "0.02067": 1
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.n_iter_no_change": {
      "None": 862,
      "20": 2,
      "300": 1
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.subsample": {
      "1.0": 755,
      "0.65": 22,
      "0.5": 21,
      "0.8": 18,
      "0.7": 12,
      "0.9": 10,
      "0.2": 10,
      "0.75": 2,
      "0.6": 2,
      "0.3": 2,
      "0.1": 1,
      "0.9000000000000001": 1,
      "0.8573598985000007": 1,
      "1": 1,
      "0.15000000000000002": 1,
      "params['subsample']": 1,
      "0.35": 1,
      "0.96": 1,
      "subsample": 1,
      "best_params[3]": 1,
      "trial.suggest_float('subsample', 0.1, 1.0)": 1
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.tol": {
      "0.0001": 865
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.validation_fraction": {
      "0.1": 865
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.verbose": {
      "0": 839,
      "1": 17,
      "True": 6,
      "2": 2,
      "50": 1
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.__init__.warm_start": {
      "False": 852,
      "True": 13
    },
    "sklearn.ensemble._voting.VotingClassifier.__init__.verbose": {
      "False": 300,
      "1": 3,
      "True": 1
    },
    "sklearn.preprocessing._function_transformer.FunctionTransformer.__init__.func": {
      "down_scale": 49,
      "lambda x: [' '.join(doc['ingredients']).lower() for doc in x]": 28,
      "replace_integers_by_strings": 22,
      "has_significant_name": 22,
      "has_pure_breed": 22,
      "breed_matches_fur_length": 21,
      "include_description_length": 20,
      "include_aspect_ratio": 18,
      "itemgetter(f)": 12,
      "square": 12,
      "np.log1p": 10,
      "winsorize": 10,
      "to_records": 9,
      "_print_shape": 8,
      "lambda x: x.astype('float16')": 6,
      "None": 6,
      "lambda a: a[['len_character']]": 4,
      "transform_url": 4,
      "lambda x: x.astype('float')": 4,
      "lambda a: a['comment_text']": 3,
      "lambda x: x['ciphertext']": 3,
      "np.log": 3,
      "add_features": 3,
      "lambda data: data[:, binary_data_indices]": 3,
      "lambda data: data[:, numeric_data_indices]": 3,
      "lambda data: data[:, categorical_data_indices]": 3,
      "get_DayOfWeek": 2,
      "get_Open": 2,
      "get_Promo": 2,
      "get_StateHoliday": 2,
      "get_SchoolHoliday": 2,
      "get_StoreType": 2,
      "get_Assortment": 2,
      "get_Promo2Active": 2,
      "get_CompetitionActive": 2,
      "get_CompetitionDistance": 2,
      "get_DayOfYear": 2,
      "counts": 2,
      "lambda data: data.iloc[:, get_ind(binary_col)]": 2,
      "lambda data: data.iloc[:, get_ind(numeric_col)]": 2,
      "lambda data: data.iloc[:, get_ind(categor_col)]": 2,
      "lambda x: x.astype('float32')": 2,
      "lambda x: x[col_names]": 2,
      "transformers.replace_integers_by_strings": 2,
      "transformers.has_significant_name": 2,
      "transformers.has_pure_breed": 2,
      "transformers.breed_matches_fur_length": 2,
      "transformers.include_description_length": 2,
      "transformers.include_aspect_ratio": 2,
      "get_descr_cols": 2,
      "count_words": 2,
      "lambda x: [doc['ingredients'] for doc in x]": 2,
      "lambda x: apply_fasttext(x)": 2,
      "lambda x: x": 2,
      "lambda x: x**2": 2,
      "lambda x: x**3": 2,
      "lambda x: np.clip(x, -np.Inf, -0.68)": 2,
      "lambda x: np.clip(x, -0.68, 0)": 2,
      "lambda x: np.clip(x, 0, 0.68)": 2,
      "lambda x: np.clip(x, 0.68, np.Inf)": 2,
      "lambda X: X[:, [1]]": 2,
      "lambda a: a['text']": 1,
      "get_previous_sales": 1,
      "get_name_col": 1,
      "get_condition_col": 1,
      "get_category_col": 1,
      "get_brand_col": 1,
      "get_shipping_col": 1,
      "get_desc_col": 1,
      "apply_custom_transformations": 1,
      "fill_missing_values": 1,
      "categorize_low_freqs": 1,
      "lambda df: df.text": 1,
      "lambda df: df.lemma": 1,
      "sel_obj": 1,
      "sel_ints": 1,
      "drop_cols_func": 1,
      "lambda x: DayWeekMonthYear(pd.to_datetime(x.iloc[:, 0]))": 1,
      "lambda X: X.reshape(-1, 1)": 1,
      "lambda df: cocrime(df)": 1,
      "itemgetter(field)": 1,
      "lambda X: X['assetCode']": 1,
      "lambda X: X[market_numeric_features]": 1,
      "lambda X: X.fillna(0)": 1,
      "bin_onehot": 1,
      "preprocess_data": 1,
      "pre_process": 1,
      "get_nums": 1,
      "get_cat_name": 1,
      "get_brand_name": 1,
      "lambda x: x['text']": 1,
      "lambda x: x.drop(columns=text_colnames)": 1,
      "lambda x: x[numeric_colnames]": 1,
      "get_cat_cols": 1,
      "get_brand_cols": 1,
      "get_last_cat_cols": 1,
      "get_name_cols": 1,
      "lambda X: X.replace({'F': 0, 'T': 1, 'N': 0, 'Y': 1})": 1,
      "combine_low_count_classes": 1,
      "lambda X: X.mean(axis=1, keepdims=True)": 1,
      "pd.cut": 1,
      "column_remover": 1,
      "feature_generator": 1,
      "get_num_cols": 1,
      "get_main_category": 1,
      "get_second_category": 1,
      "get_third_category": 1,
      "get_brand_category": 1,
      "tranformCategories": 1,
      "_custom_eng": 1,
      "ext_source_feature": 1,
      "ext_source_312": 1,
      "ext_source_mul31_2": 1,
      "lambda x: apply_word2vec(x)": 1,
      "lambda x: [preprocess(ingredients) for ingredients in x]": 1,
      "remove_extra": 1,
      "get_numeric_columns": 1,
      "get_index_columns": 1,
      "get_bools_columns": 1,
      "lambda a: a['negated_phrase']": 1,
      "lambda data: data.iloc[:, binary_data_indices]": 1,
      "lambda data: data.iloc[:, numeric_data_indices]": 1,
      "lambda data: data.iloc[:, numeric_data_indices_log]": 1,
      "lambda data: data.iloc[:, categorical_data_indices]": 1,
      "lambda x: 4 * (x - 0.5)**2": 1,
      "lambda x: x.todense()": 1,
      "clean_tweets": 1,
      "lambda x: x > x.min()": 1,
      "lambda x: x > 0": 1,
      "lambda x: 1 / (x + 0.01)": 1,
      "lambda x: x**4": 1,
      "lambda x, cap: np.clip(x, -cap, cap)": 1,
      "lambda X: X[:, [0]]": 1,
      "lambda X: X[:, [2, 3]]": 1,
      "lambda X: X[:, [4, 5]].astype(int)": 1,
      "lambda X: X[:, [6, 7]].astype(int)": 1,
      "lambda X: X[:, [8, 9]].astype(int)": 1,
      "copy": 1,
      "string_impute": 1
    },
    "sklearn.preprocessing._function_transformer.FunctionTransformer.transform.X": {
      "ap_train": 2,
      "ap_test": 2,
      "df.Age": 1,
      "X": 1
    },
    "sklearn.tree._classes.DecisionTreeRegressor.__init__.max_leaf_nodes": {
      "None": 849,
      "max_leaf_nodes": 12,
      "4": 12,
      "30": 4,
      "best_tree_size": 2,
      "20": 2,
      "150": 2,
      "max_leaf": 1,
      "25": 1,
      "3000": 1,
      "55100": 1,
      "64": 1,
      "16": 1,
      "5": 1,
      "10": 1,
      "600": 1,
      "7": 1,
      "100": 1,
      "500": 1,
      "15": 1
    },
    "sklearn.pipeline.Pipeline.score.X": {
      "X_test": 104,
      "X_train": 32,
      "x_test": 21,
      "X": 9,
      "X_val": 8,
      "X_valid": 8,
      "feature_2": 4,
      "x_train": 3,
      "X_train_clean": 3,
      "X_test_clean": 3,
      "test_data": 3,
      "XT": 3,
      "X[train]": 3,
      "X[test]": 3,
      "TrainingFeatures": 2,
      "X_validation": 2,
      "c": 1,
      "testX": 1,
      "dataset['text'][test_split:]": 1,
      "x_val": 1,
      "xtrain": 1,
      "X_transformed_test": 1,
      "house_cpy": 1,
      "train.description": 1,
      "X_train_final": 1,
      "X_valid_final": 1,
      "X_train_pca": 1,
      "X_valid_pca": 1,
      "val_sentences": 1,
      "df_test.text": 1,
      "x": 1,
      "x_valid": 1,
      "train": 1,
      "X_validate": 1,
      "xTest": 1,
      "xTrain": 1,
      "X_eval": 1,
      "self.data['Customers'].values.reshape(-1, 1)": 1,
      "_inp(df_validation)": 1,
      "train_text": 1,
      "df.iloc[test_idx, 0].values": 1
    },
    "sklearn.pipeline.Pipeline.score.y": {
      "y_test": 127,
      "y_train": 35,
      "y": 11,
      "y_valid": 9,
      "y_val": 6,
      "Y_val": 3,
      "yt": 3,
      "y[train]": 3,
      "y[test]": 3,
      "Y_train": 2,
      "test_labels": 2,
      "Y": 2,
      "Y_validation": 2,
      "y_equidistant": 2,
      "y_balanced": 2,
      "d": 1,
      "testY": 1,
      "targets": 1,
      "dataset['author'][test_split:]": 1,
      "ytrain": 1,
      "Y_test": 1,
      "boxcox(test_labels, best_lambda)": 1,
      "train.interest_level": 1,
      "y_train_final": 1,
      "y_valid_final": 1,
      "y_train_pca": 1,
      "y_valid_pca": 1,
      "val_labels": 1,
      "test_y_POS": 1,
      "y_pred": 1,
      "train['median_relevance']": 1,
      "y_validate": 1,
      "yTest": 1,
      "yTrain": 1,
      "y_eval": 1,
      "self.data['Sales'].values.reshape(-1, 1)": 1,
      "_out(df_validation)": 1,
      "train_data['target']": 1,
      "df.iloc[test_idx, 1].values": 1
    },
    "sklearn.compose._column_transformer.make_column_transformer.remainder": {
      "'drop'": 38,
      "'passthrough'": 22
    },
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix.estimator": {
      "svc": 14,
      "xgbc": 13,
      "model": 12,
      "rf": 12,
      "ada": 12,
      "knn": 11,
      "mlpc": 11,
      "clf": 10,
      "clf_xgb": 6,
      "classifier": 5,
      "dummy_clf": 4,
      "DecisionTree_confusion": 4,
      "forest_confusion": 4,
      "knn_confusion": 4,
      "xgb": 3,
      "pipe": 3,
      "rfc": 3,
      "dtree_model": 2,
      "log_reg": 2,
      "log_model": 2,
      "lr_tfidf": 2,
      "gs": 2,
      "gbm": 2,
      "svc_model": 1,
      "random_forest_model": 1,
      "clf_final": 1,
      "grid_log_reg": 1,
      "dt_clf": 1,
      "grid_rf": 1,
      "grid_svc": 1,
      "mlp": 1,
      "grid_mlp": 1,
      "log_mc": 1,
      "nb": 1,
      "rfg": 1,
      "cbc": 1,
      "lgbm": 1,
      "decision_tree": 1,
      "best_model": 1,
      "abc": 1,
      "model_1": 1,
      "model_2": 1,
      "images_model": 1,
      "model1": 1,
      "model3": 1,
      "model_a": 1,
      "model_b": 1,
      "nb_model": 1,
      "tree_clf": 1,
      "grid_search": 1,
      "model_svc": 1,
      "model_lr": 1,
      "Log_model": 1,
      "grid": 1,
      "grid2": 1,
      "svm_model": 1,
      "cm_aug": 1,
      "m": 1,
      "init_mod": 1,
      "tuned_mod": 1
    },
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix.X": {
      "test_features": 66,
      "X_test": 35,
      "X_valid": 14,
      "x_test": 13,
      "X_te_equid": 6,
      "X_te_balan": 6,
      "X_train": 4,
      "scaled_X_test": 4,
      "tv_X_test": 4,
      "test_x": 3,
      "X_val[columns]": 2,
      "X_test.fillna(0)": 2,
      "X_test_ex.fillna(0)": 2,
      "X_fea_2_te_equid": 2,
      "X_fea_2_te_balan": 2,
      "test_X": 2,
      "Xtest": 1,
      "x_train_work": 1,
      "X_eval": 1,
      "test": 1,
      "X_val_bow_df": 1,
      "X": 1,
      "X_val": 1,
      "vt_count_test": 1,
      "tfidf_vt_test": 1,
      "nb_X_val": 1,
      "X[:5500]": 1,
      "xs": 1,
      "null": 1
    },
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix.y_true": {
      "y_test": 127,
      "y_valid": 14,
      "y_te_equid": 6,
      "y_te_balan": 6,
      "y_train": 4,
      "test_y": 4,
      "y_val": 4,
      "y": 2,
      "y_test_ex": 2,
      "y_fea_2_te_equid": 2,
      "y_fea_2_te_balan": 2,
      "ytest": 1,
      "y_eval": 1,
      "test_labels": 1,
      "predictions": 1,
      "nb_y_val": 1,
      "y[:5500]": 1,
      "null": 1
    },
    "sklearn.feature_extraction.text.CountVectorizer.__init__.max_df": {
      "1.0": 2744,
      "0.95": 53,
      "0.9": 34,
      "0.999": 23,
      "0.5": 22,
      "0.8": 10,
      "max_df": 7,
      "0.99": 6,
      "0.85": 5,
      "0.7": 4,
      "0.97": 3,
      "0.6": 3,
      "0.15": 3,
      "1": 3,
      "0.2": 2,
      "maxdf": 2,
      "5000": 1,
      "159": 1,
      "0.4": 1,
      "0.82": 1,
      "500": 1,
      "MAX_DF": 1,
      "0.05": 1,
      "max_d": 1,
      "0.11": 1,
      "3": 1,
      "MAX_DF_COUNT": 1,
      "0.75": 1,
      "maxDF": 1
    },
    "sklearn.model_selection._split.StratifiedShuffleSplit.__init__.n_splits": {
      "1": 115,
      "10": 28,
      "2": 19,
      "5": 19,
      "20": 10,
      "3": 8,
      "num_folds": 8,
      "n_splits": 6,
      "n_folds": 4,
      "sss_n_splits": 3,
      "30": 3,
      "6": 2,
      "nr_runs": 2,
      "kfold": 2,
      "7": 2,
      "my_n_splits": 1,
      "nfolds": 1,
      "nr_split": 1,
      "100": 1,
      "num_models": 1,
      "FOLDS": 1,
      "12": 1,
      "35": 1,
      "25": 1
    },
    "sklearn.model_selection._split.StratifiedShuffleSplit.__init__.train_size": {
      "None": 200,
      "split": 14,
      "0.8": 4,
      "0.75": 3,
      "0.7": 2,
      "0.9": 2,
      "2 / 3": 2,
      "0.5": 2,
      "1 - 1 / n_folds": 2,
      "0.2": 2,
      "tr_ratio": 1,
      "0.1": 1,
      "train_ratio": 1,
      "downsample_ratio": 1,
      "0.95": 1,
      "100000": 1,
      "train_size": 1
    },
    "sklearn.model_selection._split.StratifiedShuffleSplit.__init__.random_state": {
      "42": 45,
      "None": 33,
      "0": 25,
      "random_state": 20,
      "seed_val": 14,
      "115": 10,
      "seed": 9,
      "12345": 8,
      "1": 7,
      "23": 5,
      "42069": 5,
      "51": 5,
      "random_seed": 3,
      "7": 3,
      "123": 3,
      "i": 3,
      "SEED": 3,
      "6": 3,
      "12": 2,
      "split_seed": 2,
      "15": 2,
      "2020": 2,
      "1989": 2,
      "101": 2,
      "2": 1,
      "777": 1,
      "60": 1,
      "30": 1,
      "97": 1,
      "44": 1,
      "21": 1,
      "100": 1,
      "CFG.seed": 1,
      "seed_value": 1,
      "9487": 1,
      "1234": 1,
      "3": 1,
      "10": 1,
      "19": 1,
      "RS": 1,
      "20": 1,
      "123457869": 1,
      "999": 1,
      "87951": 1,
      "31415": 1,
      "random_state + i": 1,
      "2021": 1,
      "13": 1
    },
    "sklearn.model_selection._split.StratifiedShuffleSplit.split.X": {
      "X": 49,
      "X_num_tr": 14,
      "trainX": 11,
      "trn_x": 10,
      "train_X": 8,
      "x_train": 7,
      "train": 7,
      "train_x": 7,
      "df": 6,
      "X_train": 6,
      "train_names": 5,
      "X_full[my_features]": 4,
      "train_df": 3,
      "x": 3,
      "train_features": 3,
      "df_train['image_id']": 3,
      "train_c": 3,
      "scaled_train": 2,
      "df_split_index": 2,
      "combined_data": 2,
      "index": 2,
      "train['id_code']": 2,
      "labels": 2,
      "allfeats": 2,
      "data['text']": 2,
      "train_data": 2,
      "df[[labels[l]] + ['cp_time']].values": 1,
      "Xall": 1,
      "xAll": 1,
      "train_df_merged": 1,
      "train_df[features]": 1,
      "Xtrain": 1,
      "df_train": 1,
      "tmp": 1,
      "x_images": 1,
      "train_raw": 1,
      "A": 1,
      "df.iloc[:, 1:]": 1,
      "image_file_path": 1,
      "train.iloc[:, 1:]": 1,
      "_y": 1,
      "x_data": 1,
      "data_df": 1,
      "csv_pd['id']": 1,
      "application_train": 1,
      "train_X.values": 1,
      "preprocessed_train_data": 1,
      "X_resampled": 1,
      "data": 1,
      "seq_array": 1,
      "train_csv": 1,
      "pubg_copy": 1,
      "train_unscaled": 1,
      "odf.label.values": 1,
      "X_augmented": 1,
      "all_labels_df.id": 1,
      "dtrain[['question1', 'question2']].values": 1,
      "df_dd['image_id']": 1,
      "trainn": 1,
      "train_dataset[key].input": 1,
      "ytrain": 1,
      "img_ids": 1,
      "pre_train": 1,
      "X_train_full": 1,
      "X_train_prepared": 1,
      "lstm_X_train_np": 1,
      "tr": 1,
      "train_scale": 1,
      "dataset": 1,
      "test": 1,
      "y": 1,
      "h_y": 1,
      "features": 1,
      "df_fold": 1,
      "np.zeros(len(y_trn))": 1
    },
    "sklearn.model_selection._split.StratifiedShuffleSplit.split.y": {
      "y": 66,
      "train_y": 16,
      "y_train": 14,
      "trainy": 10,
      "trn_y": 10,
      "labels": 9,
      "np.zeros(train_names.shape)": 5,
      "y_full": 4,
      "train_targets": 3,
      "df_train['label']": 3,
      "train_c['target']": 3,
      "df_split_index": 2,
      "Y": 2,
      "label": 2,
      "y_train[:, i]": 2,
      "train['diagnosis']": 2,
      "labels['breed']": 2,
      "df['label']": 2,
      "metadata['target']": 2,
      "train_df.target": 2,
      "data['author']": 2,
      "groups": 2,
      "df.Score": 1,
      "df[[labels[l]] + ['cp_time']].values": 1,
      "yall": 1,
      "yAll": 1,
      "train_df_merged['Age_cat']": 1,
      "df.isup_grade": 1,
      "train_df['event']": 1,
      "train_df['target']": 1,
      "Ytrain": 1,
      "kgroups": 1,
      "df_train.label": 1,
      "y_encoded": 1,
      "tmp['label']": 1,
      "label_raw": 1,
      "train['label']": 1,
      "b": 1,
      "df.target": 1,
      "df.iloc[:, 0]": 1,
      "train['target']": 1,
      "_y['isDefensivePI']": 1,
      "train['SalePrice_bins']": 1,
      "target": 1,
      "y_labels": 1,
      "df.Label": 1,
      "data_df.bins.values": 1,
      "csv_pd['label']": 1,
      "application_train['TARGET']": 1,
      "one_hot": 1,
      "y_resampled": 1,
      "data['target']": 1,
      "label_array": 1,
      "train_csv.isup_grade.values": 1,
      "train_data['cat_1']": 1,
      "pubg_copy['matchType']": 1,
      "train_data['season']": 1,
      "train_unscaled['population']": 1,
      "odf[y_cols].values": 1,
      "train['target_enc']": 1,
      "y_augmented": 1,
      "all_labels_df.breed": 1,
      "dtrain['is_duplicate']": 1,
      "df_dd['class_id']": 1,
      "train_dataset[key].input.EncodedPixels.apply(str.split).apply(len) > 0": 1,
      "ytrain": 1,
      "df[KEYS]": 1,
      "pre_train[target]": 1,
      "y_train_full": 1,
      "lstm_Y_train_np": 1,
      "dataset.target.values": 1,
      "test.target.values": 1,
      "y_trn": 1
    },
    "sklearn.neighbors._classification.KNeighborsClassifier.__init__.metric": {
      "'minkowski'": 1745,
      "'manhattan'": 52,
      "'euclidean'": 6,
      "'cityblock'": 6,
      "'braycurtis'": 4,
      "'cosine'": 2,
      "dist": 2,
      "optimal_line_distance": 1,
      "params['metric_knn']": 1,
      "mydist": 1,
      "metric": 1
    },
    "sklearn.metrics._classification.cohen_kappa_score.labels": {
      "None": 1028,
      "[0, 1, 2, 3, 4]": 28,
      "numpy.arange(optr.num_class)": 9,
      "[0, 1, 2, 3, 4, 5]": 3,
      "labels": 2,
      "range(5)": 1,
      "[0, 1, 2, 3]": 1
    },
    "sklearn.metrics._ranking.average_precision_score.average": {
      "'macro'": 124,
      "None": 21,
      "'micro'": 7,
      "'weighted'": 2
    },
    "sklearn.linear_model._logistic.LogisticRegression.fit.sample_weight": {
      "None": 3365,
      "w_train": 2,
      "weight_train": 1,
      "sample_weight": 1
    },
    "sklearn.calibration.CalibratedClassifierCV.__init__.cv": {
      "None": 678,
      "5": 28,
      "'prefit'": 22,
      "10": 17,
      "3": 16,
      "kFold": 7,
      "2": 6,
      "4": 3,
      "7": 1,
      "k": 1,
      "cv_num": 1,
      "StratifiedKFold(5)": 1,
      "folds": 1
    },
    "sklearn.calibration.calibration_curve.n_bins": {
      "10": 21,
      "5": 4
    },
    "sklearn.calibration.calibration_curve.y_true": {
      "outs": 4,
      "train_y": 3,
      "y_test": 3,
      "Yv": 3,
      "ycV": 2,
      "y_test_prime[:, 0]": 2,
      "y_test_prime[:, 1]": 2,
      "y_test_prime[:, 2]": 2,
      "test_test": 1,
      "Y_valid": 1,
      "Ytest": 1,
      "Yt": 1
    },
    "sklearn.calibration.calibration_curve.y_prob": {
      "prob_pos": 6,
      "y_probs[:, 0]": 2,
      "y_probs[:, 1]": 2,
      "y_probs[:, 2]": 2,
      "model.predict_proba(xcV)[:, 1]": 1,
      "calibrated_model.predict_proba(xcV)[:, 1]": 1,
      "train_pred": 1,
      "calib_pred": 1,
      "sig_pred": 1,
      "full_upd_preds[:, 1]": 1,
      "outlier_obj_preds[:, 1]": 1,
      "cv_preds[:, 1]": 1,
      "selection_preds[:, 1]": 1,
      "lgbm_train": 1,
      "preds_linear": 1,
      "preds_ranked": 1,
      "preds_platt": 1
    },
    "sklearn.metrics._ranking.roc_auc_score.sample_weight": {
      "None": 8290,
      "df_i.testiness": 4,
      "df.testiness": 2,
      "pred[:, 1:2]": 1
    },
    "sklearn.datasets._samples_generator.make_regression.n_samples": {
      "200": 1,
      "n_samples": 1,
      "100": 1
    },
    "sklearn.datasets._samples_generator.make_regression.random_state": {
      "1": 1,
      "42": 1,
      "random_state": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.random_state": {
      "None": 104,
      "1": 16,
      "42": 6,
      "0": 5,
      "9": 4,
      "random_state": 3,
      "next(rsit)": 1,
      "5": 1,
      "i": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.max_iter": {
      "200": 80,
      "1000": 13,
      "500": 9,
      "10000": 8,
      "100": 4,
      "300": 4,
      "10": 4,
      "30": 3,
      "400": 2,
      "max_iter": 2,
      "int(1000000.0)": 1,
      "180": 1,
      "iter_use": 1,
      "1500": 1,
      "epoch_train": 1,
      "12": 1,
      "trial.suggest_int('max_iter', 1000, 5000)": 1,
      "20": 1,
      "50": 1,
      "40": 1,
      "2000": 1,
      "110": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.predict.X": {
      "X_test": 17,
      "X_val": 5,
      "x_train": 5,
      "X_validation": 5,
      "x_test": 4,
      "X_valid": 3,
      "x_valid": 3,
      "x_val": 2,
      "prediction_input": 2,
      "X_test2": 2,
      "X_val_ohe": 2,
      "vl_x": 2,
      "test_x": 2,
      "X_test_1": 2,
      "X_test_prediction": 2,
      "X_train": 2,
      "X_test[:2]": 1,
      "X_test_df": 1,
      "testing": 1,
      "X": 1,
      "test_onehot": 1,
      "test_data": 1,
      "test[['feature_1', 'feature_2', 'feature_3']]": 1,
      "X_train_b_oh": 1,
      "X_train_c_oh": 1,
      "test_data_oh": 1,
      "test_x_": 1,
      "val[cols_to_fit]": 1,
      "x": 1,
      "mt_features_test": 1,
      "new_test_scaled": 1,
      "X_validation_encoded": 1,
      "colTransformer.transform(X_test)": 1,
      "scale_X": 1,
      "testFeatures": 1,
      "test_df": 1,
      "X / 100.0": 1,
      "scale(X_test)": 1,
      "myPredictions": 1,
      "[[passengers, distance]]": 1,
      "test": 1,
      "data": 1,
      "x_train[working_sample[train_counter]]": 1,
      "X2": 1,
      "X3": 1,
      "scaled_test": 1,
      "X_valid[df_train_col]": 1,
      "df_test_sc_ms": 1,
      "X_submit_scaled": 1,
      "sub_X": 1,
      "X_test_sc": 1,
      "val_df": 1,
      "test[columns]": 1,
      "x_mul": 1
    },
    "sklearn.manifold._mds.MDS.__init__.n_components": {
      "2": 8,
      "n_components": 3
    },
    "sklearn.manifold._mds.MDS.__init__.dissimilarity": {
      "'euclidean'": 7,
      "'precomputed'": 4
    },
    "sklearn.manifold._mds.MDS.__init__.random_state": {
      "None": 7,
      "1": 3,
      "314": 1
    },
    "sklearn.manifold._mds.MDS.fit_transform.X": {
      "1 - abs(corr)": 1,
      "1 - abs(corr_with_loading)": 1,
      "X_eda": 1,
      "X": 1,
      "cosine_dist": 1,
      "X_ss": 1
    },
    "sklearn.metrics._classification.fbeta_score.beta": {
      "2": 104,
      "0.5": 20,
      "null": 10,
      "1": 3,
      "self.beta": 3,
      "100": 2,
      "np.float(beta_value)": 1
    },
    "sklearn.metrics._classification.fbeta_score.average": {
      "'samples'": 90,
      "'binary'": 30,
      "'micro'": 8,
      "'macro'": 7,
      "None": 7,
      "'weighted'": 1
    },
    "sklearn.metrics._classification.fbeta_score.y_true": {
      "y_true": 26,
      "y": 23,
      "y_test": 20,
      "y_valid": 12,
      "Y_valid": 7,
      "targs": 6,
      "all_targets": 5,
      "targets": 4,
      "target": 3,
      "y_val": 2,
      "y_values": 2,
      "ans": 2,
      "yTest": 2,
      "model_ans[1]": 2,
      "ground_truth[i, :]": 2,
      "y_true[i, :]": 2,
      "y_true_sm": 1,
      "Y_val": 1,
      "y_train0": 1,
      "true_value": 1,
      "model_predict[idx, :] > 0.5": 1,
      "val_targets_c": 1,
      "val_targets_t": 1,
      "vals": 1,
      "yt": 1,
      "np.array(Y_test)": 1,
      "y_obs": 1,
      "t.cpu().detach().numpy()": 1,
      "y_train[val_index]": 1,
      "np.array(y_val)": 1,
      "y_train.iloc[train_index]": 1,
      "y_train.iloc[test_index]": 1,
      "np.asarray(y_validation)": 1,
      "valid_labels": 1,
      "y_valid == 1": 1,
      "np.array(y)": 1,
      "y_train": 1,
      "np.array(valid_y)[:len(valid_pred)]": 1,
      "true_label": 1
    },
    "sklearn.metrics._classification.fbeta_score.y_pred": {
      "y_pred": 26,
      "np.array(p_valid) > 0.2": 18,
      "train_pred": 17,
      "clf.predict(X_test)": 10,
      "preds > th": 6,
      "p2": 5,
      "predictions": 5,
      "yp": 4,
      "thresholded_predictions": 3,
      "np.round(y_pred)": 2,
      "pred": 2,
      "preds": 2,
      "results.round()": 2,
      "predicted_classes": 2,
      "best_predictions": 2,
      "pre": 2,
      "y_pred_class": 2,
      "pred[i, :]": 2,
      "y_pred[i, :]": 2,
      "y_true": 1,
      "y_predict": 1,
      "val_test_pred_lgb": 1,
      "y_pred_sm": 1,
      "np.array(p_val) > 0.2": 1,
      "np.array(p_train) > 0.2": 1,
      "model_target[idx, :]": 1,
      "np.array(val_predicts[0]) > threshold": 1,
      "np.array(val_predicts[1]) > threshold": 1,
      "y_pred_max": 1,
      "np.array(p_valid) > 0.18": 1,
      "np.array(p_valid) > 0.5": 1,
      "(yp > 0.5).astype(int)": 1,
      "train_predict": 1,
      "move_threshold(probs, threshold)": 1,
      "np.array(p_valid) > thres": 1,
      "np.where(o.cpu().detach().numpy() > 0.5, 1, 0)": 1,
      "np.array(pred_val) > 0.2": 1,
      "pred > th": 1,
      "predictions_train": 1,
      "predictions_test": 1,
      "reduced_predictions": 1,
      "y_pred_dum": 1,
      "yTestPredLGB": 1,
      "yTestPredXGB": 1,
      "p_valid > 0.2": 1,
      "np.array(p)": 1,
      "np.array(valid_pred) > threshhold": 1,
      "prediction": 1
    },
    "sklearn.tree._classes.DecisionTreeClassifier.__init__.class_weight": {
      "None": 1495,
      "'balanced'": 45,
      "{0: 1, 1: pos_weights}": 2,
      "{0: 1, 1: 6.6}": 1,
      "{0: 0.2, 1: 0.8}": 1,
      "dict_weight": 1,
      "{1: 45}": 1,
      "'auto'": 1,
      "{0: 1, 1: 400}": 1
    },
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.max_features": {
      "None": 774,
      "'sqrt'": 106,
      "0.55": 19,
      "'auto'": 17,
      "3": 9,
      "0.35": 6,
      "2": 6,
      "0.95": 5,
      "0.1": 5,
      "'log2'": 4,
      "7": 4,
      "0.4": 3,
      "0.8": 3,
      "10": 3,
      "25": 2,
      "0.7": 2,
      "0.5": 2,
      "0.45": 2,
      "19": 1,
      "40": 1,
      "_max_features": 1,
      "42": 1,
      "12": 1,
      "36": 1,
      "119": 1,
      "4": 1,
      "0.12": 1,
      "trial.suggest_uniform('max_features', 0.1, 1.0)": 1,
      "15": 1,
      "150": 1,
      "max_feature": 1,
      "max_features": 1,
      "79": 1,
      "23": 1,
      "0.2": 1
    },
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.min_samples_leaf": {
      "1": 784,
      "15": 90,
      "18": 18,
      "10": 13,
      "9": 12,
      "4": 10,
      "3": 9,
      "2": 8,
      "6": 7,
      "8": 7,
      "5": 6,
      "50": 4,
      "43": 4,
      "17": 2,
      "60": 2,
      "49": 2,
      "33": 1,
      "0.00043": 1,
      "24": 1,
      "_min_samples_leaf": 1,
      "7": 1,
      "20": 1,
      "trial.suggest_int('min_samples_leaf', 1, 19, 3)": 1,
      "0.0024212450940811515": 1,
      "40": 1,
      "min_samples_leaf": 1,
      "16": 1
    },
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.min_samples_split": {
      "2": 792,
      "10": 96,
      "14": 27,
      "5": 17,
      "15": 7,
      "9": 6,
      "4": 5,
      "6": 4,
      "110": 3,
      "109": 2,
      "20": 2,
      "12": 2,
      "3": 2,
      "8": 2,
      "50": 2,
      "2000": 2,
      "49": 2,
      "600": 1,
      "550": 1,
      "24": 1,
      "_min_samp_split": 1,
      "500": 1,
      "140": 1,
      "100": 1,
      "360": 1,
      "1": 1,
      "0.9900745088899041": 1,
      "400": 1,
      "1.0": 1,
      "x": 1,
      "min_samples_split": 1,
      "160": 1,
      "30": 1
    },
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.max_iter": {
      "1000": 57,
      "10000000.0": 8,
      "10000": 6,
      "50000": 5,
      "100000": 4,
      "1000000": 1,
      "2000": 1,
      "10000.0": 1,
      "5000": 1,
      "100000.0": 1
    },
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.alphas": {
      "None": 46,
      "alphas": 8,
      "e_alphas": 6,
      "[0.0001, 0.0003, 0.0006, 0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1, 3, 6]": 3,
      "[1, 0.1, 0.001, 0.0005]": 3,
      "elastic_alphas": 3,
      "lamdbalar": 3,
      "[1e-09, 1e-08, 1e-07, 1e-06, 0.001, 2.0, 10.0]": 2,
      "alpha_elnet": 1,
      "np.logspace(-4, -2, 9)": 1,
      "[0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.001, 0.1, 1.0]": 1,
      "[0.0001, 0.0005, 0.001, 0.01, 0.1, 1, 10]": 1,
      "[1, 0.1, 0.003, 0.03, 1e-05]": 1,
      "np.linspace(0.01, 0.99, 100)": 1,
      "[0.1, 0.3, 1, 3, 10]": 1,
      "np.arange(0.0001, 0.1, 0.0001)": 1,
      "[alpha * 0.6, alpha * 0.65, alpha * 0.7, alpha * 0.75, alpha * 0.8, alpha * 0.85, alpha * 0.9, alpha * 0.95, alpha, alpha * 1.05, alpha * 1.1, alpha * 1.15, alpha * 1.25, alpha * 1.3, alpha * 1.35, alpha * 1.4]": 1,
      "[0.0001, 0.0003, 0.0006, 0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1, 3, 6, 10, 13]": 1,
      "alpha_las": 1
    },
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.cv": {
      "None": 41,
      "5": 12,
      "10": 12,
      "kfolds": 11,
      "kfold": 2,
      "cv": 2,
      "kf": 1,
      "k_folds": 1,
      "LeaveOneOut()": 1,
      "6": 1,
      "_cv": 1
    },
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.l1_ratio": {
      "0.5": 38,
      "e_l1ratio": 6,
      "l1ratio": 5,
      "[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1]": 4,
      "np.linspace(0.01, 1, 100)": 3,
      "1": 3,
      "[0.1, 0.3, 0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.95, 1]": 3,
      "elastic_l1ratio": 3,
      "0.85": 2,
      "l1ratio_elnet": 1,
      "[0.1, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 1]": 1,
      "[0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99]": 1,
      "l_ones": 1,
      "[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 0.995, 1]": 1,
      "l1_list": 1,
      "[0.8, 0.85, 0.9, 0.95, 0.99, 1]": 1,
      "[0.01, 0.1, 0.5, 0.9, 0.99]": 1,
      "[0.3, 0.6, 0.9]": 1,
      "[0.1, 0.5, 0.7, 0.9, 0.95, 0.96, 0.97, 0.98, 0.99, 1]": 1,
      "[ratio * 0.85, ratio * 0.9, ratio * 0.95, ratio, ratio * 1.05, ratio * 1.1, ratio * 1.15]": 1,
      "ratio": 1,
      "l1_ratios": 1,
      "np.linspace(0.5, 1)": 1,
      "ratios": 1,
      "[0.01, 0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1]": 1,
      "[0.1, 0.2, 0.3, 0.4, 0.5, 0.7, 0.8, 0.9]": 1,
      "e_ratio": 1
    },
    "sklearn.impute._iterative.IterativeImputer.__init__.estimator": {
      "None": 47,
      "ExtraTreesRegressor(random_state=0)": 3,
      "BayesianRidge()": 2,
      "self.estimator": 1,
      "RandomForestRegressor()": 1,
      "LinearRegression()": 1
    },
    "sklearn.impute._iterative.IterativeImputer.fit_transform.X": {
      "signals[signal_col].to_numpy().reshape(-1, 1)": 2,
      "df_data": 2,
      "train[features]": 2,
      "train[ordinal]": 2,
      "train_df3_copy": 1,
      "df[p_data]": 1,
      "test_df[p_data]": 1,
      "X[numerical_feature]": 1,
      "imp_train_input[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch']]": 1,
      "imp_train_input[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]": 1,
      "imp_train_input": 1,
      "undsamp_train": 1,
      "test_working": 1,
      "df_iterative_imputer[feature_cols]": 1,
      "df_miss_itr[feature_cols]": 1,
      "X1": 1,
      "train[['Age']]": 1,
      "X_train[num_cols]": 1,
      "X_test[num_cols]": 1,
      "df[['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']]": 1,
      "np.array(df[feature]).reshape(-1, 1)": 1,
      "pc": 1,
      "pc_test_rev": 1,
      "dataframe_train[age_column].values.reshape(-1, 1)": 1,
      "data_train[p_vals]": 1,
      "data_temp_test[p_vals_test]": 1,
      "X_imputation": 1,
      "X": 1,
      "X_tot": 1,
      "train[label_cols]": 1,
      "test[label_cols]": 1
    },
    "sklearn.feature_selection._univariate_selection.SelectKBest.__init__.k": {
      "5": 55,
      "10": 51,
      "'all'": 35,
      "179": 17,
      "k": 14,
      "100": 12,
      "50": 11,
      "4": 11,
      "15": 9,
      "350": 9,
      "2": 8,
      "20": 8,
      "200": 5,
      "30": 5,
      "6": 4,
      "n_features": 4,
      "3": 3,
      "40": 3,
      "i": 3,
      "8": 3,
      "250": 3,
      "self.k": 3,
      "300": 3,
      "160": 3,
      "120": 3,
      "opt_k": 3,
      "len(cont_vars)": 3,
      "52": 2,
      "150": 2,
      "60": 2,
      "min(top_k, X_train.shape[1])": 2,
      "32": 2,
      "13": 2,
      "46": 2,
      "12": 2,
      "290": 2,
      "1500": 2,
      "170": 2,
      "kbest": 2,
      "5000": 2,
      "k_ind": 2,
      "features": 2,
      "29": 2,
      "400": 1,
      "14000": 1,
      "173": 1,
      "6500": 1,
      "50000": 1,
      "15000": 1,
      "55": 1,
      "69": 1,
      "31": 1,
      "80": 1,
      "171": 1,
      "int(self.n_features * 0.9)": 1,
      "int(self.n_features * 0.1)": 1,
      "260": 1,
      "best_params['SFromModel__k']": 1,
      "500": 1,
      "118": 1,
      "len(features)": 1,
      "num_feats": 1,
      "25": 1,
      "8000": 1,
      "data_sparse.shape[1]": 1,
      "dummy_sparse.shape[1]": 1,
      "125": 1,
      "min(TOP_K, x_train.shape[1])": 1,
      "k_val": 1,
      "1000": 1,
      "96": 1,
      "9": 1,
      "138": 1,
      "72": 1,
      "285": 1,
      "n": 1,
      "min(TOP_K_ngram, x_train.shape[1])": 1,
      "42": 1,
      "32 * 32 * 2": 1,
      "110": 1,
      "1": 1,
      "27": 1,
      "220": 1,
      "2000": 1,
      "min(self.k, X.shape[1])": 1,
      "num_of_features": 1,
      "45": 1
    },
    "sklearn.feature_selection._base.SelectorMixin.get_support.indices": {
      "False": 435,
      "True": 52
    },
    "sklearn.feature_extraction.text.TfidfTransformer.fit.X": {
      "X": 9,
      "train_data_cv": 3,
      "word_count_vector": 3,
      "term_freq_matrix": 3,
      "x_train_dtm": 2,
      "df_test_bow_trans": 2,
      "train_X_bow": 2,
      "X_train_counts": 2,
      "X_train": 2,
      "review_bow": 2,
      "ingredient_list_count": 1,
      "train_text_bow": 1,
      "test_text_bow": 1,
      "train_keyword_bow": 1,
      "test_keyword_bow": 1,
      "count_vectorizer.transform(all_text)": 1,
      "train_sparse": 1,
      "phrases_bow": 1,
      "test_bow": 1,
      "X_train_dtm": 1,
      "X_train_cv": 1,
      "X_pos": 1,
      "X_neg": 1,
      "freq_term_matrix": 1,
      "count_vector": 1,
      "small_tranformed": 1,
      "cvec_term_doc": 1,
      "finaldata": 1,
      "train_comments_count": 1,
      "X_vect_train": 1,
      "X_vect_test": 1,
      "train_data_features": 1,
      "feature_counts": 1,
      "counted_fitted_words": 1,
      "feature_vec": 1,
      "X_test": 1
    },
    "sklearn.feature_extraction.text.TfidfTransformer.__init__.use_idf": {
      "True": 314,
      "False": 20,
      "use_idf": 2
    },
    "sklearn.model_selection._search.RandomizedSearchCV.__init__.refit": {
      "True": 556,
      "False": 3,
      "'roc_auc'": 3,
      "'nrmse'": 2,
      "refit": 2,
      "'AUC'": 1,
      "get_best_qwk_params": 1,
      "'Accuracy'": 1,
      "'cohen_kappa'": 1,
      "'cohen_kappa_quadratic'": 1,
      "'accuracy'": 1,
      "'r2'": 1
    },
    "sklearn.base.clone.estimator": {
      "model": 49,
      "x": 40,
      "self.meta_model": 36,
      "clf": 25,
      "self.estimator": 10,
      "regr": 5,
      "estimator1": 4,
      "xgb_model": 4,
      "self.meta_regressor": 4,
      "grid_search.best_estimator_": 3,
      "orig_model": 3,
      "rf_model": 3,
      "lgbm_model": 3,
      "self.model": 3,
      "clf_": 3,
      "encoder": 3,
      "mod": 2,
      "xgb_reg_model": 2,
      "pipe": 2,
      "self.base_estimator": 2,
      "pipeline": 2,
      "search.estimator": 2,
      "regressor": 2,
      "pipe_grid.best_estimator_": 1,
      "self.transformation": 1,
      "rf_reg_model": 1,
      "self.base_model_g": 1,
      "self.base_model_c": 1,
      "simple_model": 1,
      "self.base_clf": 1,
      "sgd_clf": 1,
      "estimator": 1,
      "decisionTree": 1,
      "tr_": 1,
      "best_reg": 1,
      "sgd": 1,
      "hasher": 1,
      "cbe": 1,
      "best_clf": 1,
      "std_scaler": 1,
      "grid": 1,
      "self.regressor": 1
    },
    "sklearn.linear_model._base.LinearRegression.fit.sample_weight": {
      "None": 2362,
      "wts": 22,
      "weights": 7,
      "newwts": 4,
      "w": 3,
      "wts_train": 2,
      "weights.flatten()": 2,
      "np.array(weights)": 1,
      "sample_weights": 1,
      "X_cc['weight']": 1,
      "X_ft['weight']": 1,
      "sample_weight": 1
    },
    "sklearn.model_selection._validation.cross_validate.scoring": {
      "None": 88,
      "scoring": 42,
      "'roc_auc'": 34,
      "'neg_root_mean_squared_error'": 15,
      "'neg_mean_squared_error'": 15,
      "'accuracy'": 15,
      "kappa_score": 9,
      "'neg_mean_absolute_error'": 6,
      "'f1'": 6,
      "'neg_log_loss'": 5,
      "'f1_macro'": 4,
      "['roc_auc', 'accuracy', 'recall', 'precision', 'f1']": 4,
      "['neg_mean_absolute_error', 'r2']": 4,
      "('accuracy', 'f1')": 3,
      "['neg_mean_absolute_error']": 3,
      "['accuracy', 'precision', 'recall']": 3,
      "['r2', 'neg_mean_squared_log_error']": 3,
      "scoring_funcs": 2,
      "metrics": 2,
      "list(scoring.values())": 2,
      "('r2', 'neg_mean_squared_error')": 2,
      "'r2'": 2,
      "['roc_auc']": 2,
      "['r2']": 2,
      "scorer": 2,
      "make_scorer(matthews_corrcoef)": 2,
      "score_func": 1,
      "scorings": 1,
      "make_scorer(score_func, greater_is_better=True)": 1,
      "('accuracy', 'f1', 'roc_auc')": 1,
      "scoring_list": 1,
      "('accuracy', 'recall', 'f1', 'roc_auc')": 1,
      "'balanced_accuracy'": 1,
      "('accuracy', 'roc_auc')": 1,
      "['accuracy']": 1,
      "['r2', 'neg_mean_absolute_error', 'neg_mean_squared_error']": 1,
      "cv_roc_auc_scorer": 1,
      "['r2', 'neg_root_mean_squared_error']": 1,
      "'explained_variance'": 1,
      "['neg_mean_squared_error']": 1,
      "confusion_matrix_scorer": 1,
      "{'rmse': make_scorer(rmse)}": 1,
      "logloss_score": 1,
      "rmse_loss": 1,
      "self.scoring": 1,
      "rmse": 1,
      "('r2', 'neg_mean_squared_error', 'neg_mean_absolute_error', 'neg_root_mean_squared_error')": 1,
      "score_funcs": 1
    },
    "sklearn.preprocessing._data.Normalizer.__init__.norm": {
      "'l2'": 126,
      "norm": 1,
      "'max'": 1
    },
    "sklearn.preprocessing._data.Normalizer.__init__.copy": {
      "True": 114,
      "False": 14
    },
    "sklearn.tree._classes.DecisionTreeClassifier.__init__.splitter": {
      "'best'": 1535,
      "'random'": 13
    },
    "sklearn.preprocessing._label.label_binarize.y": {
      "y": 9,
      "y1": 3,
      "new_y": 3,
      "y_score2": 3,
      "temp": 2,
      "df.Sentiment.to_xarray()": 2,
      "integer_encoded2": 2,
      "y_true": 2,
      "df.author": 1,
      "y_test": 1,
      "true_labels": 1,
      "train['Author']": 1,
      "ytrain": 1,
      "test_y": 1,
      "labels['breed']": 1,
      "df_test['open_channels']": 1,
      "y_val": 1,
      "Y_valid": 1
    },
    "sklearn.manifold._t_sne.TSNE.__init__.n_jobs": {
      "None": 497,
      "-1": 25,
      "self.n_jobs": 10,
      "-2": 2,
      "4": 1,
      "n_jobs": 1
    },
    "sklearn.multiclass.OneVsRestClassifier.predict_proba.X": {
      "X_test": 13,
      "X_train_tf": 5,
      "X_val_tf": 5,
      "e_[len(mtrain):]": 3,
      "X_train": 3,
      "X_val": 3,
      "X_train_fold": 2,
      "X_val_fold": 2,
      "X_valid": 2,
      "x_test": 2,
      "X_test[features]": 1,
      "X_test_stack[features_stack]": 1,
      "X_train_val": 1,
      "test_matrix": 1,
      "test": 1,
      "X_train_n": 1,
      "X_val_n": 1,
      "test_data_features": 1,
      "X_sample": 1
    },
    "sklearn.cluster._kmeans.KMeans.fit_predict.X": {
      "pixel_matrix": 18,
      "X": 15,
      "X_scaled": 12,
      "word_vectors": 9,
      "np.mat(data)": 8,
      "x_3d": 7,
      "x": 7,
      "df": 7,
      "combinationOverlapMatrix": 7,
      "region_metadata[['lat', 'lon']].values": 6,
      "data[['pickup_longitude', 'pickup_latitude']]": 4,
      "data[['dropoff_longitude', 'dropoff_latitude']]": 4,
      "X_train": 4,
      "modified_image": 4,
      "X_train[flist].values": 3,
      "image_PCA": 3,
      "data": 3,
      "thetas": 3,
      "results_wind": 3,
      "tripAttributes": 3,
      "features": 2,
      "X_features": 2,
      "geodata": 2,
      "L1_one_hot[column_names]": 2,
      "L2_one_hot[column_names]": 2,
      "matrice[:, :2]": 2,
      "corr_feat_mtx": 2,
      "image": 2,
      "km[km.columns[1:3]]": 2,
      "results": 2,
      "user_question_part1_m": 2,
      "user_question_part2_m": 2,
      "user_question_part3_m": 2,
      "user_question_part4_m": 2,
      "user_question_part5_m": 2,
      "user_question_part6_m": 2,
      "user_question_part7_m": 2,
      "question_c_part_part1": 2,
      "question_c_part_part2": 2,
      "question_c_part_part3": 2,
      "question_c_part_part4": 2,
      "question_c_part_part5": 2,
      "question_c_part_part6": 2,
      "question_c_part_part7": 2,
      "image[:, :, 0].reshape(-1, 1)": 2,
      "c": 2,
      "c_test": 2,
      "reshaped_data": 2,
      "X_for_kmeans": 2,
      "x2": 2,
      "x2b": 2,
      "train": 2,
      "matrix": 1,
      "df[['pickup_longitude', 'pickup_latitude']]": 1,
      "df_test": 1,
      "mprob": 1,
      "df['pscore'].values.reshape(-1, 1)": 1,
      "np.array(X_full[var[0]]).reshape(-1, 1)": 1,
      "corr.as_matrix()": 1,
      "sales2": 1,
      "self.encoding[df['X'].values].values.reshape(-1, 1)": 1,
      "distances": 1,
      "temp": 1,
      "X_sel[:4500]": 1,
      "df_media.values": 1,
      "media_cluster.values": 1,
      "PCA_components[['pc1', 'pc2']]": 1,
      "all_df[cat_features]": 1,
      "scale_patient_df[['x', 'y', 'intensity']].values": 1,
      "df_dataset4_week1.loc[527057:527070, ['x', 'y']]": 1,
      "pca_user_order": 1,
      "st_cluster_data": 1,
      "pca_result": 1,
      "X[conts]": 1,
      "zero": 1,
      "one": 1,
      "grped_weeks[['Weekly_Sales']]": 1,
      "grped_depts[['Weekly_Sales']]": 1,
      "utilMat": 1,
      "x_pca": 1,
      "ide_qs_binary": 1,
      "features_df": 1,
      "a": 1,
      "tmp": 1,
      "array": 1,
      "df_encoded[['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']]": 1,
      "Ttrain": 1,
      "vz": 1,
      "encoded_data": 1,
      "X_subset": 1,
      "deviation_pivot": 1,
      "m": 1,
      "np.column_stack([corr_features, intersection_features])": 1,
      "train[col].values": 1,
      "X_reduced": 1,
      "df_2014[['X', 'Y']]": 1,
      "df[['pickup_latitude', 'pickup_longitude']].values": 1,
      "df[['dropoff_latitude', 'dropoff_longitude']].values": 1,
      "[np.array(x) for x in df['Hist'].values]": 1,
      "np.array(DATA['LNFare']).reshape(-1, 1)": 1,
      "np.array(DATA['FirstNameFreq']).reshape(-1, 1)": 1,
      "train.drop(columns=['Id', 'idhogar'])[train['Target'] == group[0]]": 1,
      "train_X_scaled": 1,
      "XX": 1,
      "np.reshape(y_tot, (y_tot.shape[0], 1))": 1,
      "news_train_df[sem_labels].values": 1,
      "X.iloc[:, 3:]": 1,
      "pca_train_df": 1,
      "scores.reshape([-1, 1])": 1
    },
    "sklearn.cross_decomposition._pls.PLSRegression.__init__.n_components": {
      "i": 2,
      "1": 1,
      "512": 1,
      "msemin + 1": 1,
      "n_comp": 1,
      "n_components": 1,
      "24": 1,
      "2": 1
    },
    "sklearn.cross_decomposition._pls.PLSRegression.__init__.tol": {
      "1e-06": 7,
      "0.0005009294958980265": 1,
      "0.0003": 1
    },
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.__init__.base_estimator": {
      "None": 439,
      "DecisionTreeClassifier()": 14,
      "DecisionTreeClassifier(max_depth=2)": 7,
      "dt": 6,
      "DecisionTreeClassifier(max_depth=1)": 4,
      "ensemble.ExtraTreesClassifier(n_estimators=500)": 4,
      "ensemble.GradientBoostingClassifier(n_estimators=1000, max_depth=10)": 4,
      "DecisionTreeClassifier(max_depth=5)": 4,
      "tree": 4,
      "DecisionTreeClassifier(random_state=random_state)": 3,
      "lr": 3,
      "DTC": 3,
      "DecisionTreeClassifier(max_depth=8)": 2,
      "clf": 2,
      "dtclf": 2,
      "LogisticRegression(max_iter=100000)": 2,
      "rfc": 2,
      "ex": 2,
      "ExtraTreesClassifier(n_estimators=500)": 2,
      "rf": 1,
      "DecisionTreeClassifier(max_depth=20, criterion='entropy', splitter='random')": 1,
      "base_estimator_ada": 1,
      "LogisticRegression()": 1,
      "RandomForestClassifier(n_estimators=n_rf_trees, min_samples_leaf=100, n_jobs=-1, verbose=True)": 1,
      "model_logit": 1,
      "DecisionTreeClassifier(max_depth=8, min_samples_leaf=10, random_state=42)": 1,
      "DecisionTree()": 1,
      "DecisionTreeClassifier(max_depth=10)": 1,
      "base_network": 1,
      "base": 1,
      "first_forest": 1,
      "DecisionTreeClassifier(max_depth=5, min_samples_split=30, min_samples_leaf=30)": 1,
      "DecisionTreeClassifier(max_depth=3, criterion='entropy')": 1,
      "DecisionTreeClassifier(max_depth=3)": 1,
      "GradientBoostingClassifier(n_estimators=100)": 1,
      "ensemble.ExtraTreesClassifier(n_estimators=200, max_features=0.8, max_depth=80, criterion='gini')": 1,
      "ensemble.GradientBoostingClassifier(n_estimators=500, max_features=0.8, max_depth=50, criterion='friedman_mse')": 1
    },
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict_proba.X": {
      "test": 36,
      "X_test": 6,
      "X": 3,
      "X[train_index]": 2,
      "X[test_index]": 2,
      "test_LDA": 1,
      "Stacked": 1,
      "TargetStacked": 1,
      "Xp_data_img_test": 1,
      "test_df": 1,
      "X_train": 1,
      "normalize(test_data)": 1,
      "X_val": 1,
      "X1": 1,
      "test_data": 1,
      "va_x": 1
    },
    "sklearn.impute._base.SimpleImputer.transform.X": {
      "train": 20,
      "X_test": 19,
      "test": 18,
      "X": 16,
      "poly_features_test": 16,
      "app_test_poly": 8,
      "X_valid": 8,
      "train[i].to_numpy().reshape(-1, 1)": 7,
      "test[i].to_numpy().reshape(-1, 1)": 7,
      "app_test": 7,
      "test.loc[test['PdDistrict'] == district, ['X', 'Y']]": 7,
      "X_train": 6,
      "app_test_domain": 5,
      "test_data": 5,
      "x_test": 4,
      "test_df": 4,
      "data[[col]]": 3,
      "X_valid_plus": 3,
      "np.array(server_features)": 3,
      "df_train_tran[[col]]": 3,
      "test[ordinal]": 3,
      "X[:, 1:2]": 2,
      "train_data[[col]]": 2,
      "x_train": 2,
      "df_test": 2,
      "features": 2,
      "data": 2,
      "y": 2,
      "X_test_1": 2,
      "X_train[num_attr]": 2,
      "X_val[num_attr]": 2,
      "X_train[cat_attr]": 2,
      "X_val[cat_attr]": 2,
      "X_test_cats": 2,
      "X_test_nums": 2,
      "housing_num": 2,
      "X_val": 2,
      "df_train_tran_id[[col]]": 2,
      "df_test_tran_id[[col]]": 2,
      "x_train[num_var1]": 2,
      "X[:, np.r_[2:3]]": 2,
      "X_test[:, np.r_[2:3]]": 2,
      "train_df": 2,
      "X_test_preprocessed[[col]]": 2,
      "val_preprocessed[[col]]": 2,
      "val_X": 2,
      "df": 2,
      "train_df.loc[:, not_categorical]": 2,
      "test_df.loc[:, not_categorical]": 2,
      "num": 2,
      "test[features]": 2,
      "test_looe": 1,
      "X_test[numerical_col]": 1,
      "X_test[categorical_col]": 1,
      "drop_x_test_new": 1,
      "drop_test_full": 1,
      "df_train[i].to_numpy().reshape(-1, 1)": 1,
      "df_test[i].to_numpy().reshape(-1, 1)": 1,
      "testData": 1,
      "X_valid[categorical_cols]": 1,
      "X_valid[numerical_cols]": 1,
      "X_test[categorical_cols]": 1,
      "X_test[numerical_cols]": 1,
      "train['FireplaceQu'].to_frame()": 1,
      "test['FireplaceQu'].to_frame()": 1,
      "train[['LotFrontage', 'GarageYrBlt', 'MasVnrArea']]": 1,
      "test[['LotFrontage', 'GarageYrBlt', 'MasVnrArea']]": 1,
      "df['Age'].values.reshape(-1, 1)": 1,
      "df['Embarked'].values.reshape(-1, 1)": 1,
      "test['Age'].values.reshape(-1, 1)": 1,
      "test['Embarked'].values.reshape(-1, 1)": 1,
      "X_val[numeric_features]": 1,
      "X_val[object_cols]": 1,
      "test_df_selected_features": 1,
      "x.iloc[:, 2:3]": 1,
      "x.iloc[:, [6]]": 1,
      "t.iloc[:, [2]]": 1,
      "t.iloc[:, [5]]": 1,
      "X[:, :]": 1,
      "X_test[:, :]": 1,
      "test_data[[col]]": 1,
      "X_full[num_features]": 1,
      "X_test[num_features]": 1,
      "X_full[cat_features]": 1,
      "X_test[cat_features]": 1,
      "test.loc[test_by_district & test_by_cat, ['X', 'Y']]": 1,
      "ArrayTrain": 1,
      "ArrayTest": 1,
      "X_train_full": 1,
      "test_data[cont_cols]": 1,
      "train_modified": 1,
      "test_modified": 1,
      "df_test[num_housing]": 1,
      "df_test[req_credit]": 1,
      "df_test[cols]": 1,
      "data_test_end": 1,
      "test_data[test_numerical]": 1,
      "test_data[replace_col]": 1,
      "test_data[test_categorical]": 1,
      "X_test_num": 1,
      "out_enc_X_valid": 1,
      "X_train[:, 1:2]": 1,
      "X_test[:, 1:4]": 1,
      "test_df[num_cols_test]": 1,
      "test_df[na_cols]": 1,
      "test_df[cat_cols_test]": 1,
      "test[['Embarked']]": 1,
      "transaction_data[low_missing_num_trans_cols]": 1,
      "identity_data[low_missing_num_id_cols]": 1,
      "transaction_data[medium_missing_num_trans_cols]": 1,
      "identity_data[medium_missing_num_id_cols]": 1,
      "df_dataset_plays": 1,
      "df_dataset1_week1": 1,
      "X_train_csv": 1,
      "X_test_csv": 1,
      "titanic_numerical": 1,
      "X_test[num_attr_test]": 1,
      "X_test[cat_attr_test]": 1,
      "train_features": 1,
      "valid_features": 1,
      "testDataset": 1,
      "trainDataset": 1,
      "xtrain": 1,
      "xval": 1,
      "all_num_data": 1,
      "train_cat": 1,
      "test_cat": 1,
      "train_num": 1,
      "test_num": 1,
      "CSVnum": 1,
      "df_train_tran[[cat_cols[i]]]": 1,
      "df_test_tran[[cat_cols[i]]]": 1,
      "df_test_tran[[col]]": 1,
      "house_test[num_cols]": 1,
      "house_test[cat_cols]": 1,
      "X_test[categorical_feat]": 1,
      "X_test[numerical_feat]": 1,
      "X_test[:]": 1,
      "num_data": 1,
      "test_feat": 1,
      "df_flo": 1,
      "d[['Age']]": 1,
      "d[['Embarked']]": 1,
      "d[['Fare']]": 1,
      "[train['Age'].values]": 1,
      "test[num_var1]": 1,
      "x_train[cat_vars]": 1,
      "test[cat_vars]": 1,
      "XX": 1,
      "train[['Age']]": 1,
      "test[['Age', 'Fare']]": 1,
      "play": 1,
      "df_train['Age'].values.reshape(-1, 1)": 1,
      "df_test['Age'].values.reshape(-1, 1)": 1,
      "train_x.loc[:, scale_cols]": 1,
      "X_train_continuous": 1,
      "test_x.loc[:, scale_cols]": 1,
      "X_test_continuous": 1,
      "df_test.iloc[:, :]": 1,
      "train_df[['Age']]": 1,
      "test_df[['Age']]": 1,
      "test[['CPI']]": 1,
      "test[['Unemployment']]": 1,
      "housing_cat": 1,
      "inputs_df[numeric_cols]": 1,
      "testing_data[numeric_cols]": 1,
      "test.drop(['id'], axis=1)": 1,
      "tec": 1,
      "data_num": 1,
      "feature_test": 1,
      "z": 1,
      "poly_ft_test": 1,
      "df[missing_val_num]": 1,
      "df[missing_val_cat]": 1,
      "label_test[features]": 1,
      "data_set": 1,
      "d_test": 1,
      "pd.DataFrame(valid[col])": 1,
      "pd.DataFrame(test[col])": 1,
      "test[num_attr]": 1,
      "test[cat_attr]": 1,
      "jane": 1,
      "test_X": 1,
      "X_train[:, np.r_[3:5, 6:9, 23:26, 27:93]]": 1,
      "X_test[:, np.r_[3:5, 6:26, 27:93]]": 1,
      "a": 1,
      "b": 1,
      "t2data": 1,
      "t2data_test": 1,
      "temp2": 1,
      "X_trn": 1,
      "X_tst": 1,
      "X_train[features]": 1,
      "X_test[features]": 1,
      "new_X": 1,
      "new_ts": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.solver": {
      "'adam'": 128,
      "'lbfgs'": 8,
      "'sgd'": 3,
      "solver": 2
    },
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.alpha": {
      "0.0001": 119,
      "0.001": 8,
      "0.005": 5,
      "alpha": 2,
      "1e-05": 2,
      "2.0": 1,
      "0.1": 1,
      "0.5": 1,
      "1": 1,
      "0.45": 1
    },
    "sklearn.neighbors._regression.KNeighborsRegressor.__init__.weights": {
      "'uniform'": 323,
      "'distance'": 30,
      "weights": 2,
      "w": 1
    },
    "sklearn.neighbors._regression.KNeighborsRegressor.__init__.algorithm": {
      "'auto'": 348,
      "'ball_tree'": 5,
      "'kd_tree'": 2,
      "'brute'": 1
    },
    "sklearn.svm._classes.SVR.__init__.max_iter": {
      "-1": 449,
      "5000": 6,
      "10000": 5,
      "1000": 3,
      "200": 2,
      "100": 2,
      "2500": 1,
      "8000": 1,
      "100000": 1,
      "trial.suggest_int('max_iter', 1000, 5000)": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.max_iter": {
      "1000": 107,
      "100": 10,
      "100000": 4,
      "200": 3,
      "50": 2,
      "40": 1,
      "5": 1,
      "1500": 1,
      "400": 1,
      "5000": 1,
      "10000": 1,
      "2000": 1,
      "20": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.tol": {
      "0.001": 129,
      "1e-05": 2,
      "1e-10": 1,
      "None": 1,
      "0.01": 1
    },
    "sklearn.linear_model._ridge.Ridge.__init__.random_state": {
      "None": 1003,
      "42": 46,
      "205": 32,
      "0": 25,
      "seed": 23,
      "101": 19,
      "random_state": 9,
      "RANDOM_STATE": 6,
      "666": 5,
      "198": 5,
      "SEED": 4,
      "2021": 3,
      "145": 3,
      "35591": 3,
      "100": 3,
      "241": 3,
      "2020": 2,
      "111": 2,
      "150": 2,
      "369": 2,
      "RANDOM_SEED": 2,
      "1001": 2,
      "25": 2,
      "123": 2,
      "7": 1,
      "params['random_state']": 1,
      "self.params['random_state']": 1,
      "1234": 1,
      "520": 1,
      "52": 1,
      "2018": 1,
      "2019": 1,
      "251": 1,
      "51": 1,
      "5": 1,
      "1": 1,
      "8": 1,
      "10": 1,
      "144": 1,
      "114514": 1,
      "rand_state": 1
    },
    "sklearn.compose._target.TransformedTargetRegressor.__init__.transformer": {
      "None": 14,
      "PowerTransformer()": 3,
      "StandardScaler()": 2,
      "MinMaxScaler()": 1,
      "QuantileTransformer()": 1,
      "preprocessor_Y": 1,
      "QuantileTransformer(output_distribution='normal')": 1
    },
    "sklearn.compose._target.TransformedTargetRegressor.__init__.regressor": {
      "LinearRegression()": 4,
      "stack_pipeline": 2,
      "best_model": 2,
      "f": 2,
      "model0": 1,
      "lasso": 1,
      "lin_svr": 1,
      "pipeline": 1,
      "base_estimator": 1,
      "Pipeline([('preprocessing', preprocessing), ('regressor', XGBRegressor(n_estimators=100, max_depth=2, objective='reg:squarederror', tree_method='gpu_hist'))], verbose=False)": 1,
      "Pipeline([('preprocessing', preprocessing), ('regressor', stacked)], verbose=False)": 1,
      "model_pipeline": 1,
      "RidgeCV()": 1,
      "Ridge(alpha=0.1)": 1,
      "regressor": 1,
      "model_search": 1,
      "ExtraTreesRegressor(n_estimators=1000, criterion='mae', min_samples_split=0.001, n_jobs=4)": 1
    },
    "sklearn.compose._target.TransformedTargetRegressor.fit.X": {
      "x_train": 4,
      "train[features]": 2,
      "X_train": 2,
      "train_X": 1,
      "train": 1,
      "train_X_df": 1,
      "np.array(X_train).reshape(-1, 1)": 1
    },
    "sklearn.compose._target.TransformedTargetRegressor.fit.y": {
      "y_train": 6,
      "train[target]": 2,
      "train_y": 1,
      "target": 1,
      "train_Y_df": 1,
      "np.array(y_train).reshape(-1, 1)": 1
    },
    "sklearn.compose._target.TransformedTargetRegressor.predict.X": {
      "x_train": 4,
      "x_test": 4,
      "test": 2,
      "test_X": 2,
      "X_test": 2,
      "train_X": 1,
      "np.array(X_test).reshape(-1, 1)": 1,
      "X_train": 1
    },
    "sklearn.preprocessing._data.PowerTransformer.fit.X": {
      "all_data[skewed_feats_over]": 2,
      "train1[['fare_amount']]": 1,
      "train_y": 1,
      "train_data[[col]]": 1,
      "X": 1,
      "raw_vec": 1
    },
    "sklearn.preprocessing._data.PowerTransformer.transform.X": {
      "test": 6,
      "X_val": 3,
      "train1[['fare_amount']]": 2,
      "X": 2,
      "test_data": 2,
      "all_data[skewed_feats_over]": 2,
      "train_y": 1,
      "test_X_df": 1,
      "combined_data[[col]]": 1,
      "test[columns_for_prediction]": 1,
      "tdata_local": 1,
      "np.nan_to_num(full_test)": 1,
      "test11": 1,
      "np.array(new_test_df[col]).reshape(-1, 1)": 1,
      "raw_vec": 1,
      "test_features[col].values.reshape(vec_len_test, 1) + 11": 1
    },
    "sklearn.preprocessing._data.PowerTransformer.inverse_transform.X": {
      "cek": 3,
      "pt.transform(train1[['fare_amount']])": 1,
      "preds.reshape(-1, 1)": 1,
      "np.array(preds).T": 1,
      "np.array(final_preds).T": 1,
      "train_data[['SalePrice_yeojohnson2']]": 1
    },
    "sklearn.base.BaseEstimator.get_params.deep": {
      "True": 106,
      "False": 2
    },
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix.cmap": {
      "'viridis'": 116,
      "plt.cm.Blues": 47,
      "plt.cm.Greens": 7,
      "'Blues'": 5,
      "'cool'": 4,
      "'plasma'": 1
    },
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix.normalize": {
      "None": 159,
      "'true'": 17,
      "normalize": 2,
      "'all'": 1,
      "False": 1
    },
    "sklearn.feature_selection._univariate_selection.SelectKBest.__init__.score_func": {
      "f_classif": 136,
      "f_regression": 96,
      "chi2": 87,
      "mutual_info_regression": 27,
      "mutual_info_classif": 11,
      "valid_scoring[scoring]": 4,
      "discrete_mutual_info_regression": 2,
      "self.cat_score_func": 1,
      "score_func": 1,
      "feature_selection.f_classif": 1,
      "function": 1
    },
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.bootstrap": {
      "False": 303,
      "True": 10,
      "None": 1
    },
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.ccp_alpha": {
      "0.0": 314
    },
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.criterion": {
      "'mse'": 311,
      "'mae'": 2,
      "'friedman_mse'": 1
    },
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.max_depth": {
      "None": 178,
      "30": 30,
      "4": 21,
      "g['md']": 17,
      "20": 16,
      "15": 11,
      "5": 7,
      "10": 6,
      "12": 5,
      "6": 5,
      "8": 4,
      "3": 4,
      "depth": 2,
      "2": 2,
      "35": 1,
      "m[1]": 1,
      "l1_et_max_depth": 1,
      "7": 1,
      "result_extra_trees.best_params_['max_depth']": 1,
      "rand_depth": 1
    },
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.max_leaf_nodes": {
      "None": 311,
      "leafs": 2,
      "128": 1
    },
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.max_samples": {
      "None": 313,
      "0.8": 1
    },
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.min_impurity_decrease": {
      "0.0": 314
    },
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.min_impurity_split": {
      "None": 314
    },
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.min_samples_leaf": {
      "1": 271,
      "2": 22,
      "35": 5,
      "4": 3,
      "5": 2,
      "40": 2,
      "100": 2,
      "16": 2,
      "50": 1,
      "10": 1,
      "result_extra_trees.best_params_['min_samples_leaf']": 1,
      "n_attributed / (1000 * total_data)": 1,
      "3": 1
    },
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.min_samples_split": {
      "2": 276,
      "4": 21,
      "25": 5,
      "20": 2,
      "30": 2,
      "12": 1,
      "11": 1,
      "24": 1,
      "5": 1,
      "result_extra_trees.best_params_['min_samples_split']": 1,
      "2 * (n_attributed / (1000 * total_data))": 1,
      "1": 1,
      "0.001": 1
    },
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.min_weight_fraction_leaf": {
      "0.0": 314
    },
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.oob_score": {
      "False": 306,
      "True": 8
    },
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.random_state": {
      "None": 125,
      "0": 54,
      "42": 26,
      "seed": 18,
      "g['rs']": 17,
      "1": 14,
      "17": 7,
      "rnd": 6,
      "35": 6,
      "3": 6,
      "seed_val": 3,
      "18": 3,
      "50": 3,
      "SEED": 2,
      "ra1": 2,
      "ra2": 2,
      "104743": 2,
      "12": 1,
      "99": 1,
      "520": 1,
      "m[2]": 1,
      "CFG['seed']": 1,
      "308537": 1,
      "random_state": 1,
      "10233": 1,
      "14": 1,
      "7": 1,
      "rnd_seed": 1,
      "2016": 1,
      "123": 1,
      "88": 1,
      "x": 1,
      "10": 1,
      "RANDOM_SEED": 1,
      "20170214": 1
    },
    "sklearn.ensemble._forest.ExtraTreesRegressor.__init__.warm_start": {
      "False": 309,
      "True": 5
    },
    "sklearn.model_selection._validation.cross_validate.return_train_score": {
      "False": 198,
      "True": 101
    },
    "sklearn.model_selection._split.StratifiedShuffleSplit.__init__.test_size": {
      "0.2": 83,
      "None": 47,
      "0.1": 28,
      "0.3": 17,
      "0.25": 9,
      "0.5": 7,
      "0.05": 6,
      "0.15": 4,
      "sss_test_size": 3,
      "0.16": 3,
      "test_size": 3,
      "val_size": 2,
      "test_ratio": 2,
      "0.075": 2,
      "0.35": 2,
      "0.33": 2,
      "1 / 3": 2,
      "1 / n_folds": 2,
      "0.8": 2,
      "0.28": 1,
      "valid_size": 1,
      "va_ratio": 1,
      "1 - wandb.config.PROP_DATA": 1,
      "0.22": 1,
      "0.4": 1,
      "0.65": 1,
      "validation_split_size": 1,
      "CFG.test_size": 1,
      "0.01": 1,
      "split": 1,
      "250": 1,
      "1975": 1,
      "holdout_frac": 1
    },
    "sklearn.feature_extraction.text.CountVectorizer.__init__.binary": {
      "False": 2692,
      "True": 237,
      "'true'": 8
    },
    "sklearn.feature_extraction.text.CountVectorizer.__init__.dtype": {
      "np.int64": 2796,
      "np.uint8": 115,
      "np.int8": 12,
      "np.float32": 6,
      "'int32'": 4,
      "'int8'": 2,
      "np.int16": 1,
      "np.uint32": 1
    },
    "sklearn.linear_model._logistic.LogisticRegressionCV.fit.X": {
      "X_train": 18,
      "XV": 12,
      "X_train_scaled": 10,
      "x_train": 10,
      "X": 7,
      "X_learn": 4,
      "train": 3,
      "train_feat": 3,
      "a": 2,
      "x_train_W": 2,
      "X_train_lr": 2,
      "X_subj": 1,
      "X_review": 1,
      "lr_train_data": 1,
      "train_X": 1,
      "train_data_filtered": 1,
      "x_nb": 1,
      "X_sparsed_train": 1,
      "data": 1,
      "X_train_scale": 1,
      "X_all_encoded": 1,
      "train_x": 1,
      "X_meta": 1,
      "d_f_train": 1,
      "trainDataframeX": 1,
      "partial_X": 1,
      "train_set": 1,
      "xtrain_tfv_std": 1,
      "X_train_pca": 1,
      "X_train_rfe": 1,
      "X_train_pca_rfe": 1,
      "tfidf_train": 1,
      "trainX": 1,
      "train_count_mtx": 1
    },
    "sklearn.linear_model._logistic.LogisticRegressionCV.fit.y": {
      "y_train": 42,
      "y_valid": 13,
      "y": 11,
      "y_learn": 4,
      "labels": 3,
      "train_y": 3,
      "train_label": 3,
      "y_train_W": 2,
      "y_train_lr": 2,
      "subj_df.label": 1,
      "review_df.label": 1,
      "train_label_int": 1,
      "Y": 1,
      "Y_train": 1,
      "target": 1,
      "train_labels": 1,
      "d_f2_train": 1,
      "targets": 1,
      "trainDataframeY": 1,
      "partial_y": 1,
      "train_matchType": 1,
      "train_df.Sentiment": 1
    },
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.n_jobs": {
      "None": 88,
      "1": 12,
      "-1": 12,
      "4": 6,
      "10": 3,
      "3": 2,
      "2": 1,
      "5": 1
    },
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.max_iter": {
      "100": 99,
      "500": 10,
      "max_iter": 3,
      "1000": 3,
      "400": 2,
      "300": 2,
      "10000": 2,
      "30000": 1,
      "100000": 1,
      "200": 1,
      "150": 1
    },
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.cv": {
      "None": 57,
      "5": 43,
      "3": 12,
      "10": 3,
      "6": 2,
      "skf": 2,
      "nfolds": 1,
      "cv": 1,
      "kfolds": 1,
      "11": 1,
      "50": 1,
      "4": 1
    },
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.random_state": {
      "None": 69,
      "0": 24,
      "random_state": 12,
      "111": 9,
      "42": 3,
      "77": 2,
      "55": 2,
      "17": 1,
      "1": 1,
      "random_seed": 1,
      "100": 1
    },
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.verbose": {
      "0": 114,
      "1": 4,
      "True": 2,
      "2": 2,
      "3": 2,
      "50": 1
    },
    "sklearn.linear_model._logistic.LogisticRegressionCV.score.X": {
      "X_test": 3,
      "X_train_lr": 2,
      "X_subj": 1,
      "X_review": 1,
      "val_X": 1,
      "data": 1,
      "X_train_scale": 1,
      "d_f_test": 1,
      "testDataframeX": 1,
      "X_test_lr": 1,
      "X_train_rf": 1,
      "X_test_rf": 1,
      "val_set": 1,
      "xvalid_tfv_std": 1,
      "X_train": 1,
      "trainX": 1
    },
    "sklearn.linear_model._logistic.LogisticRegressionCV.score.y": {
      "y_test": 3,
      "y_train": 2,
      "y_train_lr": 2,
      "subj_df.label": 1,
      "review_df.label": 1,
      "val_y": 1,
      "target": 1,
      "d_f2_test": 1,
      "testDataframeY": 1,
      "y_test_lr": 1,
      "y_train_rf": 1,
      "y_test_rf": 1,
      "val_matchType": 1,
      "y_valid": 1,
      "labels": 1
    },
    "sklearn.preprocessing._function_transformer.FunctionTransformer.__init__.validate": {
      "False": 383,
      "True": 73
    },
    "sklearn.model_selection._validation.cross_val_predict.n_jobs": {
      "None": 176,
      "-1": 28,
      "4": 4,
      "1": 2,
      "8": 2,
      "30": 1,
      "5": 1
    },
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.max_iter": {
      "1000": 98,
      "10000000.0": 7,
      "10000": 5,
      "50000": 4,
      "9999": 2,
      "100000": 2,
      "1000000.0": 1,
      "2000": 1
    },
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.tol": {
      "0.0001": 119,
      "0.001": 1
    },
    "sklearn.feature_selection._rfe.RFE.__init__.n_features_to_select": {
      "None": 96,
      "100": 6,
      "2": 3,
      "20": 3,
      "1": 3,
      "n_features": 3,
      "n_features_to_select": 3,
      "n_features_optimal": 3,
      "i": 2,
      "50": 2,
      "10": 2,
      "14": 2,
      "15": 2,
      "150": 2,
      "95": 1,
      "num_feats": 1,
      "83": 1,
      "60": 1,
      "8": 1,
      "22": 1,
      "41": 1,
      "70": 1,
      "200": 1,
      "12": 1
    },
    "sklearn.linear_model._coordinate_descent.ElasticNet.__init__.max_iter": {
      "1000": 373,
      "best_itr": 19,
      "2200": 16,
      "5000": 10,
      "3000": 9,
      "10000": 6,
      "3500": 5,
      "best_iter": 5,
      "50000": 3,
      "1000000": 2,
      "250": 2,
      "5": 2,
      "100000": 2,
      "60": 2,
      "1500": 1,
      "opt_params['max_iter']": 1,
      "cv_model.n_iter_": 1,
      "2000": 1,
      "200000": 1,
      "10000000.0": 1,
      "100": 1,
      "2700": 1,
      "3800": 1,
      "4500": 1,
      "2500": 1
    },
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.Cs": {
      "10": 100,
      "[0.001, 0.01, 0.1, 1, 10, 100]": 9,
      "Cs": 3,
      "7": 2,
      "[0.1, 0.05, 0.01, 0.005, 0.003, 0.001, 0.0001]": 2,
      "100": 2,
      "5": 1,
      "C_s": 1,
      "c_values": 1,
      "[0.01, 0.1, 1, 10.0, 100.0]": 1,
      "np.linspace(0.11, 0.14, num=100)": 1,
      "50": 1,
      "20": 1
    },
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.solver": {
      "'lbfgs'": 91,
      "'newton-cg'": 13,
      "'saga'": 10,
      "'liblinear'": 5,
      "s": 4,
      "'sag'": 2
    },
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.tol": {
      "0.0001": 121,
      "1e-10": 1,
      "0.001": 1,
      "0.01": 1,
      "0.0002": 1
    },
    "sklearn.decomposition._pca.PCA.__init__.whiten": {
      "False": 2551,
      "True": 96,
      "whiten": 6
    },
    "sklearn.decomposition._pca.PCA.__init__.svd_solver": {
      "'auto'": 2580,
      "'full'": 59,
      "'randomized'": 13,
      "self.svd_solver": 1
    },
    "sklearn.decomposition._pca.PCA.fit_transform.y": {
      "None": 1716,
      "y_out": 1,
      "self.train_data.loc[:, targets]": 1,
      "y[:150000]": 1
    },
    "sklearn.metrics._classification.classification_report.digits": {
      "2": 2988,
      "4": 41,
      "3": 41,
      "6": 3,
      "5": 1
    },
    "sklearn.random_projection.GaussianRandomProjection.__init__.n_components": {
      "n_comp": 62,
      "N_COMP": 13,
      "COMPONENTS": 5,
      "3": 3,
      "5": 2,
      "n_compute": 2,
      "n_com": 1,
      "25": 1,
      "32": 1,
      "30": 1,
      "15": 1,
      "num_decompose": 1,
      "'auto'": 1
    },
    "sklearn.random_projection.GaussianRandomProjection.__init__.eps": {
      "0.1": 91,
      "0.2": 3
    },
    "sklearn.random_projection.GaussianRandomProjection.__init__.random_state": {
      "420": 56,
      "None": 12,
      "17": 11,
      "42": 5,
      "random_seed": 2,
      "seed": 2,
      "421": 1,
      "SEED + 354": 1,
      "rstate": 1,
      "random_state": 1,
      "rs": 1,
      "98": 1
    },
    "sklearn.random_projection.BaseRandomProjection.transform.X": {
      "test": 113,
      "test[col]": 10,
      "test_df": 8,
      "X_test": 6,
      "test[kolom]": 4,
      "test_X[col]": 2,
      "X_Test": 2,
      "train": 2,
      "standardized_test": 2,
      "testf": 2,
      "emotions_vectors": 1,
      "full_vec": 1
    },
    "sklearn.random_projection.SparseRandomProjection.__init__.n_components": {
      "n_comp": 62,
      "N_COMP": 13,
      "NUM_OF_COM": 6,
      "COMPONENTS": 4,
      "n_col": 3,
      "n_com": 2,
      "25": 2,
      "10": 2,
      "5": 2,
      "n_compute": 2,
      "n_components": 1,
      "30": 1,
      "15": 1,
      "num_decompose": 1,
      "'auto'": 1
    },
    "sklearn.random_projection.SparseRandomProjection.__init__.dense_output": {
      "True": 93,
      "False": 10
    },
    "sklearn.random_projection.SparseRandomProjection.__init__.random_state": {
      "420": 57,
      "None": 18,
      "17": 11,
      "42": 8,
      "random_seed": 2,
      "seed": 2,
      "421": 1,
      "rstate": 1,
      "random_state": 1,
      "rs": 1,
      "98": 1
    },
    "sklearn.model_selection._split.TimeSeriesSplit.split.X": {
      "X": 33,
      "X_train": 13,
      "self.train_df": 7,
      "train": 6,
      "x_train": 6,
      "values": 2,
      "X_train_CS": 2,
      "dates": 1,
      "observed": 1,
      "date_df[id_]": 1,
      "df": 1,
      "x": 1,
      "lag_df": 1,
      "full_df.iloc[:train_length]": 1,
      "train_clean_rob": 1
    },
    "sklearn.dummy.DummyClassifier.__init__.random_state": {
      "None": 36,
      "0": 7,
      "1": 3,
      "seed": 1,
      "3735928559": 1,
      "42": 1,
      "376": 1
    },
    "sklearn.dummy.DummyClassifier.__init__.strategy": {
      "'prior'": 22,
      "'most_frequent'": 21,
      "'stratified'": 4,
      "'uniform'": 2,
      "'constant'": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.random_state": {
      "None": 95,
      "42": 12,
      "0": 6,
      "SEED": 5,
      "seed": 2,
      "54": 2,
      "2020": 2,
      "52": 2,
      "1001": 2,
      "1017": 1,
      "seed_val": 1,
      "69": 1,
      "random_state": 1,
      "1010": 1,
      "17": 1
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.max_iter": {
      "1000": 34,
      "50": 3,
      "500": 1,
      "135": 1
    },
    "sklearn.cluster._kmeans.MiniBatchKMeans.fit.X": {
      "coords[sample_ind]": 37,
      "vz": 8,
      "X": 7,
      "vz_sample": 6,
      "data": 5,
      "text": 4,
      "dico": 2,
      "X_w2v": 2,
      "bboxarray": 2,
      "geo_df[['latitude', 'longitude']]": 2,
      "train.drop(['id', 'target'], axis=1).iloc[:len(train) * 8 // 10]": 1,
      "train.drop(['id', 'target'], axis=1)": 1,
      "img_orbs_feat[:100000]": 1,
      "train_x": 1,
      "X_svd": 1,
      "train[['pickup_longitude', 'pickup_latitude']]": 1,
      "train[['dropoff_longitude', 'dropoff_latitude']]": 1,
      "coordinates": 1,
      "nptda": 1,
      "descriptor_list": 1,
      "pickup_clusters": 1,
      "tf_idf": 1,
      "coord[sample_ind]": 1,
      "X_no_missing_oh": 1,
      "coords": 1,
      "gifts.loc[:, ['Longitude', 'Latitude']].as_matrix()": 1,
      "tsne_representation[:n_tr]": 1
    },
    "sklearn.cluster._kmeans.MiniBatchKMeans.__init__.n_clusters": {
      "100": 39,
      "k": 10,
      "num_clusters": 9,
      "n_clusters": 8,
      "10": 4,
      "50": 4,
      "numClusters": 3,
      "2": 2,
      "9": 2,
      "120": 2,
      "15": 2,
      "3": 2,
      "n_comp": 2,
      "500": 2,
      "36": 2,
      "no_clusters": 1,
      "n_clust": 1,
      "colors_num": 1,
      "8**2": 1,
      "5000": 1,
      "4": 1,
      "6": 1,
      "16": 1,
      "25": 1,
      "9**2": 1,
      "DISPLAY_CLUSTER_MATRIX[0] * DISPLAY_CLUSTER_MATRIX[1]": 1,
      "n_digits": 1
    },
    "sklearn.cluster._kmeans.MiniBatchKMeans.__init__.batch_size": {
      "10000": 36,
      "100": 29,
      "1000": 12,
      "batch_size": 11,
      "100000": 3,
      "5000": 2,
      "120000": 2,
      "20": 2,
      "32**3": 1,
      "600": 1,
      "256": 1,
      "2000": 1,
      "45": 1,
      "36**3": 1,
      "32": 1,
      "50": 1
    },
    "sklearn.cluster._kmeans.MiniBatchKMeans.predict.X": {
      "test[['pickup_latitude', 'pickup_longitude']]": 26,
      "test[['dropoff_latitude', 'dropoff_longitude']]": 26,
      "train[['pickup_latitude', 'pickup_longitude']]": 24,
      "train[['dropoff_latitude', 'dropoff_longitude']]": 24,
      "vz": 8,
      "vz_sample": 6,
      "df[['pickup_latitude', 'pickup_longitude']]": 5,
      "df[['dropoff_latitude', 'dropoff_longitude']]": 5,
      "text": 4,
      "data": 3,
      "df[['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude']]": 3,
      "X_w2v": 3,
      "ds[['pickup_latitude', 'pickup_longitude']]": 2,
      "ds[['dropoff_latitude', 'dropoff_longitude']]": 2,
      "prop[['latitude', 'longitude']]": 2,
      "X_valid": 1,
      "X_test": 1,
      "train.drop(['id', 'target'], axis=1).iloc[len(train) * 8 // 10:]": 1,
      "test.drop(['id'], axis=1)": 1,
      "X[sample_ind]": 1,
      "df_all[['pickup_latitude', 'pickup_longitude']]": 1,
      "df_all[['dropoff_latitude', 'dropoff_longitude']]": 1,
      "train_x": 1,
      "test_x": 1,
      "X_svd": 1,
      "train[['pickup_longitude', 'pickup_latitude']]": 1,
      "train[['dropoff_longitude', 'dropoff_latitude']]": 1,
      "test[['pickup_longitude', 'pickup_latitude']]": 1,
      "test[['dropoff_longitude', 'dropoff_latitude']]": 1,
      "combine_df[['pickup_latitude', 'pickup_longitude']]": 1,
      "combine_df[['dropoff_latitude', 'dropoff_longitude']]": 1,
      "combine_df[['center_latitude', 'center_longitude']]": 1,
      "npq": 1,
      "[d]": 1,
      "pickup_clusters[sample_slice]": 1,
      "tf_idf": 1,
      "Data[['pickup_latitude', 'pickup_longitude']]": 1,
      "Data[['dropoff_latitude', 'dropoff_longitude']]": 1,
      "train_new_df[['pickup_latitude', 'pickup_longitude']]": 1,
      "train_new_df[['dropoff_latitude', 'dropoff_longitude']]": 1,
      "X": 1,
      "df[['pickup_longitude', 'pickup_latitude']]": 1,
      "df[['dropoff_longitude', 'dropoff_latitude']]": 1,
      "tsne_representation[:n_tr]": 1,
      "newsdf[sem_labels].values": 1,
      "cities1k[['X', 'Y']]": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.solver": {
      "'adam'": 306,
      "'lbfgs'": 105,
      "'sgd'": 11,
      "solver": 4,
      "params['solver']": 1,
      "str(space_eval(space, best)['solver'])": 1
    },
    "sklearn.cluster._dbscan.DBSCAN.fit.X": {
      "X": 12,
      "all_points": 7,
      "dfs": 4,
      "train_pca": 4,
      "np.radians(coords)": 2,
      "embedding": 2,
      "features_scaled": 2,
      "data": 2,
      "coords": 1,
      "tsne_scaled": 1,
      "filtered_data": 1,
      "Xpca": 1,
      "encoded_images": 1,
      "cell_reduced": 1,
      "gene_reduced": 1,
      "combined_reduced": 1,
      "train.drop(['id', 'target'], axis=1).iloc[:len(train) * 8 // 10]": 1,
      "train.drop(['id', 'target'], axis=1)": 1,
      "subg[['x', 'y']]": 1,
      "use_image_embeddings[:, :n_dims]": 1,
      "X_test": 1,
      "scaled_data": 1,
      "embeddings": 1,
      "multi_choice[Activity_column_value]": 1,
      "normalize(nn[ft])": 1,
      "slow_trip[['pickup_longitude', 'pickup_latitude']]": 1,
      "slow_trip[['dropoff_longitude', 'dropoff_latitude']]": 1,
      "fast_trip[['pickup_longitude', 'pickup_latitude']]": 1,
      "fast_trip[['dropoff_longitude', 'dropoff_latitude']]": 1,
      "X4": 1,
      "x": 1,
      "np.radians(df_nyc_taxi.loc[:, 'pickup_longitude':'pickup_latitude'])": 1,
      "np.radians(df_nyc_taxi.loc[:, 'dropoff_longitude':'dropoff_latitude'])": 1,
      "label_embedding": 1,
      "temp": 1,
      "np.radians(coords.as_matrix())": 1,
      "coordinates": 1
    },
    "sklearn.cluster._dbscan.DBSCAN.__init__.eps": {
      "eps": 19,
      "0.5": 8,
      "0.3": 6,
      "0.6": 5,
      "self.eps": 5,
      "3": 5,
      "epsilon": 4,
      "1400": 4,
      "1": 3,
      "6": 3,
      "0.2": 2,
      "0.00715": 2,
      "0.75": 2,
      "0.095": 2,
      "4": 2,
      "0.0012": 2,
      "0.001": 2,
      "1.2": 2,
      "EPS_IN_RADIAN": 2,
      "0.15": 1,
      "20": 1,
      "13": 1,
      "0.7": 1,
      "eps_new": 1,
      "8.910612167916213e-05": 1,
      "1.5": 1,
      "ep": 1,
      "2": 1,
      "7": 1,
      "0.0035 + ii * stepeps": 1,
      "p[0]": 1,
      "12.5": 1,
      "0.085": 1,
      "1.25": 1,
      "0.8": 1,
      "0.0076": 1,
      "eps_": 1,
      "0.08": 1,
      "0.4 / KMS_PER_RADIAN": 1,
      "0.01": 1,
      "1.5 * resized_image_row_size * resized_image_column_size": 1,
      "60": 1
    },
    "sklearn.cluster._dbscan.DBSCAN.__init__.min_samples": {
      "5": 27,
      "1": 17,
      "min_samples": 9,
      "2": 7,
      "20": 7,
      "min_samp": 7,
      "10": 6,
      "15": 3,
      "4": 3,
      "30": 2,
      "MIN_SAMPLES_CLUSTER": 2,
      "800": 1,
      "min_events": 1,
      "200": 1,
      "min_cars": 1,
      "p[1]": 1,
      "25": 1,
      "7": 1,
      "19": 1,
      "min_samples_": 1,
      "80": 1,
      "3": 1,
      "0.0008 * coords.shape[0]": 1,
      "100": 1
    },
    "sklearn.neighbors._unsupervised.NearestNeighbors.__init__.n_neighbors": {
      "5": 36,
      "2": 8,
      "KNN": 7,
      "6": 6,
      "1": 6,
      "neigh": 5,
      "3": 5,
      "50": 4,
      "k": 4,
      "ng": 3,
      "20": 2,
      "knn": 2,
      "len(img_lst)": 2,
      "KNN_LIMIT": 2,
      "nb_ppv": 2,
      "120": 1,
      "51": 1,
      "min(50, df.shape[0])": 1,
      "100": 1,
      "min(len(coord), k)": 1,
      "n": 1,
      "anchor_encoding.shape[0]": 1,
      "len(self.ID_lst)": 1,
      "n_neighbors": 1,
      "num_neighbors": 1,
      "min(49, len(posting_ids) - 1)": 1,
      "1500": 1,
      "synonyms_number + 1": 1,
      "opt + ext": 1,
      "self.k": 1,
      "10": 1
    },
    "sklearn.neighbors._unsupervised.NearestNeighbors.fit.X": {
      "regions[['Lat', 'Long']]": 12,
      "X": 10,
      "X_train": 5,
      "image_embeddings": 5,
      "train_preds": 4,
      "train": 4,
      "text_embeddings": 4,
      "regions[['lat', 'lon']]": 4,
      "norm_data": 3,
      "embeddings": 3,
      "yrm[['x', 'y']]": 2,
      "item_vectors": 2,
      "train_emd": 2,
      "cities.loc[cities.mclust == m, ['X', 'Y']].values": 2,
      "M": 2,
      "coords": 1,
      "x_train_se": 1,
      "x_train_es": 1,
      "encoded_images": 1,
      "df": 1,
      "rx[['x', 'y']]": 1,
      "vecs": 1,
      "np.stack(df[df.len == l]['border'].values)": 1,
      "osrm_journeys": 1,
      "embedding": 1,
      "x[mask, :]": 1,
      "x": 1,
      "person_df.iloc[:, 1:2049]": 1,
      "unhappy[features]": 1,
      "unhappy[features].values": 1,
      "sen_emb": 1,
      "prof_emb": 1,
      "imgEmbs_np": 1,
      "santa_cities_to_analyze": 1,
      "vec_x_cat_train": 1,
      "coord": 1,
      "train_embeddings": 1,
      "lon_lat_array": 1,
      "sample_train[['x', 'y']]": 1,
      "embeds": 1,
      "xtrain": 1,
      "playerOffenseXY.drop(['Position'], axis=1)": 1,
      "playerDefenseXY.drop(['Position'], axis=1)": 1,
      "playersTackleXY": 1,
      "image_embedding": 1,
      "X_mat": 1,
      "emb_vectors": 1,
      "scaler.fit_transform(temp[clmns].values)": 1,
      "encoding": 1,
      "anchor_encoding": 1,
      "self.centroid_array": 1,
      "train_encoding": 1,
      "train_encoding_lst": 1,
      "train.loc[train.transactiondate < d, ['longitude', 'latitude']]": 1,
      "em": 1,
      "X[y == 0, :]": 1,
      "X[y == 1, :]": 1,
      "use": 1,
      "feature_list_compressed": 1,
      "feature_list": 1,
      "embed_mat": 1,
      "data[:, :2]": 1,
      "self.samples": 1,
      "known": 1,
      "data": 1
    },
    "sklearn.preprocessing._data.StandardScaler.__init__.with_mean": {
      "True": 6108,
      "False": 39,
      "0": 3,
      "0.0": 2
    },
    "sklearn.utils.validation.check_array.array": {
      "X": 44,
      "y": 12,
      "x": 1,
      "np.where(train_pivot == np.inf, 0, train_pivot)": 1,
      "np.where(test_pivot == np.inf, 0, test_pivot)": 1
    },
    "sklearn.linear_model._least_angle.LassoLarsCV.__init__.normalize": {
      "True": 43,
      "False": 1
    },
    "sklearn.ensemble._bagging.BaggingClassifier.__init__.n_estimators": {
      "10": 88,
      "100": 33,
      "5": 9,
      "num_trees": 8,
      "1000": 7,
      "200": 4,
      "40": 4,
      "50": 3,
      "300": 3,
      "n_est": 3,
      "ne": 2,
      "2": 2,
      "n_estimators": 2,
      "5000": 1,
      "2500": 1,
      "400": 1,
      "700": 1,
      "3": 1,
      "n_first_bag_est": 1,
      "n_second_bag_est": 1,
      "params": 1,
      "24": 1,
      "max(int(observation.step / 50), 1)": 1,
      "20": 1,
      "27": 1,
      "153": 1,
      "270": 1,
      "25": 1,
      "trial.suggest_int('n_estimators', 10, 1000)": 1,
      "6": 1,
      "2000": 1
    },
    "sklearn.neighbors._regression.KNeighborsRegressor.__init__.leaf_size": {
      "30": 339,
      "13": 6,
      "25": 3,
      "leaf": 2,
      "100": 2,
      "76": 1,
      "15": 1,
      "17": 1,
      "300": 1
    },
    "sklearn.neighbors._regression.KNeighborsRegressor.__init__.p": {
      "2": 347,
      "1": 6,
      "p": 2,
      "5": 1
    },
    "sklearn.neighbors._regression.KNeighborsRegressor.__init__.metric": {
      "'minkowski'": 347,
      "'manhattan'": 4,
      "'braycurtis'": 2,
      "'l1'": 1,
      "m": 1,
      "mydist": 1
    },
    "sklearn.linear_model._ransac.RANSACRegressor.__init__.base_estimator": {
      "None": 19,
      "LinearRegression()": 6,
      "lr": 2,
      "LinearRegression(fit_intercept=False)": 1
    },
    "sklearn.linear_model._theil_sen.TheilSenRegressor.__init__.fit_intercept": {
      "True": 25,
      "False": 1
    },
    "sklearn.linear_model._huber.HuberRegressor.__init__.fit_intercept": {
      "True": 39,
      "False": 1
    },
    "sklearn.linear_model._bayes.BayesianRidge.__init__.fit_intercept": {
      "True": 191,
      "False": 3
    },
    "sklearn.linear_model._least_angle.LassoLars.__init__.fit_intercept": {
      "True": 11,
      "False": 1
    },
    "sklearn.linear_model._least_angle.LassoLars.__init__.alpha": {
      "1.0": 10,
      "25": 1,
      "model_llcv.alpha_": 1
    },
    "sklearn.linear_model._bayes.ARDRegression.__init__.fit_intercept": {
      "True": 11,
      "False": 1
    },
    "sklearn.ensemble._bagging.BaggingRegressor.__init__.base_estimator": {
      "None": 66,
      "rf": 24,
      "DecisionTreeRegressor()": 14,
      "lr": 3,
      "SVR()": 2,
      "LinearRegression()": 2,
      "DecisionTreeRegressor(random_state=3508)": 2,
      "Model": 2,
      "tree.DecisionTreeRegressor(random_state=1)": 2,
      "GradientBoostingRegressor(learning_rate=2.2227e-13)": 1,
      "GaussianProcessRegressor(n_restarts_optimizer=6)": 1,
      "SVR(kernel='linear', C=0.001)": 1,
      "kn1": 1,
      "tree.DecisionTreeRegressor()": 1,
      "xgb.XGBRegressor(colsample_bytree=0.4, learning_rate=0.03, max_depth=6, min_child_weight=1.5, n_estimators=390, reg_alpha=0.75, reg_lambda=0.45, subsample=0.6, seed=42, tree_method='gpu_hist', gpu_id=0)": 1,
      "DecisionTreeRegressor(max_depth=i, random_state=3508)": 1,
      "model_rf": 1,
      "LGBMRegressor(n_estimators=100, num_leaves=16, learning_rate=0.1, max_depth=5, colsample_bytree=0.5, min_split_gain=0.02, min_child_samples=100, min_child_weight=0.02, reg_lambda=0.01, random_state=SEED + 743, objective='rmse')": 1,
      "BayesianRidge(normalize=False, fit_intercept=True)": 1,
      "clf": 1,
      "lgr": 1,
      "SVR(C=0.5)": 1,
      "Ridge(alpha=parameter[0])": 1,
      "Ridge()": 1,
      "Ridge(alpha=optpars['sbm+funcdeweighted_win_ridgebag'][target])": 1,
      "Ridge(alpha=optpars['sbm+sbm_win_ridge_alphabag'][target])": 1,
      "Ridge(alpha=optpars['fnc_extended_ridgebag'][target])": 1,
      "SVR(kernel=args['kernel'], C=1.0, epsilon=0.2)": 1,
      "DecisionTreeRegressor(max_depth=args['max_depth'], min_samples_leaf=args['min_samples_leaf'])": 1,
      "MLPRegressor(args)": 1,
      "dt_stump": 1,
      "DecisionTreeRegressor(max_depth=6, max_features=0.85)": 1,
      "DecisionTreeRegressor(max_depth=5, max_features=0.85)": 1,
      "Model3": 1
    },
    "sklearn.ensemble._bagging.BaggingRegressor.__init__.warm_start": {
      "False": 140,
      "True": 2
    },
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.__init__.n_restarts_optimizer": {
      "0": 9,
      "6": 1,
      "10": 1
    },
    "sklearn.preprocessing._data.robust_scale.axis": {
      "0": 2
    },
    "sklearn.preprocessing._data.robust_scale.quantile_range": {
      "(0, 100)": 2
    },
    "sklearn.preprocessing._data.robust_scale.X": {
      "df_nona": 2
    },
    "sklearn.ensemble._bagging.BaggingRegressor.predict.X": {
      "X_test": 36,
      "X_train": 7,
      "x_test": 3,
      "test": 3,
      "((validset - args['mean']) / args['std']).numpy()": 3,
      "((testset - args['mean']) / args['std']).numpy()": 3,
      "test_x": 2,
      "test_df": 2,
      "x_predfinal": 2,
      "tX_test0": 1,
      "pipe.transform(X)": 1,
      "X": 1,
      "xin": 1,
      "x_train": 1,
      "testing": 1,
      "scale(X_test)": 1,
      "test.loc[seuil_1:seuil_2]": 1,
      "x_va": 1,
      "x_te": 1,
      "df[-test_rows:][numeric_columns]": 1,
      "test_features": 1,
      "test_data1": 1,
      "X_val": 1
    },
    "sklearn.linear_model._logistic.LogisticRegression.__init__.warm_start": {
      "False": 5120,
      "True": 8,
      "set_warm_start": 1
    },
    "sklearn.preprocessing._encoders.OneHotEncoder.inverse_transform.X": {
      "y_pred": 6,
      "y_true": 1,
      "pred >= 0.5": 1,
      "predict": 1,
      "predict1": 1,
      "predict2": 1,
      "predict3": 1,
      "prediccion": 1,
      "our_predictions": 1,
      "y_pred_ohe >= 0.5": 1,
      "model.predict(X_test)": 1
    },
    "sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay.plot.ax": {
      "None": 24,
      "ax": 7,
      "ax[0]": 1
    },
    "sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay.plot.colorbar": {
      "True": 31,
      "None": 1
    },
    "sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay.plot.cmap": {
      "'viridis'": 23,
      "plt.cm.Blues": 4,
      "cmap": 2,
      "'cividis'": 2,
      "'BuGn'": 1
    },
    "sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay.__init__.display_labels": {
      "None": 10,
      "labels": 2,
      "cm_plot_labels": 2,
      "display_labels": 2,
      "model.classes_": 2,
      "categories": 1,
      "[0, 1]": 1,
      "[0, 1, 2]": 1,
      "gbc.classes_": 1,
      "gbc_umap_2.classes_": 1,
      "gbc_add_umap_2.classes_": 1,
      "gbc_umap6_only.classes_": 1,
      "gbc_add_umap_6.classes_": 1,
      "umap_only['gbc_umap' + str(n_components)].classes_": 1,
      "raw_add_umap['gbc_umap' + str(n_components)].classes_": 1,
      "[x for x in range(10)]": 1,
      "['not disaster', 'disaster']": 1,
      "list(label_dict.keys())": 1,
      "[i for i in range(9)]": 1
    },
    "sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay.__init__.confusion_matrix": {
      "cm": 21,
      "confusion_matrix(y_true, y_pred)": 3,
      "np.mean(confusion_matrices, axis=0)": 2,
      "confusion_matrix(y_test, y_pred_gbc_umap6_only)": 1,
      "confusion_matrix(y_test, y_pred_gbc_umap6)": 1,
      "confusion_matrix(y_test, umap_only['y_pred_gbc_umap' + str(n_components)])": 1,
      "confusion_matrix(y_test, raw_add_umap['y_pred_gbc_umap' + str(n_components)])": 1,
      "con_mat": 1,
      "conf_matrix": 1
    },
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.__init__.reg_param": {
      "0.0": 190,
      "0.5": 41,
      "0.111": 20,
      "0.6": 4,
      "0.2": 3,
      "0.4": 2,
      "0.225": 2,
      "0.075": 2,
      "0.04": 1,
      "0.3": 1,
      "reg": 1,
      "0.25": 1,
      "random.uniform(0.01, 0.6)": 1,
      "reg_param": 1,
      "rp_best": 1,
      "0.35": 1,
      "0.8": 1,
      "r": 1,
      "bestreg": 1,
      "0.05": 1
    },
    "sklearn.svm._classes.NuSVC.__init__.probability": {
      "True": 91,
      "False": 17
    },
    "sklearn.svm._classes.NuSVC.__init__.kernel": {
      "'rbf'": 59,
      "'poly'": 48,
      "'linear'": 1
    },
    "sklearn.svm._classes.NuSVC.__init__.degree": {
      "3": 62,
      "4": 44,
      "2": 2
    },
    "sklearn.svm._classes.NuSVC.__init__.gamma": {
      "'scale'": 64,
      "'auto'": 44
    },
    "sklearn.svm._classes.NuSVC.__init__.random_state": {
      "None": 57,
      "4": 29,
      "42": 9,
      "0": 4,
      "256": 3,
      "seed": 2,
      "123": 1,
      "48": 1,
      "SEED": 1,
      "1": 1
    },
    "sklearn.svm._classes.NuSVC.__init__.nu": {
      "0.5": 66,
      "0.59": 20,
      "0.6": 12,
      "0.4": 4,
      "nu": 1,
      "0.1135": 1,
      "0.1": 1,
      "0.7": 1,
      "0.8": 1,
      "0.75": 1
    },
    "sklearn.svm._classes.NuSVC.__init__.coef0": {
      "0.0": 65,
      "0.053": 23,
      "0.08": 13,
      "0.6": 3,
      "0.05": 2,
      "0.09": 1,
      "0.75": 1
    },
    "sklearn.svm._classes.SVC.__init__.degree": {
      "3": 1576,
      "4": 58,
      "2": 23,
      "1": 8,
      "5": 5,
      "6": 1,
      "j": 1,
      "8": 1,
      "9": 1,
      "degree": 1
    },
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.fit.X": {
      "train3[train_index, :]": 64,
      "train3p[train_index, :]": 22,
      "X_train": 18,
      "train4[train_index, :]": 8,
      "comb": 6,
      "train": 4,
      "trainX": 4,
      "slim_x_train": 4,
      "x_train": 4,
      "trn3[trn_index, :]": 4,
      "X_train[tr_idx]": 3,
      "X_aug": 3,
      "train2[train_index]": 3,
      "pca_X_train": 2,
      "ptrain_add_np[train_index, :]": 2,
      "np.vstack((train3, test3))": 2,
      "trainX[er < 0.75]": 2,
      "_train": 1,
      "X.iloc[tr_idx]": 1,
      "X": 1,
      "X_pca": 1,
      "train4_pse[train_index, :]": 1,
      "X_l": 1,
      "slim_train_features[train_index, :]": 1,
      "train2[train_idx, :]": 1,
      "X[train_index]": 1,
      "df_train[predictors]": 1,
      "X_train_sample": 1,
      "train_X[train_index]": 1,
      "train3": 1,
      "train_s[train_idx]": 1
    },
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.fit.y": {
      "train2.loc[train_index]['target']": 72,
      "y_train": 22,
      "train2p.loc[train_index]['target']": 22,
      "train_y": 4,
      "np.concatenate((train_y, test_pred))": 4,
      "trainY": 4,
      "y_train.loc[train_indices]": 4,
      "y": 3,
      "y_train[tr_idx]": 3,
      "Y_aug.ravel()": 3,
      "train2_y.iloc[train_index]": 3,
      "clusters2": 2,
      "Y_train": 2,
      "ptrain_add.loc[train_index]['target']": 2,
      "trn2.loc[trn_index]['target']": 2,
      "np.concatenate((train_label, test_label))": 2,
      "trainY[er < 0.75]": 2,
      "y.iloc[tr_idx]": 1,
      "train2_pse.loc[train_index]['target']": 1,
      "Y_l.ravel()": 1,
      "train_data.iloc[train_index]['target']": 1,
      "trn2.loc[trn_index]['tgt']": 1,
      "trn2_add.loc[trn_index]['tgt']": 1,
      "train1.loc[train_idx]['target']": 1,
      "y[train_index]": 1,
      "y_train_sample": 1,
      "train_y.iloc[train_index]": 1,
      "train2['target']": 1,
      "new_train.loc[train_index]['target']": 1,
      "train_c.loc[train_idx]['target']": 1
    },
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.predict_proba.X": {
      "test3": 89,
      "train3[test_index, :]": 47,
      "train3[test_index3, :]": 21,
      "X_test": 14,
      "train3[oof_test_index, :]": 12,
      "test": 10,
      "test4": 9,
      "train4[test_index, :]": 7,
      "X_val": 6,
      "trn3[tst_index, :]": 6,
      "trainX": 4,
      "tst3": 4,
      "X_train[val_idx]": 3,
      "validX": 3,
      "testX": 3,
      "train2[test_index]": 3,
      "test2": 3,
      "ptrain_add_np[test_index3, :]": 2,
      "ptest_np": 2,
      "train3": 2,
      "x_val": 2,
      "test_df.iloc[:, 1:]": 1,
      "_val": 1,
      "_test": 1,
      "X.iloc[te_idx]": 1,
      "T": 1,
      "train4[test_index2, :]": 1,
      "train3[val_index, :]": 1,
      "slim_train_features[test_index, :]": 1,
      "slim_test_features": 1,
      "x_test": 1,
      "test_features_slim[idx_test[0]]": 1,
      "X_train": 1,
      "train2[val_idx, :]": 1,
      "X[train_index]": 1,
      "X[test_index]": 1,
      "X": 1,
      "X_val_sample": 1,
      "train_X[test_index]": 1,
      "train_s[val_idx]": 1,
      "test_s": 1,
      "train3p[test_index3]": 1,
      "train3p[test_index4]": 1
    },
    "sklearn.metrics._scorer.make_scorer.needs_threshold": {
      "False": 794,
      "True": 6
    },
    "sklearn.preprocessing._data.RobustScaler.__init__.quantile_range": {
      "(25.0, 75.0)": 499,
      "(10.0, 90.0)": 22,
      "(5.0, 95.0)": 3,
      "(35, 65)": 3,
      "(5, 95)": 2,
      "(25, 75)": 2,
      "(20.0, 85.0)": 1,
      "quantile_range": 1,
      "[5, 95]": 1
    },
    "sklearn.preprocessing._data.QuantileTransformer.transform.X": {
      "raw_vec": 137,
      "test_features[col].values.reshape(vec_len_test, 1)": 99,
      "test[col].values.reshape(vec_len_test, 1)": 19,
      "test": 10,
      "test_features[GENES + CELLS]": 9,
      "train[GENES + CELLS]": 7,
      "test[GENES + CELLS]": 7,
      "test_df[cols_numeric]": 7,
      "X_test": 5,
      "df[self.label_cols]": 3,
      "df[self.numeric_cols + self.time_cols]": 3,
      "x_test": 3,
      "df[col].values.reshape(-1, 1)": 3,
      "train_features[GENES + CELLS]": 3,
      "test_features[g_c_features]": 2,
      "x_train": 2,
      "Y": 2,
      "X_final[:, 2:]": 2,
      "self.test_df[numerical_features]": 2,
      "test_vec": 2,
      "to[self.cont_names]": 2,
      "X_train.drop(cols, axis=1)": 2,
      "X_test.drop(cols, axis=1)": 2,
      "X_train": 2,
      "X": 2,
      "data[col].to_numpy().reshape(-1, 1)": 2,
      "Xtest[[col]]": 1,
      "test_feature[col].values.reshape(vec_len_test, 1)": 1,
      "test_X_df": 1,
      "raw_vec_train": 1,
      "raw_vec_test": 1,
      "X.drop(cols, axis=1)": 1,
      "test_x.drop(cols, axis=1)": 1,
      "train_df[cont_features]": 1,
      "test_df[cont_features]": 1,
      "train_features[G_COLS + C_COLS].values": 1,
      "test_features[G_COLS + C_COLS].values": 1,
      "n": 1,
      "train_features[col].values.reshape(-1, 1)": 1,
      "test_features[col].values.reshape(-1, 1)": 1,
      "_X_train[cols]": 1,
      "_X_test[cols]": 1,
      "X_val": 1,
      "principal_Df_test": 1,
      "df_test_features_scaled": 1,
      "raw_vec_elapsed_time": 1,
      "raw_vec_lag_time": 1,
      "test_data.loc[:, cont_features]": 1,
      "x_train[c].reshape(-1, 1)": 1,
      "x_test[c].reshape(-1, 1)": 1,
      "raw_vec[:-2, :]": 1,
      "X_val[:, coli:coli + 1]": 1,
      "X_test[:, coli:coli + 1]": 1,
      "test_dataset_X[:, coli:coli + 1]": 1,
      "df_cp[gene_cols + cell_cols]": 1,
      "te_df[gene_cols + cell_cols]": 1,
      "Xt": 1,
      "test_rg[col].values.reshape(vec_len_test, 1)": 1,
      "df[num_cols]": 1,
      "test_features.drop('cp_type', axis=1)": 1,
      "non_moa": 1,
      "test_features.drop('cp_type', axis=1).iloc[:, 2:]": 1,
      "test_features_df[col].values.reshape(vec_len_test, 1)": 1,
      "test_features[g_cols + c_cols]": 1,
      "test_model_sc": 1,
      "testData": 1,
      "X[genes + cells]": 1,
      "X_test[genes + cells]": 1,
      "x_test[cont_cols]": 1,
      "df2[cols]": 1,
      "df2[BOTH]": 1,
      "train[[c]]": 1,
      "test[[c]]": 1,
      "test_features0[col].values.reshape(vec_len_test, 1)": 1,
      "X[:, col].reshape(X.shape[0], 1)": 1,
      "vec.reshape(-1, 1)": 1,
      "VT.transform(test)": 1,
      "test_features[g_columns + c_columns].values": 1
    },
    "sklearn.feature_extraction.text.CountVectorizer.__init__.lowercase": {
      "True": 2831,
      "False": 101,
      "1": 3,
      "0": 1,
      "lowercase": 1
    },
    "sklearn.preprocessing._encoders.OrdinalEncoder.__init__.categories": {
      "'auto'": 298,
      "{0: orders[i]}": 3,
      "[[1, 2, 3]]": 3,
      "[np.array(['Novice', 'Contributor', 'Expert', 'Master', 'Grandmaster'])]": 2,
      "[np.array(['Freezing', 'Cold', 'Warm', 'Hot', 'Boiling Hot', 'Lava Hot'])]": 2,
      "[['Novice', 'Contributor', 'Expert', 'Master', 'Grandmaster'], ['Freezing', 'Cold', 'Warm', 'Hot', 'Boiling Hot', 'Lava Hot']]": 2,
      "categories": 2,
      "[Utilities, ExterQual, ExterCond, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2, HeatingQC, KitchenQual, Functional, FireplaceQu, GarageFinish, GarageQual, GarageCond, PoolQC, Fence]": 2,
      "[ordinal_encode_order_lists[i]]": 1,
      "[cat]": 1,
      "labels": 1,
      "[orderd_labels]": 1,
      "[categories]": 1,
      "[['Class_1', 'Class_2', 'Class_3', 'Class_4']]": 1,
      "[['Novice', 'Contributor', 'Expert', 'Master', 'Grandmaster'], ['Freezing', 'Cold', 'Warm', 'Hot', 'Boiling Hot', 'Lava Hot'], np.sort(train_df['ord_3'].unique()), np.sort(train_df['ord_4'].unique()), np.sort(train_df['ord_5'].unique())]": 1,
      "[list(set(list(['NA']) + list(df_kaggle_train[c].unique()) + list(df_kaggle_test[c].unique())))]": 1,
      "cat": 1,
      "[months]": 1,
      "[days]": 1,
      "list_categories": 1
    },
    "sklearn.pipeline.FeatureUnion.fit_transform.X": {
      "preprocess(train)": 8,
      "train": 6,
      "merge": 6,
      "train_X_df": 5,
      "df": 4,
      "X_train": 4,
      "train_df": 3,
      "full_df": 2,
      "x_train": 2,
      "test": 2,
      "train.Phrase": 2,
      "arr.values": 2,
      "X": 2,
      "df_test": 2,
      "df.values": 2,
      "data.values": 2,
      "corpustr": 2,
      "X_test": 2,
      "full": 1,
      "df_train": 1,
      "data['train_data']": 1,
      "data['test_data']": 1,
      "prep_train": 1,
      "prep_test": 1,
      "outliers_clipped": 1,
      "outliers_clipped_val": 1,
      "train.ingredients.str.join(' ')": 1,
      "train.cleaned": 1,
      "combined": 1,
      "train_set": 1,
      "train_data": 1,
      "all_data_merge_1": 1,
      "train_X": 1,
      "y_train": 1,
      "test_features": 1,
      "X_train[num_attributes]": 1,
      "df.to_dict('records')": 1,
      "X_only.values": 1,
      "train_df.values": 1,
      "train_df[features]": 1,
      "reduced_X_train.values": 1,
      "df.ingredients.str.join(' ')": 1,
      "X_valid": 1,
      "train.values": 1,
      "train_processed": 1
    },
    "sklearn.tree._export.export_graphviz.filled": {
      "True": 132,
      "False": 69,
      "filled": 1
    },
    "sklearn.tree._export.export_graphviz.special_characters": {
      "False": 150,
      "True": 52
    },
    "sklearn.tree._export.export_graphviz.rotate": {
      "False": 180,
      "True": 22
    },
    "sklearn.tree._export.export_graphviz.precision": {
      "3": 165,
      "precision": 19,
      "2": 12,
      "1": 4,
      "4": 1,
      "5": 1
    },
    "sklearn.ensemble._voting.VotingRegressor.__init__.estimators": {
      "estimators": 7,
      "[('lin', linreg), ('ridge', ridge), ('sgd', sgd)]": 3,
      "regressors": 2,
      "[('RandomForest', RandomForestRegressor(n_estimators=100, random_state=0)), ('XGBoost', XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=0, objective='reg:gamma')), ('LGBM', LGBMRegressor(n_estimators=500, learning_rate=0.01, random_state=0, objective='gamma')), ('CatBoost', CatBoostRegressor(n_estimators=100, learning_rate=0.1, random_state=0, verbose=0, objective='Tweedie:variance_power=1.5'))]": 2,
      "[('XGBoostR', XGBR_grid.best_estimator_), ('AdaBoostR', AdaBoostR_grid.best_estimator_)]": 2,
      "gb_ensemble": 2,
      "[('lr', m1), ('dt', m2), ('rf', m3)]": 2,
      "named_estimators": 2,
      "[('GBRegressor', GradientBoostingRegressor()), ('XGBR', XGBRegressor())]": 2,
      "[('Ridge', ridge_mod), ('Lasso', lasso_mod), ('XGBRegressor', xgb_regress), ('Random_forest', random_forest)]": 1,
      "[('lr', LinearRegression(n_jobs=-1)), ('knn', KNeighborsRegressor(n_jobs=-1)), ('gb', GradientBoostingRegressor(random_state=0)), ('lgbm', LGBMRegressor(random_state=0)), ('xgb', XGBRegressor(nthread=-1, seed=0))]": 1,
      "[('svr', SVR_best), ('abr', ABR_best), ('gbr', GBR_best), ('rfr', RFR_best), ('knr', KNR_best)]": 1,
      "[('rf', RandomForestRegressor(n_estimators=50, random_state=1)), ('XGB', XGBRegressor(learning_rate=0.7, max_depth=6, objective='count:poisson'))]": 1,
      "[('rf', RandomForestRegressor(n_estimators=50, random_state=1)), ('XGB', XGBRegressor(learning_rate=0.5, max_depth=6, objective='count:poisson'))]": 1,
      "[('rf', RandomForestRegressor(n_estimators=1000, random_state=1)), ('XGB', XGBRegressor(learning_rate=0.7, max_depth=6, objective='count:poisson'))]": 1,
      "[('rf', RandomForestRegressor(n_estimators=1000, random_state=1)), ('XGB', XGBRegressor(learning_rate=0.5, max_depth=6, objective='count:poisson'))]": 1,
      "[('RF', model1), ('GB', model2), ('BR', model3)]": 1,
      "[('lgbm', LGBMRegressor(random_state=RANDOM_STATE)), ('xgb', XGBRegressor(random_state=RANDOM_STATE))]": 1,
      "[('lr', m1), ('rf', m2), ('dt', m3)]": 1,
      "[('adaDTC', adaDTC), ('cb_model', cb_model)]": 1,
      "[('lgb', model1), ('cbt', model3), ('etr', model6), ('hgb', model8)]": 1,
      "[('lr', r1), ('rf', r2), ('xg', r3), ('gb', r4)]": 1,
      "[('XGBoost', xgb_model), ('LGBoost', lgbm_model)]": 1,
      "[('lr', clf1), ('bm', clf2), ('nn', clf3)]": 1,
      "[('XGBoostR', XGBR_grid.best_estimator_), ('AdaBoostR', AdaBoostR_grid.best_estimator_), ('Ridge', ridge_grid.best_estimator_)]": 1,
      "[('XGBoostR', XGBR_grid.best_estimator_), ('Ridge', ridge_grid.best_estimator_)]": 1,
      "[('AdaBoostR', AdaBoostR_grid.best_estimator_), ('Ridge', ridge_grid.best_estimator_)]": 1,
      "voting_estimators": 1,
      "[('lr', mlp), ('rf', rf), ('dt', clf), ('XGB', xg)]": 1,
      "regressor": 1,
      "[('Linear Regression', LR), ('Ridge Regression', rid), ('Lasso Regression', lasso), ('Random Forest Reressor', RFR)]": 1,
      "[('xgb', xgb), ('lgbm', lgbm)]": 1,
      "[('XGBoost', model_xgb), ('LGBM', model_lgbm), ('GradientBoosting', model_gb)]": 1,
      "[('GBRegressor', GradientBoostingRegressor()), ('XGBR', XGBRegressor()), ('RFR', RandomForestRegressor(random_state=seed))]": 1,
      "[('GBRegressor', GradientBoostingRegressor()), ('RFR', RandomForestRegressor(random_state=seed))]": 1,
      "[('XGBR', XGBRegressor()), ('RFR', RandomForestRegressor(random_state=seed))]": 1,
      "[('lr', r1), ('lasso', r2), ('ridge', r3), ('en', r4), ('dtr', r5), ('xgbr', r6), ('gbr', r7), ('abr', r8), ('rfr', r9)]": 1,
      "[('Ridge', ridge_mod), ('Lasso', lasso_mod), ('Elastic', elastic_cv), ('XGBRegressor', xgb)]": 1,
      "base_models": 1,
      "[('lg', model2), ('CAT', model1), ('RF', RF)]": 1,
      "[('rdg', rdg), ('rf', rf), ('grb', gr_boosting), ('xgb', xgb_r), ('lgb', lgb)]": 1,
      "[('Ridge', ridge_mod), ('Lasso', lasso_mod), ('Random_forest', random_forest)]": 1,
      "[('xgb', xgbbest), ('lgb', lgbbest), ('cat', cb_model)]": 1
    },
    "sklearn.ensemble._voting.VotingRegressor.__init__.n_jobs": {
      "None": 50,
      "-1": 7,
      "4": 1
    },
    "sklearn.ensemble._voting.VotingRegressor.fit.X": {
      "X_train": 19,
      "x_train": 9,
      "train": 5,
      "X": 2,
      "X_train_transformed": 2,
      "(X_train, Y_train)": 1,
      "X_train_red": 1
    },
    "sklearn.ensemble._voting.VotingRegressor.fit.y": {
      "y_train": 25,
      "target": 4,
      "y_train.ravel()": 3,
      "Y_train": 2,
      "y": 2,
      "(X_valid, Y_valid)": 1,
      "y_train[col]": 1,
      "target.iloc[:, i]": 1
    },
    "sklearn.ensemble._stacking.StackingRegressor.__init__.estimators": {
      "estimators": 35,
      "base_models": 5,
      "[('LassoRegression', LassoRegression), ('ElasticNet', ElasticNet(alpha=EnetRegressor.best_params_['alpha'], l1_ratio=EnetRegressor.best_params_['l1_ratio'])), ('RandomForest', RandomForestRegressor(max_depth=rf_cv.best_params_['max_depth'], max_features=rf_cv.best_params_['max_features'], n_estimators=1000)), ('XGBoost', XGBRegressor(**xgb_params))]": 4,
      "level0": 4,
      "model_list1": 2,
      "base_model": 1,
      "base_learners": 1,
      "[('ridge', ridge), ('lasso', lasso), ('elasticnet', elasticnet), ('randomforest', rf), ('gradientboostingregressor', gbr), ('xgb', xgbr), ('lgb', lgbr)]": 1,
      "[('xgboost', xgb), ('ridge', ridge), ('lasso', lasso)]": 1,
      "[('RandomForest', RandomForestRegressor(n_estimators=100, random_state=0)), ('XGBoost', XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=0, objective='reg:gamma')), ('LGBM', LGBMRegressor(n_estimators=500, learning_rate=0.01, random_state=0, objective='gamma')), ('CatBoost', CatBoostRegressor(n_estimators=100, learning_rate=0.1, random_state=0, verbose=0, objective='Tweedie:variance_power=1.5'))]": 1,
      "[('best_xgb', XGBRegressor(**best_xgb_param)), ('best_lgbm', LGBMRegressor(**best_lgbm_param))]": 1,
      "[('best_xgb', best_xgb), ('best_lgbm', best_lgbm)]": 1,
      "estimatorList": 1,
      "stacked_estimators": 1,
      "[('ridge', Ridge(alpha=0.8, solver='sag', max_iter=2000)), ('xgb', XGBRegressor()), ('lgbm', LGBMRegressor()), ('catboost', CatBoostRegressor())]": 1,
      "[('elasticnet', model_est), ('knn', model_knn)]": 1,
      "[('xgb', model), ('lgb', model_lgb)]": 1,
      "[('ridge', model_ridge), ('lasso', model_lasso), ('svr', model_svr), ('rf', model_rf), ('xgb', model_xgb)]": 1,
      "[('rdg', rdg), ('rf', rf), ('grb', gr_boosting), ('xgb', xgb_r), ('lgb', lgb)]": 1,
      "[('xgb', model_xgb), ('cat', model_cat), ('rgb', model_gbr), ('lgb', model_lgb)]": 1
    },
    "sklearn.ensemble._stacking.StackingRegressor.__init__.final_estimator": {
      "None": 17,
      "level1": 4,
      "random_forest": 4,
      "learner": 3,
      "lgbm": 3,
      "ExtraTreesRegressor(n_estimators=50)": 3,
      "RandomForestRegressor(random_state=42)": 2,
      "RandomForestRegressor()": 2,
      "Ridge()": 2,
      "GradientBoostingRegressor(n_estimators=200, random_state=42)": 2,
      "final_estimator": 2,
      "LGBMRegressor": 2,
      "LinearRegression()": 2,
      "lightgbm.LGBMRegressor()": 2,
      "RandomForestRegressor(n_estimators=100, random_state=42)": 1,
      "LGBMRegressor(objective='regression')": 1,
      "RandomForestRegressor(n_estimators=100)": 1,
      "rforest": 1,
      "GammaRegressor()": 1,
      "GBoost": 1,
      "i": 1,
      "RidgeCV()": 1,
      "model_xgb": 1,
      "RandomForestRegressor(n_estimators=400, random_state=1)": 1,
      "RandomForestRegressor(n_estimators=500, random_state=1)": 1,
      "RidgeCV(alphas=[500, 1000, 5000, 10000])": 1,
      "DTR(random_state=17, max_depth=4, criterion='mse')": 1,
      "LGBMRegressor(random_state=1)": 1,
      "RandomForestRegressor(n_estimators=10, random_state=49)": 1
    },
    "sklearn.svm._classes.NuSVR.__init__.gamma": {
      "'scale'": 52,
      "'auto'": 2,
      "0.05": 1,
      "0.0475": 1
    },
    "sklearn.svm._classes.NuSVR.__init__.nu": {
      "0.5": 35,
      "0.7": 7,
      "0.9": 6,
      "0.75": 5,
      "1": 1,
      "trial.suggest_float('nu', 0.0, 1.0)": 1,
      "parameter[0]": 1
    },
    "sklearn.svm._classes.NuSVR.__init__.C": {
      "1.0": 37,
      "10.0": 11,
      "30": 1,
      "0.1": 1,
      "1": 1,
      "3.0": 1,
      "trial.suggest_loguniform('C', 0.001, 1000.0)": 1,
      "76": 1,
      "parameter[1]": 1,
      "C": 1
    },
    "sklearn.manifold._mds.MDS.__init__.max_iter": {
      "300": 6,
      "100": 5
    },
    "sklearn.manifold._mds.MDS.__init__.n_init": {
      "1": 5,
      "4": 5,
      "2": 1
    },
    "sklearn.manifold._t_sne.TSNE.__init__.perplexity": {
      "30.0": 337,
      "40": 40,
      "50": 37,
      "perplexity": 27,
      "7": 21,
      "30": 18,
      "100": 14,
      "40.0": 7,
      "tSNE_perplexity": 4,
      "5": 3,
      "80": 3,
      "2": 3,
      "20": 3,
      "60": 2,
      "i": 2,
      "35": 2,
      "25": 2,
      "prplx": 1,
      "250": 1,
      "50.0": 1,
      "60.0": 1,
      "56": 1,
      "8": 1,
      "1": 1,
      "10": 1,
      "65": 1,
      "200": 1,
      "PERPLEXITY": 1
    },
    "sklearn.manifold._spectral_embedding.SpectralEmbedding.__init__.n_components": {
      "2": 5,
      "n_components": 3,
      "150": 1,
      "1": 1
    },
    "sklearn.manifold._spectral_embedding.SpectralEmbedding.__init__.n_neighbors": {
      "None": 4,
      "n_neighbors": 3,
      "nneigh": 1,
      "30": 1,
      "10": 1
    },
    "sklearn.manifold._spectral_embedding.SpectralEmbedding.fit_transform.X": {
      "features.values": 2,
      "X": 2,
      "X_eda": 1,
      "principalDf": 1,
      "hashes": 1
    },
    "sklearn.impute._base.SimpleImputer.fit.X": {
      "train": 20,
      "X": 12,
      "X_train": 8,
      "train[i].to_numpy().reshape(-1, 1)": 7,
      "X_test": 5,
      "data": 3,
      "np.array(server_features)": 3,
      "df_train_tran[[col]]": 3,
      "X[:, 1:2]": 2,
      "train_data[[col]]": 2,
      "data_train[[col]]": 2,
      "x_train": 2,
      "features": 2,
      "y": 2,
      "X_train[num_attr]": 2,
      "X_train[cat_attr]": 2,
      "housing_num": 2,
      "df_train_tran_id[[col]]": 2,
      "df_test_tran_id[[col]]": 2,
      "test_data": 2,
      "X[:, np.r_[2:3]]": 2,
      "X_test[:, np.r_[2:3]]": 2,
      "train_df": 2,
      "df": 2,
      "train_df.loc[:, not_categorical]": 2,
      "[[7, 2, 3], [4, np.nan, 6], [10, 5, 9]]": 1,
      "df_train[i].to_numpy().reshape(-1, 1)": 1,
      "train['FireplaceQu'].to_frame()": 1,
      "train[['LotFrontage', 'GarageYrBlt', 'MasVnrArea']]": 1,
      "df['Age'].values.reshape(-1, 1)": 1,
      "df['Embarked'].values.reshape(-1, 1)": 1,
      "x.iloc[:, 2:3]": 1,
      "x.iloc[:, [6]]": 1,
      "t.iloc[:, [2]]": 1,
      "t.iloc[:, [5]]": 1,
      "X[:, :]": 1,
      "test": 1,
      "test_data[[col]]": 1,
      "X_full[num_features]": 1,
      "X_full[cat_features]": 1,
      "df_train_features": 1,
      "df_train": 1,
      "ArrayTrain": 1,
      "ArrayTest": 1,
      "X_train_full": 1,
      "train_modified": 1,
      "data_test_end": 1,
      "train_data_num": 1,
      "test_data_num": 1,
      "transaction_data[low_missing_num_trans_cols]": 1,
      "identity_data[low_missing_num_id_cols]": 1,
      "transaction_data[medium_missing_num_trans_cols]": 1,
      "identity_data[medium_missing_num_id_cols]": 1,
      "df_dataset_plays": 1,
      "df_dataset1_week1": 1,
      "X_train_csv": 1,
      "X_test_csv": 1,
      "titanic_numerical": 1,
      "train_features": 1,
      "xtrain": 1,
      "all_num_data": 1,
      "train_cat": 1,
      "train_num": 1,
      "CSVnum": 1,
      "df_train_tran[[cat_cols[i]]]": 1,
      "df_test_tran[[cat_cols[i]]]": 1,
      "df_test_tran[[col]]": 1,
      "num_data": 1,
      "test_feat": 1,
      "df_flo": 1,
      "d[['Age']]": 1,
      "d[['Embarked']]": 1,
      "d[['Fare']]": 1,
      "x_test": 1,
      "[train['Age']]": 1,
      "x_train[num_var1]": 1,
      "x_train[cat_vars]": 1,
      "XX": 1,
      "data[[col]]": 1,
      "train[['Age']]": 1,
      "play": 1,
      "df_train['Age'].values.reshape(-1, 1)": 1,
      "df_test['Age'].values.reshape(-1, 1)": 1,
      "train_x.loc[:, scale_cols]": 1,
      "X_train_continuous": 1,
      "test_x.loc[:, scale_cols]": 1,
      "X_test_continuous": 1,
      "df_test.iloc[:, :]": 1,
      "train_df[['Age']]": 1,
      "test_df[['Age']]": 1,
      "df[['CPI']]": 1,
      "df[['Unemployment']]": 1,
      "housing_cat": 1,
      "prices_df[numeric_cols]": 1,
      "num": 1,
      "data_num": 1,
      "feature_test": 1,
      "data_set": 1,
      "jane": 1,
      "X_train[:, np.r_[3:5, 6:9, 23:26, 27:93]]": 1,
      "X_train[:, np.r_[3:5, 6:26, 27:93]]": 1,
      "a": 1,
      "X_trn": 1,
      "X_train[features]": 1,
      "X_test[features]": 1
    },
    "sklearn.preprocessing._data.Normalizer.fit.X": {
      "X": 7,
      "X_scaled": 3,
      "x_train": 2,
      "X_train['price'].values.reshape(1, -1)": 2,
      "train": 2,
      "np.vstack((train, test))": 2,
      "x_train['price'].values.reshape(-1, 1)": 1,
      "x_train['teacher_number_of_previously_posted_projects'].values.reshape(-1, 1)": 1,
      "df.drop('item_cnt_day', axis=1)": 1,
      "train_df[num_features]": 1,
      "df_train['Lat'].values.reshape(1, -1)": 1,
      "df_train['Long'].values.reshape(1, -1)": 1,
      "df_train['Date'].values.reshape(1, -1)": 1,
      "df_train['ConfirmedCases'].values.reshape(1, -1)": 1,
      "train_data[['Age']]": 1,
      "X_train": 1,
      "X_train[list(cols_to_normalize)]": 1,
      "X2": 1,
      "X2_test": 1,
      "X2_tt": 1,
      "X_train['total_words'].values.reshape(-1, 1)": 1,
      "X_train['total_chars'].values.reshape(-1, 1)": 1,
      "X_train['total_unique_words'].values.reshape(-1, 1)": 1,
      "X_train['word_score'].values.reshape(-1, 1)": 1,
      "X_train['total_stopwords'].values.reshape(-1, 1)": 1,
      "X_train['total_upper'].values.reshape(-1, 1)": 1,
      "X_train['total_lower'].values.reshape(-1, 1)": 1,
      "X_train['total_word_title'].values.reshape(-1, 1)": 1,
      "X_train['median_word_len'].values.reshape(-1, 1)": 1,
      "X_train_numeric.values.reshape(1, -1)": 1,
      "X_donor_choose_train['resource_cost'].values.reshape(1, -1)": 1,
      "X_donor_choose_train['teacher_number_of_previously_posted_projects'].values.reshape(1, -1)": 1,
      "train[col]": 1,
      "Xtest": 1,
      "data": 1,
      "training_set[training_set.columns[0:5]]": 1
    },
    "sklearn.preprocessing._data.Binarizer.__init__.threshold": {
      "0.0": 80,
      "10000": 1
    },
    "sklearn.preprocessing._data.Binarizer.transform.X": {
      "X_train": 13,
      "X_test": 9,
      "X_test_init": 4,
      "df[col]": 1,
      "X_train1": 1,
      "X_train2": 1,
      "X_test1": 1,
      "X_test2": 1,
      "submission_test": 1,
      "X_tst": 1
    },
    "sklearn.metrics._regression.mean_squared_error.sample_weight": {
      "None": 8420,
      "weights": 34,
      "w": 7,
      "X_val.perishable * 0.25 + 1": 1
    },
    "sklearn.ensemble._bagging.BaggingRegressor.__init__.max_samples": {
      "1.0": 95,
      "0.1": 24,
      "0.8": 5,
      "0.2": 3,
      "args['max_samples']": 3,
      "0.7": 2,
      "10": 2,
      "0.5": 1,
      "0.75": 1,
      "0.9": 1,
      "X_train.shape[0]": 1,
      "0.15": 1,
      "0.25": 1,
      "100": 1,
      "parameter[2]": 1
    },
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.ccp_alpha": {
      "0.0": 733
    },
    "sklearn.ensemble._forest.ExtraTreesClassifier.__init__.max_samples": {
      "None": 732,
      "1000": 1
    },
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform.X": {
      "X_test": 3,
      "X_train": 2,
      "x_test": 2,
      "X1_train": 1,
      "data": 1,
      "test": 1,
      "X_t": 1,
      "bert_clean_embed": 1,
      "bert_test_embed": 1,
      "x_valid": 1,
      "X_test_": 1,
      "total_df": 1,
      "X_val": 1,
      "X_train_sub": 1,
      "X_test_sub": 1,
      "train_data[features]": 1
    },
    "sklearn.tree._classes.DecisionTreeRegressor.__init__.ccp_alpha": {
      "0.0": 895,
      "0.01": 1
    },
    "sklearn.tree._classes.DecisionTreeRegressor.__init__.max_features": {
      "None": 873,
      "'auto'": 6,
      "'sqrt'": 6,
      "8": 4,
      "10": 2,
      "0.85": 2,
      "1": 1,
      "9": 1,
      "25": 1
    },
    "sklearn.tree._classes.DecisionTreeRegressor.__init__.min_impurity_split": {
      "None": 895,
      "1e-07": 1
    },
    "sklearn.tree._classes.DecisionTreeRegressor.__init__.min_weight_fraction_leaf": {
      "0.0": 894,
      "0.001": 2
    },
    "sklearn.tree._classes.DecisionTreeRegressor.__init__.splitter": {
      "'best'": 891,
      "'random'": 5
    },
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.tol": {
      "0.0001": 78,
      "0.01": 5,
      "0.1": 2
    },
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.batch_size": {
      "'auto'": 131,
      "batch_size": 2,
      "100": 2,
      "50": 1,
      "16": 1,
      "256": 1,
      "300": 1,
      "2000": 1,
      "40": 1
    },
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.__init__.n_components": {
      "None": 266,
      "1": 7,
      "2": 4,
      "10": 4,
      "150": 1,
      "40": 1,
      "100": 1,
      "3": 1,
      "5": 1,
      "18": 1
    },
    "sklearn.kernel_ridge.KernelRidge.__init__.alpha": {
      "0.6": 45,
      "1": 23,
      "0.1": 11,
      "1.0": 8,
      "0.7": 2,
      "14.1": 1,
      "0.05": 1,
      "k": 1,
      "80": 1,
      "0.0001": 1,
      "4.5": 1,
      "0.015": 1,
      "0.15": 1
    },
    "sklearn.kernel_ridge.KernelRidge.__init__.kernel": {
      "'polynomial'": 60,
      "'linear'": 18,
      "'rbf'": 17,
      "'laplacian'": 2
    },
    "sklearn.kernel_ridge.KernelRidge.__init__.degree": {
      "2": 50,
      "3": 39,
      "7": 5,
      "d": 1,
      "4": 1,
      "1": 1
    },
    "sklearn.kernel_ridge.KernelRidge.__init__.coef0": {
      "2.5": 52,
      "1": 41,
      "3": 2,
      "2.3": 1,
      "0.5": 1
    },
    "sklearn.feature_selection._rfe.RFECV.__init__.estimator": {
      "estimator": 12,
      "model": 7,
      "clf": 6,
      "rfr": 4,
      "ranker": 3,
      "rfc": 3,
      "lr": 3,
      "LogisticRegression()": 2,
      "svc": 2,
      "lm": 2,
      "grid_search.best_estimator_": 2,
      "logreg": 2,
      "RandomForestRegressor(random_state=42)": 1,
      "lg": 1,
      "ridges": 1,
      "GradientBoostingClassifier()": 1,
      "alg": 1,
      "RandomForestClassifier(random_state=42)": 1,
      "ExtraTreesClassifier(n_estimators=200, criterion='entropy', min_samples_split=3, n_jobs=-1)": 1,
      "regressor": 1,
      "svm_classifier": 1,
      "logistic_classifier": 1,
      "xg_reg": 1,
      "best_estimator": 1,
      "logreg1": 1,
      "lass": 1,
      "lass1": 1,
      "etc": 1,
      "self.estimator": 1,
      "lgb.LGBMClassifier(**params)": 1,
      "Ridge()": 1,
      "linreg": 1,
      "lgbmclf": 1,
      "rfecv": 1,
      "lgb": 1,
      "log_reg": 1,
      "estimater": 1
    },
    "sklearn.feature_selection._rfe.RFECV.__init__.step": {
      "1": 49,
      "15": 6,
      "10": 5,
      "rfe_step": 3,
      "steps": 3,
      "step": 3,
      "2": 2,
      "5": 1,
      "0.1": 1
    },
    "sklearn.feature_selection._rfe.RFECV.__init__.cv": {
      "3": 11,
      "5": 10,
      "10": 8,
      "cv": 6,
      "kf": 4,
      "StratifiedKFold(2)": 4,
      "repfold": 4,
      "20": 3,
      "rfe_cv": 2,
      "KFold(n_splits=5, shuffle=False)": 2,
      "KFold(y.shape[0], n_folds=5, shuffle=False, random_state=1001)": 2,
      "StratifiedKFold(3)": 2,
      "splits - 1": 2,
      "None": 2,
      "2": 1,
      "cv_split": 1,
      "repeated_folds": 1,
      "StratifiedKFold(3, random_state=0)": 1,
      "StratifiedKFold(n_splits=folds, shuffle=False, random_state=42).split(train, train['outliers'].values)": 1,
      "skf": 1,
      "StratifiedKFold(n_splits=folds, shuffle=True, random_state=1001).split(X, y)": 1,
      "StratifiedKFold(n_splits=folds, shuffle=False, random_state=1001).split(X, y)": 1,
      "KFold(y.shape[0], n_folds=5, shuffle=False, random_state=101)": 1,
      "StratifiedKFold(10)": 1,
      "KFold(n_splits=5)": 1
    },
    "sklearn.feature_selection._rfe.RFECV.__init__.scoring": {
      "None": 16,
      "'roc_auc'": 14,
      "'accuracy'": 10,
      "scorer": 9,
      "'r2'": 8,
      "robust_roc_auc": 4,
      "'neg_mean_absolute_error'": 2,
      "'neg_log_loss'": 2,
      "'f1'": 2,
      "neg_rmse": 1,
      "kappa_score": 1,
      "make_scorer(mean_absolute_error)": 1,
      "'log_loss'": 1,
      "'neg_root_mean_squared_error'": 1,
      "standard_roc_auc": 1
    },
    "sklearn.feature_selection._rfe.RFECV.fit.X": {
      "X": 16,
      "X_train": 12,
      "train_set": 8,
      "X_train_sc": 3,
      "x_train": 3,
      "X_std": 2,
      "X_transformed": 2,
      "trn_x": 2,
      "train_X": 2,
      "all_X": 2,
      "X_train_scaled": 1,
      "to_train_df.drop('SalePrice', axis=1)": 1,
      "features": 1,
      "balanced_data": 1,
      "train_df": 1,
      "X_dat": 1,
      "train_x": 1,
      "df_bc": 1,
      "trans_x": 1,
      "data_cv.drop('shot_made_flag', axis=1)": 1,
      "np.array(features)": 1,
      "x_train_train": 1,
      "train": 1,
      "np.array(X_train)": 1,
      "X_train[features]": 1,
      "X_ohe_fs": 1
    },
    "sklearn.feature_selection._rfe.RFECV.fit.y": {
      "y": 20,
      "y_train": 19,
      "train_labels": 8,
      "train_y": 3,
      "target": 2,
      "trn_y": 2,
      "all_y": 2,
      "y_train.values.flatten()": 1,
      "to_train_df['SalePrice']": 1,
      "train['AdoptionSpeed']": 1,
      "known": 1,
      "np.log(y_dat)": 1,
      "targets": 1,
      "Y": 1,
      "data_cv.shot_made_flag": 1,
      "np.array(labels)": 1,
      "y_train_train": 1,
      "np.array(Y_train)": 1,
      "X_train[target]": 1
    },
    "sklearn.preprocessing._data.StandardScaler.__init__.with_std": {
      "True": 6148,
      "False": 4
    },
    "sklearn.svm._classes.SVC.__init__.shrinking": {
      "True": 1673,
      "grid_search_svm.best_params_['shrinking']": 1,
      "False": 1
    },
    "sklearn.ensemble._iforest.IsolationForest.__init__.contamination": {
      "'auto'": 16,
      "outliers_fraction": 5,
      "0.05": 4,
      "0.01": 4,
      "contamination": 3,
      "float(0.005)": 2,
      "0.1": 2,
      "0.003": 1,
      "0.001": 1,
      "0.03": 1,
      "510 / (5877 + 510)": 1,
      "0.005": 1,
      "0.0015": 1,
      "cont": 1,
      "0.02": 1
    },
    "sklearn.model_selection._validation.cross_validate.n_jobs": {
      "None": 214,
      "-1": 70,
      "4": 7,
      "2": 6,
      "5": 1,
      "1": 1
    },
    "sklearn.linear_model._logistic.LogisticRegression.__init__.l1_ratio": {
      "None": 5121,
      "0.5": 4,
      "trial.suggest_float('l1_ratio', 1e-05, 1, log=True)": 1,
      "l1_ratio": 1,
      "0.25": 1,
      "0.3": 1
    },
    "sklearn.svm._classes.LinearSVC.__init__.verbose": {
      "0": 439,
      "True": 10,
      "1": 2,
      "2": 2
    },
    "sklearn.svm._classes.LinearSVC.__init__.fit_intercept": {
      "True": 450,
      "False": 2,
      "trial.suggest_categorical('fit_intercept', [True, False])": 1
    },
    "sklearn.model_selection._validation.learning_curve.return_times": {
      "False": 121,
      "True": 8
    },
    "sklearn.model_selection._validation.learning_curve.estimator": {
      "estimator": 33,
      "model": 17,
      "LR_clf_counts": 11,
      "SVM_clf_counts": 6,
      "NB_clf_counts": 6,
      "LR_clf_tfidf": 6,
      "SVM_clf_tfidf": 6,
      "NB_clf_tfidf": 6,
      "lr": 3,
      "SVC(C=0.01, kernel='rbf')": 2,
      "MLPClassifier(hidden_layer_sizes=(150, 100, 50), max_iter=300)": 2,
      "model.best_estimator_": 2,
      "estimator1": 2,
      "estimator2": 2,
      "learning_model_pipeline": 2,
      "pipe_lr": 2,
      "Ridge(alpha=30, solver='sparse_cg')": 1,
      "rfc": 1,
      "DecisionTreeRegressor(max_depth=3)": 1,
      "classifiers[key]": 1,
      "estimator3": 1,
      "estimator4": 1,
      "LinearRegression(normalize=True)": 1,
      "pipeline": 1,
      "est": 1,
      "RandomForestRegressor(n_jobs=-1, n_estimators=600, min_samples_split=5, min_samples_leaf=1, max_features='sqrt', max_depth=10, bootstrap=True, random_state=42)": 1,
      "regressor": 1,
      "grid_svm.best_estimator_": 1,
      "learning_algo": 1,
      "classifier": 1,
      "ppl": 1,
      "r": 1,
      "pipe_svm": 1,
      "RandomForestRegressor(n_estimators=result.best_params_['n_estimators'], min_samples_split=result.best_params_['min_samples_split'], min_samples_leaf=result.best_params_['min_samples_leaf'], max_depth=result.best_params_['max_depth'])": 1,
      "LGBMRegressor(**params)": 1,
      "rf_classifier_low_depth": 1,
      "rf_classifier": 1
    },
    "sklearn.model_selection._validation.learning_curve.X": {
      "X_train": 55,
      "X": 53,
      "x_train_pca": 2,
      "x_test_pca": 2,
      "x": 2,
      "_x_train": 2,
      "X_train_p": 2,
      "bioresponce_data": 2,
      "x_train": 1,
      "X_set": 1,
      "X_train_filled": 1,
      "fit_data": 1,
      "train_10_percent": 1,
      "X_training": 1,
      "features": 1,
      "images": 1,
      "df_train": 1
    },
    "sklearn.model_selection._validation.learning_curve.y": {
      "y_train": 60,
      "y": 55,
      "y_test": 2,
      "Y": 2,
      "_y_train": 2,
      "bioresponce_target": 2,
      "fit_labels": 1,
      "y_10_percent": 1,
      "Y_training_actual": 1,
      "target": 1,
      "answers": 1,
      "Y_train": 1
    },
    "sklearn.decomposition._truncated_svd.TruncatedSVD.__init__.tol": {
      "0.0": 991,
      "0": 4,
      "1.0": 1
    },
    "sklearn.preprocessing._data.StandardScaler.__init__.copy": {
      "True": 6137,
      "False": 15
    },
    "sklearn.svm._classes.SVC.__init__.coef0": {
      "0.0": 1628,
      "1": 41,
      "0.04": 1,
      "10": 1,
      "0.05": 1,
      "3.0": 1,
      "0.01": 1,
      "1.0": 1
    },
    "sklearn.svm._classes.SVC.__init__.cache_size": {
      "200": 1649,
      "500": 9,
      "1000": 9,
      "2000": 3,
      "5": 1,
      "16000": 1,
      "12000": 1,
      "300": 1,
      "3000": 1
    },
    "sklearn.svm._classes.LinearSVC.__init__.dual": {
      "True": 387,
      "False": 66
    },
    "sklearn.pipeline.Pipeline.__init__.verbose": {
      "False": 3687,
      "True": 19
    },
    "sklearn.compose._column_transformer.ColumnTransformer.__init__.verbose": {
      "False": 434,
      "True": 7,
      "verbose": 1,
      "self.verbose": 1
    },
    "sklearn.metrics._classification.hamming_loss.y_true": {
      "y_test": 14,
      "yval": 6,
      "val_image_predictions": 1,
      "np.round(test_image_predictions)": 1,
      "Y": 1,
      "test_prob": 1,
      "toxic_prob": 1,
      "nontoxic_prob": 1,
      "toxic_prob[i]": 1,
      "y_true": 1,
      "real": 1,
      "test_labels": 1,
      "batch_labels1.reshape(-1).detach().cpu()": 1,
      "batch_labels0.reshape(-1).detach().cpu()": 1,
      "Ym_test": 1,
      "Ycv": 1,
      "val_y": 1
    },
    "sklearn.metrics._classification.hamming_loss.y_pred": {
      "predictions": 9,
      "y_pred": 7,
      "predictionc": 2,
      "prediction": 2,
      "predictions_2": 1,
      "val_image_labels": 1,
      "test_image_labels": 1,
      "Y_pred": 1,
      "test_lbl.values": 1,
      "toxic_lbl.values": 1,
      "nontoxic_lbl.values": 1,
      "toxic_lbl.values[i]": 1,
      "predictions.astype(int)": 1,
      "torch.round(torch.sigmoid(predicted[1].reshape(-1).detach().cpu()))": 1,
      "torch.round(torch.sigmoid(predicted[0].reshape(-1).detach().cpu()))": 1,
      "Ym_test_pred": 1,
      "Ycv_pred": 1,
      "y_pred2": 1,
      "preds": 1
    },
    "sklearn.impute._iterative.IterativeImputer.__init__.max_iter": {
      "10": 37,
      "30": 7,
      "500": 4,
      "4": 2,
      "9": 1,
      "self.max_iter": 1,
      "100": 1,
      "300": 1,
      "20": 1
    },
    "sklearn.impute._iterative.IterativeImputer.__init__.random_state": {
      "None": 25,
      "0": 15,
      "42": 4,
      "SEED": 4,
      "1": 3,
      "37": 1,
      "23": 1,
      "seed": 1,
      "34": 1
    },
    "sklearn.neighbors._kde.KernelDensity.fit.X": {
      "X": 17,
      "self.dataRepresentation[:, eigVecInd].reshape(-1, 1)": 8,
      "obs": 3,
      "np.array(df_target[feat][df_target['target'] == 0]).reshape(-1, 1)": 2,
      "np.array(df_target[feat][df_target['target'] == 1]).reshape(-1, 1)": 2,
      "list(zip(y[filt]))": 2,
      "X_plot": 2,
      "var_81_a[:, None]": 2,
      "predictions_null_sensors['time_to_eruption'].to_numpy()[:, np.newaxis]": 1,
      "train_predictions_null_sensors['time_to_eruption'].to_numpy()[:, np.newaxis]": 1,
      "values.reshape(-1, 1)": 1,
      "self.dataRepresentation[:, templateInd].reshape(-1, 1)": 1,
      "mX": 1,
      "x[:, None]": 1,
      "train['length'].reshape(-1, 1)": 1,
      "train['last'].reshape(-1, 1)": 1,
      "X_train": 1
    },
    "sklearn.neighbors._kde.KernelDensity.__init__.kernel": {
      "'gaussian'": 44,
      "kernel": 3,
      "'exponential'": 2,
      "'tophat'": 1
    },
    "sklearn.neighbors._kde.KernelDensity.__init__.bandwidth": {
      "0.02": 18,
      "sigmaOfKDE": 9,
      "0.75": 8,
      "bin_size * bin_bandwidth_multiplier": 4,
      "1.0": 4,
      "bWidth": 3,
      "0.3": 2,
      "0.1": 1,
      "bandwidth": 1
    },
    "sklearn.neighbors._kde.KernelDensity.sample.n_samples": {
      "100000": 2
    },
    "sklearn.neighbors._kde.KernelDensity.sample.random_state": {
      "42": 2
    },
    "sklearn.metrics.pairwise.euclidean_distances.X": {
      "map_poses * map_mask.resolution": 7,
      "i": 6,
      "val_y.values.reshape(1, -1)": 3,
      "vectors.cpu().numpy()": 2,
      "np.stack(train_df.pred.values)": 2,
      "points": 2,
      "question1_tfidf.getrow(i)": 2,
      "x.reshape(1, -1)": 1,
      "corr[idx == uidx]": 1,
      "test_preds": 1,
      "question2_tfidf.getrow(i)": 1,
      "question1_tfidf": 1,
      "document_embeddings": 1,
      "[[Pclass, Age, SibSp, Parch, Fare, Sex_female, Sex_male, Embarked_C, Embarked_Q, Embarked_S], list(centroids.loc[cluster, :])]": 1,
      "weights": 1
    },
    "sklearn.metrics.pairwise.euclidean_distances.Y": {
      "None": 12,
      "j": 6,
      "val_y_pred.reshape(1, -1)": 3,
      "final_vectors": 2,
      "questionD_tfidf.getrow(i)": 2,
      "y.reshape(1, -1)": 1,
      "[list(centroids[uidx])]": 1,
      "data_preds": 1,
      "np.stack(valid_df.pred.values)": 1,
      "np.stack(test_df.pred.values)": 1,
      "question2_tfidf.getrow(i)": 1,
      "question2_tfidf": 1
    },
    "sklearn.cluster._kmeans.MiniBatchKMeans.__init__.random_state": {
      "None": 76,
      "20": 9,
      "0": 7,
      "42": 7,
      "1": 3,
      "rng": 1,
      "71": 1,
      "2": 1
    },
    "sklearn.cluster._kmeans.MiniBatchKMeans.__init__.verbose": {
      "0": 98,
      "1": 5,
      "False": 2
    },
    "sklearn.feature_extraction.image.extract_patches_2d.max_patches": {
      "None": 6,
      "20": 2,
      "30": 2,
      "500": 2,
      "no_patches": 1,
      "300": 1,
      "1": 1
    },
    "sklearn.feature_extraction.image.extract_patches_2d.random_state": {
      "None": 9,
      "rng": 2,
      "0": 2,
      "1": 2
    },
    "sklearn.feature_extraction.image.extract_patches_2d.image": {
      "im_data": 5,
      "imgf": 2,
      "im": 2,
      "img": 2,
      "grayimg": 1,
      "rgb2gray(img)": 1,
      "gray_scale_img": 1,
      "image": 1
    },
    "sklearn.feature_extraction.image.extract_patches_2d.patch_size": {
      "(4, 4)": 5,
      "patch_size": 4,
      "(200, 200)": 2,
      "(20, 20)": 2,
      "(64, 64)": 1,
      "(self.height, self.width)": 1
    },
    "sklearn.cluster._kmeans.MiniBatchKMeans.partial_fit.X": {
      "data": 2
    },
    "sklearn.manifold._t_sne.TSNE.__init__.metric": {
      "'euclidean'": 513,
      "'cosine'": 16,
      "'precomputed'": 6,
      "'jaccard'": 1
    },
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.n_components": {
      "2": 37,
      "None": 6,
      "len(cols)": 2,
      "8": 2,
      "15": 1,
      "data.shape[1]": 1,
      "100": 1,
      "20": 1,
      "150": 1,
      "10": 1
    },
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.kernel": {
      "'rbf'": 27,
      "'linear'": 9,
      "'sigmoid'": 7,
      "'poly'": 5,
      "'cosine'": 3,
      "kernel": 2
    },
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.random_state": {
      "None": 42,
      "self.random_state": 5,
      "random_state": 2,
      "0": 2,
      "seed": 1,
      "1000": 1
    },
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.n_jobs": {
      "None": 46,
      "self.n_jobs": 5,
      "-1": 1,
      "1": 1
    },
    "sklearn.impute._base.SimpleImputer.__init__.add_indicator": {
      "False": 1121,
      "True": 19
    },
    "sklearn.impute._base.SimpleImputer.__init__.fill_value": {
      "None": 982,
      "'missing'": 47,
      "0": 25,
      "-1": 14,
      "'NA'": 9,
      "'NaN'": 7,
      "0.0": 6,
      "''": 4,
      "'no_event'": 4,
      "'Missing'": 3,
      "'None'": 3,
      "'-1'": 3,
      "-999": 3,
      "'MISSING'": 2,
      "'N.A'": 2,
      "'unknown'": 2,
      "'Abs'": 2,
      "-9999.99": 2,
      "'[]'": 1,
      "self.fill_value": 1,
      "9999": 1,
      "fill_value": 1,
      "col_mode[curr_col]": 1,
      "'Nan'": 1,
      "-9999": 1,
      "'none'": 1,
      "v": 1,
      "X_train[categorical_feat].mode()": 1,
      "previous_application[categorical].mode()": 1,
      "bureau[categorical].mode()": 1,
      "'S'": 1,
      "-10": 1,
      "'Unknown'": 1,
      "'US'": 1,
      "'20/3/2001'": 1,
      "'movie'": 1,
      "'film'": 1,
      "'en'": 1
    },
    "sklearn.metrics._classification.precision_recall_fscore_support.average": {
      "'weighted'": 16,
      "None": 15,
      "'binary'": 13,
      "'macro'": 10,
      "'micro'": 4
    },
    "sklearn.metrics._classification.precision_recall_fscore_support.y_true": {
      "y_test": 12,
      "TestLabel": 9,
      "labels": 6,
      "y_true": 4,
      "y_valid": 2,
      "y_train": 2,
      "val_y.argmax(axis=1)": 2,
      "train_y[valid_idx]": 2,
      "train_y": 2,
      "test[col]": 2,
      "y_new": 2,
      "[1 if np.sum(x) > 1 else 0 for x in ytrue]": 1,
      "y_test['target']": 1,
      "predictions['Target']": 1,
      "p.label_ids": 1,
      "target": 1,
      "np.array(y_val)": 1,
      "Y_test": 1,
      "y_val": 1,
      "y_predict": 1,
      "y_tru": 1,
      "y_validation": 1,
      "lb": 1,
      "X_test['surface'].values": 1
    },
    "sklearn.metrics._classification.precision_recall_fscore_support.y_pred": {
      "y_pred": 13,
      "y_test_pred": 5,
      "preds": 5,
      "val_pred": 2,
      "valid_yhat_fold": 2,
      "train_yhat": 2,
      "y_prediction[col]": 2,
      "y_finalpred": 2,
      "y_valid_pred": 1,
      "result": 1,
      "[1 if np.sum(x) > 1 else 0 for x in ypred]": 1,
      "log_clf.predict(TestData)": 1,
      "lda.predict(TestData)": 1,
      "gnb.predict(TestData)": 1,
      "knn.predict(TestData)": 1,
      "svm.predict(TestData)": 1,
      "dt.predict(TestData)": 1,
      "rf.predict(TestData)": 1,
      "adb.predict(TestData)": 1,
      "gb.predict(TestData)": 1,
      "y_predict": 1,
      "scores": 1,
      "y_trfull": 1,
      "prediction": 1,
      "train_predict": 1,
      "pred": 1,
      "y_train": 1,
      "y_prd": 1,
      "predictions": 1,
      "op": 1,
      "y_pred_train": 1,
      "y_pred_valid": 1,
      "self.predict(X_test)": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.n_jobs": {
      "None": 793,
      "-1": 28,
      "1": 11,
      "8": 4,
      "4": 2,
      "7": 1,
      "n_jobs": 1,
      "model_njobs": 1
    },
    "sklearn.pipeline.FeatureUnion.fit_transform.y": {
      "None": 75,
      "y": 6,
      "train['Survived']": 1,
      "df_train['target']": 1,
      "y_train": 1,
      "X_train[cat_attributes].values": 1
    },
    "sklearn.preprocessing._label.label_binarize.classes": {
      "[0, 1, 2]": 15,
      "list(range(0, 100))": 4,
      "[0, 1, 2, 3, 4]": 4,
      "classes": 2,
      "[0, 1]": 2,
      "config.class_list": 2,
      "null": 2,
      "class_labels": 1,
      "['EAP', 'HPL', 'MWS']": 1,
      "classnames": 1,
      "CLASS_NAMES": 1,
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']": 1
    },
    "sklearn.model_selection._validation.validation_curve.scoring": {
      "'r2'": 6,
      "'accuracy'": 5,
      "'neg_mean_absolute_error'": 4,
      "'roc_auc'": 4,
      "None": 4,
      "'neg_mean_squared_error'": 3,
      "rmse_scorer": 2,
      "mae_scoring": 1,
      "scoring": 1,
      "logloss_score": 1,
      "gini_scorer": 1
    },
    "sklearn.model_selection._validation.validation_curve.estimator": {
      "estimator": 6,
      "DecisionTreeRegressor()": 4,
      "rf_clf": 4,
      "model.best_estimator_": 3,
      "model": 2,
      "RandomForestRegressor(n_estimators=100)": 2,
      "reg": 1,
      "RandomForestRegressor(max_depth=3)": 1,
      "pipe_lr": 1,
      "rf_class": 1,
      "RandomForestRegressor(n_jobs=4)": 1,
      "RandomForestRegressor(n_estimators=120, n_jobs=4)": 1,
      "RandomForestRegressor(n_estimators=120, n_jobs=4, max_features=16)": 1,
      "mnb": 1,
      "xgb_model": 1,
      "RandomForestRegressor()": 1,
      "KNeighborsClassifier(metric=metric)": 1
    },
    "sklearn.model_selection._validation.validation_curve.X": {
      "X": 17,
      "X_train": 3,
      "X[:20000]": 3,
      "X_train[:20000]": 3,
      "X_train[:500000]": 2,
      "X_train_filled": 2,
      "train_prep": 1,
      "some_sample_data_to_test[col]": 1
    },
    "sklearn.model_selection._validation.validation_curve.y": {
      "y": 17,
      "y_train": 4,
      "y[:20000]": 3,
      "y_train[:20000]": 3,
      "y_train[:500000]": 2,
      "customers_train": 1,
      "np.array(train_tgt)": 1,
      "some_sample_data_to_test['target']": 1
    },
    "sklearn.ensemble._voting.VotingRegressor.predict.X": {
      "X_test": 9,
      "test": 4,
      "x_train": 4,
      "x_val": 3,
      "x_test": 2,
      "X_valid": 2,
      "X_transformed": 2,
      "df_test.values": 2,
      "test_feature": 1,
      "X_val": 1,
      "df_test": 1,
      "X_train_red": 1,
      "X_test_red": 1,
      "test_pred": 1
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.fit.X": {
      "X_train": 8,
      "x_train_vector": 2,
      "X_train_tfidf": 1,
      "x_vector": 1,
      "X1_train": 1,
      "tfidf_train": 1,
      "x_train": 1
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.fit.y": {
      "y_train": 10,
      "Y_train": 1,
      "y_train_tfidf": 1,
      "y": 1,
      "y1_train": 1,
      "train_y": 1
    },
    "sklearn.ensemble._weight_boosting.AdaBoostRegressor.__init__.base_estimator": {
      "None": 188,
      "DecisionTreeRegressor()": 6,
      "DecisionTreeRegressor(max_depth=15)": 3,
      "DecisionTreeRegressor(max_depth=4)": 3,
      "mdl": 3,
      "DecisionTreeRegressor(max_depth=8)": 2,
      "model_dtr": 2,
      "base": 2,
      "DecisionTreeRegressor(max_depth=68, splitter='random')": 2,
      "DecisionTreeRegressor(random_state=0)": 1,
      "rd": 1,
      "SVR()": 1,
      "tree": 1,
      "regr_1": 1,
      "LinearRegression(normalize=True)": 1,
      "model_rnd_frst": 1,
      "lr": 1,
      "lr_lassocv": 1,
      "lr_ridgecv": 1,
      "lr_elastic_netcv": 1,
      "knn_best": 1,
      "dt": 1,
      "mdl1": 1,
      "mdl2": 1,
      "DecisionTreeRegressor(max_depth=1)": 1,
      "RF": 1,
      "Ridge()": 1,
      "dt_stump": 1,
      "DecisionTreeRegressor(max_depth=5)": 1,
      "GBR": 1,
      "RandomForestRegressor(max_depth=10)": 1
    },
    "sklearn.cluster._kmeans.KMeans.__init__.max_iter": {
      "300": 874,
      "100": 14,
      "1000": 9,
      "50": 6,
      "10000": 5,
      "3000": 3,
      "400": 2,
      "100000": 2,
      "10": 2,
      "max_iter": 2,
      "2000": 2,
      "max_iterations": 1,
      "1": 1,
      "5000": 1,
      "90": 1,
      "200": 1,
      "5": 1,
      "500": 1
    },
    "sklearn.preprocessing._data.PowerTransformer.__init__.method": {
      "'yeo-johnson'": 66,
      "'box-cox'": 10
    },
    "sklearn.compose._column_transformer.ColumnTransformer.fit_transform.y": {
      "None": 207,
      "y": 3,
      "y_train": 3,
      "train_y": 1,
      "df_train['target']": 1,
      "y_pca": 1
    },
    "sklearn.linear_model._ridge.RidgeClassifier.fit.X": {
      "train_vectors": 29,
      "X_train": 14,
      "zipped_new_data_list": 5,
      "tfidf_train": 5,
      "Train": 4,
      "train_vector": 3,
      "train_tfidf_vectors": 3,
      "pca_X_train": 2,
      "X_train_vect_TFID": 2,
      "x": 2,
      "X_train[train_index]": 2,
      "train_set['X']": 2,
      "X_numeric_train": 2,
      "cv_train": 1,
      "td_train": 1,
      "x_train_tfidf": 1,
      "level1_train": 1,
      "Stacked": 1,
      "x_cleaned": 1,
      "x_train": 1,
      "transformed_train": 1,
      "xtrain": 1,
      "X_train_vec": 1,
      "xtrain_ctv": 1,
      "xtrain_tweet": 1,
      "train_Vectors": 1
    },
    "sklearn.linear_model._ridge.RidgeClassifier.fit.y": {
      "train_df['target']": 23,
      "y_train": 19,
      "y_train['target']": 12,
      "train_data['target']": 5,
      "train['target']": 4,
      "y": 3,
      "y[train_index]": 2,
      "train_set['y']": 2,
      "ytrain_tweet": 2,
      "Y": 1,
      "df_train[target_col]": 1,
      "df_train.target": 1,
      "y_train_ch": 1,
      "y_train_vt": 1,
      "y_train_gr": 1,
      "train2.loc[test_index]['target']": 1,
      "df['target']": 1,
      "trainData['target']": 1,
      "df_train['target']": 1,
      "train.relabeled": 1,
      "f_train.target": 1,
      "train_y_train": 1,
      "ytrain": 1,
      "df1['target']": 1,
      "train_df['target_relabeled']": 1
    },
    "sklearn.feature_selection._univariate_selection.chi2.X": {
      "ts": 8,
      "np.asarray(valid[i]).reshape(-1, 1)": 4,
      "X_train": 3,
      "desc_tfidf_all_tr": 2,
      "X": 2,
      "data_cat_dummies_sample": 2,
      "data_numericals_sample.fillna(data_numericals_sample.median())": 2,
      "data[feature_columns]": 2,
      "x_train_tfidf": 1,
      "oh_encoded": 1,
      "x_train": 1,
      "features": 1,
      "x_train[Columns.ind_num_cat_columns.value]": 1,
      "train_cat.drop(['target'], axis=1).replace(-1, 0)": 1,
      "X_train.fillna(0)": 1,
      "train_matrix": 1,
      "col[present_x].values.reshape(-1, 1)": 1,
      "train_df[col].values.reshape(-1, 1)": 1
    },
    "sklearn.feature_selection._univariate_selection.chi2.y": {
      "y": 9,
      "y_train": 5,
      "valid['target']": 2,
      "np.asarray(valid[j])": 2,
      "label_tr": 2,
      "data[HOTEL_CLUSTER].loc[data_cat_dummies_sample.index]": 2,
      "data[HOTEL_CLUSTER].loc[data_numericals_sample.index]": 2,
      "data.type": 2,
      "y == cat": 2,
      "data_copy['target']": 1,
      "labels == category_id": 1,
      "df_train['target']": 1,
      "y_train['AdoptionSpeed'].values.reshape(-1, 1)": 1,
      "train['target']": 1,
      "y[present_x]": 1,
      "train_df['AdoptionSpeed'].values": 1
    },
    "sklearn.model_selection._validation.learning_curve.train_sizes": {
      "train_sizes": 54,
      "np.linspace(0.01, 1.0, 10)": 42,
      "np.linspace(0.1, 1.0, 5)": 9,
      "np.linspace(0.1, 1.0, 10)": 6,
      "np.linspace(0.1, 1, 10)": 4,
      "np.arange(0.1, 1.1, 0.1)": 2,
      "np.linspace(0.05, 1, 6)": 2,
      "training_sample_sizes": 2,
      "np.linspace(0.01, 1.0, 20)": 1,
      "np.linspace(0.1, 1.0, 50)": 1,
      "[50, 80, 110]": 1,
      "np.linspace(0.1, 1.0, 7)": 1,
      "trainSizes": 1,
      "np.linspace(0.1, 1.0, 9)": 1,
      "np.arange(0.1, 1.0, 0.2)": 1,
      "np.arange(0.1, 1, 0.2)": 1
    },
    "sklearn.model_selection._validation.learning_curve.cv": {
      "cv": 47,
      "3": 45,
      "5": 15,
      "None": 8,
      "10": 4,
      "kf": 3,
      "4": 2,
      "k_fold": 2,
      "GroupKFold(5).split(X, y, groups=groups)": 1,
      "7": 1,
      "num_folds": 1
    },
    "sklearn.model_selection._validation.learning_curve.scoring": {
      "None": 56,
      "'precision_weighted'": 41,
      "scoring": 8,
      "'accuracy'": 4,
      "'neg_mean_squared_error'": 4,
      "'roc_auc'": 3,
      "'neg_root_mean_squared_error'": 3,
      "'neg_mean_absolute_error'": 2,
      "scorer": 2,
      "'f1_macro'": 1,
      "rmse_scorer": 1,
      "'f1'": 1,
      "make_scorer(gini_normalized)": 1,
      "make_scorer(gini_normalized, needs_proba=True)": 1,
      "score": 1
    },
    "sklearn.datasets._base.load_sample_image.image_name": {
      "'flower.jpg'": 2
    },
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.alpha": {
      "0.9": 914,
      "0.01": 29,
      "0.8": 5,
      "LOWER_ALPHA": 3,
      "UPPER_ALPHA": 3,
      "0.1": 3,
      "0.5": 3,
      "0.95": 3,
      "0.05": 2,
      "q": 2,
      "0.8979588317644014": 2,
      "l_alpha": 2,
      "m_alpha": 2,
      "u_alpha": 2,
      "0.7": 2,
      "alpha": 2,
      "Quantile1": 1,
      "Quantile2": 1,
      "Quantile3": 1,
      "Quantile4": 1,
      "Quantile5": 1,
      "Quantile6": 1,
      "Quantile7": 1,
      "Quantile8": 1,
      "Quantile9": 1,
      "0.03": 1
    },
    "sklearn.dummy.DummyClassifier.fit.X": {
      "X_train": 11,
      "X": 5,
      "x_train": 2,
      "X_tr_equid": 2,
      "X_tr_balan": 2,
      "df_train[features]": 2,
      "xtrain_tfv": 1,
      "train.id_code": 1,
      "y_train": 1,
      "Y": 1,
      "X_trcv": 1,
      "X_train_vec_df": 1,
      "train_X": 1
    },
    "sklearn.dummy.DummyClassifier.fit.y": {
      "y_train": 15,
      "y": 2,
      "y_equidistant": 2,
      "y_tr_equid": 2,
      "y_tr_balan": 2,
      "df_train['AdoptionSpeed']": 2,
      "ytrain": 1,
      "train.diagnosis": 1,
      "Y": 1,
      "y_train_lg": 1,
      "train_y": 1,
      "y_balanced": 1
    },
    "sklearn.dummy.DummyClassifier.predict_proba.X": {
      "xvalid_tfv": 1,
      "Y": 1,
      "X_train": 1,
      "X_test": 1
    },
    "sklearn.preprocessing._data.RobustScaler.__init__.with_centering": {
      "True": 529,
      "False": 5
    },
    "sklearn.preprocessing._data.RobustScaler.__init__.with_scaling": {
      "True": 533,
      "False": 1
    },
    "sklearn.preprocessing._data.RobustScaler.__init__.unit_variance": {
      "False": 533,
      "True": 1
    },
    "sklearn.feature_selection._rfe.RFE.__init__.step": {
      "1": 132,
      "10": 5,
      "step": 2,
      "3": 1,
      "15": 1,
      "0.5": 1
    },
    "sklearn.cluster._agglomerative.AgglomerativeClustering.__init__.linkage": {
      "'ward'": 28,
      "'average'": 6,
      "'complete'": 1,
      "linkage": 1
    },
    "sklearn.cluster._agglomerative.AgglomerativeClustering.__init__.n_clusters": {
      "None": 7,
      "2": 6,
      "5": 5,
      "3": 4,
      "10": 2,
      "n": 2,
      "n_clusters": 2,
      "50": 2,
      "4": 1,
      "num_clusters": 1,
      "N_CLUSTERS": 1,
      "9": 1,
      "6": 1,
      "100": 1
    },
    "sklearn.cluster._agglomerative.AgglomerativeClustering.fit.X": {
      "train": 5,
      "X_red": 2,
      "train.drop(['id', 'target'], axis=1).iloc[:len(train) * 8 // 10]": 1,
      "train.drop(['id', 'target'], axis=1)": 1,
      "columns_std": 1,
      "X": 1,
      "distance_matrix": 1,
      "x_train_s": 1,
      "sales_corr": 1,
      "cust_corr": 1,
      "x": 1,
      "new": 1,
      "daily_sales_item_lookup_scaled_weekly.T.values": 1,
      "agg_cluster_X": 1,
      "shops": 1
    },
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.__init__.store_covariance": {
      "False": 275,
      "True": 1
    },
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.__init__.tol": {
      "0.0001": 272,
      "1e-09": 1,
      "0.01": 1,
      "1e-10": 1,
      "1": 1
    },
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.predict.X": {
      "X_test": 9,
      "slim_x_test": 4,
      "X_val": 2,
      "pca_X_test": 2,
      "X_train": 2,
      "X": 1,
      "X_pca": 1,
      "pseudo_labeled_X": 1,
      "x_test": 1
    },
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.__init__.solver": {
      "'svd'": 278,
      "'eigen'": 6,
      "'lsqr'": 2,
      "'lbfgs'": 1
    },
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.__init__.tol": {
      "0.0001": 286,
      "1e-09": 1
    },
    "sklearn.manifold._t_sne.TSNE.__init__.learning_rate": {
      "200.0": 499,
      "100": 15,
      "200": 5,
      "150": 4,
      "1000": 3,
      "300": 2,
      "50": 2,
      "500": 2,
      "20": 2,
      "15": 1,
      "2000": 1
    },
    "sklearn.linear_model._base.LinearRegression.__init__.copy_X": {
      "True": 2978,
      "False": 6
    },
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.normalize": {
      "False": 81,
      "True": 4
    },
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.n_jobs": {
      "None": 70,
      "-1": 13,
      "2": 1,
      "1": 1
    },
    "sklearn.preprocessing._data.minmax_scale.X": {
      "x": 37,
      "train_test['cont4']": 19,
      "train_test['cont5']": 19,
      "train_test['cont6']": 19,
      "train_test['cont7']": 19,
      "train_test['cont8']": 19,
      "train_test['cont9']": 19,
      "train_test['cont10']": 19,
      "train_test['cont11']": 19,
      "train_test['cont12']": 19,
      "train_test['cont13']": 19,
      "train_test['cont1']": 18,
      "df[col]": 17,
      "my_transaction[col]": 6,
      "data": 6,
      "data[col]": 5,
      "train_df[col]": 5,
      "test_df[col]": 5,
      "x.astype(float)": 4,
      "weights.ravel()": 4,
      "train_set[train_pre].astype(float)": 4,
      "pred_set[train_pre].astype(float)": 4,
      "train_test['cont2']": 3,
      "train_test['cont3']": 3,
      "col": 3,
      "prepared_sample": 3,
      "df_train[col]": 3,
      "X['TARGET']": 3,
      "v": 3,
      "x[:, :]": 2,
      "deg_C[:]": 2,
      "relative_humidity[:]": 2,
      "absolute_humidity[:]": 2,
      "sensor_1[:]": 2,
      "sensor_2[:]": 2,
      "sensor_3[:]": 2,
      "sensor_4[:]": 2,
      "sensor_5[:]": 2,
      "train_test['cont14']": 2,
      "lr[label]": 2,
      "transaction_V[col]": 2,
      "db": 2,
      "test_df[key].values.astype(np.float32)": 2,
      "train_df[key].values.astype(np.float32)": 2,
      "train": 2,
      "test": 2,
      "new[col]": 2,
      "train_data[col]": 2,
      "test_data[col]": 2,
      "testData[:, :]": 1,
      "y[:, :]": 1,
      "month[:]": 1,
      "dayofweek[:]": 1,
      "hour[:]": 1,
      "target_benzene[:]": 1,
      "target_carbon_monoxide[:]": 1,
      "y_true": 1,
      "y_pred": 1,
      "r_script[label]": 1,
      "lstm[label]": 1,
      "gru_cnn[label]": 1,
      "gru_capsule[label]": 1,
      "gru_pool[label]": 1,
      "lstm_bi[label]": 1,
      "lstm_conv[label]": 1,
      "gru_fasttext[label]": 1,
      "ridge[label]": 1,
      "list(yo)": 1,
      "train['{}_ID_code_counts'.format(f)]": 1,
      "centroid": 1,
      "bandwidth": 1,
      "rolloff": 1,
      "mfcc": 1,
      "sound_data[birds[i]]['spec_c']": 1,
      "sound_data[birds[i]]['spec_r']": 1,
      "df_test[train_title[i]]": 1,
      "x.values.astype(float)": 1,
      "files[model][label]": 1,
      "get_sub_file(key)[label]": 1,
      "blend[label]": 1,
      "x_train_val": 1,
      "x_test": 1,
      "all_data[ord_cols]": 1,
      "data - data.mean()": 1,
      "importances": 1,
      "sc": 1,
      "spectral_rolloff": 1,
      "spectral_bandwidth": 1,
      "mfccs": 1,
      "df_test[col]": 1,
      "allave[col].values": 1,
      "gru[col].values": 1,
      "sup[col].values": 1,
      "activities_df": 1,
      "y": 1,
      "y_validation": 1,
      "pred_val": 1,
      "data['temp']": 1,
      "data['atemp']": 1,
      "data['humidity']": 1,
      "data['windspeed']": 1,
      "train_targets['count']": 1,
      "train_df['addr1']": 1,
      "test_df['addr1']": 1,
      "lgb[label]": 1,
      "gru[label]": 1,
      "lstm_nb_svm[label]": 1,
      "train_df[['Hire_count', 'Zone_ID']]": 1,
      "train_df['weekday']": 1,
      "train_df[['zone_id']]": 1,
      "zone_id_int": 1,
      "test_df['weekday']": 1,
      "submission_1[col].values": 1,
      "submission_2[col].values": 1,
      "xtr_te": 1,
      "np.sqrt(np.mean([(math.log(y_pred[i] + 1) - math.log(y[i] + 1))**2.0 for (i, pred) in enumerate(y_pred)]))": 1
    },
    "sklearn.covariance._robust_covariance.MinCovDet.__init__.support_fraction": {
      "None": 4,
      "0.7": 1
    },
    "sklearn.covariance._robust_covariance.MinCovDet.fit.X": {
      "train4": 1,
      "df_of_a_type[NUMERIC_FEATURES]": 1,
      "combo_input[:, :]": 1
    },
    "sklearn.ensemble._bagging.BaggingRegressor.__init__.n_estimators": {
      "10": 72,
      "45": 19,
      "n_estimators": 10,
      "20": 6,
      "100": 4,
      "50": 4,
      "args['n_estimators']": 3,
      "1000": 2,
      "15": 2,
      "2000": 2,
      "25": 2,
      "n_trees": 2,
      "5": 1,
      "4000": 1,
      "80": 1,
      "40": 1,
      "55": 1,
      "500": 1,
      "parameter[1]": 1,
      "8": 1,
      "16": 1,
      "32": 1,
      "200": 1,
      "100000": 1,
      "3": 1,
      "4": 1
    },
    "sklearn.ensemble._bagging.BaggingRegressor.__init__.random_state": {
      "None": 91,
      "25": 23,
      "0": 5,
      "42": 5,
      "1165842557": 3,
      "rng": 3,
      "1": 2,
      "333": 1,
      "2021": 1,
      "9843": 1,
      "93843": 1,
      "27": 1,
      "1211": 1,
      "71": 1,
      "seed": 1,
      "123": 1,
      "51": 1
    },
    "sklearn.ensemble._bagging.BaggingClassifier.__init__.random_state": {
      "None": 123,
      "0": 25,
      "seed": 9,
      "42": 7,
      "random_state": 3,
      "4372": 2,
      "2014": 2,
      "40": 2,
      "123": 2,
      "54": 2,
      "333": 1,
      "22": 1,
      "1234": 1,
      "432": 1,
      "2": 1,
      "random_seed": 1,
      "1": 1,
      "99999": 1,
      "555": 1
    },
    "sklearn.svm._classes.SVR.__init__.tol": {
      "0.001": 454,
      "0.01": 11,
      "1e-05": 2,
      "0.003": 1,
      "0.000121": 1,
      "trial.suggest_uniform('tol', 0.01, 500)": 1,
      "0.0001": 1
    },
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.decode_error": {
      "'strict'": 3184,
      "'ignore'": 27,
      "'replace'": 4
    },
    "sklearn.preprocessing._data.maxabs_scale.X": {
      "train": 2,
      "test": 2,
      "X_train": 2,
      "X_test": 2
    },
    "sklearn.linear_model._huber.HuberRegressor.fit.X": {
      "X": 2,
      "x_train": 2,
      "X_train_sc": 2,
      "X_train": 2,
      "train[feature_columns]": 2,
      "tr": 2,
      "feature_train": 1,
      "trainX": 1,
      "sub.Weeks.values[:, np.newaxis]": 1
    },
    "sklearn.linear_model._huber.HuberRegressor.fit.y": {
      "y_train": 6,
      "train['FVC']": 2,
      "y.ix[indextrain]": 2,
      "Price": 1,
      "y": 1,
      "targets[i]": 1,
      "trainSet['scalar_coupling_constant']": 1,
      "sub.FVC.values": 1
    },
    "sklearn.utils.resample.replace": {
      "True": 117,
      "False": 59
    },
    "sklearn.utils.resample.n_samples": {
      "700": 61,
      "len(df_majority) // 4": 10,
      "len(df_4)": 9,
      "len(insincere) * 4": 6,
      "75000": 5,
      "len(not_fraud)": 4,
      "len(fraud)": 4,
      "int(len(X_train) / 1000)": 4,
      "79000": 4,
      "10000": 3,
      "len(train_4)": 3,
      "len(df_1)": 3,
      "179902": 3,
      "1900": 3,
      "len(insincere)": 3,
      "len(df_d)": 3,
      "len(df_a)": 3,
      "584": 2,
      "len(negative)": 2,
      "len(insincere) * 5": 2,
      "len(toxic)": 2,
      "len(survived)": 2,
      "9778": 2,
      "400000": 2,
      "samples": 2,
      "None": 2,
      "197969": 1,
      "17288": 1,
      "sample": 1,
      "val": 1,
      "number_to_sample": 1,
      "len(train_1)": 1,
      "len(not_duplicate_ids)": 1,
      "n_size": 1,
      "num_samples": 1,
      "16": 1,
      "4": 1,
      "473518": 1,
      "len(X_min)": 1,
      "len(insincere_questions) * 5": 1,
      "7159298": 1,
      "int(unworthy_worthy_ration * len(worthy))": 1,
      "len(df_majority) // 3": 1,
      "dataset[dataset['target'] == 1].shape[0]": 1,
      "df['Survived'].value_counts()[0]": 1,
      "len(insincere) * 3": 1,
      "len(train_majority)": 1,
      "25000": 1,
      "208236": 1,
      "179813": 1,
      "73012": 1,
      "1000001": 1,
      "120001": 1
    },
    "sklearn.utils.resample.random_state": {
      "2020": 60,
      "None": 24,
      "123": 23,
      "42": 23,
      "100": 12,
      "27": 11,
      "10": 6,
      "13": 2,
      "43": 2,
      "111": 2,
      "1234": 2,
      "25": 2,
      "142": 1,
      "451": 1,
      "123456": 1,
      "44": 1,
      "0": 1,
      "1337": 1,
      "1": 1
    },
    "sklearn.feature_selection._univariate_selection.f_regression.X": {
      "train_no_y.values[:, 1:9]": 4,
      "X": 3,
      "label_encoded": 2,
      "loaded_dfs[REGRESSION_FTS]": 1,
      "train_df_binary": 1,
      "X_train.fillna(0)": 1,
      "train[categorical_cols + numerical_cols]": 1
    },
    "sklearn.feature_selection._univariate_selection.f_regression.y": {
      "train_y": 4,
      "y": 3,
      "Y": 2,
      "loaded_dfs[LABEL]": 1,
      "target_df_log": 1,
      "y_train": 1,
      "train['fare_amount']": 1
    },
    "sklearn.feature_selection._mutual_info.mutual_info_regression.X": {
      "X": 27,
      "train_no_y.values[:, 1:9]": 4,
      "x": 4,
      "train": 2,
      "Canadate": 2,
      "X_train": 2,
      "X_preprocessed": 2,
      "pca_x": 2,
      "X_train.fillna(0)": 2,
      "X_train_SS.fillna(0)": 1,
      "df[cont_features].values": 1,
      "train_df_categorical_le": 1,
      "x_train": 1,
      "subset": 1,
      "subset.values.reshape(-1, 1)": 1,
      "house_train.drop(['SalePrice'], axis=1)": 1,
      "X_train_ADS.fillna(0)": 1,
      "Xtr_pca": 1,
      "train[categorical_cols][:10000]": 1,
      "train[numerical_cols][:10000]": 1,
      "subtrain": 1,
      "X_res": 1
    },
    "sklearn.feature_selection._mutual_info.mutual_info_regression.y": {
      "y": 33,
      "y_train": 6,
      "Y_train": 5,
      "train_y": 4,
      "target": 2,
      "Y": 2,
      "sample_target": 2,
      "train['fare_amount'][:10000]": 2,
      "df['target'].values": 1,
      "target_df_log": 1,
      "house_train['SalePrice']": 1,
      "y_res": 1
    },
    "sklearn.linear_model._ridge.Ridge.__init__.copy_X": {
      "True": 1224,
      "False": 1
    },
    "sklearn.linear_model._ridge.Ridge.__init__.max_iter": {
      "None": 1133,
      "100": 38,
      "200": 14,
      "10000": 11,
      "1000": 9,
      "5000": 6,
      "500": 4,
      "250": 2,
      "params['max_iter']": 1,
      "self.params['max_iter']": 1,
      "8000": 1,
      "2000": 1,
      "15.0": 1,
      "self.ITER_RIDGE": 1,
      "20": 1,
      "2147483647": 1
    },
    "sklearn.linear_model._ridge.Ridge.__init__.tol": {
      "0.001": 1141,
      "0.01": 40,
      "0.0025": 15,
      "0.0001": 11,
      "0.05": 5,
      "10": 3,
      "0.0005": 2,
      "0.8042543139861018": 1,
      "1e-06": 1,
      "trial.suggest_float('tol', 0.1, 0.9)": 1,
      "1e-09": 1,
      "1e-05": 1,
      "0.03": 1,
      "0.1": 1,
      "0.005": 1
    },
    "sklearn.feature_selection._mutual_info.mutual_info_regression.discrete_features": {
      "'auto'": 31,
      "discrete_features": 22,
      "features": 2,
      "self.index_discrete_columns": 1,
      "True": 1,
      "disc_features": 1,
      "False": 1,
      "X.dtypes == 'category'": 1
    },
    "sklearn.feature_selection._mutual_info.mutual_info_regression.random_state": {
      "None": 36,
      "0": 19,
      "123": 2,
      "SEED": 1,
      "self.seed": 1,
      "71": 1
    },
    "sklearn.multioutput.MultiOutputClassifier.__init__.n_jobs": {
      "None": 59,
      "-1": 9
    },
    "sklearn.multioutput.MultiOutputClassifier.fit.X": {
      "X_train": 14,
      "x_train": 4,
      "x0": 4,
      "X_train_dtm": 3,
      "X_train_cv": 1,
      "train_data": 1,
      "X": 1,
      "X_train1": 1,
      "df": 1,
      "df_X_train": 1
    },
    "sklearn.multioutput.MultiOutputClassifier.fit.Y": {
      "y_train": 16,
      "Y_train": 4,
      "y0": 4,
      "y_train_cv": 1,
      "train_cats": 1,
      "y": 1,
      "X_test": 1,
      "y_train1": 1,
      "df_scored": 1,
      "df_y_train": 1
    },
    "sklearn.ensemble._weight_boosting.AdaBoostRegressor.__init__.loss": {
      "'linear'": 217,
      "'exponential'": 8,
      "'square'": 7,
      "trial.suggest_categorical('loss', ada_losses)": 1
    },
    "sklearn.linear_model._least_angle.Lars.__init__.fit_intercept": {
      "True": 5,
      "False": 2
    },
    "sklearn.cluster._kmeans.MiniBatchKMeans.__init__.init": {
      "'k-means++'": 105
    },
    "sklearn.cluster._kmeans.MiniBatchKMeans.__init__.n_init": {
      "3": 90,
      "1": 10,
      "100": 3,
      "4": 1,
      "10": 1
    },
    "sklearn.cluster._kmeans.MiniBatchKMeans.__init__.init_size": {
      "None": 84,
      "1000": 10,
      "init_size": 8,
      "n_clust * 10": 1,
      "n_clusters * 3": 1,
      "10": 1
    },
    "sklearn.cluster._kmeans.MiniBatchKMeans.__init__.max_iter": {
      "100": 92,
      "1000": 11,
      "50": 2
    },
    "sklearn.cluster._kmeans.KMeans.transform.X": {
      "vz": 7,
      "vz_sample": 6,
      "full_data[['latitude', 'longitude']]": 4,
      "test": 4,
      "X_tr": 2,
      "X_te": 2,
      "train": 2,
      "X_test_cell": 1,
      "X_test_gene": 1,
      "X_test_cell_gene": 1,
      "X_train": 1,
      "X_test": 1,
      "train_x": 1,
      "test_x": 1,
      "corr_feat_df": 1,
      "X_scaled": 1,
      "tf_idf": 1,
      "test.drop(['y'], axis=1)": 1,
      "X": 1,
      "hists": 1
    },
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.n_components": {
      "10": 14,
      "11": 9,
      "20": 6,
      "n_topics": 6,
      "5": 4,
      "components": 3,
      "n_components": 2,
      "15": 2,
      "num_topics": 2,
      "3": 2,
      "6": 1,
      "LDA_FEATURES": 1,
      "16": 1,
      "TOPIC_COMP": 1,
      "1000": 1,
      "100": 1,
      "number_topics": 1,
      "LDA_DIM": 1,
      "9": 1,
      "num_topics_per_cluster": 1,
      "8": 1,
      "self.ldanc": 1
    },
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.learning_method": {
      "'online'": 39,
      "'batch'": 22,
      "None": 1
    },
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.max_iter": {
      "10": 27,
      "5": 19,
      "20": 9,
      "30": 3,
      "120": 2,
      "n_iter": 1,
      "max_iter": 1
    },
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.random_state": {
      "0": 30,
      "42": 14,
      "None": 10,
      "32": 2,
      "12345": 1,
      "100": 1,
      "10": 1,
      "SEED": 1,
      "777": 1,
      "1": 1
    },
    "sklearn._config.set_config.display": {
      "'diagram'": 22,
      "'text'": 2,
      "None": 1
    },
    "sklearn.model_selection._validation.validation_curve.param_name": {
      "null": 16,
      "'max_depth'": 4,
      "'min_samples_split'": 2,
      "'logisticregression__C'": 2,
      "'n_estimators'": 2,
      "param_name": 2,
      "'columntransformer__targetencoder-5__smoothing'": 1,
      "'columntransformer__targetencoder-4__smoothing'": 1,
      "param": 1,
      "'min_samples_leaf'": 1
    },
    "sklearn.model_selection._validation.validation_curve.param_range": {
      "null": 16,
      "param_range": 5,
      "param_range1": 3,
      "max_depth": 2,
      "min_samples_split": 2,
      "depth_range": 1,
      "estimator_range": 1,
      "n_estimators": 1,
      "min_samples_leaf": 1
    },
    "sklearn.model_selection._validation.validation_curve.cv": {
      "None": 7,
      "3": 7,
      "skf": 4,
      "kf": 3,
      "cv": 3,
      "5": 3,
      "4": 2,
      "10": 2,
      "StratifiedShuffleSplit(5, random_state=1, test_size=0.1)": 1
    },
    "sklearn.tree._export.export_graphviz.max_depth": {
      "None": 144,
      "10": 25,
      "4": 15,
      "3": 8,
      "2": 7,
      "5": 1,
      "6": 1,
      "7": 1
    },
    "sklearn.svm._classes.LinearSVR.__init__.random_state": {
      "None": 34,
      "42": 5,
      "0": 5,
      "1": 3,
      "71": 2,
      "2021": 1,
      "1017": 1,
      "1994": 1,
      "198": 1,
      "10": 1
    },
    "sklearn.svm._classes.LinearSVR.__init__.tol": {
      "0.0001": 50,
      "0.001": 2,
      "0.01": 1,
      "1e-05": 1
    },
    "sklearn.svm._classes.LinearSVR.__init__.C": {
      "1.0": 37,
      "0.1": 3,
      "1.2": 2,
      "10": 2,
      "0.05": 2,
      "333": 1,
      "1": 1,
      "0.01": 1,
      "0.2": 1,
      "0.0005": 1,
      "0.025": 1,
      "parameter[0]": 1,
      "C": 1
    },
    "sklearn.svm._classes.LinearSVR.fit.X": {
      "X_train": 7,
      "X": 4,
      "train": 3,
      "dfe": 2,
      "trainFactors": 1,
      "trn_data": 1,
      "X_text[:n_train]": 1,
      "train_feature[tr]": 1,
      "train_x": 1,
      "train_data": 1,
      "training_features": 1,
      "X_t": 1,
      "tr_x": 1,
      "features_train": 1,
      "train_tfIdf.todense()": 1,
      "Xtrain": 1
    },
    "sklearn.svm._classes.LinearSVR.fit.y": {
      "y_train": 7,
      "target": 3,
      "y": 2,
      "Y_train": 2,
      "target_fe": 2,
      "trainResponse": 1,
      "df_target": 1,
      "score[tr]": 1,
      "df_train.target": 1,
      "train['log_loss']": 1,
      "log_train_prices": 1,
      "training_target": 1,
      "df.target": 1,
      "train_target": 1,
      "tr_y": 1,
      "label_train": 1,
      "ytrain": 1
    },
    "sklearn.model_selection._split.TimeSeriesSplit.__init__.gap": {
      "0": 125,
      "date_gap_num": 1,
      "1": 1
    },
    "sklearn.metrics._classification.brier_score_loss.y_true": {
      "dev_y": 5,
      "y_test": 2,
      "Y_valid": 1
    },
    "sklearn.metrics._classification.brier_score_loss.y_prob": {
      "guess_dev": 5,
      "prob_pos": 3
    },
    "sklearn.metrics._classification.hinge_loss.y_true": {
      "dev_y": 5,
      "y_true": 3,
      "(y_true - 0.5) * 2": 1,
      "y_val.argmax(axis=1)": 1,
      "y_true.argmax(axis=1)": 1
    },
    "sklearn.metrics._classification.hinge_loss.pred_decision": {
      "guess_dev_negative_one": 4,
      "raw": 2,
      "y_pred": 2,
      "guess_dev": 1,
      "np.loadtxt('pred_margins.txt')": 1,
      "(y_scores - 0.5) * 2": 1
    },
    "sklearn.feature_extraction._hash.FeatureHasher.__init__.input_type": {
      "'string'": 22
    },
    "sklearn.feature_selection._univariate_selection.SelectFpr.__init__.alpha": {
      "0.001": 2,
      "0.02": 1,
      "0.03": 1,
      "1e-06": 1
    },
    "sklearn.feature_selection._univariate_selection.SelectFpr.__init__.score_func": {
      "f_classif": 4,
      "mutual_info_classif": 1
    },
    "sklearn.preprocessing._encoders.OrdinalEncoder.__init__.handle_unknown": {
      "'error'": 298,
      "'ignore'": 15,
      "'use_encoded_value'": 13
    },
    "sklearn.preprocessing._encoders.OrdinalEncoder.__init__.unknown_value": {
      "None": 313,
      "np.nan": 4,
      "-1": 4,
      "-99": 3,
      "999": 1,
      "-10": 1
    },
    "sklearn.manifold._t_sne.TSNE.__init__.early_exaggeration": {
      "12.0": 528,
      "12": 3,
      "60": 2,
      "5": 1,
      "50": 1,
      "4": 1
    },
    "sklearn.compose._column_transformer.ColumnTransformer.__init__.remainder": {
      "'drop'": 321,
      "'passthrough'": 120,
      "remainder": 1,
      "num_imputer": 1
    },
    "sklearn.datasets._samples_generator.make_classification.n_samples": {
      "100": 18,
      "2000": 13,
      "1000": 11,
      "768": 8,
      "1024": 7,
      "512": 4,
      "100000": 3,
      "40": 3,
      "n_samples": 2,
      "500": 2,
      "400000": 1,
      "N": 1,
      "total_train_rows + total_test_rows": 1,
      "10": 1,
      "700": 1,
      "5000": 1,
      "NUM_SAMPLES": 1,
      "20000": 1
    },
    "sklearn.datasets._samples_generator.make_classification.n_features": {
      "20": 17,
      "2": 17,
      "100": 12,
      "512": 6,
      "255": 5,
      "3": 4,
      "5": 3,
      "n_features": 2,
      "useful[k % 512]": 2,
      "useful[k]": 2,
      "10": 2,
      "50": 1,
      "M": 1,
      "15": 1,
      "4": 1,
      "40": 1,
      "NUM_FEATURES": 1,
      "feats": 1
    },
    "sklearn.datasets._samples_generator.make_classification.n_informative": {
      "2": 30,
      "3": 13,
      "50": 12,
      "40": 7,
      "np.random.randint(33, 47)": 5,
      "1": 3,
      "useful[k % 512]": 2,
      "useful[k]": 2,
      "n_info": 1,
      "5": 1,
      "useful_cols_count": 1,
      "random.randint(33, 47)": 1,
      "10": 1
    },
    "sklearn.datasets._samples_generator.make_classification.n_redundant": {
      "0": 43,
      "2": 26,
      "1": 8,
      "5": 1,
      "15": 1
    },
    "sklearn.metrics._classification.log_loss.eps": {
      "1e-15": 4050,
      "1e-07": 26,
      "eps": 1,
      "1e-06": 1
    },
    "sklearn.metrics._classification.log_loss.normalize": {
      "True": 4077,
      "False": 1
    },
    "sklearn.metrics._classification.log_loss.sample_weight": {
      "None": 4070,
      "weights": 2,
      "[2] * 78545 + [1] * 78545 * 5": 1,
      "[1] * 78545 * 5 + [2] * 78545": 1,
      "sample_weights * CLF_dict[c]['Prediction'].shape[0]": 1,
      "sample_weights * Yval.shape[0]": 1,
      "sum_weights": 1,
      "val_w": 1
    },
    "sklearn.preprocessing._data.minmax_scale.feature_range": {
      "(0, 1)": 422,
      "MIN_MAX": 4,
      "(-1, 1)": 3,
      "(-0.1, 1.175)": 2,
      "(0, min(1, max(0.01, x.max())))": 1,
      "(1, 5)": 1
    },
    "sklearn.linear_model._least_angle.LassoLars.__init__.normalize": {
      "True": 11,
      "False": 1
    },
    "sklearn.decomposition._nmf.NMF.__init__.n_components": {
      "n_components": 36,
      "5": 5,
      "n_comp": 4,
      "2": 3,
      "50": 2,
      "20": 2,
      "n_col": 2,
      "nb_comp": 1,
      "nmfNC": 1,
      "components": 1,
      "NMF_FEATURES": 1,
      "num_topics": 1,
      "num_classes": 1,
      "k": 1,
      "26": 1,
      "128": 1,
      "200": 1,
      "no_topics": 1
    },
    "sklearn.decomposition._nmf.NMF.__init__.init": {
      "'warn'": 55,
      "'random'": 4,
      "'nndsvd'": 3,
      "'nndsvdar'": 2,
      "None": 1
    },
    "sklearn.decomposition._nmf.NMF.__init__.random_state": {
      "1337": 27,
      "None": 10,
      "seed": 9,
      "1": 4,
      "42": 3,
      "0": 2,
      "100": 2,
      "69": 2,
      "10": 2,
      "420": 2,
      "random_seed": 1,
      "SEED": 1
    },
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__.n_estimators": {
      "800": 2,
      "200": 1,
      "100": 1,
      "trees": 1,
      "n_estimator": 1,
      "300": 1
    },
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__.random_state": {
      "0": 3,
      "42": 2,
      "seed_val": 1,
      "seed": 1
    },
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__.max_depth": {
      "5": 2,
      "3": 2,
      "depth": 1,
      "8": 1,
      "7": 1
    },
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.__init__.eigen_solver": {
      "'auto'": 6,
      "'dense'": 1
    },
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.__init__.method": {
      "'standard'": 6,
      "method": 1
    },
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.fit_transform.X": {
      "r": 2,
      "X_plot": 1,
      "X": 1,
      "df": 1
    },
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.transform.X": {
      "r": 4,
      "r[:, :50]": 1
    },
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.__init__.n_neighbors": {
      "5": 4,
      "10": 2,
      "n_neighbors": 1
    },
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.__init__.n_components": {
      "2": 5,
      "n_components": 1,
      "150": 1
    },
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.__init__.random_state": {
      "None": 4,
      "42": 2,
      "1": 1
    },
    "sklearn.decomposition._nmf.NMF.fit_transform.X": {
      "tfidf_col": 28,
      "tfidf": 4,
      "train.drop(['y'], axis=1)": 2,
      "train": 2,
      "X_tfidf": 1,
      "tfidf_ind": 1,
      "temp_on": 1,
      "temp_off": 1,
      "train_X_to_select": 1,
      "test_X_to_select": 1,
      "X_train_sc": 1
    },
    "sklearn.neighbors._regression.KNeighborsRegressor.__init__.n_jobs": {
      "None": 300,
      "-1": 48,
      "1": 5,
      "4": 2,
      "n_jobs": 1
    },
    "sklearn.ensemble._voting.VotingRegressor.__init__.weights": {
      "None": 53,
      "[0.1, 0.1, 0.2, 0.4, 0.2]": 1,
      "[1, 1]": 1,
      "[1, 1, 1, 1]": 1,
      "[0.5, 0.5]": 1,
      "[1.1, 1]": 1
    },
    "sklearn.preprocessing._data.QuantileTransformer.inverse_transform.X": {
      "d.reshape(-1, 1)": 11,
      "best_models[2].predict(X_test.drop('Date', axis=1)).reshape(-1, 1)": 1,
      "z": 1,
      "val.reshape(-1, 1)": 1,
      "predictions": 1,
      "model.predict(X_val)": 1,
      "model.predict(X_test)": 1
    },
    "sklearn.multioutput.RegressorChain.fit.X": {
      "X_train": 3,
      "x": 2,
      "x_train": 1,
      "x_train_sub": 1
    },
    "sklearn.multioutput.RegressorChain.fit.Y": {
      "y_train": 4,
      "y": 2,
      "y_train_sub": 1
    },
    "sklearn.metrics._classification.precision_score.zero_division": {
      "'warn'": 1116,
      "0": 35,
      "1": 2
    },
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.vocabulary": {
      "None": 3186,
      "all_ingredients_union": 10,
      "list(set([str(i).lower() for i in ingredients]))": 4,
      "vocab": 3,
      "words": 2,
      "all_ingredients": 2,
      "list(set(trn_words).intersection(set(sub_words)))": 2,
      "model.wv.index2word": 1,
      "com_feature": 1,
      "ingredient_vocab": 1,
      "Vt_['word']": 1,
      "np.unique(wb)": 1,
      "list(set([str(i).lower() for i in all_ingredients]))": 1
    },
    "sklearn.model_selection._split.TimeSeriesSplit.split.y": {
      "None": 45,
      "y": 15,
      "y_train": 15,
      "Y": 1,
      "train.iloc[:train_length][target_cols]": 1
    },
    "sklearn.linear_model._theil_sen.TheilSenRegressor.__init__.random_state": {
      "None": 22,
      "42": 3,
      "0": 1
    },
    "sklearn.feature_selection._base.SelectorMixin.inverse_transform.X": {
      "X_num_train": 18,
      "X_num_test": 18,
      "X_new": 12,
      "X_selected": 1,
      "temp": 1
    },
    "sklearn.svm._classes.NuSVR.__init__.kernel": {
      "'rbf'": 54,
      "'linear'": 1,
      "trial.suggest_categorical('kernel', ['rbf'])": 1
    },
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.n_init": {
      "1": 223,
      "10": 14,
      "5": 9,
      "50": 5,
      "3": 5,
      "n_init": 3,
      "2": 2,
      "20": 1,
      "4": 1,
      "CLUSTER_GMM_N_INIT": 1,
      "7": 1,
      "6": 1
    },
    "sklearn.model_selection._split.PredefinedSplit.__init__.test_fold": {
      "np.concatenate((train_ind, val_ind))": 8,
      "validation_split": 2,
      "test_fold": 2,
      "split_index": 1,
      "tmp['_is_val'].values": 1
    },
    "sklearn.preprocessing._data.Binarizer.fit.X": {
      "X_train": 9,
      "X_test": 9,
      "X_train_init": 4,
      "X_test_init": 4,
      "X_train1": 1
    },
    "sklearn.feature_selection._variance_threshold.VarianceThreshold.fit.y": {
      "None": 241,
      "y_train1": 1,
      "y": 1
    },
    "sklearn.preprocessing._data.MinMaxScaler.fit.y": {
      "None": 519,
      "y_train1": 1,
      "y_train": 1
    },
    "sklearn.svm._classes.NuSVR.__init__.tol": {
      "0.001": 38,
      "0.01": 16,
      "5e-05": 1,
      "0.0001": 1
    },
    "sklearn.impute._iterative.IterativeImputer.__init__.missing_values": {
      "np.nan": 51,
      "0": 4
    },
    "sklearn.impute._iterative.IterativeImputer.__init__.sample_posterior": {
      "False": 51,
      "True": 4
    },
    "sklearn.impute._iterative.IterativeImputer.__init__.min_value": {
      "-np.inf": 50,
      "1": 4,
      "0": 1
    },
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.eps": {
      "0.001": 82,
      "1e-07": 2,
      "0.05": 1
    },
    "sklearn.ensemble._stacking.StackingRegressor.__init__.cv": {
      "None": 47,
      "5": 6,
      "10": 4,
      "8": 3,
      "kfolds": 2,
      "4": 1,
      "cv": 1,
      "6": 1
    },
    "sklearn.ensemble._stacking.StackingRegressor.fit.X": {
      "X_train": 17,
      "X": 14,
      "X_tr": 2,
      "x": 2,
      "train_X": 2,
      "X_train_pc": 1,
      "X_train_fe": 1,
      "X_train_numeric": 1,
      "x_train": 1,
      "train": 1,
      "model_data.iloc[:, 1:]": 1,
      "train_model_sc": 1,
      "Xtrain": 1,
      "X_train_tree": 1,
      "train_feature": 1
    },
    "sklearn.ensemble._stacking.StackingRegressor.fit.y": {
      "y_train": 21,
      "y": 14,
      "y_tr": 2,
      "Y_train": 2,
      "confirmed_cases": 1,
      "fatalities": 1,
      "train_y": 1,
      "model_data.iloc[:, 0:1]": 1,
      "train_label": 1,
      "ytrain": 1,
      "train_Y": 1,
      "train['target']": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.average": {
      "False": 837,
      "True": 4
    },
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.fit_intercept": {
      "True": 841
    },
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.power_t": {
      "0.5": 841
    },
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.verbose": {
      "0": 838,
      "50": 1,
      "1": 1,
      "2": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.warm_start": {
      "False": 837,
      "True": 4
    },
    "sklearn.utils.class_weight.compute_class_weight.y": {
      "null": 218,
      "y_train": 12,
      "train['target'].values": 4,
      "train_targets": 2,
      "train_data['label']": 1,
      "train_df['target'].values": 1,
      "fold_samp['study_level'].values": 1,
      "df['target'].values": 1,
      "train['label']": 1,
      "train_df['target']": 1,
      "dfy_train": 1,
      "train['toxic'].values": 1,
      "valid['toxic'].values": 1,
      "np.argmax(Y_train, axis=1)": 1,
      "labels": 1,
      "self.samples[:, 1]": 1,
      "ytdf": 1,
      "y_val": 1,
      "train_labels": 1
    },
    "sklearn.utils.class_weight.compute_class_weight.classes": {
      "null": 218,
      "np.unique(y_train)": 11,
      "np.unique(train['target'].values)": 4,
      "np.unique(train_targets)": 2,
      "[0, 1]": 2,
      "np.unique(train_data['label'])": 1,
      "np.unique(train_df['target'].values)": 1,
      "np.unique(fold_samp['study_level'].values)": 1,
      "np.unique(df['target'].values)": 1,
      "train['label'].unique()": 1,
      "classes": 1,
      "np.unique(dfy_train)": 1,
      "np.unique(train['toxic'].values)": 1,
      "np.unique(valid['toxic'].values)": 1,
      "np.arange(classes_size)": 1,
      "np.unique(labels)": 1,
      "target_names": 1,
      "np.unique(ytdf)": 1,
      "np.unique(train_labels)": 1
    },
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.input": {
      "'content'": 3215
    },
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.preprocessor": {
      "None": 3109,
      "get_col('description')": 25,
      "lambda x: x": 16,
      "get_col('title')": 7,
      "build_preprocessor('item_description', arr)": 5,
      "clean_text": 5,
      "build_preprocessor('item_description')": 4,
      "dummy": 2,
      "build_preprocessor('name', arr)": 2,
      "build_preprocessor('nameL', arr)": 2,
      "build_preprocessor('nameWL', arr)": 2,
      "build_preprocessor('brand_name', arr)": 2,
      "build_preprocessor('bmcn', arr)": 2,
      "build_preprocessor('cnbm_max', arr)": 2,
      "build_preprocessor('cnbm_min', arr)": 2,
      "build_preprocessor('maxs', arr)": 2,
      "build_preprocessor('item_descriptionL', arr)": 2,
      "build_preprocessor('item_descriptionWL', arr)": 2,
      "preprocessor('item_description')": 2,
      "stripString": 2,
      "preprocessor": 2,
      "preprocess_text": 2,
      "lambda x: x['project_resource_summary']": 1,
      "lambda x: x['student_description']": 1,
      "lambda x: x['project_description']": 1,
      "lambda x: x['collated_description']": 1,
      "as_it_is": 1,
      "get_col('text')": 1,
      "get_col('project_resource_summary')": 1,
      "get_col('project_title')": 1,
      "build_preprocessor('JOB_DUTIES')": 1,
      "build_preprocessor('REQUIREMENTS')": 1,
      "build_preprocessor('EXP_JOB_CLASS_FUNCTION')": 1,
      "build_preprocessor('comment_text')": 1,
      "build_preprocessor('comment_text_char')": 1,
      "prep_remove_html": 1
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.C": {
      "1.0": 9,
      "1e-05": 1,
      "0.0001": 1
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.fit_intercept": {
      "True": 11
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.max_iter": {
      "1000": 11
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.tol": {
      "0.001": 10,
      "0.0001": 1
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.shuffle": {
      "True": 11
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.verbose": {
      "0": 9,
      "1": 1,
      "10": 1
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.loss": {
      "'epsilon_insensitive'": 9,
      "'squared_epsilon_insensitive'": 2
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.epsilon": {
      "DEFAULT_EPSILON": 10,
      "1e-05": 1
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.random_state": {
      "None": 6,
      "123": 2,
      "SEED": 1,
      "1017": 1,
      "42": 1
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.warm_start": {
      "False": 8,
      "True": 3
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.average": {
      "False": 10,
      "True": 1
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.fit.X": {
      "X_t": 2,
      "col_tr.fit_transform(X_train[cols])": 1,
      "col_tr.transform(X_valid[cols])": 1,
      "train_feature[tr]": 1,
      "train[col]": 1
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.fit.y": {
      "y_t": 2,
      "y_train": 1,
      "y_valid": 1,
      "score[tr]": 1,
      "train['logerror']": 1
    },
    "sklearn.linear_model._coordinate_descent.Lasso.__init__.tol": {
      "0.0001": 728,
      "0.01": 7,
      "0.001": 4,
      "1": 3,
      "0.005": 1,
      "0.5": 1,
      "1e-06": 1,
      "0.1": 1,
      "0.0925": 1,
      "1e-05": 1
    },
    "sklearn.linear_model._coordinate_descent.Lasso.__init__.positive": {
      "False": 743,
      "True": 5
    },
    "sklearn.linear_model._coordinate_descent.Lasso.__init__.selection": {
      "'cyclic'": 728,
      "'random'": 20
    },
    "sklearn.compose._target.TransformedTargetRegressor.__init__.func": {
      "None": 10,
      "np.log1p": 7,
      "np.log": 4,
      "np.sqrt": 2
    },
    "sklearn.compose._target.TransformedTargetRegressor.__init__.inverse_func": {
      "None": 10,
      "np.expm1": 6,
      "np.exp": 5,
      "np.square": 2
    },
    "sklearn.svm._classes.LinearSVR.__init__.epsilon": {
      "0.0": 48,
      "0": 1,
      "1.5": 1,
      "0.3": 1,
      "0.01": 1,
      "5.0": 1,
      "0.001": 1
    },
    "sklearn.svm._classes.LinearSVR.__init__.loss": {
      "'epsilon_insensitive'": 49,
      "'squared_epsilon_insensitive'": 5
    },
    "sklearn.svm._classes.LinearSVR.__init__.fit_intercept": {
      "True": 52,
      "False": 2
    },
    "sklearn.svm._classes.LinearSVR.__init__.intercept_scaling": {
      "1.0": 53,
      "1": 1
    },
    "sklearn.svm._classes.LinearSVR.__init__.dual": {
      "True": 54
    },
    "sklearn.svm._classes.LinearSVR.__init__.verbose": {
      "0": 50,
      "True": 2,
      "1": 2
    },
    "sklearn.svm._classes.LinearSVR.__init__.max_iter": {
      "1000": 48,
      "10000": 3,
      "50": 1,
      "2000": 1,
      "500": 1
    },
    "sklearn.cluster._dbscan.DBSCAN.__init__.leaf_size": {
      "30": 100,
      "20": 2,
      "50": 1
    },
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.__init__.contamination": {
      "outliers_fraction": 12,
      "0.05": 1,
      "0.016": 1,
      "0.025": 1,
      "0.03": 1,
      "0.01": 1,
      "outlier_ratio_0": 1,
      "outlier_ratio_1": 1
    },
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.__init__.random_state": {
      "None": 18,
      "2020": 1
    },
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.fit.X": {
      "X_train": 9,
      "x_train": 2,
      "X_pos": 2,
      "Xpca": 1
    },
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.predict.X": {
      "X_train": 9,
      "x_train": 2,
      "X_pos": 2,
      "Xpca": 1,
      "X_test_pca": 1
    },
    "sklearn.datasets._samples_generator.make_blobs.random_state": {
      "42": 2,
      "0": 1,
      "None": 1
    },
    "sklearn.datasets._samples_generator.make_blobs.n_samples": {
      "1000": 2,
      "300": 1,
      "100": 1
    },
    "sklearn.preprocessing._data.minmax_scale.axis": {
      "0": 383,
      "axis": 44,
      "1": 6
    },
    "sklearn.model_selection._validation.learning_curve.n_jobs": {
      "-1": 55,
      "n_jobs": 42,
      "None": 25,
      "1": 4,
      "jobsInParallel": 2,
      "4": 1
    },
    "sklearn.feature_extraction.text.CountVectorizer.__init__.decode_error": {
      "'strict'": 2920,
      "'replace'": 10,
      "'ignore'": 7
    },
    "sklearn.metrics._regression.median_absolute_error.y_true": {
      "y_test": 11,
      "Y": 5,
      "y_train": 4,
      "y_valid": 2,
      "y_val": 2,
      "target_train": 1,
      "y_true": 1
    },
    "sklearn.metrics._regression.median_absolute_error.y_pred": {
      "pred": 5,
      "y_pred": 5,
      "y_train_pred": 1,
      "y_test_pred": 1,
      "predictions": 1,
      "predictions_test": 1,
      "np.ones_like(Y.values) * 6.5": 1,
      "np.ones_like(Y.values) * 4.5": 1,
      "mean * np.ones_like(Y)": 1,
      "median * np.ones_like(Y)": 1,
      "geom_mean * np.ones_like(Y)": 1,
      "prediction": 1,
      "y_train_reg": 1,
      "y_test_reg": 1,
      "target_train_predict": 1,
      "y_train_pred_xgb": 1,
      "y_test_pred_xgb": 1,
      "y_predict_dummy_median": 1
    },
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups.subset": {
      "'train'": 11,
      "'test'": 6,
      "'all'": 1
    },
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups.download_if_missing": {
      "True": 18
    },
    "sklearn.gaussian_process.kernels.RBF.__init__.length_scale": {
      "1.0": 8,
      "[1.0, 1.0, 1.0, 1.0]": 2,
      "1": 2,
      "0.0001": 1
    },
    "sklearn.gaussian_process.kernels.RBF.__init__.length_scale_bounds": {
      "(1e-05, 100000.0)": 8,
      "(0.01, 100.0)": 2,
      "(0.0001, 1000.0)": 1,
      "(3.0, 3000.0)": 1,
      "(0.1, 10.0)": 1
    },
    "sklearn.gaussian_process.kernels.WhiteKernel.__init__.noise_level": {
      "4.0 * full_df_y_var": 1,
      "1.0": 1
    },
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.__init__.kernel": {
      "None": 8,
      "kernel": 2,
      "gp_kernel": 1
    },
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.fit.X": {
      "Xx": 2,
      "train[features].apply(expit).values.reshape(-1, len(features))": 1,
      "xtr1.to_numpy()[idx_Mi8, 0].reshape(-1, 1)": 1,
      "train_x": 1,
      "X_train": 1,
      "train_tfIdf.todense()": 1
    },
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.fit.y": {
      "y_train": 2,
      "Yt": 2,
      "train[target_col].values.reshape(-1, 1)": 1,
      "np.array(ytr1[idx_Mi8].ravel()).reshape(-1, 1)": 1,
      "train_y": 1
    },
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.predict.X": {
      "Xx": 2,
      "features_values": 1,
      "test_x": 1,
      "predictable": 1,
      "val_tfIdf.todense()": 1,
      "X_test_tfIdf.todense()": 1
    },
    "sklearn.metrics.pairwise.cosine_similarity.Y": {
      "None": 28,
      "j": 6,
      "text_tfidf": 4,
      "v123": 4,
      "s_embeds": 4,
      "topic_text.fillna(0)": 3,
      "val_y_pred.reshape(1, -1)": 3,
      "V1[:rank, :].T": 3,
      "wiki.loc[['cat', 'dog']]": 3,
      "glove.loc[['cat', 'dog']]": 3,
      "b": 2,
      "temp.drop('Patient', 1)": 2,
      "features_arr[idx_2]": 2,
      "img_features_arr[idx_2]": 2,
      "embeddings": 2,
      "q_vec.reshape(1, -1)": 2,
      "monet_vecs": 2,
      "processed_text_matrix": 1,
      "new_item_tfidf": 1,
      "tfidf_matrix": 1,
      "ar2": 1,
      "description": 1,
      "new": 1,
      "train_embeds": 1,
      "features[corpus_start_idx:corpus_end_idx]": 1,
      "count_vec_matrix": 1,
      "[row['question2_sent_embeddings']]": 1,
      "docs_tfidf": 1,
      "query_embedding": 1,
      "factors": 1,
      "qs_transformed": 1,
      "Qs_transformed": 1,
      "vectors": 1,
      "vj": 1,
      "hypothesis[n].reshape(1, -1)": 1,
      "duties_vectors": 1,
      "[B]": 1,
      "tfidf_matrix.T": 1,
      "bow_vector.reshape(1, -1)": 1,
      "tfidf_vector.reshape(1, -1)": 1,
      "test_tf_df": 1,
      "base_embeds": 1,
      "model_base_embeds": 1,
      "feature": 1,
      "vec_question": 1,
      "train_data_features2td": 1,
      "image2": 1,
      "corpus": 1,
      "Vx2.T": 1,
      "TRu_[len(train) + len(test):]": 1,
      "TRvh_.T": 1,
      "ugroup": 1,
      "question2_tfidf": 1,
      "bw": 1,
      "UsersU.T": 1,
      "np.hstack((dfidf[-3:], dfidfw[-3:]))": 1,
      "[sent_emb[1]]": 1,
      "[y_pred_nn]": 1,
      "Y": 1,
      "q_query_tfidf": 1,
      "[s_embeds[0]]": 1,
      "corpus[j]": 1,
      "next_embed": 1,
      "self._co_vectors": 1,
      "word_embeddings_test": 1,
      "cs_tf": 1,
      "X_question_text": 1,
      "prof_dtm": 1,
      "encoding_mat": 1,
      "wv2.reshape(1, -1)": 1,
      "mat": 1,
      "t_p_scores": 1,
      "f_p_scores": 1,
      "g_p_scores": 1,
      "y": 1,
      "[vec2]": 1
    },
    "sklearn.preprocessing._data.scale.with_mean": {
      "True": 311,
      "'True'": 3
    },
    "sklearn.preprocessing._data.scale.with_std": {
      "True": 311,
      "'True'": 3
    },
    "sklearn.metrics._ranking.ndcg_score.y_true": {
      "y_test_enc": 1,
      "y_test_enc_": 1
    },
    "sklearn.metrics._ranking.ndcg_score.y_score": {
      "y_pred": 1,
      "y_pred_": 1
    },
    "sklearn.metrics._ranking.ndcg_score.k": {
      "5": 2
    },
    "sklearn.metrics._ranking.ndcg_score.sample_weight": {
      "None": 2
    },
    "sklearn.metrics._ranking.ndcg_score.ignore_ties": {
      "False": 2
    },
    "sklearn.ensemble._bagging.BaggingClassifier.__init__.bootstrap": {
      "True": 186
    },
    "sklearn.ensemble._bagging.BaggingClassifier.__init__.n_jobs": {
      "None": 161,
      "-1": 18,
      "4": 4,
      "1": 3
    },
    "sklearn.metrics._classification.confusion_matrix.normalize": {
      "None": 4425,
      "'true'": 32,
      "normalize": 2,
      "'all'": 1
    },
    "sklearn.feature_extraction.text.TfidfVectorizer.__init__.dtype": {
      "np.float64": 3125,
      "np.float32": 82,
      "'int32'": 4,
      "np.uint8": 3,
      "np.int16": 1
    },
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.ngram_range": {
      "(1, 1)": 29,
      "(1, 2)": 19,
      "(1, 3)": 13,
      "(1, 5)": 2,
      "(1, 4)": 1,
      "(2, 2)": 1,
      "(3, 6)": 1
    },
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.lowercase": {
      "True": 36,
      "False": 30
    },
    "sklearn.feature_extraction.text.HashingVectorizer.fit_transform.X": {
      "title_text_raw": 1,
      "X_train": 1,
      "Text_1": 1,
      "Text_2": 1,
      "data.ingredients": 1,
      "train_df['question_text']": 1,
      "train_cleaned['comment_text']": 1
    },
    "sklearn.model_selection._validation.cross_validate.verbose": {
      "0": 276,
      "1": 13,
      "10": 5,
      "False": 4,
      "3": 1
    },
    "sklearn.model_selection._validation.cross_validate.return_estimator": {
      "False": 276,
      "True": 23
    },
    "sklearn.svm._classes.LinearSVC.__init__.class_weight": {
      "None": 445,
      "'balanced'": 7,
      "{0: 0.07, 1: 1}": 1
    },
    "sklearn.impute._base.SimpleImputer.__init__.verbose": {
      "0": 1135,
      "1": 3,
      "VERBOSE": 1,
      "-1": 1
    },
    "sklearn.impute._base.SimpleImputer.__init__.copy": {
      "True": 1134,
      "False": 6
    },
    "sklearn.model_selection._validation.cross_val_predict.fit_params": {
      "None": 212,
      "fit_params": 2
    },
    "sklearn.model_selection._validation.validation_curve.verbose": {
      "0": 21,
      "2": 6,
      "True": 3,
      "1": 2
    },
    "sklearn.preprocessing._data.MinMaxScaler.__init__.copy": {
      "True": 2271,
      "False": 26
    },
    "sklearn.linear_model._bayes.BayesianRidge.__init__.alpha_init": {
      "None": 193,
      "0.0001": 1
    },
    "sklearn.multioutput.MultiOutputRegressor.__init__.n_jobs": {
      "None": 71,
      "-1": 8,
      "n_jobs": 1,
      "4": 1
    },
    "sklearn.linear_model._bayes.BayesianRidge.__init__.normalize": {
      "False": 186,
      "True": 8
    },
    "sklearn.utils.shuffle.n_samples": {
      "None": 787,
      "undersampled_nb_0": 27,
      "3000000": 1,
      "1000000": 1,
      "1000": 1,
      "undersampling_nb_0": 1,
      "undersampled_no_0": 1,
      "undersampled_records_0": 1,
      "under_sample_len": 1
    },
    "sklearn.linear_model._logistic.LogisticRegression.__init__.intercept_scaling": {
      "1": 5121,
      "1.0": 3,
      "intercept_scaling": 3,
      "1000.0": 1,
      "0.0001": 1
    },
    "sklearn.feature_selection._rfe.RFE.__init__.verbose": {
      "0": 133,
      "5": 4,
      "3": 2,
      "2": 2,
      "1": 1
    },
    "sklearn.svm._classes.SVC.__init__.decision_function_shape": {
      "'ovr'": 1627,
      "None": 33,
      "'ovo'": 15
    },
    "sklearn.preprocessing._data.PolynomialFeatures.__init__.interaction_only": {
      "False": 525,
      "True": 37
    },
    "sklearn.datasets._samples_generator.make_classification.random_state": {
      "None": 25,
      "random_state": 13,
      "47": 11,
      "10": 8,
      "0": 5,
      "1": 4,
      "5": 3,
      "7": 2,
      "42": 2,
      "123": 1,
      "3228 + i": 1,
      "125": 1,
      "577": 1,
      "random_seed": 1,
      "rnd": 1
    },
    "sklearn.datasets._samples_generator.make_classification.n_classes": {
      "2": 64,
      "n_classes": 12,
      "1": 1,
      "3": 1,
      "5": 1
    },
    "sklearn.tree._classes.DecisionTreeClassifier.__init__.max_leaf_nodes": {
      "None": 1514,
      "4": 5,
      "6": 4,
      "8": 4,
      "max_leaf_nodes": 3,
      "5": 2,
      "best_leaf_node": 2,
      "n": 2,
      "21": 2,
      "2": 1,
      "num_leaf_node": 1,
      "leaf": 1,
      "91": 1,
      "40": 1,
      "25": 1,
      "dt_grid.best_params_.get('max_leaf_nodes')": 1,
      "nn": 1,
      "22": 1,
      "3": 1
    },
    "sklearn.tree._classes.DecisionTreeClassifier.__init__.min_weight_fraction_leaf": {
      "0.0": 1546,
      "fraction": 1,
      "0.01": 1
    },
    "sklearn.tree._classes.BaseDecisionTree.apply.X": {
      "data": 1,
      "test_data": 1
    },
    "sklearn.ensemble._bagging.BaggingRegressor.__init__.n_jobs": {
      "None": 126,
      "-1": 14,
      "10": 1,
      "1": 1
    },
    "sklearn.impute._knn.KNNImputer.__init__.n_neighbors": {
      "5": 24,
      "2": 11,
      "3": 9,
      "20": 4,
      "40": 3,
      "6": 2,
      "9": 2,
      "23": 2,
      "10": 2,
      "k": 1,
      "27": 1,
      "15": 1,
      "int(s)": 1,
      "n": 1
    },
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.n_components": {
      "X.shape[1]": 6,
      "4": 5,
      "6": 5,
      "np.sum(dpgmm.weights_ > np.quantile(dpgmm.weights_, 0.95))": 3,
      "1": 3,
      "5": 1,
      "np.sum(dpgmm.weights_ > np.quantile(dpgmm.weights_, 0.9))": 1,
      "np.sum(dpgmm.weights_ > np.quantile(dpgmm.weights_, 0.85))": 1
    },
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.random_state": {
      "None": 12,
      "2019": 10,
      "42": 3
    },
    "sklearn.metrics._plot.roc_curve.plot_roc_curve.name": {
      "None": 39,
      "'ROC fold {}'.format(i)": 2,
      "'ROC-TP/FP'": 1,
      "'Baseline'": 1
    },
    "sklearn.metrics._plot.roc_curve.plot_roc_curve.ax": {
      "None": 39,
      "ax": 2,
      "ax[1]": 1,
      "ax[i]": 1
    },
    "sklearn.preprocessing._label.MultiLabelBinarizer.fit.y": {
      "train.labels.apply(lambda x: x.split())": 8,
      "label_split": 4,
      "resized_train['labels']": 3,
      "train_df.labels.apply(lambda x: x.split())": 3,
      "classes": 3,
      "df['labels']": 3,
      "df.labels": 2,
      "train_labels.labels.apply(lambda x: x.split())": 2,
      "train['new_labels']": 1,
      "data['labels']": 1,
      "[labels]": 1,
      "targets": 1,
      "[range(N_CLASSES)]": 1,
      "[features]": 1,
      "labels": 1,
      "df_labels": 1,
      "split_tags": 1,
      "train_label": 1,
      "np.hstack([df_train['category_split'], df_test['category_split']])": 1,
      "[news_train_df.provider.cat.categories.values]": 1,
      "[news_train_df.headlineTag.cat.categories.values]": 1,
      "flat_cats": 1
    },
    "sklearn.preprocessing._label.MultiLabelBinarizer.transform.y": {
      "train.labels.apply(lambda x: x.split())": 8,
      "label_split": 4,
      "train_labels.labels.apply(lambda x: x.split())": 4,
      "resized_train['labels']": 3,
      "train_df.labels.apply(lambda x: x.split())": 3,
      "[target]": 3,
      "df['labels']": 3,
      "X['features']": 2,
      "[item.split() for item in val_labels]": 2,
      "[item.split() for item in train_labels]": 2,
      "validation['labelId']": 1,
      "data['labels']": 1,
      "data['pred']": 1,
      "targets": 1,
      "[label]": 1,
      "single_labels": 1,
      "X_train['features'].apply(flt)": 1,
      "X_test['features'].apply(flt)": 1,
      "df_test['category_list'].fillna('nan')": 1,
      "[item.split() for item in val_ids['Target']]": 1,
      "[i.split(',') for i in list(test_df['labels'])]": 1,
      "[i.split(',') for i in list(cv_df['labels'])]": 1,
      "test_data": 1,
      "df_labels": 1,
      "test_df.ingredients": 1,
      "data['car_features']": 1,
      "train_label": 1
    },
    "sklearn.tree._classes.DecisionTreeClassifier.__init__.min_impurity_decrease": {
      "0.0": 1547,
      "self.min_impurity_decrease": 1
    },
    "sklearn.tree._classes.DecisionTreeClassifier.__init__.min_impurity_split": {
      "None": 1544,
      "1e-07": 2,
      "2": 2
    },
    "sklearn.metrics._classification.classification_report.labels": {
      "None": 3044,
      "[0, 1]": 4,
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]": 4,
      "[1, 0]": 3,
      "model1.classes_": 2,
      "model2.classes_": 2,
      "list(label_dict.keys())": 1,
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]": 1,
      "np.arange(39)": 1,
      "[True, False]": 1,
      "classes": 1,
      "[x for x in range(0, 10)]": 1,
      "range(len(CLASSES))": 1,
      "[0, 1, 2]": 1,
      "gbc.classes_": 1,
      "gbc_umap_2.classes_": 1,
      "umap_only['gbc_umap' + str(n_components)].classes_": 1,
      "raw_add_umap['gbc_umap' + str(n_components)].classes_": 1,
      "y_train.cat.categories.tolist()": 1,
      "y_test.cat.categories.tolist()": 1,
      "np.unique(y_true)": 1
    },
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.penalty": {
      "'l2'": 111,
      "'l1'": 14
    },
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.class_weight": {
      "None": 108,
      "'balanced'": 16,
      "'auto'": 1
    },
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.refit": {
      "True": 124,
      "False": 1
    },
    "sklearn.pipeline.Pipeline.__init__.memory": {
      "None": 3692,
      "cache_directory": 8,
      "cachedir": 4,
      "'/tmp'": 2
    },
    "sklearn.preprocessing._data.MaxAbsScaler.__init__.copy": {
      "True": 54,
      "False": 1
    },
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.verbose": {
      "0": 250,
      "-1": 8,
      "1": 4,
      "2": 3,
      "5": 1
    },
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.means_init": {
      "None": 200,
      "ms": 55,
      "[cov.location_ for cov in covs]": 3,
      "np.arange(11).reshape(-1, 1) * delta": 1,
      "mean0": 1,
      "mean1": 1,
      "[[11], [14.5]]": 1,
      "means_init": 1,
      "means_init + noise": 1,
      "np.array(mean_init[i]).reshape(-1, 1) if mean_init[i] else None": 1,
      "init_means": 1
    },
    "sklearn.covariance._shrunk_covariance.ledoit_wolf.X": {
      "r.T": 1
    },
    "sklearn.naive_bayes.GaussianNB.__init__.var_smoothing": {
      "1e-09": 733,
      "nb_grid.best_params_['var_smoothing']": 2,
      "2e-09": 1,
      "0.1": 1,
      "clf.best_params_['var_smoothing']": 1,
      "1e-15": 1,
      "var_smoothing": 1,
      "True": 1
    },
    "sklearn.preprocessing._label.MultiLabelBinarizer.__init__.sparse_output": {
      "False": 168,
      "True": 7
    },
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.beta_1": {
      "0.9": 420,
      "0.6": 2,
      "0.05": 2,
      "0.95": 1,
      "0.85": 1,
      "0.5": 1,
      "0.2": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.beta_2": {
      "0.999": 424,
      "0.9": 2,
      "0.4": 2
    },
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.shuffle": {
      "True": 428
    },
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.warm_start": {
      "False": 419,
      "True": 9
    },
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.validation_fraction": {
      "0.1": 419,
      "0.3": 4,
      "0.25": 2,
      "0.2": 2,
      "0.001": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.learning_rate_init": {
      "0.001": 405,
      "0.0001": 5,
      "0.01": 4,
      "0.0005": 2,
      "mlp_clf.best_params_['learning_rate_init']": 2,
      "0.07": 1,
      "0.08": 1,
      "0.1": 1,
      "0.00029619362959451735": 1,
      "0.0009": 1,
      "0.0012": 1,
      "0.002": 1,
      "mlp_lr": 1,
      "0.003": 1,
      "0.011": 1
    },
    "sklearn.linear_model._bayes.BayesianRidge.__init__.compute_score": {
      "False": 179,
      "True": 15
    },
    "sklearn.feature_extraction.text.CountVectorizer.__init__.strip_accents": {
      "None": 2881,
      "'unicode'": 34,
      "'ascii'": 20,
      "strip_accents": 2
    },
    "sklearn.compose._column_transformer.make_column_selector.__init__.dtype_exclude": {
      "None": 18,
      "'object'": 7,
      "['category']": 2,
      "'category'": 1
    },
    "sklearn.compose._column_transformer.make_column_selector.__init__.dtype_include": {
      "None": 10,
      "'object'": 8,
      "'category'": 2,
      "['object']": 2,
      "object": 2,
      "'float'": 2,
      "[np.int64, np.float64]": 1,
      "['int64', 'float64']": 1
    },
    "sklearn.linear_model._coordinate_descent.ElasticNet.__init__.normalize": {
      "False": 451,
      "True": 16
    },
    "sklearn.feature_extraction.text.CountVectorizer.__init__.vocabulary": {
      "None": 2835,
      "count_vectorizer.vocabulary_": 19,
      "desc_terms": 18,
      "name_terms": 18,
      "vocabulary_one": 9,
      "new_voc": 8,
      "vocabulary_bi": 5,
      "Dict": 5,
      "set(words.words())": 3,
      "filth": 2,
      "vectorizer.vocabulary_": 2,
      "list(set(trn_words).intersection(set(sub_words)))": 2,
      "english_sw": 1,
      "subject_dict.keys()": 1,
      "subject_sub_dict.keys()": 1,
      "vectorizer.get_feature_names()": 1,
      "product_ids": 1,
      "common_words": 1,
      "list(my_vocab.keys())": 1,
      "worddictionary2": 1,
      "worddictionary": 1,
      "ngramdictionary": 1,
      "word_counts_df['word'].tolist()": 1
    },
    "sklearn.feature_extraction.text.TfidfTransformer.__init__.smooth_idf": {
      "True": 325,
      "False": 11
    },
    "sklearn.linear_model._ridge.RidgeClassifier.__init__.alpha": {
      "1.0": 137,
      "alpha": 3,
      "C": 2,
      "alpha_RID": 2,
      "20": 1,
      "value": 1,
      "5": 1,
      "2.2": 1,
      "10": 1,
      "152.5": 1,
      "1": 1
    },
    "sklearn.metrics._ranking.roc_curve.drop_intermediate": {
      "True": 1398,
      "False": 13
    },
    "sklearn.impute._knn.KNNImputer.fit.X": {
      "train['Age'].values.reshape(-1, 1)": 1,
      "train[['Age', 'Pclass', 'SibSp']]": 1,
      "train[['Fare', 'Pclass', 'Parch']]": 1,
      "df_conc": 1,
      "df_conc_test": 1,
      "train[numeric_cols]": 1
    },
    "sklearn.impute._knn.KNNImputer.transform.X": {
      "train['Age'].values.reshape(-1, 1)": 1,
      "test['Age'].values.reshape(-1, 1)": 1,
      "test['LotFrontage'].values.reshape(-1, 1)": 1,
      "test['GarageYrBlt'].values.reshape(-1, 1)": 1,
      "test[['Age', 'Pclass', 'SibSp']]": 1,
      "df_conc": 1,
      "df_conc_test": 1,
      "X": 1,
      "Y_pretest": 1,
      "y_pretest1": 1,
      "numval": 1,
      "numtest": 1,
      "train[numeric_cols]": 1,
      "valid[numeric_cols]": 1,
      "test[numeric_cols]": 1
    },
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.fit.sample_weight": {
      "None": 222,
      "[class_weights[int(y_train[i])] for i in range(y_train.shape[0])]": 1
    },
    "sklearn.naive_bayes.GaussianNB.fit.sample_weight": {
      "None": 384,
      "[class_weights[int(y_train[i])] for i in range(y_train.shape[0])]": 1,
      "df_cell_train.time": 1,
      "grid_time": 1
    },
    "sklearn.linear_model._ridge.RidgeClassifier.__init__.normalize": {
      "False": 146,
      "True": 3,
      "normalize": 1,
      "norm": 1
    },
    "sklearn.linear_model._ridge.RidgeClassifier.__init__.class_weight": {
      "None": 143,
      "'balanced'": 4,
      "{0: 1, 1: b}": 4
    },
    "sklearn.cluster._kmeans.KMeans.__init__.algorithm": {
      "'auto'": 919,
      "'elkan'": 9
    },
    "sklearn.decomposition._pca.PCA.__init__.copy": {
      "True": 2650,
      "False": 3
    },
    "sklearn.utils.validation.check_random_state.seed": {
      "self.random_state": 18,
      "random_state": 15,
      "ra1": 3,
      "seed": 1
    },
    "sklearn.decomposition._kernel_pca.KernelPCA.fit_transform.X": {
      "data": 5,
      "X_train_pca": 4,
      "X_train": 2,
      "features.values": 1,
      "portion_of_data": 1,
      "trainxdf": 1,
      "testxdf": 1,
      "encoded_train": 1,
      "X_train_copy[:, pca_index]": 1,
      "X": 1,
      "df": 1,
      "s[features]": 1,
      "train.drop(['id', 'color', 'type'], axis=1)": 1
    },
    "sklearn.utils.validation.column_or_1d.warn": {
      "True": 2,
      "False": 1
    },
    "sklearn.utils.validation.column_or_1d.y": {
      "y": 3
    },
    "sklearn.preprocessing._discretization.KBinsDiscretizer.__init__.n_bins": {
      "10": 17,
      "3": 6,
      "2": 6,
      "5": 4,
      "6": 4,
      "n_bins": 3,
      "4": 3,
      "20": 3,
      "self.group_count": 2,
      "100": 2,
      "self.bins_age": 1,
      "50": 1,
      "bins": 1,
      "12": 1,
      "9": 1,
      "bin_number": 1
    },
    "sklearn.preprocessing._discretization.KBinsDiscretizer.__init__.encode": {
      "'ordinal'": 44,
      "'onehot'": 10,
      "bin_encode_strategy": 1,
      "'onehot-dense'": 1
    },
    "sklearn.preprocessing._discretization.KBinsDiscretizer.__init__.strategy": {
      "'quantile'": 24,
      "'uniform'": 22,
      "'kmeans'": 6,
      "self.strategy": 2,
      "bin_strategy": 1,
      "strategy": 1
    },
    "sklearn.feature_extraction.text.CountVectorizer.__init__.encoding": {
      "'utf-8'": 2929,
      "'KOI8-R'": 6,
      "'ascii'": 1,
      "'latin-1'": 1
    },
    "sklearn.preprocessing._data.scale.axis": {
      "0": 307,
      "1": 7
    },
    "sklearn.preprocessing._data.scale.copy": {
      "True": 314
    },
    "sklearn.metrics._classification.jaccard_score.y_true": {
      "y_test": 6,
      "t_msk": 2,
      "y_train": 2,
      "_lung_mask": 2,
      "y_val": 1
    },
    "sklearn.metrics._classification.jaccard_score.y_pred": {
      "pred_binary_mask": 2,
      "y_pred": 2,
      "yhat": 2,
      "clf.predict(X_val_prepared)": 1,
      "predknn": 1,
      "predTree": 1,
      "predsvm": 1,
      "predlr": 1,
      "right_mask > 0": 1,
      "left_mask > 0": 1
    },
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.random_state": {
      "None": 100,
      "42": 15,
      "0": 3,
      "10": 1,
      "1": 1
    },
    "sklearn.cluster._dbscan.DBSCAN.__init__.metric": {
      "'euclidean'": 87,
      "'precomputed'": 5,
      "'haversine'": 4,
      "metric_fun": 2,
      "'cosine'": 1,
      "metric": 1,
      "'jaccard'": 1,
      "''": 1,
      "'l1'": 1
    },
    "sklearn.cluster._optics.OPTICS.fit.X": {
      "X_red": 2,
      "encoded_images": 1
    },
    "sklearn.cluster._optics.OPTICS.__init__.min_samples": {
      "2": 1,
      "20": 1,
      "4": 1,
      "5": 1
    },
    "sklearn.cluster._optics.OPTICS.__init__.metric": {
      "'minkowski'": 2,
      "'cosine'": 1,
      "'precomputed'": 1
    },
    "sklearn.cluster._optics.OPTICS.__init__.max_eps": {
      "np.inf": 3,
      "eps": 1
    },
    "sklearn.neighbors._unsupervised.NearestNeighbors.__init__.metric": {
      "'minkowski'": 74,
      "'cosine'": 24,
      "'euclidean'": 10,
      "'manhattan'": 1,
      "metric": 1
    },
    "sklearn.ensemble._iforest.IsolationForest.__init__.n_estimators": {
      "100": 35,
      "500": 3,
      "1000": 3,
      "150": 2,
      "50": 1
    },
    "sklearn.base.OutlierMixin.fit_predict.X": {
      "x_train": 2,
      "train": 1,
      "train_data[train_data.columns.difference(no_features)]": 1,
      "df_train": 1,
      "x": 1,
      "df.drop(columns=['shop_id', 'item_id'])": 1,
      "train_t_with_label": 1,
      "train[:]": 1,
      "train[features]": 1,
      "df.values.reshape(-1, 1)": 1,
      "X": 1,
      "feature_importance": 1,
      "train[['distance', 'trip_duration']]": 1,
      "train_iso_outliers": 1,
      "train_ee_outliers": 1,
      "train_set_0[original_features]": 1,
      "train_set_1[original_features]": 1,
      "base_train": 1
    },
    "sklearn.ensemble._iforest.IsolationForest.__init__.max_samples": {
      "'auto'": 35,
      "100": 3,
      "0.85": 1,
      "0.05": 1,
      "50": 1,
      "300": 1,
      "n_samples": 1,
      "1.0": 1
    },
    "sklearn.ensemble._iforest.IsolationForest.__init__.max_features": {
      "1.0": 39,
      "1": 2,
      "train_df.shape[1]": 1,
      "0.8": 1,
      "0.96": 1
    },
    "sklearn.ensemble._iforest.IsolationForest.__init__.bootstrap": {
      "False": 42,
      "True": 2
    },
    "sklearn.ensemble._iforest.IsolationForest.__init__.verbose": {
      "0": 43,
      "2": 1
    },
    "sklearn.tree._export.plot_tree.class_names": {
      "None": 23,
      "['0', '1']": 5,
      "['Not Survived', 'Survived']": 3,
      "to.y_names": 2,
      "cn": 2,
      "boston_dataset.target": 1,
      "['Safe', 'Unsafe']": 1,
      "target_column": 1,
      "['No Survived', 'Survived']": 1,
      "['Not survived', 'Survived']": 1,
      "['Offense', 'Defense']": 1,
      "['gini_cdp_year']": 1
    },
    "sklearn.tree._export.export_graphviz.class_names": {
      "None": 113,
      "['0', '1']": 24,
      "['No', 'Yes']": 15,
      "class_names": 6,
      "c": 5,
      "['extreme', 'moderate', 'vulnerable', 'non-vulnerable']": 4,
      "['0', '1', '2', '3']": 2,
      "['0', '1', '2', '3', '4', '5']": 2,
      "[str(x) for x in range(11)]": 2,
      "'Response'": 2,
      "['Saved', 'UnSaved']": 2,
      "['0', '1', '2', '3', '4']": 2,
      "[Level1_equidistant, Level2_equidistant, Level3_equidistant, Level4_equidistant, Level5_equidistant, Level6_equidistant]": 2,
      "[Level1_balanced, Level2_balanced, Level3_balanced, Level4_balanced, Level5_balanced, Level6_balanced]": 2,
      "boston_dataset.target": 1,
      "True": 1,
      "['Happy', 'Unhappy']": 1,
      "['0', '1', '2', '3', '4', '5', '6']": 1,
      "['No delay', 'Delay']": 1,
      "target_column": 1,
      "['Died', 'Survived']": 1,
      "['NO', 'YES']": 1,
      "dt_target_names": 1,
      "['Sobreviveu', 'N\u00e3o sobreviveu']": 1,
      "np.unique(y_train.astype('str'))": 1,
      "'Survived'": 1,
      "targets": 1,
      "['Not Survived', 'Survived']": 1,
      "train_new.target.unique().tolist()": 1,
      "classn": 1,
      "['count']": 1,
      "rf_1tree.classes_": 1,
      "'item_cnt'": 1
    },
    "sklearn.tree._export.export_graphviz.rounded": {
      "True": 103,
      "False": 99
    },
    "sklearn.datasets._samples_generator.make_blobs.centers": {
      "None": 2,
      "4": 1,
      "5": 1
    },
    "sklearn.datasets._samples_generator.make_blobs.cluster_std": {
      "1.0": 2,
      "0.6": 1,
      "5.0": 1
    },
    "sklearn.metrics.cluster._unsupervised.silhouette_score.X": {
      "X": 9,
      "df": 2,
      "trainFactors": 2,
      "x_train_sc": 2,
      "X_subset": 2,
      "features_scaled": 2,
      "k_data": 2,
      "X_train_multilabel": 1,
      "pt": 1,
      "a": 1,
      "X_w2v[:2000]": 1,
      "trainHFactors": 1,
      "nan_features": 1,
      "x_train": 1,
      "df_id_vs_variable": 1,
      "ridf[ft]": 1,
      "nn[pcas]": 1,
      "nn[ft]": 1,
      "df_store.fillna(0)": 1,
      "vz": 1,
      "dat": 1,
      "latlong": 1,
      "mnist_features_prepared": 1,
      "features.values": 1,
      "EncoderScaled": 1,
      "train_norm_feat": 1,
      "test_norm_feat": 1,
      "norm_feat": 1
    },
    "sklearn.metrics.cluster._unsupervised.silhouette_score.labels": {
      "cluster_labels": 7,
      "labels": 6,
      "kmeans.labels_": 6,
      "e.labels_": 3,
      "clt.labels_": 3,
      "km.labels_": 2,
      "model.labels_": 2,
      "kmeans.predict(df)": 1,
      "tmp_clf.labels_": 1,
      "x_cluster.labels_": 1,
      "labels[:2000]": 1,
      "gm.predict(ridf[ft])": 1,
      "gm.predict(nn[pcas])": 1,
      "nn[col]": 1,
      "store_cluster.ravel()": 1,
      "kmeans_clusters": 1,
      "algorithm.labels_": 1,
      "label": 1,
      "dbscan.labels_": 1,
      "km_predict": 1
    },
    "sklearn.neighbors._classification.KNeighborsClassifier.__init__.metric_params": {
      "None": 1821
    },
    "sklearn.ensemble._forest.RandomForestClassifier.__init__.max_samples": {
      "None": 5149,
      "0.8": 10,
      "0.5": 9,
      "0.75": 2,
      "trial.suggest_float('max_samples', 0.5, 0.8)": 2,
      "max_samples": 2,
      "50000": 1,
      "150": 1,
      "0.15": 1,
      "0.5985586520207642": 1,
      "0.8634669615516827": 1,
      "0.63249673484119": 1
    },
    "sklearn.tree._classes.ExtraTreeRegressor.__init__.criterion": {
      "'mse'": 5
    },
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.verbose": {
      "0": 81,
      "1": 2,
      "True": 1,
      "False": 1
    },
    "sklearn.model_selection._split.LeaveOneGroupOut.split.X": {
      "X": 4,
      "X_train": 2,
      "x_train": 1
    },
    "sklearn.model_selection._split.LeaveOneGroupOut.split.y": {
      "y1": 2,
      "Y_train": 2,
      "y_train": 1,
      "y2": 1,
      "y3": 1
    },
    "sklearn.model_selection._split.LeaveOneGroupOut.split.groups": {
      "groups": 6,
      "earthquakes_id": 1
    },
    "sklearn.metrics.cluster._supervised.mutual_info_score.contingency": {
      "None": 7,
      "cXY": 1
    },
    "sklearn.metrics.cluster._supervised.mutual_info_score.labels_true": {
      "y_train": 2,
      "y_valid": 2,
      "None": 1,
      "test['{}_a_coref'.format(model)]": 1,
      "test['{}_b_coref'.format(model)]": 1,
      "col_init": 1
    },
    "sklearn.metrics.cluster._supervised.mutual_info_score.labels_pred": {
      "None": 1,
      "verySimpleLearner.predict_proba(trainInputFeature)[:, 1]": 1,
      "verySimpleLearner.predict_proba(validInputFeature)[:, 1]": 1,
      "verySimpleLearner.predict_proba(trainInputFeatures)[:, 1]": 1,
      "verySimpleLearner.predict_proba(validInputFeatures)[:, 1]": 1,
      "test['lee_a_coref']": 1,
      "test['lee_b_coref']": 1,
      "col_corr": 1
    },
    "sklearn.impute._iterative.IterativeImputer.__init__.verbose": {
      "0": 55
    },
    "sklearn.preprocessing._data.minmax_scale.copy": {
      "True": 432,
      "False": 1
    },
    "sklearn.svm._classes.NuSVR.__init__.max_iter": {
      "-1": 54,
      "N_iterations": 1,
      "10000": 1
    },
    "sklearn.svm._classes.NuSVR.__init__.verbose": {
      "False": 54,
      "True": 2
    },
    "sklearn.feature_selection._univariate_selection.f_classif.X": {
      "Xtrn": 1,
      "X": 1,
      "train_merged_anova_nona.meter.values.reshape((-1, 1))": 1,
      "train_merged_anova_nona.primary_use.values.reshape((-1, 1))": 1,
      "train_merged_anova_nona.floor_count.values.reshape((-1, 1))": 1,
      "train_float": 1,
      "X_train": 1,
      "X_train.fillna(0)": 1,
      "tfidf_train": 1,
      "train_meta_df[X_cols]": 1
    },
    "sklearn.feature_selection._univariate_selection.f_classif.y": {
      "train_merged_anova_nona.meter_reading.values.reshape(-1)": 3,
      "y": 2,
      "y_train": 2,
      "train['target']": 1,
      "train_df['AdoptionSpeed'].values": 1,
      "train_meta_df['target']": 1
    },
    "sklearn.model_selection._validation.validation_curve.n_jobs": {
      "None": 22,
      "-1": 7,
      "4": 2,
      "n_jobs": 1
    },
    "sklearn.manifold._spectral_embedding.SpectralEmbedding.__init__.affinity": {
      "'nearest_neighbors'": 9,
      "'rbf'": 1
    },
    "sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay.plot.include_values": {
      "True": 29,
      "include_values": 2,
      "False": 1
    },
    "sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay.plot.xticks_rotation": {
      "'horizontal'": 30,
      "xticks_rotation": 2
    },
    "sklearn.datasets._svmlight_format_io.dump_svmlight_file.zero_based": {
      "True": 11,
      "False": 5
    },
    "sklearn.datasets._svmlight_format_io.dump_svmlight_file.X": {
      "X_train": 3,
      "X_test": 3,
      "X_trn_feature": 2,
      "X_tst_feature": 2,
      "X": 1,
      "digits_X": 1,
      "train_word_features": 1,
      "test_word_features": 1,
      "train_char_features": 1,
      "test_char_features": 1
    },
    "sklearn.datasets._svmlight_format_io.dump_svmlight_file.y": {
      "y_train": 5,
      "y_test": 3,
      "y_tst": 2,
      "np.ones((159571, ))": 2,
      "np.zeros((153164, ))": 2,
      "y": 1,
      "digits_y": 1
    },
    "sklearn.datasets._svmlight_format_io.dump_svmlight_file.f": {
      "'dtrain.svm'": 3,
      "'dtest.svm'": 3,
      "'trn.sps'": 2,
      "'tst.sps'": 2,
      "'/kaggle/working/train' + str(i + 1) + '.libsvm'": 1,
      "libsvm_file_path": 1,
      "'train_word_features'": 1,
      "'test_word_features'": 1,
      "'train_char_features'": 1,
      "'test_char_features'": 1
    },
    "sklearn.utils.class_weight.compute_sample_weight.class_weight": {
      "'balanced'": 9
    },
    "sklearn.utils.class_weight.compute_sample_weight.y": {
      "y_train": 5,
      "y_train.target": 3,
      "y": 1
    },
    "sklearn.neighbors._unsupervised.NearestNeighbors.__init__.algorithm": {
      "'auto'": 77,
      "'ball_tree'": 19,
      "'brute'": 8,
      "'kd_tree'": 6
    },
    "sklearn.kernel_ridge.KernelRidge.__init__.gamma": {
      "None": 89,
      "0.01": 5,
      "0.1": 2,
      "0.06": 1
    },
    "sklearn.ensemble._voting.VotingClassifier.__init__.weights": {
      "None": 255,
      "[1, 1, 1]": 6,
      "[2, 3, 3, 1]": 6,
      "[1, 2]": 4,
      "weights": 3,
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]": 3,
      "[0.35, 0.65]": 2,
      "[1, 2, 3]": 1,
      "[1, 5, 1, 2, 1, 1]": 1,
      "[1, 1, 5]": 1,
      "[3, 1, 1, 1]": 1,
      "[1, 1, 1.2]": 1,
      "[3, 1, 1]": 1,
      "[3, 2, 4, 1, 5]": 1,
      "[5, 2, 3, 4, 1]": 1,
      "[5, 1, 4, 2, 3]": 1,
      "[3, 3]": 1,
      "[2, 3]": 1,
      "[1, 1.5]": 1,
      "[8, 4]": 1,
      "WEIGHTS": 1,
      "[871856020222, 0.907895269918]": 1,
      "[3, 3, 3, 1, 1]": 1,
      "means": 1,
      "[2, 1, 4]": 1,
      "[1, 2, 2]": 1,
      "[2, 1, 1]": 1,
      "[0.05607363, 0.70759724, 0.23632913]": 1,
      "[0.94, 1.35, 0.58, 0.9]": 1,
      "[0.9, 1.35, 0.65, 0.8]": 1,
      "[1, 1, 1, 1]": 1,
      "[2.3, 1]": 1
    },
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.scoring": {
      "None": 97,
      "'roc_auc'": 13,
      "'neg_log_loss'": 8,
      "'f1'": 4,
      "'accuracy'": 2,
      "make_scorer(average_precision_score, needs_threshold=True)": 1
    },
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.multi_class": {
      "'auto'": 103,
      "'ovr'": 14,
      "'multinomial'": 8
    },
    "sklearn.neighbors._unsupervised.NearestNeighbors.__init__.n_jobs": {
      "None": 100,
      "-1": 10
    },
    "sklearn.metrics.cluster._supervised.v_measure_score.labels_true": {
      "pred": 2
    },
    "sklearn.metrics.cluster._supervised.v_measure_score.labels_pred": {
      "test_label == n": 2
    },
    "sklearn.feature_selection._rfe.RFE.score.X": {
      "X_test": 4,
      "cv_feat": 1,
      "train_df": 1,
      "train_1": 1,
      "X_train": 1,
      "x_valid": 1
    },
    "sklearn.feature_selection._rfe.RFE.score.y": {
      "y_test": 4,
      "labels": 2,
      "cv_ans.values.ravel()": 1,
      "y_train": 1,
      "y_valid": 1
    },
    "sklearn.feature_selection._rfe.RFE.predict.X": {
      "X_test": 11,
      "Xt": 4,
      "X_test_transformed": 2,
      "val_x": 2,
      "X_train": 2,
      "df": 1,
      "test_1": 1,
      "X_train_scaled": 1,
      "X_test_scaled": 1,
      "test": 1,
      "xvalid": 1,
      "x_valid": 1,
      "test1": 1
    },
    "sklearn.feature_selection._mutual_info.mutual_info_classif.n_neighbors": {
      "3": 69
    },
    "sklearn.feature_selection._mutual_info.mutual_info_classif.random_state": {
      "0": 28,
      "None": 15,
      "17": 13,
      "123": 4,
      "1": 3,
      "self.seed": 2,
      "RANDOM_STATE": 1,
      "40": 1,
      "11": 1,
      "42": 1
    },
    "sklearn.feature_selection._mutual_info.mutual_info_classif.X": {
      "X": 22,
      "train_float.values": 14,
      "ts": 8,
      "train_wheezy.values": 2,
      "train[['DebtRatio']]": 2,
      "X_train": 2,
      "x_train": 1,
      "x": 1,
      "train_int.values": 1,
      "train[[feature]]": 1,
      "X[['DebtRatio']]": 1,
      "train[['Debt']]": 1,
      "train[['MonthlyIncome']]": 1,
      "train": 1,
      "X.values": 1,
      "X_train_dummy": 1,
      "x_train_fs.astype('float')": 1,
      "train_data": 1,
      "X_cat": 1,
      "X_train.fillna(0)": 1,
      "imputed_X_train": 1,
      "Xt": 1,
      "train_master[continuous_columns]": 1,
      "subtrain": 1,
      "X_res": 1
    },
    "sklearn.feature_selection._mutual_info.mutual_info_classif.y": {
      "y": 25,
      "train.target.values": 14,
      "train.loc[X.index, 'SeriousDlqin2yrs']": 8,
      "train['SeriousDlqin2yrs']": 6,
      "y_train": 5,
      "target_wheezy": 2,
      "data_train.loc[X.index, 'SeriousDlqin2yrs']": 2,
      "y.values.ravel()": 1,
      "y_label": 1,
      "train['target'].values": 1,
      "y_train_data": 1,
      "train_master[target_column]": 1,
      "target": 1,
      "y_res": 1
    },
    "sklearn.tree._export.export_graphviz.impurity": {
      "True": 163,
      "False": 39
    },
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.learning_offset": {
      "10.0": 40,
      "50.0": 21,
      "learning_offset": 1
    },
    "sklearn.decomposition._lda.LatentDirichletAllocation.fit.X": {
      "tf": 14,
      "vstack([X, X_test])": 2,
      "X": 2,
      "Xtr": 1,
      "text_vecs": 1,
      "tf_mws": 1,
      "tf_hpl": 1,
      "tf_eap": 1,
      "X_tfidf": 1,
      "df_ratio_100": 1,
      "train.drop(['y'], axis=1)": 1,
      "Xtf": 1,
      "bow2": 1,
      "data_count_vec": 1
    },
    "sklearn.covariance._graph_lasso.GraphicalLasso.__init__.alpha": {
      "0.01": 34,
      "alpha": 2,
      "0.05": 1
    },
    "sklearn.covariance._graph_lasso.GraphicalLasso.fit.X": {
      "x2": 17,
      "x2b": 17,
      "tmp_df": 12,
      "x2[np.where(clusters == i)[0]]": 2,
      "x2b[np.where(clusters == i)[0]]": 2
    },
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.precisions_init": {
      "None": 202,
      "ps": 57,
      "[cov.precision_ for cov in covs]": 3,
      "out_info[i][1]": 1,
      "out_info[i][2]": 1,
      "precisions_init": 1,
      "init_precs": 1
    },
    "sklearn.ensemble._bagging.BaggingClassifier.predict_proba.X": {
      "X_test": 7,
      "test3": 6,
      "Xtest": 4,
      "test_X": 4,
      "train3[val_index, :]": 2,
      "X_val": 2,
      "test.drop(['xmin', 'ymin', 'xmax', 'ymax'], axis=1)": 2,
      "train3[test_index3, :]": 1,
      "local_X_test": 1,
      "X_val_scaled": 1,
      "test_scaled": 1,
      "rfe_test3": 1,
      "xtest": 1
    },
    "sklearn.decomposition._nmf.NMF.transform.X": {
      "X": 4,
      "tfidf_col": 2,
      "X_test": 2,
      "test": 2,
      "tfidf_vectorizer.transform(train.project_essay)": 1,
      "tfidf_vectorizer.transform(test.project_essay)": 1,
      "test.drop(['y'], axis=1)": 1,
      "Xtrain": 1,
      "Xtest": 1,
      "prod_matrix": 1,
      "tfidftran": 1
    },
    "sklearn.utils.validation.check_array.dtype": {
      "'numeric'": 37,
      "None": 13,
      "FLOAT_DTYPES": 7,
      "np.object": 2
    },
    "sklearn.utils.validation.check_array.accept_sparse": {
      "False": 55,
      "'csc'": 3,
      "'csr'": 1
    },
    "sklearn.utils.validation.check_array.copy": {
      "False": 50,
      "copy": 5,
      "True": 2,
      "self.copy": 2
    },
    "sklearn.metrics._ranking.label_ranking_average_precision_score.sample_weight": {
      "None": 35,
      "sample_weight[nonzero_weight_sample_indices]": 24
    },
    "sklearn.metrics._ranking.label_ranking_average_precision_score.y_true": {
      "truth[nonzero_weight_sample_indices, :] > 0": 23,
      "yb.cpu().numpy()": 9,
      "y.cpu().numpy()": 9,
      "yval": 6,
      "y_true": 3,
      "all_targets": 2,
      "ground_truth": 2,
      "labels": 1,
      "TRAIN_TARGETS": 1,
      "targets": 1,
      "y_true[nonzero_weight_sample_indices, :] > 0": 1,
      "y_.cpu().numpy()": 1
    },
    "sklearn.metrics._ranking.label_ranking_average_precision_score.y_score": {
      "scores[nonzero_weight_sample_indices, :]": 23,
      "o.cpu().numpy()": 17,
      "y_pred": 2,
      "all_predictions": 2,
      "predictions": 2,
      "predictionc.toarray()": 2,
      "prediction.toarray()": 2,
      "val_preds_file": 2,
      "outputs.detach().numpy()": 1,
      "ytrain": 1,
      "outputs": 1,
      "y_pred[nonzero_weight_sample_indices, :]": 1,
      "y_score": 1,
      "output.cpu().numpy()": 1,
      "outputs_.cpu().numpy()": 1
    },
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.fit.X": {
      "words_dict": 12,
      "cat_x_dict": 2
    },
    "sklearn.ensemble._stacking.StackingRegressor.__init__.n_jobs": {
      "None": 50,
      "-1": 13,
      "1": 2
    },
    "sklearn.ensemble._stacking.StackingRegressor.__init__.verbose": {
      "0": 61,
      "1": 4
    },
    "sklearn.cluster._dbscan.DBSCAN.__init__.algorithm": {
      "'auto'": 90,
      "'kd_tree'": 7,
      "'ball_tree'": 5,
      "''": 1
    },
    "sklearn.cluster._dbscan.DBSCAN.fit_predict.X": {
      "X": 12,
      "distances": 4,
      "word_vector": 3,
      "pd.DataFrame([x_tsne0, y_tsne0]).T.values": 3,
      "embeddings": 2,
      "scl.fit_transform(hits[['x2', 'y2', 'z2']].values)": 1,
      "dis_mat": 1,
      "train.drop(['id', 'target'], axis=1).iloc[len(train) * 8 // 10:]": 1,
      "test.drop(['id'], axis=1)": 1,
      "first_split[column_names]": 1,
      "second_split[column_names]": 1,
      "third_split[column_names]": 1,
      "fourth_split[column_names]": 1,
      "features_2d": 1,
      "X_train": 1,
      "hashes": 1,
      "x_other[:, :3]": 1,
      "x_te_other[:, :3]": 1,
      "x[:, :n_components]": 1,
      "df.values.reshape(-1, 1)": 1,
      "reduced_data": 1,
      "df_encoded[['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']]": 1,
      "embs": 1,
      "image_content_array": 1
    },
    "sklearn.utils.extmath.safe_sparse_dot.a": {
      "Z.T": 10,
      "X.T": 10,
      "adj": 5,
      "adj.T": 5,
      "csr_gemm(1, Z, F, -1, Y.copy())": 5,
      "csr_gemm(1, V, F, 0, Y.copy())": 5
    },
    "sklearn.utils.extmath.safe_sparse_dot.b": {
      "F.T": 15,
      "graph_resid(F, adj).T": 5,
      "csr_gemm(1, Z, F, -1, Y.copy())": 5,
      "csr_gemm(1, Z, V, 0, Y.copy())": 5,
      "csr_gemm(1, X, B, -1, Y.copy())": 5,
      "csr_gemm(1, X, V, 0, Y.copy())": 5
    },
    "sklearn.feature_selection._rfe.RFECV.__init__.min_features_to_select": {
      "1": 57,
      "12": 7,
      "rfe_min_features": 3,
      "20": 2,
      "50": 1,
      "10": 1,
      "min_features_to_select": 1,
      "25": 1
    },
    "sklearn.feature_selection._rfe.RFECV.__init__.verbose": {
      "0": 58,
      "2": 8,
      "1": 6,
      "False": 1
    },
    "sklearn.feature_selection._rfe.RFECV.__init__.n_jobs": {
      "None": 45,
      "-1": 23,
      "1": 3,
      "4": 2
    },
    "sklearn.feature_extraction.text.CountVectorizer.fit_transform.y": {
      "None": 1813,
      "ytr": 1,
      "y": 1
    },
    "sklearn.decomposition._truncated_svd.TruncatedSVD.fit.y": {
      "None": 188,
      "s_labels": 2,
      "tr_y": 1
    },
    "sklearn.decomposition._truncated_svd.TruncatedSVD.fit_transform.y": {
      "None": 516,
      "tr_y": 1,
      "y": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.penalty": {
      "'l2'": 117,
      "None": 9,
      "'elasticnet'": 6,
      "'l1'": 2
    },
    "sklearn.kernel_ridge.KernelRidge.fit.X": {
      "X_train": 10,
      "train.values": 5,
      "x_train2": 3,
      "X": 3,
      "X_train_scaled": 1,
      "x_train1": 1,
      "x_train3": 1,
      "x_train4": 1,
      "x_train5": 1,
      "train": 1,
      "x_tr": 1,
      "X_train_vectorized": 1,
      "x_train": 1
    },
    "sklearn.kernel_ridge.KernelRidge.fit.y": {
      "y_train": 9,
      "y_train_values1": 4,
      "y_train_values2": 4,
      "y_train2": 3,
      "y": 3,
      "y_train.values.flatten()": 1,
      "y_train1": 1,
      "y_train3": 1,
      "y_train4": 1,
      "y_train5": 1,
      "y_tr": 1,
      "Y_train": 1
    },
    "sklearn.kernel_ridge.KernelRidge.predict.X": {
      "X_valid": 8,
      "test.values": 6,
      "x_val2": 3,
      "X": 3,
      "X_test": 2,
      "X_train_scaled": 1,
      "x_val1": 1,
      "new_test1": 1,
      "new_test2": 1,
      "x_val3": 1,
      "new_test3": 1,
      "x_val4": 1,
      "new_test4": 1,
      "x_val5": 1,
      "new_test5": 1,
      "train": 1,
      "x_tt": 1,
      "x_val": 1,
      "test_feature": 1,
      "vect.transform(X_test)": 1,
      "vect.transform(test['comment_text'])": 1,
      "x_validate": 1
    },
    "sklearn.cluster._kmeans.KMeans.__init__.precompute_distances": {
      "'deprecated'": 920,
      "'auto'": 7,
      "True": 1
    },
    "sklearn.cluster._kmeans.KMeans.__init__.copy_x": {
      "True": 928
    },
    "sklearn.dummy.DummyClassifier.predict.X": {
      "X": 5,
      "X_test": 4,
      "X_te_equid": 2,
      "X_te_balan": 2,
      "df_val[features]": 2,
      "X_train": 2,
      "train.id_code": 1,
      "test.id_code": 1,
      "images": 1,
      "X_tscv": 1,
      "X_test_vec_df": 1,
      "val_X": 1,
      "x_test": 1,
      "test_df_grouped[['installation_id']]": 1
    },
    "sklearn.dummy.DummyClassifier.score.X": {
      "X_dev": 4,
      "X": 4,
      "X_test": 2,
      "train.id_code": 1,
      "X_trcv": 1,
      "X_tscv": 1,
      "x_valid": 1,
      "X_train": 1,
      "X_valid": 1
    },
    "sklearn.dummy.DummyClassifier.score.y": {
      "y_dev": 4,
      "y_test": 2,
      "y_valid": 2,
      "y_equidistant": 2,
      "train.diagnosis": 1,
      "y_train_lg": 1,
      "y_test_lg": 1,
      "y_train": 1,
      "y": 1,
      "y_balanced": 1
    },
    "sklearn.inspection._permutation_importance.permutation_importance.n_repeats": {
      "5": 14,
      "10": 5,
      "n_repeats": 3,
      "1": 2,
      "30": 1
    },
    "sklearn.inspection._permutation_importance.permutation_importance.random_state": {
      "None": 15,
      "0": 5,
      "42": 3,
      "11": 1,
      "21": 1
    },
    "sklearn.inspection._permutation_importance.permutation_importance.estimator": {
      "gbr": 8,
      "model": 4,
      "my_svm.model": 1,
      "clf": 1,
      "clf2": 1,
      "kr": 1,
      "lin_model": 1,
      "self.estimator": 1,
      "en": 1,
      "tree": 1,
      "ada": 1,
      "rfc": 1,
      "classifier": 1,
      "naive": 1,
      "RFRegModel": 1
    },
    "sklearn.inspection._permutation_importance.permutation_importance.X": {
      "data": 9,
      "xtrain": 3,
      "X": 3,
      "Xtest": 2,
      "my_svm.X_val": 1,
      "training_set": 1,
      "X_test": 1,
      "X_train_permutation": 1,
      "data_random": 1,
      "train_x": 1,
      "test_x": 1,
      "x_val": 1
    },
    "sklearn.inspection._permutation_importance.permutation_importance.y": {
      "target": 11,
      "ytrain": 3,
      "y": 3,
      "ytest": 2,
      "my_svm.y_val": 1,
      "y_test": 1,
      "y_train": 1,
      "train_t": 1,
      "test_y": 1,
      "y_val": 1
    },
    "sklearn.impute._iterative.IterativeImputer.fit.X": {
      "df2": 2,
      "df_imput_regress.values": 2,
      "weather[col_weather]": 2,
      "class_age": 2,
      "X_df.set_index('ctry')": 1,
      "X[self.columns_to_impute]": 1,
      "X": 1,
      "train.iloc[:, 8:]": 1,
      "test.iloc[:, 7:]": 1,
      "weather_train.drop('timestamp', axis=1)": 1,
      "weather_train[['site_id', 'dew_temperature', 'air_temperature', 'sea_level_pressure', 'wind_direction', 'wind_speed']]": 1,
      "X_plus": 1,
      "dataframe_train[fare_column].values.reshape(-1, 1)": 1
    },
    "sklearn.impute._iterative.IterativeImputer.transform.X": {
      "X": 4,
      "df2": 2,
      "class_age": 2,
      "test[features]": 2,
      "test[ordinal]": 2,
      "X_df.set_index('ctry')": 1,
      "X[self.columns_to_impute]": 1,
      "test[['Age']]": 1,
      "train.iloc[:, 8:]": 1,
      "test.iloc[:, 7:]": 1,
      "df[col_names]": 1,
      "weather_train[['site_id', 'dew_temperature', 'air_temperature', 'sea_level_pressure', 'wind_direction', 'wind_speed']]": 1,
      "dat[features]": 1,
      "test_dat[features]": 1,
      "dataframe_test[age_column].values.reshape(-1, 1)": 1,
      "dataframe_validation[fare_column].values.reshape(-1, 1)": 1
    },
    "sklearn.metrics._classification.classification_report.output_dict": {
      "False": 3015,
      "True": 59
    },
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.__init__.shrinkage": {
      "None": 282,
      "'auto'": 5
    },
    "sklearn.naive_bayes.BernoulliNB.__init__.fit_prior": {
      "True": 191,
      "False": 13,
      "nbBer_grid.best_params_['fit_prior']": 2
    },
    "sklearn.cluster._kmeans.k_means.X": {
      "df_pca[pcs]": 2,
      "corr": 1,
      "u_df": 1
    },
    "sklearn.cluster._kmeans.k_means.n_clusters": {
      "i": 1,
      "10": 1,
      "8": 1,
      "ln_clusters": 1
    },
    "sklearn.svm._classes.SVR.__init__.cache_size": {
      "200": 463,
      "3000.0": 2,
      "2000": 2,
      "2400.0": 1,
      "500": 1,
      "800": 1,
      "1000": 1
    },
    "sklearn.svm._classes.SVR.__init__.shrinking": {
      "True": 468,
      "False": 2,
      "trial.suggest_categorical('shrinking', [True, False])": 1
    },
    "sklearn.svm._classes.SVR.__init__.verbose": {
      "False": 464,
      "True": 6,
      "1": 1
    },
    "sklearn.neighbors._unsupervised.NearestNeighbors.fit.y": {
      "None": 111,
      "xrd.values": 1,
      "rx.target": 1,
      "yrm.values": 1
    },
    "sklearn.ensemble._stacking.StackingClassifier.predict_proba.X": {
      "X_test": 3,
      "X_val": 2,
      "x_val_norm": 2,
      "X_test_transformed": 1,
      "test_data_prepared": 1,
      "X_valid": 1,
      "test_data": 1,
      "x_test": 1,
      "test": 1,
      "X.loc[val_idx, :]": 1,
      "test_encode": 1,
      "x_test_norm": 1
    },
    "sklearn.metrics._classification.balanced_accuracy_score.y_true": {
      "y_test": 11,
      "y_train": 2,
      "TRUE": 2,
      "correct_labels": 2,
      "y_cora_test": 1,
      "oof_tar[-1]": 1,
      "true": 1,
      "y_val": 1,
      "y_true": 1,
      "y": 1
    },
    "sklearn.metrics._classification.balanced_accuracy_score.y_pred": {
      "y_pred": 12,
      "PRED": 2,
      "predicted_labels": 2,
      "model.predict(X_t3gram_vectorizer_test)": 1,
      "oof_pred[-1]": 1,
      "oof": 1,
      "model.predict(X_train)": 1,
      "model.predict(X_val)": 1,
      "yhat": 1,
      "predictions2": 1
    },
    "sklearn.preprocessing._discretization.KBinsDiscretizer.transform.X": {
      "test_df['n_images'].values.reshape(-1, 1)": 2,
      "test_df.image_size_scaled.values.reshape(-1, 1)": 2,
      "test_df['mean_color'].values.reshape(-1, 1)": 2,
      "test_data.image_size_scaled.values.reshape(-1, 1)": 2,
      "test['n_images'].values.reshape(-1, 1)": 1,
      "test['mean_color'].values.reshape(-1, 1)": 1,
      "X['Age'].values.reshape(-1, 1)": 1,
      "train_all['item_avg_price'].values.reshape(-1, 1)": 1,
      "train_all['cat_price'].values.reshape(-1, 1)": 1,
      "train_all['cat_shop_price'].values.reshape(-1, 1)": 1,
      "train_all['item_shop_price'].values.reshape(-1, 1)": 1,
      "X_train_e": 1,
      "X_test_e": 1,
      "df_train[features]": 1,
      "df_test[features]": 1,
      "train_df[c].values.reshape(-1, 1)": 1,
      "test_df[c].values.reshape(-1, 1)": 1,
      "df.loc[df['train'] == 0, 'item_price'].values.reshape(-1, 1)": 1,
      "train['Age'].to_numpy().reshape(-1, 1)": 1,
      "test['Age'].to_numpy().reshape(-1, 1)": 1,
      "train['Fare'].to_numpy().reshape(-1, 1)": 1,
      "test['Fare'].to_numpy().reshape(-1, 1)": 1,
      "data[feature].values": 1,
      "dataframe_validation[age_column].values.reshape(-1, 1)": 1,
      "dataframe_validation[fare_column].values.reshape(-1, 1)": 1,
      "dataframe_validation[sibsp_column].values.reshape(-1, 1)": 1,
      "dataframe_validation[parch_column].values.reshape(-1, 1)": 1,
      "dataframe_validation[totalcompanions_column].values.reshape(-1, 1)": 1,
      "dataframe_validation[ticketletters_column].values.reshape(-1, 1)": 1,
      "dataframe_validation[ticketnumbers_column].values.reshape(-1, 1)": 1,
      "dataframe_validation[ticketsymbols_column].values.reshape(-1, 1)": 1,
      "dataframe_validation[ticketcharacters_column].values.reshape(-1, 1)": 1
    },
    "sklearn.linear_model._ransac.RANSACRegressor.__init__.max_trials": {
      "100": 28
    },
    "sklearn.linear_model._ransac.RANSACRegressor.__init__.min_samples": {
      "None": 25,
      "50": 3
    },
    "sklearn.linear_model._ransac.RANSACRegressor.__init__.loss": {
      "'absolute_loss'": 28
    },
    "sklearn.linear_model._ransac.RANSACRegressor.__init__.residual_threshold": {
      "None": 25,
      "5.0": 3
    },
    "sklearn.linear_model._ransac.RANSACRegressor.__init__.random_state": {
      "None": 19,
      "0": 3,
      "42": 3,
      "myseeds[ransac_model]": 1,
      "ra1": 1,
      "random_state": 1
    },
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.warm_start": {
      "False": 976,
      "True": 13
    },
    "sklearn.naive_bayes.GaussianNB.__init__.priors": {
      "None": 737,
      "priors": 2,
      "[90 / 250, 160 / 250]": 1,
      "[0.05, 0.95]": 1
    },
    "sklearn.model_selection._validation.cross_validate.groups": {
      "None": 296,
      "data['SentenceId']": 1,
      "train_group": 1,
      "train_dataset_df.query('group != 5')['group']": 1
    },
    "sklearn.feature_extraction.text.TfidfVectorizer.fit.y": {
      "None": 855,
      "Y": 1
    },
    "sklearn.preprocessing._data.normalize.norm": {
      "'l2'": 408,
      "'l1'": 13,
      "'max'": 8
    },
    "sklearn.metrics._plot.roc_curve.RocCurveDisplay.__init__.fpr": {
      "fpr": 2
    },
    "sklearn.metrics._plot.roc_curve.RocCurveDisplay.__init__.tpr": {
      "tpr": 2
    },
    "sklearn.metrics._ranking.precision_recall_curve.pos_label": {
      "None": 197,
      "1": 3,
      "clf.classes_[1]": 1
    },
    "sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay.__init__.precision": {
      "prec": 1,
      "precision": 1
    },
    "sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay.__init__.recall": {
      "recall": 2
    },
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.verbose": {
      "False": 110,
      "1": 5,
      "True": 3,
      "0": 2
    },
    "sklearn.svm._classes.OneClassSVM.__init__.kernel": {
      "'rbf'": 8
    },
    "sklearn.svm._classes.OneClassSVM.fit.X": {
      "data": 2,
      "X": 1,
      "data_SVM": 1,
      "X_train": 1,
      "X_inlier[:50000]": 1
    },
    "sklearn.svm._classes.OneClassSVM.decision_function.X": {
      "X": 1
    },
    "sklearn.model_selection._search.GridSearchCV.__init__.pre_dispatch": {
      "'2*n_jobs'": 2748,
      "4": 2,
      "'8'": 1,
      "2": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.learning_rate_init": {
      "0.001": 129,
      "0.01": 8,
      "1": 1,
      "0.003": 1,
      "0.0005": 1,
      "trial.suggest_uniform('learning_rate_init', 0.01, 0.5)": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.learning_rate": {
      "'constant'": 127,
      "'adaptive'": 13,
      "'invscaling'": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.power_t": {
      "0.5": 428
    },
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.momentum": {
      "0.9": 428
    },
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.nesterovs_momentum": {
      "True": 428
    },
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.epsilon": {
      "1e-08": 426,
      "1e-09": 2
    },
    "sklearn.neighbors._kde.KernelDensity.score_samples.X": {
      "gridpoints": 17,
      "x": 11,
      "xAxis.reshape(-1, 1)": 9,
      "np.array(percentileValuesToShow).reshape(-1, 1)": 5,
      "list(zip(range(-99, 100)))": 2,
      "X_plot": 2,
      "x_grid[:, None]": 2,
      "x.reshape(-1, 1)": 1,
      "mGridpoints": 1,
      "x_d[:, None]": 1,
      "X_test": 1
    },
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.ccp_alpha": {
      "0.0": 988,
      "1e-13": 1
    },
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.criterion": {
      "'friedman_mse'": 961,
      "'mse'": 28
    },
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.init": {
      "None": 986,
      "LinearRegression()": 3
    },
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.max_leaf_nodes": {
      "None": 984,
      "5": 1,
      "26": 1,
      "12": 1,
      "100": 1,
      "10": 1
    },
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.min_impurity_decrease": {
      "0.0": 987,
      "0.025": 1,
      "0.001": 1
    },
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.min_impurity_split": {
      "None": 988,
      "1e-07": 1
    },
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.min_weight_fraction_leaf": {
      "0.0": 981,
      "0.01556": 4,
      "0.08012": 4
    },
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.n_iter_no_change": {
      "None": 972,
      "100": 6,
      "5": 5,
      "2": 3,
      "10": 1,
      "27": 1,
      "15": 1
    },
    "sklearn.ensemble._gb.GradientBoostingRegressor.__init__.validation_fraction": {
      "0.1": 986,
      "0.2": 2,
      "valid_fraction": 1
    },
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.n_features": {
      "2**27": 23,
      "2**20": 19,
      "2**28": 4,
      "2**dim": 4,
      "6706": 2,
      "10000": 2,
      "2**23": 1,
      "20": 1,
      "2**18": 1,
      "2**9": 1,
      "2**16": 1,
      "n_features": 1,
      "2**21": 1,
      "2**10": 1,
      "8200": 1,
      "5000": 1,
      "100": 1,
      "6": 1
    },
    "sklearn.feature_extraction.text.HashingVectorizer.transform.X": {
      "X_test": 2,
      "train['comment_text']": 2,
      "test['comment_text']": 2,
      "train['text']": 2,
      "test['text']": 2,
      "[words_excerpt]": 1,
      "X_train_text": 1,
      "X_test_text": 1,
      "data_train['comment_text']": 1,
      "data_test['comment_text']": 1,
      "X_train_ml": 1,
      "X_train": 1,
      "X": 1,
      "df['parsed']": 1,
      "train_df.cleaned_text.values": 1,
      "df": 1,
      "df1": 1,
      "df2": 1,
      "test.ingredients": 1,
      "df_train['text']": 1,
      "text": 1
    },
    "sklearn.naive_bayes.MultinomialNB.__init__.fit_prior": {
      "True": 902,
      "False": 7
    },
    "sklearn.naive_bayes.MultinomialNB.__init__.class_prior": {
      "None": 905,
      "[0.5, 0.5]": 3,
      "avg_crimes.values.tolist()": 1
    },
    "sklearn.svm._classes.LinearSVC.__init__.multi_class": {
      "'ovr'": 451,
      "'crammer_singer'": 2
    },
    "sklearn.linear_model._coordinate_descent.Lasso.__init__.copy_X": {
      "True": 748
    },
    "sklearn.linear_model._coordinate_descent.ElasticNet.__init__.copy_X": {
      "True": 467
    },
    "sklearn.svm._classes.LinearSVC.__init__.penalty": {
      "'l2'": 439,
      "'l1'": 13,
      "penalty": 1
    },
    "sklearn.linear_model._perceptron.Perceptron.__init__.class_weight": {
      "None": 75,
      "'balanced'": 3
    },
    "sklearn.ensemble._bagging.BaggingRegressor.__init__.max_features": {
      "1.0": 130,
      "0.8": 3,
      "args['max_features']": 3,
      "0.9": 1,
      "0.75": 1,
      "X_train.shape[1]": 1,
      "25": 1,
      "0.4": 1,
      "parameter[3]": 1
    },
    "sklearn.ensemble._bagging.BaggingRegressor.__init__.verbose": {
      "0": 139,
      "4": 1,
      "1": 1,
      "False": 1
    },
    "sklearn.cross_decomposition._pls.PLSRegression.__init__.copy": {
      "True": 9
    },
    "sklearn.cross_decomposition._pls.PLSRegression.__init__.max_iter": {
      "500": 8,
      "10000": 1
    },
    "sklearn.cross_decomposition._pls.PLSRegression.__init__.scale": {
      "True": 9
    },
    "sklearn.naive_bayes.GaussianNB.partial_fit.X": {
      "x_train": 1,
      "train_numeric_part_gauss_X": 1
    },
    "sklearn.naive_bayes.GaussianNB.partial_fit.y": {
      "y_train": 1,
      "train_numeric_part_gauss.Response": 1
    },
    "sklearn.naive_bayes.GaussianNB.partial_fit.classes": {
      "np.unique(y_train)": 1,
      "np.unique(train_numeric_part_gauss.Response)": 1
    },
    "sklearn.ensemble._bagging.BaggingRegressor.__init__.bootstrap": {
      "True": 142
    },
    "sklearn.cluster._kmeans.KMeans.fit_transform.X": {
      "X_scaled": 9,
      "train.drop(['y'], axis=1)": 3,
      "X_cell_v": 1,
      "X_gene_e": 1,
      "X_cell_gene": 1,
      "gene_expression": 1,
      "all_df": 1,
      "all_df[features]": 1,
      "pca_df": 1,
      "pca_test": 1,
      "X_transform": 1,
      "u": 1,
      "df[['Latitude', 'Longitude', 'Weight']]": 1,
      "X": 1
    },
    "sklearn.mixture._gaussian_mixture.GaussianMixture.bic.X": {
      "X": 3,
      "X_preprocessed": 2,
      "X_cell_v": 1,
      "X_gene_e_red": 1,
      "ridf[ft]": 1,
      "nn[pcas]": 1
    },
    "sklearn.manifold._isomap.Isomap.__init__.n_neighbors": {
      "5": 13,
      "10": 1,
      "2": 1
    },
    "sklearn.manifold._isomap.Isomap.__init__.n_components": {
      "2": 11,
      "3": 3,
      "200": 1
    },
    "sklearn.manifold._isomap.Isomap.fit.X": {
      "train_df.drop(['label'], axis=1)[::10]": 2,
      "x": 1,
      "VCT.transform(clit_df.excerpt)": 1
    },
    "sklearn.manifold._isomap.Isomap.transform.X": {
      "train_df.drop(['label'], axis=1)[::10]": 2,
      "x": 1,
      "VCT.transform(cs_df.Desc)": 1,
      "VCT.transform(clit_df.excerpt)": 1
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.predict.X": {
      "test_df": 3,
      "val_df": 2,
      "test[columns]": 2,
      "test_data": 1,
      "X_test": 1,
      "vl_x": 1
    },
    "sklearn.compose._column_transformer.ColumnTransformer.fit.X": {
      "X": 4,
      "X_treino": 4,
      "train_x": 3,
      "x_train": 3,
      "X_train": 2,
      "X_fit": 2,
      "df[imputer_cols]": 2,
      "X_all": 2,
      "housing_df_x": 1,
      "df": 1,
      "train_merged[features]": 1,
      "train.drop('target', axis=1)": 1,
      "v2_train.drop('target', axis=1)": 1,
      "train[train_col]": 1,
      "train[feature_columns]": 1,
      "data": 1,
      "train[features]": 1
    },
    "sklearn.metrics._regression.r2_score.multioutput": {
      "'uniform_average'": 2017,
      "multioutput": 8,
      "'variance_weighted'": 3,
      "'raw_values'": 1
    },
    "sklearn.model_selection._search.GridSearchCV.__init__.error_score": {
      "np.nan": 2742,
      "0": 5,
      "'raise'": 3,
      "'roc_auc'": 1,
      "'auc'": 1
    },
    "sklearn.cluster._spectral.SpectralClustering.__init__.n_clusters": {
      "np_classes": 4,
      "10": 1,
      "i": 1,
      "clusters_count": 1,
      "4": 1,
      "25": 1
    },
    "sklearn.cluster._spectral.SpectralClustering.__init__.affinity": {
      "'nearest_neighbors'": 5,
      "'precomputed'": 2,
      "'rbf'": 2
    },
    "sklearn.cluster._spectral.SpectralClustering.__init__.assign_labels": {
      "'kmeans'": 7,
      "'discretize'": 2
    },
    "sklearn.cluster._spectral.SpectralClustering.fit_predict.X": {
      "X": 4,
      "clusterFrame.values": 1
    },
    "sklearn.metrics._regression.r2_score.sample_weight": {
      "None": 2016,
      "sample_weight": 8,
      "validation_weights": 5
    },
    "sklearn.svm._classes.OneClassSVM.__init__.nu": {
      "outliers_fraction": 3,
      "0.95 * outliers_fraction": 1,
      "p_nu": 1,
      "0.95 * outliers_fraction + 0.05": 1,
      "0.01": 1,
      "0.5": 1
    },
    "sklearn.svm._classes.OneClassSVM.__init__.gamma": {
      "0.1": 3,
      "0.01": 2,
      "'scale'": 2,
      "'auto'": 1
    },
    "sklearn.svm._classes.OneClassSVM.predict.X": {
      "data": 2,
      "data_SVM": 1,
      "X_mix": 1,
      "X_test": 1,
      "X_inlier": 1,
      "X_outlier": 1
    },
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.decision_function.X": {
      "X_train": 9,
      "x_train": 2
    },
    "sklearn.semi_supervised._label_propagation.LabelSpreading.__init__.gamma": {
      "0.01": 4,
      "100": 1,
      "50": 1,
      "0.0125": 1,
      "20": 1
    },
    "sklearn.semi_supervised._label_propagation.LabelSpreading.__init__.kernel": {
      "'rbf'": 6,
      "'knn'": 2
    },
    "sklearn.semi_supervised._label_propagation.LabelSpreading.__init__.max_iter": {
      "10": 7,
      "30": 1
    },
    "sklearn.linear_model._huber.HuberRegressor.__init__.max_iter": {
      "100": 29,
      "1000": 5,
      "200": 2,
      "300": 2,
      "120": 2
    },
    "sklearn.feature_selection._univariate_selection.GenericUnivariateSelect.__init__.mode": {
      "'fwe'": 4,
      "'k_best'": 1
    },
    "sklearn.feature_selection._univariate_selection.GenericUnivariateSelect.__init__.param": {
      "0.001": 3,
      "80": 1,
      "0.007": 1
    },
    "sklearn.cluster._spectral.SpectralClustering.fit.X": {
      "a": 2,
      "transformed": 1,
      "X": 1
    },
    "sklearn.cluster._spectral.SpectralClustering.__init__.random_state": {
      "None": 6,
      "123": 1,
      "42": 1,
      "43": 1
    },
    "sklearn.linear_model._ransac.RANSACRegressor.fit.X": {
      "X_train": 7,
      "X": 2,
      "X[trainidx]": 1
    },
    "sklearn.linear_model._ransac.RANSACRegressor.fit.y": {
      "y_train": 7,
      "y": 2,
      "y[trainidx]": 1
    },
    "sklearn.linear_model._ransac.RANSACRegressor.predict.X": {
      "X_test": 5,
      "X_train": 4,
      "X[predidx]": 1,
      "test_feature": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.early_stopping": {
      "False": 835,
      "True": 6
    },
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.norm": {
      "'l2'": 58,
      "None": 8
    },
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.stop_words": {
      "None": 30,
      "stopwords": 18,
      "'english'": 14,
      "stop_words": 2,
      "stop": 1,
      "ENGLISH_STOP_WORDS": 1
    },
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.token_pattern": {
      "'(?u)\\\\b\\\\w\\\\w+\\\\b'": 54,
      "'.+'": 9,
      "'\\\\w+'": 2,
      "'w{1,}'": 1
    },
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.tokenizer": {
      "None": 52,
      "split_cat": 9,
      "TweetTokenizer().tokenize": 2,
      "preproc_bigrams": 1,
      "tokenizer": 1,
      "nltk.tokenize.word_tokenize": 1
    },
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.dtype": {
      "np.float64": 52,
      "np.float32": 12,
      "np.uint8": 2
    },
    "sklearn.impute._iterative.IterativeImputer.__init__.imputation_order": {
      "'ascending'": 54,
      "'arabic'": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.loss": {
      "'squared_loss'": 123,
      "'squared_epsilon_insensitive'": 4,
      "'huber'": 4,
      "'epsilon_insensitive'": 3
    },
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.alpha": {
      "0.0001": 110,
      "0.001": 5,
      "1": 5,
      "0.01": 3,
      "alpha": 2,
      "1e-10": 2,
      "a": 1,
      "10": 1,
      "0.02": 1,
      "0.0003": 1,
      "0.03": 1,
      "0.0": 1,
      "1e-05": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.eta0": {
      "0.01": 120,
      "0.0001": 4,
      "0.1": 3,
      "1.0": 1,
      "0.05": 1,
      "1": 1,
      "0.001": 1,
      "1e-14": 1,
      "0.2": 1,
      "0.017": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.early_stopping": {
      "False": 131,
      "True": 3
    },
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.verbose": {
      "0": 127,
      "1": 4,
      "-1": 2,
      "False": 1
    },
    "sklearn.multiclass.OneVsOneClassifier.__init__.estimator": {
      "model": 7,
      "linear_model.LogisticRegression(C=alpha, multi_class='multinomial', solver='saga', penalty=reg)": 1,
      "linear_model.LogisticRegression(C=10, multi_class='multinomial', solver='saga', penalty='l1')": 1,
      "svm": 1,
      "estimator": 1,
      "clf": 1,
      "LogisticRegression()": 1
    },
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.n_jobs": {
      "None": 113,
      "-1": 6,
      "5": 1
    },
    "sklearn.model_selection._split.BaseCrossValidator.split.X": {
      "y_train": 1,
      "X_train": 1
    },
    "sklearn.metrics.cluster._unsupervised.davies_bouldin_score.X": {
      "scaled_features": 3,
      "ridf[ft]": 1,
      "nn[pcas]": 1
    },
    "sklearn.metrics.cluster._unsupervised.davies_bouldin_score.labels": {
      "kmeans.labels_": 3,
      "gm.predict(ridf[ft])": 1,
      "gm.predict(nn[pcas])": 1
    },
    "sklearn.tree._export.export_text.feature_names": {
      "None": 4,
      "list(all_num_2020_no_Nan_X.columns)": 1,
      "features": 1
    },
    "sklearn.tree._export.export_text.decision_tree": {
      "clf": 1,
      "clf.estimators_[i]": 1,
      "m": 1,
      "decisiontree": 1,
      "best_tree": 1,
      "clf.estimators_[0][0]": 1
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.max_iter": {
      "100": 24,
      "250": 6,
      "max_iter": 3,
      "50000": 1,
      "50": 1
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.validation_fraction": {
      "0.1": 19,
      "None": 10,
      "0.25": 5,
      "0.15": 1
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.learning_rate": {
      "0.1": 23,
      "0.01": 10,
      "0.10675193678150449": 1,
      "0.05065982344408913": 1
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.max_depth": {
      "None": 20,
      "10": 6,
      "6": 4,
      "2": 3,
      "31": 1,
      "15": 1
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.min_samples_leaf": {
      "20": 26,
      "24": 6,
      "32": 3
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.max_leaf_nodes": {
      "31": 27,
      "60": 6,
      "185": 1,
      "100": 1
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.random_state": {
      "None": 20,
      "1": 6,
      "123": 4,
      "2021": 3,
      "42": 2
    },
    "sklearn.metrics._ranking.roc_auc_score.multi_class": {
      "'raise'": 8258,
      "'ovr'": 27,
      "'ovo'": 12
    },
    "sklearn.model_selection._split.GroupShuffleSplit.split.y": {
      "None": 42,
      "dataset.raw": 4,
      "self.train_df[self.target]": 2,
      "y": 1,
      "train['FVC']": 1,
      "train['Sentiment']": 1,
      "train_data['Sentiment']": 1,
      "self.raw": 1,
      "target['surface']": 1
    },
    "sklearn.linear_model._bayes.BayesianRidge.__init__.alpha_1": {
      "1e-06": 186,
      "3e-06": 1,
      "1.0": 1,
      "0.0001": 1,
      "5.589616542154059e-07": 1,
      "0.1": 1,
      "2.104047761709729e-05": 1,
      "alpha_1": 1,
      "1.1082096418660657e-08": 1
    },
    "sklearn.linear_model._bayes.BayesianRidge.__init__.alpha_2": {
      "1e-06": 187,
      "1.0": 1,
      "1e-07": 1,
      "9.799343618469923": 1,
      "0.1": 1,
      "8.87111148542247e-06": 1,
      "alpha_1": 1,
      "2.8447219170176236e-07": 1
    },
    "sklearn.linear_model._bayes.BayesianRidge.__init__.lambda_1": {
      "1e-06": 187,
      "1e-09": 1,
      "1e-07": 1,
      "1.7735725582463822": 1,
      "0.03": 1,
      "0.9517616852006183": 1,
      "lambda_1": 1,
      "2.8045244511702467e-07": 1
    },
    "sklearn.linear_model._bayes.BayesianRidge.__init__.lambda_2": {
      "1e-06": 186,
      "1e-05": 1,
      "1e-09": 1,
      "0.0001": 1,
      "3.616928181181732e-06": 1,
      "0.01": 1,
      "0.016369928482509982": 1,
      "lambda_2": 1,
      "9.998976228544691e-06": 1
    },
    "sklearn.utils.extmath.cartesian.arrays": {
      "gift_counts": 5
    },
    "sklearn.metrics._classification.brier_score_loss.pos_label": {
      "None": 5,
      "y.max()": 1,
      "1": 1,
      "y_train.max()": 1
    },
    "sklearn.decomposition._factor_analysis.FactorAnalysis.transform.X": {
      "val1_X": 2,
      "train_scaled": 1,
      "test.drop(['y'], axis=1)": 1,
      "standardized_test": 1,
      "test": 1
    },
    "sklearn.decomposition._factor_analysis.FactorAnalysis.__init__.rotation": {
      "None": 33,
      "'varimax'": 1
    },
    "sklearn.datasets._samples_generator.make_regression.n_features": {
      "2": 1,
      "n_features": 1,
      "100": 1
    },
    "sklearn.datasets._samples_generator.make_regression.noise": {
      "10": 1,
      "noise": 1,
      "0.0": 1
    },
    "sklearn.datasets._samples_generator.make_regression.bias": {
      "0.0": 2,
      "10": 1
    },
    "sklearn.preprocessing._data.MaxAbsScaler.fit.X": {
      "X": 2,
      "train_features": 1,
      "X_train": 1,
      "train_data[scaler_columns]": 1,
      "X_test": 1,
      "train": 1,
      "pd.concat([trainX.iloc[:, :nc], validX.iloc[:, :nc], testX.iloc[:, :nc]])": 1,
      "pd.concat([trainX[GMCols], validX[GMCols], testX[GMCols]])": 1
    },
    "sklearn.preprocessing._data.MaxAbsScaler.transform.X": {
      "X_test": 5,
      "X1": 3,
      "X": 2,
      "X_test_transformed": 2,
      "test": 2,
      "trainX.iloc[:, :nc]": 2,
      "validX.iloc[:, :nc]": 2,
      "testX.iloc[:, :nc]": 2,
      "train_features": 1,
      "test_features": 1,
      "simple_engineered_feature_test": 1,
      "X_train": 1,
      "train_data[scaler_columns]": 1,
      "test_data[scaler_columns]": 1,
      "scaler_train_data": 1,
      "scaler_test_data": 1,
      "train": 1,
      "sdf": 1,
      "trainX[trainY == 1].iloc[:, :nc].reset_index(drop=True)": 1,
      "trainX[trainY == 0].iloc[:, :nc].reset_index(drop=True)": 1,
      "trainX[GMCols]": 1,
      "validX[GMCols]": 1,
      "testX[GMCols]": 1
    },
    "sklearn.cluster._dbscan.DBSCAN.__init__.n_jobs": {
      "None": 87,
      "-1": 11,
      "32": 2,
      "4": 2,
      "6": 1
    },
    "sklearn.preprocessing._data.PolynomialFeatures.fit.y": {
      "None": 92,
      "y": 6,
      "y_train[index].iloc[:, 0]": 2,
      "Y_train": 1,
      "y_train": 1,
      "case_array": 1,
      "death_array": 1
    },
    "sklearn.model_selection._split.TimeSeriesSplit.split.groups": {
      "None": 76,
      "split_groups": 1
    },
    "sklearn.metrics.cluster._unsupervised.silhouette_score.metric": {
      "'euclidean'": 41,
      "'precomputed'": 1
    },
    "sklearn.cluster._mean_shift.MeanShift.fit.X": {
      "latlong": 2,
      "X": 2,
      "X_train_multilabel[:3000, ].toarray()": 1
    },
    "sklearn.metrics.pairwise.linear_kernel.X": {
      "row[:row.shape[0] / 2]": 24,
      "tfidf_matrix": 5,
      "prof_dtm[0:1]": 2,
      "TargetQues": 1,
      "text_embeddings[index].reshape(1, -1)": 1,
      "req_vectors": 1,
      "xtrain_embeddings": 1
    },
    "sklearn.metrics.pairwise.linear_kernel.Y": {
      "row[row.shape[0] / 2:]": 24,
      "tfidf_matrix": 5,
      "prof_dtm": 2,
      "tfidfTrans": 1,
      "text_embeddings": 1,
      "req_vectors": 1,
      "xtrain_embeddings": 1
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.predict_proba.X": {
      "X_test": 6,
      "val_df": 3,
      "x_train": 2,
      "x_val": 2,
      "test.values": 2,
      "test_data": 1,
      "hgbc_x_valid": 1,
      "test[hgbc_features]": 1,
      "X_train": 1,
      "train_df_x_scaled": 1,
      "val_X": 1,
      "XX": 1,
      "train[cols]": 1
    },
    "sklearn.model_selection._validation.cross_val_score.fit_params": {
      "None": 3780,
      "self.fit_params": 6,
      "{'callbacks': [es]}": 5,
      "fit_params": 4,
      "fitparam": 2,
      "dict(clf__sample_weight=wgts)": 1,
      "{'cat_features': [1, 2, 3, 4, 5, 6]}": 1,
      "{'callbacks': [es, mc]}": 1,
      "{'eval_metric': kappa_score}": 1
    },
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.weights_init": {
      "None": 262,
      "[1 / 6] * 6": 1,
      "[1 / n_cluster] * n_cluster": 1,
      "[0.8, 0.2]": 1,
      "weights_init": 1
    },
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.verbose": {
      "0": 25
    },
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.max_iter": {
      "100": 17,
      "10000": 8
    },
    "sklearn.datasets._samples_generator.make_classification.n_repeated": {
      "0": 78,
      "5": 1
    },
    "sklearn.datasets._samples_generator.make_classification.n_clusters_per_class": {
      "2": 47,
      "1": 23,
      "3": 7,
      "clusters + 1": 2
    },
    "sklearn.datasets._samples_generator.make_classification.flip_y": {
      "0.01": 35,
      "0.05": 18,
      "0": 8,
      "0.0": 8,
      "0.08": 6,
      "0.1": 2,
      "flip_y": 1,
      "0.075": 1
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.verbose": {
      "0": 31,
      "4": 3,
      "1": 1
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.verbose": {
      "0": 28,
      "2": 1,
      "25": 1
    },
    "sklearn.linear_model._theil_sen.TheilSenRegressor.__init__.verbose": {
      "False": 26
    },
    "sklearn.semi_supervised._label_propagation.LabelPropagation.__init__.n_neighbors": {
      "7": 2
    },
    "sklearn.semi_supervised._label_propagation.LabelPropagation.__init__.max_iter": {
      "1000": 2
    },
    "sklearn.datasets._samples_generator.make_classification.weights": {
      "None": 68,
      "[0.9, 0.1]": 7,
      "[0.01, 0.05, 0.94]": 1,
      "[0.2, 0.8]": 1,
      "(0.36, 0.64)": 1,
      "[0.1, 0.025, 0.205, 0.008, 0.9]": 1
    },
    "sklearn.datasets._samples_generator.make_classification.class_sep": {
      "1.0": 56,
      "1.5": 7,
      "1": 5,
      "3": 5,
      "2": 2,
      "2.0": 1,
      "0.8": 1,
      "0.95": 1,
      "0.5": 1
    },
    "sklearn.datasets._samples_generator.make_classification.hypercube": {
      "True": 79
    },
    "sklearn.datasets._samples_generator.make_classification.shift": {
      "0.0": 79
    },
    "sklearn.datasets._samples_generator.make_classification.scale": {
      "1.0": 79
    },
    "sklearn.datasets._samples_generator.make_classification.shuffle": {
      "True": 78,
      "False": 1
    },
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.__init__.priors": {
      "None": 265,
      "[0.5, 0.5]": 8,
      "[0.167, 0.167, 0.167, 0.167, 0.167, 0.167]": 2,
      "0.5": 1
    },
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.gamma": {
      "None": 31,
      "0.0433": 7,
      "0.001": 7,
      "1": 6,
      "5": 1,
      "15": 1
    },
    "sklearn.decomposition._kernel_pca.KernelPCA.transform.X": {
      "X_test_pca": 4,
      "X_test": 2,
      "encoded_test": 1,
      "X_test_copy[:, pca_index]": 1,
      "x_train": 1,
      "x_test": 1,
      "test.drop(['id', 'color'], axis=1).values": 1
    },
    "sklearn.cluster._kmeans.KMeans.fit.y": {
      "None": 669,
      "y": 2,
      "train[['Fatalities']]": 1,
      "target": 1,
      "Y_train": 1
    },
    "sklearn.pipeline.make_union.n_jobs": {
      "None": 28,
      "1": 13,
      "4": 7,
      "2": 4,
      "3": 2
    },
    "sklearn.cluster._dbscan.dbscan.X": {
      "capped.values": 1
    },
    "sklearn.model_selection._search.ParameterGrid.__init__.param_grid": {
      "param_grid": 12,
      "parameters": 3,
      "grid": 3,
      "candidate['params']": 2,
      "params": 2,
      "{'C': [0.1, 1, 10], 'gamma': ['auto', 0.01]}": 1,
      "xgb_hyperparameters": 1,
      "params_grid": 1,
      "all_params": 1
    },
    "sklearn.model_selection._split.StratifiedShuffleSplit.split.groups": {
      "None": 213,
      "group": 2,
      "groups": 1
    },
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.staged_predict.X": {
      "X_test": 1,
      "X_train": 1
    },
    "sklearn.metrics._classification.zero_one_loss.y_true": {
      "y_pred": 4,
      "y_test": 2,
      "y_train": 1,
      "y": 1
    },
    "sklearn.metrics._classification.zero_one_loss.y_pred": {
      "y_test": 2,
      "y_train": 2,
      "predicted_train": 1,
      "predicted_validation": 1,
      "y_pred": 1,
      "predictions": 1
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.staged_predict.X": {
      "X_test": 1,
      "X_train": 1
    },
    "sklearn.cluster._affinity_propagation.affinity_propagation.S": {
      "corr.as_matrix()": 1
    },
    "sklearn.svm._classes.NuSVC.__init__.max_iter": {
      "-1": 107,
      "9000": 1
    },
    "sklearn.linear_model._bayes.BayesianRidge.__init__.n_iter": {
      "300": 180,
      "30": 4,
      "50000": 2,
      "1000": 2,
      "10000": 2,
      "8000": 1,
      "1": 1,
      "304": 1,
      "500": 1
    },
    "sklearn.linear_model._bayes.BayesianRidge.__init__.verbose": {
      "False": 186,
      "True": 8
    },
    "sklearn.linear_model._perceptron.Perceptron.__init__.max_iter": {
      "1000": 71,
      "50": 3,
      "None": 1,
      "200": 1,
      "2000000": 1,
      "20000": 1
    },
    "sklearn.linear_model._perceptron.Perceptron.__init__.eta0": {
      "1.0": 74,
      "0.1": 3,
      "0.5": 1
    },
    "sklearn.linear_model._perceptron.Perceptron.__init__.random_state": {
      "0": 74,
      "1": 3,
      "RS": 1
    },
    "sklearn.cluster._agglomerative.FeatureAgglomeration.__init__.connectivity": {
      "None": 4,
      "connectivity": 1
    },
    "sklearn.cluster._agglomerative.FeatureAgglomeration.__init__.n_clusters": {
      "n_comp": 3,
      "32": 1,
      "n_cluster": 1
    },
    "sklearn.cluster._agglomerative.FeatureAgglomeration.fit.X": {
      "X": 1,
      "train_X": 1
    },
    "sklearn.decomposition._nmf.NMF.fit.X": {
      "tfidf": 4,
      "X": 3,
      "vstack([X, X_test])": 1,
      "X_tfidf": 1,
      "df[tfidf_features]": 1,
      "A": 1,
      "prod_matrix": 1
    },
    "sklearn.decomposition._lda.LatentDirichletAllocation.transform.X": {
      "X": 3,
      "X_test": 3,
      "text_vecs": 1,
      "df_ratio_100": 1,
      "test.drop(['y'], axis=1)": 1,
      "bow_train": 1,
      "bow_dev": 1,
      "bow_test": 1,
      "tftran": 1,
      "valid_cv": 1
    },
    "sklearn.preprocessing._label.LabelBinarizer.inverse_transform.Y": {
      "yhat": 5,
      "preds": 4,
      "y_predicted": 3,
      "prediction": 2,
      "p.reshape(1, -1)": 1,
      "y_j_sub_conv": 1,
      "y_j_sub_conv2": 1,
      "pred1_classes": 1,
      "pred2_classes": 1,
      "predictions": 1,
      "np.asarray(y_test)": 1,
      "model.predict(test_images_X)": 1,
      "forest.predict(testX)": 1
    },
    "sklearn.feature_extraction.text.CountVectorizer.fit.y": {
      "None": 780,
      "y": 3
    },
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.beta_1": {
      "0.9": 141
    },
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.beta_2": {
      "0.999": 141
    },
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.early_stopping": {
      "False": 132,
      "True": 9
    },
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.epsilon": {
      "1e-08": 141
    },
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.momentum": {
      "0.9": 139,
      "0.7": 1,
      "0.5": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.n_iter_no_change": {
      "10": 139,
      "5": 1,
      "20": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.nesterovs_momentum": {
      "True": 141
    },
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.power_t": {
      "0.5": 141
    },
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.shuffle": {
      "True": 138,
      "False": 3
    },
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.tol": {
      "0.0001": 140,
      "1e-05": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.validation_fraction": {
      "0.1": 136,
      "0": 2,
      "valid_fraction": 1,
      "0.3": 1,
      "0.0": 1
    },
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.warm_start": {
      "False": 139,
      "True": 2
    },
    "sklearn.linear_model._coordinate_descent.ElasticNet.fit.sample_weight": {
      "None": 474,
      "sample_weight": 1
    },
    "sklearn.svm._classes.LinearSVC.__init__.intercept_scaling": {
      "1": 453
    },
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.n_iter_no_change": {
      "10": 427,
      "35": 1
    },
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix.display_labels": {
      "None": 130,
      "[1, 2, 3, 4, 5, 6]": 16,
      "['0', '1', '2', '3', '4']": 8,
      "['Dead', 'Survived']": 5,
      "['\u0424\u0435\u0439\u043a\u043e\u0432\u044b\u0435', '\u0420\u0435\u0430\u043b\u044c\u043d\u044b\u0435']": 4,
      "class_names": 4,
      "[0, 1]": 4,
      "['0', '1']": 3,
      "['Drowned', 'Survived']": 2,
      "list(encoder.classes_)": 1,
      "labels": 1,
      "class_labels": 1,
      "['Fake', 'Real']": 1
    },
    "sklearn.decomposition._fastica.FastICA.fit.X": {
      "X": 2,
      "data.T": 2,
      "stats_scaled": 1,
      "xdat[y == 1]": 1,
      "alldata": 1
    },
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.dual": {
      "False": 125
    },
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.__init__.kernel": {
      "None": 15,
      "1.0 * RBF(1.0)": 3,
      "kernel": 3,
      "k": 1,
      "1.0 * RBF(length_scale=1.0, length_scale_bounds=(0.1, 10.0))": 1,
      "4.0 * RBF(1.0)": 1
    },
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.__init__.n_restarts_optimizer": {
      "0": 23,
      "5": 1
    },
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.__init__.max_iter_predict": {
      "100": 23,
      "200": 1
    },
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.fit.X": {
      "X_train": 5,
      "train_X": 1,
      "monster_train_A[features]": 1,
      "X_train[0:5000]": 1
    },
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.fit.y": {
      "y_train": 5,
      "train_y": 1,
      "monster_train_A['type']": 1,
      "Y_train[0:5000]": 1
    },
    "sklearn.decomposition._truncated_svd.TruncatedSVD.inverse_transform.X": {
      "sim": 2,
      "unit_vect": 2,
      "svd_forecast.T": 1,
      "U123": 1,
      "X_n": 1
    },
    "sklearn.neighbors._graph.kneighbors_graph.X": {
      "X": 1,
      "x_train": 1
    },
    "sklearn.neighbors._graph.kneighbors_graph.n_neighbors": {
      "k": 1,
      "2": 1
    },
    "sklearn.neighbors._regression.KNeighborsRegressor.__init__.metric_params": {
      "None": 355,
      "{'lag': 0}": 1
    },
    "sklearn.model_selection._split.TimeSeriesSplit.__init__.max_train_size": {
      "None": 125,
      "1241711": 2
    },
    "sklearn.linear_model._bayes.BayesianRidge.__init__.tol": {
      "0.001": 191,
      "1e-06": 1,
      "0.16864712769300896": 1,
      "0.0001": 1
    },
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.verbose_interval": {
      "10": 253,
      "1": 12,
      "250": 1
    },
    "sklearn.covariance._shrunk_covariance.OAS.fit.X": {
      "x11": 10,
      "x21": 10,
      "x12": 9,
      "x22": 9,
      "x_train_0[labels_0 == l]": 5,
      "x_train_1[labels_1 == l]": 5,
      "train_X[train_index][y_train == j]": 3,
      "x2": 2,
      "x2b": 2,
      "xi": 1,
      "x13": 1,
      "x23": 1,
      "x14": 1,
      "x24": 1,
      "C": 1
    },
    "sklearn.linear_model._ridge.Ridge.fit.sample_weight": {
      "None": 649,
      "w": 2
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.l2_regularization": {
      "0.0": 28,
      "0.01": 3,
      "1.766059063693552": 1,
      "1": 1,
      "0.5629424804207567": 1,
      "0.05": 1
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.max_bins": {
      "255": 30,
      "9": 3,
      "128": 1,
      "64": 1
    },
    "sklearn.preprocessing._data.normalize.copy": {
      "True": 427,
      "False": 2
    },
    "sklearn.preprocessing._data.normalize.return_norm": {
      "False": 428,
      "True": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.l1_ratio": {
      "0.15": 127,
      "0.09": 2,
      "l1r": 1,
      "0.0": 1,
      "0": 1,
      "0.7": 1,
      "0.25": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.shuffle": {
      "True": 134
    },
    "sklearn.isotonic.IsotonicRegression.fit.X": {
      "oof[idx1]": 2,
      "self.trues_valid[col]": 1,
      "mainclfpreds": 1,
      "raw_results[i]": 1
    },
    "sklearn.isotonic.IsotonicRegression.fit.y": {
      "train2['target'].values": 2,
      "self.preds_valid[col]": 1,
      "train[target]": 1,
      "raw_results_n[i]": 1
    },
    "sklearn.isotonic.IsotonicRegression.__init__.y_min": {
      "None": 7,
      "0": 2,
      "0.0": 1
    },
    "sklearn.isotonic.IsotonicRegression.__init__.y_max": {
      "None": 7,
      "1": 2,
      "1.0": 1
    },
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__.min_samples_split": {
      "2": 3,
      "100": 2,
      "20": 1,
      "10": 1
    },
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__.sparse_output": {
      "True": 6,
      "False": 1
    },
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__.n_jobs": {
      "-1": 5,
      "None": 2
    },
    "sklearn.model_selection._split.StratifiedKFold.split.groups": {
      "None": 3887,
      "y": 6,
      "groups": 4,
      "target": 2,
      "X['installation_id']": 1,
      "train_df['patient_id'].tolist()": 1
    },
    "sklearn.metrics._regression.mean_absolute_error.multioutput": {
      "'uniform_average'": 2916,
      "'raw_values'": 2,
      "multioutput": 2
    },
    "sklearn.model_selection._validation.cross_validate.fit_params": {
      "None": 296,
      "fit_params": 2,
      "{'eval_metric': 'auc'}": 1
    },
    "sklearn.decomposition._fastica.FastICA.__init__.max_iter": {
      "200": 177,
      "500": 6,
      "1000": 5,
      "100": 1,
      "300": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.fit_intercept": {
      "True": 128,
      "False": 6
    },
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.epsilon": {
      "DEFAULT_EPSILON": 130,
      "0.0001": 2,
      "eps": 1,
      "0.1": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.learning_rate": {
      "'invscaling'": 130,
      "'adaptive'": 4
    },
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.power_t": {
      "0.25": 129,
      "0.4": 2,
      "0.2": 1,
      "0.229": 1,
      "0.1": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.warm_start": {
      "False": 133,
      "True": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.average": {
      "False": 134
    },
    "sklearn.decomposition._nmf.NMF.__init__.shuffle": {
      "False": 64,
      "True": 1
    },
    "sklearn.linear_model._coordinate_descent.ElasticNet.__init__.warm_start": {
      "False": 464,
      "True": 3
    },
    "sklearn.linear_model._coordinate_descent.ElasticNet.__init__.positive": {
      "False": 465,
      "True": 2
    },
    "sklearn.ensemble._forest.RandomTreesEmbedding.fit.X": {
      "X": 3,
      "X_train": 1
    },
    "sklearn.utils.extmath.weighted_mode.axis": {
      "1": 1
    },
    "sklearn.utils.extmath.weighted_mode.a": {
      "weighted_voting_df": 1
    },
    "sklearn.utils.extmath.weighted_mode.w": {
      "MODEL_WEIGHTING": 1
    },
    "sklearn.base.ClassifierMixin.score.sample_weight": {
      "None": 2842
    },
    "sklearn.metrics.cluster._supervised.adjusted_rand_score.labels_true": {
      "labels_true": 5,
      "actual": 1
    },
    "sklearn.metrics.cluster._supervised.adjusted_rand_score.labels_pred": {
      "labels": 5,
      "y_pred": 1
    },
    "sklearn.manifold._t_sne.TSNE.__init__.n_iter_without_progress": {
      "300": 533,
      "150": 2,
      "50": 1
    },
    "sklearn.manifold._t_sne.TSNE.__init__.min_grad_norm": {
      "1e-07": 534,
      "1e-06": 2
    },
    "sklearn.metrics._classification.confusion_matrix.sample_weight": {
      "None": 4455,
      "sample_weight": 3,
      "weights": 2
    },
    "sklearn.feature_selection._from_model.SelectFromModel.__init__.max_features": {
      "None": 201,
      "max_selected_features": 6,
      "num_feats": 3,
      "m_feats": 2,
      "mf": 1,
      "self.n_features": 1,
      "20": 1
    },
    "sklearn.metrics._classification.cohen_kappa_score.sample_weight": {
      "None": 1062,
      "w": 6,
      "sample_weight": 2,
      "y['sample_weight']": 2
    },
    "sklearn.linear_model._omp.OrthogonalMatchingPursuit.__init__.n_nonzero_coefs": {
      "None": 4,
      "8": 1
    },
    "sklearn.linear_model._omp.OrthogonalMatchingPursuit.__init__.fit_intercept": {
      "True": 5
    },
    "sklearn.linear_model._omp.OrthogonalMatchingPursuit.__init__.normalize": {
      "True": 4,
      "False": 1
    },
    "sklearn.linear_model._omp.OrthogonalMatchingPursuit.__init__.precompute": {
      "'auto'": 4,
      "True": 1
    },
    "sklearn.linear_model._omp.OrthogonalMatchingPursuit.__init__.tol": {
      "None": 5
    },
    "sklearn.linear_model._omp.OrthogonalMatchingPursuit.fit.X": {
      "X_train": 1
    },
    "sklearn.linear_model._omp.OrthogonalMatchingPursuit.fit.y": {
      "y_train": 1
    },
    "sklearn.linear_model._bayes.ARDRegression.__init__.alpha_1": {
      "1e-06": 11,
      "1e-09": 1
    },
    "sklearn.linear_model._bayes.ARDRegression.__init__.alpha_2": {
      "1e-06": 11,
      "1.0": 1
    },
    "sklearn.linear_model._bayes.ARDRegression.__init__.lambda_1": {
      "1e-06": 11,
      "1e-09": 1
    },
    "sklearn.linear_model._bayes.ARDRegression.__init__.lambda_2": {
      "1e-06": 11,
      "1e-09": 1
    },
    "sklearn.linear_model._bayes.ARDRegression.__init__.n_iter": {
      "300": 11,
      "1": 1
    },
    "sklearn.linear_model._bayes.ARDRegression.__init__.verbose": {
      "False": 11,
      "True": 1
    },
    "sklearn.linear_model._bayes.ARDRegression.predict.X": {
      "X_test": 1,
      "train[feature_columns]": 1,
      "submission[feature_columns]": 1,
      "X_test_scaled": 1,
      "data_test_file.values": 1,
      "test_X": 1
    },
    "sklearn.linear_model._bayes.ARDRegression.fit.X": {
      "X_train": 1,
      "train[feature_columns]": 1,
      "X_train_scaled": 1
    },
    "sklearn.linear_model._bayes.ARDRegression.fit.y": {
      "y_train": 2,
      "train['FVC']": 1
    },
    "sklearn.model_selection._validation.cross_val_score.groups": {
      "None": 3778,
      "x.Patient": 9,
      "X['molecule_name']": 3,
      "train.Patient": 3,
      "temp.Patient": 3,
      "groups": 3,
      "dlabels['date']": 2
    },
    "sklearn.ensemble._iforest.IsolationForest.decision_function.X": {
      "X_train[NO_NAN_COLS]": 1,
      "X_test[NO_NAN_COLS]": 1,
      "X_train": 1,
      "X_test": 1,
      "df_train": 1,
      "X": 1,
      "train.drop(['id', 'target'], axis=1)": 1,
      "imputed_total": 1
    },
    "sklearn.cluster._mean_shift.estimate_bandwidth.quantile": {
      "0.1": 1,
      "0.2": 1,
      "0.001": 1
    },
    "sklearn.cluster._mean_shift.estimate_bandwidth.n_samples": {
      "1000": 1,
      "891": 1,
      "None": 1
    },
    "sklearn.cluster._mean_shift.estimate_bandwidth.X": {
      "latlong": 1,
      "train": 1,
      "X": 1
    },
    "sklearn.cluster._mean_shift.MeanShift.__init__.bandwidth": {
      "bw": 2,
      "bandwidth": 2,
      "None": 1
    },
    "sklearn.cluster._mean_shift.MeanShift.__init__.bin_seeding": {
      "True": 4,
      "False": 1
    },
    "sklearn.cluster._mean_shift.MeanShift.__init__.min_bin_freq": {
      "5": 2,
      "1": 2,
      "10": 1
    },
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix.values_format": {
      "None": 157,
      "'d'": 7,
      "''": 6,
      "'.4g'": 6,
      "' '": 3,
      "values_format": 1
    },
    "sklearn.cluster._affinity_propagation.AffinityPropagation.__init__.damping": {
      "0.5": 3,
      "0.9": 1
    },
    "sklearn.cluster._affinity_propagation.AffinityPropagation.fit.X": {
      "train.drop(['id', 'target'], axis=1)": 2,
      "Normalizer().fit_transform(model_input)": 1,
      "feat_hist_nozero_df": 1
    },
    "sklearn.cluster._affinity_propagation.AffinityPropagation.predict.X": {
      "test.drop(['id'], axis=1)": 2
    },
    "sklearn.cluster._agglomerative.AgglomerativeClustering.fit_predict.X": {
      "df[['Murder', 'Assault', 'UrbanPop', 'Rape']]": 5,
      "components": 2,
      "train.drop(['id', 'target'], axis=1).iloc[len(train) * 8 // 10:]": 1,
      "test.drop(['id'], axis=1)": 1,
      "columns_std": 1,
      "data": 1,
      "feature_vecs": 1,
      "seq_dist": 1,
      "df_store.fillna(0)": 1,
      "df_store.fillna(1)": 1,
      "Means2_norm": 1,
      "agg_cluster_destination_id": 1,
      "tsne_representation[:n_tr]": 1
    },
    "sklearn.cluster._birch.Birch.__init__.threshold": {
      "0.5": 21,
      "0.01": 8,
      "0.6": 5,
      "0.4": 1
    },
    "sklearn.cluster._birch.Birch.predict.X": {
      "coords": 6,
      "train.drop(['id', 'target'], axis=1).iloc[len(train) * 8 // 10:]": 1,
      "test.drop(['id'], axis=1)": 1,
      "X": 1
    },
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.fit_intercept": {
      "True": 125
    },
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.intercept_scaling": {
      "1.0": 125
    },
    "sklearn.feature_extraction._hash.FeatureHasher.__init__.n_features": {
      "2**20": 11,
      "12": 2,
      "hash_vector_size": 2,
      "8": 2,
      "6": 1,
      "20": 1,
      "m": 1,
      "100": 1,
      "2**18": 1
    },
    "sklearn.feature_extraction._hash.FeatureHasher.transform.raw_X": {
      "X_train[col].astype('str')": 1,
      "X_train_hash.to_numpy()": 1,
      "phone['phone_brand'] + ' ' + phone['device_model']": 1,
      "review_df['business_id']": 1
    },
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.degree": {
      "3": 53
    },
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.coef0": {
      "1": 53
    },
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.kernel_params": {
      "None": 53
    },
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.alpha": {
      "1.0": 51,
      "0.1": 2
    },
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.fit_inverse_transform": {
      "False": 30,
      "True": 23
    },
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.eigen_solver": {
      "'auto'": 53
    },
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.tol": {
      "0": 53
    },
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.max_iter": {
      "None": 53
    },
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.remove_zero_eig": {
      "False": 53
    },
    "sklearn.multiclass.OneVsOneClassifier.fit.X": {
      "X_train": 2,
      "train_data": 1,
      "train": 1,
      "y_train_pred": 1
    },
    "sklearn.multiclass.OneVsOneClassifier.fit.y": {
      "y_train": 2,
      "Y": 1,
      "y": 1,
      "y_train.values.ravel()": 1
    },
    "sklearn.multiclass.OneVsOneClassifier.predict.X": {
      "test_data": 1,
      "test": 1,
      "X_test": 1,
      "test_eng": 1
    },
    "sklearn.mixture._gaussian_mixture.GaussianMixture.__init__.warm_start": {
      "False": 266
    },
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.fit_intercept": {
      "True": 85
    },
    "sklearn.preprocessing._discretization.KBinsDiscretizer.fit.X": {
      "X['Age'].values.reshape(-1, 1)": 1,
      "train_all['item_avg_price'].values.reshape(-1, 1)": 1,
      "train_all['cat_price'].values.reshape(-1, 1)": 1,
      "train_all['cat_shop_price'].values.reshape(-1, 1)": 1,
      "train_all['item_shop_price'].values.reshape(-1, 1)": 1,
      "X_train_e": 1,
      "X_test_e": 1,
      "df_train[features]": 1,
      "train_df[c].values.reshape(-1, 1)": 1,
      "train['Age'].to_numpy().reshape(-1, 1)": 1,
      "train['Fare'].to_numpy().reshape(-1, 1)": 1,
      "data[feature].values": 1
    },
    "sklearn.svm._classes.SVC.__init__.break_ties": {
      "False": 1667,
      "True": 8
    },
    "sklearn.impute._iterative.IterativeImputer.__init__.skip_complete": {
      "False": 53,
      "True": 2
    },
    "sklearn.feature_selection._mutual_info.mutual_info_classif.discrete_features": {
      "'auto'": 50,
      "True": 9,
      "discrete_features": 4,
      "self.index_discrete_columns": 2,
      "False": 1,
      "features": 1,
      "is_discrete": 1,
      "X.dtypes == np.int64": 1
    },
    "sklearn.metrics._scorer.get_scorer.scoring": {
      "'f1_macro'": 3,
      "'accuracy'": 1,
      "'neg_mean_squared_error'": 1
    },
    "sklearn.ensemble._stacking.StackingClassifier.__init__.n_jobs": {
      "None": 43,
      "-1": 5
    },
    "sklearn.neural_network._multilayer_perceptron.MLPRegressor.__init__.max_fun": {
      "15000": 139,
      "int(1000000.0)": 1,
      "10000": 1
    },
    "sklearn.decomposition._fastica.FastICA.__init__.tol": {
      "0.0001": 188,
      "0.03": 1,
      "0.1": 1
    },
    "sklearn.impute._base.MissingIndicator.fit_transform.X": {
      "df_miss[feature_cols]": 1
    },
    "sklearn.impute._iterative.IterativeImputer.__init__.add_indicator": {
      "False": 53,
      "True": 2
    },
    "sklearn.tree._export.plot_tree.label": {
      "'all'": 41,
      "None": 1
    },
    "sklearn.tree._export.plot_tree.rounded": {
      "False": 31,
      "True": 11
    },
    "sklearn.ensemble._stacking.StackingClassifier.__init__.verbose": {
      "0": 44,
      "3": 2,
      "1": 2
    },
    "sklearn.metrics._regression.mean_absolute_percentage_error.y_true": {
      "y_test": 3,
      "y_val": 1,
      "y_train": 1,
      "unit_sales_by_date.values[moving_average_days:]": 1
    },
    "sklearn.metrics._regression.mean_absolute_percentage_error.y_pred": {
      "pred": 2,
      "moving_avg": 1,
      "ar_predictions": 1,
      "arma_predictions": 1,
      "arima_predictions": 1
    },
    "sklearn.model_selection._split.TimeSeriesSplit.__init__.test_size": {
      "None": 126,
      "181": 1
    },
    "sklearn.metrics._regression.mean_squared_log_error.sample_weight": {
      "None": 1052
    },
    "sklearn.metrics._regression.mean_squared_log_error.multioutput": {
      "'uniform_average'": 1052
    },
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.analyzer": {
      "'word'": 65,
      "'char'": 1
    },
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.binary": {
      "False": 58,
      "hash_binary": 4,
      "True": 3,
      "Hash_binary": 1
    },
    "sklearn.ensemble._voting.VotingRegressor.__init__.verbose": {
      "False": 57,
      "True": 1
    },
    "sklearn.metrics._classification.f1_score.zero_division": {
      "'warn'": 4036,
      "0": 44,
      "True": 5,
      "1": 2
    },
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.n_alphas": {
      "100": 84,
      "10": 1
    },
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.precompute": {
      "'auto'": 84,
      "True": 1
    },
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.copy_X": {
      "True": 85
    },
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.positive": {
      "False": 83,
      "True": 2
    },
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.random_state": {
      "None": 72,
      "42": 8,
      "0": 3,
      "1": 1,
      "101": 1
    },
    "sklearn.linear_model._coordinate_descent.ElasticNetCV.__init__.selection": {
      "'cyclic'": 85
    },
    "sklearn.utils.class_weight.compute_sample_weight.indices": {
      "None": 9
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.loss": {
      "'auto'": 29,
      "'categorical_crossentropy'": 5,
      "'binary_crossentropy'": 1
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.scoring": {
      "'loss'": 29,
      "kappa_score": 5,
      "scoring": 1
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.predict.X": {
      "X_test": 5,
      "reduce_test": 1,
      "X_train": 1,
      "val_df_x": 1,
      "val_X": 1,
      "test[cols]": 1,
      "test_df": 1,
      "X_val": 1
    },
    "sklearn.model_selection._validation.learning_curve.random_state": {
      "None": 125,
      "1": 2,
      "42": 1,
      "random_state": 1
    },
    "sklearn.model_selection._validation.learning_curve.verbose": {
      "0": 126,
      "4": 1,
      "100": 1,
      "True": 1
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.n_iter_no_change": {
      "10": 30,
      "25": 4,
      "50": 1
    },
    "sklearn.impute._iterative.IterativeImputer.__init__.n_nearest_features": {
      "None": 53,
      "self.n_nearest_features": 1,
      "2": 1
    },
    "sklearn.impute._base.MissingIndicator.fit.X": {
      "X": 2
    },
    "sklearn.impute._base.MissingIndicator.transform.X": {
      "X": 1
    },
    "sklearn.compose._column_transformer.ColumnTransformer.__init__.sparse_threshold": {
      "0.3": 428,
      "0": 13,
      "sparse_threshold": 1,
      "0.9": 1
    },
    "sklearn.compose._column_transformer.ColumnTransformer.__init__.n_jobs": {
      "None": 433,
      "-1": 7,
      "1": 2,
      "n_jobs": 1
    },
    "sklearn.compose._column_transformer.ColumnTransformer.__init__.transformer_weights": {
      "None": 442,
      "transformer_weights": 1
    },
    "sklearn.pipeline.make_pipeline.verbose": {
      "False": 1090,
      "True": 7
    },
    "sklearn.decomposition._nmf.NMF.__init__.alpha": {
      "0.0": 58,
      "0.1": 5,
      "0.01": 1,
      "alpha": 1
    },
    "sklearn.decomposition._nmf.NMF.__init__.l1_ratio": {
      "0.0": 59,
      "0.5": 5,
      "l1_ratio": 1
    },
    "sklearn.impute._knn.KNNImputer.__init__.weights": {
      "'uniform'": 62,
      "'distance'": 2
    },
    "sklearn.ensemble._gb.GradientBoostingRegressor.staged_predict.X": {
      "X_test": 12,
      "X_test_scaled": 1
    },
    "sklearn.datasets._base.load_digits.return_X_y": {
      "False": 9,
      "True": 5
    },
    "sklearn.pipeline.FeatureUnion.fit.y": {
      "None": 35,
      "y": 9,
      "train_y": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.validation_fraction": {
      "0.1": 840,
      "0.2": 1
    },
    "sklearn.linear_model._stochastic_gradient.SGDClassifier.__init__.n_iter_no_change": {
      "5": 838,
      "10": 3
    },
    "sklearn.ensemble._voting.VotingClassifier.__init__.flatten_transform": {
      "True": 304
    },
    "sklearn.metrics.pairwise.pairwise_distances.X": {
      "train.v2_na.reshape(1, -1)": 9,
      "X": 2,
      "train_clus": 1,
      "row_use": 1,
      "train_data": 1,
      "unknown": 1,
      "feature": 1,
      "get_col(df, col)": 1,
      "title_features": 1,
      "tfidf_title_features": 1,
      "Matrix": 1,
      "hm": 1
    },
    "sklearn.metrics.pairwise.pairwise_distances.Y": {
      "train[elt].reshape(1, -1)": 9,
      "None": 5,
      "training": 1,
      "dataset": 1,
      "feature": 1,
      "get_col(df2, col)": 1,
      "title_features[doc_id]": 1,
      "tfidf_title_features[doc_id]": 1,
      "Matrix": 1
    },
    "sklearn.utils.multiclass.type_of_target.y": {
      "y": 10,
      "y_train": 2,
      "y_train_encoded": 2,
      "y_train.astype('int')": 1,
      "Y": 1,
      "df_train['winPlacePerc']": 1
    },
    "sklearn.utils.validation.check_array.ensure_2d": {
      "True": 47,
      "False": 12
    },
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.mahalanobis.X": {
      "df[NUMERIC_FEATURES]": 1,
      "combo_input[:, :]": 1
    },
    "sklearn.metrics._classification.f1_score.pos_label": {
      "1": 4082,
      "None": 3,
      "0": 2
    },
    "sklearn.metrics._classification.f1_score.sample_weight": {
      "None": 4087
    },
    "sklearn.model_selection._validation.cross_val_predict.groups": {
      "None": 212,
      "x.Patient": 1,
      "temp.Patient": 1
    },
    "sklearn.linear_model._coordinate_descent.Lasso.__init__.precompute": {
      "False": 742,
      "True": 6
    },
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.n_iter_no_change": {
      "5": 130,
      "250": 4
    },
    "sklearn.datasets._samples_generator.make_multilabel_classification.n_samples": {
      "10000": 1
    },
    "sklearn.datasets._samples_generator.make_multilabel_classification.n_features": {
      "20": 1
    },
    "sklearn.datasets._samples_generator.make_multilabel_classification.n_classes": {
      "5": 1
    },
    "sklearn.datasets._samples_generator.make_multilabel_classification.random_state": {
      "88": 1
    },
    "sklearn.preprocessing._data.RobustScaler.__init__.copy": {
      "True": 531,
      "False": 3
    },
    "sklearn.preprocessing._data.quantile_transform.n_quantiles": {
      "256": 3,
      "1000": 3,
      "900": 2
    },
    "sklearn.preprocessing._data.quantile_transform.output_distribution": {
      "'uniform'": 6,
      "'normal'": 2
    },
    "sklearn.preprocessing._data.quantile_transform.X": {
      "gray_img": 3,
      "df_train_trans[feature].values.reshape(-1, 1)": 1,
      "df_train['target'].values.reshape(-1, 1)": 1,
      "train[cols]": 1,
      "test.query('seq_length == 107')[cols]": 1,
      "test.query('seq_length == 130')[cols]": 1
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.loss": {
      "'hinge'": 37,
      "'log'": 2
    },
    "sklearn.cluster._agglomerative.AgglomerativeClustering.__init__.distance_threshold": {
      "None": 28,
      "0": 5,
      "0.2": 1,
      "threshold": 1,
      "20": 1
    },
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.fit_intercept": {
      "True": 118,
      "False": 2
    },
    "sklearn.linear_model._least_angle.LassoLarsIC.__init__.criterion": {
      "'aic'": 5,
      "'bic'": 2
    },
    "sklearn.linear_model._least_angle.LassoLarsIC.__init__.fit_intercept": {
      "True": 5,
      "False": 2
    },
    "sklearn.preprocessing._encoders.OneHotEncoder.fit_transform.y": {
      "None": 764,
      "cat_col": 1
    },
    "sklearn.metrics.pairwise.paired_euclidean_distances.X": {
      "pcities[1:]": 1,
      "cities[lines[:, 0]]": 1,
      "oddCities[oddLines[:, 0]]": 1
    },
    "sklearn.metrics.pairwise.paired_euclidean_distances.Y": {
      "pcities[:-1]": 1,
      "cities[lines[:, 1]]": 1,
      "oddCities[oddLines[:, 1]]": 1
    },
    "sklearn.cluster._agglomerative.AgglomerativeClustering.__init__.affinity": {
      "'euclidean'": 31,
      "'precomputed'": 2,
      "pearson_affinity": 2,
      "sim_affinity": 1
    },
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.__init__.warm_start": {
      "False": 21,
      "True": 3
    },
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.target": {
      "None": 7,
      "y": 4
    },
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.ax": {
      "ax": 6,
      "None": 2,
      "ax[0]": 1,
      "ax[1]": 1,
      "ax[2]": 1
    },
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.estimator": {
      "estim": 4,
      "m": 2,
      "clf": 1,
      "clf_2": 1,
      "model_rf": 1,
      "rf": 1,
      "kr": 1
    },
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.X": {
      "X": 5,
      "valid_xs": 3,
      "X_train": 2,
      "valid_xs_final": 1
    },
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.features": {
      "[1]": 2,
      "[*cols]": 1,
      "[(cols[9], cols[10])]": 1,
      "[(cols[3], cols[-2])]": 1,
      "[(cols[6], cols[-1])]": 1,
      "['YearMade', 'ProductSize']": 1,
      "['feature_fastai', 'date', 'feature_107', 'feature_116']": 1,
      "['feature_fastai', 'feature_119', 'feature_107']": 1,
      "['var_81', 'var_139', 'var_110']": 1,
      "['Sex_Male', 'Age']": 1
    },
    "sklearn.impute._base.SimpleImputer.fit.y": {
      "None": 173,
      "y": 2
    },
    "sklearn.impute._base.MissingIndicator.fit.y": {
      "y": 1,
      "None": 1
    },
    "sklearn.neighbors._lof.LocalOutlierFactor.__init__.contamination": {
      "'auto'": 6,
      "0.001": 4,
      "0.1": 3,
      "outliers_fraction": 2,
      "0.03": 1,
      "0.01": 1
    },
    "sklearn.neighbors._lof.LocalOutlierFactor.fit.X": {
      "X_scaled": 3,
      "ohe_reduced_transaction_df": 1
    },
    "sklearn.preprocessing._label.LabelBinarizer.inverse_transform.threshold": {
      "None": 22,
      "0.5": 1
    },
    "sklearn.model_selection._split.check_cv.classifier": {
      "is_classifier(self.estimator)": 10,
      "False": 5
    },
    "sklearn.model_selection._split.check_cv.cv": {
      "self.cv": 15
    },
    "sklearn.model_selection._split.check_cv.y": {
      "y": 9,
      "y_labels": 4,
      "None": 2
    },
    "sklearn.base.is_classifier.estimator": {
      "self.estimator": 11
    },
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.grid_resolution": {
      "100": 6,
      "20": 5
    },
    "sklearn.model_selection._validation.learning_curve.shuffle": {
      "False": 128,
      "True": 1
    },
    "sklearn.metrics._classification.jaccard_score.average": {
      "'binary'": 7,
      "'weighted'": 4,
      "'micro'": 2
    },
    "sklearn.neighbors._lof.LocalOutlierFactor.__init__.n_neighbors": {
      "20": 10,
      "10": 3,
      "35": 2,
      "5": 1,
      "150": 1
    },
    "sklearn.feature_selection._rfe.RFE.predict_proba.X": {
      "X_test": 4,
      "X_test_transformed": 2,
      "xvalid": 1,
      "test[xtrain.columns]": 1,
      "dataframe_tst": 1,
      "test": 1,
      "X_test_scaled": 1
    },
    "sklearn.metrics.pairwise.pairwise_distances.metric": {
      "'euclidean'": 14,
      "'l1'": 2,
      "'cosine'": 2,
      "car_iou": 1,
      "metric": 1,
      "'l2'": 1
    },
    "sklearn.model_selection._split.LeaveOneOut.get_n_splits.X": {
      "X_train": 1
    },
    "sklearn.utils.validation.check_X_y.dtype": {
      "'numeric'": 21
    },
    "sklearn.utils.validation.check_X_y.y_numeric": {
      "False": 20,
      "True": 1
    },
    "sklearn.utils.estimator_checks.check_estimator.Estimator": {
      "CorrelationSelector": 1
    },
    "sklearn.neighbors._unsupervised.NearestNeighbors.__init__.radius": {
      "1.0": 109,
      "radius": 1
    },
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.__init__.optimizer": {
      "'fmin_l_bfgs_b'": 23,
      "None": 1
    },
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.__init__.n_jobs": {
      "None": 22,
      "-1": 2
    },
    "sklearn.tree._export.export_graphviz.proportion": {
      "False": 197,
      "True": 5
    },
    "sklearn.dummy.DummyRegressor.__init__.constant": {
      "None": 51,
      "train['is_churn'].mean()": 1
    },
    "sklearn.tree._classes.DecisionTreeClassifier.fit.sample_weight": {
      "None": 919,
      "[1, 2, 3]": 3
    },
    "sklearn.metrics._classification.precision_recall_fscore_support.pos_label": {
      "1": 58
    },
    "sklearn.neighbors._kde.KernelDensity.__init__.metric": {
      "'euclidean'": 48,
      "'manhattan'": 2
    },
    "sklearn.ensemble._bagging.BaggingClassifier.__init__.bootstrap_features": {
      "False": 184,
      "True": 2
    },
    "sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay.plot.values_format": {
      "None": 30,
      "values_format": 2
    },
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix.ax": {
      "None": 174,
      "ax": 4,
      "ax0": 1,
      "ax[ind]": 1
    },
    "sklearn.preprocessing._function_transformer.FunctionTransformer.__init__.inverse_func": {
      "None": 454,
      "np.expm1": 1,
      "np.exp": 1
    },
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.weight_concentration_prior_type": {
      "'dirichlet_process'": 25
    },
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.weight_concentration_prior": {
      "None": 23,
      "0.001": 2
    },
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.n_init": {
      "1": 25
    },
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.__init__.priors": {
      "None": 287
    },
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.__init__.store_covariance": {
      "False": 287
    },
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.__init__.covariance_estimator": {
      "None": 287
    },
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.fit.X": {
      "X_train": 1
    },
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.fit.y": {
      "y_train": 1
    },
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.__init__.radius": {
      "50": 1,
      "500.0": 1
    },
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.__init__.weights": {
      "'uniform'": 2
    },
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.__init__.algorithm": {
      "'auto'": 2
    },
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.__init__.leaf_size": {
      "30": 2
    },
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.__init__.p": {
      "2": 2
    },
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.__init__.metric": {
      "'minkowski'": 2
    },
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.__init__.outlier_label": {
      "None": 2
    },
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.__init__.metric_params": {
      "None": 2
    },
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.__init__.n_jobs": {
      "None": 2
    },
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.predict.X": {
      "X_test": 1,
      "X_train": 1
    },
    "sklearn.tree._classes.DecisionTreeClassifier.__init__.ccp_alpha": {
      "0.0": 1544,
      "ccp_alpha": 2,
      "0.00375": 1,
      "ideal_alpha": 1
    },
    "sklearn.preprocessing._data.PowerTransformer.__init__.standardize": {
      "True": 76
    },
    "sklearn.metrics.pairwise.pairwise_distances_argmin_min.X": {
      "km.cluster_centers_": 1
    },
    "sklearn.metrics.pairwise.pairwise_distances_argmin_min.Y": {
      "X": 1
    },
    "sklearn.datasets._samples_generator.make_blobs.n_features": {
      "2": 3,
      "4": 1
    },
    "sklearn.preprocessing._function_transformer.FunctionTransformer.__init__.kw_args": {
      "None": 398,
      "{'factor': 1}": 30,
      "{'factor': 1 / 600}": 10,
      "{'l': 0.0001, 'h': 0.0001}": 5,
      "{'split_aspect': True, 'aspect_slope': True, 'drop_aspects': True, 'elev_asp_slope': True, 'asp_slope_factor': 10}": 3,
      "{'perf_bin_onehot': True}": 1,
      "{'bins': bins, 'labels': labels, 'retbins': False}": 1,
      "{'g': 6, 'p': 0.25}": 1,
      "{'factor': optpars['fnc_graph_ridge_degree_scale'][target]}": 1,
      "{'factor': optpars['fnc_graph_ridge_clustering_r_scale'][target]}": 1,
      "{'factor': optpars['fnc_graph_ridge_clustering_i_scale'][target]}": 1,
      "{'factor': optpars['fnc_graph_ridge_betweenness_scale'][target]}": 1,
      "{'factor': optpars['fnc_graph_ridge_eigenvec_scale'][target]}": 1,
      "{'factor': optpars['fnc_graph_ridge_gm_scale'][target]}": 1,
      "{'factor': optpars['fnc_graph_ridge_csf_scale'][target]}": 1
    },
    "sklearn.ensemble._stacking.StackingRegressor.__init__.passthrough": {
      "False": 65
    },
    "sklearn.datasets._base.load_files.container_path": {
      "path": 2,
      "'../input/alldata4ai/data_all/data_all/'": 2
    },
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__.verbose": {
      "0": 5,
      "False": 1,
      "True": 1
    },
    "sklearn.ensemble._forest.RandomTreesEmbedding.transform.X": {
      "X_test.loc[:, continuous_features]": 2,
      "X_train.loc[trn_idx, continuous_features]": 1,
      "X_train.loc[val_idx, continuous_features]": 1,
      "X_train.loc[:, continuous_features]": 1,
      "X_train": 1,
      "X_test": 1
    },
    "sklearn.feature_selection._mutual_info.mutual_info_regression.n_neighbors": {
      "3": 58,
      "5": 1,
      "20": 1
    },
    "sklearn.feature_selection._mutual_info.mutual_info_regression.copy": {
      "True": 60
    },
    "sklearn.metrics.cluster._unsupervised.silhouette_samples.X": {
      "X": 2,
      "X_subset": 1
    },
    "sklearn.metrics.cluster._unsupervised.silhouette_samples.labels": {
      "cluster_labels": 3
    },
    "sklearn.metrics._classification.classification_report.zero_division": {
      "'warn'": 3070,
      "0": 4
    },
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.verbose": {
      "0": 60,
      "1": 1,
      "False": 1
    },
    "sklearn.ensemble._bagging.BaggingClassifier.__init__.oob_score": {
      "False": 182,
      "True": 4
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.loss": {
      "'least_squares'": 30
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.max_depth": {
      "None": 20,
      "4": 4,
      "18": 2,
      "2": 1,
      "5": 1,
      "3": 1,
      "15": 1
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.min_samples_leaf": {
      "20": 26,
      "40": 1,
      "1": 1,
      "25": 1,
      "28": 1
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.max_leaf_nodes": {
      "31": 28,
      "29": 1,
      "64": 1
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.learning_rate": {
      "0.1": 22,
      "0.05": 3,
      "0.01": 2,
      "0.15": 1,
      "0.013": 1,
      "0.0025": 1
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.max_iter": {
      "100": 20,
      "500": 3,
      "225": 1,
      "175": 1,
      "10000": 1,
      "1750": 1,
      "num_rounds": 1,
      "5000": 1,
      "6500": 1
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.random_state": {
      "None": 22,
      "rand": 3,
      "42": 1,
      "CFG['seed']": 1,
      "random_state": 1,
      "0": 1,
      "1": 1
    },
    "sklearn.linear_model._glm.glm.TweedieRegressor.__init__.alpha": {
      "1.0": 9,
      "0.005": 1
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.staged_predict_proba.X": {
      "X_train": 1,
      "X_valid": 1
    },
    "sklearn.linear_model._perceptron.Perceptron.__init__.tol": {
      "0.001": 77,
      "0.0001": 1
    },
    "sklearn.cluster._birch.Birch.__init__.branching_factor": {
      "50": 13,
      "100": 12,
      "150": 6,
      "10": 2,
      "60": 1,
      "25": 1
    },
    "sklearn.cluster._birch.Birch.__init__.compute_labels": {
      "True": 35
    },
    "sklearn.cross_decomposition._pls.CCA.__init__.n_components": {
      "1": 1
    },
    "sklearn.base.RegressorMixin.score.sample_weight": {
      "None": 1799,
      "W_train": 1,
      "W_test": 1
    },
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.n_jobs": {
      "None": 55,
      "-1": 5,
      "3": 1,
      "4": 1
    },
    "sklearn.decomposition._incremental_pca.IncrementalPCA.__init__.n_components": {
      "5": 3,
      "90": 1,
      "n_components": 1,
      "nr_components": 1,
      "4": 1,
      "in_components": 1,
      "150": 1
    },
    "sklearn.decomposition._incremental_pca.IncrementalPCA.partial_fit.X": {
      "train": 1,
      "chunk[predictors]": 1,
      "x": 1,
      "i.drop(['winPlacePerc'], axis=1).values": 1
    },
    "sklearn.decomposition._incremental_pca.IncrementalPCA.transform.X": {
      "cat[predictors]": 2,
      "train": 1,
      "features": 1,
      "test_df": 1,
      "x": 1,
      "X_val": 1,
      "X_test": 1,
      "digitsTest": 1
    },
    "sklearn.ensemble._bagging.BaggingRegressor.__init__.oob_score": {
      "False": 141,
      "True": 1
    },
    "sklearn.svm._classes.NuSVC.__init__.tol": {
      "0.001": 106,
      "tol": 1,
      "0.008654": 1
    },
    "sklearn.decomposition._kernel_pca.KernelPCA.__init__.copy_X": {
      "True": 51,
      "False": 2
    },
    "sklearn.naive_bayes.CategoricalNB.__init__.alpha": {
      "1.0": 3,
      "3.4": 2,
      "5.0": 1
    },
    "sklearn.naive_bayes.CategoricalNB.fit.X": {
      "X_train_oe": 2,
      "X_train": 1,
      "X": 1,
      "X_oe": 1
    },
    "sklearn.naive_bayes.CategoricalNB.fit.y": {
      "y_train": 3,
      "Y": 1,
      "df.target": 1
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.predict_log_proba.X": {
      "X_val": 2
    },
    "sklearn.metrics._classification.recall_score.zero_division": {
      "'warn'": 1086,
      "0": 36,
      "1": 2
    },
    "sklearn.cluster._kmeans.k_means.max_iter": {
      "400": 2,
      "300": 2
    },
    "sklearn.cluster._kmeans.k_means.random_state": {
      "0": 2,
      "None": 2
    },
    "sklearn.metrics._classification.precision_score.pos_label": {
      "1": 1148,
      "None": 3,
      "0": 2
    },
    "sklearn.metrics._classification.recall_score.pos_label": {
      "1": 1119,
      "None": 3,
      "0": 2
    },
    "sklearn.naive_bayes.BernoulliNB.__init__.class_prior": {
      "None": 205,
      "prior": 1
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.l2_regularization": {
      "0.0": 28,
      "0.5": 1,
      "0.02": 1
    },
    "sklearn.decomposition._pca.PCA.__init__.iterated_power": {
      "'auto'": 2653
    },
    "sklearn.decomposition._pca.PCA.__init__.tol": {
      "0.0": 2653
    },
    "sklearn.linear_model._huber.HuberRegressor.__init__.alpha": {
      "0.0001": 35,
      "0.05": 2,
      "0.0": 2,
      "0.001": 1
    },
    "sklearn.metrics._regression.explained_variance_score.multioutput": {
      "'uniform_average'": 79
    },
    "sklearn.model_selection._search.RandomizedSearchCV.__init__.pre_dispatch": {
      "'2*n_jobs'": 572,
      "0": 1
    },
    "sklearn.metrics.pairwise.manhattan_distances.X": {
      "i": 6,
      "[[-73.988129, 40.732029]]": 1,
      "[[row['pickup_longitude'], row['pickup_latitude']]]": 1
    },
    "sklearn.metrics.pairwise.manhattan_distances.Y": {
      "j": 6,
      "[[-73.990173, 40.75668]]": 1,
      "[[row['dropoff_longitude'], row['dropoff_latitude']]]": 1
    },
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.normalize": {
      "False": 117,
      "True": 3
    },
    "sklearn.pipeline.Pipeline.decision_function.X": {
      "data.loc['validation']": 2,
      "X_test": 1,
      "test_df": 1,
      "validation_stack": 1,
      "test": 1
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.tol": {
      "0.001": 39
    },
    "sklearn.metrics._classification.jaccard_score.pos_label": {
      "1": 9,
      "0": 4
    },
    "sklearn.ensemble._bagging.BaggingClassifier.__init__.warm_start": {
      "False": 186
    },
    "sklearn.ensemble._bagging.BaggingClassifier.__init__.verbose": {
      "0": 185,
      "1": 1
    },
    "sklearn.linear_model._bayes.BayesianRidge.predict.return_std": {
      "False": 120,
      "True": 1
    },
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.decode_error": {
      "'strict'": 64,
      "'ignore'": 2
    },
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.alternate_sign": {
      "True": 55,
      "False": 11
    },
    "sklearn.utils.extmath.density.w": {
      "clf.coef_": 3
    },
    "sklearn.naive_bayes.ComplementNB.__init__.alpha": {
      "1.0": 5,
      "0.01": 2,
      "alpha": 1
    },
    "sklearn.covariance._shrunk_covariance.ShrunkCovariance.fit.X": {
      "x_cluster": 2,
      "x2": 1,
      "x2b": 1
    },
    "sklearn.svm._classes.NuSVR.__init__.degree": {
      "3": 56
    },
    "sklearn.svm._classes.NuSVR.__init__.shrinking": {
      "True": 56
    },
    "sklearn.preprocessing._encoders.OrdinalEncoder.inverse_transform.X": {
      "ts['feat_static_cat'].reshape(1, -1)": 4,
      "df['train'][features['cat']]": 2,
      "df['test'][features['cat']]": 2
    },
    "sklearn.metrics._classification.accuracy_score.sample_weight": {
      "None": 7122,
      "np.apply_along_axis(lambda x: type_ratio[x], 0, y_true - 1)": 2,
      "y_train.map(test_weight_map)": 1,
      "y_test.map(test_weight_map)": 1,
      "y.map(test_weight_map)": 1
    },
    "sklearn.manifold._isomap.Isomap.fit_transform.X": {
      "X": 1,
      "X_iso_train": 1,
      "df": 1,
      "trans_df": 1,
      "X_train": 1
    },
    "sklearn.metrics.cluster._supervised.homogeneity_score.labels_true": {
      "labels_true": 5,
      "labels_true_wr": 3
    },
    "sklearn.metrics.cluster._supervised.homogeneity_score.labels_pred": {
      "labels": 5,
      "labels_wr": 3
    },
    "sklearn.metrics.cluster._supervised.completeness_score.labels_true": {
      "labels_true": 5,
      "labels_true_wr": 3
    },
    "sklearn.metrics.cluster._supervised.completeness_score.labels_pred": {
      "labels": 5,
      "labels_wr": 3
    },
    "sklearn.decomposition._incremental_pca.IncrementalPCA.__init__.copy": {
      "True": 8,
      "False": 1
    },
    "sklearn.decomposition._incremental_pca.IncrementalPCA.__init__.batch_size": {
      "None": 7,
      "len(features) // 5": 1,
      "10": 1
    },
    "sklearn.decomposition._incremental_pca.IncrementalPCA.fit.X": {
      "fnc": 2,
      "features": 1
    },
    "sklearn.metrics._regression.mean_squared_error.multioutput": {
      "'uniform_average'": 8440,
      "'raw_values'": 19,
      "multioutput": 2,
      "multi": 1
    },
    "sklearn.preprocessing._data.quantile_transform.random_state": {
      "None": 5,
      "0": 3
    },
    "sklearn.preprocessing._data.quantile_transform.copy": {
      "True": 8
    },
    "sklearn.tree._export.plot_tree.max_depth": {
      "None": 39,
      "3": 1,
      "2": 1,
      "4": 1
    },
    "sklearn.datasets._openml.fetch_openml.version": {
      "1": 2,
      "'active'": 1
    },
    "sklearn.datasets._openml.fetch_openml.name": {
      "'mnist_784'": 3
    },
    "sklearn.decomposition._sparse_pca.SparsePCA.transform.X": {
      "normalize(test[features], axis=0)": 1,
      "test": 1,
      "test_df": 1
    },
    "sklearn.linear_model._logistic.LogisticRegression.predict_log_proba.X": {
      "x_test": 1,
      "X_train": 1,
      "X_test": 1
    },
    "sklearn.cluster._kmeans.MiniBatchKMeans.__init__.reassignment_ratio": {
      "0.01": 104,
      "0.09": 1
    },
    "sklearn.base.ClusterMixin.fit_predict.X": {
      "x1": 6,
      "x2": 6,
      "x_train_0": 5,
      "x_train_1": 5,
      "X": 1,
      "tsne_representation[:n_tr]": 1
    },
    "sklearn.pipeline.FeatureUnion.__init__.verbose": {
      "False": 323,
      "True": 1
    },
    "sklearn.metrics._classification.balanced_accuracy_score.sample_weight": {
      "None": 22,
      "[weights[i] for i in y_true]": 1
    },
    "sklearn.metrics._classification.precision_recall_fscore_support.beta": {
      "1.0": 57,
      "1": 1
    },
    "sklearn.cross_decomposition._pls.PLSSVD.__init__.n_components": {
      "10": 3
    },
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.positive": {
      "False": 118,
      "True": 2
    },
    "sklearn.metrics._classification.multilabel_confusion_matrix.sample_weight": {
      "None": 57
    },
    "sklearn.cluster._spectral.SpectralClustering.__init__.eigen_solver": {
      "None": 7,
      "'arpack'": 2
    },
    "sklearn.utils.validation.check_array.estimator": {
      "None": 51,
      "self": 8
    },
    "sklearn.utils.validation.check_array.force_all_finite": {
      "True": 56,
      "'allow-nan'": 2,
      "False": 1
    },
    "sklearn.cluster._birch.Birch.__init__.copy": {
      "True": 35
    },
    "sklearn.linear_model._perceptron.Perceptron.__init__.penalty": {
      "None": 78
    },
    "sklearn.linear_model._perceptron.Perceptron.__init__.alpha": {
      "0.0001": 78
    },
    "sklearn.linear_model._perceptron.Perceptron.__init__.fit_intercept": {
      "True": 78
    },
    "sklearn.linear_model._perceptron.Perceptron.__init__.shuffle": {
      "True": 78
    },
    "sklearn.linear_model._perceptron.Perceptron.__init__.verbose": {
      "0": 78
    },
    "sklearn.linear_model._perceptron.Perceptron.__init__.n_jobs": {
      "None": 74,
      "-1": 3,
      "model_njobs": 1
    },
    "sklearn.linear_model._perceptron.Perceptron.__init__.warm_start": {
      "False": 78
    },
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.predict.X": {
      "X_test": 6,
      "monster_train_B[features]": 1,
      "X_test[1001:1002]": 1,
      "reduce_test[fear]": 1
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.random_state": {
      "None": 34,
      "0": 5
    },
    "sklearn.linear_model._ridge.RidgeClassifierCV.fit.X": {
      "X": 3,
      "X_train": 2,
      "tfidf_train": 1,
      "train_vectors": 1
    },
    "sklearn.linear_model._ridge.RidgeClassifierCV.fit.y": {
      "y": 3,
      "Y_train": 2,
      "y_train": 1,
      "train_data['target']": 1
    },
    "sklearn.linear_model._theil_sen.TheilSenRegressor.fit.X": {
      "X_train": 1
    },
    "sklearn.linear_model._theil_sen.TheilSenRegressor.fit.y": {
      "y_train": 1
    },
    "sklearn.linear_model._ransac.RANSACRegressor.score.X": {
      "X_test": 1
    },
    "sklearn.linear_model._ransac.RANSACRegressor.score.y": {
      "y_test": 1
    },
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.__init__.store_precision": {
      "True": 62,
      "False": 1
    },
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.__init__.assume_centered": {
      "False": 62,
      "True": 1
    },
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.fit.X": {
      "X": 1
    },
    "sklearn.datasets._base.load_boston.return_X_y": {
      "False": 19,
      "True": 1
    },
    "sklearn.metrics._classification.precision_recall_fscore_support.labels": {
      "None": 57,
      "np.unique(y_pred)": 1
    },
    "sklearn.kernel_approximation.RBFSampler.__init__.random_state": {
      "0": 1,
      "1": 1
    },
    "sklearn.kernel_approximation.RBFSampler.__init__.gamma": {
      "1": 1,
      "1.0": 1
    },
    "sklearn.kernel_approximation.RBFSampler.transform.X": {
      "X": 1
    },
    "sklearn.manifold._spectral_embedding.SpectralEmbedding.__init__.n_jobs": {
      "None": 9,
      "-1": 1
    },
    "sklearn.isotonic.IsotonicRegression.predict.T": {
      "preds2": 2
    },
    "sklearn.tree._export.plot_tree.ax": {
      "None": 41,
      "ax": 1
    },
    "sklearn.tree._export.plot_tree.fontsize": {
      "None": 38,
      "8": 2,
      "10": 1,
      "12": 1
    },
    "sklearn.metrics.pairwise.cosine_distances.X": {
      "tfidf_comb": 1
    },
    "sklearn.metrics.pairwise.paired_distances.X": {
      "src_arr": 5
    },
    "sklearn.metrics.pairwise.paired_distances.Y": {
      "point1d": 5
    },
    "sklearn.linear_model._huber.HuberRegressor.__init__.epsilon": {
      "1.35": 37,
      "epsilon": 2,
      "2.95": 1
    },
    "sklearn.inspection._partial_dependence.partial_dependence.features": {
      "feature": 1
    },
    "sklearn.inspection._partial_dependence.partial_dependence.X": {
      "data": 1
    },
    "sklearn.inspection._partial_dependence.partial_dependence.grid_resolution": {
      "50": 1
    },
    "sklearn.inspection._partial_dependence.partial_dependence.estimator": {
      "clf": 1
    },
    "sklearn.kernel_approximation.Nystroem.__init__.kernel": {
      "'rbf'": 5
    },
    "sklearn.kernel_approximation.Nystroem.__init__.n_components": {
      "100": 5
    },
    "sklearn.kernel_approximation.Nystroem.__init__.random_state": {
      "None": 3,
      "0": 2
    },
    "sklearn.kernel_approximation.Nystroem.transform.X": {
      "x_test": 3,
      "sig_data_final_test": 1
    },
    "sklearn.feature_extraction.text.CountVectorizer.__init__.input": {
      "'content'": 2936,
      "'train_df[\"text\"]'": 1
    },
    "sklearn.decomposition._nmf.NMF.__init__.solver": {
      "'cd'": 63,
      "'mu'": 2
    },
    "sklearn.manifold._isomap.Isomap.__init__.eigen_solver": {
      "'auto'": 13,
      "'dense'": 2
    },
    "sklearn.datasets._samples_generator.make_circles.noise": {
      "0.2": 1,
      "0.1": 1
    },
    "sklearn.datasets._samples_generator.make_circles.factor": {
      "0.5": 1,
      "0.25": 1
    },
    "sklearn.datasets._samples_generator.make_circles.random_state": {
      "1": 1,
      "None": 1
    },
    "sklearn.datasets._samples_generator.make_moons.noise": {
      "0.3": 5,
      "0.05": 4,
      "0.15": 1
    },
    "sklearn.datasets._samples_generator.make_moons.random_state": {
      "None": 8,
      "0": 2
    },
    "sklearn.multiclass.OneVsRestClassifier.decision_function.X": {
      "X_test": 2,
      "xval": 2
    },
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.covariance_type": {
      "'full'": 25
    },
    "sklearn.manifold._mds.smacof.n_components": {
      "2": 2
    },
    "sklearn.manifold._mds.smacof.dissimilarities": {
      "D.to_numpy()": 1,
      "D": 1
    },
    "sklearn.covariance._shrunk_covariance.LedoitWolf.fit.X": {
      "returnsClosePrevMktres1": 2,
      "bData0": 2,
      "bData1": 2,
      "residual": 1,
      "returnsClosePrevRaw1": 1,
      "x21": 1,
      "x22": 1,
      "x23": 1,
      "x24": 1,
      "x2b1": 1,
      "x2b2": 1,
      "x2b3": 1,
      "x2b4": 1
    },
    "sklearn.inspection._permutation_importance.permutation_importance.n_jobs": {
      "None": 23,
      "-1": 1,
      "2": 1
    },
    "sklearn.ensemble._stacking.StackingClassifier.__init__.stack_method": {
      "'auto'": 42,
      "'predict_proba'": 4,
      "'predict'": 2
    },
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.preprocessor": {
      "None": 65,
      "preprocessor": 1
    },
    "sklearn.neural_network._rbm.BernoulliRBM.__init__.n_components": {
      "2": 2
    },
    "sklearn.neural_network._rbm.BernoulliRBM.__init__.random_state": {
      "1": 1,
      "None": 1
    },
    "sklearn.neighbors._lof.LocalOutlierFactor.__init__.n_jobs": {
      "None": 14,
      "-1": 3
    },
    "sklearn._config.set_config.print_changed_only": {
      "None": 24,
      "False": 1
    },
    "sklearn.model_selection._split.LeaveOneGroupOut.get_n_splits.X": {
      "X": 3
    },
    "sklearn.model_selection._split.LeaveOneGroupOut.get_n_splits.y": {
      "y1": 1,
      "y2": 1,
      "y3": 1
    },
    "sklearn.model_selection._split.LeaveOneGroupOut.get_n_splits.groups": {
      "groups": 3
    },
    "sklearn.feature_extraction._hash.FeatureHasher.__init__.dtype": {
      "np.float64": 20,
      "np.float32": 2
    },
    "sklearn.metrics._regression.max_error.y_true": {
      "y_test": 22
    },
    "sklearn.metrics._regression.max_error.y_pred": {
      "pred": 3,
      "y_test_pred": 2,
      "y_test_pred2": 2,
      "rdg_predict": 2,
      "rf_predict": 2,
      "gr_predict": 2,
      "y_pred": 1,
      "y_pred_2": 1,
      "xgb_predict": 1,
      "lgb_predict": 1,
      "vote_predict": 1,
      "sr_predict": 1,
      "svr_predict": 1,
      "gb_predict": 1,
      "kn_predict": 1
    },
    "sklearn.impute._iterative.IterativeImputer.__init__.max_value": {
      "np.inf": 54,
      "100": 1
    },
    "sklearn.feature_selection._univariate_selection.SelectFdr.__init__.alpha": {
      "0.03": 1
    },
    "sklearn.feature_selection._univariate_selection.SelectFdr.__init__.score_func": {
      "mutual_info_classif": 1
    },
    "sklearn.feature_selection._univariate_selection.SelectFwe.__init__.alpha": {
      "0.03": 1
    },
    "sklearn.feature_selection._univariate_selection.SelectFwe.__init__.score_func": {
      "mutual_info_classif": 1
    },
    "sklearn.decomposition._kernel_pca.KernelPCA.fit.X": {
      "x_train": 1
    },
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.__init__.n_jobs": {
      "-1": 1
    },
    "sklearn.preprocessing._label.MultiLabelBinarizer.inverse_transform.yt": {
      "np.round(preds)": 1,
      "pred_classes": 1,
      "np.where(Y_.cpu().detach().numpy() > 0.5, 1, 0)": 1,
      "Y_predict[1:8]": 1,
      "predicted": 1
    },
    "sklearn.metrics._plot.precision_recall_curve.plot_precision_recall_curve.ax": {
      "None": 6,
      "ax[2]": 1
    },
    "sklearn.inspection._permutation_importance.permutation_importance.scoring": {
      "None": 14,
      "'neg_mean_squared_error'": 10,
      "'roc_auc'": 1
    },
    "sklearn.datasets._samples_generator.make_moons.n_samples": {
      "1000": 4,
      "200": 4,
      "n_samples": 1,
      "100": 1
    },
    "sklearn.cluster._agglomerative.AgglomerativeClustering.fit.y": {
      "None": 18,
      "target": 1,
      "agg_cluster_Y": 1
    },
    "sklearn.utils.validation.check_X_y.force_all_finite": {
      "True": 19,
      "False": 2
    },
    "sklearn.utils.safe_sqr.X": {
      "coefs": 2
    },
    "sklearn.utils.metaestimators.if_delegate_has_method.delegate": {
      "'estimator'": 5
    },
    "sklearn.utils.safe_mask.X": {
      "X": 1,
      "X_train": 1
    },
    "sklearn.utils.safe_mask.mask": {
      "mask": 1,
      "X_mask": 1
    },
    "sklearn.preprocessing._data.KernelCenterer.transform.K": {
      "X_tst": 1
    },
    "sklearn.neighbors._lof.LocalOutlierFactor.__init__.metric": {
      "'minkowski'": 16,
      "'manhattan'": 1
    },
    "sklearn.manifold._mds.MDS.__init__.n_jobs": {
      "None": 10,
      "1": 1
    },
    "sklearn.manifold._isomap.Isomap.__init__.n_jobs": {
      "None": 14,
      "4": 1
    },
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.strip_accents": {
      "None": 61,
      "'unicode'": 5
    },
    "sklearn.feature_extraction.text.HashingVectorizer.fit.X": {
      "train['text']": 2,
      "list(train_df.cleaned_text.values) + list(test_df.cleaned_text.values)": 1,
      "df": 1,
      "df_train['text']": 1
    },
    "sklearn.calibration.calibration_curve.normalize": {
      "False": 21,
      "True": 4
    },
    "sklearn.linear_model._base.LinearRegression.__init__.positive": {
      "False": 2983,
      "True": 1
    },
    "sklearn.neighbors._nearest_centroid.NearestCentroid.fit.X": {
      "train_X": 1
    },
    "sklearn.neighbors._nearest_centroid.NearestCentroid.fit.y": {
      "train_y": 1
    },
    "sklearn.neighbors._nearest_centroid.NearestCentroid.predict.X": {
      "val_X": 1
    },
    "sklearn.preprocessing._data.RobustScaler.inverse_transform.X": {
      "pred_.reshape(-1, 1)": 1,
      "ridge_prediction": 1,
      "y_pred": 1
    },
    "sklearn.cluster._optics.OPTICS.__init__.xi": {
      "0.05": 2,
      "xier": 1,
      "0.2": 1
    },
    "sklearn.cluster._optics.OPTICS.__init__.min_cluster_size": {
      "None": 3,
      "0.05": 1
    },
    "sklearn.metrics._ranking.roc_auc_score.labels": {
      "None": 8288,
      "config['labels']": 4,
      "np.array([0, 1])": 3,
      "np.unique(tgts)": 2
    },
    "sklearn.preprocessing._data.power_transform.method": {
      "'yeo-johnson'": 2
    },
    "sklearn.preprocessing._data.power_transform.X": {
      "train_test[feature].values.reshape(-1, 1)": 1,
      "np.expand_dims(predictions_template_df['confidenceValue'], axis=1)": 1
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.tol": {
      "1e-07": 35
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.warm_start": {
      "False": 35
    },
    "sklearn.cluster._kmeans.KMeans.score.X": {
      "X": 1,
      "data": 1
    },
    "sklearn.isotonic.IsotonicRegression.__init__.out_of_bounds": {
      "'nan'": 9,
      "'clip'": 1
    },
    "sklearn.neighbors._regression.RadiusNeighborsRegressor.__init__.radius": {
      "r": 1,
      "radius": 1,
      "1.0": 1
    },
    "sklearn.neighbors._regression.RadiusNeighborsRegressor.__init__.weights": {
      "'uniform'": 2,
      "w": 1
    },
    "sklearn.neighbors._regression.RadiusNeighborsRegressor.__init__.metric": {
      "'minkowski'": 2,
      "m": 1
    },
    "sklearn.neighbors._regression.RadiusNeighborsRegressor.__init__.p": {
      "2": 2,
      "p": 1
    },
    "sklearn.neighbors._regression.RadiusNeighborsRegressor.fit.X": {
      "X_train": 1
    },
    "sklearn.neighbors._regression.RadiusNeighborsRegressor.fit.y": {
      "y_train": 1
    },
    "sklearn.neighbors._regression.RadiusNeighborsRegressor.predict.X": {
      "X_test": 1
    },
    "sklearn.datasets._base.load_breast_cancer.return_X_y": {
      "True": 1,
      "False": 1
    },
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.__init__.random_state": {
      "None": 20,
      "123": 2,
      "random_seed": 1,
      "0": 1
    },
    "sklearn.tree._classes.ExtraTreeClassifier.__init__.random_state": {
      "None": 28,
      "123": 2,
      "random_seed": 1,
      "42": 1
    },
    "sklearn.feature_extraction.text.TfidfTransformer.transform.copy": {
      "True": 117,
      "False": 1
    },
    "sklearn.cluster._kmeans.KMeans.fit_transform.y": {
      "None": 23,
      "y[:150000]": 1
    },
    "sklearn.random_projection.SparseRandomProjection.__init__.eps": {
      "0.1": 102,
      "1": 1
    },
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix.xticks_rotation": {
      "'horizontal'": 176,
      "70": 4
    },
    "sklearn.feature_extraction.text.CountVectorizer.inverse_transform.X": {
      "Xs_test": 1
    },
    "sklearn.random_projection.BaseRandomProjection.fit.X": {
      "alldata": 2,
      "emotions_vectors": 1
    },
    "sklearn.preprocessing._function_transformer.FunctionTransformer.__init__.check_inverse": {
      "True": 454,
      "False": 2
    },
    "sklearn.datasets._openml.fetch_openml.as_frame": {
      "'auto'": 2,
      "False": 1
    },
    "sklearn.compose._column_transformer.ColumnTransformer.fit.y": {
      "None": 29,
      "y": 2
    },
    "sklearn.model_selection._search.RandomizedSearchCV.__init__.error_score": {
      "np.nan": 567,
      "0": 4,
      "'raise'": 1,
      "-1.0": 1
    },
    "sklearn.model_selection._validation.learning_curve.fit_params": {
      "None": 128,
      "fitParams": 1
    },
    "sklearn.impute._knn.KNNImputer.__init__.metric": {
      "'nan_euclidean'": 64
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.random_state": {
      "17": 1
    },
    "sklearn.manifold._t_sne.TSNE.fit_transform.y": {
      "None": 527,
      "train_df_org_label": 1
    },
    "sklearn.datasets._samples_generator.make_circles.n_samples": {
      "1000": 1,
      "100": 1
    },
    "sklearn.preprocessing._data.StandardScaler.partial_fit.X": {
      "warmup_train[columns_std]": 1,
      "train[columns_std]": 1
    },
    "sklearn.svm._classes.NuSVC.__init__.cache_size": {
      "200": 107,
      "1000": 1
    },
    "sklearn.datasets._base.load_iris.return_X_y": {
      "False": 36,
      "True": 2
    },
    "sklearn.linear_model._ridge.RidgeClassifier.__init__.tol": {
      "0.001": 146,
      "0.01": 5
    },
    "sklearn.linear_model._ridge.RidgeClassifier.__init__.solver": {
      "'auto'": 140,
      "'sag'": 6,
      "'lsqr'": 4,
      "'sparse_cg'": 1
    },
    "sklearn.cluster._kmeans.MiniBatchKMeans.__init__.max_no_improvement": {
      "10": 105
    },
    "sklearn.metrics.pairwise.pairwise_distances_argmin.X": {
      "X": 2,
      "k_means_cluster_centers": 1
    },
    "sklearn.metrics.pairwise.pairwise_distances_argmin.Y": {
      "mbk_means_cluster_centers": 2,
      "k_means_cluster_centers": 1
    },
    "sklearn.decomposition._lda.LatentDirichletAllocation.fit.y": {
      "None": 28,
      "y_train": 1
    },
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.n_components": {
      "n_comp": 2
    },
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.alpha": {
      "0.1": 2
    },
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.n_iter": {
      "50": 2
    },
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.batch_size": {
      "3": 2
    },
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.random_state": {
      "42": 2
    },
    "sklearn.cluster._kmeans.MiniBatchKMeans.__init__.tol": {
      "0.0": 103,
      "0.001": 2
    },
    "sklearn.decomposition._fastica.FastICA.inverse_transform.X": {
      "random_latents": 4,
      "sampled_latents": 2,
      "ica.fit_transform(train_x.values.reshape(-1, 28 * 28))": 1
    },
    "sklearn.metrics.pairwise.sigmoid_kernel.X": {
      "question1_tfidf": 1
    },
    "sklearn.metrics.pairwise.sigmoid_kernel.Y": {
      "question2_tfidf": 1
    },
    "sklearn.metrics.pairwise.rbf_kernel.X": {
      "question1_tfidf": 1,
      "i": 1
    },
    "sklearn.metrics.pairwise.rbf_kernel.Y": {
      "question2_tfidf": 1,
      "j": 1
    },
    "sklearn.metrics.pairwise.polynomial_kernel.X": {
      "question1_tfidf": 1,
      "i": 1
    },
    "sklearn.metrics.pairwise.polynomial_kernel.Y": {
      "question2_tfidf": 1,
      "j": 1
    },
    "sklearn.linear_model._least_angle.Lars.__init__.n_nonzero_coefs": {
      "500": 6,
      "10": 1
    },
    "sklearn.datasets._base.load_files.encoding": {
      "'UTF-8'": 2,
      "None": 2
    },
    "sklearn.decomposition._lda.LatentDirichletAllocation.perplexity.X": {
      "cvz": 2
    },
    "sklearn.decomposition._lda.LatentDirichletAllocation.score.X": {
      "cvz": 2
    },
    "sklearn.cluster._agglomerative.FeatureAgglomeration.__init__.linkage": {
      "'ward'": 5
    },
    "sklearn.metrics._regression.mean_tweedie_deviance.power": {
      "1": 1,
      "2": 1
    },
    "sklearn.metrics._regression.mean_tweedie_deviance.y_true": {
      "1 + actuals": 2
    },
    "sklearn.metrics._regression.mean_tweedie_deviance.y_pred": {
      "1 + predictions": 2
    },
    "sklearn.semi_supervised._label_propagation.LabelPropagation.fit.X": {
      "x_train_3": 1
    },
    "sklearn.semi_supervised._label_propagation.LabelPropagation.fit.y": {
      "y_train_3": 1
    },
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.selection": {
      "'cyclic'": 118,
      "'random'": 2
    },
    "sklearn.cluster._dbscan.DBSCAN.__init__.metric_params": {
      "None": 103
    },
    "sklearn.cluster._dbscan.DBSCAN.__init__.p": {
      "None": 103
    },
    "sklearn.metrics._ranking.roc_auc_score.max_fpr": {
      "None": 8297
    },
    "sklearn.calibration.CalibratedClassifierCV.__init__.ensemble": {
      "True": 781,
      "False": 1
    },
    "sklearn.metrics.pairwise.pairwise_distances_chunked.reduce_func": {
      "reduce_func": 1
    },
    "sklearn.metrics.pairwise.pairwise_distances_chunked.metric": {
      "'cosine'": 1
    },
    "sklearn.metrics.pairwise.pairwise_distances_chunked.n_jobs": {
      "-1": 1
    },
    "sklearn.metrics.pairwise.pairwise_distances_chunked.X": {
      "train_embeddings": 1
    },
    "sklearn.linear_model._least_angle.LassoLarsIC.fit.X": {
      "xtrain": 2
    },
    "sklearn.linear_model._least_angle.LassoLarsIC.fit.y": {
      "ytrain": 2
    },
    "sklearn.linear_model._least_angle.LassoLarsCV.__init__.cv": {
      "None": 41,
      "10": 3
    },
    "sklearn.linear_model._least_angle.LassoLarsCV.__init__.max_iter": {
      "500": 42,
      "1000": 1,
      "10000": 1
    },
    "sklearn.linear_model._least_angle.LarsCV.fit.X": {
      "xtrain": 1,
      "X": 1,
      "X_train": 1
    },
    "sklearn.linear_model._least_angle.LarsCV.fit.y": {
      "y": 2,
      "ytrain": 1
    },
    "sklearn.neural_network._rbm.BernoulliRBM.fit.X": {
      "data": 1
    },
    "sklearn.neural_network._rbm.BernoulliRBM.score_samples.X": {
      "X": 1
    },
    "sklearn.preprocessing._data.QuantileTransformer.__init__.copy": {
      "True": 365,
      "False": 3
    },
    "sklearn.preprocessing._data.PowerTransformer.__init__.copy": {
      "True": 75,
      "False": 1
    },
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix.labels": {
      "None": 179,
      "[0, 1]": 1
    },
    "sklearn.preprocessing._data.MinMaxScaler.partial_fit.X": {
      "i": 1
    },
    "sklearn.ensemble._bagging.BaggingRegressor.__init__.bootstrap_features": {
      "False": 142
    },
    "sklearn.linear_model._coordinate_descent.Lasso.__init__.warm_start": {
      "False": 747,
      "True": 1
    },
    "sklearn.tree._classes.ExtraTreeRegressor.__init__.splitter": {
      "'random'": 4,
      "'best'": 1
    },
    "sklearn.tree._classes.ExtraTreeRegressor.__init__.random_state": {
      "None": 4,
      "198": 1
    },
    "sklearn.decomposition._nmf.NMF.__init__.beta_loss": {
      "'frobenius'": 64,
      "'kullback-leibler'": 1
    },
    "sklearn.decomposition._nmf.NMF.__init__.tol": {
      "0.0001": 65
    },
    "sklearn.decomposition._nmf.NMF.__init__.max_iter": {
      "200": 63,
      "50": 1,
      "10000": 1
    },
    "sklearn.feature_selection._univariate_selection.GenericUnivariateSelect.__init__.score_func": {
      "f_classif": 4,
      "mutual_info_regression": 1
    },
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.eps": {
      "0.001": 120
    },
    "sklearn.linear_model._least_angle.LassoLarsCV.__init__.precompute": {
      "'auto'": 42,
      "False": 1,
      "True": 1
    },
    "sklearn.metrics._classification.multilabel_confusion_matrix.samplewise": {
      "False": 57
    },
    "sklearn.impute._iterative.IterativeImputer.__init__.tol": {
      "0.001": 54,
      "0.0002": 1
    },
    "sklearn.isotonic.IsotonicRegression.transform.T": {
      "oof[idx1]": 2,
      "preds[idx2]": 2
    },
    "sklearn.metrics.pairwise.pairwise_kernels.metric": {
      "'rbf'": 1
    },
    "sklearn.metrics.pairwise.pairwise_kernels.filter_params": {
      "True": 1
    },
    "sklearn.metrics.pairwise.pairwise_kernels.X": {
      "S / S.max()": 1
    },
    "sklearn.decomposition._fastica.FastICA.__init__.algorithm": {
      "'parallel'": 190
    },
    "sklearn.decomposition._fastica.FastICA.__init__.whiten": {
      "True": 190
    },
    "sklearn.semi_supervised._label_propagation.LabelSpreading.__init__.n_neighbors": {
      "7": 6,
      "15": 2
    },
    "sklearn.neighbors._nca.NeighborhoodComponentsAnalysis.__init__.random_state": {
      "42": 1
    },
    "sklearn.linear_model._bayes.ARDRegression.predict.return_std": {
      "False": 4,
      "True": 2
    },
    "sklearn.multiclass.OneVsOneClassifier.decision_function.X": {
      "y_valid_pred": 1
    },
    "sklearn.feature_selection._univariate_selection.f_regression.center": {
      "True": 13
    },
    "sklearn.linear_model._least_angle.Lars.fit.X": {
      "X_train[y_is_within_cut]": 1,
      "X_train": 1
    },
    "sklearn.linear_model._least_angle.Lars.fit.y": {
      "y_train[y_is_within_cut]": 1,
      "y": 1
    },
    "sklearn.impute._iterative.IterativeImputer.__init__.initial_strategy": {
      "'mean'": 51,
      "'most_frequent'": 4
    },
    "sklearn.linear_model._bayes.ARDRegression.__init__.tol": {
      "0.001": 12
    },
    "sklearn.linear_model._bayes.ARDRegression.__init__.compute_score": {
      "False": 11,
      "True": 1
    },
    "sklearn.linear_model._bayes.ARDRegression.__init__.threshold_lambda": {
      "10000.0": 12
    },
    "sklearn.linear_model._bayes.ARDRegression.__init__.normalize": {
      "False": 12
    },
    "sklearn.linear_model._bayes.ARDRegression.__init__.copy_X": {
      "True": 12
    },
    "sklearn.metrics.cluster._unsupervised.silhouette_score.sample_size": {
      "None": 41,
      "10000": 1
    },
    "sklearn.base.clone.safe": {
      "True": 231
    },
    "sklearn.tree._classes.ExtraTreeClassifier.__init__.min_samples_split": {
      "2": 32
    },
    "sklearn.tree._classes.ExtraTreeClassifier.__init__.max_features": {
      "'auto'": 31,
      "0.01": 1
    },
    "sklearn.tree._classes.ExtraTreeClassifier.__init__.max_depth": {
      "None": 30,
      "8": 1,
      "5": 1
    },
    "sklearn.tree._classes.ExtraTreeClassifier.__init__.criterion": {
      "'gini'": 31,
      "'entropy'": 1
    },
    "sklearn.tree._export.plot_tree.proportion": {
      "False": 40,
      "True": 2
    },
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.scoring": {
      "'accuracy'": 1,
      "'r2'": 1
    },
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.cv": {
      "10": 1,
      "5": 1
    },
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.n_jobs": {
      "-1": 2
    },
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.estimator": {
      "classifier": 1,
      "xgb_model": 1
    },
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.param_distributions": {
      "param_grid": 1,
      "params": 1
    },
    "sklearn.compose._target.TransformedTargetRegressor.__init__.check_inverse": {
      "True": 22,
      "False": 1
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.early_stopping": {
      "False": 37,
      "True": 2
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.average": {
      "False": 37,
      "True": 2
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.class_weight": {
      "None": 37,
      "'balanced'": 2
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.n_jobs": {
      "None": 37,
      "-1": 2
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.verbose": {
      "0": 38,
      "False": 1
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.validation_fraction": {
      "0.1": 39
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.n_iter_no_change": {
      "5": 38,
      "20": 1
    },
    "sklearn.dummy.DummyClassifier.__init__.constant": {
      "None": 49,
      "1": 1
    },
    "sklearn.semi_supervised._label_propagation.LabelSpreading.__init__.n_jobs": {
      "None": 5,
      "-1": 3
    },
    "sklearn.metrics._classification.fbeta_score.labels": {
      "None": 143
    },
    "sklearn.decomposition._pca.PCA.fit.y": {
      "None": 850,
      "y": 1
    },
    "sklearn.covariance._shrunk_covariance.LedoitWolf.__init__.assume_centered": {
      "False": 9
    },
    "sklearn.preprocessing._function_transformer.FunctionTransformer.__init__.accept_sparse": {
      "False": 455,
      "True": 1
    },
    "sklearn.metrics.cluster._supervised.adjusted_mutual_info_score.labels_true": {
      "y": 1
    },
    "sklearn.metrics.cluster._supervised.adjusted_mutual_info_score.labels_pred": {
      "y_preds": 1
    },
    "sklearn.metrics._plot.roc_curve.plot_roc_curve.drop_intermediate": {
      "True": 42,
      "False": 1
    },
    "sklearn.feature_extraction.text.TfidfVectorizer.fit_transform.y": {
      "None": 1791,
      "y": 1,
      "y_train": 1
    },
    "sklearn.gaussian_process.kernels.ConstantKernel.__init__.constant_value": {
      "1.0": 2
    },
    "sklearn.gaussian_process.kernels.ConstantKernel.__init__.constant_value_bounds": {
      "(0.001, 1000.0)": 2
    },
    "sklearn.linear_model._least_angle.LassoLarsCV.__init__.verbose": {
      "False": 44
    },
    "sklearn.linear_model._least_angle.LassoLarsCV.__init__.max_n_alphas": {
      "1000": 43,
      "5000": 1
    },
    "sklearn.linear_model._least_angle.LassoLarsCV.__init__.n_jobs": {
      "None": 43,
      "1": 1
    },
    "sklearn.linear_model._least_angle.LassoLars.__init__.precompute": {
      "'auto'": 11,
      "True": 1
    },
    "sklearn.linear_model._least_angle.LassoLars.__init__.max_iter": {
      "500": 11,
      "5000": 1
    },
    "sklearn.linear_model._least_angle.LassoLars.__init__.verbose": {
      "False": 12
    },
    "sklearn.linear_model._ridge.RidgeClassifierCV.__init__.alphas": {
      "(0.1, 1.0, 10.0)": 38,
      "alphas": 1,
      "[0.001, 0.01, 0.1, 1]": 1
    },
    "sklearn.linear_model._ridge.RidgeClassifierCV.__init__.cv": {
      "None": 39,
      "5": 1
    },
    "sklearn.linear_model._ridge.RidgeClassifier.__init__.fit_intercept": {
      "True": 151
    },
    "sklearn.linear_model._ridge.RidgeClassifier.__init__.copy_X": {
      "True": 151
    },
    "sklearn.linear_model._ridge.RidgeClassifier.__init__.max_iter": {
      "None": 151
    },
    "sklearn.neighbors._lof.LocalOutlierFactor.__init__.p": {
      "2": 13,
      "1": 4
    },
    "sklearn.covariance._shrunk_covariance.ShrunkCovariance.__init__.shrinkage": {
      "0.1": 4,
      "shrinkage": 2
    },
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.__init__.sort": {
      "True": 239,
      "False": 1
    },
    "sklearn.datasets._svmlight_format_io.load_svmlight_file.zero_based": {
      "False": 2
    },
    "sklearn.datasets._svmlight_format_io.load_svmlight_file.f": {
      "libsvm_file_path": 2
    },
    "sklearn.model_selection._split.GroupShuffleSplit.__init__.train_size": {
      "None": 63,
      "reduced_train_size": 1
    },
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.__init__.random_state": {
      "None": 10,
      "1": 1
    },
    "sklearn.multioutput.MultiOutputClassifier.score.X": {
      "X_train": 1,
      "X_val": 1
    },
    "sklearn.multioutput.MultiOutputClassifier.score.y": {
      "y_train": 1,
      "y_val": 1
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.early_stopping": {
      "'auto'": 29,
      "True": 1
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.n_iter_no_change": {
      "10": 29,
      "60": 1
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.tol": {
      "1e-07": 29,
      "1e-06": 1
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.validation_fraction": {
      "0.1": 27,
      "None": 2,
      "0.2": 1
    },
    "sklearn.preprocessing._data.MaxAbsScaler.inverse_transform.X": {
      "test_predictions": 1
    },
    "sklearn.linear_model._glm.glm.TweedieRegressor.__init__.power": {
      "0.0": 5,
      "2.2": 1,
      "2": 1,
      "1.8": 1,
      "1.5": 1,
      "0": 1
    },
    "sklearn.linear_model._glm.glm.TweedieRegressor.__init__.link": {
      "'auto'": 5,
      "'log'": 4,
      "'identity'": 1
    },
    "sklearn.linear_model._glm.glm.TweedieRegressor.__init__.max_iter": {
      "100": 9,
      "100000": 1
    },
    "sklearn.linear_model._glm.glm.TweedieRegressor.__init__.warm_start": {
      "False": 9,
      "True": 1
    },
    "sklearn.metrics.pairwise.pairwise_distances.n_jobs": {
      "None": 20,
      "-1": 1
    },
    "sklearn.semi_supervised._label_propagation.LabelSpreading.__init__.alpha": {
      "0.2": 7,
      "0.4": 1
    },
    "sklearn.semi_supervised._label_propagation.LabelSpreading.__init__.tol": {
      "0.001": 8
    },
    "sklearn.metrics.cluster._supervised.normalized_mutual_info_score.labels_true": {
      "train_target_df": 1,
      "var": 1
    },
    "sklearn.metrics.cluster._supervised.normalized_mutual_info_score.labels_pred": {
      "scoring_var": 1,
      "var_ref": 1
    },
    "sklearn.cluster._mean_shift.MeanShift.__init__.cluster_all": {
      "True": 5
    },
    "sklearn.cluster._mean_shift.MeanShift.predict.X": {
      "cities[['X', 'Y']]": 1
    },
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.learning_decay": {
      "0.7": 62
    },
    "sklearn.tree._export.export_graphviz.node_ids": {
      "False": 201,
      "True": 1
    },
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.resource": {
      "'n_estimators'": 1,
      "'n_samples'": 1
    },
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.max_resources": {
      "40": 1,
      "'auto'": 1
    },
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.random_state": {
      "42": 1,
      "None": 1
    },
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.verbose": {
      "1": 1,
      "0": 1
    },
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.return_train_score": {
      "True": 2
    },
    "sklearn.metrics.cluster._unsupervised.silhouette_score.random_state": {
      "None": 41,
      "16446054": 1
    },
    "sklearn.linear_model._bayes.BayesianRidge.__init__.lambda_init": {
      "None": 193,
      "0.0001": 1
    },
    "sklearn.decomposition._kernel_pca.KernelPCA.fit_transform.y": {
      "None": 20,
      "y_train": 1
    },
    "sklearn.covariance._graph_lasso.GraphicalLasso.__init__.max_iter": {
      "100": 35,
      "200": 2
    },
    "sklearn.ensemble._gb.GradientBoostingClassifier.staged_decision_function.X": {
      "X_test": 3,
      "X_train": 1
    },
    "sklearn.__check_build.raise_build_error.e": {},
    "sklearn._config.set_config.assume_finite": {
      "None": 25
    },
    "sklearn._config.set_config.working_memory": {
      "None": 25
    },
    "sklearn.base.BaseEstimator.__repr__.N_CHAR_MAX": {},
    "sklearn.base.BaseEstimator.__setstate__.state": {},
    "sklearn.base.BiclusterMixin.get_indices.i": {},
    "sklearn.base.BiclusterMixin.get_shape.i": {},
    "sklearn.base.BiclusterMixin.get_submatrix.i": {},
    "sklearn.base.BiclusterMixin.get_submatrix.data": {},
    "sklearn.base.ClusterMixin.fit_predict.y": {
      "None": 24
    },
    "sklearn.base.DensityMixin.score.X": {},
    "sklearn.base.DensityMixin.score.y": {},
    "sklearn.base.OutlierMixin.fit_predict.y": {
      "None": 19
    },
    "sklearn.base.is_outlier_detector.estimator": {},
    "sklearn.base.is_regressor.estimator": {},
    "sklearn.calibration.CalibratedClassifierCV.__init__.n_jobs": {
      "None": 782
    },
    "sklearn.calibration.CalibratedClassifierCV.fit.sample_weight": {
      "None": 753
    },
    "sklearn.calibration.calibration_curve.strategy": {
      "'uniform'": 25
    },
    "sklearn.cluster._affinity_propagation.AffinityPropagation.__init__.max_iter": {
      "200": 4
    },
    "sklearn.cluster._affinity_propagation.AffinityPropagation.__init__.convergence_iter": {
      "15": 4
    },
    "sklearn.cluster._affinity_propagation.AffinityPropagation.__init__.copy": {
      "True": 4
    },
    "sklearn.cluster._affinity_propagation.AffinityPropagation.__init__.preference": {
      "None": 4
    },
    "sklearn.cluster._affinity_propagation.AffinityPropagation.__init__.affinity": {
      "'euclidean'": 4
    },
    "sklearn.cluster._affinity_propagation.AffinityPropagation.__init__.verbose": {
      "False": 4
    },
    "sklearn.cluster._affinity_propagation.AffinityPropagation.__init__.random_state": {
      "'warn'": 4
    },
    "sklearn.cluster._affinity_propagation.AffinityPropagation.fit.y": {
      "None": 4
    },
    "sklearn.cluster._affinity_propagation.AffinityPropagation.fit_predict.X": {},
    "sklearn.cluster._affinity_propagation.AffinityPropagation.fit_predict.y": {},
    "sklearn.cluster._affinity_propagation.affinity_propagation.preference": {
      "None": 1
    },
    "sklearn.cluster._affinity_propagation.affinity_propagation.convergence_iter": {
      "15": 1
    },
    "sklearn.cluster._affinity_propagation.affinity_propagation.max_iter": {
      "200": 1
    },
    "sklearn.cluster._affinity_propagation.affinity_propagation.damping": {
      "0.5": 1
    },
    "sklearn.cluster._affinity_propagation.affinity_propagation.copy": {
      "True": 1
    },
    "sklearn.cluster._affinity_propagation.affinity_propagation.verbose": {
      "False": 1
    },
    "sklearn.cluster._affinity_propagation.affinity_propagation.return_n_iter": {
      "False": 1
    },
    "sklearn.cluster._affinity_propagation.affinity_propagation.random_state": {
      "'warn'": 1
    },
    "sklearn.cluster._agglomerative.AgglomerativeClustering.__init__.memory": {
      "None": 36
    },
    "sklearn.cluster._agglomerative.AgglomerativeClustering.__init__.connectivity": {
      "None": 36
    },
    "sklearn.cluster._agglomerative.AgglomerativeClustering.__init__.compute_full_tree": {
      "'auto'": 36
    },
    "sklearn.cluster._agglomerative.AgglomerativeClustering.__init__.compute_distances": {
      "False": 36
    },
    "sklearn.cluster._agglomerative.AgglomerativeClustering.fit_predict.y": {
      "None": 18
    },
    "sklearn.cluster._agglomerative.FeatureAgglomeration.__init__.affinity": {
      "'euclidean'": 5
    },
    "sklearn.cluster._agglomerative.FeatureAgglomeration.__init__.memory": {
      "None": 5
    },
    "sklearn.cluster._agglomerative.FeatureAgglomeration.__init__.compute_full_tree": {
      "'auto'": 5
    },
    "sklearn.cluster._agglomerative.FeatureAgglomeration.__init__.pooling_func": {
      "np.mean": 5
    },
    "sklearn.cluster._agglomerative.FeatureAgglomeration.__init__.distance_threshold": {
      "None": 5
    },
    "sklearn.cluster._agglomerative.FeatureAgglomeration.__init__.compute_distances": {
      "False": 5
    },
    "sklearn.cluster._agglomerative.FeatureAgglomeration.fit.y": {
      "None": 2
    },
    "sklearn.cluster._agglomerative.linkage_tree.X": {},
    "sklearn.cluster._agglomerative.linkage_tree.connectivity": {},
    "sklearn.cluster._agglomerative.linkage_tree.n_clusters": {},
    "sklearn.cluster._agglomerative.linkage_tree.linkage": {},
    "sklearn.cluster._agglomerative.linkage_tree.affinity": {},
    "sklearn.cluster._agglomerative.linkage_tree.return_distance": {},
    "sklearn.cluster._agglomerative.ward_tree.X": {},
    "sklearn.cluster._agglomerative.ward_tree.connectivity": {},
    "sklearn.cluster._agglomerative.ward_tree.n_clusters": {},
    "sklearn.cluster._agglomerative.ward_tree.return_distance": {},
    "sklearn.cluster._bicluster.SpectralBiclustering.__init__.n_clusters": {},
    "sklearn.cluster._bicluster.SpectralBiclustering.__init__.method": {},
    "sklearn.cluster._bicluster.SpectralBiclustering.__init__.n_components": {},
    "sklearn.cluster._bicluster.SpectralBiclustering.__init__.n_best": {},
    "sklearn.cluster._bicluster.SpectralBiclustering.__init__.svd_method": {},
    "sklearn.cluster._bicluster.SpectralBiclustering.__init__.n_svd_vecs": {},
    "sklearn.cluster._bicluster.SpectralBiclustering.__init__.mini_batch": {},
    "sklearn.cluster._bicluster.SpectralBiclustering.__init__.init": {},
    "sklearn.cluster._bicluster.SpectralBiclustering.__init__.n_init": {},
    "sklearn.cluster._bicluster.SpectralBiclustering.__init__.n_jobs": {},
    "sklearn.cluster._bicluster.SpectralBiclustering.__init__.random_state": {},
    "sklearn.cluster._bicluster.SpectralCoclustering.__init__.n_clusters": {},
    "sklearn.cluster._bicluster.SpectralCoclustering.__init__.svd_method": {},
    "sklearn.cluster._bicluster.SpectralCoclustering.__init__.n_svd_vecs": {},
    "sklearn.cluster._bicluster.SpectralCoclustering.__init__.mini_batch": {},
    "sklearn.cluster._bicluster.SpectralCoclustering.__init__.init": {},
    "sklearn.cluster._bicluster.SpectralCoclustering.__init__.n_init": {},
    "sklearn.cluster._bicluster.SpectralCoclustering.__init__.n_jobs": {},
    "sklearn.cluster._bicluster.SpectralCoclustering.__init__.random_state": {},
    "sklearn.cluster._birch.Birch.fit.y": {
      "None": 47
    },
    "sklearn.cluster._birch.Birch.partial_fit.X": {},
    "sklearn.cluster._birch.Birch.partial_fit.y": {},
    "sklearn.cluster._birch.Birch.transform.X": {},
    "sklearn.cluster._dbscan.DBSCAN.fit.y": {
      "None": 64
    },
    "sklearn.cluster._dbscan.DBSCAN.fit.sample_weight": {
      "None": 64
    },
    "sklearn.cluster._dbscan.DBSCAN.fit_predict.y": {
      "None": 43
    },
    "sklearn.cluster._dbscan.DBSCAN.fit_predict.sample_weight": {
      "None": 43
    },
    "sklearn.cluster._dbscan.dbscan.eps": {
      "0.5": 1
    },
    "sklearn.cluster._dbscan.dbscan.min_samples": {
      "5": 1
    },
    "sklearn.cluster._dbscan.dbscan.metric": {
      "'minkowski'": 1
    },
    "sklearn.cluster._dbscan.dbscan.metric_params": {
      "None": 1
    },
    "sklearn.cluster._dbscan.dbscan.algorithm": {
      "'auto'": 1
    },
    "sklearn.cluster._dbscan.dbscan.leaf_size": {
      "30": 1
    },
    "sklearn.cluster._dbscan.dbscan.p": {
      "2": 1
    },
    "sklearn.cluster._dbscan.dbscan.sample_weight": {
      "None": 1
    },
    "sklearn.cluster._dbscan.dbscan.n_jobs": {
      "None": 1
    },
    "sklearn.cluster._kmeans.KMeans.fit.sample_weight": {
      "None": 674
    },
    "sklearn.cluster._kmeans.KMeans.fit_predict.y": {
      "None": 251
    },
    "sklearn.cluster._kmeans.KMeans.fit_predict.sample_weight": {
      "None": 251
    },
    "sklearn.cluster._kmeans.KMeans.fit_transform.sample_weight": {
      "None": 24
    },
    "sklearn.cluster._kmeans.KMeans.predict.sample_weight": {
      "None": 369
    },
    "sklearn.cluster._kmeans.KMeans.score.y": {
      "None": 2
    },
    "sklearn.cluster._kmeans.KMeans.score.sample_weight": {
      "None": 2
    },
    "sklearn.cluster._kmeans.MiniBatchKMeans.__init__.compute_labels": {
      "True": 105
    },
    "sklearn.cluster._kmeans.MiniBatchKMeans.fit.y": {
      "None": 92
    },
    "sklearn.cluster._kmeans.MiniBatchKMeans.fit.sample_weight": {
      "None": 92
    },
    "sklearn.cluster._kmeans.MiniBatchKMeans.partial_fit.y": {
      "None": 2
    },
    "sklearn.cluster._kmeans.MiniBatchKMeans.partial_fit.sample_weight": {
      "None": 2
    },
    "sklearn.cluster._kmeans.MiniBatchKMeans.predict.sample_weight": {
      "None": 174
    },
    "sklearn.cluster._kmeans.k_means.sample_weight": {
      "None": 4
    },
    "sklearn.cluster._kmeans.k_means.init": {
      "'k-means++'": 4
    },
    "sklearn.cluster._kmeans.k_means.precompute_distances": {
      "'deprecated'": 4
    },
    "sklearn.cluster._kmeans.k_means.n_init": {
      "10": 4
    },
    "sklearn.cluster._kmeans.k_means.verbose": {
      "False": 4
    },
    "sklearn.cluster._kmeans.k_means.tol": {
      "0.0001": 4
    },
    "sklearn.cluster._kmeans.k_means.copy_x": {
      "True": 4
    },
    "sklearn.cluster._kmeans.k_means.n_jobs": {
      "'deprecated'": 4
    },
    "sklearn.cluster._kmeans.k_means.algorithm": {
      "'auto'": 4
    },
    "sklearn.cluster._kmeans.k_means.return_n_iter": {
      "False": 4
    },
    "sklearn.cluster._kmeans.kmeans_plusplus.X": {},
    "sklearn.cluster._kmeans.kmeans_plusplus.n_clusters": {},
    "sklearn.cluster._kmeans.kmeans_plusplus.x_squared_norms": {},
    "sklearn.cluster._kmeans.kmeans_plusplus.random_state": {},
    "sklearn.cluster._kmeans.kmeans_plusplus.n_local_trials": {},
    "sklearn.cluster._mean_shift.MeanShift.__init__.seeds": {
      "None": 5
    },
    "sklearn.cluster._mean_shift.MeanShift.__init__.n_jobs": {
      "None": 5
    },
    "sklearn.cluster._mean_shift.MeanShift.__init__.max_iter": {
      "300": 5
    },
    "sklearn.cluster._mean_shift.MeanShift.fit.y": {
      "None": 5
    },
    "sklearn.cluster._mean_shift.estimate_bandwidth.random_state": {
      "0": 3
    },
    "sklearn.cluster._mean_shift.estimate_bandwidth.n_jobs": {
      "None": 3
    },
    "sklearn.cluster._mean_shift.get_bin_seeds.X": {},
    "sklearn.cluster._mean_shift.get_bin_seeds.bin_size": {},
    "sklearn.cluster._mean_shift.get_bin_seeds.min_bin_freq": {},
    "sklearn.cluster._mean_shift.mean_shift.X": {},
    "sklearn.cluster._mean_shift.mean_shift.bandwidth": {},
    "sklearn.cluster._mean_shift.mean_shift.seeds": {},
    "sklearn.cluster._mean_shift.mean_shift.bin_seeding": {},
    "sklearn.cluster._mean_shift.mean_shift.min_bin_freq": {},
    "sklearn.cluster._mean_shift.mean_shift.cluster_all": {},
    "sklearn.cluster._mean_shift.mean_shift.max_iter": {},
    "sklearn.cluster._mean_shift.mean_shift.n_jobs": {},
    "sklearn.cluster._optics.OPTICS.__init__.p": {
      "2": 4
    },
    "sklearn.cluster._optics.OPTICS.__init__.metric_params": {
      "None": 4
    },
    "sklearn.cluster._optics.OPTICS.__init__.cluster_method": {
      "'xi'": 4
    },
    "sklearn.cluster._optics.OPTICS.__init__.eps": {
      "None": 4
    },
    "sklearn.cluster._optics.OPTICS.__init__.predecessor_correction": {
      "True": 4
    },
    "sklearn.cluster._optics.OPTICS.__init__.algorithm": {
      "'auto'": 4
    },
    "sklearn.cluster._optics.OPTICS.__init__.leaf_size": {
      "30": 4
    },
    "sklearn.cluster._optics.OPTICS.__init__.n_jobs": {
      "None": 4
    },
    "sklearn.cluster._optics.OPTICS.fit.y": {
      "None": 3
    },
    "sklearn.cluster._optics.cluster_optics_dbscan.reachability": {},
    "sklearn.cluster._optics.cluster_optics_dbscan.core_distances": {},
    "sklearn.cluster._optics.cluster_optics_dbscan.ordering": {},
    "sklearn.cluster._optics.cluster_optics_dbscan.eps": {},
    "sklearn.cluster._optics.cluster_optics_xi.reachability": {},
    "sklearn.cluster._optics.cluster_optics_xi.predecessor": {},
    "sklearn.cluster._optics.cluster_optics_xi.ordering": {},
    "sklearn.cluster._optics.cluster_optics_xi.min_samples": {},
    "sklearn.cluster._optics.cluster_optics_xi.min_cluster_size": {},
    "sklearn.cluster._optics.cluster_optics_xi.xi": {},
    "sklearn.cluster._optics.cluster_optics_xi.predecessor_correction": {},
    "sklearn.cluster._optics.compute_optics_graph.X": {},
    "sklearn.cluster._optics.compute_optics_graph.min_samples": {},
    "sklearn.cluster._optics.compute_optics_graph.max_eps": {},
    "sklearn.cluster._optics.compute_optics_graph.metric": {},
    "sklearn.cluster._optics.compute_optics_graph.p": {},
    "sklearn.cluster._optics.compute_optics_graph.metric_params": {},
    "sklearn.cluster._optics.compute_optics_graph.algorithm": {},
    "sklearn.cluster._optics.compute_optics_graph.leaf_size": {},
    "sklearn.cluster._optics.compute_optics_graph.n_jobs": {},
    "sklearn.cluster._spectral.SpectralClustering.__init__.n_components": {
      "None": 9
    },
    "sklearn.cluster._spectral.SpectralClustering.__init__.n_init": {
      "10": 9
    },
    "sklearn.cluster._spectral.SpectralClustering.__init__.gamma": {
      "1.0": 9
    },
    "sklearn.cluster._spectral.SpectralClustering.__init__.n_neighbors": {
      "10": 9
    },
    "sklearn.cluster._spectral.SpectralClustering.__init__.eigen_tol": {
      "0.0": 9
    },
    "sklearn.cluster._spectral.SpectralClustering.__init__.degree": {
      "3": 9
    },
    "sklearn.cluster._spectral.SpectralClustering.__init__.coef0": {
      "1": 9
    },
    "sklearn.cluster._spectral.SpectralClustering.__init__.kernel_params": {
      "None": 9
    },
    "sklearn.cluster._spectral.SpectralClustering.__init__.n_jobs": {
      "None": 9
    },
    "sklearn.cluster._spectral.SpectralClustering.__init__.verbose": {
      "False": 9
    },
    "sklearn.cluster._spectral.SpectralClustering.fit.y": {
      "None": 4
    },
    "sklearn.cluster._spectral.SpectralClustering.fit_predict.y": {
      "None": 5
    },
    "sklearn.cluster._spectral.spectral_clustering.affinity": {},
    "sklearn.cluster._spectral.spectral_clustering.n_clusters": {},
    "sklearn.cluster._spectral.spectral_clustering.n_components": {},
    "sklearn.cluster._spectral.spectral_clustering.eigen_solver": {},
    "sklearn.cluster._spectral.spectral_clustering.random_state": {},
    "sklearn.cluster._spectral.spectral_clustering.n_init": {},
    "sklearn.cluster._spectral.spectral_clustering.eigen_tol": {},
    "sklearn.cluster._spectral.spectral_clustering.assign_labels": {},
    "sklearn.cluster._spectral.spectral_clustering.verbose": {},
    "sklearn.cluster.setup.configuration.parent_package": {},
    "sklearn.cluster.setup.configuration.top_path": {},
    "sklearn.compose._column_transformer.ColumnTransformer.get_params.deep": {
      "True": 1
    },
    "sklearn.compose._column_transformer.make_column_selector.__call__.df": {},
    "sklearn.compose._column_transformer.make_column_selector.__init__.pattern": {
      "None": 28
    },
    "sklearn.compose._column_transformer.make_column_transformer.sparse_threshold": {
      "0.3": 60
    },
    "sklearn.compose._column_transformer.make_column_transformer.n_jobs": {
      "None": 60
    },
    "sklearn.compose._column_transformer.make_column_transformer.verbose": {
      "False": 60
    },
    "sklearn.conftest.pytest_collection_modifyitems.config": {},
    "sklearn.conftest.pytest_collection_modifyitems.items": {},
    "sklearn.conftest.pytest_runtest_setup.item": {},
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.__init__.store_precision": {
      "True": 19
    },
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.__init__.assume_centered": {
      "False": 19
    },
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.__init__.support_fraction": {
      "None": 19
    },
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.fit.y": {
      "None": 14
    },
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.score.X": {},
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.score.y": {},
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.score.sample_weight": {},
    "sklearn.covariance._elliptic_envelope.EllipticEnvelope.score_samples.X": {},
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.error_norm.comp_cov": {},
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.error_norm.norm": {},
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.error_norm.scaling": {},
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.error_norm.squared": {},
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.fit.y": {
      "None": 1
    },
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.score.X_test": {},
    "sklearn.covariance._empirical_covariance.EmpiricalCovariance.score.y": {},
    "sklearn.covariance._empirical_covariance.empirical_covariance.X": {},
    "sklearn.covariance._empirical_covariance.empirical_covariance.assume_centered": {},
    "sklearn.covariance._empirical_covariance.log_likelihood.emp_cov": {},
    "sklearn.covariance._empirical_covariance.log_likelihood.precision": {},
    "sklearn.covariance._graph_lasso.GraphicalLasso.__init__.mode": {
      "'cd'": 37
    },
    "sklearn.covariance._graph_lasso.GraphicalLasso.__init__.tol": {
      "0.0001": 37
    },
    "sklearn.covariance._graph_lasso.GraphicalLasso.__init__.enet_tol": {
      "0.0001": 37
    },
    "sklearn.covariance._graph_lasso.GraphicalLasso.__init__.verbose": {
      "False": 37
    },
    "sklearn.covariance._graph_lasso.GraphicalLasso.__init__.assume_centered": {
      "False": 37
    },
    "sklearn.covariance._graph_lasso.GraphicalLasso.fit.y": {
      "None": 50
    },
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.__init__.alphas": {
      "4": 1
    },
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.__init__.n_refinements": {
      "4": 1
    },
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.__init__.cv": {
      "None": 1
    },
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.__init__.tol": {
      "0.0001": 1
    },
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.__init__.enet_tol": {
      "0.0001": 1
    },
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.__init__.max_iter": {
      "100": 1
    },
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.__init__.mode": {
      "'cd'": 1
    },
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.__init__.verbose": {
      "False": 1
    },
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.__init__.assume_centered": {
      "False": 1
    },
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.fit.X": {},
    "sklearn.covariance._graph_lasso.GraphicalLassoCV.fit.y": {},
    "sklearn.covariance._graph_lasso.graphical_lasso.emp_cov": {},
    "sklearn.covariance._graph_lasso.graphical_lasso.alpha": {},
    "sklearn.covariance._graph_lasso.graphical_lasso.cov_init": {},
    "sklearn.covariance._graph_lasso.graphical_lasso.mode": {},
    "sklearn.covariance._graph_lasso.graphical_lasso.tol": {},
    "sklearn.covariance._graph_lasso.graphical_lasso.enet_tol": {},
    "sklearn.covariance._graph_lasso.graphical_lasso.max_iter": {},
    "sklearn.covariance._graph_lasso.graphical_lasso.verbose": {},
    "sklearn.covariance._graph_lasso.graphical_lasso.return_costs": {},
    "sklearn.covariance._graph_lasso.graphical_lasso.eps": {},
    "sklearn.covariance._graph_lasso.graphical_lasso.return_n_iter": {},
    "sklearn.covariance._robust_covariance.MinCovDet.__init__.store_precision": {
      "True": 5
    },
    "sklearn.covariance._robust_covariance.MinCovDet.__init__.assume_centered": {
      "False": 5
    },
    "sklearn.covariance._robust_covariance.MinCovDet.__init__.random_state": {
      "None": 5
    },
    "sklearn.covariance._robust_covariance.MinCovDet.correct_covariance.data": {},
    "sklearn.covariance._robust_covariance.MinCovDet.fit.y": {
      "None": 3
    },
    "sklearn.covariance._robust_covariance.MinCovDet.reweight_covariance.data": {},
    "sklearn.covariance._robust_covariance.fast_mcd.X": {},
    "sklearn.covariance._robust_covariance.fast_mcd.support_fraction": {},
    "sklearn.covariance._robust_covariance.fast_mcd.cov_computation_method": {},
    "sklearn.covariance._robust_covariance.fast_mcd.random_state": {},
    "sklearn.covariance._shrunk_covariance.LedoitWolf.__init__.store_precision": {
      "True": 9
    },
    "sklearn.covariance._shrunk_covariance.LedoitWolf.__init__.block_size": {
      "1000": 9
    },
    "sklearn.covariance._shrunk_covariance.LedoitWolf.fit.y": {
      "None": 16
    },
    "sklearn.covariance._shrunk_covariance.OAS.fit.y": {
      "None": 61
    },
    "sklearn.covariance._shrunk_covariance.ShrunkCovariance.__init__.store_precision": {
      "True": 6
    },
    "sklearn.covariance._shrunk_covariance.ShrunkCovariance.__init__.assume_centered": {
      "False": 6
    },
    "sklearn.covariance._shrunk_covariance.ShrunkCovariance.fit.y": {
      "None": 4
    },
    "sklearn.covariance._shrunk_covariance.ledoit_wolf.assume_centered": {
      "False": 1
    },
    "sklearn.covariance._shrunk_covariance.ledoit_wolf.block_size": {
      "1000": 1
    },
    "sklearn.covariance._shrunk_covariance.ledoit_wolf_shrinkage.X": {},
    "sklearn.covariance._shrunk_covariance.ledoit_wolf_shrinkage.assume_centered": {},
    "sklearn.covariance._shrunk_covariance.ledoit_wolf_shrinkage.block_size": {},
    "sklearn.covariance._shrunk_covariance.oas.X": {},
    "sklearn.covariance._shrunk_covariance.oas.assume_centered": {},
    "sklearn.covariance._shrunk_covariance.shrunk_covariance.emp_cov": {},
    "sklearn.covariance._shrunk_covariance.shrunk_covariance.shrinkage": {},
    "sklearn.cross_decomposition._pls.CCA.__init__.scale": {
      "True": 1
    },
    "sklearn.cross_decomposition._pls.CCA.__init__.max_iter": {
      "500": 1
    },
    "sklearn.cross_decomposition._pls.CCA.__init__.tol": {
      "1e-06": 1
    },
    "sklearn.cross_decomposition._pls.CCA.__init__.copy": {
      "True": 1
    },
    "sklearn.cross_decomposition._pls.PLSCanonical.__init__.n_components": {},
    "sklearn.cross_decomposition._pls.PLSCanonical.__init__.scale": {},
    "sklearn.cross_decomposition._pls.PLSCanonical.__init__.algorithm": {},
    "sklearn.cross_decomposition._pls.PLSCanonical.__init__.max_iter": {},
    "sklearn.cross_decomposition._pls.PLSCanonical.__init__.tol": {},
    "sklearn.cross_decomposition._pls.PLSCanonical.__init__.copy": {},
    "sklearn.cross_decomposition._pls.PLSSVD.__init__.scale": {
      "True": 3
    },
    "sklearn.cross_decomposition._pls.PLSSVD.__init__.copy": {
      "True": 3
    },
    "sklearn.cross_decomposition._pls.PLSSVD.fit.X": {},
    "sklearn.cross_decomposition._pls.PLSSVD.fit.Y": {},
    "sklearn.cross_decomposition._pls.PLSSVD.fit_transform.X": {},
    "sklearn.cross_decomposition._pls.PLSSVD.fit_transform.y": {},
    "sklearn.cross_decomposition._pls.PLSSVD.transform.X": {},
    "sklearn.cross_decomposition._pls.PLSSVD.transform.Y": {},
    "sklearn.datasets._base.clear_data_home.data_home": {},
    "sklearn.datasets._base.get_data_home.data_home": {},
    "sklearn.datasets._base.load_breast_cancer.as_frame": {
      "False": 2
    },
    "sklearn.datasets._base.load_diabetes.return_X_y": {
      "False": 7
    },
    "sklearn.datasets._base.load_diabetes.as_frame": {
      "False": 7
    },
    "sklearn.datasets._base.load_digits.n_class": {
      "10": 14
    },
    "sklearn.datasets._base.load_digits.as_frame": {
      "False": 14
    },
    "sklearn.datasets._base.load_files.description": {
      "None": 4
    },
    "sklearn.datasets._base.load_files.categories": {
      "None": 4
    },
    "sklearn.datasets._base.load_files.load_content": {
      "True": 4
    },
    "sklearn.datasets._base.load_files.shuffle": {
      "True": 4
    },
    "sklearn.datasets._base.load_files.decode_error": {
      "'strict'": 4
    },
    "sklearn.datasets._base.load_files.random_state": {
      "0": 4
    },
    "sklearn.datasets._base.load_iris.as_frame": {
      "False": 38
    },
    "sklearn.datasets._base.load_linnerud.return_X_y": {},
    "sklearn.datasets._base.load_linnerud.as_frame": {},
    "sklearn.datasets._base.load_wine.return_X_y": {
      "False": 4
    },
    "sklearn.datasets._base.load_wine.as_frame": {
      "False": 4
    },
    "sklearn.datasets._california_housing.fetch_california_housing.data_home": {},
    "sklearn.datasets._california_housing.fetch_california_housing.download_if_missing": {},
    "sklearn.datasets._california_housing.fetch_california_housing.return_X_y": {},
    "sklearn.datasets._california_housing.fetch_california_housing.as_frame": {},
    "sklearn.datasets._covtype.fetch_covtype.data_home": {},
    "sklearn.datasets._covtype.fetch_covtype.download_if_missing": {},
    "sklearn.datasets._covtype.fetch_covtype.random_state": {},
    "sklearn.datasets._covtype.fetch_covtype.shuffle": {},
    "sklearn.datasets._covtype.fetch_covtype.return_X_y": {},
    "sklearn.datasets._covtype.fetch_covtype.as_frame": {},
    "sklearn.datasets._kddcup99.fetch_kddcup99.subset": {},
    "sklearn.datasets._kddcup99.fetch_kddcup99.data_home": {},
    "sklearn.datasets._kddcup99.fetch_kddcup99.shuffle": {},
    "sklearn.datasets._kddcup99.fetch_kddcup99.random_state": {},
    "sklearn.datasets._kddcup99.fetch_kddcup99.percent10": {},
    "sklearn.datasets._kddcup99.fetch_kddcup99.download_if_missing": {},
    "sklearn.datasets._kddcup99.fetch_kddcup99.return_X_y": {},
    "sklearn.datasets._kddcup99.fetch_kddcup99.as_frame": {},
    "sklearn.datasets._lfw.fetch_lfw_pairs.subset": {},
    "sklearn.datasets._lfw.fetch_lfw_pairs.data_home": {},
    "sklearn.datasets._lfw.fetch_lfw_pairs.funneled": {},
    "sklearn.datasets._lfw.fetch_lfw_pairs.resize": {},
    "sklearn.datasets._lfw.fetch_lfw_pairs.color": {},
    "sklearn.datasets._lfw.fetch_lfw_pairs.slice_": {},
    "sklearn.datasets._lfw.fetch_lfw_pairs.download_if_missing": {},
    "sklearn.datasets._lfw.fetch_lfw_people.data_home": {},
    "sklearn.datasets._lfw.fetch_lfw_people.funneled": {},
    "sklearn.datasets._lfw.fetch_lfw_people.resize": {},
    "sklearn.datasets._lfw.fetch_lfw_people.min_faces_per_person": {},
    "sklearn.datasets._lfw.fetch_lfw_people.color": {},
    "sklearn.datasets._lfw.fetch_lfw_people.slice_": {},
    "sklearn.datasets._lfw.fetch_lfw_people.download_if_missing": {},
    "sklearn.datasets._lfw.fetch_lfw_people.return_X_y": {},
    "sklearn.datasets._olivetti_faces.fetch_olivetti_faces.data_home": {},
    "sklearn.datasets._olivetti_faces.fetch_olivetti_faces.shuffle": {},
    "sklearn.datasets._olivetti_faces.fetch_olivetti_faces.random_state": {},
    "sklearn.datasets._olivetti_faces.fetch_olivetti_faces.download_if_missing": {},
    "sklearn.datasets._olivetti_faces.fetch_olivetti_faces.return_X_y": {},
    "sklearn.datasets._openml.fetch_openml.data_id": {
      "None": 3
    },
    "sklearn.datasets._openml.fetch_openml.data_home": {
      "None": 3
    },
    "sklearn.datasets._openml.fetch_openml.target_column": {
      "'default-target'": 3
    },
    "sklearn.datasets._openml.fetch_openml.cache": {
      "True": 3
    },
    "sklearn.datasets._openml.fetch_openml.return_X_y": {
      "False": 3
    },
    "sklearn.datasets._rcv1.fetch_rcv1.data_home": {},
    "sklearn.datasets._rcv1.fetch_rcv1.subset": {},
    "sklearn.datasets._rcv1.fetch_rcv1.download_if_missing": {},
    "sklearn.datasets._rcv1.fetch_rcv1.random_state": {},
    "sklearn.datasets._rcv1.fetch_rcv1.shuffle": {},
    "sklearn.datasets._rcv1.fetch_rcv1.return_X_y": {},
    "sklearn.datasets._samples_generator.make_biclusters.shape": {},
    "sklearn.datasets._samples_generator.make_biclusters.n_clusters": {},
    "sklearn.datasets._samples_generator.make_biclusters.noise": {},
    "sklearn.datasets._samples_generator.make_biclusters.minval": {},
    "sklearn.datasets._samples_generator.make_biclusters.maxval": {},
    "sklearn.datasets._samples_generator.make_biclusters.shuffle": {},
    "sklearn.datasets._samples_generator.make_biclusters.random_state": {},
    "sklearn.datasets._samples_generator.make_blobs.center_box": {
      "(-10.0, 10.0)": 4
    },
    "sklearn.datasets._samples_generator.make_blobs.shuffle": {
      "True": 4
    },
    "sklearn.datasets._samples_generator.make_blobs.return_centers": {
      "False": 4
    },
    "sklearn.datasets._samples_generator.make_checkerboard.shape": {},
    "sklearn.datasets._samples_generator.make_checkerboard.n_clusters": {},
    "sklearn.datasets._samples_generator.make_checkerboard.noise": {},
    "sklearn.datasets._samples_generator.make_checkerboard.minval": {},
    "sklearn.datasets._samples_generator.make_checkerboard.maxval": {},
    "sklearn.datasets._samples_generator.make_checkerboard.shuffle": {},
    "sklearn.datasets._samples_generator.make_checkerboard.random_state": {},
    "sklearn.datasets._samples_generator.make_circles.shuffle": {
      "True": 2
    },
    "sklearn.datasets._samples_generator.make_friedman1.n_samples": {},
    "sklearn.datasets._samples_generator.make_friedman1.n_features": {},
    "sklearn.datasets._samples_generator.make_friedman1.noise": {},
    "sklearn.datasets._samples_generator.make_friedman1.random_state": {},
    "sklearn.datasets._samples_generator.make_friedman2.n_samples": {},
    "sklearn.datasets._samples_generator.make_friedman2.noise": {},
    "sklearn.datasets._samples_generator.make_friedman2.random_state": {},
    "sklearn.datasets._samples_generator.make_friedman3.n_samples": {},
    "sklearn.datasets._samples_generator.make_friedman3.noise": {},
    "sklearn.datasets._samples_generator.make_friedman3.random_state": {},
    "sklearn.datasets._samples_generator.make_gaussian_quantiles.mean": {},
    "sklearn.datasets._samples_generator.make_gaussian_quantiles.cov": {},
    "sklearn.datasets._samples_generator.make_gaussian_quantiles.n_samples": {},
    "sklearn.datasets._samples_generator.make_gaussian_quantiles.n_features": {},
    "sklearn.datasets._samples_generator.make_gaussian_quantiles.n_classes": {},
    "sklearn.datasets._samples_generator.make_gaussian_quantiles.shuffle": {},
    "sklearn.datasets._samples_generator.make_gaussian_quantiles.random_state": {},
    "sklearn.datasets._samples_generator.make_hastie_10_2.n_samples": {},
    "sklearn.datasets._samples_generator.make_hastie_10_2.random_state": {},
    "sklearn.datasets._samples_generator.make_low_rank_matrix.n_samples": {},
    "sklearn.datasets._samples_generator.make_low_rank_matrix.n_features": {},
    "sklearn.datasets._samples_generator.make_low_rank_matrix.effective_rank": {},
    "sklearn.datasets._samples_generator.make_low_rank_matrix.tail_strength": {},
    "sklearn.datasets._samples_generator.make_low_rank_matrix.random_state": {},
    "sklearn.datasets._samples_generator.make_moons.shuffle": {
      "True": 10
    },
    "sklearn.datasets._samples_generator.make_multilabel_classification.n_labels": {
      "2": 1
    },
    "sklearn.datasets._samples_generator.make_multilabel_classification.length": {
      "50": 1
    },
    "sklearn.datasets._samples_generator.make_multilabel_classification.allow_unlabeled": {
      "True": 1
    },
    "sklearn.datasets._samples_generator.make_multilabel_classification.sparse": {
      "False": 1
    },
    "sklearn.datasets._samples_generator.make_multilabel_classification.return_indicator": {
      "'dense'": 1
    },
    "sklearn.datasets._samples_generator.make_multilabel_classification.return_distributions": {
      "False": 1
    },
    "sklearn.datasets._samples_generator.make_regression.n_informative": {
      "10": 3
    },
    "sklearn.datasets._samples_generator.make_regression.n_targets": {
      "1": 3
    },
    "sklearn.datasets._samples_generator.make_regression.effective_rank": {
      "None": 3
    },
    "sklearn.datasets._samples_generator.make_regression.tail_strength": {
      "0.5": 3
    },
    "sklearn.datasets._samples_generator.make_regression.shuffle": {
      "True": 3
    },
    "sklearn.datasets._samples_generator.make_regression.coef": {
      "False": 3
    },
    "sklearn.datasets._samples_generator.make_s_curve.n_samples": {},
    "sklearn.datasets._samples_generator.make_s_curve.noise": {},
    "sklearn.datasets._samples_generator.make_s_curve.random_state": {},
    "sklearn.datasets._samples_generator.make_sparse_coded_signal.n_samples": {},
    "sklearn.datasets._samples_generator.make_sparse_coded_signal.n_components": {},
    "sklearn.datasets._samples_generator.make_sparse_coded_signal.n_features": {},
    "sklearn.datasets._samples_generator.make_sparse_coded_signal.n_nonzero_coefs": {},
    "sklearn.datasets._samples_generator.make_sparse_coded_signal.random_state": {},
    "sklearn.datasets._samples_generator.make_sparse_spd_matrix.dim": {},
    "sklearn.datasets._samples_generator.make_sparse_spd_matrix.alpha": {},
    "sklearn.datasets._samples_generator.make_sparse_spd_matrix.norm_diag": {},
    "sklearn.datasets._samples_generator.make_sparse_spd_matrix.smallest_coef": {},
    "sklearn.datasets._samples_generator.make_sparse_spd_matrix.largest_coef": {},
    "sklearn.datasets._samples_generator.make_sparse_spd_matrix.random_state": {},
    "sklearn.datasets._samples_generator.make_sparse_uncorrelated.n_samples": {},
    "sklearn.datasets._samples_generator.make_sparse_uncorrelated.n_features": {},
    "sklearn.datasets._samples_generator.make_sparse_uncorrelated.random_state": {},
    "sklearn.datasets._samples_generator.make_spd_matrix.n_dim": {},
    "sklearn.datasets._samples_generator.make_spd_matrix.random_state": {},
    "sklearn.datasets._samples_generator.make_swiss_roll.n_samples": {},
    "sklearn.datasets._samples_generator.make_swiss_roll.noise": {},
    "sklearn.datasets._samples_generator.make_swiss_roll.random_state": {},
    "sklearn.datasets._species_distributions.fetch_species_distributions.data_home": {},
    "sklearn.datasets._species_distributions.fetch_species_distributions.download_if_missing": {},
    "sklearn.datasets._svmlight_format_io.dump_svmlight_file.comment": {
      "None": 16
    },
    "sklearn.datasets._svmlight_format_io.dump_svmlight_file.query_id": {
      "None": 16
    },
    "sklearn.datasets._svmlight_format_io.dump_svmlight_file.multilabel": {
      "False": 16
    },
    "sklearn.datasets._svmlight_format_io.load_svmlight_file.n_features": {
      "None": 2
    },
    "sklearn.datasets._svmlight_format_io.load_svmlight_file.dtype": {
      "np.float64": 2
    },
    "sklearn.datasets._svmlight_format_io.load_svmlight_file.multilabel": {
      "False": 2
    },
    "sklearn.datasets._svmlight_format_io.load_svmlight_file.query_id": {
      "False": 2
    },
    "sklearn.datasets._svmlight_format_io.load_svmlight_file.offset": {
      "0": 2
    },
    "sklearn.datasets._svmlight_format_io.load_svmlight_file.length": {
      "-1": 2
    },
    "sklearn.datasets._svmlight_format_io.load_svmlight_files.files": {},
    "sklearn.datasets._svmlight_format_io.load_svmlight_files.n_features": {},
    "sklearn.datasets._svmlight_format_io.load_svmlight_files.dtype": {},
    "sklearn.datasets._svmlight_format_io.load_svmlight_files.multilabel": {},
    "sklearn.datasets._svmlight_format_io.load_svmlight_files.zero_based": {},
    "sklearn.datasets._svmlight_format_io.load_svmlight_files.query_id": {},
    "sklearn.datasets._svmlight_format_io.load_svmlight_files.offset": {},
    "sklearn.datasets._svmlight_format_io.load_svmlight_files.length": {},
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups.data_home": {
      "None": 18
    },
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups.categories": {
      "None": 18
    },
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups.shuffle": {
      "True": 18
    },
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups.random_state": {
      "42": 18
    },
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups.remove": {
      "()": 18
    },
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups.return_X_y": {
      "False": 18
    },
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups_vectorized.subset": {},
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups_vectorized.remove": {},
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups_vectorized.data_home": {},
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups_vectorized.download_if_missing": {},
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups_vectorized.return_X_y": {},
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups_vectorized.normalize": {},
    "sklearn.datasets._twenty_newsgroups.fetch_20newsgroups_vectorized.as_frame": {},
    "sklearn.datasets.setup.configuration.parent_package": {},
    "sklearn.datasets.setup.configuration.top_path": {},
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.n_components": {},
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.alpha": {},
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.max_iter": {},
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.tol": {},
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.fit_algorithm": {},
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.transform_algorithm": {},
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.transform_n_nonzero_coefs": {},
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.transform_alpha": {},
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.n_jobs": {},
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.code_init": {},
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.dict_init": {},
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.verbose": {},
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.split_sign": {},
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.random_state": {},
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.positive_code": {},
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.positive_dict": {},
    "sklearn.decomposition._dict_learning.DictionaryLearning.__init__.transform_max_iter": {},
    "sklearn.decomposition._dict_learning.DictionaryLearning.fit.X": {},
    "sklearn.decomposition._dict_learning.DictionaryLearning.fit.y": {},
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.fit_algorithm": {
      "'lars'": 2
    },
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.n_jobs": {
      "None": 2
    },
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.shuffle": {
      "True": 2
    },
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.dict_init": {
      "None": 2
    },
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.transform_algorithm": {
      "'omp'": 2
    },
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.transform_n_nonzero_coefs": {
      "None": 2
    },
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.transform_alpha": {
      "None": 2
    },
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.verbose": {
      "False": 2
    },
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.split_sign": {
      "False": 2
    },
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.positive_code": {
      "False": 2
    },
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.positive_dict": {
      "False": 2
    },
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.__init__.transform_max_iter": {
      "1000": 2
    },
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.fit.X": {},
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.fit.y": {},
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.partial_fit.X": {},
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.partial_fit.y": {},
    "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning.partial_fit.iter_offset": {},
    "sklearn.decomposition._dict_learning.SparseCoder.__init__.dictionary": {},
    "sklearn.decomposition._dict_learning.SparseCoder.__init__.transform_algorithm": {},
    "sklearn.decomposition._dict_learning.SparseCoder.__init__.transform_n_nonzero_coefs": {},
    "sklearn.decomposition._dict_learning.SparseCoder.__init__.transform_alpha": {},
    "sklearn.decomposition._dict_learning.SparseCoder.__init__.split_sign": {},
    "sklearn.decomposition._dict_learning.SparseCoder.__init__.n_jobs": {},
    "sklearn.decomposition._dict_learning.SparseCoder.__init__.positive_code": {},
    "sklearn.decomposition._dict_learning.SparseCoder.__init__.transform_max_iter": {},
    "sklearn.decomposition._dict_learning.SparseCoder.fit.X": {},
    "sklearn.decomposition._dict_learning.SparseCoder.fit.y": {},
    "sklearn.decomposition._dict_learning.SparseCoder.transform.X": {},
    "sklearn.decomposition._dict_learning.SparseCoder.transform.y": {},
    "sklearn.decomposition._dict_learning.dict_learning.X": {},
    "sklearn.decomposition._dict_learning.dict_learning.n_components": {},
    "sklearn.decomposition._dict_learning.dict_learning.alpha": {},
    "sklearn.decomposition._dict_learning.dict_learning.max_iter": {},
    "sklearn.decomposition._dict_learning.dict_learning.tol": {},
    "sklearn.decomposition._dict_learning.dict_learning.method": {},
    "sklearn.decomposition._dict_learning.dict_learning.n_jobs": {},
    "sklearn.decomposition._dict_learning.dict_learning.dict_init": {},
    "sklearn.decomposition._dict_learning.dict_learning.code_init": {},
    "sklearn.decomposition._dict_learning.dict_learning.callback": {},
    "sklearn.decomposition._dict_learning.dict_learning.verbose": {},
    "sklearn.decomposition._dict_learning.dict_learning.random_state": {},
    "sklearn.decomposition._dict_learning.dict_learning.return_n_iter": {},
    "sklearn.decomposition._dict_learning.dict_learning.positive_dict": {},
    "sklearn.decomposition._dict_learning.dict_learning.positive_code": {},
    "sklearn.decomposition._dict_learning.dict_learning.method_max_iter": {},
    "sklearn.decomposition._dict_learning.dict_learning_online.X": {},
    "sklearn.decomposition._dict_learning.dict_learning_online.n_components": {},
    "sklearn.decomposition._dict_learning.dict_learning_online.alpha": {},
    "sklearn.decomposition._dict_learning.dict_learning_online.n_iter": {},
    "sklearn.decomposition._dict_learning.dict_learning_online.return_code": {},
    "sklearn.decomposition._dict_learning.dict_learning_online.dict_init": {},
    "sklearn.decomposition._dict_learning.dict_learning_online.callback": {},
    "sklearn.decomposition._dict_learning.dict_learning_online.batch_size": {},
    "sklearn.decomposition._dict_learning.dict_learning_online.verbose": {},
    "sklearn.decomposition._dict_learning.dict_learning_online.shuffle": {},
    "sklearn.decomposition._dict_learning.dict_learning_online.n_jobs": {},
    "sklearn.decomposition._dict_learning.dict_learning_online.method": {},
    "sklearn.decomposition._dict_learning.dict_learning_online.iter_offset": {},
    "sklearn.decomposition._dict_learning.dict_learning_online.random_state": {},
    "sklearn.decomposition._dict_learning.dict_learning_online.return_inner_stats": {},
    "sklearn.decomposition._dict_learning.dict_learning_online.inner_stats": {},
    "sklearn.decomposition._dict_learning.dict_learning_online.return_n_iter": {},
    "sklearn.decomposition._dict_learning.dict_learning_online.positive_dict": {},
    "sklearn.decomposition._dict_learning.dict_learning_online.positive_code": {},
    "sklearn.decomposition._dict_learning.dict_learning_online.method_max_iter": {},
    "sklearn.decomposition._dict_learning.sparse_encode.X": {},
    "sklearn.decomposition._dict_learning.sparse_encode.dictionary": {},
    "sklearn.decomposition._dict_learning.sparse_encode.gram": {},
    "sklearn.decomposition._dict_learning.sparse_encode.cov": {},
    "sklearn.decomposition._dict_learning.sparse_encode.algorithm": {},
    "sklearn.decomposition._dict_learning.sparse_encode.n_nonzero_coefs": {},
    "sklearn.decomposition._dict_learning.sparse_encode.alpha": {},
    "sklearn.decomposition._dict_learning.sparse_encode.copy_cov": {},
    "sklearn.decomposition._dict_learning.sparse_encode.init": {},
    "sklearn.decomposition._dict_learning.sparse_encode.max_iter": {},
    "sklearn.decomposition._dict_learning.sparse_encode.n_jobs": {},
    "sklearn.decomposition._dict_learning.sparse_encode.check_input": {},
    "sklearn.decomposition._dict_learning.sparse_encode.verbose": {},
    "sklearn.decomposition._dict_learning.sparse_encode.positive": {},
    "sklearn.decomposition._factor_analysis.FactorAnalysis.__init__.tol": {
      "0.01": 34
    },
    "sklearn.decomposition._factor_analysis.FactorAnalysis.__init__.copy": {
      "True": 34
    },
    "sklearn.decomposition._factor_analysis.FactorAnalysis.__init__.max_iter": {
      "1000": 34
    },
    "sklearn.decomposition._factor_analysis.FactorAnalysis.__init__.noise_variance_init": {
      "None": 34
    },
    "sklearn.decomposition._factor_analysis.FactorAnalysis.__init__.svd_method": {
      "'randomized'": 34
    },
    "sklearn.decomposition._factor_analysis.FactorAnalysis.__init__.iterated_power": {
      "3": 34
    },
    "sklearn.decomposition._factor_analysis.FactorAnalysis.fit.y": {
      "None": 16
    },
    "sklearn.decomposition._factor_analysis.FactorAnalysis.score.X": {},
    "sklearn.decomposition._factor_analysis.FactorAnalysis.score.y": {},
    "sklearn.decomposition._factor_analysis.FactorAnalysis.score_samples.X": {},
    "sklearn.decomposition._fastica.FastICA.__init__.fun": {
      "'logcosh'": 190
    },
    "sklearn.decomposition._fastica.FastICA.__init__.fun_args": {
      "None": 190
    },
    "sklearn.decomposition._fastica.FastICA.__init__.w_init": {
      "None": 190
    },
    "sklearn.decomposition._fastica.FastICA.fit.y": {
      "None": 7
    },
    "sklearn.decomposition._fastica.FastICA.fit_transform.y": {
      "None": 163
    },
    "sklearn.decomposition._fastica.FastICA.inverse_transform.copy": {
      "True": 7
    },
    "sklearn.decomposition._fastica.FastICA.transform.copy": {
      "True": 146
    },
    "sklearn.decomposition._fastica.fastica.X": {},
    "sklearn.decomposition._fastica.fastica.n_components": {},
    "sklearn.decomposition._fastica.fastica.algorithm": {},
    "sklearn.decomposition._fastica.fastica.whiten": {},
    "sklearn.decomposition._fastica.fastica.fun": {},
    "sklearn.decomposition._fastica.fastica.fun_args": {},
    "sklearn.decomposition._fastica.fastica.max_iter": {},
    "sklearn.decomposition._fastica.fastica.tol": {},
    "sklearn.decomposition._fastica.fastica.w_init": {},
    "sklearn.decomposition._fastica.fastica.random_state": {},
    "sklearn.decomposition._fastica.fastica.return_X_mean": {},
    "sklearn.decomposition._fastica.fastica.compute_sources": {},
    "sklearn.decomposition._fastica.fastica.return_n_iter": {},
    "sklearn.decomposition._incremental_pca.IncrementalPCA.__init__.whiten": {
      "False": 9
    },
    "sklearn.decomposition._incremental_pca.IncrementalPCA.fit.y": {
      "None": 3
    },
    "sklearn.decomposition._incremental_pca.IncrementalPCA.partial_fit.y": {
      "None": 4
    },
    "sklearn.decomposition._incremental_pca.IncrementalPCA.partial_fit.check_input": {
      "True": 4
    },
    "sklearn.decomposition._kernel_pca.KernelPCA.fit.y": {
      "None": 1
    },
    "sklearn.decomposition._kernel_pca.KernelPCA.inverse_transform.X": {},
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.doc_topic_prior": {
      "None": 62
    },
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.topic_word_prior": {
      "None": 62
    },
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.batch_size": {
      "128": 62
    },
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.evaluate_every": {
      "-1": 62
    },
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.total_samples": {
      "1000000.0": 62
    },
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.perp_tol": {
      "0.1": 62
    },
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.mean_change_tol": {
      "0.001": 62
    },
    "sklearn.decomposition._lda.LatentDirichletAllocation.__init__.max_doc_update_iter": {
      "100": 62
    },
    "sklearn.decomposition._lda.LatentDirichletAllocation.partial_fit.X": {},
    "sklearn.decomposition._lda.LatentDirichletAllocation.partial_fit.y": {},
    "sklearn.decomposition._lda.LatentDirichletAllocation.perplexity.sub_sampling": {
      "False": 2
    },
    "sklearn.decomposition._lda.LatentDirichletAllocation.score.y": {
      "None": 2
    },
    "sklearn.decomposition._nmf.NMF.__init__.verbose": {
      "0": 65
    },
    "sklearn.decomposition._nmf.NMF.__init__.regularization": {
      "'both'": 65
    },
    "sklearn.decomposition._nmf.NMF.fit.y": {
      "None": 12
    },
    "sklearn.decomposition._nmf.NMF.fit_transform.y": {
      "None": 43
    },
    "sklearn.decomposition._nmf.NMF.fit_transform.W": {
      "None": 43
    },
    "sklearn.decomposition._nmf.NMF.fit_transform.H": {
      "None": 43
    },
    "sklearn.decomposition._nmf.NMF.inverse_transform.W": {},
    "sklearn.decomposition._nmf.non_negative_factorization.X": {},
    "sklearn.decomposition._nmf.non_negative_factorization.W": {},
    "sklearn.decomposition._nmf.non_negative_factorization.H": {},
    "sklearn.decomposition._nmf.non_negative_factorization.n_components": {},
    "sklearn.decomposition._nmf.non_negative_factorization.init": {},
    "sklearn.decomposition._nmf.non_negative_factorization.update_H": {},
    "sklearn.decomposition._nmf.non_negative_factorization.solver": {},
    "sklearn.decomposition._nmf.non_negative_factorization.beta_loss": {},
    "sklearn.decomposition._nmf.non_negative_factorization.tol": {},
    "sklearn.decomposition._nmf.non_negative_factorization.max_iter": {},
    "sklearn.decomposition._nmf.non_negative_factorization.alpha": {},
    "sklearn.decomposition._nmf.non_negative_factorization.l1_ratio": {},
    "sklearn.decomposition._nmf.non_negative_factorization.regularization": {},
    "sklearn.decomposition._nmf.non_negative_factorization.random_state": {},
    "sklearn.decomposition._nmf.non_negative_factorization.verbose": {},
    "sklearn.decomposition._nmf.non_negative_factorization.shuffle": {},
    "sklearn.decomposition._pca.PCA.score.X": {},
    "sklearn.decomposition._pca.PCA.score.y": {},
    "sklearn.decomposition._pca.PCA.score_samples.X": {},
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.__init__.n_components": {},
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.__init__.alpha": {},
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.__init__.ridge_alpha": {},
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.__init__.n_iter": {},
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.__init__.callback": {},
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.__init__.batch_size": {},
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.__init__.verbose": {},
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.__init__.shuffle": {},
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.__init__.n_jobs": {},
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.__init__.method": {},
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.__init__.random_state": {},
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.fit.X": {},
    "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA.fit.y": {},
    "sklearn.decomposition._sparse_pca.SparsePCA.__init__.alpha": {
      "1": 11
    },
    "sklearn.decomposition._sparse_pca.SparsePCA.__init__.ridge_alpha": {
      "0.01": 11
    },
    "sklearn.decomposition._sparse_pca.SparsePCA.__init__.max_iter": {
      "1000": 11
    },
    "sklearn.decomposition._sparse_pca.SparsePCA.__init__.tol": {
      "1e-08": 11
    },
    "sklearn.decomposition._sparse_pca.SparsePCA.__init__.method": {
      "'lars'": 11
    },
    "sklearn.decomposition._sparse_pca.SparsePCA.__init__.n_jobs": {
      "None": 11
    },
    "sklearn.decomposition._sparse_pca.SparsePCA.__init__.U_init": {
      "None": 11
    },
    "sklearn.decomposition._sparse_pca.SparsePCA.__init__.V_init": {
      "None": 11
    },
    "sklearn.decomposition._sparse_pca.SparsePCA.__init__.verbose": {
      "False": 11
    },
    "sklearn.decomposition._sparse_pca.SparsePCA.fit.X": {},
    "sklearn.decomposition._sparse_pca.SparsePCA.fit.y": {},
    "sklearn.decomposition.setup.configuration.parent_package": {},
    "sklearn.decomposition.setup.configuration.top_path": {},
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.decision_function.X": {},
    "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict_log_proba.X": {},
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.decision_function.X": {},
    "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.predict_log_proba.X": {},
    "sklearn.dummy.DummyClassifier.fit.sample_weight": {
      "None": 31
    },
    "sklearn.dummy.DummyClassifier.predict_log_proba.X": {},
    "sklearn.dummy.DummyClassifier.score.sample_weight": {
      "None": 16
    },
    "sklearn.dummy.DummyRegressor.__init__.quantile": {
      "None": 52
    },
    "sklearn.dummy.DummyRegressor.fit.sample_weight": {
      "None": 25
    },
    "sklearn.dummy.DummyRegressor.predict.return_std": {
      "False": 25
    },
    "sklearn.dummy.DummyRegressor.score.sample_weight": {
      "None": 1
    },
    "sklearn.ensemble._bagging.BaggingClassifier.decision_function.X": {},
    "sklearn.ensemble._bagging.BaggingClassifier.predict_log_proba.X": {},
    "sklearn.ensemble._base.BaseEnsemble.__getitem__.index": {},
    "sklearn.ensemble._base.BaseEnsemble.__init__.base_estimator": {},
    "sklearn.ensemble._base.BaseEnsemble.__init__.n_estimators": {},
    "sklearn.ensemble._base.BaseEnsemble.__init__.estimator_params": {},
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__.min_samples_leaf": {
      "1": 7
    },
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__.min_weight_fraction_leaf": {
      "0.0": 7
    },
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__.max_leaf_nodes": {
      "None": 7
    },
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__.min_impurity_decrease": {
      "0.0": 7
    },
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__.min_impurity_split": {
      "None": 7
    },
    "sklearn.ensemble._forest.RandomTreesEmbedding.__init__.warm_start": {
      "False": 7
    },
    "sklearn.ensemble._forest.RandomTreesEmbedding.fit.y": {
      "None": 4
    },
    "sklearn.ensemble._forest.RandomTreesEmbedding.fit.sample_weight": {
      "None": 4
    },
    "sklearn.ensemble._forest.RandomTreesEmbedding.fit_transform.X": {},
    "sklearn.ensemble._forest.RandomTreesEmbedding.fit_transform.y": {},
    "sklearn.ensemble._forest.RandomTreesEmbedding.fit_transform.sample_weight": {},
    "sklearn.ensemble._gb.GradientBoostingClassifier.decision_function.X": {},
    "sklearn.ensemble._gb.GradientBoostingRegressor.apply.X": {},
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.categorical_features": {
      "None": 35
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.monotonic_cst": {
      "None": 35
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.__init__.early_stopping": {
      "'auto'": 35
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.decision_function.X": {},
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.staged_decision_function.X": {},
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.staged_predict.X": {},
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier.staged_predict_proba.X": {},
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.max_bins": {
      "255": 30
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.categorical_features": {
      "None": 30
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.monotonic_cst": {
      "None": 30
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.warm_start": {
      "False": 30
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.__init__.scoring": {
      "'loss'": 30
    },
    "sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor.staged_predict.X": {},
    "sklearn.ensemble._iforest.IsolationForest.__init__.warm_start": {
      "False": 44
    },
    "sklearn.ensemble._iforest.IsolationForest.fit.sample_weight": {
      "None": 28
    },
    "sklearn.ensemble._stacking.StackingClassifier.decision_function.X": {},
    "sklearn.ensemble._stacking.StackingClassifier.fit.sample_weight": {
      "None": 40
    },
    "sklearn.ensemble._stacking.StackingClassifier.transform.X": {},
    "sklearn.ensemble._stacking.StackingRegressor.fit.sample_weight": {
      "None": 47
    },
    "sklearn.ensemble._stacking.StackingRegressor.transform.X": {},
    "sklearn.ensemble._voting.VotingClassifier.fit.sample_weight": {
      "None": 259
    },
    "sklearn.ensemble._voting.VotingClassifier.transform.X": {},
    "sklearn.ensemble._voting.VotingRegressor.fit.sample_weight": {
      "None": 39
    },
    "sklearn.ensemble._voting.VotingRegressor.transform.X": {},
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.decision_function.X": {},
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.predict_log_proba.X": {},
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.staged_decision_function.X": {},
    "sklearn.ensemble._weight_boosting.AdaBoostClassifier.staged_predict_proba.X": {},
    "sklearn.ensemble._weight_boosting.AdaBoostRegressor.fit.sample_weight": {
      "None": 78
    },
    "sklearn.ensemble._weight_boosting.AdaBoostRegressor.staged_predict.X": {},
    "sklearn.ensemble.setup.configuration.parent_package": {},
    "sklearn.ensemble.setup.configuration.top_path": {},
    "sklearn.externals.conftest.pytest_ignore_collect.path": {},
    "sklearn.externals.conftest.pytest_ignore_collect.config": {},
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.__init__.dtype": {
      "np.float64": 240
    },
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.__init__.separator": {
      "'='": 240
    },
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.fit.y": {
      "None": 14
    },
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.fit_transform.y": {
      "None": 225
    },
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.inverse_transform.X": {},
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.inverse_transform.dict_type": {},
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.restrict.support": {},
    "sklearn.feature_extraction._dict_vectorizer.DictVectorizer.restrict.indices": {},
    "sklearn.feature_extraction._hash.FeatureHasher.__init__.alternate_sign": {
      "True": 22
    },
    "sklearn.feature_extraction._hash.FeatureHasher.fit.X": {},
    "sklearn.feature_extraction._hash.FeatureHasher.fit.y": {},
    "sklearn.feature_extraction.image.PatchExtractor.fit.X": {},
    "sklearn.feature_extraction.image.PatchExtractor.fit.y": {},
    "sklearn.feature_extraction.image.PatchExtractor.transform.X": {},
    "sklearn.feature_extraction.image.grid_to_graph.n_x": {},
    "sklearn.feature_extraction.image.grid_to_graph.n_y": {},
    "sklearn.feature_extraction.image.grid_to_graph.n_z": {},
    "sklearn.feature_extraction.image.grid_to_graph.mask": {},
    "sklearn.feature_extraction.image.grid_to_graph.return_as": {},
    "sklearn.feature_extraction.image.grid_to_graph.dtype": {},
    "sklearn.feature_extraction.image.img_to_graph.img": {},
    "sklearn.feature_extraction.image.img_to_graph.mask": {},
    "sklearn.feature_extraction.image.img_to_graph.return_as": {},
    "sklearn.feature_extraction.image.img_to_graph.dtype": {},
    "sklearn.feature_extraction.image.reconstruct_from_patches_2d.patches": {},
    "sklearn.feature_extraction.image.reconstruct_from_patches_2d.image_size": {},
    "sklearn.feature_extraction.setup.configuration.parent_package": {},
    "sklearn.feature_extraction.setup.configuration.top_path": {},
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.input": {
      "'content'": 66
    },
    "sklearn.feature_extraction.text.HashingVectorizer.__init__.encoding": {
      "'utf-8'": 66
    },
    "sklearn.feature_extraction.text.HashingVectorizer.fit.y": {
      "None": 5
    },
    "sklearn.feature_extraction.text.HashingVectorizer.fit_transform.y": {
      "None": 7
    },
    "sklearn.feature_extraction.text.HashingVectorizer.partial_fit.X": {},
    "sklearn.feature_extraction.text.HashingVectorizer.partial_fit.y": {},
    "sklearn.feature_extraction.text.TfidfTransformer.fit.y": {
      "None": 56
    },
    "sklearn.feature_extraction.text.strip_accents_ascii.s": {},
    "sklearn.feature_extraction.text.strip_accents_unicode.s": {},
    "sklearn.feature_extraction.text.strip_tags.s": {},
    "sklearn.feature_selection._from_model.SelectFromModel.__init__.norm_order": {
      "1": 215
    },
    "sklearn.feature_selection._from_model.SelectFromModel.__init__.importance_getter": {
      "'auto'": 215
    },
    "sklearn.feature_selection._from_model.SelectFromModel.partial_fit.X": {},
    "sklearn.feature_selection._from_model.SelectFromModel.partial_fit.y": {},
    "sklearn.feature_selection._mutual_info.mutual_info_classif.copy": {
      "True": 69
    },
    "sklearn.feature_selection._rfe.RFE.__init__.importance_getter": {
      "'auto'": 142
    },
    "sklearn.feature_selection._rfe.RFE.decision_function.X": {},
    "sklearn.feature_selection._rfe.RFE.predict_log_proba.X": {},
    "sklearn.feature_selection._rfe.RFECV.__init__.importance_getter": {
      "'auto'": 73
    },
    "sklearn.feature_selection._rfe.RFECV.fit.groups": {
      "None": 68
    },
    "sklearn.feature_selection._sequential.SequentialFeatureSelector.__init__.n_jobs": {
      "None": 2
    },
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.__init__.copy_X_train": {
      "True": 24
    },
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.__init__.multi_class": {
      "'one_vs_rest'": 24
    },
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.log_marginal_likelihood.theta": {},
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.log_marginal_likelihood.eval_gradient": {},
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.log_marginal_likelihood.clone_kernel": {},
    "sklearn.gaussian_process._gpc.GaussianProcessClassifier.predict_proba.X": {},
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.__init__.alpha": {
      "1e-10": 11
    },
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.__init__.optimizer": {
      "'fmin_l_bfgs_b'": 11
    },
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.__init__.normalize_y": {
      "False": 11
    },
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.__init__.copy_X_train": {
      "True": 11
    },
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.log_marginal_likelihood.theta": {
      "None": 1
    },
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.log_marginal_likelihood.eval_gradient": {
      "False": 1
    },
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.log_marginal_likelihood.clone_kernel": {
      "True": 1
    },
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.predict.return_std": {
      "False": 7
    },
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.predict.return_cov": {
      "False": 7
    },
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.sample_y.X": {},
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.sample_y.n_samples": {},
    "sklearn.gaussian_process._gpr.GaussianProcessRegressor.sample_y.random_state": {},
    "sklearn.gaussian_process.kernels.CompoundKernel.__call__.X": {},
    "sklearn.gaussian_process.kernels.CompoundKernel.__call__.Y": {},
    "sklearn.gaussian_process.kernels.CompoundKernel.__call__.eval_gradient": {},
    "sklearn.gaussian_process.kernels.CompoundKernel.__eq__.b": {},
    "sklearn.gaussian_process.kernels.CompoundKernel.__init__.kernels": {},
    "sklearn.gaussian_process.kernels.CompoundKernel.diag.X": {},
    "sklearn.gaussian_process.kernels.CompoundKernel.get_params.deep": {},
    "sklearn.gaussian_process.kernels.ConstantKernel.__call__.X": {},
    "sklearn.gaussian_process.kernels.ConstantKernel.__call__.Y": {},
    "sklearn.gaussian_process.kernels.ConstantKernel.__call__.eval_gradient": {},
    "sklearn.gaussian_process.kernels.ConstantKernel.diag.X": {},
    "sklearn.gaussian_process.kernels.DotProduct.__call__.X": {},
    "sklearn.gaussian_process.kernels.DotProduct.__call__.Y": {},
    "sklearn.gaussian_process.kernels.DotProduct.__call__.eval_gradient": {},
    "sklearn.gaussian_process.kernels.DotProduct.__init__.sigma_0": {
      "1.0": 2
    },
    "sklearn.gaussian_process.kernels.DotProduct.__init__.sigma_0_bounds": {
      "(1e-05, 100000.0)": 2
    },
    "sklearn.gaussian_process.kernels.DotProduct.diag.X": {},
    "sklearn.gaussian_process.kernels.ExpSineSquared.__call__.X": {},
    "sklearn.gaussian_process.kernels.ExpSineSquared.__call__.Y": {},
    "sklearn.gaussian_process.kernels.ExpSineSquared.__call__.eval_gradient": {},
    "sklearn.gaussian_process.kernels.ExpSineSquared.__init__.length_scale": {},
    "sklearn.gaussian_process.kernels.ExpSineSquared.__init__.periodicity": {},
    "sklearn.gaussian_process.kernels.ExpSineSquared.__init__.length_scale_bounds": {},
    "sklearn.gaussian_process.kernels.ExpSineSquared.__init__.periodicity_bounds": {},
    "sklearn.gaussian_process.kernels.Exponentiation.__call__.X": {},
    "sklearn.gaussian_process.kernels.Exponentiation.__call__.Y": {},
    "sklearn.gaussian_process.kernels.Exponentiation.__call__.eval_gradient": {},
    "sklearn.gaussian_process.kernels.Exponentiation.__eq__.b": {},
    "sklearn.gaussian_process.kernels.Exponentiation.__init__.kernel": {},
    "sklearn.gaussian_process.kernels.Exponentiation.__init__.exponent": {},
    "sklearn.gaussian_process.kernels.Exponentiation.diag.X": {},
    "sklearn.gaussian_process.kernels.Exponentiation.get_params.deep": {},
    "sklearn.gaussian_process.kernels.Hyperparameter.__eq__.other": {},
    "sklearn.gaussian_process.kernels.Hyperparameter.__new__.cls": {},
    "sklearn.gaussian_process.kernels.Hyperparameter.__new__.name": {},
    "sklearn.gaussian_process.kernels.Hyperparameter.__new__.value_type": {},
    "sklearn.gaussian_process.kernels.Hyperparameter.__new__.bounds": {},
    "sklearn.gaussian_process.kernels.Hyperparameter.__new__.n_elements": {},
    "sklearn.gaussian_process.kernels.Hyperparameter.__new__.fixed": {},
    "sklearn.gaussian_process.kernels.Kernel.__add__.b": {},
    "sklearn.gaussian_process.kernels.Kernel.__call__.X": {},
    "sklearn.gaussian_process.kernels.Kernel.__call__.Y": {},
    "sklearn.gaussian_process.kernels.Kernel.__call__.eval_gradient": {},
    "sklearn.gaussian_process.kernels.Kernel.__eq__.b": {},
    "sklearn.gaussian_process.kernels.Kernel.__mul__.b": {},
    "sklearn.gaussian_process.kernels.Kernel.__pow__.b": {},
    "sklearn.gaussian_process.kernels.Kernel.__radd__.b": {},
    "sklearn.gaussian_process.kernels.Kernel.__rmul__.b": {},
    "sklearn.gaussian_process.kernels.Kernel.clone_with_theta.theta": {},
    "sklearn.gaussian_process.kernels.Kernel.diag.X": {},
    "sklearn.gaussian_process.kernels.Kernel.get_params.deep": {},
    "sklearn.gaussian_process.kernels.KernelOperator.__eq__.b": {},
    "sklearn.gaussian_process.kernels.KernelOperator.__init__.k1": {},
    "sklearn.gaussian_process.kernels.KernelOperator.__init__.k2": {},
    "sklearn.gaussian_process.kernels.KernelOperator.get_params.deep": {},
    "sklearn.gaussian_process.kernels.Matern.__call__.X": {},
    "sklearn.gaussian_process.kernels.Matern.__call__.Y": {},
    "sklearn.gaussian_process.kernels.Matern.__call__.eval_gradient": {},
    "sklearn.gaussian_process.kernels.Matern.__init__.length_scale": {
      "1.0": 1
    },
    "sklearn.gaussian_process.kernels.Matern.__init__.length_scale_bounds": {
      "(1e-05, 100000.0)": 1
    },
    "sklearn.gaussian_process.kernels.Matern.__init__.nu": {
      "1.5": 1
    },
    "sklearn.gaussian_process.kernels.NormalizedKernelMixin.diag.X": {},
    "sklearn.gaussian_process.kernels.PairwiseKernel.__call__.X": {},
    "sklearn.gaussian_process.kernels.PairwiseKernel.__call__.Y": {},
    "sklearn.gaussian_process.kernels.PairwiseKernel.__call__.eval_gradient": {},
    "sklearn.gaussian_process.kernels.PairwiseKernel.__init__.gamma": {},
    "sklearn.gaussian_process.kernels.PairwiseKernel.__init__.gamma_bounds": {},
    "sklearn.gaussian_process.kernels.PairwiseKernel.__init__.metric": {},
    "sklearn.gaussian_process.kernels.PairwiseKernel.__init__.pairwise_kernels_kwargs": {},
    "sklearn.gaussian_process.kernels.PairwiseKernel.diag.X": {},
    "sklearn.gaussian_process.kernels.Product.__call__.X": {},
    "sklearn.gaussian_process.kernels.Product.__call__.Y": {},
    "sklearn.gaussian_process.kernels.Product.__call__.eval_gradient": {},
    "sklearn.gaussian_process.kernels.Product.diag.X": {},
    "sklearn.gaussian_process.kernels.RBF.__call__.X": {},
    "sklearn.gaussian_process.kernels.RBF.__call__.Y": {},
    "sklearn.gaussian_process.kernels.RBF.__call__.eval_gradient": {},
    "sklearn.gaussian_process.kernels.RationalQuadratic.__call__.X": {},
    "sklearn.gaussian_process.kernels.RationalQuadratic.__call__.Y": {},
    "sklearn.gaussian_process.kernels.RationalQuadratic.__call__.eval_gradient": {},
    "sklearn.gaussian_process.kernels.RationalQuadratic.__init__.length_scale": {
      "1.0": 1
    },
    "sklearn.gaussian_process.kernels.RationalQuadratic.__init__.alpha": {
      "1.0": 1
    },
    "sklearn.gaussian_process.kernels.RationalQuadratic.__init__.length_scale_bounds": {
      "(1e-05, 100000.0)": 1
    },
    "sklearn.gaussian_process.kernels.RationalQuadratic.__init__.alpha_bounds": {
      "(1e-05, 100000.0)": 1
    },
    "sklearn.gaussian_process.kernels.Sum.__call__.X": {},
    "sklearn.gaussian_process.kernels.Sum.__call__.Y": {},
    "sklearn.gaussian_process.kernels.Sum.__call__.eval_gradient": {},
    "sklearn.gaussian_process.kernels.Sum.diag.X": {},
    "sklearn.gaussian_process.kernels.WhiteKernel.__call__.X": {},
    "sklearn.gaussian_process.kernels.WhiteKernel.__call__.Y": {},
    "sklearn.gaussian_process.kernels.WhiteKernel.__call__.eval_gradient": {},
    "sklearn.gaussian_process.kernels.WhiteKernel.__init__.noise_level_bounds": {
      "(1e-05, 100000.0)": 2
    },
    "sklearn.gaussian_process.kernels.WhiteKernel.diag.X": {},
    "sklearn.impute._base.MissingIndicator.__init__.missing_values": {
      "np.nan": 13
    },
    "sklearn.impute._base.MissingIndicator.__init__.features": {
      "'missing-only'": 13
    },
    "sklearn.impute._base.MissingIndicator.__init__.sparse": {
      "'auto'": 13
    },
    "sklearn.impute._base.MissingIndicator.__init__.error_on_new": {
      "True": 13
    },
    "sklearn.impute._base.MissingIndicator.fit_transform.y": {
      "None": 1
    },
    "sklearn.impute._base.SimpleImputer.inverse_transform.X": {},
    "sklearn.impute._iterative.IterativeImputer.fit.y": {
      "None": 17
    },
    "sklearn.impute._iterative.IterativeImputer.fit_transform.y": {
      "None": 35
    },
    "sklearn.impute._knn.KNNImputer.__init__.missing_values": {
      "np.nan": 64
    },
    "sklearn.impute._knn.KNNImputer.__init__.copy": {
      "True": 64
    },
    "sklearn.impute._knn.KNNImputer.__init__.add_indicator": {
      "False": 64
    },
    "sklearn.impute._knn.KNNImputer.fit.y": {
      "None": 6
    },
    "sklearn.inspection._partial_dependence.partial_dependence.response_method": {
      "'auto'": 1
    },
    "sklearn.inspection._partial_dependence.partial_dependence.percentiles": {
      "(0.05, 0.95)": 1
    },
    "sklearn.inspection._partial_dependence.partial_dependence.method": {
      "'auto'": 1
    },
    "sklearn.inspection._partial_dependence.partial_dependence.kind": {
      "'legacy'": 1
    },
    "sklearn.inspection._permutation_importance.permutation_importance.sample_weight": {
      "None": 25
    },
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.__init__.pd_results": {},
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.__init__.features": {},
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.__init__.feature_names": {},
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.__init__.target_idx": {},
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.__init__.pdp_lim": {},
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.__init__.deciles": {},
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.__init__.kind": {},
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.__init__.subsample": {},
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.__init__.random_state": {},
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.plot.ax": {},
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.plot.n_cols": {},
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.plot.line_kw": {},
    "sklearn.inspection._plot.partial_dependence.PartialDependenceDisplay.plot.contour_kw": {},
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.feature_names": {
      "None": 11
    },
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.response_method": {
      "'auto'": 11
    },
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.n_cols": {
      "3": 11
    },
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.percentiles": {
      "(0.05, 0.95)": 11
    },
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.method": {
      "'auto'": 11
    },
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.n_jobs": {
      "None": 11
    },
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.verbose": {
      "0": 11
    },
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.line_kw": {
      "None": 11
    },
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.contour_kw": {
      "None": 11
    },
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.kind": {
      "'average'": 11
    },
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.subsample": {
      "1000": 11
    },
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.random_state": {
      "None": 11
    },
    "sklearn.inspection._plot.partial_dependence.plot_partial_dependence.convert_feature.fx": {},
    "sklearn.inspection.setup.configuration.parent_package": {},
    "sklearn.inspection.setup.configuration.top_path": {},
    "sklearn.isotonic.IsotonicRegression.__init__.increasing": {
      "True": 10
    },
    "sklearn.isotonic.IsotonicRegression.__setstate__.state": {},
    "sklearn.isotonic.IsotonicRegression.fit.sample_weight": {
      "None": 5
    },
    "sklearn.isotonic.check_increasing.x": {},
    "sklearn.isotonic.check_increasing.y": {},
    "sklearn.isotonic.isotonic_regression.y": {},
    "sklearn.isotonic.isotonic_regression.sample_weight": {},
    "sklearn.isotonic.isotonic_regression.y_min": {},
    "sklearn.isotonic.isotonic_regression.y_max": {},
    "sklearn.isotonic.isotonic_regression.increasing": {},
    "sklearn.kernel_approximation.AdditiveChi2Sampler.__init__.sample_steps": {},
    "sklearn.kernel_approximation.AdditiveChi2Sampler.__init__.sample_interval": {},
    "sklearn.kernel_approximation.AdditiveChi2Sampler.fit.X": {},
    "sklearn.kernel_approximation.AdditiveChi2Sampler.fit.y": {},
    "sklearn.kernel_approximation.AdditiveChi2Sampler.transform.X": {},
    "sklearn.kernel_approximation.Nystroem.__init__.gamma": {
      "None": 5
    },
    "sklearn.kernel_approximation.Nystroem.__init__.coef0": {
      "None": 5
    },
    "sklearn.kernel_approximation.Nystroem.__init__.degree": {
      "None": 5
    },
    "sklearn.kernel_approximation.Nystroem.__init__.kernel_params": {
      "None": 5
    },
    "sklearn.kernel_approximation.Nystroem.__init__.n_jobs": {
      "None": 5
    },
    "sklearn.kernel_approximation.Nystroem.fit.X": {},
    "sklearn.kernel_approximation.Nystroem.fit.y": {},
    "sklearn.kernel_approximation.PolynomialCountSketch.__init__.gamma": {},
    "sklearn.kernel_approximation.PolynomialCountSketch.__init__.degree": {},
    "sklearn.kernel_approximation.PolynomialCountSketch.__init__.coef0": {},
    "sklearn.kernel_approximation.PolynomialCountSketch.__init__.n_components": {},
    "sklearn.kernel_approximation.PolynomialCountSketch.__init__.random_state": {},
    "sklearn.kernel_approximation.PolynomialCountSketch.fit.X": {},
    "sklearn.kernel_approximation.PolynomialCountSketch.fit.y": {},
    "sklearn.kernel_approximation.PolynomialCountSketch.transform.X": {},
    "sklearn.kernel_approximation.RBFSampler.__init__.n_components": {
      "100": 2
    },
    "sklearn.kernel_approximation.RBFSampler.fit.X": {},
    "sklearn.kernel_approximation.RBFSampler.fit.y": {},
    "sklearn.kernel_approximation.SkewedChi2Sampler.__init__.skewedness": {},
    "sklearn.kernel_approximation.SkewedChi2Sampler.__init__.n_components": {},
    "sklearn.kernel_approximation.SkewedChi2Sampler.__init__.random_state": {},
    "sklearn.kernel_approximation.SkewedChi2Sampler.fit.X": {},
    "sklearn.kernel_approximation.SkewedChi2Sampler.fit.y": {},
    "sklearn.kernel_approximation.SkewedChi2Sampler.transform.X": {},
    "sklearn.kernel_ridge.KernelRidge.__init__.kernel_params": {
      "None": 97
    },
    "sklearn.kernel_ridge.KernelRidge.fit.sample_weight": {
      "None": 30
    },
    "sklearn.linear_model._bayes.BayesianRidge.__init__.copy_X": {
      "True": 194
    },
    "sklearn.linear_model._bayes.BayesianRidge.fit.sample_weight": {
      "None": 75
    },
    "sklearn.linear_model._coordinate_descent.ElasticNet.fit.check_input": {
      "True": 475
    },
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.n_alphas": {
      "100": 120
    },
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.precompute": {
      "'auto'": 120
    },
    "sklearn.linear_model._coordinate_descent.LassoCV.__init__.copy_X": {
      "True": 120
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet.__init__.fit_intercept": {
      "True": 19
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet.__init__.normalize": {
      "False": 19
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet.__init__.copy_X": {
      "True": 19
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet.__init__.max_iter": {
      "1000": 19
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet.__init__.tol": {
      "0.0001": 19
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNet.__init__.warm_start": {
      "False": 19
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.l1_ratio": {
      "0.5": 1
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.eps": {
      "0.001": 1
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.n_alphas": {
      "100": 1
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.alphas": {
      "None": 1
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.fit_intercept": {
      "True": 1
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.normalize": {
      "False": 1
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.max_iter": {
      "1000": 1
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.tol": {
      "0.0001": 1
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.cv": {
      "None": 1
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.copy_X": {
      "True": 1
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.verbose": {
      "0": 1
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.n_jobs": {
      "None": 1
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV.__init__.selection": {
      "'cyclic'": 1
    },
    "sklearn.linear_model._coordinate_descent.MultiTaskLasso.__init__.alpha": {},
    "sklearn.linear_model._coordinate_descent.MultiTaskLasso.__init__.fit_intercept": {},
    "sklearn.linear_model._coordinate_descent.MultiTaskLasso.__init__.normalize": {},
    "sklearn.linear_model._coordinate_descent.MultiTaskLasso.__init__.copy_X": {},
    "sklearn.linear_model._coordinate_descent.MultiTaskLasso.__init__.max_iter": {},
    "sklearn.linear_model._coordinate_descent.MultiTaskLasso.__init__.tol": {},
    "sklearn.linear_model._coordinate_descent.MultiTaskLasso.__init__.warm_start": {},
    "sklearn.linear_model._coordinate_descent.MultiTaskLasso.__init__.random_state": {},
    "sklearn.linear_model._coordinate_descent.MultiTaskLasso.__init__.selection": {},
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__.eps": {},
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__.n_alphas": {},
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__.alphas": {},
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__.fit_intercept": {},
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__.normalize": {},
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__.max_iter": {},
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__.tol": {},
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__.copy_X": {},
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__.cv": {},
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__.verbose": {},
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__.n_jobs": {},
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__.random_state": {},
    "sklearn.linear_model._coordinate_descent.MultiTaskLassoCV.__init__.selection": {},
    "sklearn.linear_model._coordinate_descent.enet_path.X": {},
    "sklearn.linear_model._coordinate_descent.enet_path.y": {},
    "sklearn.linear_model._coordinate_descent.enet_path.l1_ratio": {},
    "sklearn.linear_model._coordinate_descent.enet_path.eps": {},
    "sklearn.linear_model._coordinate_descent.enet_path.n_alphas": {},
    "sklearn.linear_model._coordinate_descent.enet_path.alphas": {},
    "sklearn.linear_model._coordinate_descent.enet_path.precompute": {},
    "sklearn.linear_model._coordinate_descent.enet_path.Xy": {},
    "sklearn.linear_model._coordinate_descent.enet_path.copy_X": {},
    "sklearn.linear_model._coordinate_descent.enet_path.coef_init": {},
    "sklearn.linear_model._coordinate_descent.enet_path.verbose": {},
    "sklearn.linear_model._coordinate_descent.enet_path.return_n_iter": {},
    "sklearn.linear_model._coordinate_descent.enet_path.positive": {},
    "sklearn.linear_model._coordinate_descent.enet_path.check_input": {},
    "sklearn.linear_model._coordinate_descent.lasso_path.X": {},
    "sklearn.linear_model._coordinate_descent.lasso_path.y": {},
    "sklearn.linear_model._coordinate_descent.lasso_path.eps": {},
    "sklearn.linear_model._coordinate_descent.lasso_path.n_alphas": {},
    "sklearn.linear_model._coordinate_descent.lasso_path.alphas": {},
    "sklearn.linear_model._coordinate_descent.lasso_path.precompute": {},
    "sklearn.linear_model._coordinate_descent.lasso_path.Xy": {},
    "sklearn.linear_model._coordinate_descent.lasso_path.copy_X": {},
    "sklearn.linear_model._coordinate_descent.lasso_path.coef_init": {},
    "sklearn.linear_model._coordinate_descent.lasso_path.verbose": {},
    "sklearn.linear_model._coordinate_descent.lasso_path.return_n_iter": {},
    "sklearn.linear_model._coordinate_descent.lasso_path.positive": {},
    "sklearn.linear_model._glm.glm.GammaRegressor.__init__.alpha": {
      "1.0": 3
    },
    "sklearn.linear_model._glm.glm.GammaRegressor.__init__.fit_intercept": {
      "True": 3
    },
    "sklearn.linear_model._glm.glm.GammaRegressor.__init__.max_iter": {
      "100": 3
    },
    "sklearn.linear_model._glm.glm.GammaRegressor.__init__.tol": {
      "0.0001": 3
    },
    "sklearn.linear_model._glm.glm.GammaRegressor.__init__.warm_start": {
      "False": 3
    },
    "sklearn.linear_model._glm.glm.GammaRegressor.__init__.verbose": {
      "0": 3
    },
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.__init__.alpha": {},
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.__init__.fit_intercept": {},
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.__init__.family": {},
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.__init__.link": {},
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.__init__.solver": {},
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.__init__.max_iter": {},
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.__init__.tol": {},
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.__init__.warm_start": {},
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.__init__.verbose": {},
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.fit.X": {},
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.fit.y": {},
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.fit.sample_weight": {},
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.predict.X": {},
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.score.X": {},
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.score.y": {},
    "sklearn.linear_model._glm.glm.GeneralizedLinearRegressor.score.sample_weight": {},
    "sklearn.linear_model._glm.glm.PoissonRegressor.__init__.alpha": {
      "1.0": 1
    },
    "sklearn.linear_model._glm.glm.PoissonRegressor.__init__.fit_intercept": {
      "True": 1
    },
    "sklearn.linear_model._glm.glm.PoissonRegressor.__init__.max_iter": {
      "100": 1
    },
    "sklearn.linear_model._glm.glm.PoissonRegressor.__init__.tol": {
      "0.0001": 1
    },
    "sklearn.linear_model._glm.glm.PoissonRegressor.__init__.warm_start": {
      "False": 1
    },
    "sklearn.linear_model._glm.glm.PoissonRegressor.__init__.verbose": {
      "0": 1
    },
    "sklearn.linear_model._glm.glm.TweedieRegressor.__init__.fit_intercept": {
      "True": 10
    },
    "sklearn.linear_model._glm.glm.TweedieRegressor.__init__.tol": {
      "0.0001": 10
    },
    "sklearn.linear_model._glm.glm.TweedieRegressor.__init__.verbose": {
      "0": 10
    },
    "sklearn.linear_model._huber.HuberRegressor.__init__.warm_start": {
      "False": 40
    },
    "sklearn.linear_model._huber.HuberRegressor.__init__.tol": {
      "1e-05": 40
    },
    "sklearn.linear_model._huber.HuberRegressor.fit.sample_weight": {
      "None": 15
    },
    "sklearn.linear_model._least_angle.Lars.__init__.verbose": {
      "False": 7
    },
    "sklearn.linear_model._least_angle.Lars.__init__.normalize": {
      "True": 7
    },
    "sklearn.linear_model._least_angle.Lars.__init__.precompute": {
      "'auto'": 7
    },
    "sklearn.linear_model._least_angle.Lars.__init__.eps": {
      "np.finfo(float).eps": 7
    },
    "sklearn.linear_model._least_angle.Lars.__init__.copy_X": {
      "True": 7
    },
    "sklearn.linear_model._least_angle.Lars.__init__.fit_path": {
      "True": 7
    },
    "sklearn.linear_model._least_angle.Lars.__init__.jitter": {
      "None": 7
    },
    "sklearn.linear_model._least_angle.Lars.__init__.random_state": {
      "None": 7
    },
    "sklearn.linear_model._least_angle.Lars.fit.Xy": {
      "None": 2
    },
    "sklearn.linear_model._least_angle.LarsCV.__init__.fit_intercept": {
      "True": 1
    },
    "sklearn.linear_model._least_angle.LarsCV.__init__.verbose": {
      "False": 1
    },
    "sklearn.linear_model._least_angle.LarsCV.__init__.max_iter": {
      "500": 1
    },
    "sklearn.linear_model._least_angle.LarsCV.__init__.normalize": {
      "True": 1
    },
    "sklearn.linear_model._least_angle.LarsCV.__init__.precompute": {
      "'auto'": 1
    },
    "sklearn.linear_model._least_angle.LarsCV.__init__.cv": {
      "None": 1
    },
    "sklearn.linear_model._least_angle.LarsCV.__init__.max_n_alphas": {
      "1000": 1
    },
    "sklearn.linear_model._least_angle.LarsCV.__init__.n_jobs": {
      "None": 1
    },
    "sklearn.linear_model._least_angle.LarsCV.__init__.eps": {
      "np.finfo(float).eps": 1
    },
    "sklearn.linear_model._least_angle.LarsCV.__init__.copy_X": {
      "True": 1
    },
    "sklearn.linear_model._least_angle.LassoLars.__init__.eps": {
      "np.finfo(float).eps": 12
    },
    "sklearn.linear_model._least_angle.LassoLars.__init__.copy_X": {
      "True": 12
    },
    "sklearn.linear_model._least_angle.LassoLars.__init__.fit_path": {
      "True": 12
    },
    "sklearn.linear_model._least_angle.LassoLars.__init__.positive": {
      "False": 12
    },
    "sklearn.linear_model._least_angle.LassoLars.__init__.jitter": {
      "None": 12
    },
    "sklearn.linear_model._least_angle.LassoLars.__init__.random_state": {
      "None": 12
    },
    "sklearn.linear_model._least_angle.LassoLarsCV.__init__.fit_intercept": {
      "True": 44
    },
    "sklearn.linear_model._least_angle.LassoLarsCV.__init__.eps": {
      "np.finfo(float).eps": 44
    },
    "sklearn.linear_model._least_angle.LassoLarsCV.__init__.copy_X": {
      "True": 44
    },
    "sklearn.linear_model._least_angle.LassoLarsCV.__init__.positive": {
      "False": 44
    },
    "sklearn.linear_model._least_angle.LassoLarsIC.__init__.verbose": {
      "False": 7
    },
    "sklearn.linear_model._least_angle.LassoLarsIC.__init__.normalize": {
      "True": 7
    },
    "sklearn.linear_model._least_angle.LassoLarsIC.__init__.precompute": {
      "'auto'": 7
    },
    "sklearn.linear_model._least_angle.LassoLarsIC.__init__.max_iter": {
      "500": 7
    },
    "sklearn.linear_model._least_angle.LassoLarsIC.__init__.eps": {
      "np.finfo(float).eps": 7
    },
    "sklearn.linear_model._least_angle.LassoLarsIC.__init__.copy_X": {
      "True": 7
    },
    "sklearn.linear_model._least_angle.LassoLarsIC.__init__.positive": {
      "False": 7
    },
    "sklearn.linear_model._least_angle.LassoLarsIC.fit.copy_X": {
      "None": 2
    },
    "sklearn.linear_model._least_angle.lars_path.X": {},
    "sklearn.linear_model._least_angle.lars_path.y": {},
    "sklearn.linear_model._least_angle.lars_path.Xy": {},
    "sklearn.linear_model._least_angle.lars_path.Gram": {},
    "sklearn.linear_model._least_angle.lars_path.max_iter": {},
    "sklearn.linear_model._least_angle.lars_path.alpha_min": {},
    "sklearn.linear_model._least_angle.lars_path.method": {},
    "sklearn.linear_model._least_angle.lars_path.copy_X": {},
    "sklearn.linear_model._least_angle.lars_path.eps": {},
    "sklearn.linear_model._least_angle.lars_path.copy_Gram": {},
    "sklearn.linear_model._least_angle.lars_path.verbose": {},
    "sklearn.linear_model._least_angle.lars_path.return_path": {},
    "sklearn.linear_model._least_angle.lars_path.return_n_iter": {},
    "sklearn.linear_model._least_angle.lars_path.positive": {},
    "sklearn.linear_model._least_angle.lars_path_gram.Xy": {},
    "sklearn.linear_model._least_angle.lars_path_gram.Gram": {},
    "sklearn.linear_model._least_angle.lars_path_gram.n_samples": {},
    "sklearn.linear_model._least_angle.lars_path_gram.max_iter": {},
    "sklearn.linear_model._least_angle.lars_path_gram.alpha_min": {},
    "sklearn.linear_model._least_angle.lars_path_gram.method": {},
    "sklearn.linear_model._least_angle.lars_path_gram.copy_X": {},
    "sklearn.linear_model._least_angle.lars_path_gram.eps": {},
    "sklearn.linear_model._least_angle.lars_path_gram.copy_Gram": {},
    "sklearn.linear_model._least_angle.lars_path_gram.verbose": {},
    "sklearn.linear_model._least_angle.lars_path_gram.return_path": {},
    "sklearn.linear_model._least_angle.lars_path_gram.return_n_iter": {},
    "sklearn.linear_model._least_angle.lars_path_gram.positive": {},
    "sklearn.linear_model._logistic.LogisticRegressionCV.__init__.l1_ratios": {
      "None": 125
    },
    "sklearn.linear_model._logistic.LogisticRegressionCV.fit.sample_weight": {
      "None": 96
    },
    "sklearn.linear_model._logistic.LogisticRegressionCV.score.sample_weight": {
      "None": 19
    },
    "sklearn.linear_model._omp.OrthogonalMatchingPursuitCV.__init__.copy": {
      "True": 5
    },
    "sklearn.linear_model._omp.OrthogonalMatchingPursuitCV.__init__.fit_intercept": {
      "True": 5
    },
    "sklearn.linear_model._omp.OrthogonalMatchingPursuitCV.__init__.normalize": {
      "True": 5
    },
    "sklearn.linear_model._omp.OrthogonalMatchingPursuitCV.__init__.max_iter": {
      "None": 5
    },
    "sklearn.linear_model._omp.OrthogonalMatchingPursuitCV.__init__.cv": {
      "None": 5
    },
    "sklearn.linear_model._omp.OrthogonalMatchingPursuitCV.__init__.n_jobs": {
      "None": 5
    },
    "sklearn.linear_model._omp.OrthogonalMatchingPursuitCV.__init__.verbose": {
      "False": 5
    },
    "sklearn.linear_model._omp.OrthogonalMatchingPursuitCV.fit.X": {},
    "sklearn.linear_model._omp.OrthogonalMatchingPursuitCV.fit.y": {},
    "sklearn.linear_model._omp.orthogonal_mp.X": {},
    "sklearn.linear_model._omp.orthogonal_mp.y": {},
    "sklearn.linear_model._omp.orthogonal_mp.n_nonzero_coefs": {},
    "sklearn.linear_model._omp.orthogonal_mp.tol": {},
    "sklearn.linear_model._omp.orthogonal_mp.precompute": {},
    "sklearn.linear_model._omp.orthogonal_mp.copy_X": {},
    "sklearn.linear_model._omp.orthogonal_mp.return_path": {},
    "sklearn.linear_model._omp.orthogonal_mp.return_n_iter": {},
    "sklearn.linear_model._omp.orthogonal_mp_gram.Gram": {},
    "sklearn.linear_model._omp.orthogonal_mp_gram.Xy": {},
    "sklearn.linear_model._omp.orthogonal_mp_gram.n_nonzero_coefs": {},
    "sklearn.linear_model._omp.orthogonal_mp_gram.tol": {},
    "sklearn.linear_model._omp.orthogonal_mp_gram.norms_squared": {},
    "sklearn.linear_model._omp.orthogonal_mp_gram.copy_Gram": {},
    "sklearn.linear_model._omp.orthogonal_mp_gram.copy_Xy": {},
    "sklearn.linear_model._omp.orthogonal_mp_gram.return_path": {},
    "sklearn.linear_model._omp.orthogonal_mp_gram.return_n_iter": {},
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.C": {
      "1.0": 39
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.fit_intercept": {
      "True": 39
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.shuffle": {
      "True": 39
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.__init__.warm_start": {
      "False": 39
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.fit.coef_init": {
      "None": 15
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.fit.intercept_init": {
      "None": 15
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.partial_fit.X": {},
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.partial_fit.y": {},
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier.partial_fit.classes": {},
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.early_stopping": {
      "False": 11
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.validation_fraction": {
      "0.1": 11
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.__init__.n_iter_no_change": {
      "5": 11
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.fit.coef_init": {
      "None": 6
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.fit.intercept_init": {
      "None": 6
    },
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.partial_fit.X": {},
    "sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor.partial_fit.y": {},
    "sklearn.linear_model._perceptron.Perceptron.__init__.l1_ratio": {
      "0.15": 78
    },
    "sklearn.linear_model._perceptron.Perceptron.__init__.early_stopping": {
      "False": 78
    },
    "sklearn.linear_model._perceptron.Perceptron.__init__.validation_fraction": {
      "0.1": 78
    },
    "sklearn.linear_model._perceptron.Perceptron.__init__.n_iter_no_change": {
      "5": 78
    },
    "sklearn.linear_model._ransac.RANSACRegressor.__init__.is_data_valid": {
      "None": 28
    },
    "sklearn.linear_model._ransac.RANSACRegressor.__init__.is_model_valid": {
      "None": 28
    },
    "sklearn.linear_model._ransac.RANSACRegressor.__init__.max_skips": {
      "np.inf": 28
    },
    "sklearn.linear_model._ransac.RANSACRegressor.__init__.stop_n_inliers": {
      "np.inf": 28
    },
    "sklearn.linear_model._ransac.RANSACRegressor.__init__.stop_score": {
      "np.inf": 28
    },
    "sklearn.linear_model._ransac.RANSACRegressor.__init__.stop_probability": {
      "0.99": 28
    },
    "sklearn.linear_model._ransac.RANSACRegressor.fit.sample_weight": {
      "None": 10
    },
    "sklearn.linear_model._ridge.RidgeClassifier.fit.sample_weight": {
      "None": 88
    },
    "sklearn.linear_model._ridge.RidgeClassifierCV.__init__.fit_intercept": {
      "True": 40
    },
    "sklearn.linear_model._ridge.RidgeClassifierCV.__init__.normalize": {
      "False": 40
    },
    "sklearn.linear_model._ridge.RidgeClassifierCV.__init__.scoring": {
      "None": 40
    },
    "sklearn.linear_model._ridge.RidgeClassifierCV.__init__.class_weight": {
      "None": 40
    },
    "sklearn.linear_model._ridge.RidgeClassifierCV.__init__.store_cv_values": {
      "False": 40
    },
    "sklearn.linear_model._ridge.RidgeClassifierCV.fit.sample_weight": {
      "None": 7
    },
    "sklearn.linear_model._ridge.ridge_regression.X": {},
    "sklearn.linear_model._ridge.ridge_regression.y": {},
    "sklearn.linear_model._ridge.ridge_regression.alpha": {},
    "sklearn.linear_model._ridge.ridge_regression.sample_weight": {},
    "sklearn.linear_model._ridge.ridge_regression.solver": {},
    "sklearn.linear_model._ridge.ridge_regression.max_iter": {},
    "sklearn.linear_model._ridge.ridge_regression.tol": {},
    "sklearn.linear_model._ridge.ridge_regression.verbose": {},
    "sklearn.linear_model._ridge.ridge_regression.random_state": {},
    "sklearn.linear_model._ridge.ridge_regression.return_n_iter": {},
    "sklearn.linear_model._ridge.ridge_regression.return_intercept": {},
    "sklearn.linear_model._ridge.ridge_regression.check_input": {},
    "sklearn.linear_model._stochastic_gradient.SGDRegressor.__init__.validation_fraction": {
      "0.1": 134
    },
    "sklearn.linear_model._theil_sen.TheilSenRegressor.__init__.copy_X": {
      "True": 26
    },
    "sklearn.linear_model._theil_sen.TheilSenRegressor.__init__.max_subpopulation": {
      "10000.0": 26
    },
    "sklearn.linear_model._theil_sen.TheilSenRegressor.__init__.n_subsamples": {
      "None": 26
    },
    "sklearn.linear_model._theil_sen.TheilSenRegressor.__init__.max_iter": {
      "300": 26
    },
    "sklearn.linear_model._theil_sen.TheilSenRegressor.__init__.tol": {
      "0.001": 26
    },
    "sklearn.linear_model._theil_sen.TheilSenRegressor.__init__.n_jobs": {
      "None": 26
    },
    "sklearn.linear_model.setup.configuration.parent_package": {},
    "sklearn.linear_model.setup.configuration.top_path": {},
    "sklearn.manifold._isomap.Isomap.__init__.tol": {
      "0": 15
    },
    "sklearn.manifold._isomap.Isomap.__init__.max_iter": {
      "None": 15
    },
    "sklearn.manifold._isomap.Isomap.__init__.path_method": {
      "'auto'": 15
    },
    "sklearn.manifold._isomap.Isomap.__init__.neighbors_algorithm": {
      "'auto'": 15
    },
    "sklearn.manifold._isomap.Isomap.__init__.metric": {
      "'minkowski'": 15
    },
    "sklearn.manifold._isomap.Isomap.__init__.p": {
      "2": 15
    },
    "sklearn.manifold._isomap.Isomap.__init__.metric_params": {
      "None": 15
    },
    "sklearn.manifold._isomap.Isomap.fit.y": {
      "None": 4
    },
    "sklearn.manifold._isomap.Isomap.fit_transform.y": {
      "None": 5
    },
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.__init__.reg": {
      "0.001": 7
    },
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.__init__.tol": {
      "1e-06": 7
    },
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.__init__.max_iter": {
      "100": 7
    },
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.__init__.hessian_tol": {
      "0.0001": 7
    },
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.__init__.modified_tol": {
      "1e-12": 7
    },
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.__init__.neighbors_algorithm": {
      "'auto'": 7
    },
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.__init__.n_jobs": {
      "None": 7
    },
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.fit.X": {},
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.fit.y": {},
    "sklearn.manifold._locally_linear.LocallyLinearEmbedding.fit_transform.y": {
      "None": 5
    },
    "sklearn.manifold._locally_linear.locally_linear_embedding.X": {},
    "sklearn.manifold._locally_linear.locally_linear_embedding.n_neighbors": {},
    "sklearn.manifold._locally_linear.locally_linear_embedding.n_components": {},
    "sklearn.manifold._locally_linear.locally_linear_embedding.reg": {},
    "sklearn.manifold._locally_linear.locally_linear_embedding.eigen_solver": {},
    "sklearn.manifold._locally_linear.locally_linear_embedding.tol": {},
    "sklearn.manifold._locally_linear.locally_linear_embedding.max_iter": {},
    "sklearn.manifold._locally_linear.locally_linear_embedding.method": {},
    "sklearn.manifold._locally_linear.locally_linear_embedding.hessian_tol": {},
    "sklearn.manifold._locally_linear.locally_linear_embedding.modified_tol": {},
    "sklearn.manifold._locally_linear.locally_linear_embedding.random_state": {},
    "sklearn.manifold._locally_linear.locally_linear_embedding.n_jobs": {},
    "sklearn.manifold._mds.MDS.__init__.metric": {
      "True": 11
    },
    "sklearn.manifold._mds.MDS.__init__.verbose": {
      "0": 11
    },
    "sklearn.manifold._mds.MDS.__init__.eps": {
      "0.001": 11
    },
    "sklearn.manifold._mds.MDS.fit.X": {},
    "sklearn.manifold._mds.MDS.fit.y": {},
    "sklearn.manifold._mds.MDS.fit.init": {},
    "sklearn.manifold._mds.MDS.fit_transform.y": {
      "None": 6
    },
    "sklearn.manifold._mds.MDS.fit_transform.init": {
      "None": 6
    },
    "sklearn.manifold._mds.smacof.metric": {
      "True": 2
    },
    "sklearn.manifold._mds.smacof.init": {
      "None": 2
    },
    "sklearn.manifold._mds.smacof.n_init": {
      "8": 2
    },
    "sklearn.manifold._mds.smacof.n_jobs": {
      "None": 2
    },
    "sklearn.manifold._mds.smacof.max_iter": {
      "300": 2
    },
    "sklearn.manifold._mds.smacof.verbose": {
      "0": 2
    },
    "sklearn.manifold._mds.smacof.eps": {
      "0.001": 2
    },
    "sklearn.manifold._mds.smacof.random_state": {
      "None": 2
    },
    "sklearn.manifold._mds.smacof.return_n_iter": {
      "False": 2
    },
    "sklearn.manifold._spectral_embedding.SpectralEmbedding.__init__.gamma": {
      "None": 10
    },
    "sklearn.manifold._spectral_embedding.SpectralEmbedding.__init__.random_state": {
      "None": 10
    },
    "sklearn.manifold._spectral_embedding.SpectralEmbedding.__init__.eigen_solver": {
      "None": 10
    },
    "sklearn.manifold._spectral_embedding.SpectralEmbedding.fit.X": {},
    "sklearn.manifold._spectral_embedding.SpectralEmbedding.fit.y": {},
    "sklearn.manifold._spectral_embedding.SpectralEmbedding.fit_transform.y": {
      "None": 7
    },
    "sklearn.manifold._spectral_embedding.spectral_embedding.adjacency": {},
    "sklearn.manifold._spectral_embedding.spectral_embedding.n_components": {},
    "sklearn.manifold._spectral_embedding.spectral_embedding.eigen_solver": {},
    "sklearn.manifold._spectral_embedding.spectral_embedding.random_state": {},
    "sklearn.manifold._spectral_embedding.spectral_embedding.eigen_tol": {},
    "sklearn.manifold._spectral_embedding.spectral_embedding.norm_laplacian": {},
    "sklearn.manifold._spectral_embedding.spectral_embedding.drop_first": {},
    "sklearn.manifold._t_sne.TSNE.__init__.square_distances": {
      "'legacy'": 536
    },
    "sklearn.manifold._t_sne.TSNE.fit.X": {},
    "sklearn.manifold._t_sne.TSNE.fit.y": {},
    "sklearn.manifold._t_sne.trustworthiness.X": {},
    "sklearn.manifold._t_sne.trustworthiness.X_embedded": {},
    "sklearn.manifold._t_sne.trustworthiness.n_neighbors": {},
    "sklearn.manifold._t_sne.trustworthiness.metric": {},
    "sklearn.manifold.setup.configuration.parent_package": {},
    "sklearn.manifold.setup.configuration.top_path": {},
    "sklearn.metrics._classification.balanced_accuracy_score.adjusted": {
      "False": 23
    },
    "sklearn.metrics._classification.brier_score_loss.sample_weight": {
      "None": 8
    },
    "sklearn.metrics._classification.classification_report.sample_weight": {
      "None": 3074
    },
    "sklearn.metrics._classification.fbeta_score.pos_label": {
      "1": 143
    },
    "sklearn.metrics._classification.fbeta_score.sample_weight": {
      "None": 143
    },
    "sklearn.metrics._classification.fbeta_score.zero_division": {
      "'warn'": 143
    },
    "sklearn.metrics._classification.hamming_loss.sample_weight": {
      "None": 35
    },
    "sklearn.metrics._classification.hinge_loss.labels": {
      "None": 11
    },
    "sklearn.metrics._classification.hinge_loss.sample_weight": {
      "None": 11
    },
    "sklearn.metrics._classification.jaccard_score.labels": {
      "None": 13
    },
    "sklearn.metrics._classification.jaccard_score.sample_weight": {
      "None": 13
    },
    "sklearn.metrics._classification.jaccard_score.zero_division": {
      "'warn'": 13
    },
    "sklearn.metrics._classification.matthews_corrcoef.sample_weight": {
      "None": 145
    },
    "sklearn.metrics._classification.precision_recall_fscore_support.warn_for": {
      "('precision', 'recall', 'f-score')": 58
    },
    "sklearn.metrics._classification.precision_recall_fscore_support.sample_weight": {
      "None": 58
    },
    "sklearn.metrics._classification.precision_recall_fscore_support.zero_division": {
      "'warn'": 58
    },
    "sklearn.metrics._classification.precision_score.sample_weight": {
      "None": 1153
    },
    "sklearn.metrics._classification.recall_score.sample_weight": {
      "None": 1124
    },
    "sklearn.metrics._classification.zero_one_loss.normalize": {
      "True": 8
    },
    "sklearn.metrics._classification.zero_one_loss.sample_weight": {
      "None": 8
    },
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix.sample_weight": {
      "None": 180
    },
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix.include_values": {
      "True": 180
    },
    "sklearn.metrics._plot.confusion_matrix.plot_confusion_matrix.colorbar": {
      "True": 180
    },
    "sklearn.metrics._plot.det_curve.DetCurveDisplay.__init__.fpr": {},
    "sklearn.metrics._plot.det_curve.DetCurveDisplay.__init__.fnr": {},
    "sklearn.metrics._plot.det_curve.DetCurveDisplay.__init__.estimator_name": {},
    "sklearn.metrics._plot.det_curve.DetCurveDisplay.__init__.pos_label": {},
    "sklearn.metrics._plot.det_curve.DetCurveDisplay.plot.ax": {},
    "sklearn.metrics._plot.det_curve.DetCurveDisplay.plot.name": {},
    "sklearn.metrics._plot.det_curve.plot_det_curve.estimator": {},
    "sklearn.metrics._plot.det_curve.plot_det_curve.X": {},
    "sklearn.metrics._plot.det_curve.plot_det_curve.y": {},
    "sklearn.metrics._plot.det_curve.plot_det_curve.sample_weight": {},
    "sklearn.metrics._plot.det_curve.plot_det_curve.response_method": {},
    "sklearn.metrics._plot.det_curve.plot_det_curve.name": {},
    "sklearn.metrics._plot.det_curve.plot_det_curve.ax": {},
    "sklearn.metrics._plot.det_curve.plot_det_curve.pos_label": {},
    "sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay.__init__.average_precision": {
      "None": 2
    },
    "sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay.__init__.estimator_name": {
      "None": 2
    },
    "sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay.__init__.pos_label": {
      "None": 2
    },
    "sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay.plot.ax": {
      "None": 2
    },
    "sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay.plot.name": {
      "None": 2
    },
    "sklearn.metrics._plot.precision_recall_curve.plot_precision_recall_curve.sample_weight": {
      "None": 7
    },
    "sklearn.metrics._plot.precision_recall_curve.plot_precision_recall_curve.response_method": {
      "'auto'": 7
    },
    "sklearn.metrics._plot.precision_recall_curve.plot_precision_recall_curve.name": {
      "None": 7
    },
    "sklearn.metrics._plot.precision_recall_curve.plot_precision_recall_curve.pos_label": {
      "None": 7
    },
    "sklearn.metrics._plot.roc_curve.RocCurveDisplay.__init__.roc_auc": {
      "None": 2
    },
    "sklearn.metrics._plot.roc_curve.RocCurveDisplay.__init__.estimator_name": {
      "None": 2
    },
    "sklearn.metrics._plot.roc_curve.RocCurveDisplay.__init__.pos_label": {
      "None": 2
    },
    "sklearn.metrics._plot.roc_curve.RocCurveDisplay.plot.ax": {
      "None": 2
    },
    "sklearn.metrics._plot.roc_curve.RocCurveDisplay.plot.name": {
      "None": 2
    },
    "sklearn.metrics._plot.roc_curve.plot_roc_curve.sample_weight": {
      "None": 43
    },
    "sklearn.metrics._plot.roc_curve.plot_roc_curve.response_method": {
      "'auto'": 43
    },
    "sklearn.metrics._plot.roc_curve.plot_roc_curve.pos_label": {
      "None": 43
    },
    "sklearn.metrics._ranking.average_precision_score.pos_label": {
      "1": 154
    },
    "sklearn.metrics._ranking.average_precision_score.sample_weight": {
      "None": 154
    },
    "sklearn.metrics._ranking.coverage_error.y_true": {},
    "sklearn.metrics._ranking.coverage_error.y_score": {},
    "sklearn.metrics._ranking.coverage_error.sample_weight": {},
    "sklearn.metrics._ranking.dcg_score.y_true": {},
    "sklearn.metrics._ranking.dcg_score.y_score": {},
    "sklearn.metrics._ranking.dcg_score.k": {},
    "sklearn.metrics._ranking.dcg_score.log_base": {},
    "sklearn.metrics._ranking.dcg_score.sample_weight": {},
    "sklearn.metrics._ranking.dcg_score.ignore_ties": {},
    "sklearn.metrics._ranking.det_curve.y_true": {},
    "sklearn.metrics._ranking.det_curve.y_score": {},
    "sklearn.metrics._ranking.det_curve.pos_label": {},
    "sklearn.metrics._ranking.det_curve.sample_weight": {},
    "sklearn.metrics._ranking.label_ranking_loss.y_true": {},
    "sklearn.metrics._ranking.label_ranking_loss.y_score": {},
    "sklearn.metrics._ranking.label_ranking_loss.sample_weight": {},
    "sklearn.metrics._ranking.precision_recall_curve.sample_weight": {
      "None": 201
    },
    "sklearn.metrics._ranking.top_k_accuracy_score.y_true": {},
    "sklearn.metrics._ranking.top_k_accuracy_score.y_score": {},
    "sklearn.metrics._ranking.top_k_accuracy_score.k": {},
    "sklearn.metrics._ranking.top_k_accuracy_score.normalize": {},
    "sklearn.metrics._ranking.top_k_accuracy_score.sample_weight": {},
    "sklearn.metrics._ranking.top_k_accuracy_score.labels": {},
    "sklearn.metrics._regression.explained_variance_score.sample_weight": {
      "None": 79
    },
    "sklearn.metrics._regression.mean_absolute_percentage_error.sample_weight": {
      "None": 6
    },
    "sklearn.metrics._regression.mean_absolute_percentage_error.multioutput": {
      "'uniform_average'": 6
    },
    "sklearn.metrics._regression.mean_gamma_deviance.y_true": {},
    "sklearn.metrics._regression.mean_gamma_deviance.y_pred": {},
    "sklearn.metrics._regression.mean_gamma_deviance.sample_weight": {},
    "sklearn.metrics._regression.mean_poisson_deviance.y_true": {},
    "sklearn.metrics._regression.mean_poisson_deviance.y_pred": {},
    "sklearn.metrics._regression.mean_poisson_deviance.sample_weight": {},
    "sklearn.metrics._regression.mean_tweedie_deviance.sample_weight": {
      "None": 2
    },
    "sklearn.metrics._regression.median_absolute_error.multioutput": {
      "'uniform_average'": 26
    },
    "sklearn.metrics._regression.median_absolute_error.sample_weight": {
      "None": 26
    },
    "sklearn.metrics._scorer.check_scoring.estimator": {},
    "sklearn.metrics._scorer.check_scoring.scoring": {},
    "sklearn.metrics._scorer.check_scoring.allow_none": {},
    "sklearn.metrics.cluster._bicluster.consensus_score.a": {},
    "sklearn.metrics.cluster._bicluster.consensus_score.b": {},
    "sklearn.metrics.cluster._bicluster.consensus_score.similarity": {},
    "sklearn.metrics.cluster._supervised.adjusted_mutual_info_score.average_method": {
      "'arithmetic'": 1
    },
    "sklearn.metrics.cluster._supervised.contingency_matrix.labels_true": {},
    "sklearn.metrics.cluster._supervised.contingency_matrix.labels_pred": {},
    "sklearn.metrics.cluster._supervised.contingency_matrix.eps": {},
    "sklearn.metrics.cluster._supervised.contingency_matrix.sparse": {},
    "sklearn.metrics.cluster._supervised.contingency_matrix.dtype": {},
    "sklearn.metrics.cluster._supervised.entropy.labels": {},
    "sklearn.metrics.cluster._supervised.fowlkes_mallows_score.labels_true": {},
    "sklearn.metrics.cluster._supervised.fowlkes_mallows_score.labels_pred": {},
    "sklearn.metrics.cluster._supervised.fowlkes_mallows_score.sparse": {},
    "sklearn.metrics.cluster._supervised.homogeneity_completeness_v_measure.labels_true": {},
    "sklearn.metrics.cluster._supervised.homogeneity_completeness_v_measure.labels_pred": {},
    "sklearn.metrics.cluster._supervised.homogeneity_completeness_v_measure.beta": {},
    "sklearn.metrics.cluster._supervised.normalized_mutual_info_score.average_method": {
      "'arithmetic'": 2
    },
    "sklearn.metrics.cluster._supervised.pair_confusion_matrix.labels_true": {},
    "sklearn.metrics.cluster._supervised.pair_confusion_matrix.labels_pred": {},
    "sklearn.metrics.cluster._supervised.rand_score.labels_true": {},
    "sklearn.metrics.cluster._supervised.rand_score.labels_pred": {},
    "sklearn.metrics.cluster._supervised.v_measure_score.beta": {
      "1.0": 2
    },
    "sklearn.metrics.cluster._unsupervised.calinski_harabasz_score.X": {},
    "sklearn.metrics.cluster._unsupervised.calinski_harabasz_score.labels": {},
    "sklearn.metrics.cluster._unsupervised.silhouette_samples.metric": {
      "'euclidean'": 3
    },
    "sklearn.metrics.cluster.setup.configuration.parent_package": {},
    "sklearn.metrics.cluster.setup.configuration.top_path": {},
    "sklearn.metrics.pairwise.additive_chi2_kernel.X": {},
    "sklearn.metrics.pairwise.additive_chi2_kernel.Y": {},
    "sklearn.metrics.pairwise.check_paired_arrays.X": {},
    "sklearn.metrics.pairwise.check_paired_arrays.Y": {},
    "sklearn.metrics.pairwise.check_pairwise_arrays.X": {},
    "sklearn.metrics.pairwise.check_pairwise_arrays.Y": {},
    "sklearn.metrics.pairwise.check_pairwise_arrays.precomputed": {},
    "sklearn.metrics.pairwise.check_pairwise_arrays.dtype": {},
    "sklearn.metrics.pairwise.check_pairwise_arrays.accept_sparse": {},
    "sklearn.metrics.pairwise.check_pairwise_arrays.force_all_finite": {},
    "sklearn.metrics.pairwise.check_pairwise_arrays.copy": {},
    "sklearn.metrics.pairwise.chi2_kernel.X": {},
    "sklearn.metrics.pairwise.chi2_kernel.Y": {},
    "sklearn.metrics.pairwise.chi2_kernel.gamma": {},
    "sklearn.metrics.pairwise.cosine_distances.Y": {
      "None": 1
    },
    "sklearn.metrics.pairwise.cosine_similarity.dense_output": {
      "True": 134
    },
    "sklearn.metrics.pairwise.euclidean_distances.Y_norm_squared": {
      "None": 32
    },
    "sklearn.metrics.pairwise.euclidean_distances.squared": {
      "False": 32
    },
    "sklearn.metrics.pairwise.euclidean_distances.X_norm_squared": {
      "None": 32
    },
    "sklearn.metrics.pairwise.haversine_distances.X": {},
    "sklearn.metrics.pairwise.haversine_distances.Y": {},
    "sklearn.metrics.pairwise.laplacian_kernel.X": {},
    "sklearn.metrics.pairwise.laplacian_kernel.Y": {},
    "sklearn.metrics.pairwise.laplacian_kernel.gamma": {},
    "sklearn.metrics.pairwise.linear_kernel.dense_output": {
      "True": 35
    },
    "sklearn.metrics.pairwise.manhattan_distances.sum_over_features": {
      "True": 8
    },
    "sklearn.metrics.pairwise.nan_euclidean_distances.X": {},
    "sklearn.metrics.pairwise.nan_euclidean_distances.Y": {},
    "sklearn.metrics.pairwise.nan_euclidean_distances.squared": {},
    "sklearn.metrics.pairwise.nan_euclidean_distances.missing_values": {},
    "sklearn.metrics.pairwise.nan_euclidean_distances.copy": {},
    "sklearn.metrics.pairwise.paired_cosine_distances.X": {},
    "sklearn.metrics.pairwise.paired_cosine_distances.Y": {},
    "sklearn.metrics.pairwise.paired_distances.metric": {
      "'euclidean'": 5
    },
    "sklearn.metrics.pairwise.paired_manhattan_distances.X": {},
    "sklearn.metrics.pairwise.paired_manhattan_distances.Y": {},
    "sklearn.metrics.pairwise.pairwise_distances.force_all_finite": {
      "True": 21
    },
    "sklearn.metrics.pairwise.pairwise_distances_argmin.axis": {
      "1": 3
    },
    "sklearn.metrics.pairwise.pairwise_distances_argmin.metric": {
      "'euclidean'": 3
    },
    "sklearn.metrics.pairwise.pairwise_distances_argmin.metric_kwargs": {
      "None": 3
    },
    "sklearn.metrics.pairwise.pairwise_distances_argmin_min.axis": {
      "1": 1
    },
    "sklearn.metrics.pairwise.pairwise_distances_argmin_min.metric": {
      "'euclidean'": 1
    },
    "sklearn.metrics.pairwise.pairwise_distances_argmin_min.metric_kwargs": {
      "None": 1
    },
    "sklearn.metrics.pairwise.pairwise_distances_chunked.Y": {
      "None": 1
    },
    "sklearn.metrics.pairwise.pairwise_distances_chunked.working_memory": {
      "None": 1
    },
    "sklearn.metrics.pairwise.pairwise_kernels.Y": {
      "None": 1
    },
    "sklearn.metrics.pairwise.pairwise_kernels.n_jobs": {
      "None": 1
    },
    "sklearn.metrics.pairwise.polynomial_kernel.degree": {
      "3": 2
    },
    "sklearn.metrics.pairwise.polynomial_kernel.gamma": {
      "None": 2
    },
    "sklearn.metrics.pairwise.polynomial_kernel.coef0": {
      "1": 2
    },
    "sklearn.metrics.pairwise.rbf_kernel.gamma": {
      "None": 2
    },
    "sklearn.metrics.pairwise.sigmoid_kernel.gamma": {
      "None": 1
    },
    "sklearn.metrics.pairwise.sigmoid_kernel.coef0": {
      "1": 1
    },
    "sklearn.metrics.setup.configuration.parent_package": {},
    "sklearn.metrics.setup.configuration.top_path": {},
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.tol": {
      "0.001": 25
    },
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.reg_covar": {
      "1e-06": 25
    },
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.init_params": {
      "'kmeans'": 25
    },
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.mean_precision_prior": {
      "None": 25
    },
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.mean_prior": {
      "None": 25
    },
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.degrees_of_freedom_prior": {
      "None": 25
    },
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.covariance_prior": {
      "None": 25
    },
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.warm_start": {
      "False": 25
    },
    "sklearn.mixture._bayesian_mixture.BayesianGaussianMixture.__init__.verbose_interval": {
      "10": 25
    },
    "sklearn.model_selection._search.ParameterGrid.__getitem__.ind": {},
    "sklearn.model_selection._search.ParameterSampler.__init__.param_distributions": {},
    "sklearn.model_selection._search.ParameterSampler.__init__.n_iter": {},
    "sklearn.model_selection._search.ParameterSampler.__init__.random_state": {},
    "sklearn.model_selection._search.fit_grid_point.X": {},
    "sklearn.model_selection._search.fit_grid_point.y": {},
    "sklearn.model_selection._search.fit_grid_point.estimator": {},
    "sklearn.model_selection._search.fit_grid_point.parameters": {},
    "sklearn.model_selection._search.fit_grid_point.train": {},
    "sklearn.model_selection._search.fit_grid_point.test": {},
    "sklearn.model_selection._search.fit_grid_point.scorer": {},
    "sklearn.model_selection._search.fit_grid_point.verbose": {},
    "sklearn.model_selection._search.fit_grid_point.error_score": {},
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.estimator": {},
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.param_grid": {},
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.factor": {},
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.resource": {},
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.max_resources": {},
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.min_resources": {},
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.aggressive_elimination": {},
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.cv": {},
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.scoring": {},
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.refit": {},
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.error_score": {},
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.return_train_score": {},
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.random_state": {},
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.n_jobs": {},
    "sklearn.model_selection._search_successive_halving.HalvingGridSearchCV.__init__.verbose": {},
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.n_candidates": {
      "'exhaust'": 2
    },
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.factor": {
      "3": 2
    },
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.min_resources": {
      "'smallest'": 2
    },
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.aggressive_elimination": {
      "False": 2
    },
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.refit": {
      "True": 2
    },
    "sklearn.model_selection._search_successive_halving.HalvingRandomSearchCV.__init__.error_score": {
      "np.nan": 2
    },
    "sklearn.model_selection._split.BaseCrossValidator.get_n_splits.X": {},
    "sklearn.model_selection._split.BaseCrossValidator.get_n_splits.y": {},
    "sklearn.model_selection._split.BaseCrossValidator.get_n_splits.groups": {},
    "sklearn.model_selection._split.BaseCrossValidator.split.y": {
      "None": 2
    },
    "sklearn.model_selection._split.BaseCrossValidator.split.groups": {
      "None": 2
    },
    "sklearn.model_selection._split.LeaveOneOut.get_n_splits.y": {
      "None": 1
    },
    "sklearn.model_selection._split.LeaveOneOut.get_n_splits.groups": {
      "None": 1
    },
    "sklearn.model_selection._split.LeavePGroupsOut.__init__.n_groups": {},
    "sklearn.model_selection._split.LeavePGroupsOut.get_n_splits.X": {},
    "sklearn.model_selection._split.LeavePGroupsOut.get_n_splits.y": {},
    "sklearn.model_selection._split.LeavePGroupsOut.get_n_splits.groups": {},
    "sklearn.model_selection._split.LeavePGroupsOut.split.X": {},
    "sklearn.model_selection._split.LeavePGroupsOut.split.y": {},
    "sklearn.model_selection._split.LeavePGroupsOut.split.groups": {},
    "sklearn.model_selection._split.LeavePOut.__init__.p": {},
    "sklearn.model_selection._split.LeavePOut.get_n_splits.X": {},
    "sklearn.model_selection._split.LeavePOut.get_n_splits.y": {},
    "sklearn.model_selection._split.LeavePOut.get_n_splits.groups": {},
    "sklearn.model_selection._split.PredefinedSplit.get_n_splits.X": {
      "None": 1
    },
    "sklearn.model_selection._split.PredefinedSplit.get_n_splits.y": {
      "None": 1
    },
    "sklearn.model_selection._split.PredefinedSplit.get_n_splits.groups": {
      "None": 1
    },
    "sklearn.model_selection._split.PredefinedSplit.split.X": {
      "None": 1
    },
    "sklearn.model_selection._split.PredefinedSplit.split.y": {
      "None": 1
    },
    "sklearn.model_selection._split.PredefinedSplit.split.groups": {
      "None": 1
    },
    "sklearn.model_selection._validation.cross_val_predict.pre_dispatch": {
      "'2*n_jobs'": 214
    },
    "sklearn.model_selection._validation.cross_val_score.pre_dispatch": {
      "'2*n_jobs'": 3801
    },
    "sklearn.model_selection._validation.cross_validate.pre_dispatch": {
      "'2*n_jobs'": 299
    },
    "sklearn.model_selection._validation.cross_validate.error_score": {
      "np.nan": 299
    },
    "sklearn.model_selection._validation.learning_curve.groups": {
      "None": 129
    },
    "sklearn.model_selection._validation.learning_curve.exploit_incremental_learning": {
      "False": 129
    },
    "sklearn.model_selection._validation.learning_curve.pre_dispatch": {
      "'all'": 129
    },
    "sklearn.model_selection._validation.learning_curve.error_score": {
      "np.nan": 129
    },
    "sklearn.model_selection._validation.permutation_test_score.estimator": {},
    "sklearn.model_selection._validation.permutation_test_score.X": {},
    "sklearn.model_selection._validation.permutation_test_score.y": {},
    "sklearn.model_selection._validation.permutation_test_score.groups": {},
    "sklearn.model_selection._validation.permutation_test_score.cv": {},
    "sklearn.model_selection._validation.permutation_test_score.n_permutations": {},
    "sklearn.model_selection._validation.permutation_test_score.n_jobs": {},
    "sklearn.model_selection._validation.permutation_test_score.random_state": {},
    "sklearn.model_selection._validation.permutation_test_score.verbose": {},
    "sklearn.model_selection._validation.permutation_test_score.scoring": {},
    "sklearn.model_selection._validation.permutation_test_score.fit_params": {},
    "sklearn.model_selection._validation.validation_curve.groups": {
      "None": 32
    },
    "sklearn.model_selection._validation.validation_curve.pre_dispatch": {
      "'all'": 32
    },
    "sklearn.model_selection._validation.validation_curve.error_score": {
      "np.nan": 32
    },
    "sklearn.model_selection._validation.validation_curve.fit_params": {
      "None": 32
    },
    "sklearn.multiclass.OneVsOneClassifier.__init__.n_jobs": {
      "None": 13
    },
    "sklearn.multiclass.OneVsOneClassifier.partial_fit.X": {},
    "sklearn.multiclass.OneVsOneClassifier.partial_fit.y": {},
    "sklearn.multiclass.OneVsOneClassifier.partial_fit.classes": {},
    "sklearn.multiclass.OneVsRestClassifier.partial_fit.X": {},
    "sklearn.multiclass.OneVsRestClassifier.partial_fit.y": {},
    "sklearn.multiclass.OneVsRestClassifier.partial_fit.classes": {},
    "sklearn.multiclass.OutputCodeClassifier.__init__.estimator": {},
    "sklearn.multiclass.OutputCodeClassifier.__init__.code_size": {},
    "sklearn.multiclass.OutputCodeClassifier.__init__.random_state": {},
    "sklearn.multiclass.OutputCodeClassifier.__init__.n_jobs": {},
    "sklearn.multiclass.OutputCodeClassifier.fit.X": {},
    "sklearn.multiclass.OutputCodeClassifier.fit.y": {},
    "sklearn.multiclass.OutputCodeClassifier.predict.X": {},
    "sklearn.multioutput.ClassifierChain.decision_function.X": {},
    "sklearn.multioutput.ClassifierChain.fit.X": {},
    "sklearn.multioutput.ClassifierChain.fit.Y": {},
    "sklearn.multioutput.ClassifierChain.predict_proba.X": {},
    "sklearn.multioutput.MultiOutputClassifier.fit.sample_weight": {
      "None": 31
    },
    "sklearn.multioutput.MultiOutputRegressor.partial_fit.X": {},
    "sklearn.multioutput.MultiOutputRegressor.partial_fit.y": {},
    "sklearn.multioutput.MultiOutputRegressor.partial_fit.sample_weight": {},
    "sklearn.naive_bayes.CategoricalNB.__init__.fit_prior": {
      "True": 6
    },
    "sklearn.naive_bayes.CategoricalNB.__init__.class_prior": {
      "None": 6
    },
    "sklearn.naive_bayes.CategoricalNB.__init__.min_categories": {
      "None": 6
    },
    "sklearn.naive_bayes.CategoricalNB.fit.sample_weight": {
      "None": 5
    },
    "sklearn.naive_bayes.CategoricalNB.partial_fit.X": {},
    "sklearn.naive_bayes.CategoricalNB.partial_fit.y": {},
    "sklearn.naive_bayes.CategoricalNB.partial_fit.classes": {},
    "sklearn.naive_bayes.CategoricalNB.partial_fit.sample_weight": {},
    "sklearn.naive_bayes.ComplementNB.__init__.fit_prior": {
      "True": 8
    },
    "sklearn.naive_bayes.ComplementNB.__init__.class_prior": {
      "None": 8
    },
    "sklearn.naive_bayes.ComplementNB.__init__.norm": {
      "False": 8
    },
    "sklearn.naive_bayes.GaussianNB.partial_fit.sample_weight": {
      "None": 2
    },
    "sklearn.neighbors._classification.RadiusNeighborsClassifier.predict_proba.X": {},
    "sklearn.neighbors._graph.KNeighborsTransformer.__init__.mode": {},
    "sklearn.neighbors._graph.KNeighborsTransformer.__init__.n_neighbors": {},
    "sklearn.neighbors._graph.KNeighborsTransformer.__init__.algorithm": {},
    "sklearn.neighbors._graph.KNeighborsTransformer.__init__.leaf_size": {},
    "sklearn.neighbors._graph.KNeighborsTransformer.__init__.metric": {},
    "sklearn.neighbors._graph.KNeighborsTransformer.__init__.p": {},
    "sklearn.neighbors._graph.KNeighborsTransformer.__init__.metric_params": {},
    "sklearn.neighbors._graph.KNeighborsTransformer.__init__.n_jobs": {},
    "sklearn.neighbors._graph.KNeighborsTransformer.fit.X": {},
    "sklearn.neighbors._graph.KNeighborsTransformer.fit.y": {},
    "sklearn.neighbors._graph.KNeighborsTransformer.fit_transform.X": {},
    "sklearn.neighbors._graph.KNeighborsTransformer.fit_transform.y": {},
    "sklearn.neighbors._graph.KNeighborsTransformer.transform.X": {},
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.__init__.mode": {},
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.__init__.radius": {},
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.__init__.algorithm": {},
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.__init__.leaf_size": {},
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.__init__.metric": {},
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.__init__.p": {},
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.__init__.metric_params": {},
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.__init__.n_jobs": {},
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.fit.X": {},
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.fit.y": {},
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.fit_transform.X": {},
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.fit_transform.y": {},
    "sklearn.neighbors._graph.RadiusNeighborsTransformer.transform.X": {},
    "sklearn.neighbors._graph.kneighbors_graph.mode": {
      "'connectivity'": 2
    },
    "sklearn.neighbors._graph.kneighbors_graph.metric": {
      "'minkowski'": 2
    },
    "sklearn.neighbors._graph.kneighbors_graph.p": {
      "2": 2
    },
    "sklearn.neighbors._graph.kneighbors_graph.metric_params": {
      "None": 2
    },
    "sklearn.neighbors._graph.kneighbors_graph.include_self": {
      "False": 2
    },
    "sklearn.neighbors._graph.kneighbors_graph.n_jobs": {
      "None": 2
    },
    "sklearn.neighbors._graph.radius_neighbors_graph.X": {},
    "sklearn.neighbors._graph.radius_neighbors_graph.radius": {},
    "sklearn.neighbors._graph.radius_neighbors_graph.mode": {},
    "sklearn.neighbors._graph.radius_neighbors_graph.metric": {},
    "sklearn.neighbors._graph.radius_neighbors_graph.p": {},
    "sklearn.neighbors._graph.radius_neighbors_graph.metric_params": {},
    "sklearn.neighbors._graph.radius_neighbors_graph.include_self": {},
    "sklearn.neighbors._graph.radius_neighbors_graph.n_jobs": {},
    "sklearn.neighbors._kde.KernelDensity.__init__.algorithm": {
      "'auto'": 50
    },
    "sklearn.neighbors._kde.KernelDensity.__init__.atol": {
      "0": 50
    },
    "sklearn.neighbors._kde.KernelDensity.__init__.rtol": {
      "0": 50
    },
    "sklearn.neighbors._kde.KernelDensity.__init__.breadth_first": {
      "True": 50
    },
    "sklearn.neighbors._kde.KernelDensity.__init__.leaf_size": {
      "40": 50
    },
    "sklearn.neighbors._kde.KernelDensity.__init__.metric_params": {
      "None": 50
    },
    "sklearn.neighbors._kde.KernelDensity.fit.y": {
      "None": 47
    },
    "sklearn.neighbors._kde.KernelDensity.fit.sample_weight": {
      "None": 47
    },
    "sklearn.neighbors._kde.KernelDensity.score.X": {},
    "sklearn.neighbors._kde.KernelDensity.score.y": {},
    "sklearn.neighbors._lof.LocalOutlierFactor.__init__.algorithm": {
      "'auto'": 17
    },
    "sklearn.neighbors._lof.LocalOutlierFactor.__init__.leaf_size": {
      "30": 17
    },
    "sklearn.neighbors._lof.LocalOutlierFactor.__init__.metric_params": {
      "None": 17
    },
    "sklearn.neighbors._lof.LocalOutlierFactor.__init__.novelty": {
      "False": 17
    },
    "sklearn.neighbors._lof.LocalOutlierFactor.fit.y": {
      "None": 4
    },
    "sklearn.neighbors._nca.NeighborhoodComponentsAnalysis.__init__.n_components": {
      "None": 1
    },
    "sklearn.neighbors._nca.NeighborhoodComponentsAnalysis.__init__.init": {
      "'auto'": 1
    },
    "sklearn.neighbors._nca.NeighborhoodComponentsAnalysis.__init__.warm_start": {
      "False": 1
    },
    "sklearn.neighbors._nca.NeighborhoodComponentsAnalysis.__init__.max_iter": {
      "50": 1
    },
    "sklearn.neighbors._nca.NeighborhoodComponentsAnalysis.__init__.tol": {
      "1e-05": 1
    },
    "sklearn.neighbors._nca.NeighborhoodComponentsAnalysis.__init__.callback": {
      "None": 1
    },
    "sklearn.neighbors._nca.NeighborhoodComponentsAnalysis.__init__.verbose": {
      "0": 1
    },
    "sklearn.neighbors._nca.NeighborhoodComponentsAnalysis.fit.X": {},
    "sklearn.neighbors._nca.NeighborhoodComponentsAnalysis.fit.y": {},
    "sklearn.neighbors._nca.NeighborhoodComponentsAnalysis.transform.X": {},
    "sklearn.neighbors._nearest_centroid.NearestCentroid.__init__.metric": {
      "'euclidean'": 4
    },
    "sklearn.neighbors._nearest_centroid.NearestCentroid.__init__.shrink_threshold": {
      "None": 4
    },
    "sklearn.neighbors._regression.RadiusNeighborsRegressor.__init__.algorithm": {
      "'auto'": 3
    },
    "sklearn.neighbors._regression.RadiusNeighborsRegressor.__init__.leaf_size": {
      "30": 3
    },
    "sklearn.neighbors._regression.RadiusNeighborsRegressor.__init__.metric_params": {
      "None": 3
    },
    "sklearn.neighbors._regression.RadiusNeighborsRegressor.__init__.n_jobs": {
      "None": 3
    },
    "sklearn.neighbors._unsupervised.NearestNeighbors.__init__.leaf_size": {
      "30": 110
    },
    "sklearn.neighbors._unsupervised.NearestNeighbors.__init__.p": {
      "2": 110
    },
    "sklearn.neighbors._unsupervised.NearestNeighbors.__init__.metric_params": {
      "None": 110
    },
    "sklearn.neighbors.setup.configuration.parent_package": {},
    "sklearn.neighbors.setup.configuration.top_path": {},
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.__init__.max_fun": {
      "15000": 428
    },
    "sklearn.neural_network._multilayer_perceptron.MLPClassifier.predict_log_proba.X": {},
    "sklearn.neural_network._rbm.BernoulliRBM.__init__.learning_rate": {
      "0.1": 2
    },
    "sklearn.neural_network._rbm.BernoulliRBM.__init__.batch_size": {
      "10": 2
    },
    "sklearn.neural_network._rbm.BernoulliRBM.__init__.n_iter": {
      "10": 2
    },
    "sklearn.neural_network._rbm.BernoulliRBM.__init__.verbose": {
      "0": 2
    },
    "sklearn.neural_network._rbm.BernoulliRBM.fit.y": {
      "None": 1
    },
    "sklearn.neural_network._rbm.BernoulliRBM.gibbs.v": {},
    "sklearn.neural_network._rbm.BernoulliRBM.partial_fit.X": {},
    "sklearn.neural_network._rbm.BernoulliRBM.partial_fit.y": {},
    "sklearn.neural_network._rbm.BernoulliRBM.transform.X": {},
    "sklearn.pipeline.FeatureUnion.get_params.deep": {},
    "sklearn.pipeline.Pipeline.__getitem__.ind": {},
    "sklearn.pipeline.Pipeline.fit_predict.X": {},
    "sklearn.pipeline.Pipeline.fit_predict.y": {},
    "sklearn.pipeline.Pipeline.get_params.deep": {
      "True": 34
    },
    "sklearn.pipeline.Pipeline.predict_log_proba.X": {},
    "sklearn.pipeline.Pipeline.score.sample_weight": {
      "None": 236
    },
    "sklearn.pipeline.Pipeline.score_samples.X": {},
    "sklearn.pipeline.make_pipeline.memory": {
      "None": 1097
    },
    "sklearn.pipeline.make_union.verbose": {
      "False": 54
    },
    "sklearn.preprocessing._data.Binarizer.__init__.copy": {
      "True": 81
    },
    "sklearn.preprocessing._data.Binarizer.fit.y": {
      "None": 27
    },
    "sklearn.preprocessing._data.Binarizer.transform.copy": {
      "None": 33
    },
    "sklearn.preprocessing._data.KernelCenterer.fit.K": {},
    "sklearn.preprocessing._data.KernelCenterer.fit.y": {},
    "sklearn.preprocessing._data.KernelCenterer.transform.copy": {
      "True": 1
    },
    "sklearn.preprocessing._data.MaxAbsScaler.fit.y": {
      "None": 9
    },
    "sklearn.preprocessing._data.MaxAbsScaler.partial_fit.X": {},
    "sklearn.preprocessing._data.MaxAbsScaler.partial_fit.y": {},
    "sklearn.preprocessing._data.MinMaxScaler.__init__.clip": {
      "False": 2297
    },
    "sklearn.preprocessing._data.MinMaxScaler.partial_fit.y": {
      "None": 1
    },
    "sklearn.preprocessing._data.Normalizer.fit.y": {
      "None": 48
    },
    "sklearn.preprocessing._data.Normalizer.transform.copy": {
      "None": 114
    },
    "sklearn.preprocessing._data.PolynomialFeatures.__init__.order": {
      "'C'": 562
    },
    "sklearn.preprocessing._data.PowerTransformer.fit.y": {
      "None": 7
    },
    "sklearn.preprocessing._data.PowerTransformer.fit_transform.y": {
      "None": 40
    },
    "sklearn.preprocessing._data.QuantileTransformer.__init__.ignore_implicit_zeros": {
      "False": 368
    },
    "sklearn.preprocessing._data.QuantileTransformer.__init__.subsample": {
      "int(100000.0)": 368
    },
    "sklearn.preprocessing._data.QuantileTransformer.fit.y": {
      "None": 200
    },
    "sklearn.preprocessing._data.RobustScaler.fit.y": {
      "None": 48
    },
    "sklearn.preprocessing._data.StandardScaler.fit.sample_weight": {
      "None": 1837
    },
    "sklearn.preprocessing._data.StandardScaler.inverse_transform.copy": {
      "None": 241
    },
    "sklearn.preprocessing._data.StandardScaler.partial_fit.y": {
      "None": 2
    },
    "sklearn.preprocessing._data.StandardScaler.partial_fit.sample_weight": {
      "None": 2
    },
    "sklearn.preprocessing._data.StandardScaler.transform.copy": {
      "None": 4369
    },
    "sklearn.preprocessing._data.add_dummy_feature.X": {},
    "sklearn.preprocessing._data.add_dummy_feature.value": {},
    "sklearn.preprocessing._data.binarize.copy": {
      "True": 12
    },
    "sklearn.preprocessing._data.maxabs_scale.axis": {
      "0": 8
    },
    "sklearn.preprocessing._data.maxabs_scale.copy": {
      "True": 8
    },
    "sklearn.preprocessing._data.power_transform.standardize": {
      "True": 2
    },
    "sklearn.preprocessing._data.power_transform.copy": {
      "True": 2
    },
    "sklearn.preprocessing._data.quantile_transform.axis": {
      "0": 8
    },
    "sklearn.preprocessing._data.quantile_transform.ignore_implicit_zeros": {
      "False": 8
    },
    "sklearn.preprocessing._data.quantile_transform.subsample": {
      "int(100000.0)": 8
    },
    "sklearn.preprocessing._data.robust_scale.with_centering": {
      "True": 2
    },
    "sklearn.preprocessing._data.robust_scale.with_scaling": {
      "True": 2
    },
    "sklearn.preprocessing._data.robust_scale.copy": {
      "True": 2
    },
    "sklearn.preprocessing._data.robust_scale.unit_variance": {
      "False": 2
    },
    "sklearn.preprocessing._discretization.KBinsDiscretizer.__init__.dtype": {
      "None": 56
    },
    "sklearn.preprocessing._discretization.KBinsDiscretizer.fit.y": {
      "None": 12
    },
    "sklearn.preprocessing._discretization.KBinsDiscretizer.inverse_transform.Xt": {},
    "sklearn.preprocessing._encoders.OneHotEncoder.fit.y": {
      "None": 362
    },
    "sklearn.preprocessing._encoders.OrdinalEncoder.fit.y": {
      "None": 39
    },
    "sklearn.preprocessing._function_transformer.FunctionTransformer.__init__.inv_kw_args": {
      "None": 456
    },
    "sklearn.preprocessing._function_transformer.FunctionTransformer.fit.X": {},
    "sklearn.preprocessing._function_transformer.FunctionTransformer.fit.y": {},
    "sklearn.preprocessing._function_transformer.FunctionTransformer.inverse_transform.X": {},
    "sklearn.preprocessing._label.LabelBinarizer.__init__.neg_label": {
      "0": 490
    },
    "sklearn.preprocessing._label.LabelBinarizer.__init__.pos_label": {
      "1": 490
    },
    "sklearn.preprocessing._label.label_binarize.neg_label": {
      "0": 36
    },
    "sklearn.preprocessing._label.label_binarize.pos_label": {
      "1": 36
    },
    "sklearn.preprocessing._label.label_binarize.sparse_output": {
      "False": 36
    },
    "sklearn.preprocessing.setup.configuration.parent_package": {},
    "sklearn.preprocessing.setup.configuration.top_path": {},
    "sklearn.random_projection.BaseRandomProjection.__init__.n_components": {},
    "sklearn.random_projection.BaseRandomProjection.__init__.eps": {},
    "sklearn.random_projection.BaseRandomProjection.__init__.dense_output": {},
    "sklearn.random_projection.BaseRandomProjection.__init__.random_state": {},
    "sklearn.random_projection.BaseRandomProjection.fit.y": {
      "None": 3
    },
    "sklearn.random_projection.SparseRandomProjection.__init__.density": {
      "'auto'": 103
    },
    "sklearn.random_projection.johnson_lindenstrauss_min_dim.n_samples": {},
    "sklearn.random_projection.johnson_lindenstrauss_min_dim.eps": {},
    "sklearn.semi_supervised._label_propagation.LabelPropagation.__init__.kernel": {
      "'rbf'": 2
    },
    "sklearn.semi_supervised._label_propagation.LabelPropagation.__init__.gamma": {
      "20": 2
    },
    "sklearn.semi_supervised._label_propagation.LabelPropagation.__init__.tol": {
      "0.001": 2
    },
    "sklearn.semi_supervised._label_propagation.LabelPropagation.__init__.n_jobs": {
      "None": 2
    },
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.__init__.base_estimator": {},
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.__init__.threshold": {},
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.__init__.criterion": {},
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.__init__.k_best": {},
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.__init__.max_iter": {},
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.__init__.verbose": {},
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.decision_function.X": {},
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.fit.X": {},
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.fit.y": {},
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.predict.X": {},
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.predict_log_proba.X": {},
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.predict_proba.X": {},
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.score.X": {},
    "sklearn.semi_supervised._self_training.SelfTrainingClassifier.score.y": {},
    "sklearn.setup.configuration.parent_package": {},
    "sklearn.setup.configuration.top_path": {},
    "sklearn.setup_module.module": {},
    "sklearn.svm._bounds.l1_min_c.X": {},
    "sklearn.svm._bounds.l1_min_c.y": {},
    "sklearn.svm._bounds.l1_min_c.loss": {},
    "sklearn.svm._bounds.l1_min_c.fit_intercept": {},
    "sklearn.svm._bounds.l1_min_c.intercept_scaling": {},
    "sklearn.svm._classes.LinearSVC.fit.sample_weight": {
      "None": 216
    },
    "sklearn.svm._classes.LinearSVR.fit.sample_weight": {
      "None": 28
    },
    "sklearn.svm._classes.NuSVC.__init__.shrinking": {
      "True": 108
    },
    "sklearn.svm._classes.NuSVC.__init__.class_weight": {
      "None": 108
    },
    "sklearn.svm._classes.NuSVC.__init__.verbose": {
      "False": 108
    },
    "sklearn.svm._classes.NuSVC.__init__.decision_function_shape": {
      "'ovr'": 108
    },
    "sklearn.svm._classes.NuSVC.__init__.break_ties": {
      "False": 108
    },
    "sklearn.svm._classes.NuSVR.__init__.coef0": {
      "0.0": 56
    },
    "sklearn.svm._classes.NuSVR.__init__.cache_size": {
      "200": 56
    },
    "sklearn.svm._classes.OneClassSVM.__init__.degree": {
      "3": 8
    },
    "sklearn.svm._classes.OneClassSVM.__init__.coef0": {
      "0.0": 8
    },
    "sklearn.svm._classes.OneClassSVM.__init__.tol": {
      "0.001": 8
    },
    "sklearn.svm._classes.OneClassSVM.__init__.shrinking": {
      "True": 8
    },
    "sklearn.svm._classes.OneClassSVM.__init__.cache_size": {
      "200": 8
    },
    "sklearn.svm._classes.OneClassSVM.__init__.verbose": {
      "False": 8
    },
    "sklearn.svm._classes.OneClassSVM.__init__.max_iter": {
      "-1": 8
    },
    "sklearn.svm._classes.OneClassSVM.fit.y": {
      "None": 6
    },
    "sklearn.svm._classes.OneClassSVM.fit.sample_weight": {
      "None": 6
    },
    "sklearn.svm._classes.OneClassSVM.score_samples.X": {},
    "sklearn.svm.setup.configuration.parent_package": {},
    "sklearn.svm.setup.configuration.top_path": {},
    "sklearn.tree._classes.BaseDecisionTree.__init__.criterion": {},
    "sklearn.tree._classes.BaseDecisionTree.__init__.splitter": {},
    "sklearn.tree._classes.BaseDecisionTree.__init__.max_depth": {},
    "sklearn.tree._classes.BaseDecisionTree.__init__.min_samples_split": {},
    "sklearn.tree._classes.BaseDecisionTree.__init__.min_samples_leaf": {},
    "sklearn.tree._classes.BaseDecisionTree.__init__.min_weight_fraction_leaf": {},
    "sklearn.tree._classes.BaseDecisionTree.__init__.max_features": {},
    "sklearn.tree._classes.BaseDecisionTree.__init__.max_leaf_nodes": {},
    "sklearn.tree._classes.BaseDecisionTree.__init__.random_state": {},
    "sklearn.tree._classes.BaseDecisionTree.__init__.min_impurity_decrease": {},
    "sklearn.tree._classes.BaseDecisionTree.__init__.min_impurity_split": {},
    "sklearn.tree._classes.BaseDecisionTree.__init__.class_weight": {},
    "sklearn.tree._classes.BaseDecisionTree.__init__.ccp_alpha": {},
    "sklearn.tree._classes.BaseDecisionTree.apply.check_input": {
      "True": 2
    },
    "sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path.sample_weight": {
      "None": 5
    },
    "sklearn.tree._classes.BaseDecisionTree.decision_path.X": {},
    "sklearn.tree._classes.BaseDecisionTree.decision_path.check_input": {},
    "sklearn.tree._classes.BaseDecisionTree.fit.X": {},
    "sklearn.tree._classes.BaseDecisionTree.fit.y": {},
    "sklearn.tree._classes.BaseDecisionTree.fit.sample_weight": {},
    "sklearn.tree._classes.BaseDecisionTree.fit.check_input": {},
    "sklearn.tree._classes.BaseDecisionTree.fit.X_idx_sorted": {},
    "sklearn.tree._classes.BaseDecisionTree.predict.check_input": {
      "True": 1547
    },
    "sklearn.tree._classes.DecisionTreeClassifier.fit.check_input": {
      "True": 922
    },
    "sklearn.tree._classes.DecisionTreeClassifier.fit.X_idx_sorted": {
      "'deprecated'": 922
    },
    "sklearn.tree._classes.DecisionTreeClassifier.predict_log_proba.X": {},
    "sklearn.tree._classes.DecisionTreeClassifier.predict_proba.check_input": {
      "True": 144
    },
    "sklearn.tree._classes.DecisionTreeRegressor.fit.sample_weight": {
      "None": 572
    },
    "sklearn.tree._classes.DecisionTreeRegressor.fit.check_input": {
      "True": 572
    },
    "sklearn.tree._classes.DecisionTreeRegressor.fit.X_idx_sorted": {
      "'deprecated'": 572
    },
    "sklearn.tree._classes.ExtraTreeClassifier.__init__.splitter": {
      "'random'": 32
    },
    "sklearn.tree._classes.ExtraTreeClassifier.__init__.min_samples_leaf": {
      "1": 32
    },
    "sklearn.tree._classes.ExtraTreeClassifier.__init__.min_weight_fraction_leaf": {
      "0.0": 32
    },
    "sklearn.tree._classes.ExtraTreeClassifier.__init__.max_leaf_nodes": {
      "None": 32
    },
    "sklearn.tree._classes.ExtraTreeClassifier.__init__.min_impurity_decrease": {
      "0.0": 32
    },
    "sklearn.tree._classes.ExtraTreeClassifier.__init__.min_impurity_split": {
      "None": 32
    },
    "sklearn.tree._classes.ExtraTreeClassifier.__init__.class_weight": {
      "None": 32
    },
    "sklearn.tree._classes.ExtraTreeClassifier.__init__.ccp_alpha": {
      "0.0": 32
    },
    "sklearn.tree._classes.ExtraTreeRegressor.__init__.max_depth": {
      "None": 5
    },
    "sklearn.tree._classes.ExtraTreeRegressor.__init__.min_samples_split": {
      "2": 5
    },
    "sklearn.tree._classes.ExtraTreeRegressor.__init__.min_samples_leaf": {
      "1": 5
    },
    "sklearn.tree._classes.ExtraTreeRegressor.__init__.min_weight_fraction_leaf": {
      "0.0": 5
    },
    "sklearn.tree._classes.ExtraTreeRegressor.__init__.max_features": {
      "'auto'": 5
    },
    "sklearn.tree._classes.ExtraTreeRegressor.__init__.min_impurity_decrease": {
      "0.0": 5
    },
    "sklearn.tree._classes.ExtraTreeRegressor.__init__.min_impurity_split": {
      "None": 5
    },
    "sklearn.tree._classes.ExtraTreeRegressor.__init__.max_leaf_nodes": {
      "None": 5
    },
    "sklearn.tree._classes.ExtraTreeRegressor.__init__.ccp_alpha": {
      "0.0": 5
    },
    "sklearn.tree._export.export_graphviz.label": {
      "'all'": 202
    },
    "sklearn.tree._export.export_graphviz.leaves_parallel": {
      "False": 202
    },
    "sklearn.tree._export.export_text.max_depth": {
      "10": 6
    },
    "sklearn.tree._export.export_text.spacing": {
      "3": 6
    },
    "sklearn.tree._export.export_text.decimals": {
      "2": 6
    },
    "sklearn.tree._export.export_text.show_weights": {
      "False": 6
    },
    "sklearn.tree._export.export_text.print_tree_recurse.node": {},
    "sklearn.tree._export.export_text.print_tree_recurse.depth": {},
    "sklearn.tree._export.plot_tree.impurity": {
      "True": 42
    },
    "sklearn.tree._export.plot_tree.node_ids": {
      "False": 42
    },
    "sklearn.tree._export.plot_tree.rotate": {
      "'deprecated'": 42
    },
    "sklearn.tree._export.plot_tree.precision": {
      "3": 42
    },
    "sklearn.tree.setup.configuration.parent_package": {},
    "sklearn.tree.setup.configuration.top_path": {},
    "sklearn.utils.Bunch.__getattr__.key": {},
    "sklearn.utils.Bunch.__setattr__.key": {},
    "sklearn.utils.Bunch.__setattr__.value": {},
    "sklearn.utils.Bunch.__setstate__.state": {},
    "sklearn.utils._estimator_html_repr.estimator_html_repr.estimator": {},
    "sklearn.utils.all_estimators.type_filter": {
      "None": 1
    },
    "sklearn.utils.all_estimators.is_abstract.c": {},
    "sklearn.utils.axis0_safe_slice.X": {},
    "sklearn.utils.axis0_safe_slice.mask": {},
    "sklearn.utils.axis0_safe_slice.len_mask": {},
    "sklearn.utils.check_matplotlib_support.caller_name": {},
    "sklearn.utils.check_pandas_support.caller_name": {},
    "sklearn.utils.deprecation.deprecated.__call__.obj": {},
    "sklearn.utils.deprecation.deprecated.__init__.extra": {},
    "sklearn.utils.estimator_checks.check_class_weight_balanced_classifiers.name": {},
    "sklearn.utils.estimator_checks.check_class_weight_balanced_classifiers.classifier_orig": {},
    "sklearn.utils.estimator_checks.check_class_weight_balanced_classifiers.X_train": {},
    "sklearn.utils.estimator_checks.check_class_weight_balanced_classifiers.y_train": {},
    "sklearn.utils.estimator_checks.check_class_weight_balanced_classifiers.X_test": {},
    "sklearn.utils.estimator_checks.check_class_weight_balanced_classifiers.y_test": {},
    "sklearn.utils.estimator_checks.check_class_weight_balanced_classifiers.weights": {},
    "sklearn.utils.estimator_checks.check_class_weight_balanced_linear_classifier.name": {},
    "sklearn.utils.estimator_checks.check_class_weight_balanced_linear_classifier.Classifier": {},
    "sklearn.utils.estimator_checks.check_class_weight_classifiers.name": {},
    "sklearn.utils.estimator_checks.check_class_weight_classifiers.classifier_orig": {},
    "sklearn.utils.estimator_checks.check_classifier_data_not_an_array.name": {},
    "sklearn.utils.estimator_checks.check_classifier_data_not_an_array.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_classifier_multioutput.name": {},
    "sklearn.utils.estimator_checks.check_classifier_multioutput.estimator": {},
    "sklearn.utils.estimator_checks.check_classifiers_classes.name": {},
    "sklearn.utils.estimator_checks.check_classifiers_classes.classifier_orig": {},
    "sklearn.utils.estimator_checks.check_classifiers_multilabel_representation_invariance.name": {},
    "sklearn.utils.estimator_checks.check_classifiers_multilabel_representation_invariance.classifier_orig": {},
    "sklearn.utils.estimator_checks.check_classifiers_one_label.name": {},
    "sklearn.utils.estimator_checks.check_classifiers_one_label.classifier_orig": {},
    "sklearn.utils.estimator_checks.check_classifiers_predictions.X": {},
    "sklearn.utils.estimator_checks.check_classifiers_predictions.y": {},
    "sklearn.utils.estimator_checks.check_classifiers_predictions.name": {},
    "sklearn.utils.estimator_checks.check_classifiers_predictions.classifier_orig": {},
    "sklearn.utils.estimator_checks.check_classifiers_regression_target.name": {},
    "sklearn.utils.estimator_checks.check_classifiers_regression_target.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_classifiers_train.name": {},
    "sklearn.utils.estimator_checks.check_classifiers_train.classifier_orig": {},
    "sklearn.utils.estimator_checks.check_classifiers_train.readonly_memmap": {},
    "sklearn.utils.estimator_checks.check_classifiers_train.X_dtype": {},
    "sklearn.utils.estimator_checks.check_clusterer_compute_labels_predict.name": {},
    "sklearn.utils.estimator_checks.check_clusterer_compute_labels_predict.clusterer_orig": {},
    "sklearn.utils.estimator_checks.check_clustering.name": {},
    "sklearn.utils.estimator_checks.check_clustering.clusterer_orig": {},
    "sklearn.utils.estimator_checks.check_clustering.readonly_memmap": {},
    "sklearn.utils.estimator_checks.check_complex_data.name": {},
    "sklearn.utils.estimator_checks.check_complex_data.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_decision_proba_consistency.name": {},
    "sklearn.utils.estimator_checks.check_decision_proba_consistency.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_dict_unchanged.name": {},
    "sklearn.utils.estimator_checks.check_dict_unchanged.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_dont_overwrite_parameters.name": {},
    "sklearn.utils.estimator_checks.check_dont_overwrite_parameters.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_dtype_object.name": {},
    "sklearn.utils.estimator_checks.check_dtype_object.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_estimator.generate_only": {
      "False": 1
    },
    "sklearn.utils.estimator_checks.check_estimator_get_tags_default_keys.name": {},
    "sklearn.utils.estimator_checks.check_estimator_get_tags_default_keys.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_estimator_sparse_data.name": {},
    "sklearn.utils.estimator_checks.check_estimator_sparse_data.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_estimators_data_not_an_array.name": {},
    "sklearn.utils.estimator_checks.check_estimators_data_not_an_array.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_estimators_data_not_an_array.X": {},
    "sklearn.utils.estimator_checks.check_estimators_data_not_an_array.y": {},
    "sklearn.utils.estimator_checks.check_estimators_data_not_an_array.obj_type": {},
    "sklearn.utils.estimator_checks.check_estimators_dtypes.name": {},
    "sklearn.utils.estimator_checks.check_estimators_dtypes.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_estimators_empty_data_messages.name": {},
    "sklearn.utils.estimator_checks.check_estimators_empty_data_messages.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_estimators_fit_returns_self.name": {},
    "sklearn.utils.estimator_checks.check_estimators_fit_returns_self.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_estimators_fit_returns_self.readonly_memmap": {},
    "sklearn.utils.estimator_checks.check_estimators_nan_inf.name": {},
    "sklearn.utils.estimator_checks.check_estimators_nan_inf.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_estimators_overwrite_params.name": {},
    "sklearn.utils.estimator_checks.check_estimators_overwrite_params.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_estimators_partial_fit_n_features.name": {},
    "sklearn.utils.estimator_checks.check_estimators_partial_fit_n_features.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_estimators_pickle.name": {},
    "sklearn.utils.estimator_checks.check_estimators_pickle.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_estimators_unfitted.name": {},
    "sklearn.utils.estimator_checks.check_estimators_unfitted.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_fit1d.name": {},
    "sklearn.utils.estimator_checks.check_fit1d.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_fit2d_1feature.name": {},
    "sklearn.utils.estimator_checks.check_fit2d_1feature.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_fit2d_1sample.name": {},
    "sklearn.utils.estimator_checks.check_fit2d_1sample.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_fit2d_predict1d.name": {},
    "sklearn.utils.estimator_checks.check_fit2d_predict1d.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_fit_idempotent.name": {},
    "sklearn.utils.estimator_checks.check_fit_idempotent.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_fit_non_negative.name": {},
    "sklearn.utils.estimator_checks.check_fit_non_negative.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_fit_score_takes_y.name": {},
    "sklearn.utils.estimator_checks.check_fit_score_takes_y.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_get_params_invariance.name": {},
    "sklearn.utils.estimator_checks.check_get_params_invariance.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_methods_sample_order_invariance.name": {},
    "sklearn.utils.estimator_checks.check_methods_sample_order_invariance.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_methods_subset_invariance.name": {},
    "sklearn.utils.estimator_checks.check_methods_subset_invariance.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_n_features_in.name": {},
    "sklearn.utils.estimator_checks.check_n_features_in.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_n_features_in_after_fitting.name": {},
    "sklearn.utils.estimator_checks.check_n_features_in_after_fitting.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_no_attributes_set_in_init.name": {},
    "sklearn.utils.estimator_checks.check_no_attributes_set_in_init.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_non_transformer_estimators_n_iter.name": {},
    "sklearn.utils.estimator_checks.check_non_transformer_estimators_n_iter.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_nonsquare_error.name": {},
    "sklearn.utils.estimator_checks.check_nonsquare_error.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_outlier_corruption.num_outliers": {},
    "sklearn.utils.estimator_checks.check_outlier_corruption.expected_outliers": {},
    "sklearn.utils.estimator_checks.check_outlier_corruption.decision": {},
    "sklearn.utils.estimator_checks.check_outliers_fit_predict.name": {},
    "sklearn.utils.estimator_checks.check_outliers_fit_predict.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_outliers_train.name": {},
    "sklearn.utils.estimator_checks.check_outliers_train.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_outliers_train.readonly_memmap": {},
    "sklearn.utils.estimator_checks.check_parameters_default_constructible.name": {},
    "sklearn.utils.estimator_checks.check_parameters_default_constructible.Estimator": {},
    "sklearn.utils.estimator_checks.check_parameters_default_constructible.param_filter.p": {},
    "sklearn.utils.estimator_checks.check_pipeline_consistency.name": {},
    "sklearn.utils.estimator_checks.check_pipeline_consistency.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_regressor_data_not_an_array.name": {},
    "sklearn.utils.estimator_checks.check_regressor_data_not_an_array.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_regressor_multioutput.name": {},
    "sklearn.utils.estimator_checks.check_regressor_multioutput.estimator": {},
    "sklearn.utils.estimator_checks.check_regressors_int.name": {},
    "sklearn.utils.estimator_checks.check_regressors_int.regressor_orig": {},
    "sklearn.utils.estimator_checks.check_regressors_no_decision_function.name": {},
    "sklearn.utils.estimator_checks.check_regressors_no_decision_function.regressor_orig": {},
    "sklearn.utils.estimator_checks.check_regressors_train.name": {},
    "sklearn.utils.estimator_checks.check_regressors_train.regressor_orig": {},
    "sklearn.utils.estimator_checks.check_regressors_train.readonly_memmap": {},
    "sklearn.utils.estimator_checks.check_regressors_train.X_dtype": {},
    "sklearn.utils.estimator_checks.check_requires_y_none.name": {},
    "sklearn.utils.estimator_checks.check_requires_y_none.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_sample_weights_invariance.name": {},
    "sklearn.utils.estimator_checks.check_sample_weights_invariance.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_sample_weights_invariance.kind": {},
    "sklearn.utils.estimator_checks.check_sample_weights_list.name": {},
    "sklearn.utils.estimator_checks.check_sample_weights_list.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_sample_weights_not_an_array.name": {},
    "sklearn.utils.estimator_checks.check_sample_weights_not_an_array.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_sample_weights_pandas_series.name": {},
    "sklearn.utils.estimator_checks.check_sample_weights_pandas_series.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_sample_weights_shape.name": {},
    "sklearn.utils.estimator_checks.check_sample_weights_shape.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_set_params.name": {},
    "sklearn.utils.estimator_checks.check_set_params.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_sparsify_coefficients.name": {},
    "sklearn.utils.estimator_checks.check_sparsify_coefficients.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_supervised_y_2d.name": {},
    "sklearn.utils.estimator_checks.check_supervised_y_2d.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_supervised_y_no_nan.name": {},
    "sklearn.utils.estimator_checks.check_supervised_y_no_nan.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_transformer_data_not_an_array.name": {},
    "sklearn.utils.estimator_checks.check_transformer_data_not_an_array.transformer": {},
    "sklearn.utils.estimator_checks.check_transformer_general.name": {},
    "sklearn.utils.estimator_checks.check_transformer_general.transformer": {},
    "sklearn.utils.estimator_checks.check_transformer_general.readonly_memmap": {},
    "sklearn.utils.estimator_checks.check_transformer_n_iter.name": {},
    "sklearn.utils.estimator_checks.check_transformer_n_iter.estimator_orig": {},
    "sklearn.utils.estimator_checks.check_transformer_preserve_dtypes.name": {},
    "sklearn.utils.estimator_checks.check_transformer_preserve_dtypes.transformer_orig": {},
    "sklearn.utils.estimator_checks.check_transformers_unfitted.name": {},
    "sklearn.utils.estimator_checks.check_transformers_unfitted.transformer": {},
    "sklearn.utils.estimator_checks.parametrize_with_checks.estimators": {},
    "sklearn.utils.extmath.cartesian.out": {
      "None": 5
    },
    "sklearn.utils.extmath.fast_logdet.A": {},
    "sklearn.utils.extmath.log_logistic.X": {},
    "sklearn.utils.extmath.log_logistic.out": {},
    "sklearn.utils.extmath.make_nonnegative.X": {},
    "sklearn.utils.extmath.make_nonnegative.min_value": {},
    "sklearn.utils.extmath.randomized_range_finder.A": {},
    "sklearn.utils.extmath.randomized_range_finder.size": {},
    "sklearn.utils.extmath.randomized_range_finder.n_iter": {},
    "sklearn.utils.extmath.randomized_range_finder.power_iteration_normalizer": {},
    "sklearn.utils.extmath.randomized_range_finder.random_state": {},
    "sklearn.utils.extmath.randomized_svd.M": {},
    "sklearn.utils.extmath.randomized_svd.n_components": {},
    "sklearn.utils.extmath.randomized_svd.n_oversamples": {},
    "sklearn.utils.extmath.randomized_svd.n_iter": {},
    "sklearn.utils.extmath.randomized_svd.power_iteration_normalizer": {},
    "sklearn.utils.extmath.randomized_svd.transpose": {},
    "sklearn.utils.extmath.randomized_svd.flip_sign": {},
    "sklearn.utils.extmath.randomized_svd.random_state": {},
    "sklearn.utils.extmath.row_norms.X": {},
    "sklearn.utils.extmath.row_norms.squared": {},
    "sklearn.utils.extmath.safe_sparse_dot.dense_output": {
      "False": 40
    },
    "sklearn.utils.extmath.softmax.X": {},
    "sklearn.utils.extmath.softmax.copy": {},
    "sklearn.utils.extmath.squared_norm.x": {},
    "sklearn.utils.extmath.stable_cumsum.arr": {},
    "sklearn.utils.extmath.stable_cumsum.axis": {},
    "sklearn.utils.extmath.stable_cumsum.rtol": {},
    "sklearn.utils.extmath.stable_cumsum.atol": {},
    "sklearn.utils.extmath.svd_flip.u": {},
    "sklearn.utils.extmath.svd_flip.v": {},
    "sklearn.utils.extmath.svd_flip.u_based_decision": {},
    "sklearn.utils.fixes.delayed.function": {},
    "sklearn.utils.gen_batches.n": {},
    "sklearn.utils.gen_batches.batch_size": {},
    "sklearn.utils.gen_batches.min_batch_size": {},
    "sklearn.utils.gen_even_slices.n": {},
    "sklearn.utils.gen_even_slices.n_packs": {},
    "sklearn.utils.gen_even_slices.n_samples": {},
    "sklearn.utils.get_chunk_n_rows.row_bytes": {},
    "sklearn.utils.get_chunk_n_rows.max_n_rows": {},
    "sklearn.utils.get_chunk_n_rows.working_memory": {},
    "sklearn.utils.graph.single_source_shortest_path_length.graph": {},
    "sklearn.utils.graph.single_source_shortest_path_length.source": {},
    "sklearn.utils.graph.single_source_shortest_path_length.cutoff": {},
    "sklearn.utils.indices_to_mask.indices": {},
    "sklearn.utils.indices_to_mask.mask_length": {},
    "sklearn.utils.is_scalar_nan.x": {},
    "sklearn.utils.multiclass.check_classification_targets.y": {},
    "sklearn.utils.multiclass.class_distribution.y": {},
    "sklearn.utils.multiclass.class_distribution.sample_weight": {},
    "sklearn.utils.multiclass.is_multilabel.y": {},
    "sklearn.utils.resample.stratify": {
      "None": 176
    },
    "sklearn.utils.safe_sqr.copy": {
      "True": 2
    },
    "sklearn.utils.setup.configuration.parent_package": {},
    "sklearn.utils.setup.configuration.top_path": {},
    "sklearn.utils.sparsefuncs.count_nonzero.X": {},
    "sklearn.utils.sparsefuncs.count_nonzero.axis": {},
    "sklearn.utils.sparsefuncs.count_nonzero.sample_weight": {},
    "sklearn.utils.sparsefuncs.csc_median_axis_0.X": {},
    "sklearn.utils.sparsefuncs.incr_mean_variance_axis.X": {},
    "sklearn.utils.sparsefuncs.incr_mean_variance_axis.axis": {},
    "sklearn.utils.sparsefuncs.incr_mean_variance_axis.last_mean": {},
    "sklearn.utils.sparsefuncs.incr_mean_variance_axis.last_var": {},
    "sklearn.utils.sparsefuncs.incr_mean_variance_axis.last_n": {},
    "sklearn.utils.sparsefuncs.incr_mean_variance_axis.weights": {},
    "sklearn.utils.sparsefuncs.inplace_column_scale.X": {},
    "sklearn.utils.sparsefuncs.inplace_column_scale.scale": {},
    "sklearn.utils.sparsefuncs.inplace_csr_column_scale.X": {},
    "sklearn.utils.sparsefuncs.inplace_csr_column_scale.scale": {},
    "sklearn.utils.sparsefuncs.inplace_csr_row_scale.X": {},
    "sklearn.utils.sparsefuncs.inplace_csr_row_scale.scale": {},
    "sklearn.utils.sparsefuncs.inplace_row_scale.X": {},
    "sklearn.utils.sparsefuncs.inplace_row_scale.scale": {},
    "sklearn.utils.sparsefuncs.inplace_swap_column.X": {},
    "sklearn.utils.sparsefuncs.inplace_swap_column.m": {},
    "sklearn.utils.sparsefuncs.inplace_swap_column.n": {},
    "sklearn.utils.sparsefuncs.inplace_swap_row.X": {},
    "sklearn.utils.sparsefuncs.inplace_swap_row.m": {},
    "sklearn.utils.sparsefuncs.inplace_swap_row.n": {},
    "sklearn.utils.sparsefuncs.inplace_swap_row_csc.X": {},
    "sklearn.utils.sparsefuncs.inplace_swap_row_csc.m": {},
    "sklearn.utils.sparsefuncs.inplace_swap_row_csc.n": {},
    "sklearn.utils.sparsefuncs.inplace_swap_row_csr.X": {},
    "sklearn.utils.sparsefuncs.inplace_swap_row_csr.m": {},
    "sklearn.utils.sparsefuncs.inplace_swap_row_csr.n": {},
    "sklearn.utils.sparsefuncs.mean_variance_axis.X": {},
    "sklearn.utils.sparsefuncs.mean_variance_axis.axis": {},
    "sklearn.utils.sparsefuncs.mean_variance_axis.weights": {},
    "sklearn.utils.sparsefuncs.mean_variance_axis.return_sum_weights": {},
    "sklearn.utils.sparsefuncs.min_max_axis.X": {},
    "sklearn.utils.sparsefuncs.min_max_axis.axis": {},
    "sklearn.utils.sparsefuncs.min_max_axis.ignore_nan": {},
    "sklearn.utils.tosequence.x": {},
    "sklearn.utils.validation.as_float_array.X": {},
    "sklearn.utils.validation.as_float_array.copy": {},
    "sklearn.utils.validation.as_float_array.force_all_finite": {},
    "sklearn.utils.validation.assert_all_finite.X": {},
    "sklearn.utils.validation.assert_all_finite.allow_nan": {},
    "sklearn.utils.validation.check_X_y.accept_large_sparse": {
      "True": 21
    },
    "sklearn.utils.validation.check_X_y.order": {
      "None": 21
    },
    "sklearn.utils.validation.check_X_y.copy": {
      "False": 21
    },
    "sklearn.utils.validation.check_X_y.ensure_2d": {
      "True": 21
    },
    "sklearn.utils.validation.check_X_y.allow_nd": {
      "False": 21
    },
    "sklearn.utils.validation.check_X_y.multi_output": {
      "False": 21
    },
    "sklearn.utils.validation.check_X_y.ensure_min_samples": {
      "1": 21
    },
    "sklearn.utils.validation.check_X_y.ensure_min_features": {
      "1": 21
    },
    "sklearn.utils.validation.check_X_y.estimator": {
      "None": 21
    },
    "sklearn.utils.validation.check_array.accept_large_sparse": {
      "True": 59
    },
    "sklearn.utils.validation.check_array.order": {
      "None": 59
    },
    "sklearn.utils.validation.check_array.allow_nd": {
      "False": 59
    },
    "sklearn.utils.validation.check_array.ensure_min_samples": {
      "1": 59
    },
    "sklearn.utils.validation.check_array.ensure_min_features": {
      "1": 59
    },
    "sklearn.utils.validation.check_is_fitted.msg": {
      "None": 50
    },
    "sklearn.utils.validation.check_is_fitted.all_or_any": {
      "all": 50
    },
    "sklearn.utils.validation.check_memory.memory": {},
    "sklearn.utils.validation.check_non_negative.X": {},
    "sklearn.utils.validation.check_non_negative.whom": {},
    "sklearn.utils.validation.check_scalar.x": {},
    "sklearn.utils.validation.check_scalar.name": {},
    "sklearn.utils.validation.check_scalar.target_type": {},
    "sklearn.utils.validation.check_scalar.min_val": {},
    "sklearn.utils.validation.check_scalar.max_val": {},
    "sklearn.utils.validation.check_symmetric.array": {},
    "sklearn.utils.validation.check_symmetric.tol": {},
    "sklearn.utils.validation.check_symmetric.raise_warning": {},
    "sklearn.utils.validation.check_symmetric.raise_exception": {},
    "sklearn.utils.validation.has_fit_parameter.estimator": {},
    "sklearn.utils.validation.has_fit_parameter.parameter": {}
  }
}